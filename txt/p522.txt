process-aware information systems: lessons to
be learned from process mining
w.m.p. van der aalst
department of mathematics and computer science,
eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands.
w.m.p.v.d.aalst@tue.nl
abstract. aprocess-aware information system (pais) is a software
system that manages and executes operational processes involving peo-
ple, applications, and/or information sources on the basis of process mod-
els. example paiss are work°ow management systems, case-handling
systems, enterprise information systems, etc. this paper provides a brief
introduction to these systems and discusses the role of process models
in the pais life-cycle. moreover, it provides a critical re°ection on the
state-of-the-art based on experiences with process mining . process min-
ing techniques attempt to extract non-trivial and useful information from
event logs. one aspect of process mining is control-°ow discovery, i.e.,
automatically constructing a process model (e.g., a petri net) describ-
ing the causal dependencies between activities. the insights provided by
process mining are very valuable for the development of the next gener-
ation paiss because they clearly show a mismatch between the models
proposed for driving these systems and reality. on the one hand, models
tend to oversimplify things resulting in systems that are too restrictive.
on the other hand, models fail to capture important aspects of business
processes.
1 introduction
in the last two decades there has been a shift from \data-aware" information
systems to \process-aware" information systems [24]. to support business pro-
cesses, an enterprise information system needs to be aware of these processes and
their organizational context. early examples of such systems were called work-
flow management (wfm) systems [4, 28, 33, 36, 38, 41, 45, 67]. in more recent
years, vendors prefer the term business process management (bpm) systems.
bpm systems have a wider scope than the classical wfm systems and are not
just focusing on process automation. bpm systems tend to provide more support
for various forms of analysis (e.g., simulation) and management support (e.g.,
monitoring). both wfm and bpm aim to support operational processes that
are often referred to as \work°ow processes" or simply \work°ows". we will use
the generic term process-aware information system (pais) to refer to systems
that manage and execute such work°ows.
in a service oriented architecture (soa) the information system is seen as a
set of connected services. a pais can be realized using such an architecture andin fact it is very natural to see processes as the \glue" connecting services. the ¯t
between soa and pais is illustrated by emerging standards such as bpel [20]
and bpmn [68]. the focus on web services and soa has stirred up enthusiasm
for process-orientation. as a result it is expected that in the future generic paiss
will start to play a more important role. however, at the same time it should
not be forgotten that most paiss are dedicated towards a particular application
domain or even a speci¯c company.
the °ow-oriented nature of work°ow processes makes the petri net formalism
a natural candidate for the modeling and analysis of work°ows. most work°ow
management systems provide a graphical language which is close to petri nets.
although the routing elements are di®erent from petri nets, the informal se-
mantics of the languages used are typically token-based and hence a (partial)
mapping to petri nets is relatively straightforward. this explains the interest in
applying petri nets to paiss.
the purpose of this paper is twofold. on the one hand, we aim to provide
anintroduction to paiss and the role of models in the development and con-
¯guration of such systems. on the other hand, we would like to share some
insights obtained through process mining . process mining exploits event logs of
real processes and uses these to discover models or check the conformance of
existing ones. experiences with process mining show that there are typically
large discrepancies between the idealized models used to con¯gure systems and
the real-life processes. moreover, process mining has changed our perception of
models. for example, there is no such thing as themodel. in any situation dif-
ferent models are possible all providing a particular view on the process at hand.
based on our experiences using process mining, we would like to challenge some
of the basic assumptions related to pais and business process modeling.
the remainder of this paper is organized as follows. section 2 provides a
de¯nition and classi¯cation of paiss. the role of process models is discussed
in section 3 and section 4 brie°y introduces the concept of process mining.
section 5 presents the lessons that can be learned from process mining. this
section serves as a \reality check" for pais research. section 6 concludes the
paper.
2 process-aware information systems
in this paper we adopt the following de¯nition of a process-aware information
system (pais): a software system that manages and executes operational pro-
cesses involving people, applications, and/or information sources on the basis of
process models [24]. although not explicitly stated in this de¯nition, it should
be noted that the process models mentioned are usually represented in some
graphical language, e.g., a petri-net-like notation. the models are typically in-
stantiated multiple times (e.g., for every customer order) and every instance is
handled in a prede¯ned way (possibly with variations).
classical examples of paiss are workflow management (wfm) systems and
business process management (bpm) systems. these systems support opera-tional business processes and are driven by an explicit process representation.
given the above de¯nition, one can see that a text editor is not \process aware"
insofar as it is used to facilitate the execution of speci¯c tasks without any
knowledge of the process of which these tasks are part. a similar comment can
be made regarding e-mail clients used to send and receive electronic mail. a task
in a process may result in an e-mail being sent, but the e-mail client is unaware
of the process it is used in. at any point in time one can send an e-mail to any
person without being supported nor restricted by the e-mail client. text edi-
tors and e-mail clients (at least contemporary ones) are applications supporting
tasks, not processes. the same applies to a large number of applications used in
the context of information systems.
process awareness is an important property for information systems and the
shift from task-driven to paiss brings a number of advantages [24]:
{the use of explicit process models provides a means for communication be-
tween people.
{systems driven by models rather than code have less problems dealing with
change, i.e., if an information system is driven by process models, only the
models need to be changed to support evolving or emerging business pro-
cesses.
{the explicit representation of the processes supported by an organization
allows their automated enactment. this may lead to a better performance.
{the explicit representation of processes enables management support at the
(re)design level, i.e., explicit process models support (re)design e®orts.
{the explicit representation of processes also enables management support at
the control level. generic process monitoring and mining facilities provide
useful information about the process as it unfolds. this information can be
used to improve the control (or even design) of the process.
a detailed introduction paiss is beyond the scope of this paper. however,
to provide an overview of the important issues, we summarize the classi¯cation
given in [24]. in addition, we refer to the well-known work°ow patterns [6, 58,
70].
2.1 design-oriented versus implementation-oriented
figure 1 summarizes the phases of a typical pais life-cycle. in the design phase,
processes are designed (or re-designed) based on the outputs of a requirements
analysis. in the con¯guration phase, designs are re¯ned into an implementation,
typically by con¯guring a generic infrastructure for a process-aware information
system (e.g. a wfm system, a case handing system, or an eai platform). after
con¯guration, the enactment phase starts: the operational processes are executed
using the con¯gured system. in the diagnosis phase, the operational processes
are analyzed to identify problems and to ¯nd aspects that can be improved.
di®erent phases of the pais life-cycle call for di®erent techniques and types
of tools. for example, the focus of traditional wfm systems is on the lower halffig. 1. the pais life-cycle [7].
of the pais life-cycle. they are mainly aimed at supporting process con¯gura-
tion and execution and provide little support for the design and diagnosis phase.
business process modeling tools are design-oriented and may use all kinds of
analysis to evaluate designs. besides classical analysis techniques such as sim-
ulation, more advanced techniques such as process mining come into play, i.e.,
process improvement by learning from running processes.
2.2 people versus software applications
another way of classifying paiss is in terms of the nature of the participants (or
resources) they involve, and in particular whether these participants are humans
or software applications. in this respect, paiss can be classi¯ed into human-
oriented and system-oriented [28] or more precisely into person-to-person (p2p),
person-to-application (p2a) and application-to-application (a2a) processes
[24].
in p2p processes the participants involved are primarily people, i.e. the pro-
cesses primarily involve tasks which require human intervention. job tracking,
project management, and groupware tools are designed to support p2p pro-
cesses. indeed, the processes supported by these tools usually do not involve
entirely automated tasks carried out by applications. also, the applications that
participate in these processes (e.g. project tracking servers, e-mail clients, video-
conferencing tools, etc.) are primarily oriented towards supporting computer-
mediated interactions.
at the other end of the spectrum, a2a processes are those that only in-
volve tasks performed by software systems. such processes are typical in the
area of distributed computing, and in particular distributed application integra-
tion. transaction processing systems, eai platforms, and web-based integration
servers are designed to support a2a processes.
p2a processes are those that involve both human tasks and interactions be-
tween people, and tasks and interactions involving applications which act with-out human intervention. work°ow systems fall in the p2a category since they
primarily aim at making people and applications work in an integrated manner.
note that the boundaries between p2p, p2a, and a2a are not crisp. instead,
there is a continuum of techniques and tools from p2p (i.e. manual, human-
driven) to a2a (automated, application-driven).
2.3 predictability of processes
the degree of structure of the process to be automated (which is strongly linked
to its predictability) is frequently used as a dimension to classify paiss [28].
structured processes are easier to support than unstructured processes. more-
over, it is also obvious that smaller processes are easier to support than larger
ones. however, like in [13, 24] we would like to elaborate on the predictability
aspect. as figure 2 shows, we distinguish between unframed ,ad hoc framed ,
loosely framed , and tightly framed processes.
tightly
framed
loosely
framed
ad hoc
framed
unframed
p2p p2agroupwareproject
managementprocess-aware
collaboration
toolsjob tracking
systemsworkflow
ad hoc
workflowscientific
workflowservice
composition
case
handling
process-unaware
application integration
a2a
fig. 2. type of paiss and associated development tools [24].
a process is said to be unframed if there is no explicit process model associ-
ated with it. this is the case for collaborative processes supported by groupware
systems that do not o®er the possibility of de¯ning process models.
a process is said to be ad hoc framed if a process model is de¯ned a priori but
only executed once or a small number of times before being discarded or changed.
this is the case in project management environments where a process model (i.e.
a project chart) is often only executed once. it is also the case in grid computingenvironments, where a scientist may de¯ne a process model corresponding to a
computation involving a number of datasets and computing resources, and then
run this process only once.
aloosely framed process is one for which there is an a-priori de¯ned process
model and a set of constraints, such that the prede¯ned model describes the
\normal way of doing things" while allowing the actual executions of the process
to deviate from this model within certain limits.
finally, a tightly framed process is one which consistently follows an a-priori
de¯ned process model. this is the case of traditional work°ow systems.
figure 2 plots di®erent types of paiss and pais-related tools with respect
the degree of framing of the underlying processes (unframed, ad hoc, loosely,
or tightly framed), and the nature of the process participants (p2p, p2a, and
a2a) [24].
as with p2p, p2a, and a2a processes, the boundaries between unframed,
ad hoc framed, loosely framed, and tightly framed processes are not crisp. in
particular, there is a continuum between loosely and tightly framed processes.
for instance, during its operational life a process considered to be tightly framed
can start deviating from its model so often and so unpredictably, that at some
point in time it may be considered to have become loosely framed. conversely,
after a large number of cases of a loosely framed process have been executed, a
common structure may become apparent, which may then be used to frame the
process in a tighter way.
the topic of °exibility in paiss attracted a lot of attention in the scienti¯c
community. numerous researchers proposed ways of dealing with °exibility and
change. unfortunately, few of these ideas have been adopted by commercial
parties. moreover, it has become clear that there is no \one size ¯ts all" solution,
i.e., depending on the application, di®erent types of °exibility are needed. in [60]
a taxonomy is given where four types of °exibility are distinguished: (1) °exibility
by design , (2)°exibility by deviation , (3)°exibility by underspeci¯cation , and (4)
°exibility by change (both at type and instance levels). this taxonomy shows
that di®erent types of °exibility exist. moreover, di®erent paradigms may be
used, i.e., even within one °exibility type there may be di®erent mechanisms
that realize di®erent forms of °exibility [63]. all of these approaches aim to
support ad hoc framed and/or loosely framed processes.
2.4 intra-organizational versus inter-organizational
initially, paiss were mainly oriented towards intra-organizational settings. fo-
cus was on the use of process support technologies (e.g. work°ow systems) to
automate operational processes involving people and applications inside an or-
ganization (or even within an organizational unit). over the last few years, there
has been a push towards processes that cross organizational barriers. such inter-
organizational processes can be one-to-one (i.e. bilateral relations), one-to-many
(i.e. an organization interacting with several others) or many-to-many (i.e. a
number of partners interacting with each other to achieve a common goal).the trend towards inter-organizational paiss is marked by the adoption of
soa and the emergence of web services standards such as bpel et al.
3 role of models
in the previous section, we introduced paiss and provided a classi¯cation. in
this section, we focus more on the role of models . first of all, we elaborate on the
di®erent purposes of models (to provide insights, for analysis purposes, or for
enactment). second, we discuss di®erences between formal and informal models.
finally, we di®erentiate between man-made and derived models.
3.1 purpose
models can serve di®erent purposes. in fact, the same model can be used for
di®erent objectives in the context of a pais.
insight when developing or improving a pais it is important that the di®erent
stakeholders get insight into the processes at hand and the way that these pro-
cesses can or should be supported. models can be used to discuss requirements,
to support design decisions, and to validate assumptions. moreover, the modeling
process itself typically provides new and valuable insights because the modeler is
triggered to make things explicit. it is interesting to use the metaphor of a con-
struction drawing for a house. only when people are confronted with concrete
drawings they are able to generate requirements and make their wishes explicit.
this holds for houses but also for other complex artifacts such as information
systems.
analysis using the metaphor of a construction drawing for a house, it is clear
that models can be used to do analysis (e.g., calculating sizes, strengths, etc.).
depending on the type of model, particular types of analysis are possible or not.
moreover, in the context of a pais, analysis may focus on the business processes
or on the information system itself. for example, the performance of a system
(e.g., response times) is not the same as the performance of the processes it
supports. traditionally, most techniques used for the analysis of business pro-
cesses originate from operations research. students taking courses in operations
management will learn to apply techniques such as simulation, queueing theory,
and markovian analysis. the focus mainly is on performance analysis and less
attention is paid to the correctness of models. however, veri¯cation is needed to
check whether the resulting system is free of logical errors. many process designs
su®er from deadlocks and livelocks that could have been detected using veri¯-
cation techniques. notions such as soundness [1, 30] can be used to verify the
correctness of systems. similar notions can be used to check interorganizational
processes where deadlocks, etc. are more likely to occur [9, 39, 42].enactment in the context of a pais, models are often used for enactment,
i.e., based on a model of the process, the corresponding run-time support is
generated. in a wfm system, a model of a process su±ces to generate the cor-
responding system support. in other environments, the set of processes is often
hard-coded. for example, although erp systems like sap have a work°ow en-
gine, most processes are hard-coded into the system and can only be changed
by programming or changing con¯guration parameters. as a result, modi¯ca-
tions are either time-consuming (because of substantial programming e®orts) or
restricted by the set of prede¯ned con¯guration parameters.
3.2 formality of models
related to the purpose of the model is the degree of formality.
informal models informal models cannot be used for enactment and rigorous
analysis. their main purpose is to provide insight, support discussion, etc. we
de¯ne a model to be informal if it is impossible to determine whether a particular
scenario (i.e., a trace of activities) is possible of not.
formal models a formal model is able to tell whether a particular sequence
of activities is possible or not. for example, given a petri net it is possible
to determine whether a trace corresponds to a possible ¯ring sequence. even
declarative models may be formal. for example, given a model in declare [47] or
plain ltl or ctl [40], it is possible to check whether a trace is possible or not.
formal models typically allow for obtaining insights, analysis, and enactment.
however, they may be more di±cult to construct than informal models.
the boundaries between formal and informal models seem well-de¯ned. however,
in practice one can see many semi-formal models (e.g., bpmn, uml activity
diagrams, epcs, etc.). these models started out as informal models without
any formal semantics. however, during the process, subsets have been formal-
ized and are supported by tools that assume particular semantics. the problem
is that some people interpret these models in a \formal way" while others use
these notations in a rather loose manner. consider for example the epc models
in sap where at least 20 percent has serious °aws when one attempts to inter-
pret them in a somewhat unambiguous manner [44]. besides the di®erences in
interpretation there is the problem that some of the informal concepts create
conundrums. for example, the informal semantics of or-join in epcs and other
languages creates the so-called \vicious cycle" paradox [2, 34].
figure 3 illustrates the relation between industry-driven languages, formal
(science-driven) models, and analysis models. the industry-driven languages can
be split into informal, semi-formal, and executable. notations such as bpmn,
epcs, etc. can be seen as semi-formal, i.e., subsets can be interpreted in a
precise manner. languages like bpel and many other work°ow languages are
executable because they are supported by concrete work°ow engines. note thatindustry-driven languages informal executable semi-formal 
bpel bpmn 
epc xpdl dfd 
uml-ad 
science-driven 
formal languages petri nets process algebra 
queueing 
networks markov 
chains analysis models state 
space coverability 
graph invariants fig. 3. relationships among models.
these can be considered as formal although there may be di®erent interpretations
among di®erent systems. however, in the context of a single execution engine,
it is clear what traces are possible and what traces are not possible.
languages like petri nets and various process algebraic languages (csp, ccs,
acp, ¼-calculus, etc.), are formal and mainly driven by the academic community.
the focus is on a clear and unambiguous speci¯cation of the process and not
on a particular analysis technique. however, such formal languages can often be
mapped onto dedicated analysis models. for example, a petri net can be mapped
onto an incidence matrix to calculate invariants or onto a coverability graph to
decide on reachability or boundedness.
let us look at some examples bridging the three layers shown in figure 3.
wo°an is able to translate sta®ware, cosa, protos, and websphere models into
petri nets and then analyze these using the coverability graph and incidence ma-
trix [62]. the toolset bpel2owfn/fiona/lola can be used to analyze bpel
models using open work°ow nets as an intermediate format [39]. these examples
show the possible interplay between various languages.
3.3 construction approach
finally, we distinguish between man-made models and derived models.
man-made models traditionally, one thinks of models as man-made, i.e.,
some designer is constructing the model from scratch. when developing a new
system or process, this is the only way to obtain models.
derived models if there is already a process or system in place, it is also
possible to \derive" models. there are basically two approaches. one approachis to try and reverse engineer models from the system itself, e.g., analyze the
code or con¯guration parameters. another approach is to extract models based
on event logs, i.e., learn from example behavior observed in the past. the next
section on process mining will elaborate on the latter type of derived models.
4 process mining
after an introduction to paiss and discussing the various roles of models in the
context of such systems, we now focus on a particular analysis technique: process
mining [12, 14, 15, 19, 21{23, 26, 32, 35, 43, 52, 64, 65]. the reason for elaborating
on this particular analysis technique is that our experiences with process mining
have dramatically changed our view on paiss and the role of models in these
systems. in fact, the goal of the paper is to provide a critical re°ection on the
state-of-the-art based on experiences with process mining . therefore, we ¯rst
provide a short introduction to process mining and then elaborate on the lessons
learned.
today's information systems are recording events in so-called event logs.
the goal of process mining is to extract information on the process from these
logs, i.e., process mining describes a family of a-posteriori analysis techniques
exploiting the information recorded in the event logs. typically, these approaches
assume that it is possible to sequentially record events such that each event
refers to an activity (i.e., a well-de¯ned step in the process) and is related to a
particular case (i.e., a process instance). furthermore, some mining techniques
use additional information such as the performer or originator of the event (i.e.,
the person/resource executing or initiating the activity), the timestamp of the
event, or data elements recorded with the event (e.g., the size of an order).
process mining addresses the problem that most organizations have very
limited information about what is actually happening in their organization. in
practice, there is often a signi¯cant gap between what is prescribed or supposed
to happen, and what actually happens. only a concise assessment of the orga-
nizational reality, which process mining strives to deliver, can help in verifying
process models, and ultimately be used in a process redesign e®ort or pais
implementation.
the idea of process mining is to discover, monitor and improve real pro-
cesses (i.e., not assumed processes) by extracting knowledge from event logs. we
consider three basic types of process mining (figure 4).
discovery there is no a-priori model, i.e., based on an event log some model is
constructed. for example, using the ®-algorithm [15] a petri net can be discov-
ered based on low-level events. many algorithms have been proposed to discover
the control-°ow [12, 14, 15, 19, 21{23, 32, 35, 43, 64, 65] and few have been prosed
to discover other aspects such as the social network [11].
conformance there is an a-priori model. this model is used to check if reality,
as recorded in the log, conforms to the model and vice versa. for example,models
analyzesrecords
events, e.g., 
messages,
transactions,
etc.specifies
configures
implements
analyzessupports/
controls
people machines
organizationscomponentsbusiness processesfig. 4. three types of process mining: (1) discovery, (2) conformance, and (3) exten-
sion.
there may be a process model indicating that purchase orders of more than one
million euro require two checks. another example is the checking of the four-eyes
principle. conformance checking may be used to detect deviations, to locate and
explain these deviations, and to measure the severity of these deviations. for
examples, we refer to the conformance checking algorithms described in [54].
extension there is an a-priori model. this model is extended with a new
aspect or perspective, i.e., the goal is not to check conformance but to enrich the
model. an example is the extension of a process model with performance data,
i.e., some a-priori process model is used on which bottlenecks are projected.
another example is the decision mining algorithm described in [53] that extends
a given process model with conditions for each decision.
today, process mining tools are becoming available and are being integrated into
larger systems. the prom framework [3] provides an extensive set of analysis
techniques which can be applied to real process enactments while covering the
whole spectrum depicted in figure 4. aris ppm was one of the ¯rst commercial
tools to o®er some support for process mining. using aris ppm, one can ex-
tract performance information and social networks. also some primitive form of
process discovery is supported. however, aris ppm still requires some a-priori
modeling. the bpm jsuite of pallas athena was the ¯rst commercial tool to sup-
port process discovery without a-priori modeling. although the above tools have
been applied to real-life processes, it remains a challenge to extract suitable pro-
cess models from event logs. this is illustrated by recent literature [12, 14, 15,
19, 21{23, 32, 35, 43, 64, 65].5 lessons learned
now we would like to provide a critical re°ection on the state-of-the-art in paiss
based on our experiences with process mining. the insights provided by process
mining are very valuable for the development of the next generation paiss be-
cause they clearly show a mismatch between the models proposed for driving
these systems and reality. on the one hand, models tend to oversimplify things
resulting in systems that are too restrictive. on the other hand, models fail to
capture important aspects of business processes.
in the remainder we present some of the main lessons learned through our
various process mining projects.
5.1 models do not re°ect reality
the ¯rst, and probably the most important, lesson is that models typically
provide a very naive view of reality. reality is typically much more dynamic and
complex than what is captured in models. models should abstract from details
and aspects not relevant for the purpose of the model. however, the discrepancies
that can be found between models and reality can typically not be justi¯ed by
reasons of abstraction.
fig. 5. process discovered based on an event log with information about 2712 patients.to illustrate this consider the process model shown in figure 5. this model
was discovered using prom's heuristics miner [64] based on the data of 2712 pa-
tients treated in a dutch hospital. the log contained 29258 events (i.e., +/- 10.8
events per case) corresponding to 264 activities. the discovered process model
re°ects the complexity of care processes. one may expect such \spaghetti-like
processes" in a hospital. however, we have found similarly unstructured pro-
cesses in many environments where one would expect more structured processes
(e.g., municipalities, banks, insurance companies, etc.). it is important to note
that the spaghetti-like process shown in figure 5 is not due to limitations of the
process mining techniques used, i.e., it is completely caused by the real complex-
ity of the process.
insights provided by process models such as the one shown in figure 5 serve as
a reality check for any pais implementation. without a complete understanding
of the processes at hand, the pais is destined to fail.
to illustrate the discrepancies between models and reality further, consider
figure 6 taken from [55]. these models have been obtained when analyzing one
of the test processes of asml (the leading manufacturer of wafer scanners in
the world). asml designs, develops, integrates and services advanced systems
to produce semiconductors. in short, it makes the wafer scanners that print
the chips. these wafer scanners are used to manufacture semi-conductors (e.g.,
processors in devices ranging from mobile phones ad mp3 players to desktop
computers). at any point in time, asml's wafer scanners record events that can
easily be distributed over the internet. hence, any event that takes place during
the test process is recorded. the availability of these event logs and the desire of
asml to improve the testing process, triggered the case study reported in [55].
if we apply prom's discovery to the low-level logs, we obtain a spaghetti-like
process similar to the one shown in figure 5. however, using domain knowledge
the low level log can be translated to an event log at the so-called job-step level.
asml also provided us with a reference model at the job-step level. this model
was used to instruct the test engineers. figure 6(a) shows the reference model.
the discovered model is shown in figure 6(b). it is interesting to note that the
discovered model allows for much more scenarios than the reference model.
in figure 7 we used prom's conformance checker while analyzing the de-
viations in asml's test process. as shown the ¯tness is only 37.5 percent, i.e.,
roughly one third of the events can be explained by the model indicating that
\exceptions are the rule" [54]. by looking at the most frequent paths that appear
in figure 6(b) and not in figure 6(a) and at the diagnostics provided in figure 7
it is possible to pinpoint the most important deviations. note that deviations
are not necessarily a bad thing and may re°ect (desirable) °exibility. we will
elaborate on this in section 5.3.
the results presented in this section are not exceptional, i.e., many processes
turn out to be more spaghetti-like than expected. nevertheless, most attention
in both academia and industry is given to the analysis and use of models and not
to the way to obtain them. both sides take models as a starting point. analysis
techniques, process engines, etc. focus on what to do with models rather than(b) discovered process model (a) reference process model fig. 6. two heuristic nets [43, 64] showing the di®erence between (a) the translated
reference model for the test process on job-step level and (b) the discovered process
model based on log which was mapped onto the job-step level [55].fig. 7. screenshot of prom's conformance checker while analyzing the di®erence be-
tween the reference model and reality [55].
obtaining faithful models. therefore, we would like to stress the need for more
emphasis on the faithfulness of models. for example, analysis results are only
meaningful if the corresponding models are adequate.
5.2 a human's characteristics are di±cult to capture
in the previous section, we focused in discrepancies between the control-°ow as
modeled and the real control-°ow. when it comes to resources similar problems
emerge, especially if the resources are human. this mismatch becomes evident
when comparing the behavior of humans observed when using process mining
techniques and the behavior of humans assumed in simulation tools [10]. in the
remainder, we focus on the problems encountered when modeling people for
simulation purposes. however, the insights also apply to other analysis methods
and enactment support (e.g., software for work distribution).
in practice there are few people that only perform activities for a single
process. often people are involved in many di®erent processes, e.g., a manager,
doctor, or specialist may perform tasks in a wide range of processes. however,
simulation often focuses on a single process. suppose a manager is involved in
10 di®erent processes and spends about 20 percent of his time on the process
that we want to analyze. in most simulation tools it is impossible to model that
a resource is only available 20 percent of the time. hence, one needs to assume
that the manager is there all the time and has a very low utilization. as a result
the simulation results are too optimistic. in the more advanced simulation tools,
one can indicate that resources are there at certain times in the week (e.g., only
on monday). this is also an incorrect abstraction as the manager distributes
his work over the various processes based on priorities and workload. suppose
that there are 5 managers all working 20 percent of their time on the process ofinterest. one could think that these 5 managers could be replaced by a single
manager (5*20%=1*100%). however, from a simulation point of view this is an
incorrect abstraction. there may be times that all 5 managers are available and
there may be times that none of them are available.
another problem is that people work at di®erent speeds based on their work-
load, i.e., it is not just the distribution of attention over various processes, but
also a person's absolute working speed in°uences his/her capacity for a particular
process. there are various studies that suggest a relation between workload and
performance of people. a well-known example is the so-called yerkes-dodson
law [69]. the yerkes-dodson law models the relationship between arousal and
performance as an inverse u-shaped curve. this implies that for a given indi-
vidual and a given type of tasks, there exists an optimal arousal level. this is
the level where the performance has its maximal value. thus work pressure is
productive, up to a certain point, beyond which performance collapses. although
this phenomenon can be easily observed in daily life, today's business process
simulation tools do not support the modeling of workload dependent processing
times.
as indicated earlier, people may be involved in di®erent processes. moreover,
they may work part-time (e.g., only in the morning). in addition to their limited
availabilities, people have a tendency to work in batches (cf. resource pattern 38:
piled execution [58]). in any operational process, the same task typically needs
to be executed for many di®erent cases (process instances). often people prefer
to let work-items related to the same task accumulate, and then process all of
these in one batch. in most simulation tools a resource is either available or not,
i.e., it is assumed that a resource is eagerly waiting for work and immediately
reacts to any work-item that arrives. clearly, this does not do justice to the
way people work in reality. for example, consider how and when people reply to
e-mails. some people handle e-mails one-by-one when they arrive while others
process all of their e-mails at ¯xed times in batch.
also related is the fact that calendars and shifts are typically ignored in
simulation tools. while holidays, lunch breaks, etc. can heavily impact the per-
formance of a process, they are typically not incorporated in the simulation
model.
all these observations show that it is very di±cult to adequately capture
human activity in simulation models. as a result it is not uncommon that the
simulation model predicts a °ow time of hours while in reality the average °ow
time is weeks. in [10] the e®ects of some of these incorrect assumptions on the
simulation results are shown. using process mining one can get insight into the
way that humans actually work and use this to build more faithful simulation
models.
note that the di±culties encountered when characterizing humans is not
only relevant for simulation but also for enactment support. it can be observed
that only few of the resource patterns [58] are supported by contemporary paiss.
moreover, insights such as the yerkes-dodson law are not used by today's paissand systems are unable to predict problems. the lack of understanding and
limited functionality impairs the successfulness of paiss.
5.3 spaghetti and flexibility: two sides of the same coin
the topic of °exibility in the context wfm systems has been addressed by
many authors [16, 18, 25, 27, 47, 48, 51, 66]. see the taxonomy in [60] or the °ex-
ibility patterns in [63] to get an overview of the di®erent approaches proposed
in literature. see also [8, 17, 28, 31, 46, 50, 59] for other classi¯cations of °exibil-
ity. researchers proposed numerous ways of dealing with °exibility and change.
unfortunately, few of these ideas have been adopted by commercial parties. pro-
cess mining can expose the need for °exibility. spaghetti-like processes as shown
in figure 5 and the quanti¯cation of non-conformance illustrated by figure 7
illustrate the need for °exibility.
when building a pais for existing processes, process mining can be used
to identify the °exibility needs. when looking at the spaghetti-like processes
discovered using process mining, it becomes evident that one has to decide on
what kinds of variability are actually desired. some deviations are good because
they correspond to adequate responses to requests from the environment. other
deviations may be undesirable because they impair quality or e±ciency.
it is easy to say that paiss should provide more °exibility. however, process
mining also shows that it is very di±cult to actually do this. it seems that much
of the research in this domain is rather naive. for example, it is ridiculous to
assume that end-users will be able construct or even understand process models
such as the one depicted in figure 5.
5.4 process models should be treated as maps
there are dozens of process modeling languages. most of these languages pro-
vide some graphical notation with split and join nodes of particular types (and,
xor, etc.). although there are important semantical di®erences between these
notations, the basic idea is always to draw a graph describing the routing of
process instances (cases). this seems to be a good approach as it is adopted by
most vendors and common practice in industry. nevertheless, our experiences
with process mining have revealed several weaknesses associated with this clas-
sical approach. diagrams like figure 5 show that automatically derived models
are di±cult to understand and lack expressiveness. this triggered us to look at
process models as ordinary geographic maps. the \map metaphor" reveals some
interesting insights.
{there is no such thing as \the map". one may use city maps, highway maps,
hiking maps, cycling maps, booting maps, etc. depending on the purpose for
which it is intended to be used. all of these maps refer to the same reality.
however, nobody would aim at trying to construct a single map that suits
all purposes. unfortunately, when it comes to processes one typically aims
at a single map.{another insight is that process models do not exploit colors, dimensions,
sizes, etc. it is remarkable that process models typically have shapes (nodes
and arcs) of a ¯xed size, and, even if the size is variable, it has no semantical
interpretation. colors in process models are only used for beati¯cation and
not to express things like intensity, costs, etc. on a geographic map the
x and y dimension have a clear interpretation. these dimensions are not
explicitly used when drawing process models.
ab
d
c
ab
d
cthe thickness of an arrow or 
node indicates its frequency, 
e.g., activity b is more frequent 
than activity c. the size of a node 
refers to the costs 
involved, e.g., d is  
more costly than a. 
the x-dimension has a temporal interpretation, 
i.e., the time between a and b or c is shorter 
than the time between b or c and d. time (a) ordinary petri net just showing the control-flo w logic. 
(b) petri net also showing other dimensions (freque ncy, time, and costs). 
fig. 8. using the map metaphor for drawing process models.
to illustrate the above, consider figure 8 showing two times the same petri
net. although from a logical point of view the petri nets are identical, the lower
one also shows frequencies, costs, and time. for example, it is shown that the path
(a; b; d ) is much more frequent than the path ( a; c; d ). moreover, activities
canddare more costly than aandb. the x-dimension is used to re°ect
time. the horizontal position corresponds to the average time at which activity
takes places after the model is initiated by placing a token on the input place. it
clearly shows that most time is spent waiting for the execution of d. figure 8(b)is still very primitive compared to the drawing of maps. maps typically also use
colors and other intuitive annotations to indicate relevant information. moreover,
maps abstract and aggregate. abstraction is used to leave out things that are
less signi¯cant (i.e., dirt roads and small townships). aggregation is used to take
things together. for example, the roads of a city are taken together into a single
shape. in terms of figure 8, abstraction could mean that cis removed because
it is too insigni¯cant. aggregation should be used to group a,b, and cinto a
single node because they typically occur together in a short time distance.
today, electronic maps overcome some of the limitations of paper maps. as
indicated above one may use di®erent maps (city maps, highway maps, etc.)
depending on the purpose. when using google maps or a car navigation system
like tomtom it is possible to dynamically zoom-in, zoom-out, change focus, or
change the type of information. moreover, these electronic maps are increasingly
used to project dynamic information on. for example tomtom is able to show
tra±c jams, fuel stations with the lowest prices, weather information, etc. these
ideas can also be used for process models.
{process models should allow for di®erent views, i.e., it should be possible to
zoom-in and zoom-out seamlessly. the static decompositions used by con-
temporary drawing tools force the user to view processes in a ¯xed manner.
moreover, decompositions typically address the needs of a technical designer
rather than an end-user. hence the challenge is to be able to support easy
navigation and seamlessly zooming-in/out when viewing process models.
{it should be possible to project dynamic information on top of process mod-
els. for example, it should be possible to view current process instances
projected on the process model and to animate history by replaying past
events on the same process model. this is similar to showing real-time traf-
¯c information by a car navigation system like tomtom.
insigniﬁcant roads 
are not shown. 
parts of the city 
are merged. focuses on the 
intended use and 
level of detail. 
highways are highlighted 
by size, contrast and color.abstraction 
aggregation customization 
emphasis 
fig. 9. prom's fuzzy miner implements some of the ideas learned from (electronic)
maps [29].
the limitations related to the representation and visualization of process
models mentioned above became evident based on experiences gathered in manyprocess mining projects. it seems that the \map metaphor" can be used to
present process models and process information in completely new ways [29, 37].
few researchers have been investigating such ideas. here we would like to point
out two ideas we have been working on. in the context of yawl [5, 37, 61, 72],
we showed that it is possible to show current work items on top of various maps.
work items can be shown on top of a geographic map, a process model, a time
chart, an organizational model, etc. in the context of prom, we have used the
\map metaphor" to enhance the so-called fuzzy miner [29]. as presented in [29],
four ideas are being combined in prom's fuzzy miner to draw maps of process
models.
{aggregation: to limit the number of information items displayed, maps often
show coherent clusters of low-level detail information in an aggregated man-
ner. one example are cities in road maps, where particular houses and streets
are combined within the citys transitive closure (e.g., the city of eindhoven
in figure 9).
{abstraction: lower-level information which is insigni¯cant in the chosen con-
text is simply omitted from the visualization. examples are bicycle paths,
which are of no interest in a motorists map.
{emphasis: more signi¯cant information is highlighted by visual means such
as color, contrast, saturation, and size. for example, maps emphasize more
important roads by displaying them as thicker, more colorful and contrasting
lines (e.g., motorway \e25" in figure 9).
{customization: there is no one single map for the world. maps are spe-
cialized on a de¯ned local context, have a speci¯c level of detail (city maps
vs highway maps), and a dedicated purpose (interregional travel vs alpine
hiking).
figure 10 shows screenshot of prom's fuzzy miner [29]. the left screen shows
a discovered model. note that the thickness of each arc is determined by the
number of times this path is taken (i.e., frequency). moreover, some nodes and
arcs have been left out because they are insigni¯cant. the left screen shows
an animation based on historic information. this animation shows the actual
execution of cases on top of the discovered model.
it is obvious that the ideas presented here are not limited to process mining.
when developing, analyzing, or controlling a pais, such visualizations can be
very useful.
5.5 analysis techniques do not use the information available
the last lesson to be learned is related to the limited use of existing artifacts.
people tend to model things from scratch and do not use information that is
already recorded in information systems. in practice, it is time consuming to
construct a good process model. for example, when constructing a simulation
model one not only has to construct a model but also determine the input pa-
rameters. a pitfall of current approaches is that existing artifacts (models, logs,fig. 10. prom's fuzzy miner (left) and the corresponding animation facility (right).
data, etc.) are not used in a direct and systematic manner. if a pais is used,
there are often models that are used to con¯gure the system (e.g., work°ow
schemas). today, these models are typically disconnected from the simulation
models and created separately. sometimes a business process modeling tool is
used to make an initial process design. this design can be used for simulation
purposes when using a tool like protos or aris. when the designed process is
implemented, another system is used and the connection between the implemen-
tation model and the design model is lost. it may be that at a later stage, when
the process needs to be analyzed, a simulation model is built from scratch. this
is a pity as the pais contains most of the information required. as a result the
process is \reinvented" again and again, thus introducing errors and unnecessary
work. the lack of reuse also applies to other sources of information. for example,
the pais may provide detailed event logs. therefore, there is no need to \in-
vent" processing times, arrival times, and routing probabilities, etc. all of this
information can be extracted from the logs. note that a wealth of information
can be derived from event logs. in fact, in [56] it is demonstrated that complete
simulation models can be extracted from event logs.
contemporary simulation tools tend to support experiments that start in
an arbitrary initial state (without any cases in the pipeline) and then simulate
the process for a long period to make statements about the steady-state be-
havior. however, this steady-state behavior does not exist (the environment of
the process changes continuously) and is thus considered irrelevant by the man-
ager. moreover, the really interesting questions are related to the near future.
therefore, it seems vital to also support transient analysis, often referred to asshort-term simulation [49, 57, 71]. the \fast-forward button" provided by short-
term simulation is a useful option, however, it requires the use of the current
state. fortunately, when using a pais it is relatively easy to obtain the current
state and load this into the simulation model.
the above not only applies to simulation models. also other types of analysis
can bene¯t from the information stored in and recorded by the pais [57].
6 conclusion
work°ow management systems, case-handling systems, enterprise information
systems, etc. are all examples of paiss. we introduced these systems by char-
acterizing them in several ways. moreover, we elaborated on the role of process
models in the context of such systems. after this introduction, we focused on
lessons learned from process mining. the goal of process mining is to extract
information from event logs. these event logs can be used to automatically gen-
erate models (process discovery) or to compare models with reality (conformance
checking).
extensive experience gathered through various process mining projects, has
revealed important lessons for the development and use of paiss. the ¯rst lesson
is that models typically provide a very naive view of reality. the second lesson
is that it is far from trivial to adequately capture the characteristics of human
actors. the third lesson is that the true need for °exibility can be seen by
analyzing spaghetti-like process models. the fourth lesson is that the way we
view processes can be improved dramatically by using the \map metaphor". the
¯fth lesson is that many artifacts (models and logs) remain unused by today's
analysis approaches.
although these lessons were triggered by the application of process mining
to many real-life logs, they are useful for the whole pais life-cycle. it does not
make any sense to talk about analysis or enactment, without a good and deep
understanding of the processes at hand.
acknowledgements
parts of the work reported in this paper are the result of joint work with many
other researchers from tu/e and qut. section 2 is based on joint work with
marlon dumas and arthur ter hofstede [24]. the experiences reported in sec-
tion 5 were only possible because the maturity of our process mining tool prom.
therefore, the author would like to thank the many people involved in the de-
velopment of prom.
references
1.w.m.p. van der aalst. the application of petri nets to work°ow management.
the journal of circuits, systems and computers , 8(1):21{66, 1998.2.w.m.p. van der aalst, j. desel, and e. kindler. on the semantics of epcs: a
vicious circle. in m. nä uttgens and f.j. rump, editors, proceedings of the epk
2002: business process management using epcs , pages 71{80, trier, germany,
november 2002. gesellschaft fä ur informatik, bonn.
3.w.m.p. van der aalst, b.f. van dongen, c.w. gä unther, r.s. mans, a.k. alves
de medeiros, a. rozinat, v. rubin, m. song, h.m.w. verbeek, and a.j.m.m.
weijters. prom 4.0: comprehensive support for real process analysis. in j. kleijn
and a. yakovlev, editors, application and theory of petri nets and other models of
concurrency (icatpn 2007) , volume 4546 of lecture notes in computer science ,
pages 484{494. springer-verlag, berlin, 2007.
4.w.m.p. van der aalst and k.m. van hee. work°ow management: models, methods,
and systems . mit press, cambridge, ma, 2004.
5.w.m.p. van der aalst and a.h.m. ter hofstede. yawl: yet another work°ow
language. information systems , 30(4):245{275, 2005.
6.w.m.p. van der aalst, a.h.m. ter hofstede, b. kiepuszewski, and a.p. barros.
work°ow patterns. distributed and parallel databases , 14(1):5{51, 2003.
7.w.m.p. van der aalst, a.h.m. ter hofstede, and m. weske. business process man-
agement: a survey. in w.m.p. van der aalst, a.h.m. ter hofstede, and m. weske,
editors, international conference on business process management (bpm 2003) ,
volume 2678 of lecture notes in computer science , pages 1{12. springer-verlag,
berlin, 2003.
8.w.m.p. van der aalst and s. jablonski. dealing with work°ow change: identi¯ca-
tion of issues and solutions. international journal of computer systems, science,
and engineering , 15(5):267{276, 2000.
9.w.m.p. van der aalst, n. lohmann, p. massuthe, c. stahl, and k. wolf. from
public views to private views: correctness-by-design for services. in m. dumas
and h. heckel, editors, proceedings of the 4th international workshop on web
services and formal methods (ws-fm 2007) , volume 4937 of lecture notes in
computer science , pages 139{153. springer-verlag, berlin, 2008.
10.w.m.p. van der aalst, j. nakatumba, a. rozinat, and n. russell. business process
simulation: how to get it right? in j. vom brocke and m. rosemann, editors,
international handbook on business process management . springer-verlag, berlin,
2008.
11.w.m.p. van der aalst, h.a. reijers, and m. song. discovering social networks
from event logs. computer supported cooperative work , 14(6):549{593, 2005.
12.w.m.p. van der aalst, h.a. reijers, a.j.m.m. weijters, b.f. van dongen, a.k.
alves de medeiros, m. song, and h.m.w. verbeek. business process mining: an
industrial application. information systems , 32(5):713{732, 2007.
13.w.m.p. van der aalst, m. sto®ele, and j.w.f. wamelink. case handling in con-
struction. automation in construction , 12(3):303{320, 2003.
14.w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. work°ow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237{267, 2003.
15.w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. work°ow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128{1142, 2004.
16.w.m.p. van der aalst, m. weske, and d. grä unbauer. case handling: a new
paradigm for business process support. data and knowledge engineering ,
53(2):129{162, 2005.
17.m. adams. facilitating dynamic flexibility and exception handling for work°ows .
phd thesis, queensland university of technology, 2007.18.m. adams, a.h.m. ter hofstede, w.m.p. van der aalst, and d. edmond. dynamic,
extensible and context-aware exception handling for work°ows. in f. curbera,
f. leymann, and m. weske, editors, proceedings of the otm conference on co-
operative information systems (coopis 2007) , volume 4803 of lecture notes in
computer science , pages 95{112. springer-verlag, berlin, 2007.
19.r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
°ow logs. in sixth international conference on extending database technology ,
pages 469{483, 1998.
20.a. alves, a. arkin, s. askary, c. barreto, b. bloch, f. curbera, m. ford,
y. goland, a. guzar, n. kartha, c.k. liu, r. khalaf, dieter koenig, m. marin,
v. mehta, s. thatte, d. rijn, p. yendluri, and a. yiu. web services business pro-
cess execution language version 2.0 (oasis standard). ws-bpel tc oasis,
http://docs.oasis-open.org/wsbpel/2.0/wsbpel-v2.0.html, 2007.
21.r. bergenthum, j. desel, r. lorenz, and s. mauser. process mining based on
regions of languages. in g. alonso, p. dadam, and m. rosemann, editors, inter-
national conference on business process management (bpm 2007) , volume 4714
oflecture notes in computer science , pages 375{383. springer-verlag, berlin,
2007.
22.a. datta. automating the discovery of as-is business process models: proba-
bilistic and algorithmic approaches. information systems research , 9(3):275{301,
1998.
23.b.f. van dongen and w.m.p. van der aalst. multi-phase process mining: building
instance graphs. in p. atzeni, w. chu, h. lu, s. zhou, and t.w. ling, editors, in-
ternational conference on conceptual modeling (er 2004) , volume 3288 of lecture
notes in computer science , pages 362{376. springer-verlag, berlin, 2004.
24.m. dumas, w.m.p. van der aalst, and a.h.m. ter hofstede. process-aware infor-
mation systems: bridging people and software through process technology . wiley
& sons, 2005.
25.s. dustdar. caramba - a process-aware collaboration system supporting ad hoc
and collaborative processes in virtual teams. distributed and parallel databases ,
15(1):45{66, 2004.
26.s. dustdar and r. gombotz. discovering web service work°ows using web
services interaction mining. international journal of business process integration
and management , 1(4):256{266, 2006.
27.c.a. ellis, k. keddara, and g. rozenberg. dynamic change within work°ow
systems. in n. comstock, c. ellis, r. kling, j. mylopoulos, and s. kaplan, editors,
proceedings of the conference on organizational computing systems , pages 10 {
21, milpitas, california, august 1995. acm sigois, acm press, new york.
28.d. georgakopoulos, m. hornick, and a. sheth. an overview of work°ow manage-
ment: from process modeling to work°ow automation infrastructure. distributed
and parallel databases , 3:119{153, 1995.
29.c.w. gä unther and w.m.p. van der aalst. fuzzy mining: adaptive process sim-
pli¯cation based on multi-perspective metrics. in g. alonso, p. dadam, and
m. rosemann, editors, international conference on business process management
(bpm 2007) , volume 4714 of lecture notes in computer science , pages 328{343.
springer-verlag, berlin, 2007.
30.k.m. van hee, n. sidorova, and m. voorhoeve. generalised soundness of work°ow
nets is decidable. in j. cortadella and w. reisig, editors, application and theory
of petri nets 2004 , volume 3099 of lecture notes in computer science , pages
197{215. springer-verlag, berlin, 2004.31.p. heinl, s. horn, s. jablonski, j. neeb, k. stein, and m. teschke. a compre-
hensive approach to flexibility in work°ow management systems. in g. geor-
gakopoulos, w. prinz, and a.l. wolf, editors, work activities coordination and
collaboration (wacc'99) , pages 79{88, san francisco, february 1999. acm press.
32.j. herbst. a machine learning approach to work°ow management. in proceedings
11th european conference on machine learning , volume 1810 of lecture notes in
computer science , pages 183{194. springer-verlag, berlin, 2000.
33.s. jablonski and c. bussler. work°ow management: modeling concepts, architec-
ture, and implementation . international thomson computer press, london, uk,
1996.
34.e. kindler. on the semantics of epcs: a framework for resolving the vicious
circle. data and knowledge engineering , 56(1):23{40, 2006.
35.e. lamma, p. mello, m. montali, f. riguzzi, and s. storari. inducing declar-
ative logic-based models from labeled traces. in g. alonso, p. dadam, and
m. rosemann, editors, international conference on business process management
(bpm 2007) , volume 4714 of lecture notes in computer science , pages 344{359.
springer-verlag, berlin, 2007.
36.p. lawrence, editor. work°ow handbook 1997, work°ow management coalition .
john wiley and sons, new york, 1997.
37.m. de leoni, w.m.p. van der aalst, and a.h.m. ter hofstede. visual support for
work assignment in process-aware information systems. in m. dumas, m. re-
ichert, and m.c. shan, editors, international conference on business process man-
agement (bpm 2008) , volume 5240 of lecture notes in computer science , pages
67{83. springer-verlag, berlin, 2008.
38.f. leymann and d. roller. production work°ow: concepts and techniques .
prentice-hall ptr, upper saddle river, new jersey, usa, 1999.
39.n. lohmann, p. massuthe, c. stahl, and d. weinberg. analyzing interacting
bpel processes. in s. dustdar, j.l. faideiro, and a. sheth, editors, international
conference on business process management (bpm 2006) , volume 4102 of lecture
notes in computer science , pages 17{32. springer-verlag, berlin, 2006.
40.z. manna and a. pnueli. the temporal logic of reactive and concurrent systems:
speci¯cation . springer-verlag, new york, 1991.
41.d.c. marinescu. internet-based work°ow management: towards a semantic
web, volume 40 of wiley series on parallel and distributed computing . wiley-
interscience, new york, 2002.
42.p. massuthe, w. reisig, and k. schmidt. an operating guideline approach to
the soa. annals of mathematics, computing & teleinformatics , 1(3):35{43, 2005.
43.a.k. alves de medeiros, a.j.m.m. weijters, and w.m.p. van der aalst. genetic
process mining: an experimental evaluation. data mining and knowledge dis-
covery , 14(2):245{304, 2007.
44.j. mendling, g. neumann, and w.m.p. van der aalst. understanding the occur-
rence of errors in process models based on metrics. in f. curbera, f. leymann,
and m. weske, editors, proceedings of the otm conference on cooperative infor-
mation systems (coopis 2007) , volume 4803 of lecture notes in computer science ,
pages 113{130. springer-verlag, berlin, 2007.
45.m. zur muehlen. work°ow-based process controlling: foundation, design and
application of work°ow-driven process information systems . logos, berlin, 2004.
46.m. pesic. constraint-based work°ow management systems: shifting control to
users . phd thesis, eindhoven university of technology, may 2008.47.m. pesic, m. h. schonenberg, n. sidorova, and w.m.p. van der aalst. constraint-
based work°ow models: change made easy. in f. curbera, f. leymann, and
m. weske, editors, proceedings of the otm conference on cooperative information
systems (coopis 2007) , volume 4803 of lecture notes in computer science , pages
77{94. springer-verlag, berlin, 2007.
48.m. reichert and p. dadam. adept°ex: supporting dynamic changes of
work°ow without loosing control. journal of intelligent information systems ,
10(2):93{129, 1998.
49.h.a. reijers and w.m.p. van der aalst. short-term simulation: bridging the gap
between operational control and strategic decision making. in m.h. hamza,
editor, proceedings of the iasted international conference on modelling and
simulation , pages 417{421. iasted/acta press, anaheim, usa, 1999.
50.s. rinderle, m. reichert, and p. dadam. evaluation of correctness criteria
for dynamic work°ow changes. in w.m.p. van der aalst, a.h.m. ter hofstede,
and m. weske, editors, international conference on business process management
(bpm 2003) , volume 2678 of lecture notes in computer science , pages 41{57.
springer-verlag, berlin, 2003.
51.s. rinderle, m. reichert, and p. dadam. correctness criteria for dynamic
changes in work°ow systems: a survey. data and knowledge engineering ,
50(1):9{34, 2004.
52.a. rozinat and w.m.p. van der aalst. conformance testing: measuring the fit
and appropriateness of event logs and process models. in c. bussler et al., editor,
bpm 2005 workshops (workshop on business process intelligence) , volume 3812
oflecture notes in computer science , pages 163{176. springer-verlag, berlin,
2006.
53.a. rozinat and w.m.p. van der aalst. decision mining in prom. in s. dustdar,
j.l. faideiro, and a. sheth, editors, international conference on business process
management (bpm 2006) , volume 4102 of lecture notes in computer science ,
pages 420{425. springer-verlag, berlin, 2006.
54.a. rozinat and w.m.p. van der aalst. conformance checking of processes based
on monitoring real behavior. information systems , 33(1):64{95, 2008.
55.a. rozinat, i.s.m. de jong, c.w. gä unther, and w.m.p. van der aalst. process
mining of test processes: a case study. beta working paper series, wp 220,
eindhoven university of technology, eindhoven, 2007.
56.a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering col-
ored petri nets from event logs. international journal on software tools for
technology transfer , 10(1):57{74, 2008.
57.a. rozinat, m.t. wynn, w.m.p. van der aalst, a.h.m. ter hofstede, and c. fidge.
work°ow simulation for operational decision support using design, historic and
state information. in m. dumas, m. reichert, and m.c. shan, editors, interna-
tional conference on business process management (bpm 2008) , volume 5240 of
lecture notes in computer science , pages 196{211. springer-verlag, berlin, 2008.
58.n. russell, w.m.p.van der aalst, a.h.m. ter hofstede, and d. edmond. work°ow
resource patterns: identi¯cation, representation and tool support. in o. pastor
and j. falcao e cunha, editors, proceedings of the 17th conference on advanced
information systems engineering (caise'05) , volume 3520 of lecture notes in
computer science , pages 216{232. springer-verlag, berlin, 2005.
59.s. sadiq, w. sadiq, and m. orlowska. pockets of flexibility in work°ow speci¯ca-
tion. in proceedings of the 20th international conference on conceptual modeling
(er 2001) , volume 2224 of lecture notes in computer science , pages 513{526.
springer-verlag, berlin, 2001.60.h. schonenberg, r. mans, n. russell, n. mulyar, and w.m.p. van der aalst.
process flexibility: a survey of contemporary approaches. in j. dietz, a. albani,
and j. barjis, editors, advances in enterprise engineering i , volume 10 of lecture
notes in business information processing , pages 16{30. springer-verlag, berlin,
2008.
61.a. streit, b. pham, and r. brown. visualisation support for managing large
business process speci¯cations. in w.m.p. van der aalst, a.h.m. ter hofstede,
and m. weske, editors, international conference on business process management
(bpm 2005) , volume 2678 of lecture notes in computer science , pages 205|219.
springer-verlag, berlin, 2005.
62.h.m.w. verbeek, t. basten, and w.m.p. van der aalst. diagnosing work°ow
processes using wo°an. the computer journal , 44(4):246{279, 2001.
63.b. weber, m. reichert, and s. rinderle-ma. change patterns and change support
features: enhancing flexibility in process-aware information systems. data and
knowledge engineering , 66(3):438{466, 2008.
64.a.j.m.m. weijters and w.m.p. van der aalst. rediscovering work°ow models
from event-based data using little thumb. integrated computer-aided engi-
neering , 10(2):151{162, 2003.
65.l. wen, w.m.p. van der aalst, j. wang, and j. sun. mining process models with
non-free-choice constructs. data mining and knowledge discovery , 15(2):145{180,
2007.
66.m. weske. formal foundation and conceptual design of dynamic adaptations in
a work°ow management system. in r. sprague, editor, proceedings of the thirty-
fourth annual hawaii international conference on system science (hicss-34) .
ieee computer society press, los alamitos, california, 2001.
67.m. weske. business process management: concepts, languages, architectures .
springer-verlag, berlin, 2007.
68.s.a. white et al. business process modeling notation speci¯cation (version 1.0,
omg final adopted speci¯cation), 2006.
69.c.d. wickens. engineering psychology and human performance . harper, 1992.
70.work°ow patterns home page. http://www.work°owpatterns.com.
71.m.t. wynn, m. dumas, c.j. fidge, a.h.m. ter hofstede, and w.m.p. van der
aalst. business process simulation for operational decision support. in a. ter
hofstede, b. benatallah, and h.y. paik, editors, bpm 2007 international work-
shops (bpi, bpd, cbp, prohealth, refmod, semantics4ws) , volume 4928 of lec-
ture notes in computer science , pages 66{77. springer-verlag, berlin, 2008.
72.yawl home page. http://www.citi.qut.edu.au/yawl/.