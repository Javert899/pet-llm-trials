improving product usage monitoring
and analysis with semantic concepts
mathias funk1, anne rozinat2, ana karla alves de medeiros2, piet van der putten1,
henk corporaal1, and wil van der aalst2
1dept. of electrical engineering, eindhoven university of technology, the netherlands
{m.funk,p.h.a.v.d.putten,h.corporaal}@tue.nl
2information systems group, eindhoven university of technology, the netherlands
{a.rozinat,a.k.medeiros,w.m.p.v.d.aalst}@tue.nl
abstract. nowadays, complex electronic products, such as dvd players or mo-
bile phones, offer a huge number of functions. as a consequence of the com-
plexity of the devices, customers often have problems to use such products effec-
tively. for example, it has been observed that an increasing number of technically
sound products is returned due to, e.g., interaction problems. one possible root
cause of this problem is that most product development processes are still too
technology-driven, i.e., potential users are brought into contact with the prod-
uct only at a very late stage. if early consumer tests are carried out, then these
typically aim at abstract market evaluations rather than formulating concrete re-
quirements towards the functionality of the product. as a result, products often
have little meaning or relevance to the customers. therefore, we need better ways
to involve users in the development of such products. this can be achieved by ob-
serving product usage in the ﬁeld and incorporating the gained knowledge in the
product creation process. this paper proposes an approach to build automatic
observation modules into products, collect usage data, and analyze these data by
means of process mining techniques exploiting a novel semantic link between ob-
servation and analysis . this link yields two main beneﬁts: (i) it adds focus to the
potential mass of captured data items; and (ii) it reduces the need for extensive
post-processing of the collected data. together with the framework’s ﬂexibility
to change observation modules remotely on-the-ﬂy, these beneﬁts speed up the
information feedback cycle towards development.
key words: product monitoring, log analysis, process mining, ontologies, se-
mantic process mining
1 introduction
complex electronic products, both for private consumers and professional users, are
hard to specify and design as no real information is available about the potential cus-
tomers’ expectations and needs. meeting these expectations is, however, crucial as
nowadays customers can choose among a wide variety of products, and will more easily
reject products that do not suit their needs. a symptom of this problem is, for example,
that an increasing number of technically sound products is being returned [1]. at the
same time, it is not possible to perform lengthy user studies as there is a strong pressure2 mathias funk et al.
on ‘time to market’. moreover, it is difﬁcult to gradually improve products by incor-
porating user feedback from the ﬁeld as often only very few generations of the same
product are made (to be replaced by new, more innovative products). in short, customers
are becoming more demanding, whereas product development must be done with fewer
iterations.
one way to ensure that products will suit the needs of potential customers is to in-
volve these people as early as possible in the development process. this can be achieved
by letting potential users test early prototypes, and to incrementally incorporate the
gained knowledge into the product under development. however, to make this approach
applicable in practice, two conditions need to be fulﬁlled.
1. it needs to be feasible to perform the tests in the ﬁrst place, i.e., it should ﬁt into
today’s challenging development cycles.
2. the collected test data needs to be useful , i.e., valid (“does this reﬂect our potential
customers?”) and relevant (“is this what we want to know?”).
to address the ﬁrst condition, the test data needs to be collected and fed back to
the development team as fast and automatically as possible. as we will demonstrate
later, our approach is supported by a tool chain that allows for seamless data collec-
tion, processing and analysis with a high degree of automation . addressing the second
condition is more difﬁcult as data quality depends on a variety of parameters. for ex-
ample, to obtain valid data one needs to choose test users that reﬂect the actual target
group. however, one common problem is that early user tests are often performed in
non-representative environments, and that people do not behave normally as they feel
observed. our approach allows for data collection from testers using the product in
their habitual environment . for example, test products are given to users who unpack,
install and use the devices at home. the products themselves record usage information
and automatically deliver it to the respective development unit in the company. this
way, tests can easily run several weeks, and thus cover different phases of use [2]. re-
search has shown that the long-term usage behavior is often quite different from the
behavior during the ﬁrst few hours after unpacking the product. finally, to ensure that
the right data is collected, we allow the observation logic to be changed dynamically
by the development team, i.e., while the test is running . this way, truly iterative data
collection and analysis becomes possible. furthermore, a visual approach to specifying
the observation logic is taken to make it accessible to the (mostly non-technical) peo-
ple that have an interest in the data collection process. these are, for example, product
managers, quality engineers, interaction designers, or user interface developers.
with the aim to further increase both the feasibility and the usefulness of product
usage observation, we extend the above-described approach by an important aspect: in
this paper, we establish a semantic link between the observation and analysis phase .
more precisely, we allow to semantically annotate the logged data during the speciﬁca-
tion of the observation logic, and these semantic annotations are preserved and actively
leveraged in the analysis phase (by semantic process mining techniques ). so-called on-
tologies [3], which are representations of a set of concepts within a domain and the
relationships between those concepts, are used to deﬁne these semantic aspects. to al-
low different views on the data, multiple ontologies can be used to “tag” the observedsemantic concepts in product usage monitoring and analysis 3
data with orthogonal concepts at the same time. as a result, the logged data is pre-
processed and structured using high-level concepts; consequently, there is no need for
extensive and time-consuming post-processing of raw data. instead, the data can be
analyzed directly and in a more efﬁcient way.
in the remainder of this paper, we ﬁrst point at related work (section 2). then,
we introduce an example scenario based on a case study that is currently performed
(section 3). afterwards, we describe our semantic monitoring and analysis approach in
more detail (section 4), and present an implementation (section 5). finally, the paper
is concluded.
2 related work
uses of remote product monitoring have been reported before [4, 5, 6, 7]. however,
these approaches assume information stakeholders capable of programming and will-
ing to use programming paradigms to achieve the sought-after data. in contrast, our
approach aims at means to specify observation in a way that is doable by actual stake-
holders of the collected information. besides that, our approach towards product obser-
vation emphasizes the integration of observation functionality into the target system by
using a software engineering process which is, in our opinion, necessary for widespread
use. while previous work [8, 9] describes our product observation approach in more de-
tail, this paper focuses on the novel semantic link between observation and analysis.
the idea of using semantics to perform analysis of processes is not new [10, 11, 12].
our analysis approach is based on previous work on semantic process mining tech-
niques [13, 14]. process mining techniques can provide valuable insights into a real-life
process based on data registered in event logs and have been successfully applied in
practice [15]. semantic process mining enhances the analysis by leveraging semantic
information [13]. however, previous works do not present any real-life application of
the semantic process mining tools. in this paper, we ﬁrst applied our semantic process
mining techniques to analyze processes based on product usage. more related work can
be found in our technical report [16].
3 example scenario
in the following we want to use a simple example scenario to explain our approach.
this example is a simpliﬁed version of (but based on) an industrial case study that is
currently being performed.
we consider a product that offers a video playback and recommendation function
as depicted in figure 1. in the upper part of the screen one can see the video that is
currently played. the video playback can be paused and resumed, and the playback
window can be maximized to be displayed in fullscreen mode and brought back to the
normal mode. in the lower part of the screen a number of recommendations related to
the current video are displayed (using the right or the left arrow more related recom-
mendations can be explored). any of these recommendations can be viewed in more4 mathias funk et al.
fig. 1. schematic view on the user interface of a video playback and recommendation function
of an industrial product in prototype stage
detail by moving the mouse pointer over it (as can be seen for the right-most recom-
mendation) and selected for playback, after which it is displayed in the upper part of
the screen. new recommendations are then retrieved and displayed according to the
selected item. furthermore, the product has a search function that allows to search for
video content by name and categories, which is not shown in figure 1.
we assume that a prototype of this product should be tested by potential end users
in a number of different countries. we want to know how people typically navigate this
user interface, and whether this differs depending on the cultural context. for example,
it would be interesting to know whether users tend to follow the provided recommen-
dations or rather search for video content on a case-by-case basis. based on this infor-
mation, the user interface of the product could be improved to best support the most
common interaction ﬂows.
4 approach
direct product information (i.e. the recording of the actual usage of a system) is po-
tentially of use to a large group of professionals involved in the product development
process: knowledge engineers, product managers, requirements engineers, developers,
interaction designers, and other information stakeholders can beneﬁt from such infor-
mation. note that the members of this group, in the following referred to as domain
experts , have traditionally only a rather modest inﬂuence during some phases of the
product creation process. especially for the development of innovative products, the
expertise of such domain experts is needed. these experts are the target users for our
approach: initially, they might have a vague understanding about what should be ob-
served in the product to answer open questions, but iteratively it is possible to map
issues to observable items within the product, and ﬁnally, to obtain comprehensible and
reliable information.
in the remainder of this section, we ﬁrst provide an overview about our product
usage monitoring approach (section 4.1) and then elaborate on the role of ontologies as
a semantic link between the different phases of observation and analysis (section 4.2).semantic concepts in product usage monitoring and analysis 5
4.1 overview
consider figure 2, which depicts an overview of our approach. the system we propose
is acombination of a logging framework and a process mining tool . on top of that, one
or more ontologies are used to link collected data items, hence, to connect observation
and analysis on the information level. the ﬁgure shows that ontologies are connected
to all three steps of the ﬂow. therefore, the deﬁnition and maintenance of one or more
ontologies should be a concurrent task that accompanies the depicted ﬂow.
fig. 2. overview of our approach towards product usage monitoring and analysis
in figure 2 one can see that the product to be observed is equipped with an obser-
vation module which has access to so-called hooks . these hooks and the observation
module have to be built into the product beforehand. for example, in the scenario de-
scribed in section 3, before actually giving the prototypes to testers at home, the user
interface would be instrumented with hooks that are triggered as soon as a video play-
back is started, a recommendation is selected etc.
during the actual test the following three steps are performed in an iterative man-
ner: (1) the ﬁrst step of the actual ﬂow is the observation speciﬁcation: domain experts
visually deﬁne what information should be observed in the product and how this infor-
mation relates to the concepts from the ontology. this task is done within an easy, but
formal visual language. (2) the outcome are observation speciﬁcations which are used
to automatically and remotely instruct the observation modules in the various products
by simply replacing their observation component . the observation modules collect ﬁeld
data during product usage depending on their current conﬁguration and send it to a cen-
tral data storage. the semantic annotations of the observation speciﬁcations enable the
observation module to categorize the captured data accordingly on-the-ﬂy. this results
in log data with an inherent semantic structure. (3) in the third step (data analysis) the
data is processed using various (semantic) process mining techniques which provide
different views on the aggregated data. this last step offers the possibility to extract the
essence out of a potentially huge data set. furthermore, it helps to present this informa-
tion in a comprehensive and directly usable way.6 mathias funk et al.
although the automatic processing chain from observation to analysis consists of
several independent parts, it now becomes clear that a common connection is feasible
by using ontologies for a semantic content structure. the whole process is of a strongly
iterative nature. cycles between the deﬁnition of ontology, observation speciﬁcation,
observation, and analysis are not only expected but encouraged to ﬁnally achieve the
most reliable and accurate picture of product usage. for instance, during the observa-
tion phase, the domain expert might come across unexpected information that needs
a special treatment and the extension of the connected ontology with new concepts.
these changes can be carried out directly and lead to an immediate improvement of the
quality of collected data.
4.2 ontologies
ontologies [3] deﬁne the set of shared concepts necessary for the analysis, and formal-
ize their relationships and properties. ontology elements are organized in a directed
graph and there are several formalisms to build ontologies such as owl [17] and
wsml [18]. an example fragment of an ontology is depicted on the right in figure 3.
fig. 3. types of ontologies relevant for product usage monitoring (left) and an example fragment
of a product-speciﬁc ontology representing user actions (right)
in the context of our product usage monitoring approach, the ontologies provide the
link between conceptual level and information level, i.e., ontology concepts appear in
the log data whenever a semantically annotated event is logged. we identify three types
of ontologies: general ,context andexpert (cf. left side in figure 3). these types can be
characterized as follows.
general general ontologies are domain-independent and they are used to capture con-
cepts that are neither product nor experiment related. they are expected to be highly
re-usable for a couple of experiments without changes.
context context ontologies provide information about the setting of an experiment. in
other words, they might characterize certain aspects of the product to be observed
(i.e., product-speciﬁc ), the habitual context of actual product use, or the people that
perform the tests (i.e., tester-speciﬁc ). the applicability of these ontologies may
be limited to a certain domain or product group, but they can be re-used across
different experiments within that scope.semantic concepts in product usage monitoring and analysis 7
expert expert ontologies are related to speciﬁc analysis purposes. for example, we
can think of certain domain-expert views, such as a user experience expert seeking
emotional feedback from testers by popping up dialogues on the tested prototypes
(i.e., experience-speciﬁc ), or the quality engineer focusing on product failures (i.e.,
failure-speciﬁc ). in principle, expert ontologies could be re-used across different
product groups.
note that multiple ontologies are used because the semantic observation and analy-
sis is not done by one person alone. a team of domain experts should be able to work
together, and to beneﬁt from each other’s insight into product usage. therefore, many
(potentially orthogonal) views on the topic have to be combined in an efﬁcient way.
nevertheless, in the remainder of this paper we focus on user actions only. on the
right side in figure 3, an excerpt of a product-speciﬁc ontology representing user actions
for our example scenario in section 3 is shown. one can see that concepts are organized
in a hierarchical way, i.e., concepts may have one or more superconcepts. for example,
the concept ‘playvideo’ is a subconcept of the ‘controlvideo’ category, which in turn
is a subconcept of ‘videoactions’. these subsumption relationships are a very useful
tool as they enable the analysis of the data on different levels of abstraction.
(a) model made using all events in the log and not using
any semantic information
(b) highly abstracted view
on the same proces
fig. 4. two models that were mined from the same log data, but using different abstraction levels
this is illustrated by figure 4, where process mining was used to automatically
create a process model from the data collected in the example scenario. in the model
depicted in figure 4(a) the raw data and no semantic annotations were used to create the
model. in fact, this model not only contains steps related to user actions but also includes
unrelated information such as status checks of the observation system itself (since these
are logged as well). in contrast, the model in figure 4(b) only contains process steps
relating to user actions. furthermore, the depicted model provides a highly abstract
view by making use of the semantic information in the log data. for example, since both
‘playvideo’ and ‘pausevideo’ are a ‘videoaction’ according to our ontology, they are8 mathias funk et al.
not differentiated in this model. note that although the model depicted in figure 4(b)
may seem too general, the level of abstraction can be varied at wish and without the
need to modify the actual data itself. this way, varying models with even heterogeneous
degrees of abstraction can be created easily. for example, we can create a model that
provides a detailed view on ‘videoactions’ but fully abstracts from ‘menuactions’.
5 implementation
we have fully implemented the approach outlined above and are currently testing it in
an industrial case study. in the following two sub sections, we describe the tools that we
used for the realization (d’puis and prom), focussing on newly added functionality
and the semantic aspects.
5.1 observation speciﬁcation and data collection via d’puis
we have developed the d’puis (dynamic product usage information system) [8, 9] as
a platform-speciﬁc realization of the speciﬁcation and observation approach depicted in
figure 2. this system consists of the following parts: (i) a visual editor to create obser-
vation speciﬁcations, (ii) a web application that distributes observation speciﬁcations
as observation components and provides storage for collected product data, and (iii) an
observation module which is integrated into product instances. an infrastructure con-
nects these parts and enables an automatic ﬂow from observation speciﬁcation to actual
product usage data.
in the context of semantically supported data collection, an interesting part of the
observation system is the visual language as the the place where semantic links between
data items are initially constructed. to do this, the visual language was extended to au-
tomatically incorporate each concept from a linked ontology as an available semantic
hook . if such a semantic hook is triggered, a semantically annotated log entry is created.
often, the actual platform hooks can be connected to semantic hooks in a straightfor-
ward way, merely differentiating between a number of options. however, the processing
nodes of our visual language also allow for more powerful observation speciﬁcations,
which is demonstrated by the following example.
consider figure 5, which depicts a part of the observation speciﬁcation for our ex-
ample scenario in the visual editor. the lightbrown block in the middle represents the
‘recommendationhook’ that is triggered whenever a recommended video is selected
for playback by the user (cf. section 3). however, in fact the same user interface com-
ponent (and, thus, the same platform hook) is triggered when a user picks a search result
after explicitly searching for video content. but in our scenario we want to differentiate
between these two conceptual actions. fortunately, we can create a context-aware ob-
servation speciﬁcation that only triggers the semantic hook ‘picknextvideo’ (i.e., the
actual recommendation) when the user did not just enter the search mode via checking
for the context node ‘entersearch’, which is also based on semantic information. if the
search mode was entered before, the semantic hook ‘picksearchresult’ is triggered in-
stead. note that this kind of domain-dependent reasoning would normally need to be
made later in the analysis stage, or hard-coded into the product.semantic concepts in product usage monitoring and analysis 9
fig. 5. visual editor for observation speciﬁcation with an example speciﬁcation from the example
scenario
data that is acquired in the described way is not only more meaningful, but also
it is self-contained . this is an important step forward as all the (usually implicit) in-
formation about the observation process, such as the characteristics of the observation
environment, and the nature of data sources, is explicitly stated in a machine-readable
form . in the analysis phase, specialized semantic process mining techniques can then
exploit such information efﬁciently.
5.2 semantic process mining using prom
to be able to analyze the log data with our process mining tool kit prom [19], we
have developed a prom import [20] plug-in that automatically extracts the recorded data
from the d’puis database and converts them to the sa-mxml ( semantically anno-
tated mining xml) format [14]1. note that this data conversion preserves the semantic
annotations collected during the observation phase for analysis. process mining tech-
niques support various types of analysis based on the behavior registered during the
execution of some process [15]. semantic process mining uses semantic information
to lift the analysis provided by current process mining techniques to the conceptual
level [13, 14]. seven semantic process mining plug-ins have been added to the prom
tool so far; we brieﬂy introduce the following two: performance metrics in ontologies
and the ontology abstraction filter.
theperformance metrics in ontologies plug-in provides feedback about (i) the pro-
cessing times of tasks (or events) and (ii) throughput times of process executions. in our
approach, the feedback in (i) is particularly important because it indicates how much
time users typically spend in using certain functionalities of products. moreover, this
plug-in also shows how frequently instances of a given concept have been performed.
figure 6(a) contains a screenshot of this plug-in in action. note that the coloring of the
1both prom and prom import are open-source and freely available at www.processmining.org .10 mathias funk et al.
concepts in the ontology is based on the frequency of instances. from this graph, it is
very intuitive to spot that the users in our example scenario were more often navigat-
ing between recommendations (concept ‘followvideorecommendation’) than actually
playing videos (concept ‘controlvideo’).
theontology abstraction filter plug-in supports ontology-based run time ﬁltering
of the data in a way that is accessible to all existing process mining algorithms in prom
(also if they are unaware of the semantic annotations in the log). in this ﬁlter, the de-
sired level of abstraction is determined by selecting or deselecting concepts linked to
events (the actual instances of these concepts) in logs. afterwards, process mining al-
gorithms can be used to create models on the current level of abstraction. for example,
figure 6(b) depicts a screenshot of the fuzzy miner [21] showing a detailed process
model of the user actions. one can see that after searching for a video (‘entersearch’
followed by ‘picksearchresult’ and ‘playvideo’) users tend to follow recommenda-
tions (‘picknextvideo’) rather than going back to explicitly search for further videos.
6 conclusion
in this paper, we presented a novel approach to semantically link the observation and
analysis of product usage data by conceptual information captured in ontologies. this
link renders a potential mass of captured data items more manageable, and reduces the
need for extensive post-processing. the presented approach ensures high information
quality and speeds up the information feedback cycle towards development. further-
more, we presented a tool chain that supports our approach throughout the phases of
observation speciﬁcation, data collection, and analysis. this chain of connected data
processing components offers also the ﬂexibility to change observation remotely on-
the-ﬂy, enabling fast data collection and analysis iterations.
our vision is a fully automated data collection, processing, analysis and presenta-
tion chain which is speciﬁed by only a few (potentially re-usable) documents. ontolo-
gies and visual languages seem to be good candidates for such speciﬁcation documents
as they are accessible to the actual stakeholders of the observed usage data (e.g., the
various domain experts). by putting these people in the position of being able to spec-
ify what they want to observe , one of the main problems in log analysis, namely data
quality, can be addressed. in many real-life scenarios, the data are often still of a poor
quality; because of a low priority in implementing logging facilities, and a lack of an-
ticipation of the kind of analysis that should be eventually performed, collected data are
not good enough to answer all the questions of interest. however, due to the immense
opportunities and increasing feasibility (resulting from novel automated approaches as
presented in this paper) it can be expected, that the integration of observation functional-
ity will have a more prominent role in future product developments. as a consequence,
better analysis results can be expected.
acknowledgements . this work is being sponsored by the dutch ministry of economic
affairs under the iop-ipcr program. some of the authors are also supported by the
european project super. furthermore, the authors would like to thank the industrial
team for the possibility of applying our approach in a real product development context.semantic concepts in product usage monitoring and analysis 11
(a) screenshot of the performance metrics in ontologies semantic prom plug-in. the cur-
rent view shows the frequencies of tasks linking to concepts
(b) screenshot of the fuzzy miner plug-in in prom. before, the semantic information in the
log has been used to ﬁlter only events referring to user actions
fig. 6. the converted log can be loaded and analyzed using the prom tool
references
1. brombacher, a., sander, p., sonnemans, p., rouvroye, j.: managing product reliability in
business processes ’under pressure’. reliability engineering & system safety 88(2005)
137–146
2. den bouwmeester, k., bosma, e.: phases of use: a means to identify factors that inﬂuence
product utilization. in: chi ’06: chi ’06 extended abstracts on human factors in computing
systems, new york, ny , usa, acm press (2006) 117–122
3. gruber, t.: a translation approach to portable ontology speciﬁcations. knowledge ac-
quisition 5(2) (1993) 199–220
4. hartson, h., castillo, j.: remote evaluation for post-deployment usability improvement.
proceedings of the working conference on advanced visual interfaces (1998) 22–29
5. hilbert, d.m., redmiles, d.f.: an approach to large-scale collection of application usage
data over the internet. icse 00(1998) 13612 mathias funk et al.
6. kabitzsch, k., vasyutynskyy, v .: architecture and data model for monitoring of distributed
automation systems. in: 1st ifac symposium on telematics applications in automation
and robotics, helsinki (2004)
7. shifroni, e., shanon, b.: interactive user modeling: an integrative explicit-implicit ap-
proach. user modeling and user-adapted interaction 2(4) (december 1992) 331–365
8. funk, m., van der putten, p.h.a., corporaal, h.: speciﬁcation for user modeling with
self-observing systems. in: proceedings of the first international conference on advances
in computer-human interaction, saint luce, martinique, iaria, ieee computer society
(february 2008) 243–248
9. funk, m., van der putten, p.h.a., corporaal, h.: uml proﬁle for modeling product ob-
servation. in: proceedings of the forum on speciﬁcation and design languages (fdl’08),
stuttgart, germany, ecsi, ieee computer society (september 2008) 185–190
10. casati, f., shan, m.: semantic analysis of business process executions. in: 8th international
conference on extending database technology (edbt ’02), london, uk, springer-verlag
(2002) 287–296
11. hepp, m., leymann, f., domingue, j., wahler, a., fensel, d.: semantic business process
management: a vision towards using semantic web services for business process manage-
ment. in: ieee international conference on e-business engineering (icebe 2005). (2005)
535 – 540
12. o’riain, s., spyns, p.: enhancing the business analysis function with semantics. in meers-
man, r., tari, z., eds.: otm conferences (1). v olume 4275 of lecture notes in computer
science., springer (2006) 818–835
13. alves de medeiros, a., pedrinaci, c., van der aalst, w., domingue, j., song, m., rozinat, a.,
norton, b., cabral, l.: an outlook on semantic business process mining and monitoring.
in meersman, r., tari, z., herrero, p., eds.: otm workshops (2). v olume 4806 of lecture
notes in computer science., springer (2007) 1244–1255
14. alves de medeiros, a.k., van der aalst, w.m.p., pedrinaci, c.: semantic process mining
tools: core building blocks. in: proceedings of the 16th european conference on informa-
tion systems (ecis). (2008)
15. van der aalst, w., reijers, h., weijters, a., van dongen, b., alves de medeiros, a., song,
m., verbeek, h.: business process mining: an industrial application. information systems
32(5) (2007) 713–732
16. funk, m., rozinat, a., alves de medeiros, a., van der putten, p., corporaal, h., van der
aalst, w.: semantic concepts in product usage monitoring and analysis. technical report
esr-2008-10, eindhoven university of technology (2008)
17. w3c: web ontology language (owl). http://www.w3.org/2004/owl/
18. de bruijn, j., lausen, h., polleres, a., fensel, d.: the web service modeling language
wsml: an overview. in sure, y ., domingue, j., eds.: eswc. v olume 4011 of lecture notes
in computer science., springer (2006) 590–604
19. van der aalst, w.m.p., van dongen, b.f., g ¨unther, c.w., mans, r.s., alves de medeiros,
a.k., rozinat, a., rubin, v ., song, m., verbeek, h.m.w., weijters, a.j.m.m.: prom 4.0:
comprehensive support for real process analysis. in kleijn, j., yakovlev, a., eds.: appli-
cation and theory of petri nets and other models of concurrency (icatpn 2007). v olume
4546 of lncs., springer-verlag, berlin (2007) 484–494
20. g ¨unther, c.w., van der aalst, w.m.p.: a generic import framework for process event
logs. in eder, j., dustdar, s., eds.: business process management workshops. v olume
4103. (2006) 81–92
21. g ¨unther, c., aalst, w.: fuzzy mining: adaptive process simpliﬁcation based on multi-
perspective metrics. in alonso, g., dadam, p., rosemann, m., eds.: international conference
on business process management (bpm 2007). v olume 4714. (2007) 328–343