prodigy : human-in-the-loop process discovery
p.m. dixit
eindhoven university of technology
philips research, eindhoven
eindhoven, netherlands
p.m.dixit@tue.nlj.c.a.m. buijs
eindhoven university of technology
eindhoven, netherlands
j.c.a.m.buijs@tue.nlw.m.p. van der aalst
rwth, aachen, germany
aachen, germany
wvdaalst@pads.rwth-aachen.de
abstract ‚Äîprocess mining is a discipline that combines the two
worlds of business process management and data mining. the
central component of process mining is a graphical process model
that provides an intuitive way of capturing the logical Ô¨Çow of a
process. traditionally, these process models are either modeled
by a user relying on domain expertise only; or discovered
automatically by relying entirely on event data. in an attempt to
address this apparent gap between user-driven and data-driven
process discovery, we present prodigy , an alternative approach
that enables interactive process discovery by allowing the user to
actively steer process discovery. prodigy provides the user with
automatic recommendations to edit a process model, and quantify
and visualize the impact of each recommendation. we evaluated
prodigy (i) objectively by comparing it with automated discovery
approaches and (ii) subjectively by performing a user study with
healthcare researchers. our results show that prodigy enables
inclusion of domain knowledge in process discovery, which leads
to an improvement of the results over the traditional process
discovery techniques. furthermore, we found that prodigy also
increases the comprehensibility of a process model by providing
the user with more control over the discovery of the process
model.
index terms ‚Äîinteractive process mining; user driven process
discovery
i. i ntroduction
a process is a series of actions performed in order to achieve
a particular task or goal. processes are omnipresent, and can
be ad-hoc, deÔ¨Åned explicitly or incorporated implicitly in a
system. for example, a manufacturing process which deals
with production of some goods, may be implicitly incorporated
in the production system. on the other hand, a loan application
process in a bank may be explicitly deÔ¨Åned in a process
model used to conÔ¨Ågure the workÔ¨Çow management system
of the bank. a process can also be viewed at various levels of
abstraction. for example, a hospital visit of a patient can be
represented by a very high level process common to all the
patients in the hospital, by abstracting all the low level detailed
activities speciÔ¨Åc to the particular patient. alternatively, for
the same patient, a different abstraction can be a process of
all patients with a similar disease.
the human understanding of these processes is usually
enabled by representing them as intuitive graphical models
expressed in languages such as bpmn, epc, petri nets etc.
typically a domain expert who has a high level overview of
the end-to-end execution of a process, models the expectedprocess models. since these modeling notations offer intuitive
visualization of processes, they have proved to be valuable
artifacts to enable communication of complex knowledge in
a comprehensible way across people from dissimilar back-
grounds. the process model as described by a domain expert is
the best guess, of how a process acts, or should act. however,
reality may not always conform to this expected behavior of
the process.
the execution histories of processes, called event logs,
can be easily extracted from the corresponding information
systems. for example, the event logs of an administrative
process can be extracted from an enterprise resource planning
(erp) system, or the event logs of a careÔ¨Çow process in a
hospital can be extracted from the electronic health record
(ehr) system. these event logs represent a rich source of
information by giving a view on a process execution in
reality. thus, these event logs can be explored to investigate
any problems in the process, and suggest improvements to
the process. statistical techniques, such as statistical process
control charts, are very popular particularly in the context
of manufacturing processes. these techniques typically focus
on analyzing the numerical data values at the activity level
and do not focus on the end-to-end process. machine learning
techniques, such as sequence mining, have also been used in
order to explore common (or uncommon) sequences of process
variants for analysis. however, sequence mining techniques
can only be used to Ô¨Ånd sequential patterns and not discover
end-to-end processes. these techniques can also not discover
process behavior such as choices, concurrency and repetition
of activities.
most of the traditional statistical or machine learning techni-
ques either dive deep into a particular aspect of processes,
or miss out on the important process oriented characteristics
such as choices or concurrency between activities. process
mining is a discipline which overcomes these pitfalls by taking
into account the process context while analyzing the event
data. broadly, process mining techniques can be grouped in
three categories: (i) process discovery techniques, which aim at
discovering a process model using an event log; (ii) process
conformance techniques, which analyze how well an event
log conforms to a given process model; and (iii) process
enhancement techniques, which extend an already existing
process model with information from the event log [1]. process
conformance and enhancement techniques require a processfig. 1: the user interface of prodigy: the process model view (a) shows the process model interactively discovered by the
user, the recommendations table (b) shows the ranked recommendations in a tabular form, the policy and activity selection
view (c) shows the activities that can be added to the process model, and the process variants analysis table (d) shows the
distribution of process variants based on case level attributes.
model to work with. a process model which is hand made or
discovered, is always the starting point for in depth process
analysis.
in order to produce a process model, there are typically two
options. on one end of the spectrum, we have the process
discovery techniques, which are automated and discover a
process model directly from the event log with very limited
user input. the user has very little inÔ¨Çuence over the actual
process discovery, and usually it is not possible to incorporate
domain knowledge during process discovery. moreover, the
resultant process models might be incomprehensible for the
user. on the other end, we have the process editor based
modeling tools which are completely user driven and use no
historical evidence from the event logs for process modeling.
however, ideally there should be something in between that
bridges the gap. in this paper we introduce prodigy ( process
discovery guided b ythe user), which addresses this gap
between the two approaches (figure 1). prodigy is a tool that
supports interactive process discovery by including human-in-
the-loop, supported by effective visualizations and data feed-
back. furthermore, prodigy supports interactive data analytics
to explore process variants.
the main contributions of this paper are:
seamless integration of user driven and data driven ap-
proaches for process discovery, by providing recommen-
dations to the user about possible locations of placing an
activity within a process model and the impact of adding
an activity at the speciÔ¨Åed location.auto-complete/anything in between functionality: to
switch efÔ¨Åciently between interactive discovery and au-
tomated discovery of a process model.
data support, feedback and analysis of the complete
process as well as process variants during discovery of
the process.
ii. r elated work
prodigy is an interactive process discovery system that
enables human-in-the-loop process discovery. our approach
sits at the intersection of the traditional user-driven process
modeling techniques and the data-driven automated process
discovery techniques, and hence is closely related to these
two Ô¨Åelds. moreover, our approach is also related to process
model repair techniques which repair a process model based
on the information from the event log.
a. modeling and discovery approaches
in this sub-section we discuss the techniques from the
literature that deal either with user-driven process modeling
or data-driven process discovery.
1) user-driven modeling: business process management as
a discipline has evolved with user-driven process modeling at
its core [2]. traditionally, a user involved in modeling of a
process interviews participants across the different functions
of the process, in order to get a holistic overview of the
process [3]. the knowledge gained through interviews is then
used to construct a human understandable graphical processfig. 2: a simple process model in a hospital setting. the Ô¨Årst
step in the process is admission, followed by either one of
diagnosis 1 or diagnosis 2. diagnosis is followed by both
treatment 1 and treatment 2, which can occur in any order.
model. many process editing tools, both open-source and
commercial, have been developed to support the user in
efÔ¨Åcient editing of a process model [4]. most of these process
editors offer users with limited or no support in decision
making while modeling the process. with the turn of the
century, there has been an added focus on recommendation
based modeling support. however, most of these are text-
based recommendations, which are generated based on query
strings [5] or semantic similarity of activity descriptions based
on ontologies [6], or based on historical evidence of a user‚Äôs
personalized preferences [7]. that is, these techniques are not
data-driven and the historical evidence from the event log is
not used to generate recommendations.
2) data-driven process discovery: automatically discove-
ring process models from event logs started gaining attention
in the early 2000‚Äôs with the introduction of alpha algorithm [8].
many discovery techniques followed [9]‚Äì[15] . each of these
discovery algorithms tackles the process discovery problem
differently, and provides different assurances. for example,
some discovery techniques generate process models that gua-
rantee perfect Ô¨Åtness with the event log. however, in all these
approaches, the input from user is rather limited, and the
decisions that lead to the generation of process models are
almost entirely data-driven.
b. hybrid approaches
the area in between manual and automated process dis-
covery is mostly unexplored. there have been some process
model repair techniques, which take as input an event log and a
process model and try to minimally change the process model
to reÔ¨Çect the reality as depicted by the event log [16]‚Äì[19].
the initial model is typically hand made. however, the set
up and goals of process model repair techniques is different
compared to the human-in-the-loop process discovery. in such
settings, the user has to Ô¨Årst construct a process model without
data support, which is then repaired using data. alternatively,
there have been approaches which let the user express some
rules or constraints that the discovered process model must
adhere to [20]‚Äì[23]. however, the user is restricted by the
languages used to represent these rules, thereby limiting users
expressiveness. moreover, the user has no control over the
actual discovery, and the resulting process model may adhere
to all the rules, but may be extremely complicated. our
approach involves users explicitly in the process of process
model discovery, and hence the user can discover a process
model at the preferred level of complexity.table i: an example event log showing the Ô¨Çow of patients
for process model from figure 2.
patient id activity timestamp age : : :
patient 1 admission 2017/02/02 14:45 68 : : :
patient 1 diagnosis 2 2017/02/02 15:15 68 : : :
patient 2 admission 2017/02/02 15:18 45 : : :
patient 3 admission 2017/02/02 15:40 89 : : :
patient 1 treatment 1 2017/02/02 16:41 68 : : :
patient 2 diagnosis 1 2017/02/02 16:45 45 : : :
iii. p reliminaries
before describing our approach in detail, we Ô¨Årst introduce
the preliminaries that are used throughout the paper.
a. process models
process models are used to model the Ô¨Çow of steps of a
process. as discussed previously, most of the process modeling
approaches allow modeling of more than just sequential Ô¨Çow
of steps. that is, they allow for rich behavioral aspects,
such as choice, synchronization, repeatable activities - either
by duplication or by introducing loops, concurrency etc. in
our approach, we use the petri net representation of process
models. figure 2 shows a simple example of a process model
represented by petri nets.
b. event logs
event logs record the process notion of a system. event logs
record what happened i.e. an activity such as admission in the
hospital, when did it happen i.e. the time when the patient
was admitted, and for which case , i.e. who was the patient
that was admitted. next to this, event logs may also contain
additional information pertaining to cases such as the age or
gender of a patient, or pertaining to activities, such as which
nurse admitted the patient. table i shows an example event
log with patient id as case identiÔ¨Åer.
c. quality dimensions
having introduced process models and event logs, we now
discuss two standard metrics which are used to evaluate
the quality of a process model based on the event log. in
order to calculate these metrics we use the alignment based
conformance technique, described in [24].
1) fitness: the Ô¨Åtness metric captures the goodness of Ô¨Åt
of cases from an event log on a process model. for every case,
the Ô¨Åtness value can span between 0 and 1. a perfect Ô¨Åtness
score of 1 indicates that the model perfectly represents the
behavior from the case. the values between 0 and 1 indicate
the degree of Ô¨Åtness of a case and the process model. the
averaged Ô¨Åtness values of all the cases in an event log indicate
the overall Ô¨Åtness of an event log with a process model.
2) precision: the precision metric captures how precise
a given process model is with respect to an event log. that
is, the precision metric penalizes a process model for adding
extra behavior not present in the event log. like Ô¨Åtness, the
precision metric is scored between 0 and 1.xuserselect a
recommendation
or skip current
recommendations1
select auto-
completec recursively
add activities
using top ranked
recommendationsdupdate policy
of next activity
recommendationsa
policyb
get next
activity/activities2 calculate
recommendations
for selected
activity/activities3
black box
process discoveryy
calculate
quality for each
recommendation4
metrics, ranking
and variants info5
event logx
fig. 3: components of the prodigy system. the thick lines indicate the usual Ô¨Çow and interactions between the various
components. dashed lines indicate alternative Ô¨Çow and interactions between components. a dotted line between two components
from atobindicates that component auses component b.
iv. c hallenges of interactive process discovery
this section focuses on the what , i.e. what are the key
challenges addressed by prodigy. human-in-the-loop process
discovery aims at merging the worlds of user driven process
modeling without data support and automated process dis-
covery which relies solely on data. in order to bridge the
gap between these seemingly linked (yet fairly unexplored)
disciplines, the following challenges are identiÔ¨Åed based on
literature review:
c1: recommendations for activity positioning in a
process model. suggesting the position of an activity
in a process model without overwhelming the user with
too much information is one of the foremost challenges
of human-in-the-loop process discovery techniques. the
said activity can be placed at multiple positions within
the process model. for example, suppose a new activity
called treatment 3 needs to be added to the process
model from figure 2. treatment 3 can happen before
treatment 1 ,treatment 3 can happen after treatment
2,treatment 3 can happen instead of treatment 1 and
so on. therefore, it is vital to recommend to the user
the locations where a particular activity can be placed
in the process model. eventually the user decides the
appropriateness of a particular recommendation based on
the metrics, as well as the interpretability of the process
model for a given recommendation. it should be noted
that only those activities can be added to the process
model, which are present in the event log.
c2: evaluating the recommendations. the recommen-dations for changing a process model need to be evaluated
based on the event log by providing relevant information
about each recommendation, using the quality dimen-
sions. ideally, the recommendations should be ranked
automatically to assist the user in decision making. as an
illustration, let‚Äôs continue with the example from c1of
adding treatment 3 to the model from figure 2. if in the
event log it was observed that treatment 1 andtreatment
3never occur together, then recommendations suggesting
anything contradictory should be penalized and ranked
low.
c3: next possible activity recommendation. ideally,
there should be a certain intuitive Ô¨Çow of choosing the
activities during the process of process modeling. since
the process model is expanded incrementally, there should
be a logical order in which the activities are added to
the model. that is, there should be a way to decide
the order or decide which activities belong together. for
example, from a user‚Äôs perspective, it would be easier to
get recommendations of all the related activities together
(or following one another), rather than getting ad-hoc
recommendations of unrelated activities. furthermore, at
any given point during the process discovery, the user
should be able to change the logic in which the next
possible activity recommendation is generated.
c4: mix and match - auto discovery and interactive
discovery. it is important to allow the user to switch
effortlessly between automated discovery and interactive
discovery. the user may decide to build a process model
until a certain point, and then wish to hand it over to adiscovery algorithm to automatically complete the rest of
the process model. that is, the user‚Äôs focus may be to
exhaustively discover a process model by using the avai-
lable domain knowledge Ô¨Årst, and then let an automated
technique take over. alternatively, the user may want to
delegate some discovery tasks to an automated discovery
algorithm, and then resume interactive process discovery
when the so-called quality of the model is unacceptable.
c5: process variant data analysis. it is common to
have multiple variants of processes in a large event log.
for example, a hospital event log may contain cases
about different patients suffering from different diseases.
in reality, some highly frequent activities may actually
be speciÔ¨Åc only to certain types of diseases. hence, a
high level process model that tries to encapsulate the
most frequent behavior, may cater to some diseases better
than others. thereby, it is important to clearly provide
such information to the user to enable informed decision
making for analyzing the process variants independently,
instead of just concentrating on the aggregated quality
scores.
v. p rodigy
this section focuses on the how , i.e. how the challenges
discussed in section iv have been addressed in prodigy. pro-
digy is an interactive system that automatically recommends
and ranks positioning of next possible activities in a process
model, while incorporating user‚Äôs choices at every step.
a. overview
figure 3 shows the high level overview of the main
components of prodigy. the usual Ô¨Çow and interactions
between the components of figure 3 is as follows: the user
selects one (or skips all) recommendation(s) from the list of
recommendations (1), the process model is updated based on
the recommendation chosen by the user and the next candidate
activities are selected (2) depending on the policy chosen (b).
the information from the event log (x) is used by a black
box process discovery algorithm (y) to come up with different
recommendations for the newly selected activity/activities (3).
the quality of each recommendation is calculated (4) by using
the event log (x) which is then presented to the user along with
ranking and process variants information (5). at any point of
time, the user can change the policy used to predict the next
activity/activities (a). similarly, the user can decide to hand
over the discovery task to the automated discovery technique
at any point of time (c) and (d). the auto-complete mechanism
recursively adds activities to the process model by using the
black box process discovery algorithm (y) by selecting the
top ranked recommendation until some termination condition
is met.
b. policy
policy is a pluggable component used to decide the next
activity/activities that should be added to the process model.
since process discovery in prodigy is incremental, the orderin which the activities are added to the process model is
important. there are a couple of reasons for this. firstly,
having a logical Ô¨Çow of adding activities incrementally may
assist the user in better decision making. for example, adding
all the semantically similar activities one after the other may
help the user in structuring the overall process model better
than adding unrelated activities in random order. secondly, by
following a strict order, it may become possible to discover
a certain structure of process model which may otherwise
become unreachable because of prior discovery decisions
when adding activities randomly. as policy is a pluggable
component, there could be many policies used to decide the
next possible activities that are added to the process model.
at any given point, the user can switch between policies
by updating the policy using component (a) of figure 3.
policies essentially cater challenge c3from section iv. in
theory, a policy can return multiple activities, and hence the
recommendations presented to the user may contain process
models containing some or all of those activities. however,
here we present two policies which suggest a single next
activity at a time. hence, in the remainder we use the singular
form of activity when referring to policies.
1) alphabetical: the alphabetical policy, as the name
suggests, orders activities purely based on their alphabetical
ordering. at any point, if a user decides to skip an activity,
then the next activity based on the alphabetical ordering is
chosen. as evident, in the case of alphabetical ordering only
one activity is selected at a time. even though this is a very
simple policy, it can still be useful as the user knows which
activity would follow.
2) log heuristics: the log heuristics based policy orders
activities based on the information extracted from the event
log. the idea is that the user starts building the process with
the most common starting activities across all the cases from
the event log, and ending it with the most common ending
activities across all cases in the event log. the activities in
between are also ordered according to their occurrences across
the cases in the event log. this example policy is described
in more detail below, but in order to do so, we Ô¨Årst introduce
some notations.
letldenote an event log. we know that a case is a
sequence of activities. it should be noted that the same activity
can be repeated multiple times in a case, and hence can be
present at multiple positions in the activity sequence of a case.
letadenote the set of all the activities from the event log
l. then for any activity a2a , let #i(a)denote the total
number of cases for which the activity at the ithposition is a.
in order to compute the policy of log heuristics, we intro-
duce a function max (act). function max (act)returns ‚Äúthe‚Äù
position where activity act occurs most frequently across
all the cases from the event log. in case there are multiple
positions, then the lowest position is chosen. let a; b2a be
two activities, then we deÔ¨Åne a partial order abas:fig. 4: primary user interaction in prodigy. based on the recommendation chosen from the recommendation table, the process
model is updated temporarily to display the change in process model.
abmax (a)< max (b)or
(max (a) =max (b)^
#max (a)(a)#max (b)(b))
abdeÔ¨Ånes a partial order, that can be made total to form a
sequence. this sequence forms the policy of log heuristics, that
suggests positioning of an activity based on the information
from the event log, across all the cases and compared to all
the other activities.
c. recommendations
recommendations component provides a list of possible
edits that can be made to the current process model, to
incorporate the next activity as suggested by the policy. as
shown in figure 3, we abstract from discussing the actual
process discovery approach which comes up with these re-
commendations as it is outside the scope of this paper. there
are multiple techniques possible that take as input a process
model and an activity, and output multiple locations wherein
the input activity can be added to the process model. similar
to the policy component, this is also a pluggable component,
and any discovery algorithm which can incrementally add
activities to a process model can be used. in this paper we use
a concrete approach that is based on free-choice net synthesis
rules [25]. however, as mentioned this is out of scope for thispaper. in this approach, a single activity can be added at a
time. for every possible position of the activity in the process
model, we then compute the Ô¨Åtness and precision scores
using the changed process model and the event log, using
the alignment based conformance technique discussed in [24].
each recommendation has its own Ô¨Åtness and precision score
and hence indicates the goodness of positioning an activity
at various locations in the process model. the Ô¨Åtness value
indicates how well the event log Ô¨Åts a process model, whereas
the precision value indicates how much extra behavior does a
process model allow, compared to the event log. it should be
noted that the Ô¨Åtness and precision values are calculated with
respect to the activities present in the process model. hence,
the event log is Ô¨Åltered to contain only those activities present
in the process model. this Ô¨Åltered event log is then used to
compute the Ô¨Åtness and precision values. also, it should be
noted that the newly added activity can be added in multiple
ways. for e.g., as a choice to a set of activities, or in parallel
to some activities. therefore, the precision or Ô¨Åtness scores
would vary depending on the different ways in which the new
activity is added. the recommendations are ranked based on a
ranking criteria, consisting of a weighted average of Ô¨Åtness and
precision values. by default the precision and Ô¨Åtness values are
weighted equally, but these weights can also be determined by
the user at any given point. recommendations and rankingfig. 5: policy panel from prodigy, showing the dropdown for
choosing a policy, auto-complete button and activities list.
component addresses challenges c1and c2described in
section iv.
d. auto-discovery
the auto-discovery component embeds the possibility of
using traditional automated process discovery in prodigy.
this component allows the user to pass the control to the
black box discovery technique. the user provides some input
to the algorithm similar to a traditional automated discovery
technique, which requires some pre-conÔ¨Åguration. the user
sets the number of activities that should be added and a
threshold for minimum Ô¨Åtness and precision values. the
user can also update the weights for Ô¨Åtness and precision
scores used for ranking the recommendations. once these
parameters are set, the auto-discovery feature iteratively adds
activities to the process model, while the thresholds are met,
by choosing the Ô¨Årst ranked process model from the list of
recommendations. the process models of the activities which
did not satisfy the threshold criteria are skipped. after the
desired number of activities are added, the user can resume
the interactive process discovery. this component allows the
user to switch between automated and interactive discovery
and thus addresses challenge c4described in section iv.
e. process variants
the process variants component is used to analyze how
different variants of the process behave for each recommen-
dation. as described in the introduction of event logs, every
case may have multiple features. for example a patient in
a hospital, has additional attributes like age, sex, gender,
type of disease etc. these features, when combined with the
process model, can provide valuable insights. the user can
compare the distribution of patients based on the process
model. for example, it would be easy to investigate how a
fig. 6: process variants tabular view pouplated based on the
selected case level attribute amount .
group of patients with a certain disease Ô¨Åt (or not Ô¨Åt) a given
process model, compared to another group of patients with
another type of disease. since the values of Ô¨Åtness are pre-
computed, these are re-used for providing the user with a
certain feature speciÔ¨Åc distribution of cases. this component
caters to challenge c5.
vi. i nterface and interaction
prodigy is composed of four display and interaction panels
as shown in figure 1. in this section we describe the user
interface of each panel, and the type of interactions possible
that enable human-in-the-loop process discovery.
a. process model panel
theprocess model panel is panel afrom figure 1. this is a
view only panel, that is, the user does not interact directly with
the process model displayed in this panel. whenever a user
chooses a recommendation, the process model in this panel is
updated by placing the new activity in the process model based
on the recommendation. this is the largest panel of prodigy.
along with the process model view, there is an option to undo
a previously selected recommendation, thereby allowing the
user to revert the changes made.
b. recommendations panel
the recommendations panel shows the recommendations
of possible edits to the process model based on the chosen
activity. this is a tabular panel, corresponding to panel bfrom
figure 1. each row in the table corresponds to a unique way of
adding an activity to the current process model. the table has
three columns: rank,Ô¨Åtness and precision , which guide the
user through the impact of each recommendation. figure 4
shows the primary user interaction in prodigy. based on the
ranking, Ô¨Åtness and precision scores, the user selects one row
from the recommendations table. the change is animated and
projected on top of the current view of process model. the
layout is changed minimally, and the new nodes added to the
process model are colored differently, so that the user can
easily spot the part of the process model that has changed. by
navigating through different rows (that is recommendations)the user can readily see the impact of each change. if a
user is satisÔ¨Åed with a particular recommendation, then that
recommendation can be made permanent by clicking use
model and select next activity button. this button Ô¨Ånalizes a
recommendation, chooses the next activity based on the policy
and generates new recommendations based on the activity
chosen. alternatively the user may click skip current recom-
mendations button to skip all of the given recommendations,
choose a next activity based on the the policy and generate
new recommendations based on the newly chosen activity.
c. policy panel
thepolicy panel , as shown in figure 5, corresponds to panel
cfrom figure 3. this panel provides the user with options for
choosing or updating a policy to select the next activity. the
policy panel contains a policy selection box which contains
all the available policies. the policy panel also contains a list
box for activities which contains the activities from the event
log. the user can scroll through the activities. the current
activity as chosen by the policy is highlighted. furthermore,
the activities in the activity list are sorted according to the
chosen policy. this provides an easy way for the user to
Ô¨Ånd out the sequence of activities as suggested by the policy.
the user can also interact and select any activity from the
activity box. this action overrides the policy and gives user
more control of the sequence in which activities should be
added to the model. whenever a new activity is chosen,
either automatically by a policy, or manually by the user,
the recommendations are recalculated for the newly selected
activity. the policy panel also has the auto-complete button.
as discussed previously, the auto-complete functionality lets
the user switch between interactive discovery and automated
discovery. upon clicking the auto-complete button, the user
is provided with a dialogue box to set the thresholds for
minimum Ô¨Åtness and minimum precision values, as well as
the number of activities that should be added automatically.
d. process variants panel
the process variants panel corresponds to panel dfrom
figure 1. as shown in figure 6, this panel is divided into
two parts. the top panel contains a feature selection list. this
lets the user choose the global case feature from the list. the
bottom panel shows the distribution depending on the type of
feature chosen. the distribution of cases is shown in a tabular
format using the process model and event log. whenever the
user chooses a certain recommendation, the information in the
feature table is updated to reÔ¨Çect the distribution based on
the changed process model. therefore, the user can navigate
through different recommendations, and choose a process
model better suited for a particular feature value, for e.g.,
patients suffering from a particular disease.
e. design evolution
the overall design of prodigy went through a number of
iterations. enabling an incremental way of interactively incor-
porating domain knowledge was the main guiding principlebehind the design of the system. after a number of revisions
inÔ¨Çuenced by various methods from literature, prodigy ended
up with four sub-components as discussed earlier. the idea be-
hind designing the tool decomposed into four sub-components
is to clearly separate the steps of the workÔ¨Çow in the usage
of the system. the process model is the core component of
process discovery and hence is the largest component and is
placed centrally. the recommendations panel contains possible
recommendations for changes in a process model. this is
theÔ¨Årst step of the workÔ¨Çow, wherein the user goes through
the recommendations and chooses one. since it is natural to
navigate (or read through) a workÔ¨Çow from left-to-right, this
panel is placed on the left hand side of the tool. the policy
panel shows all the activities and highlights the next activity
that is chosen. this next activity is chosen and highlighted
after a recommendation is made permanent by the user. hence
this is typically the second step of the workÔ¨Çow, and hence this
panel is placed on the right side of the recommendations panel.
the process variants panel shows the statistical information
based on the impact of the current process model on the case
features. the information in this panel is dependent on the
chosen activity and recommendation, and hence this panel is
placed on the right side of the policy panel.
having discussed the idea behind the overall design, and
positioning of various panels, we now brieÔ¨Çy discuss the
design decisions made within some of the panels. the policy
panel (panel cfrom figure 1) shows the activities as a list.
the idea behind this is to let the user freely navigate through
different activities, and check the natural sequence of follo-
wing or preceding activities based on the chosen policy. the
design of recommendations panel underwent multiple changes.
initially, the recommendations panel was designed as tabs,
wherein each tab contained a new process model based on the
recommendation. however, this made the impact of change
to the process model difÔ¨Åcult to comprehend for the end user.
hence, after exploring multiple design ideas, it was decided to
show the changes in process model projected on the current
process model. also, by using different colors the user can
easily view the impact and the change in the process model.
furthermore, it was decided to provide the recommendations
in a tabular format. the tabular design was chosen to provide
a holistic view showing all the recommendations that is easy
to sort and navigate.
vii. i mplementation
prodigy is implemented as a plug-in in the process mining
toolkit prom [26]. we use an alignment based approach for
computing the Ô¨Åtness and precision values, which is also
already present as a plug-in in prom [24]. prodigy can be
accessed through the nightly build version of prom (interactive
process mining package), and can be downloaded from the
process mining website. the user interface of prodigy is as
shown in figure 1.2 4 6 8 10 12 14 1600:20:40:60:81
number of activities addedprecision value
obedient ( o)
super ( s)
disobedient ( d)
fig. 7: change in the precision values of the process model,
after choosing a recommendation, i.e. adding an activity to the
model.
viii. e valuation
we conducted two types of evaluations in order to under-
stand the usage, behavior and implications of prodigy. the
Ô¨Årst type of evaluation is objective and deals with analyzing
a real life data set to compare the performance of various
settings of prodigy, along with the comparison with some
of the state-of-the-art automated process discovery techniques.
the second type of evaluation is subjective wherein the domain
experts explore prodigy based on some tasks using a synthetic
data set.
a. real life event log
we use a real life event log to demonstrate the functio-
nalities of prodigy and evaluate the outcomes of interactive
process discovery. the event log used is publicly available
and contains information about patients suffering from sepsis
disease from a hospital [27]. each sepsis patient goes through
a pathway of activities performed within the hospital. the
information is extracted from the erp system of the hospital
and contains 15,214 activity occurrences for 16 activity classes
for a total of 1050 sepsis patients.
we use prodigy to discover three process models. for all
the three models, the weights for both Ô¨Åtness and precision
values used during recommendations are kept at a default
value of 1. the log heuristics based policy is chosen to predict
the next activity. using these settings, the following types of
process models are discovered:
1)obedient user (o) : for each activity, the Ô¨Årst ranked
recommendation is chosen. each activity is added only
once. this corresponds to the auto-complete feature of
prodigy.
2)disobedient user (d) : for each activity, a random re-
commendation is chosen from the recommendations list.
each activity is added only once. this is used to evaluate
the non-conformant user who ignores the ranking criteria.
3)super user (s) : process model is discovered by using
insights about the sepsis process from the literature [28].2 4 6 8 10 12 14 1600:20:40:60:81
number of activities addedÔ¨Åtness value
obedient ( o)
super ( s)
disobedient ( d)
fig. 8: change in the Ô¨Åtness values of the process model,
after choosing a recommendation, i.e. adding an activity to
the model.
this user can be considered as a domain expert who
knows the clinical protocols and has a high level overview
of the process, and can therefore, use the insights to
guide the process discovery. this user may thus choose
to ignore the ranking information during the process
of process discovery if it contradicts with the clinical
protocols.
the precision and Ô¨Åtness values of each type of user are
compared after addition of every activity to the respective
process models in figure 7 and figure 8. the Ô¨Åtness scores for
user oand user sare fairly similar and are always above 0.9
after each iteration. the precision values for user ogradually
decrease over time with each iteration. however, there is no
clear pattern for the precision values of user s. this is because
user sexplicitly makes use of the domain knowledge, and
does not rely entirely on the precision and/or Ô¨Åtness values.
it can also be noted that both the Ô¨Åtness and precision scores
of user sare higher than user o. user dchooses random
recommendations. this is reÔ¨Çected by the Ô¨Åtness and precision
scores, which follow no particular pattern and have a low value
on an average. even though the precision score of the Ô¨Ånal
model (after adding activity 16) is higher for user d, the Ô¨Åtness
score of user dis considerably lower than the other users.
furthermore, as prodigy can also be viewed as a process
discovery algorithm, we compared the results with some of
the state-of-the-art process discovery techniques. we disco-
vered process models by using the default settings of the
automated discovery techniques. subjective measures, such
as comprehensibility and generalization of the process model
are inherently taken into account by the users in prodigy.
however, automated discovery techniques completely rely on
the information from the event log. hence, the automated
process discovery techniques usually cannot take into account
subjective measures such as simplicity of the process model.
in order to keep the comparison between the approaches fair,
in figure 9, we compare the process models entirely based ono s dimim-ialphahm ilp00.20.40.60.811.21.4
algorithmÔ¨Åtness + precisionÔ¨Åtness
precisionfig. 9: fitness and precision scores of the process models
discovered by obedient (o), disobedient (d), super (s) users
along with the automated discovery algorithms: inductive
miner (im), inductive miner infrequent (im-i), alpha miner
(alpha), ilp miner (ilp), heuristics miner (hm).
the Ô¨Åtness and precision values. as evident from figure 9, the
process models discovered using prodigy outperform other
approaches. the outcome of obedient user ( o) is comparable
to the automated process discovery techniques but not as
good as the super user ( s). it should be noted that the
two variants of inductive miner (im and imi) Ô¨Ånd process
models with almost perfect Ô¨Åtness. however, their precision
values could not be computed within a practical time frame
(more than 5 hours). this is probably because these process
models are too imprecise and contain most of the activities
in choice with a loop back, thereby allowing any execution
sequence with unlimited repetitions. this comparison clearly
demonstrates the advantages of human-in-the-loop process
discovery enabled by prodigy, compared to the traditional
automated process discovery algorithms.
b. user study
following the evaluation based on real life data, we also
conducted a user study. the overall goal of the study is
to understand the usability of prodigy and to gain insights
through user feedback. the Ô¨Ånal outputs generated by the
users using prodigy are also evaluated and compared with
the traditional automated process discovery techniques.
the user study was conducted in the context of oncology
patient Ô¨Çow in a hospital based on simulated data. we use
figure 2 in [29] as our reference process model, which
contains the expected workÔ¨Çow of three cancer types: prostate,
bladder and kidney. this process model was used to simulate
data of 850 patients: 250 each of prostate and kidney, and
350 of bladder. furthermore, in order to replicate the reality,
noise was introduced in the data by removing 3% of random
activity occurrences from random locations and adding 3%
random activity occurrences at random locations in the event
log. this ‚Äònoisy‚Äô event log was used throughout the user study.
three industry based health-care researchers participated in
p1 p2 p3hm imim-i ilpalpha00.20.40.60.811.21.41.61.82
algorithmÔ¨Åtness + precisionÔ¨Åtness
precisionfig. 10: fitness and precision scores of the process models
discovered from the noisy event log by three participants
(p1, p2, p3) along with the automated discovery algorithms:
inductive miner (im), inductive miner infrequent (imi), alpha
miner (alpha), ilp miner (ilp), heuristics miner (hm). the
process models are evaluated on the original noise free event
log to compute the quality measures.
this study. as a Ô¨Årst step, all the participants were provided
with a brief introduction of the tool. next, the participants were
asked to perform couple of tasks: (i) discover an end-to-end
process model by using a Ô¨Åltered (noisy) event log containing
only prostate cancer patients, and (ii) discover a high level
process model for all the patients using the entire (noisy) event
log. the above tasks were used to guide the domain experts
in exploration of prodigy, and their feedback was actively
registered during the usage of the tool via an unstructured
interview. furthermore, after their usage of the tool the users
were presented with a questionnaire to analyze the things that
could be improved, were interesting and missing.
c. results
in this section, we discuss the key Ô¨Åndings of the user
evaluation. for convenience, the participants are labeled as
p1,p2andp3.
1) usage patterns of prodigy: even though every expert
was given a standard introduction to the tool, there were
differences in the way the tool was used. p1relied almost
entirely on the ranking information noting that he ‚Äútrusts the
data more‚Äù , and therefore he always chose either the Ô¨Årst
or second ranked recommendation from the recommendations
list. contrary to this, p2used his domain knowledge most of
the time, and relied on the recommendations when he was
‚Äúunsure what to do, or where to add an activity‚Äù .p3added
the activities he was familiar with Ô¨Årst, and then relied on the
recommendations to decide the fate of unfamiliar activities.
the users were satisÔ¨Åed with the features and the workÔ¨Çow of
the tool, and they deemed the system easy to learn. there were
suggestions made by the participants based on their speciÔ¨Åc
way of discovering a process model. for example, p2who
relied more on his domain knowledge, navigated back throug-hout the interactive process discovery session using the undo
button, and said that he ‚Äúmisses a redo button‚Äù to navigate
forward. similarly, p1who relied more on the information
from the event log noted that ‚Äúthe recommendations helped in
guiding the process discovery, however sometimes the ranking
difference between recommendations was hard to spot due
to a very small difference in Ô¨Åtness and precision values‚Äù .
in most of the intermediary steps, the participants chose one
of the top-3 recommendations. also, none of the participants
selected a recommendation ranked lower than 5 at any given
point. prodigy supported both types of users sufÔ¨Åciently:
the one‚Äôs relying on using domain knowledge as well as the
one‚Äôs relying on using the information from the event logs
for process discovery, thereby supporting multiple ways of
discovering process models.
2) prodigy improves the results of process discovery: all
the three participants were satisÔ¨Åed with the process models
discovered by them using our tool. the comparison of Ô¨Åtness
and precision scores for the process models discovered by
the participants and some automatically discovered process
models is shown in figure 10. in most of the cases, the process
models discovered by the experts performed better than the
automated process discovery techniques. in general, the pro-
cess models discovered by the experts were deemed simpler to
understand and/or more appropriate by the respective experts,
compared to the process models discovered by the automa-
ted techniques. as p1responded about one of the process
models discovered automatically, ‚Äúits extremely complicated
and doesn‚Äôt make much sense, the interactively discovered
process model is easier to interpret‚Äù . all the participants
agreed that prodigy enabled them to have more control over
process discovery and suggested that the interactive process
discovery enabled discovery of substantially better process
models, especially in terms of intelligibility, compared to
the traditional automated process discovery techniques. an
interesting observation here was that even though the three
participants started off with an empty process model and with
the same event log, there were also a few structural differences
in the Ô¨Ånal process model. partly this could be attributed to the
usage patterns. however, another reason for these differences
could be the fact that each participant had speciÔ¨Åc preferences
to certain structural constructs in the process model over
the others. for example, p1preferred sequential constructs
over concurrency, whereas p2and p3had no preference
between sequence and concurrency. this is also reÔ¨Çected in the
figure 10, wherein the process models discovered by almost
all the participants have a similar Ô¨Åtness score, however, there
is a notable difference in the precision score of each process
model.
3) experts gained insights during process discovery: an
unprecedented Ô¨Ånding was that during interactively discove-
ring the high level process model, the experts were able to
gain insights in to the individual pathways of prostate, bladder
and kidney cancer patients. p3noted ‚Äúthe information from
process variants panel assists in Ô¨Ånding out the right overall
process model, but at the same time indicates which activitiesare applicable for which type of patients‚Äù . process variants
information was also used by the p2to guide the process
discovery in order to ‚Äúdiscover the process model that best
Ô¨Åts a speciÔ¨Åc cancer type‚Äù , rather than relying only on the
aggregated Ô¨Åtness and precision values. the strength of the tra-
ditional process discovery techniques lies in understanding the
data to make certain decisions. but the decisions made during
process discovery are not visible to the end user. since our tool
enables active user involvement in process discovery, it also
leads to exploring intermediary patterns, which may otherwise
remain unexplored or hidden. for example, information about
the link between the activities which might not be connected
directly in the Ô¨Ånal process model, however, were connected
during the intermediate steps of interactive process discovery.
hence, by encouraging the users to interactively discover a
process model, prodigy can help in gathering insights during
the process of process discovery, as noted by p3:‚Äúprodigy
is surprisingly good for exploratory purposes‚Äù .
4) study limitations: the overall feedback by all the three
participants was positive and led to a lot of suggestions and
possibilities for improvements. however, we are aware that
the user study has some limitations. firstly, even though the
participants had more than 50 years of health-care experience
between them, the number of participants is limited and hence
the results may be biased. owing to the sample size of the
study, we did not conduct structural interviews and statistical
analysis of the results. the participants from the current study
also had some basic exposure to the Ô¨Åeld of process mining,
whereas tutorials may be needed for other populations. this
paper serves as a starting point of building and evaluating
interactive process discovery. in the future, after incorporating
all the suggestions made by the participants, we would like to
evaluate and validate the tool with a broader population.
ix. c onclusion and future work
in this paper, we presented a novel approach for human-
in-the-loop process discovery. we Ô¨Årst identiÔ¨Åed the key
challenges of interactive process discovery and proposed so-
lutions in order to address these challenges. the solutions
proposed were designed and implemented in prodigy, which
was tested on a real life event log and evaluated by users
in the health-care domain. our evaluation demonstrates that
interactive process discovery can outperform the traditional
automated process discovery techniques. furthermore, the user
study also demonstrated that the tool is easy to learn and
the visual analytics techniques incorporated in the tool are
intuitive. to our knowledge, this is the Ô¨Årst application that
involves the user during process discovery, thereby giving
users more control over the comprehensibility of the Ô¨Ånal
process model. in the future, we plan to extend the tool to
include the suggestions made by the participants of the user
study. the foremost feature to be included is a collection of
new metrics to guide the user in further distinguishing the
recommendations suggested, especially when the differences
between the Ô¨Åtness and/or precision scores are not signiÔ¨Åcant.
one such metric could be based on the degree of coverabilityof the newly added activity (activities) in the event log. we
believe such new metrics, can be effectively combined with
the pre-existing metrics to assist the users in better decision
making. also, we plan to extend human-in-the-loop techniques
to other areas of process mining, such as interactive process
analytics to understand the ‚Äúhealth‚Äù of a process. prodigy can
serve as the key enabler for enabling such interactive process
analytics, wherein the user can investigate the control Ô¨Çow
aspect of the process using prodigy, and project other (data)
attribute information on the process model while discovering
the process model. another interesting direction could be
constructing user proÔ¨Åles in order to build a recommendation
system based on a user‚Äôs background and preferences. the
information from user proÔ¨Åles could be used directly in the
recommendation algorithm in order to populate process model
constructs preferred by the users.
references
[1] w. m. p. van der aalst, process mining - data science in
action, second edition . springer, 2016. [online]. available: https:
//doi.org/10.1007/978-3-662-49851-4
[2] m. hammer, what is business process management? berlin,
heidelberg: springer berlin heidelberg, 2010, pp. 3‚Äì16. [online].
available: https://doi.org/10.1007/978-3-642-00416-2 1
[3] d. georgakopoulos, m. hornick, and a. sheth, ‚Äúan overview
of workÔ¨Çow management: from process modeling to workÔ¨Çow
automation infrastructure,‚Äù distributed and parallel databases , vol. 3,
no. 2, pp. 119‚Äì153, apr 1995. [online]. available: https://doi.org/10.
1007/bf01277643
[4] r. s. aguilar-savn, ‚Äúbusiness process modelling: review and
framework,‚Äù international journal of production economics , vol. 90,
no. 2, pp. 129 ‚Äì 149, 2004, production planning and control.
[online]. available: http://www.sciencedirect.com/science/article/pii/
s0925527303001026
[5] a. koschmider, t. hornung, and a. oberweis, ‚Äúrecommendation-
based editor for business process modeling,‚Äù data knowl. eng. ,
vol. 70, no. 6, pp. 483‚Äì503, jun. 2011. [online]. available:
http://dx.doi.org/10.1016/j.datak.2011.02.002
[6] m. born, c. brelage, i. markovic, d. pfeiffer, and i. weber,
auto-completion for executable business process models . berlin,
heidelberg: springer berlin heidelberg, 2009, pp. 510‚Äì515. [online].
available: https://doi.org/10.1007/978-3-642-00328-8 51
[7] n. n. chan, w. gaaloul, and s. tata, ‚Äúa recommender system based
on historical usage data for web service discovery,‚Äù serv. oriented
comput. appl. , vol. 6, no. 1, pp. 51‚Äì63, mar. 2012. [online]. available:
http://dx.doi.org/10.1007/s11761-011-0099-2
[8] w. m. p. van der aalst, a. j. m. m. weijters, and l. maruster, ‚ÄúworkÔ¨Çow
mining: discovering process models from event logs,‚Äù ieee transactions
on knowledge and data engineering , vol. 16, no. 9, pp. 1128‚Äì1142,
sept 2004.
[9] j. m. e. m. werf, b. f. van dongen, c. a. j. hurkens, and a. sere-
brenik, process discovery using integer linear programming . berlin,
heidelberg: springer berlin heidelberg, 2008, pp. 368‚Äì387.
[10] a. k. a. de medeiros, t. a. j. m. m. weijters, and w. m. p. van der
aalst, ‚Äúgenetic process mining: an experimental evaluation,‚Äù data
mining and knowledge discovery , vol. 14, no. 2, pp. 245‚Äì304, 2007.
[11] s. j. j. leemans, d. fahland, and w. m. p. van der aalst, ‚Äúdiscovering
block-structured process models from event logs containing infrequent
behaviour,‚Äù in business process management workshops . springer,
2014, pp. 66‚Äì78.
[12] j. cortadella, m. kishinevsky, l. lavagno, and a. yakovlev, ‚Äúderiving
petri nets from Ô¨Ånite transition systems,‚Äù ieee transactions on compu-
ters, vol. 47, no. 8, pp. 859‚Äì882, 1998.
[13] r. bergenthum, j. desel, r. lorenz, and s. mauser, ‚Äúprocess mining
based on regions of languages,‚Äù in international conference on business
process management . springer, 2007, pp. 375‚Äì383.
[14] a. j. m. m. weijters, w. m. p. van der aalst, and a. k. a. de medei-
ros, ‚Äúprocess mining with the heuristics miner-algorithm,‚Äù technische
universiteit eindhoven, tech. rep. wp , vol. 166, pp. 1‚Äì34, 2006.[15] j. c. a. m. buijs, b. f. van dongen, and w. m. p. van der aalst,
‚Äúa genetic algorithm for discovering process trees,‚Äù in evolutionary
computation (cec), 2012 ieee congress on . ieee, 2012, pp. 1‚Äì
8.
[16] d. fahland and w. m. p. van der aalst, ‚Äúrepairing process models to
reÔ¨Çect reality,‚Äù in business process management . springer, 2012, pp.
229‚Äì245.
[17] a. polyvyanyy, w. m. p. van der aalst, a. h. m. ter hofstede, and m. t.
wynn, ‚Äúimpact-driven process model repair,‚Äù acm transactions on
software engineering and methodology , vol. 25, no. 4, pp. 28:1‚Äì28:60,
oct. 2016. [online]. available: http://doi.acm.org/10.1145/2980764
[18] a. armas-cervantes, m. l. rosa, m. m. dumas, l. garc ¬¥ƒ±a-ba Àúnuelos,
and n. r. van beest, ‚Äúinteractive and incremental business process
model repair,‚Äù qut eprints , 2017.
[19] m. l. rosa, h. a. reijers, w. m. p. van der aalst, r. m. dijkman,
j. mendling, m. dumas, and l. garca-bauelos, ‚Äúapromore: an
advanced process model repository,‚Äù expert systems with applications ,
vol. 38, no. 6, pp. 7029 ‚Äì 7040, 2011. [online]. available:
http://www.sciencedirect.com/science/article/pii/s0957417410013758
[20] a. j. rembert, a. omokpo, p. mazzoleni, and r. t. goodwin, ‚Äúpro-
cess discovery using prior knowledge,‚Äù in service-oriented computing .
springer, 2013, pp. 328‚Äì342.
[21] p. m. dixit, j. c. a. m. buijs, w. m. p. van der aalst, b. f. a. hompes,
and j. buurman, using domain knowledge to enhance process mining
results . cham: springer international publishing, 2017, pp. 76‚Äì104.
[online]. available: https://doi.org/10.1007/978-3-319-53435-0 4
[22] g. greco, a. guzzo, f. lupa, and p. luigi, ‚Äúprocess discovery under
precedence constraints,‚Äù acm transactions on knowledge discovery
from data , vol. 9, no. 4, pp. 32:1‚Äì32:39, jun. 2015.
[23] f. m. maggi, a. j. mooij, and w. m. p. van der aalst, ‚Äúuser-guided
discovery of declarative process models,‚Äù in computational intelligence
and data mining (cidm), 2011 ieee symposium on . ieee, 2011, pp.
192‚Äì199.
[24] a. adriansyah, b. f. van dongen, and w. m. p. van der aalst, ‚Äútowards
robust conformance checking,‚Äù in business process management works-
hops , ser. lecture notes in business information processing. springer
berlin heidelberg, 2011, vol. 66, pp. 122‚Äì133.
[25] j. desel and j. esparza, free choice petri nets . cambridge university
press, 2005, vol. 40.
[26] b. f. van dongen, a. k. de medeiros, h. m. w. verbeek, t. a. j.
m. m. weijters, and w. m. p. van der aalst, ‚Äúthe prom framework: a
new era in process mining tool support.‚Äù in icatpn , vol. 3536, 2005,
pp. 444‚Äì454.
[27] f. mannhardt, ‚Äúsepsis cases - event log,‚Äù ser. dataset. eindhoven
university of technology, 2016. [online]. available: https://doi.org/10.
4121/uuid:915d2bfb-7e84-49ad-a286-dc35f063a460
[28] f. mannhardt and d. blinde, ‚Äúanalyzing the trajectories of patients with
sepsis using process mining,‚Äù in radar+emisa 2017 . ceur-ws.org,
2017, pp. 72‚Äì80.
[29] s. wagner, m. w. beckmann, b. wullich, c. seggewies, m. ries,
t. b¬®urkle, and h.-u. prokosch, ‚Äúanalysis and classiÔ¨Åcation of oncology
activities on the way to workÔ¨Çow based single source documentation in
clinical information systems,‚Äù bmc medical informatics and decision
making , vol. 15, no. 1, p. 107, dec 2015. [online]. available:
https://doi.org/10.1186/s12911-015-0231-x