prototype selection using clustering and
conformance metrics for process discovery
mohammadreza fani sani1, mathilde boltenhagen2, and wil van der aalst1
1rwth aachen university, aachen, germany
ffanisani, wvdaalst g@pads.rwth-aachen.de
2lsv, universit e paris-saclay, ens paris-saclay, cnrs, inria, cachan (france)
fboltenhagen g@lsv.fr
abstract. automated process discovery algorithms aim to automati-
cally create process models based on event data that is captured during
the execution of business processes. these algorithms usually tend to
use all of the event data to discover a process model. using all (i.e.,
less common) behavior may lead to discover imprecise and/or complex
process models that may conceal important information of processes. in
this paper, we introduce a new incremental prototype selection algorithm
based on the clustering of process instances to address this problem. the
method iteratively computes a unique process model from a dierent set
of selected prototypes that are representative of whole event data and
stops when conformance metrics decrease. this method has been im-
plemented using both prom and rapidprom. we applied the proposed
method on several real event datasets with state-of-the-art process dis-
covery algorithms. results show that using the proposed method leads
to improve the general quality of discovered process models.
keywords: process miningprocess discovery prototype selection trace
clusteringevent log preprocessing quality enhancement
1 introduction
process mining bridges the gap between traditional data science techniques and
business process management analysis [1]. process discovery, one of the main
branches of this eld, aims to discover process models (e.g., petri nets or bpmn)
that describe the underlying processes captured within the event data. event
data that is also referred to as event logs , readily available in most current
information systems [1]. process models capture choice, concurrent, and loop
behavior of activities.
to measure the quality of discovered process models, four criteria have been
presented in the literature, i.e., tness ,precision ,generalization , and simplic-
ity[2].fitness indicates how much of the observed behavior in data is described
by the process model. in opposite, precision computes how much modeled be-
havior exists in the event log. generalization represents the ability of a model to
correctly capturing parts of the system that have not been recorded [3]. simplic-
ity measures the understandability of a process model by limiting the number
of nodes and complex structures of the resulting model.several automated process discovery algorithms have been proposed in the
literature that work perfectly on synthetic event logs. however, when dealing
with real event logs, many of them have diculties to discover proper models
and generate spaghetti-like process models, i.e., the discovered models contain
too many nodes and arcs. such structures are too complex for human analysis.
therefore, the quality of discovered process models depends on the given event
log which can be noisy or very complex [4]. moreover, sometimes the discovered
models are unacceptably imprecise and describe too much behavior compared
to the given event log. thus, many state-of-the-art process discovery algorithms
have diculties to balance between these four quality criteria.
the mentioned problems are usually caused by high data variability of event
logs and the existence of infrequent behavior in them. therefore, by applying
data preprocessing techniques, e.g., noise reduction [5,6], we are able to decrease
the data variability of event logs and consequently improve the resulting pro-
cess models. using this approach, the preprocessed event log is given to process
discovery algorithms instead of the original event log.
in this paper, we aim to improve the results of process discovery algorithms
by proposing a new preprocessing method that incrementally selects prototypes
in event logs. our main motivation is to get the most representable trace in-
stances. for this purpose, the method uses trace clustering. each cluster has a
representative instance that we consider as a prototype . the selection of proto-
types is incremental and depends on the moderate use of conformance checking
artifacts. by using prototypes we reduce the data variability of event logs and
consequently improve the precision and simplicity of discovered models.
using rapidprom [7], we study the usefulness of the proposed method by
applying it on several real event logs while using dierent process discovery
algorithms. the experimental results show that applying our method improves
the balance between the quality metrics of discovered process models.
the remainder of this paper is structured as follows. we rst provide a moti-
vating example in section 2. then, in section 3, we discuss related work. section
4 denes preliminary notations. we present the prototype selection method in
section 5. the evaluation and its results are given in section 6. finally, section
7 concludes the paper and presents some future work.
2 motivating example
research like [8] has shown that by using only a small subset of traces for pro-
cess discovery we sometimes can improve the quality of process models. the
main challenge faced this research is which traces should be selected as input
for process discovery algorithms. some methods, e.g.,[9,8], propose to use sam-
pling methods for this purpose without considering the quality of discovered
model during the selection phase. we aim to nd the most representative pro-
cess instances of a log, i.e., referred to prototypes, using a clustering method. to
motivate our approach, in fig 1, we show discovered models based on selected
traces of an event log (i.e., fig. 1e) by the inductive miner [10] in conjunction
with three preprocessing methods.(a) prototype se-
lection
(b) biased sam-
pling [8]
(c) frequency
based selection
(d) no prepro-
cessing
[ha; b; c; e; g i4;ha; c; b; e; g i4;
ha; b; c; e; f i3;ha; c; b; e; f i2
ha; d; e; f i;ha; d; e; g i;ha; bi;
ha; c; b; f i;hb; c; e; f i;ha; fi;
ha; b; b; e; d i;ha; d; e; g; f i;
ha; b; c; e; e; f i]
(e) event log lpreprocessing method fitness precision f1-measure
prototype selection 0.906 1.000 0.951
biased sampling 0.842 1.000 0.914
frequency based selection 0.842 1.000 0.914
no preprocessing 1.000 0.701 0.824
(f) conformance metrics comparison
fig. 1: comparison of dierent trace selection methods using the inductive miner
note that the statistical sampling method [9] returns all the traces to have a
high condence of not loosing information (and because of the small size of the
log). the biased sampling method [8] takes as input the percentage of desired
traces. in this example, we used 30% of the entire log to get the same number of
traces as our method. moreover, the frequency based selection method returns
the top most frequent traces in the log. considering conformance metrics of
discovered models using dierent preprocessing methods that is presented in
fig. 1f, we found that choosing the right instances in the log is a key factor to
discover high quality models.
3 related work
reducing event logs to only signicant behaviors is a common practice to improve
model quality. some variants of process discovery algorithms, e.g., the inductive
miner [10], directly incorporate lters to remove infrequent behavior. in [11],
infrequent traces are qualied as outliers and suggested to be ltered out. inde-
pendent to process discovery algorithms, ltering methods like [5,6,12] remove
outlier behaviors in event logs. these works show possibilities of improvement
when using reduced event logs as the input for process discovery algorithms.
another way to reduce log variability that causes simpler models is to ex-
tract only a small set of traces. authors in [8] and [9] present dierent trace
selection methods that improve the performance of process discovery algorithms
using random and biased sampling. these works are close to the present paper's
method as the size of the reduced log is considerably smaller than the original
one. we aim to select the most representative traces for process discovery.as our prototype selection uses a clustering method, we recall that trace
clustering has been used in process mining to get several sub-models according
to clustered sub-logs [13,14,15,16]. the quality of the sub-models is better than a
single process model discovered on the whole event log. however, getting several
process models may be a barrier for decision-makers who need a single overview
of each process.
finally, in [2] a genetic process discovery algorithm is proposed that benets
from conformance artifacts. however, this method is time-consuming for large
real event logs and it is impractical using normal hardware.
4 preliminaries
in this paper, we focus on sequences of activities, also called traces, that are
combined into event logs.
denition 1 (event log). letabe a set of activities. an event log is a
multiset of sequences over a, i.e.,l2b(a)that is a nite set of words. a
word, i.e., a sequence of activities, in an event log is also called a trace .
fig. 1 shows an example of event log l. the occurrence of trace-variant
ha;b;c;e;giin this event log is four.
a sub-logl1of a loglis a set of traces such that l1l. a trace clustering
method aims to nd disjoint sub-logs according to the similarity between traces.
denition 2 (trace clustering). given a log l, a trace clustering (l;n)
is a partitioning of lin a set of sub-logs fl1;l2:::;lngsuch that
8i6=j(li\lj=;)and]
i=1:nli=l.
we usually need a distance metric to cluster objects. one distance metric that
is widely used to cluster words is edit distance.
denition 3 (edit distance). let;02a, edit distance function
4(;0)!nreturns the minimum number of edits that are required to
transformto0.
we assume that an edit operation can only be a deletion or an insertion of
an activity in a trace. to give an example, 4(ha;c;f;e;di;ha;f;c;a;di)=4
corresponding to two deletions and two insertions.
some clustering algorithms return a medoid for each cluster that is a rep-
resentative object of that cluster. in this paper, we also return prototypes as
medoids which have the closest distance with other objects in their cluster.
denition 4 (prototypes). let:b(a)!abe a function that for each sub-
loglireturnspi2liwhich has the the minimum distance with other traces in that
sub-log, i.e.,p
2li(4(pi;)). for a trace clustering (l;n)=fl1;l2;:::;lng,
prototypes are a setp=fpi=(li) :li2(l;n)g.
in other words, a prototype is a unique trace-variant that represents a sub-log.
aprocess model , commonly petri net or bpmn, describes a set of traces. as
the present paper does not propose a specic notation for process models, we
dene a process model by its describing behavior.denition 5 (runs of process model). letmbe a process model with a
set of activitiesa. we dene a set of all possible traces that can be executed by
mas runs (m)a. in case of having loop in the model, this set is innite.
for example, fig. 1a describes six traces; therefore, we have runs (m)=
fha;c;b;e;gi;ha;b;c;e;gi;ha;d;e;gi;ha;c;b;e;fi;ha;b;c;e;fi;ha;d;e;fig.
a process model and an event log may have some deviations. for instance,
ha;fiis not in the described behavior of the model that is presented in fig. 1a).
it is shown in [17] that using the following formula, we can measure the tness
of a model and a traces based on the edit distance function.
tracefitness (l;m) = 1 min
2runs (m)4(l;)
jlj+ min
2runs (m)jj(1)
the tness of an event log and a model is a weighted average of the trace-tness
of trace logs. thus, log traces with a higher frequency have higher weights.
in contrast, precision shows how much behavior in a model exists in occurs in
the log. in this paper, we refer by precision (l;m ) to etc [18] as it has a high
performance computation; however any other precision metrics can be used. to
balance between the two main metrics, we use the f-measure [19]:
f-measure = 2precisionfitness
precision +fitness(2)
5 incremental prototype selection for process discovery
in this section, we explain the details of our approach to use the selected proto-
types , i.e., a subset of traces, for representing the entire log as a process model. as
explained, we use a clustering approach to select the representative prototypes
for process discovery. the schematic view of the proposed method is presented
in fig. 2. the method contains the following four main steps:
1.clustering for prototype selection : to select prototypes using a clustering
method.
2.model discovery : discovering a model based on the selected prototypes.
fig. 2: structure of the prototype selection approach3.quality assessment : to evaluate the discovered model based on the original
event log, conformance artifacts are computed.
4.iteration over deviating traces : while quality metrics improve, we iterate the
method (from step 1) on the deviating traces of the last discovered model.
the prototype selection is an iterative process; then, the sub-log of selected
prototypes gently grows in each iteration. during an iterative process, we expect
that tness increases while the precision value decreases. here, we explain each
step in more detail.
1- clustering for prototype selection by applying process discovery al-
gorithms directly on a complete event logs, we usually obtain complex and im-
precise process models. as presented in [20,8] by modifying and sampling event
logs we are able to improve results of process discovery algorithms in terms of
f-measure. we apply clustering to extract a very small set of representatives
traces, i.e., prototypes. in this regards, we use k-medoids [21] to cluster traces
inksub-logs by considering their similarity (using the edit distance function).
this algorithm works as follows:
1. select randomly k(i.e., the number of clusters) traces in las medoids.
2. create, or update, clusters by associating each trace to its closest medoid
based on the edit distance metric.
3. for each cluster, redene the medoid as the prototype of the cluster according
to denition 4 using function. if medoids haven't changed, return the k
prototypes. otherwise, do step 2 again.
the prototypes are then added to the set of selected prototypes which is
empty at the rst iteration of our method (see fig. 2). for example, for the
event log that is presented in fig. 1e, applying the clustering with k=3 in the
rst iteration gives ha;b;c;gi,ha;c;b;e;fiandha;d;e;fias prototypes.
2- model discovery after selecting a set of prototypes, we discover a descrip-
tive view of it, i.e., a process model. in this regard, we are exible to use any
process discovery algorithm. however, it is recommended to use methods that
guarantee to return sound process models as it is necessary for tness computa-
tion. by discovering a process model from the selected prototypes, we will have
a general view of what is going on in the process and position dierent log traces
w.r.t, this model.
3- quality assessment to ensure that the discovered process model via pro-
totypes conforms to the whole event log, we incorporate quality assessment eval-
uations in our method. we use the f-measure to get a good balance between
tness and precision. the metric is computed by considering the original event
log and the process model created based on the selected prototypes.
4- iteration over deviating traces the f-measure is computed for the rst
time after the initialization step that selects a rst set of prototypes. thereafter,
the proposed method starts an iterative procedure. in each iteration, the method
rst nds the deviating traces that are formally dened as follows.table 1: some information of the real-life event logs used in the experiments.
event log activities# traces# variants# df relations#
bpic 2012[23] 23 13087 4336 138
bpic 2018 insp. [24]15 5485 3190 67
bpic 2019[25] 44 251734 11973 538
hospital [26] 18 100000 1020 143
road [27] 11 150370 231 70
sepsis [28] 16 1050 846 115
denition 6 (deviating traces). letmbe a process model and lbe an
event log. the deviating traces isld=f2l:62runs (m)g.
after nding the deviating traces, we look for other representative traces
among them like what we did in step 1, i.e., using clustering. then, the new
prototypes will be added to the previous ones (see fig. 2). here, for clustering
of deviating traces, we are able to use similar or dierent kcompared to the
rst step. thereafter, we apply again the process discovery algorithm to nd a
new process model and so on. afterward, we compare the previous and current
f-measure values. the iterative procedure stops when the quality of the new
discovered process model is lower than the previous one. by increasing in the
number of the selected prototypes, we expected that the tness of discovered
model is increased, but its precision is decreased. so we use f-measure that bal-
ances the metrics. we make the hypothesis that process discovery algorithms
tend to approach high tness and adding traces in the input raises the tness
of the whole log and decreases the precision. this hypothesis is commonly true
(as also assumed in [22]). therefore, the algorithms stops when there is no im-
provement in f-measure of the discovered process model of prototypes.
6 experiments
in this section, we investigate whether the proposed method results in process
models with higher quality. to apply the proposed method, we implemented
theprototype selection plug-in in prom framework.the plug-in takes an event
log as input and outputs the discovered model and the selected prototypes.
as presented above, our method uses two parameters, i.e., the number of clus-
ters/prototypes that will be selected in each iteration and the process discovery
algorithm. to simplify the plug-in, we consider the same cluster size for both
step 1 and 4. we ported the prototype selection plug-in into rapidprom that
allows us to apply the proposed method on various event logs with dierent
parameters. rapidprom is an extension of rapidminer that combines scientic
workows with a range of ( prom -based) process mining algorithms.
the experiments have been conducted on six real event logs of dierent elds,
from healthcare to insurance. event logs have dierent characteristics which are
given in tab. 1.
in the following, we rst position the proposed method compared to some
state-of-the-art preprocessing methods. later, we analyze the clustering method
for selecting prototypes.table 2: average of precision, tness, and f-measure for dierent methods.
6.1 process discovery improvement
here we aim to nd out how the proposed method is able to improve the re-
sults of dierent process discovery algorithms. as the prototype selection has
two parameters, i.e., the number of clusters and the discovery algorithm, we
show results over a set of dierent settings. we repeated the experiments for
2 to 9 clusters and we used the inductive miner [29], the ilp miner [30], and
the split miner [31]. moreover, we compared our work with two trace sampling
methods [8,9], i.e., referred to sampling and statistical respectively. for both
of these methods, we ran the experiments with 20 dierent settings. when we
use the preprocessing methods, we used the inductive miner with its ltering
mechanism set to 0 and the default setting for the split miner. we also com-
pared our method to normal process discovery algorithms, i.e, discovery without
preprocessing which we denote it by nothing in the experiments. for this case,
we ran a set of experiments with 50 dierent settings for the inductive miner
(imi) and 100 for the split miner. for the ilp miner, we just run the experiment
without its internal ltering mechanism.
tables 2 and 3 show the average results of the experiments over the dierent
settings. it is shown in tab. 2 that for most of the cases, the f-measure of discov-
ered process models using the prototype selection method is higher than other
preprocessing techniques and generally, the proposed method leads to provide
more precise process models.
for simplicity, in tab.3, we consider two metrics that measure the complexity
of discovered process models. model size of process models is a combination
of the number of transitions, places, and arcs that connected them. another
metric is the cardoso metric [32] that measures the complexity of a processtable 3: comparison of simplicity measures for dierent preprocessing methods.
model by its complex structures, i.e., xor,or, and and components. for both of
these measures, a lower value means less complexity and consequently a simpler
process model. results show that we can have much simpler process models using
the proposed method. by considering both tables, we see that the presented
method helps to get more precise and simpler models in most of the event logs.
6.2 using clustering for prototype selection
here, we aim to nd how by selecting prototypes using the clustering method we
improve the quality of process models. we increased the number of prototypes
from 1 to 20 and analyze the quality of the resulted models for sepsis [28], and
road [27] event logs. we used the inductive miner without the internal ltering
for model discovery. in fig. 3, we compared the results of prototype selection
based on clustering and the most frequent variants on the discovered models.
in fig. 3a, the log coverage shows how many percentage of the traces in
the event log, is corresponds to the selected prototypes. moreover, the model
coverages indicates that how many percentages of traces in the event log is
replayable (or perfectly tted) by the discovered process model. for example,
in the sepsis event log, by selecting eight prototypes, i.e., corresponds to 5% of
traces, the discovered process model is able to perfectly replay 35% of the traces
in the event log. fig. 3a shows that process discovery algorithms depict much
behavior in the process model compared to the given event log. for event log with
high frequent traces, e.g., road , when we select very few process instances, by
selection based on frequency, we usually have higher model coverage. however,
when we select more than 10 prototypes, or for event logs with lots of unique
variants, e.g., sepsis , the model coverage of clustering method is higher.
in fig. 3b, we see how by increasing the number of prototypes, generally
tness increases and precision decreases. this reduction is higher when we select
based on frequency. results show that we can discover a high tted process(a) coverage analysis
(b) fitness and precision analysis
fig. 3: eects of increasing the number of selected prototypes on the quality
issues of discovered process models using frequency and clustering methods.
model without giving just a few prototypes to process discovery algorithms.
this experiment shows that using the clustering algorithm we can choose the
more representative prototypes specically if the log has lots of unique behavior.
7 conclusion
in this paper, we proposed an incremental method to select prototypes of the
event logs in order to generate simple and precise process models having a good
f-measure. it clusters the traces in the event log based on their control-ow dis-
tances. afterward, it returns the most representative instance for each cluster,
i.e., the prototype. we discover a process model of the selected prototypes which
is analyzed by common conformance metrics. then, the method recessively se-
lects new prototypes from deviating traces. a novel set of traces is added to the
process discovery algorithm which improves tness while decreasing precision.
to evaluate the proposed method, we have developed it in prom and
rapidprom , and have applied the proposed prototype selection method on six real
event logs. we compared it with other state-of-the-art sampling methods using
dierent process discovery algorithms. the results indicate that the proposed
method is able to select process instances properly and help process discov-
ery algorithms to return process models with a better balance between quality
measures. discovered models are less complex and, consequently, easier to un-
derstand. another advantage of our method is that it is more stable in chosen
settings of parameters and tends to return process models with higher quality.
as future work, it is possible to nd prototypes using more advanced clus-
tering methods and measures that are proposed in the literature. indeed, theweakness of the f-measure is the fact that it is an average of tness and pre-
cision, which blurs the understanding of the chosen model. instead, the use of
f-measure introduced in [33] can help one to balance between the two crite-
ria. moreover, we aim to use prototypes for other purposes, e.g., conformance
checking and performance analysis. one limitation of our method is it may nd
a local optimum rather than the global optimum. we plan to use an adjustable
number of clusters for both initiating phase and incremental steps.
acknowledgment
we thank prof. josep carmona, dr. thomas chatain and dr. sebastiaan j. van
zelst for comments that greatly improved the work. we also thank the alexander
von humboldt (avh) stiftung for supporting this research.
references
1. van der aalst, w.m.p.: process mining - data science in action, second edition.
springer berlin heidelberg (2016)
2. buijs, j.c., van dongen, b., van der aalst, w.m.p.: on the role of fitness,
precision, generalization and simplicity in process discovery. in: coopis 2012,
rome, italy. (2012) 305{322
3. carmona, j., van dongen, b., solti, a., weidlich, m.: conformance checking.
springer (2018)
4. bose, r.j.c., mans, r.s., van der aalst, w.m.p.: wanna improve process mining
results? in: ieee symposium on computational intelligence and data mining,
cidm 2013, singapore, 16-19 april, 2013. (2013) 127{134
5. conforti, r., rosa, m.l., ter hofstede, a.h.m.: filtering out infrequent behavior
from business process event logs. ieee trans. knowl. data eng. 29(2) (2017)
300{314
6. fani sani, m., van zelst, s.j., van der aalst, w.m.p.: improving process discovery
results by ltering outliers using conditional behavioural probabilities. in: business
process management workshops, revised papers. (2017)
7. van der aalst, w.m.p., bolt, a., van zelst, s.: rapidprom: mine your processes
and not just your data. corr abs/1703.03740 (2017)
8. fani sani, m., van zelst, s.j., van der aalst, w.m.p.: the impact of event
log subset selection on the performance of process discovery algorithms. in: new
trends in databases and information systems, slovenia. (2019) 391{404
9. bauer, m., senderovich, a., gal, a., grunske, l., weidlich, m.: how much event
data is enough? a statistical framework for process discovery. in: caise 2018,
tallinn, estonia, 2018, proceedings. (2018) 239{256
10. leemans, s.j., fahland, d., van der aalst, w.m.p.: discovering block-structured
process models from event logs containing infrequent behaviour. in: bpm 2013
international workshops, beijing, china. (2013) 66{78
11. ghionna, l., greco, g., guzzo, a., pontieri, l.: outlier detection techniques for
process mining applications. in: foundations of intelligent systems, 17th interna-
tional symposium, ismis. (2008) 150{159
12. fani sani, m., van zelst, s.j., van der aalst, w.m.p.: applying sequence mining
for outlier detection in process mining. in: coopis 2018, malta. (2018) 98{11613. tax, n., sidorova, n., haakma, r., van der aalst, w.m.p.: mining local process
models. j. innov. digit. ecosyst. 3(2) (2016) 183{196
14. boltenhagen, m., chatain, t., carmona, j.: generalized alignment-based trace
clustering of process behavior. in: application and theory of petri nets and
concurrency - 40th international conference, germany. (2019) 237{257
15. weerdt, j.d., vanden broucke, s.k.l.m., vanthienen, j., baesens, b.: leveraging
process discovery with trace clustering and text mining for intelligent analysis of
incident management processes. in: proceedings of the ieee congress on evolu-
tionary computation, cec. (2012) 1{8
16. de weerdt, j., vanden broucke, s., vanthienen, j., baesens, b.: active trace
clustering for improved process discovery. ieee trans. knowl. data eng. 25(12)
(2013) 2708{2720
17. fani sani, m., van zelst, s.j., van der aalst, w.m.p.: conformance checking
approximation using subset selection and edit distance. in: caise 2020, grenoble,
france, june 8-12, 2020, proceedings. (2020) 234{251
18. mu~ noz-gama, j., carmona, j.: a fresh look at precision in process conformance. in:
business process management - 8th international conference, bpm 2010, hobo-
ken, nj, usa, september 13-16, 2010. proceedings. (2010) 211{226
19. van rijsbergen, c.j.: information retrieval. (1979)
20. fani sani, m., van zelst, s.j., van der aalst, w.m.p.: repairing outlier behaviour
in event logs using contextual behaviour. enterp. model. inf. syst. archit. int. j.
concept. model. 14(2018) 5:1{5:24
21. de amorim, r.c., zampieri, m.: eective spell checking methods using clustering
algorithms. in: recent advances in natural language processing, ranlp 2013,
9-11 september, 2013, hissar, bulgaria. (2013) 172{178
22. augusto, a., dumas, m., la rosa, m.: metaheuristic optimization for automated
business process discovery. in: business process management - 17th international
conference, vienna, austria. (2019) 268{285
23. van dongen, b.f.: bpi challenge 2012. eindhoven university of technology.
dataset. (2012)
24. van dongen, b.f., borchert, f. (florian): bpi challenge 2018 eindhoven univer-
sity of technology. dataset. (2018)
25. van dongen, b.f.: bpi challenge 2019. eindhoven university of technology.
dataset. (2019)
26. mannhardt, f.: hospital billing-event log. eindhoven university of technology.
dataset. eindhoven university of technology. dataset (2017) 326{347
27. de leoni, m., mannhardt, f.: road trac ne management process. eindhoven
university of technology. dataset (2015)
28. mannhardt, f.: sepsis cases-event log. eindhoven university of technology (2016)
29. leemans, s.j.j., fahland, d., van der aalst, w.m.p.: discovering block-structured
process models from event logs containing infrequent behaviour. in: business pro-
cess management workshops - bpm 2013 international workshops. (2013) 66{78
30. van zelst, s.j., van dongen, b.f., van der aalst, w.m.p., verbeek, h.m.w.: dis-
covering relaxed sound workow nets using integer linear programming. corr
(2017)
31. augusto, a., conforti, r., dumas, m., rosa, m.l., polyvyanyy, a.: split miner:
automated discovery of accurate and simple business process models from event
logs. knowl. inf. syst. 59(2) (2019) 251{284
32. lassen, k.b., van der aalst, w.m.p.: complexity metrics for workow nets. inf.
softw. technol. 51(3) (2009) 610{626
33. chinchor, n.: muc-4 evaluation metrics, acl (1992)