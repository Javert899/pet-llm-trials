business alignment: using process mining as a
tool for delta analysis and conformance
testing
w.m.p. van der aalst
department of technology management, eindhoven university of technology, p.o.
box 513, nl-5600 mb, eindhoven, the netherlands.
phone: +31 40 247.4295/2290. fax: +31 40 243.2612.
w.m.p.v.d.aalst@tm.tue.nl
abstract. increasingly, business processes are being controlled and/or
monitored by information systems. as a result, many business processesleave their “footprints” in transactional information systems, i.e., busi-
ness events are recorded in so-called event logs. process mining aims at
improving this by providing techniques and tools for discovering process,control, data, organizational, and social structures from event logs, i.e.,
the basic idea of process mining is to diagnose business processes by
mining event logs for knowledge. in this paper we focus on the potentialuse of process mining for measuring business alignment , i.e., comparing
the real behavior of an information system or its users with the intended
or expected behavior. we identify two ways to create and/or maintainthe ﬁt between business processes and supporting information systems:
delta analysis andconformance testing . delta analysis compares the dis-
covered model (i.e., an abstraction derived from the actual process) withsome predeﬁned processes model (e.g., the workﬂow model or reference
model used to conﬁgure the system). conformance testing attempts to
quantify the “ﬁt” between the event log and some predeﬁned processes
model. in this paper, we show that delta analysis and conformance test-
ing can be used to analyze business alignment as long as the actual eventsare logged and users have some control over the process.
key words : process mining, business process management, business alignment,
workﬂow management, delta analysis, conformance testing.
1 introduction
in many organizations new processes are emerging and existing processes are
changing (“the only constant is change”). therefore, the alignment of business
processes and information systems requires continuous attention. to “maintain
the ﬁt” it is important to detect changes over time, i.e., deviations of the de-scribed or prescribed behavior. rare deviations will always happen, but should
not be regarded as a symptom of a change. however, if considerable amount
of process instances deviate from the prescribed pattern, some action should beundertaken to align the business process and the supporting information system.
similarly, to “create the ﬁt” it may be worthwhile to monitor the actual behaviorof the people in the organization before conﬁguring/installing the (new) informa-
tion system. both for creating and maintaining the ﬁt (i.e., securing alignment)
we propose process mining techniques which use event logs to discover the actual
process.
today, many enterprise information systems store relevant events in some
structured form. for example, workﬂow management systems typically register
the start and completion of activities. erp systems like sap log all transactions,e.g., users ﬁlling out forms, changing documents, etc. business-to-business (b2b)
systems log the exchange of messages with other parties. call center packages
but also general-purpose crm systems log interactions with customers. theseexamples show that many systems have some kind of event log often referred to
as “history”, “audit trail”, “transaction log”, etc. [1, 2]. the event log typically
contains information about events referring to an activity and a case. the case
(also named process instance) is the “thing” which is being handled, e.g., a
customer order, a job application, an insurance claim, a building permit, etc. the
activity (also named task, operation, action, or work-item) is some operation onthe case. typically, events have a timestamp indicating the time of occurrence.
moreover, when people are involved, event logs will typically contain information
on the person executing or initiating the event, i.e., the originator . based on this
information several tools and techniques for process mining have been developed.
process mining is useful for at least two reasons. first of all, it could be used
as a tool to ﬁnd out how people and/or procedures really work. consider for
example processes supported by an erp system like sap (e.g., a procurementprocess). such a system logs all transactions but in many cases does not enforce
a speciﬁc way of working. in such an environment, process mining could be used
to gain insight in the actual process. another example would be the ﬂow of pa-tients in a hospital. note that in such an environment all activities are logged but
information about the underlying process is typically missing. in this context it
is important to stress that management information systems provide informa-tion about key performance indicators like resource utilization, ﬂow times, and
service levels but notabout the underlying business processes (e.g., causal rela-
tions, ordering of activities, etc.). second, process mining could be used for delta
analysis , i.e., comparing the actual process with some predeﬁned process. note
that in many situations there is a descriptive or prescriptive process model. sucha model speciﬁes how people and organizations are assumed/expected to work.
by comparing the descriptive or prescriptive process model with the discovered
model, discrepancies between both can be detected and used to improve the pro-cess. consider for example the so-called reference models in the context of sap.
these models describe how the system should be used. using process mining it
is possible to verify whether this is the case. in fact, process mining could alsobe used to compare diﬀerent departments/organizations using the same erp
system. instead of doing a delta analysis it is also possible to do conformance
testing . the basic idea of conformance testing is to directly compare the log with
2the descriptive or prescriptive process model, i.e., do the log and the model “ﬁt”
together.
information
systemoperational
process
process
modelsevent
logsmodels
process
mining
conformance
testingrecords
configures
delta
analysissupports/
controls
fig. 1. tackling business alignment (i.e., the “ﬁt” between the operational process and
the information system) using delta analysis and conformance testing.
figure 1 illustrates the way process mining, delta analysis, and conformance
testing can be used to analyze business alignment. clearly, the operational pro-
cess and the information system interact, i.e., the information system is used tosupport or even control the operational process. the information system is often
conﬁgured on the basis of a process model as figure 1 shows. this model is often
some abstraction of the operational process. in fact it is interesting to note thatsimilar models can be used to analyze the operational process and to conﬁgure
the information system. people using workﬂow management systems and simu-
lation tools often note the many similarities between the workﬂow speciﬁcationand the simulation model. as indicated, many information systems log events
referring to actions in the operational process. these logs can be used for pro-
cess mining. as figure 1 shows, process mining derives a process model from an
event log. the resulting process model can be compared with the original model
(delta analysis). it is however also possible to compare the event log directlywith the original model (conformance testing).
this paper is a spin-oﬀ of the bpmds 2004 workshop (cf. [3, 4]). here the fo-
cus was on business alignment and not necessarily on requirements engineering.for the readership of the requirements engineering journal it is interesting to
put process mining, delta analysis, and conformance testing in the context of the
software development process. there are two possible ways these techniques canbe applied in this context. first of all, the software development process is also
a process and in some cases the activities in this process are also logged. there
are similarities to for example the application of process mining in the context
3of product data management (pdm) systems. here the objects are design doc-
uments (e.g., a technical drawing) that can be indiﬀerent states. artifacts in thesoftware development process (e.g., designs and executable code) also go through
diﬀerent states. a version control system such as concurrent versions system
(cvs) can be used for process mining and the actual processes can be comparedwith a normative process model. second, the aim of requirement engineering is
to produce software that “ﬁts”. for example, co-development, i.e., concurrently
designing business processes and business software applications, aims at aligningbusiness processes and software. here process mining, delta analysis, and confor-
mance testing can be used to compare designs (e.g., uml models) with real-life
scenarios. every audit trail can be seen as a scenario and using the techniquespresented in this paper a set of scenarios (e.g., event log) can be compared with
artifacts in the software development process at diﬀerent levels of granularity
(from high-level designs to executable code).
the remainder of this paper is organized as follows. section 2 introduces
the concept of business process mining followed by a short description of a case
study in section 3. section 4 discusses process mining as a tool for delta analysis,
i.e., measuring the business alignment by comparing event logs with descriptiveor prescriptive (process) models. section 5 discusses metrics for conformance
testing, i.e., quantifying the ﬁt. finally, section 6 discusses related work and
section 7 concludes the paper.
2 business process mining: an overview
the goal of process mining is to extract information about processes from trans-
action logs [1]. we assume that it is possible to record events such that (i) each
event refers to an activity (i.e., a well-deﬁned step in the process), (ii) each event
refers to a case(i.e., a process instance), (iii) each event can have a performer
a l s or e f e r r e dt oa s originator (the person executing or initiating the activity),
and (iv) events have a timestamp and are totally ordered.1table 1 shows an
example of a log involving 19 events, 5 activities, and 6 originators. in addition
to the information shown in this table, some event logs contain more informa-
tion on the case itself, i.e., data elements referring to properties of the case. forexample, the case handling systems flower logs every modiﬁcation of some
data element.
event logs such as the one shown in table 1 are used as the starting point for
mining. we distinguish three diﬀerent perspectives: (1) the process perspective,
(2) the organizational perspective and (3) the case perspective. the process per-
spective focuses on the control-ﬂow, i.e., the ordering of activities. the goal of
1note that in table 1 we abstract from event types , i.e., we consider activities to
be atomic. in real logs events typically correspond to the start or completion of an
activity. this way it is possible to measure the duration of activity and to explicitlydetect parallelism. moreover, there are other event types related to failures, schedul-
ing, delegations, etc. for simplicity we abstract from this in this paper. however, in
our process mining tools we take event types into account.
4case id activity id originator timestamp
case 1 activity a john 9-3-2004:15.01
case 2 activity a john 9-3-2004:15.12
case 3 activity a sue 9-3-2004:16.03
case 3 activity b carol 9-3-2004:16.07
case 1 activity b mike 9-3-2004:18.25
case 1 activity c john 10-3-2004:9.23
case 2 activity c mike 10-3-2004:10.34
case 4 activity a sue 10-3-2004:10.35
case 2 activity b john 10-3-2004:12.34
case 2 activity d pete 10-3-2004:12.50
case 5 activity a sue 10-3-2004:13.05
case 4 activity c carol 11-3-2004:10.12
case 1 activity d pete 11-3-2004:10.14
case 3 activity c sue 11-3-2004:10.44
case 3 activity d pete 11-3-2004:11.03
case 4 activity b sue 11-3-2004:11.18
case 5 activity e clare 11-3-2004:12.22
case 5 activity d clare 11-3-2004:14.34
case 4 activity d pete 11-3-2004:15.56
table 1. an event log.
mining this perspective is to ﬁnd a good characterization of all possible paths,
e.g., expressed in terms of a petri net or event-driven process chain (epc). the
organizational perspective focuses on the originator ﬁeld, i.e., which performers
are involved and how are they related. the goal is to either structure the or-ganization by classifying people in terms of roles and organizational units or to
show relation between individual performers (i.e., build a social network). the
case perspective focuses on properties of cases. cases can be characterized by
their path in the process or by the originators working on a case. however, cases
can also be characterized by the values of the corresponding data elements. for
example, if a case represent a replenishment order it is interesting to know the
supplier or the number of products ordered.
the process perspective is concerned with the “how?” question, the orga-
nizational perspective is concerned with the “who?” question, and the case
perspective is concerned with the “what?” question. to illustrate the ﬁrst twoconsider figure 2. the log shown in table 1 contains information about ﬁve
cases (i.e., process instances). the log shows that for four cases (1, 2, 3, and
4) the activities a, b, c, and d have been executed. for the ﬁfth case onlythree activities are executed: activities a, e, and d. each case starts with the
execution of a and ends with the execution of d. if activity b is executed, then
also activity c is executed. however, for some cases activity c is executed be-fore activity b. based on the information shown in table 1 and by making some
assumptions about the completeness of the log (i.e., assuming that the cases are
representative and a suﬃcient large subset of possible behaviors is observed), we
5aand
-splitb
cand
-join
d
e
(a) the control-flow structure expressed in terms of a petri net.
(b) the organizational structure expressed in
terms of an activity-role-performer diagram.john sue mike carol pete clarerole x role y role zjohn sue
mike
carol peteclare
(c) a sociogram based on transfer of work.
fig. 2. some mining results for the process perspective (a) and organizational (b and
c) perspective based on the event log shown in table 1.
6can deduce the process model shown in figure 2(a). the model is represented
in terms of a petri net [5]. (in fact it is a workﬂow net, see also section 4 formore details.) the petri net starts with activity a and ﬁnishes with activity
d. these activities are represented by transitions. after executing a there is a
choice between either executing b and c in parallel or just executing activitye. to execute b and c in parallel two non-observable activities (and-split and
and-join) have been added. these activities have been added for routing pur-
poses only and are not present in the event log. note that for this example weassume that two activities are in parallel if they appear in any order. by distin-
guishing between start events and complete events for activities it is possible to
explicitly detect parallelism.
figure 2(a) does not show any information about the organization, i.e., it
does not use any information on the people executing activities. however, ta-
ble 1 shows information about the performers. for example, we can deduce thatactivity a is executed by either john or sue, activity b is executed by john,
sue, mike or carol, c is executed by john, sue, mike or carol, d is executed by
pete or clare, and e is executed by clare. we could indicate this information in
figure 2(a). the information could also be used to “guess” or “discover” organi-
zational structures. for example, a guess could be that there are three roles: x,y, and z. for the execution of a role x is required and john and sue have this
role. for the execution of b and c role y is required and john, sue, mike and
carol have this role. for the execution of d and e role z is required and peteand clare have this role. for ﬁve cases these choices may seem arbitrary but for
larger data sets such inferences capture the dominant roles in an organization.
the resulting “activity-role-performer diagram” is shown in figure 2(b). thethree “discovered” roles link activities to performers. figure 2(c) shows another
view on the organization based on the transfer of work from one individual to
another, i.e., not focus on the relation between the process and individuals buton relations among individuals (or groups of individuals). consider for example
table 1. although carol and mike can execute the same activities (b and c),
mike is always working with john (cases 1 and 2) and carol is always workingwith sue (cases 3 and 4). probably carol and mike have the same role but based
on the small sample shown in table 1 it seems that john is not working with
carol and sue is not working with carol. these examples show that the event
log can be used to derive relations between performers of activities, thus result-
ing in a sociogram. for example, it is possible to generate a sociogram based onthe transfers of work from one individual to another as is shown in figure 2(c).
each node represents one of the six performers and each arc represents that
there has been a transfer of work from one individual to another. the deﬁnitionof “transfer of work from a to b” is based on whether there for the same case
an activity executed by a is directly followed by an activity executed by b. for
example, both in case 1 and 2 there is a transfer from john to mike. figure 2(c)does not show frequencies. however, for analysis proposes these frequencies can
added. the arc from john to mike would then have weight 2. typically, we do
not use absolute frequencies but weighted frequencies to get relative values be-
7tween 0 and 1. figure 2(c) shows that work is transferred to pete but not vice
versa. mike only interacts with john and carol only interacts with sue. clare isthe only person transferring work to herself.
besides the “how?” and “who?” question (i.e., the process and organization
perspectives), there is the case perspective that is concerned with the “what?”question. figure 2 does not address this. in fact, focusing on the case perspec-
tive is most interesting when also data elements are logged but these are not
listed in table 1. the case perspective looks at the case as a whole and tries toestablish relations between the various properties of a case. note that some of
the properties may refer to the activities being executed, the performers working
on the case, and the values of various data elements linked to the case. usingclustering algorithms it would for example be possible to show a positive corre-
lation between the the size of an order or its handling time and the involvement
of speciﬁc people.
orthogonal to the three perspectives (process, organization, and case), the
result of a mining eﬀort may refer to logical issues and/or performance issues.
for example, process mining can focus on the logical structure of the process
model (e.g., the petri net shown in figure 2(a)) or on performance issues such
as ﬂow time. for mining the organizational perspectives, the emphasis can beon the roles or the social network (cf. figure 2(b) and (c)) or on the utilization
of performers or execution frequencies.
to address the three perspectives and the logical and performance issues we
have developed a set of tools including emit, thumb , and minson sharing a
common xml format. recently, these tools have been merged into the prom
framework (see http://www.processmining.org for more details). figure 3 shows
a screenshot of the prom tool while analyzing the event log shown in table 1.
note that indeed the results shown in figure 2 are obtained.
3 case study
we have applied our mining techniques in several organizations. in this section,we brieﬂy show some results for one of these organizations, i.e., the processes of
a dutch governmental institution responsible for ﬁne-collection.
2a case (pro-
cess instance) is a ﬁne that has to be paid. there may be more ﬁnes related
with the same person. however, each ﬁne corresponds to an independent case.
this process has the particularity that as soon as the ﬁne is paid, the processstops. in total there are 99 distinct activities which can be either manually or
automatically executed. we selected the ﬁnes information for 130136 cases. we
constructed the process log and we applied to this log our process discovery
method that can handle noisy data [6, 7].
figure 4 (top-left) shows a fragment of the log containing 130136 cases. this
log is generated by an information system speciﬁcally constructed for the dutch
2the name of the organization is not given for reasons of conﬁdentiality. we want
to thank l. maruster, r. dorenbos, h.j. de vries, h. reijers, and a. in ’t veld for
their valuable support.
8fig. 3. some mining results obtained using prom based on the event log shown in
table 1.
governmental institution. (the institution has been in the process of using stan-
dard workﬂow technology but this process has been put “on hold”.) the top-
right screen shows a screenshot of our mining tool emit while analyzing the log.the bottom screenshot shows the whole process obtained through application
of the process mining techniques. the discovered models have been inspected
by the domain experts. they concluded that our discovered models were ableto grasp the important aspects of the process. moreover, the discovered models
revealed aspects that are often questioned when discussing the process model.
these experiences showed that process discovery can provide useful insights into
the current practice of a process and highlight diﬀerence between the actual
process and the prescriptive/descriptive model [7].
we have also applied our process mining techniques to a health-care pro-
cess where the ﬂow of multi-disciplinary patients is analyzed. we have analyzedevent logs (visits to diﬀerent specialists) of patients with peripheral arterial vas-
cular diseases of the elizabeth hospital in tilburg and the academic hospital
in maastricht. patients with peripheral arterial vascular diseases are a typicalexample of multi-disciplinary patients. we have preliminary results showing that
process mining is very diﬃcult given the “spaghetti-like” nature of this process.
only by focusing on speciﬁc tasks and abstracting from infrequent tasks we are
9fig. 4. a fragment of the log of a dutch governmental institution responsible for ﬁne-
collection and the corresponding process mining result.
able to successfully mine such processes. given this experience we are now fo-
cusing on processes have more structure. for example, environments using case
handling system like flower (the workﬂow product of pallas athena), e.g., the
employee insurance implementing body (uitvoering werknemersverzekeringen,
or uvw).
the case studies show that in many situations there is a discrepancy be-
tween the predeﬁned process (i.e., a descriptive or prescriptive process model)
and the real process (i.e., the process model obtained through mining). fromthe viewpoint of business alignment these discrepancies are of particular interest
since they may indicate a misﬁt between the information system (based on an
unrealistic or incorrect descriptive or prescriptive process model) and the realbusiness process. in the remainder we explore two techniques to analyze or mea-
sure discrepancies between some predeﬁned process and the real process: (1)
delta analysis and (2) conformance testing .
104 delta analysis
process mining can be used for delta analysis , i.e., comparing the actual pro-
cess, represented by a process model obtained through process mining, with somepredeﬁned process representing the information system. note that in many situ-
ations there is a descriptive orprescriptive process model. such a model speciﬁes
how people and organizations are assumed/expected to work. by comparing the
descriptive or prescriptive process model with the discovered model, discrepan-
cies between both can be detected and used to improve the process. figure 5shows the basic idea of delta analysis: two process models are compared, i.e., dif-
ferences between the discovered process model and the descriptive/prescriptive
process model are analyzed.
information
systemoperational
process
prescriptive/
descriptive
process
modelsevent
logsmodels
process
miningrecords
configures
delta
analysissupports/
controls
discovered
process
models
fig. 5. delta analysis as a means to analyze business alignment.
before discussing techniques for delta analysis, we ﬁrst illustrate the ex-
istence of descriptive/prescriptive process model in real-life situations. increas-
ingly, health-care workers are using medical protocols, also named medical guide-lines (to emphasize support) or pathways (to emphasize prediction), are used to
treat patients [8, 9]. this is reﬂected by the abundance of languages for describing
medical protocols, e.g., asbru, eon, glif, guide, prodigy and proforma[10–13]. these languages are comparable to typical process modeling languages
in the business domain. there are two ways medical protocols are used: (1)
actively and (2) passively. if medical protocols are used actively, the medicalinformation systems is either trying to control the careﬂow or to automatically
suggest pathways. if medical protocols are used only passively, the health-care
worker can consult them (i.e., the information system is not taking the initia-
11tive). both the active and passive use of medical protocols entails process models
(e.g., ﬂowcharts) that are of a prescriptive nature. clearly, health-care workercan (and should!) deviate from the protocol when needed. nevertheless, it is
interesting to know how well the protocol “ﬁts”. workﬂow models in workﬂow
management systems are also prescriptive and even enforce parts of the processto be executed in a certain way. note that even in processes “controlled” by a
workﬂow system, workers typically still have quite some operational freedom,
i.e., the system cannot force workers to execute tasks. for example, the orderof execution and the exact work distribution are decided by the users. the cur-
rent trend in workﬂow management is to develop systems that allow for even
more ﬂexibility (cf. case handling systems such as flower [14]). this suggeststhat it is increasingly more interesting to compare predeﬁned process models
with “discovered” models. in this context it is also interesting to consider the
so-called reference models of sap [15]. these reference models can be used both
in a descriptive and prescriptive manner. in the context of sap reference models
are typically expressed in terms of event-driven process chains (epc). such anepc can be used to describe how the sap system should be used. however, in
practice people may use the system diﬀerently or only use a subset of the system.
consider for example the two epcs shown in figure 6. the left epc representsthe full process, the right epc shows the parts that are actually being used.
note that tools like the sap reverse business engineer (rbe) can be used to
monitor how frequent parts of the sap system are being used. unfortunately,tools like rbe do not consider the order of activities nor other aspects such as
the organizational and case perspective.
figure 6 illustrates the goal of delta analysis: using process mining techniques
we want to compare the discovered model (i.e., the real process) with some pre-
deﬁned process. for clariﬁcation, we also show a smaller example expressed in
terms of a petri net. figure 7(a) shows an example of an order handling processmodeled in terms of a so-called workﬂow net [17]. workﬂow nets form a subclass
of the classical petri-nets. the squares are the active parts of the model and
correspond to tasks. the circles are the passive parts of the model and are usedto represent states. in the classical petri net, the squares are named transitions
and the circles places. a workﬂow net models the life-cycle of one case. examples
of cases are insurance claims, tax declarations, and traﬃc violations. cases are
represented by tokens and in this case the token in startcorresponds to an order.
task register is a so-called and-split and is enabled in the state shown. the ar-
row indicates that this task requires human intervention. if a person executes this
task, the token is removed from place startand two tokens are produced: one for
c1and one for c2. then, in parallel, two tasks are enabled: check
availability and
send bill. depending on the eagerness of the workers executing these two tasks
either check available orsend billis executed ﬁrst. suppose check availability is
executed ﬁrst. if the ordered goods are available, they can be shipped by exe-cuting task ship
goods. if they are not available, either a replenishment order is
issued or not. note that check availability is an or-split and produces one token
forc3,c4,o rc5. suppose that not all ordered goods are available, but the appro-
12 
conditions 
processing (purchasing
) specify address of 
customer 
address is 
specified 
interest calculation 
is specifie
d 
plant 
processing maintain 
accounting information sold - to party to be 
created 
customer is also 
vendor 
planning group 
is specifie
d 
customer - material -
info processing [standard] maintain account 
control 
maintain sales 
data ship - to party to be 
created 
trading p artner is 
specifie
d 
clearing 
between customer/vendor 
specified for automatic 
payments 
basic data processing 
for legal controls 
[standard] management of 
physical sample
s payer to be created 
specify company 
code 
company code 
is specifie
d 
bank details 
are specifie
d 
possible 
payment methods are 
specified 
customer volume rebate 
agreement 
processing [normal] customer master record 
is to be created 
specify payment 
transaction data 
manual sample 
release determine customer 
function 
invoice recipient is to 
be crea ted 
account group 
with internal 
number assignment 
determined 
define customer number 
customer number is 
determined 
payment card data is 
maintaine
d 
sales area data are 
maintaine
d 
maintain 
payment information 
alternative 
payer specific to 
company code 
specified 
create customer 
customer master record 
is created 
material 
listing/exclusion [standard] sales personnel 
is processe
d 
specify account 
group 
maintain control 
data sample receiver to 
be created 
account group 
with external number 
assignment 
dete rmined 
alternative payer for 
customer 
specified 
line item settlement is 
specifie
d 
product allocation 
[standard] specify alternative 
payer 
maintain 
messages 
decentralized 
processing required customer to be created 
for statistical purposes 
alternative payer for 
item 
allowed 
payment block 
is specifie
d 
basic data processing 
for legal controls 
[standard] maintain partner 
functions 
check if 
decentralized handling is 
desired customer is assortment 
customer 
maintain marketing 
data 
marketing data are 
maintaine
d 
dunning procedure 
is specifie
d 
sales deal 
processing [standard] decentralized 
processing not required 
maintain dunning 
data customer is one - time 
customer 
determine foreign trade 
data 
foreign trade data 
determined 
dunning block 
is specifie
d 
customer hierarchy 
processing [standard] create unloading 
point 
maintai
n correspondenc
e 
correspondence 
is maintaine
d 
sales summary 
processing [standard] create receiving 
point 
receiving point has 
been created 
assign receiving poi nt 
to an unloading 
point 
customer unloading 
pnts have been 
maintained 
maintain 
credit management data 
credit management data 
determined 
batch search strategy 
processing [standard] create department 
department has been 
created 
assign department to a 
receiving 
point 
classification 
[classification system] [standard] maintain contact 
persons 
contact person data are 
maintaine
d plant 
processing sales 
personnel master processing 
(tacit) depends 
on familiarity with 
customers and interaction with 
customers pa yment card 
setup 
conditions 
processing (purchasing
) specify address of 
customer 
address is 
specified 
interest calculation 
is specifie
d 
plant 
processing maintain 
accounting information sold - to party to be 
created 
customer is also 
vendor 
planning group 
is specifie
d 
customer - material -
info processing [standard] maintain account 
control 
maintain sales 
data ship - to party to be 
created 
trading partner is 
specifie
d 
clearing 
between customer/vendor 
specified for automatic 
payments 
basic data processing 
for legal c ontrols 
[standard] management of 
physical sample
s payer to be created 
specify company 
code 
company code 
is specifie
d 
bank details 
are specifie
d 
possible 
payment methods are 
specified 
customer volume rebate 
agreement 
processing [normal] customer master record 
is to be created 
specify payment 
transaction data 
manual sample 
release determine customer 
function 
invoice recipient is to 
be created 
account group 
with internal 
number assignment 
determined 
define customer number 
customer number is 
determined 
payment card data is 
maintaine
d 
sales area data are 
maintaine
d 
maintain 
payment information 
alternative 
payer specific to 
company code 
specified 
create customer 
customer master record 
is created 
material 
listing/exclusion [standard] sales personnel 
is processe
d 
specify account 
group 
maintain control 
data sample receiver to 
be created 
account group 
with external number 
assignment 
determined 
alternative payer for 
customer 
specified 
line item settlement is 
specifie
d 
product allocation 
[standard] specify alternative 
payer 
maintain 
messages 
decentralized 
processing required customer to be created 
for statistical purposes 
alternative payer for 
item 
allowed 
payment block 
is specifie
d 
basic data processing 
for legal contro ls 
[standard] maintain partner 
functions 
check if 
decentralized handling is 
desired customer is assortment 
customer 
maintain marketing 
data 
marketing data are 
maintaine
d 
dunning procedure 
is specifie
d 
sales deal 
processing [standard] decentralized 
processing not required 
maintain dunning 
data customer is one - time 
customer 
determine foreign trade 
data 
foreign trade data 
determined 
dunning block 
is specifie
d 
customer hierarchy 
processing [standard] create unloading 
point 
maintai
n correspondenc
e 
correspondence 
is maintaine
d 
sales summary 
processing [standard] create receiving 
point 
receiving point has 
been created 
assign receiving point 
to an unloading 
point 
customer unloading 
pnts have been 
maintained 
maintain 
credit management data 
credit management data 
determined 
batch search strategy 
processing [standard] create department 
department has been 
created 
assign department to a 
receiving 
point 
classification 
[classification system] [standard] maintain contact 
persons 
co ntact person data are 
maintaine
d plant 
processing sales 
personnel master processing 
fig. 6. two epcs: the full epc (left) and epc really being used (right) [16].
priate replenishment orders were already issued. a token is produced for c3and
task update becomes enabled. suppose that at this point in time task send bill
is executed, resulting in the state with a token in c3and c6. the token in c6is
input for two tasks. however, only one of these tasks can be executed and in this
state only receive payment is enabled. task receive payment can be executed the
moment the payment is received. task reminder is an and-join/and-split and
is blocked until the bill is sent and the goods have been shipped. note that the
reminder is sent only after a speciﬁed period. however, it is only possible to send
a reminder if the goods have been actually shipped. assume that in the state
with a token in c3and c6task update is executed. this task does not require hu-
man involvement and is triggered by a message of the warehouse indicating thatrelevant goods have arrived. again check
availability is enabled. suppose that
this task is executed and the result is positive. in the resulting state ship goods
can be executed. now there is a token in c6and c7thus enabling task reminder .
executing task reminder again enables the task send bill. a new copy of the
bill is sent with the appropriate text. it is possible to send several reminders by
alternating reminder and send bill. however, let us assume that after the ﬁrst
loop the customer pays resulting in a state with a token in c7and c8. in this
state, the and-join archive is enabled and executing this task results in the ﬁnal
state with a token in end.
13t1t1t5t6
t7
t9t11t8
t10t12
start register
send_billreceive_paymentarchiveship_goodscheck_availability
replenishupdate
reminderendc1
c2c3
c4
c5
c6c7
c8t4t3
t2
c0out_of_stock_no_repl
out_of_stock_repl
in_stock
(a) prescriptive/descriptive process model
t1t1t5t6
t7
t9t11t8
t12
start register
send_billreceive_paymentarchiveship_goodscheck_availability
replenishupdate
endc1
c2c3
c4
c5
c6c7
c8t4 t2
c0out_of_stock_repl
in_stock
(b) discovered process modelc9
fig. 7. comparing the discovered order processing model with the predeﬁned process
model.
14suppose that figure 7(a) represents the process as it is perceived by man-
agement. to see whether this model ﬁts reality, we can apply process mining ona log with events such as in table 1. using tools such as emit or prom we can
discover the workﬂow net shown in figure 7(b). we do not list the complete log
that would lead to this model. instead we just show a fragment, cf. table 2.
case id activity id originator timestamp
case 1 register pete 14-3-2004:14.33
case 2 register carol 14-3-2004:15.22
case 3 register chris 14-3-2004:16.43
case 3 send bill michael 15-3-2004:16.17
case 1 receive payment jorge 15-3-2004:18.05
case 1 check availability pete 16-3-2004:9.43
case 2 send bill mike 16-3-2004:10.24
case 4 register sue 16-3-2004:10.35
... ... ... ...
table 2. a fragment of the event log used to discover figure 7(b).
when comparing figure 7(a) and figure 7(b) it is easy to see that there
are four basic diﬀerences: (1) in the discovered process an out-of-stock situation
always results in a replenishment order, (2) in the discovered process the sending
of the bill and receiving the payment are in parallel (i.e., sometimes customersapparently pay before receiving the bill) , (3) in the discovered process it is not
possible to send multiple bills, and (4) in the discovered process it is possible to
send the bill before shipping to goods. each of these diﬀerences provides inter-esting insights in discrepancies between the real process as it has been observed
and the process model assumed by management. if the information system is
conﬁgured based on figure 7(a) and people really work as suggested by fig-
ure 7(b), there is a misalignment. these problems can be addressed by either
updating the prescriptive/descriptive model based on the discovered model ormotivating people to stick to the original prescriptive/descriptive model.
for large processes it may be diﬃcult to compare the prescriptive/descriptive
model and the discovered model. there are many ways to highlight diﬀerences
between two models in a graphical fashion. however, most of such approacheswill consider simple “node mapping techniques” rather than compare diﬀerences
inbehavior , i.e., the focus is on syntactical diﬀerences rather than semantical dif-
ferences. from a theoretical point of view there are at least two approaches thatalso incorporate behavior. the ﬁrst approach is to use inheritance of behavior
[18, 19]. the second approach is to calculate change regions [20, 21].
inheritance is a well-know concept from object-orientation but typically not
well-understood for processes. based on the inheritance notions deﬁned in [19]
we have developed the notion of the greatest common divisor (gcd) and least
common multiple (lcm) of two or more processes [18]. the inheritance relations
15deﬁned in [19] yield a partial order that can be used to reason about a common
super- or subclass of the two models (i.e., predeﬁned and discovered processes).the gcd is the common superclass which preserves as much information about
the behavior of the petri nets as possible, i.e., it is not possible to construct
a more detailed petri net which is also a superclass of both models. the gcddescribes the behavior all variants agree on. the lcm is the most compact petri
net which is still a subclass of all variants. if we apply these notions to the two
models shown in figure 7 we can get the gcd and lcm of the predeﬁned anddiscovered processes. for example, the gcd would only show the activities both
processes agree on.
the change region is determined by comparing the two process models and
extending the regions that have changed directly by the parts of the process that
are also aﬀected by the change of going from one process to the other, i.e., thesyntactical aﬀected parts of the processes are extended with the semantically af-
fected parts of the processes to yield change regions. due to the possibly complex
mixture of diﬀerent routing constructs (choice, synchronization, iteration, etc.),it is far from trivial to compute the actual change regions as is shown in [20, 21].
if we apply these notions to the two models shown in figure 7, we can highlight
the parts of the processes aﬀected by the diﬀerences between the predeﬁned anddiscovered models.
5 conformance testing
in the previous section, we presented an approach (delta analysis) that requiresa predeﬁned model and a discovered model (i.e., delta analysis). this approachhas two drawbacks. first of all, there may not be enough events to actually
discover the process model.
3
as a result, the discovered model may be ﬂawed or not representative. second,
delta analysis does not provide quantitative measures for the “ﬁt” between the
prescriptive/descriptive model and the log. therefore, we propose an alternativeapproach in addition to delta analysis: conformance testing .
figure 8 shows the basic idea of conformance testing: the event log is directly
compared with the predeﬁned process model. this can easily be done. compare
for example case 1 in table 2. this case starts with step register ( t1), followed by
receive payment ( t11). this part of the case ﬁts the discovered model figure 7(b)
but not the original model figure 7(a) because t11is not enabled after ﬁring t1.
given a complete case, represented as a sequence of activities (i.e., transitions
names in petri-net terms), it is possible to indicate whether a case ﬁts or not.consider for example figure 2 and assume that the and-split and and-join are
visible in the log. assume these are recorded as sand j. the case aed ﬁts. so
3an interesting question is now many events are required to correctly discover the
process model. there is not a simple answer to that a-priori. however, there aresimple techniques to assess the completeness of the result, e.g., k-fold cross validation
which splits the event log into k parts and for each part it is veriﬁed whether adding
it changes the result.
16information
systemoperational
process
process
modelsevent
logsmodels
conformance
testingrecords
configuressupports/
controls
fig. 8. conformance testing as a means to quantify business alignment.
do the cases asbcjd andascbjd . however, the case abd clearly does not
ﬁt. in other words the log consisting of only cases of the form aed,asbcjd
andascbjd conforms to the model while any log containing a case of the
formabd will not. in the remainder of this section we will further elaborate
on the notion of conformance and introduce some metrics.
consider figure 9 where some predeﬁned model and four logs are given. in
the four logs we removed timestamps, performer, etc. and grouped the events in
one sequence per case. event log l1shows ﬁve cases. for the ﬁrst case ( case 1 )
four events are logged: a,g,f,a n d i. clearly this sequence of events is possible
in figure 9(a), i.e., case 1 seems to ﬁt. the same holds for the other four cases
in log l1. this can be checked by playing the “token game” in the petri net
shown figure 9(a). each case in log l1corresponds to a possible ﬁring sequence
of the petri net with one initial token in the source place. similarly, each case in
event log l2corresponds to a possible ﬁring sequence of figure 9(a). however,
it is striking to see that only events corresponding to the lower part of the petri
net appear in the log. now consider event log l3shown figure 9(d). this log
does not seem to ﬁt. for example, case 1 does not correspond to a possible
ﬁring sequence because after executing aand f, place p8is still unmarked and
icannot be executed according to the model. it seems that an event involving
gis missing. also case 4 in event log l3seems to suﬀer from this problem.
also event log l4shown figure 9(e) does not ﬁt completely, i.e., eseems to be
impossible in ﬁrst two cases of this log.
figure 9 illustrates that there are two issues when checking the conformance
of a predeﬁned process model based on an actual event log. the ﬁrst problem isunderﬁtting , i.e., the log contains behavior not possible in the predeﬁned model.
event logs l3and case 4 suﬀer from underﬁtting because in each log two cases
do not “ﬁt”. the second problem is overﬁtting , i.e., the log contains behavior
17abd
eh
i
f
(a) some descriptive/prescriptive process model.
(b) event log l1.gc
p1p2p3
p4p5
p6
startp7
p8end
case 1: agfi
case 2: afgicase 3: agbcehicase 4: abedghicase 5: abdgehi
(c) event log l2.case 1: afi
case 2: afgicase 3: agbcehicase 4: abedhicase 5: abdgehi
(d) event log l3.case 1: agefi
case 2: afegicase 3: agbcehicase 4: abedghicase 5: abdgehi
(e) event log l4.case 1: afgi
case 2: afgicase 3: agficase 4: afgicase 5: agfi
fig. 9. a predeﬁned process model and some event logs used to illustrate conformance
testing.
18possible in the predeﬁned model but parts of the process model are not addressed
by the log.4event log l2seems to indicate overﬁtting, i.e., the upper half of the
process model is not used according to the log. given a ﬁxed set of activities x
it is easy to construct a petri net that ﬁts all logs, simply construct the petri net
with one place pand one transition per activity. then connect each transition
with this psuch that pis both and input and output place. the resulting net
ﬁts on any log with just activities of x. therefore, the predicative value of the
resulting petri net is negligible.
clearly both underﬁtting and overﬁtting are highly relevant. however, it is
diﬃcult to quantify overﬁtting. for example, certain paths in the process model
may only be used for speciﬁc classes of cases (e.g., rush orders) or during speciﬁc
periods (e.g., during the peak season). the fact that these are not used in some
log does not indicate that the process model is necessarily incorrect. however,
underﬁtting can easily be detected as shown by event logs l3and l4. therefore,
we only consider underﬁtting in the context of conformance testing.
to conclude this section, we consider some metrics for conformance testing.
all metrics presented are based on measuring the degree of underﬁtting. let p
be a process model and la log. a case cinlcan be successfully parsed if and
only if ccorresponds to a ﬁring sequence of pand after executing this sequence
only the sink place is marked (i.e., one token in place end).
the ﬁrst metric ﬁt1(p,l) simply counts the number of cases in lthat can
be parsed by pdivided by the number of cases. for example, ﬁt1(p,l1) = 1
while ﬁt1(p,l3) = 0.6 (only three of the ﬁve cases can be parsed). this metric
does not take into account the number of events. for large process models this
may be too simplistic, i.e., the metric does not distinguish between cases that
are close to the model and cases that are completely unrelated. fortunately, it
is also possible to simply count the number of events that can be executed. thiscan be done using blocking or non-blocking semantics. if we assume blocking
semantics, the parsing of the case stops after the ﬁrst problem is detected. if
we use non-blocking semantics, even disabled transitions are ﬁred so that theparsing of the case can continue. consider for example, case 1 in event log l4.
if we use blocking semantics, the parsing stops after executing gbecause eis
not enabled in the petri net, i.e., only two of the ﬁve events can be parsed. if weuse blocking semantics, the parsing does not stop after executing gand four of
the ﬁve events can be parsed (all except e). the second metric ﬁt2(p,l) uses
blocking semantics to simply count the number of events in lthat can be parsed
bypdivided by the total number of events in the log. again ﬁt2(p,l1) = 1 , but
ﬁt2(p,l3) = 25/27 = 0.93 and ﬁt2(p,l3) = 25/31 = 0.81 . the third metric
ﬁt3(p,l) uses non-blocking semantics to count the faction of events in lthat
can be parsed by p.n o w
ﬁt3(p,l3) = 25/27 = 0.93 and ﬁt3(p,l3) = 27/31
=0 . 8 7 . clearly, ﬁt3(p,l) is a better metric than ﬁt2(p,l) because the blocking
4the term “overﬁtting” may seem incorrect in this context because we are not really
constructing a model. however, in this section we use it as an antonym for the
term “underﬁtting”, i.e., the model allows for more behavior than the behavior that
actually occurs in real-life.
19semantics is very sensitive for the position of the anomaly in the case, i.e., “early
problems” outweigh “late problems”. note that for ﬁt2(p,l) and ﬁt3(p,l) we
did not specify penalties for tokens remaining in the net after parsing the case.
it is possible to deﬁne alternative metrics to also take this into account. table 3
summarizes the results for the three metrics.
event log ﬁt1(p,l) ﬁt2(p,l) ﬁt3(p,l)
l1 1.00 1.00 1.00
l2 1.00 1.00 1.00
l3 0.60 0.93 0.93
l4 0.60 0.81 0.87
table 3. measuring conformance using three metrics based on underﬁtting.
abd
eh
i
f
gc
p1p2p3
p4p5
p6
startp7
p8endcase 1: afi
case 2: afgicase 3: agbcehicase 4: abedhicase 5: abdgehi
2
+2 -2
fig. 10. some diagnostics showing the mismatch between figure 9(a) and event log
l3.
by trying to parse cases using the predeﬁned model it is also possible to
give diagnostics that may help to locate the source of the misalignment. for this
purpose, we use the non-blocking semantics. while parsing the log it is possible
to count how many times an activity should have been executed according tothe log but could not be executed according to the predeﬁned model. figure 10
shows that for event log l4activity idid not ﬁt twice. (note the “2” next to
activity i.) this was caused by the fact that in there was a token missing in place
p8. this is indicated by the “-2” next to place p8. for two cases a token was
missing in place p8because activity gdid not occur after executing the initial
activity a. therefore, there were two cases where a token was left in place p1.
this is indicated by the “+2” next to place p1. similar diagnostics are shown for
event log l4in figure 11. here activity ecould not be parsed for the ﬁrst two
cases. in both cases a token was missing in place p4(see “-2”) and because of the
20non-blocking semantics two tokens remained in place p6(see “+2”). figures 10
and 11 show that we can pinpoint the parts of the process where there appearsto be a misalignment.
abd
eh
i
f
gc
p1p2p3
p4p5
p6
startp7
p8endcase 1: agefi
case 2: afegicase 3: agbcehicase 4: abedghicase 5: abdgehi
2-2 +2
fig. 11. some diagnostics showing the mismatch between figure 9(a) and event log
l4.
in this section, we demonstrated that conformance testing (i.e., comparing
the log with some predeﬁned process model) can be used to measure the ﬁtness
of the model based on a log. moreover, the same mechanisms can be used to
locate the misalignment.
6 related work
this paper extends our bpmds 2004 workshop paper (cf. [4]) in several ways.for example, the current version includes concrete techniques for delta analysisand conformance testing. (in fact, in [4] conformance testing is not considered.)
recently many authors focused on business alignment [3]. an example is [22]
where the author examines the techniques that eight organizations have used toboth monitor and improve the alignment and performance of their is functions.
the idea of process mining is not new [23, 1, 6, 24–30] and has been mainly
aiming at the control-ﬂow perspective. for more information on process miningwe refer to a special issue of computers in industry on process mining [2] and a
survey paper [1]. in this paper, it is impossible to do justice to the work done in
this area. however, we would like to highlight [31] where cook and wolf providea measure to quantify discrepancies between a process model and the actual
behavior as registered using event-based data.
the work in [23, 1, 6, 24–30] is primarily focusing on the process perspective.
however, there are clear links with sociometry, and social network analysis
(sna) in particular. since the early work of moreno [32] sna has been an ac-
tive research domain. there is a vast amount of textbooks, research papers, and
21tools available in this domain [33–38, 32, 39–41]. there have been many stud-
ies analyzing workﬂow processes based on insights from social network analysis.however, these studies typically have an ad-hoc character and sociograms are
typically constructed based on questionnaires rather than using a structured and
automated approach as described in this paper. most tools in the sna domaintake sociograms as input. mison and prom are only some of the few tools that
generate sociograms as output. the only comparable tools are tools to analyze
e-mail traﬃc, cf. buddygraph (http://www.buddygraph.com/) and metasight(http://www.metasight.co.uk/). however, these tools monitor unstructured mes-
sages and cannot distinguish between diﬀerent activities (e.g., work-related in-
teraction versus social interaction).
for delta analysis one needs to compare processes. this is not as trivial as
is may seem. judging by the vast number of equivalence notions [42] researchers
do not even agree on the equivalence of processes. one of the ways to establishrelations between processes is through notions of “process inheritance” [19]. by
using such notions it is possible to calculate what two processes have in common
[18]. in [43] there is a more elaborate discussion on delta analysis based onnotions of inheritance.
finally, we would like to point out that the notion of conformance is related
to security as is discussed in [44].
7 conclusion
this paper discussed the application of process mining to business alignment.
for this purpose two fundamental assumptions are made. first, we assume that
events are actually logged by some information system. note that this assump-
tion is valid in some, but deﬁnitely not all, situations. however, the current focuson “corporate governance” and governmental regulations such as sarbanes-
oxley act trigger the development of it systems that log events. also new tech-
nologies such as rfid, bluetooth, wlan, etc. and the omnipresence of smallcomputing devices (e.g., mobile phones and pdas) enable ubiquitous and/or mo-
bile systems that can be used to record human behavior and business processes
in detail. the second fundamental assumption is that people are not completely“controlled” by the system, i.e., process mining does not give any insight if all de-
cisions are made by the system and users cannot deviate from the default path.
although the degree of freedom is limited by some systems (e.g., traditionalproduction workﬂow systems) the trend is towards more ﬂexible systems.
if we assume that events are logged and that users are able to deviate from
the default path, then process mining techniques can be used to investigate thealignment of the process models driving the information system and the actual
business process. we discussed two approaches: delta analysis and conformance
testing. delta analysis can be used to compare the prescriptive/descriptive modeland the discovered model. conformance testing can be used to quantify the ﬁt
between the prescriptive/descriptive model and the actual events. moreover, we
demonstrated that conformance testing can be used to locate the misalignment.
22a clear limitation of the approach presented in this paper is that we need to
assume that events are actually logged by some information system. this waymisalignment may be hidden (e.g., manual or unrecorded activities). therefore,
an interesting approach could be to combine the quantitative process log data
with qualitative data gathered from other sources (e.g., interviews and ques-tionnaires). this combination can help to understand potential problems more
eﬀectively. further research is needed to clarify this.
acknowledgements
the author would like to thank ton weijters, boudewijn van dongen, ana
karla alves de medeiros, minseok song, laura maruster, eric verbeek, moniquejansen-vullers, hajo reijers, michael rosemann, anne rozinat and peter van
den brand for their on-going work on process mining techniques. parts of this
paper have been based on earlier papers with these researchers.
references
1. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
2. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining ,s p e c i a l
issue of computers in industry, volume 53, number 3. elsevier science publishers,
amsterdam, 2004.
3. i. bider, g. regev, and p. soﬀer, editors. proceedings of the 5th workshop on
business process modeling, development and support (bpmds’04) ,v o l u m e2o f
caise’04 workshops . riga technical university, latvia, 2004.
4. w.m.p. van der aalst. business alignment: using process mining as a tool for
delta analysis. in j. grundspenkis and m. kirikova, editors, proceedings of the 5th
workshop on business process modeling, development and support (bpmds’04) ,
volume 2 of caise’04 workshops , pages 138–145. riga technical university, latvia,
2004.
5. j. desel, w. reisig, and g. rozenberg, editors. lectures on concurrency and petri
nets, volume 3098 of lecture notes in computer science . springer-verlag, berlin,
2004.
6. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128–1142, 2004.
7. l. maruster. a machine learning approach to understand business processes .
phd thesis, eindhoven university of technology, eindhoven, the netherlands,
2003.
8. j. bemmel and m.a. musen. handbook of medical informatics . springer-verlag,
1997.
9. e. coiera. guide to health informatics . arnold publishers, 2003.
1 0 . m .p e l e g ,,s .t u ,j .b u r y ,p .c i c c a r e s e ,j .f o x ,r . a .g r e e n e s ,r .h a l l ,p . d .j o h n s o n ,
n. jones, a. kumar, silvia miksch, s. quaglini, a. seyfang, e.h. shortliﬀe, andm. stefanelli. comparing computer-interpretable guideline models: a case-study
approach. journal of the american medical informatics association , 10(1):52–68,
2003.
2311. j. fox, n. johns, and a. rahmanzadeh. disseminating medical knowledge: the
proforma approach. artiﬁcial intelligence in medicine , 14(1):157–182, 1998.
12. s. quaglini, m. stefanelli, g. lanzola, v. caporusso, and s. panzarasa. flexi-
ble guideline-based patient careﬂow systems. artiﬁcial intelligence in medicine ,
22(1):65–80, 2001.
13. p.a. de clerq, j.a. blom, h.h. korsten, and a. hasman. approaches for creat-
ing computer-interpretable guidelines that facilitate decision support. artiﬁcial
intelligence in medicine , 31(1):1–27, 2004.
14. pallas athena. flower user manual . pallas athena bv, apeldoorn, the nether-
lands, 2002.
15. g. keller and t. teufel. sap r/3 process oriented implementation . addison-
wesley, reading ma, 1998.
16. m. rosemann and w.m.p. van der aalst. a conﬁgurable reference modelling lan-
guage. qut technical report, fit-tr-2003-05, queensland university of tech-
nology, brisbane, 2003.
17. w.m.p. van der aalst. the application of petri nets to workﬂow management.
the journal of circuits, systems and computers , 8(1):21–66, 1998.
18. w.m.p. van der aalst and t. basten. identifying commonalities and diﬀerences
in object life cycles using behavioral inheritance. in j.m. colom and m. koutny,
editors, application and theory of petri nets 2001 , volume 2075 of lecture notes
in computer science , pages 32–52. springer-verlag, berlin, 2001.
19. t. basten and w.m.p. van der aalst. inheritance of behavior. journal of logic
and algebraic programming , 47(2):47–145, 2001.
20. w.m.p. van der aalst. exterminating the dynamic change bug: a concrete
approach to support workﬂow change. information systems frontiers , 3(3):297–
317, 2001.
21. c.a. ellis, k. keddara, and g. rozenberg. dynamic change within workﬂow
systems. in n. comstock, c. ellis, r. kling, j. mylopoulos, and s. kaplan, editors,proceedings of the conference on organizational computing systems , pages 10 –
21, milpitas, california, august 1995. acm sigois, acm press, new york.
22. y.e. chan. why haven’t we mastered alignment?: the importance of the informal
organization structure. mis quarterly executive , 1(2):95–110, 2002.
23. w.m.p. van der aalst and b.f. van dongen. discovering workﬂow performance
models from timed logs. in y. han, s. tai, and d. wikarski, editors, international
conference on engineering and deployment of cooperative information systems
(edcis 2002) , volume 2480 of lecture notes in computer science , pages 45–63.
springer-verlag, berlin, 2002.
24. r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
ﬂow logs. in sixth international conference on extending database technology ,
pages 469–483, 1998.
25. j.e. cook and a.l. wolf. discovering models of software processes from event-
based data. acm transactions on software engineering and methodology ,
7(3):215–249, 1998.
26. j. herbst. a machine learning approach to workﬂow management. in proceedings
11th european conference on machine learning , volume 1810 of lecture notes in
computer science , pages 183–194. springer-verlag, berlin, 2000.
27. ids scheer. aris process performance manager (aris ppm): measure, ana-
lyze and optimize your business process performance (whitepaper). ids scheer,
saarbruecken, gemany, http://www.ids-scheer.com, 2002.
2428. m. zur m¨ uhlen and m. rosemann. workﬂow-based process monitoring and con-
trolling - technical and organizational issues. in r. sprague, editor, proceedings
of the 33rd hawaii international conference on system science (hicss-33) , pages
1–10. ieee computer society press, los alamitos, california, 2000.
29. m. sayal, f. casati, u. dayal, and m.c. shan. business process cockpit. in pro-
ceedings of 28th international conference on very large data bases (vldb’02) ,
pages 880–883. morgan kaufmann, 2002.
30. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models
from event-based data using little thumb. integrated computer-aided engi-
neering , 10(2):151–162, 2003.
31. j.e. cook and a.l. wolf. software process validation: quantitatively measuring
the correspondence of a process to a model. acm transactions on software
engineering and methodology , 8(2):147–176, 1999.
32. j.l. moreno. who shall survive? nervous and mental disease publishing com-
pany, washington, dc, 1934.
33. a.a. bavelas. a mathematical model for group structures. human organization ,
7:16–30, 1948.
34. h.r. bernard, p.d. killworth, c. mccarty, g.a. shelley, and s. robinson. com-
paring four diﬀerent methods for measuring personal social networks. social
networks , 12:179–216, 1990.
35. r.s. burt and m. minor. applied network analysis: a methodological introduction .
sage, newbury park ca, 1983.
36. m. feldman. electronic mail and weak ties in organizations. oﬃce: technology
and people , 3:83–101, 1987.
37. l.c. freeman. a set of measures of centrality based on betweenness. sociometry ,
40:35–41, 1977.
38. l.c. freeman. centrality in social networks: conceptual clariﬁcation. social
networks , 1:215–239, 1979.
39. h. nemati and c.d. barko. organizational data mining: leveraging enterprise
data resources for optimal performance . idea group publishing, hershey, pa,
usa, 2003.
40. j. scott. social network analysis . sage, newbury park ca, 1992.
41. s. wasserman and k. faust. social network analysis: methods and applications .
cambridge university press, cambridge, 1994.
42. r.j. van glabbeek and w.p. weijland. branching time and abstraction in bisim-
ulation semantics. journal of the acm , 43(3):555–600, 1996.
43. w.m.p. van der aalst. inheritance of business processes: a journey visiting four
notorious problems. in h. ehrig, w. reisig, g. rozenberg, and h. weber, editors,petri net technology for communication based systems , volume 2472 of lecture
notes in computer science , pages 383–408. springer-verlag, berlin, 2003.
44. w.m.p. van der aalst and a.k.a. de medeiros. process mining and security:
detecting anomalous process executions and checking process conformance. in
n. busi, r. gorrieri, and f. martinelli, editors, second international workshop
on security issues with petri nets and other computational models (wisp 2004) ,
pages 69–84. star, servizio tipograﬁco area della ricerca, cnr pisa, italy, 2004.
25