discovering simulation models
a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst
eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands
{a.rozinat,r.s.mans,m.s.song,w.m.p.v.d.aalst }@tue.nl
abstract. process mining is a tool to extract non-trivial and useful in-
formation from process execution logs. these so-called event logs (also
called audit trails, or transaction logs) are the starting point for various
discovery and analysis techniques that help to gain insight into certain
characteristics of the process. in this paper we use a combination of pro-
cess mining techniques to discover multiple perspectives (namely, the
control-ﬂow, data, performance, and resource perspective) of the process
from historic data, and we integrate them into a comprehensive simu-
lation model. this simulation model is represented as a coloured petri
net (cpn) and can be used to analyze the process, e.g., evaluate the
performance of di ﬀerent alternative designs. the discovery of simulation
models is explained using a running example. moreover, the approach
has been applied in two case studies; the workﬂows in two di ﬀerent mu-
nicipalities in the netherlands have been analyzed using a combination
of process mining and simulation. furthermore, the quality of the cpn
models generated for the running example and the two case studies has
been evaluated by comparing the original logs with the logs of the gen-
erated models.
1 introduction
computer simulation is a useful and versatile tool to gain insight into the op-
eration of systems. next to, e.g., natural systems also human systems can be
subject to simulation. generally, a model that represents certain key character-
istics or behaviors of the system is analyzed to show the eventual real e ﬀects of
alternative conditions and courses of action. the strength of simulation is that it
enables precisely this “what if” analysis, i.e., it allows to “look into the future”
under certain assumptions. in this paper, we focus on simulation models of oper-
ational processes. for example, in the context of a workﬂow management system
simulation can help to estimate the beneﬁt of an anticipated process redesign,
or to predict ﬂow times for an increasing number of incoming cases, a reduced
number of specialists for a certain task etc.
traditionally, such simulation models are created manually (cf. figure 1).
documentation, interviews and close observation help to get an understanding
of the real-world process of interest. this is a time-consuming activity, which
is likely to be error-prone as it is based on human perception of reality rather
than on reality itself. therefore, we propose to use process mining techniques to(semi-)automatically discover a simulation model based on information that was
recorded during process enactment. in this way, we can much quicker arrive at
a ﬁrst simulation model (to be further evaluated and potentially modiﬁed) than
with the traditional approach. in addition, it is likely to better represent reality
as it is based on objective information. note that good knowledge of the observed
operational process is inevitable for drawing conclusions from a simulation run
and, therefore, such a generated model does not make domain and modeling
expertise obsolete. however, no modeling e ﬀorts are needed to generate an initial
model. furthermore, this can be easily repeated in an iterative manner as soon
as the process changes.
explore process redesigns by simulating their effectssimulationmodeleventlogs
informationsystemreal-world processrecordssupports /controls
process miningmanual creationmodels
fig. 1. traditionally, simulation models are created manually. in this paper we aim at
the (semi-)automatic discovery of simulation models using process mining techniques
nowadays, many business processes are supported by information systems
that help coordinating the steps that need to be performed in the course of
the process. workﬂow systems, for example, assign work items to employees ac-
cording to their roles and the status of the process. typically, these systems
record events related to the activities that are performed, e.g., in audit trails
or transaction logs [3]. these event logs are the starting point for process min-
ing techniques, which, for example, construct a process model which reﬂects the
causal relations that have been observed among the activities. another example
is decision mining [32], which analyzes which properties (i.e., valuations of data
attributes) of a case might lead to taking certain paths in the process. in this pa-
per we use a combination of process mining techniques to discover and integrate
multiple perspectives of the process under consideration, namely control-ﬂow,
data, performance, and organizational perspective. in principle, further charac-
teristics can be incorporated (cf. figure 2). colored petri nets (cpns) [23] are
then used as a representation for the integrated model because of their expres-
siveness and the strong simulation capabilities of cpn tools [38].
2eventlogsimulationmodelcontrol-flow discoverymodel integrationdata dependenciesperformance characteristicsorganizational characteristics ...simulationsimulationresultsprocess mining (prom)simulation (cpn tools)
fig. 2. a combination of process mining techniques is used to discover and integrate
multiple perspectives of a process in a comprehensive simulation model
the applicability of the approach presented in this paper stands or falls with
the availability of suitable logs. fortunately, it can be observed that more and
more events are being logged in a wide variety of systems. obviously, information
systems such as workﬂow management systems (e.g. sta ﬀware), erp systems
(e.g. sap), case handling systems (e.g. flower), pdm systems (e.g. windchill),
crm systems (e.g. microsoft dynamics crm), middleware (e.g., ibm’s web-
sphere), hospital information systems (e.g., chipsoft), etc. provide very detailed
information about the activities that have been executed. moreover, one can also
ﬁnd logs in situations where the information system is not directly noticeable.
examples are medical systems (e.g., x-ray machines), mobile phones, car en-
tertainment systems, production systems (e.g., wafer steppers), copiers, sensor
networks, etc. software plays an increasingly important role in such systems and,
already today, many of these systems record events. an example is the “cus-
tomercare remote services network” of philips medical systems (pms).
this is a worldwide internet-based private network that links pms equipment
to remote service centers. an event that occurs within an x-ray machine (e.g.,
moving the table, setting the deﬂector, etc.) is recorded and analyzed. another
example is the event logging infrastructure developed by asml. asml man-
ufactures chip-making equipment such as wafer scanners. its products are also
connected to the internet. this connection is used to distribute the events logged.
already during the testing phase of a wafer scanner in the factory, thousands of
events are recorded via an internet connection. this can be used for improving
the service, improving the products, and for improving the test processes. the
logging capabilities of the machines of pms and asml illustrate the omnipres-
ence of event logs, making process mining a reality. moreover, it is an important
motivation for the work in this paper: why construct simulation models by hand
based on assumptions if there is so much real data around?
to directly support the generation of a simulation model from event logs we
have implemented a cpn tools 2.0 export plug-in (in the remainder of this paper
referred to as cpn export plug-in) in the context of the prom framework1, which
1both documentation and software (including the source code) of prom [1] can be
downloaded from www.processmining.org .
3oﬀers a wide range of tools related to process mining and process analysis. in [34]
we described the chosen cpn representation for business processes in detail, and
we presented the cpn export plug-in in prom. in this paper, we build on this
work and show how a comprehensive simulation model including characteristics
from the data, performance, and organizational perspective can be discovered
from an event log. furthermore, we evaluate how well the generated cpn model
approximates these process characteristics by generating event logs during the
simulation of the model in cpn tools, and the repeated analysis of this “second
pass”, i.e., the behavior of the simulation model is compared with reality.
the paper is organized as follows. first, we review related work in section 2.
then, section 3 introduces the notion of an event log and presents a simple
example process that is used throughout this paper. afterwards, process mining
techniques discovering di ﬀerent perspectives of a business process are described
in section 4. then, we show how these perspectives can be integrated and rep-
resented as a cpn in section 5. section 6 presents a set of plug-ins in the prom
framework that can be used to discover and integrate all these perspectives.
section 7 describes two case studies based on real-life log data. finally, we high-
light some of the challenges for future research in section 8, and the paper is
concluded by section 9.
2 related work
the work reported in this paper is related to earlier work on process mining,
i.e., discovering a process model based on some event log. the idea of applying
process mining in the context of workﬂow management was ﬁrst introduced by
agrawal et. al in [6]. a similar idea was used by datta in [13]. cook and wolf
have investigated similar issues in the context of software engineering processes
using di ﬀerent approaches [10, 9]. note that the results presented in [10, 9] are
limited to sequential behavior. cook and wolf extend their work to concurrent
processes in [11]. they propose speciﬁc metrics (such as entropy, event type
counts, and causality) and use these metrics to discover models out of event
streams. however, they do not provide an approach to generate explicit process
models. in [12] cook and wolf provide a measure to quantify discrepancies be-
tween a process model and the actual behavior as registered using event-based
data. herbst and karagiannis also address the issue of process mining in the
context of workﬂow management using an inductive approach [21]. they use
stochastic task graphs as an intermediate representation and generate a work-
ﬂow model described in the adonis modeling language. the αalgorithm [5,
39] was one of the ﬁrst algorithms to truly capture concurrency. in [5] it is shown
that this algorithm can be proven to be correct for a large class of processes.
over time many variants and extensions of the αalgorithm have been proposed.
in [39] a heuristic approach using rather simple metrics is used to construct
so-called “dependency/frequency tables” and “dependency/frequency graphs”.
this is used as input for the αalgorithm. as a result it is possible to tackle the
problem of noise. for more information on process mining we refer to a special
4issue of computers in industry on process mining [4] and a survey paper [3].
examples of more recent work are [7], [27], and [35]. in [7] the authors show how
to apply region based methods for the synthesis of petri nets from languages to
process mining. [27] and [35] speciﬁcally look at process discovery in the context
of services and software processes, respectively.
existing process mining approaches have been mainly focusing on the control-
ﬂow perspective. in this paper, we build on some initial work that has been done
for discovering social networks in the context of process mining [2] and decision
point analysis [32, 31]. the work reported in [32, 31] is closely related to [18],
where the authors describe the architecture of the business process intelligence
(bpi) tool suite on top of the hp process manager (hppm). whereas they out-
line the use of data mining techniques for process behavior analysis in a broader
scope, in [31] we show in detail how a decision point analysis can be carried out
also in the presence of duplicate and invisible activities. note that—while not an
issue in the context of hppm (as the node names of the corresponding workﬂow
model are logged as well)—dealing with duplicate activities is often needed for
real-life logs. similar to [18], in [8] the authors propose methods to monitor and
predict the behavior of a workﬂow instance in terms of pre-deﬁned metrics. the
work reported in [37] assumes the presence of a block-structured process model
with given input and output data for each node and aims at discovering the
earliest positions for decision points to avoid redundant activity executions and
decrease the uncertainty. we also would like to mention [19] and [16], where the
focus is on monitoring (also in the context of hppm) and exception handling,
respectively. in [25] decision trees are used to analyze sta ﬀassignment rules.
additional information about the organizational structure (i.e., a given organi-
zational model is assumed) is incorporated to derive higher-level attributes (i.e.,
roles) from the actual execution data (i.e., performers). however, all these tech-
niques do not provide an integrated view and do not aim at simulation. this
paper is mostly related to [34] where the cpn export of prom is described. how-
ever, the focus of [34] is not on process mining and no case studies are given.
according to our knowledge, the integration of various mining results to auto-
matically generate a complete simulation model including multiple perspectives
is a novel approach and has not been done before. furthermore, we focus on
the validation aspect as the quality of a simulation model (whether generated
or hand-made) is crucial for drawing conclusions from a simulation run. finally,
we highlight challenges that are faced when discovering simulation models from
event logs, and creating simulation models for business processes in general.
there is quite some work on the automatic generation of petri net models
for workﬂows. a typical example is described in [17] where the authors present a
translation of protos simulation models to cpn tools. in addition, three types
of data collector monitors (measuring the total ﬂow time per case, the waiting
time per task, and the resource availability/utilization per resource type), and
conﬁguration features enabling the dynamic elimination of unnecessary parts of
the process model are generated. besides the work in [17], we are not aware of
further attempts to export business process models to cpn tools. the work
5reported in this paper has a di ﬀerent starting point as it is not limited by the
simulation information present in a protos model, but aims at discovering the
process characteristics to be simulated from the event logs of real process exe-
cutions.
3 event logs
most information systems, e.g., wfm, erp, crm, scm, and b2b systems,
provide some kind of event log (also referred to as transaction log or audit trail)
[3]. it contains log entries about activities which were executed for a business
process that is supported by the information system. every event refers to a
case (i.e., process instance) and an activity, whereas activities in real business
scenarios are often logged at a more ﬁne-grained level than the atomic execution
of that activity—they record, for example, the scheduling , the start , and the
completion of an activity2. furthermore, most systems also register a time stamp,
a performer, and some additional data.
figure 3 depicts a part of an event log in mxml3format, which is used as
a running example in the remainder of this paper. the logged process reﬂects
the medical examination ﬂow in an outpatient clinic for gynecological oncology,
whereas each process instance describes the examination history of one particular
patient. note that this artiﬁcial example is based on a real-life outpatient clinic
process of the amc hospital in the netherlands. the example has been simpliﬁed
for illustration purposes.
in figure 3 we show the beginning of the ﬁrst patient’s history. note that
the event log starts with the start and completion of the “first visit” to the
gynecologist, and the start of a subsequent “x ray” examination of this pa-
tient. one can observe that for each of the audit trail entries (i.e., events) the
time stamp is recorded (a), and that the involved personnel from the outpatient
clinic is registered in the originator ﬁeld (b). furthermore, the complete event
of activity “first visit” captures the “asa”, which is a rating of anesthetic risk
ranging from 1 (low) to 5 (high), the “diagnosis”, and the “age” of the patient
in additional data attributes (c).
4 process mining from di ﬀerent perspectives
based on the example log introduced in the previous section, we will now apply
a number of process mining algorithms to gain insight into di ﬀerent perspectives
of the outpatient clinic process. the aim is to extract key characteristics that
can be used for the creation of a simulation model.
2the life cycle of an activity has been standardized by the mxml format for workﬂow
logs, which is used by the prom framework.
3both the corresponding schema deﬁnition and the prom import framework [20],
which converts logs from existing (commercial) process-aware information systems to
the mxml format used by prom, can be downloaded from www.processmining.org .
6fig. 3. log fragment in mxml format. the running example reﬂects the examination
ﬂow in an outpatient clinic and contains in total 1000 cases (i.e., patient histories)
figure 4 visualizes the dependencies between the used process mining tech-
niques. first, a control-ﬂow discovery algorithm is applied to automatically cre-
ate a process model that reﬂects the causal relations between the examination
activities in the log (section 4.1). second, a decision point analysis is performed
based on the process model and the event log to discover decision rules for the
choice points in the outpatient clinic process (section 4.2). third, a performance
analysis is carried out to enhance the process model with information about ex-
ecution times and waiting times for the activities, and probabilities for taking
alternative paths (section 4.3). fourth, a role discovery algorithm is applied to
the event log to group resources into roles, and to associate the discovered roles
with the activities in the process (section 4.4).
finally, in section 5, the mining results enhanced with data, performance,
and organizational characteristics are integrated in one comprehensive simu-
lation model. during the simulation of this model in cpn tools we generate
execution logs (similar to the original event log), and again apply the di ﬀer-
ent process mining algorithms to see whether we can rediscover the previously
discovered information in this “second pass”. note that this “second pass” is
mainly relevant for the evaluation of our approach. in real-life applications of
our approach, the simulation model is used to gain insights and to evaluate and
compare di ﬀerent redesigns, i.e., the focus is not on the quality of the discovered
simulation model. however, since such a “what if” analysis using simulation is
common practise, we will not elaborate on this and assume that the reader is
familiar with the role of simulation in business process analysis and redesign.
7eventlogsimulationmodelcontrol-flow discoverymodel integrationdecision pointanalysisperformance analysisrole discovery
processmodelmodel incl.probabilities and timemodel incl.data depen-denciesactivity setincl. rolessection 3 section 4
log generation and “second pass”
what if analysisutilizationservice levelflow time waiting time...fig. 4. overview about the process mining techniques used in this paper
4.1 control-ﬂow discovery
control-ﬂow discovery aims at the automatic extraction of a process model from
an event log, i.e., the inference of a structural representation of the underlying
process based on historic data.
typically, events in these logs are only expected to (i) refer to an activity
from the business process, (ii) refer to a case (i.e., process instance), and (iii) be
totally ordered [3, 4]. therefore, the event log from section 3 can be considered
as a set of event sequences as shown in figure 5(a)4.
based on this information, the α-algorithm [5] automatically constructs the
petri net model depicted in figure 5(b). a petri net is a dynamic structure that
consists of a set of transitions , which are indicated by boxes and relate to some
activity/task, or action that can be executed, a set of places , which are indicated
by circles and may hold one or more tokens (indicated as black dots), and a set
ofdirected arcs that connect these transitions and places with each other in a
bipartite manner. transitions are enabled as soon as all of their input places
(places connected to this transition via an incoming arc) contain a token. if a
transition is enabled, it may ﬁrewhereas it consumes a token from each of its
input places and produces a token for each of its output places (places connected
to this transition via an outgoing arc). in this way, the ﬁring of a transition may
change the marking of a net, and therefore the state of the process, which is
deﬁned by the distribution of tokens over the places.
4the letters a–ihave been introduced as a short-hand for the activity names in the
process.
8astartp0p1p6endfirst visitlabtest
x rayecg
ecg not neededsecond visitct
mrithird visitbcdep2p3fp4ghp5iabcdfgiacbdfgiabcefgiacbefgiabcdfhiacbdfhiabcefhiacbefhilog traces
(a) event log (b) discovered process modelfig. 5. control-ﬂow discovery of the outpatient clinic example. a process model re-
ﬂecting the dependencies among the activities in the process is automatically created
in a nutshell, the α-algorithm works by deriving log-based ordering relations
from the event log. based on these, it infers causal dependencies that can be
used to construct the petri net. for readers interested in further details we refer
to the original publication [5]. note that the α-algorithm is just one of the many
control-ﬂow discovery algorithms that have been developed over time (and other
algorithms might be used instead). it has been proven to be able to rediscover
a large class of workﬂow processes [5]. other algorithms have been developed to
address challenges such as noise [39] or duplicate tasks [14]. however, this is not
relevant for demonstrating the general idea of our simulation model generation
approach.
the discovered model in figure 5(b) visualizes the ﬂow of examinations in
the outpatient clinic. to be more precise, the ﬁgure shows the diagnostic pro-
cess for gynaecological oncology patients, in which a diagnosis is made for the
patient and further investigated through a number of examinations. as soon as
the diagnostic process is completed, the treatment phase can be started. the di-
agnostic process starts with the ﬁrst visit of the patient to the outpatient clinic.
during this “first visit”, a blood sample is taken from the patient, which is
tested afterwards in the lab. in parallel to the “lab test”, the patient undergoes
an “x ray” examination, i.e., “lab test” and “x ray” may occur in any order.
after completing the “lab test” and the “x ray”, the patient is sent to make an
appointment for an electrocardiogram, i.e., an “ecg”, if this is needed. after
all these examinations, the patient has a follow-up visit in the outpatient clinic.
during this “second visit”, the doctor decides whether either a magnetic reso-
nance imaging (“mri”) examination, or a computed tomography (“ct”) scan
needs to be made. after the “mri” or “ct”, the diagnostic process is ﬁnished
with a “third visit” of the patient to the outpatient clinic.
it is important to keep in mind that the model in figure 5(b) is constructed
fully automatically based on the log referred to in ﬁgures 3 and 5(a).
4.2 decision point analysis
now that we have discovered a process model reﬂecting the causal relations
between the activities in the outpatient clinic process, we want to gain more
9insight into the data perspective of that process. more precisely, we want to
discover data dependencies that inﬂuence the routing of a case. to analyze the
choices in a process we ﬁrst need to identify those parts of the model where the
process splits into alternative branches, also called decision points . based on data
attributes associated to the events in the log (cf. figure 3(c)), we subsequently
want to ﬁnd rules for following one route or the other [32].
in terms of a petri net, a decision point corresponds to a place with multiple
outgoing arcs. since a token can only be consumed by one of the transitions
connected to these arcs, alternative paths may be taken during the execution
of a process instance. the process model in figure 5(b) exhibits three such
decision points: p5(if there is a token, either gorhcan be performed), p2,
andp3(seen from the latter two places, either doremay be carried out).
the idea is to convert every decision point into a classiﬁcation problem [26, 29,
40], where the classes are the di ﬀerent decisions that can be made. as training
examples we use the process instances in the log (for which it is already known
which alternative path they followed with respect to the decision point). the
attributes to be analyzed are the case data attributes contained in the log, and
we assume that all attributes that have been written before the choice construct
under consideration are relevant for the routing of a case at that point5.
fig. 6. decision point represented as a classiﬁcation problem. data values associated
with process instances in the log are classiﬁed and used as training examples, based on
which a decision tree can be derived
to illustrate this, we show the classiﬁcation problem for decision point p2
in figure 6(a). the data attributes that are in the scope of this decision point
are “asa”, “diagnosis” and “age”, which are recorded during the ﬁrst visit of
the patient (cf. figure 3). each row contains the data values for one process
instance, i.e., figure 6(a) shows the data items associated to the ﬁrst six process
instances out of the 1000 cases in the event log. these rows correspond to the
training examples that will be provided as input to the classiﬁcation algorithm
later on.
5we also allow the user to set other scoping rules, e.g., only the data set in a directly
preceding activity, or all case data including the data that is set later.
10however, because there is no explicit information in the log about which de-
cision was made at a decision point for some process instance, we ﬁrst have to
infer this information from the log. starting from the identiﬁcation of a choice
in the process model (i.e., a decision point) a decision can be detected if the
execution of an activity in the respective alternative branch of the model has
been observed, which requires a mapping from that activity to its “occurrence
footprint” in the event log. so, if a process instance contains the given “foot-
print”, this means that there was a decision for the associated alternative path
in the process. for simplicity we examine the occurrence of the ﬁrst activity per
alternative branch to classify the possible decisions. this is su ﬃcient to ﬁll the
“class” column for our running example in figure 6(a) either with the decision
d(“ecg”) or with the decision e(“ecg not needed”). however, to success-
fully conduct decision mining for real-life business processes several challenges
posed by, for example, invisible activities ,duplicate activities , and loops need to
be addressed. we refer the interested reader to our technical report [31], where
these issues are discussed in detail.
after identifying a decision point in a business process and classifying the
decisions of all the process instances in the log, the next step is to determine
whether decisions might be inﬂuenced by case data, i.e., whether cases with
certain properties typically follow a speciﬁc route. to solve the formulated clas-
siﬁcation problem, various algorithms are available [26, 40]. we decided to use
an algorithm based on decision trees (the c4.5 algorithm [29] to be precise).
decision trees are a popular tool for inductive inference and the corresponding
algorithms have been extended in various ways to increase practical applicability.
for example, they are able to deal with continuous-valued attributes, missing at-
tribute values, and they include e ﬀective methods to avoid over-ﬁtting the data
(i.e., that the tree is too much tailored towards the particular training examples).
figure 6(b) depicts the decision tree that was derived for decision point p2
by the j48 algorithm (which is the c4.5 implementation in the weka machine
learning library [40]) with default parameters. note that decision tree algorithms
are able to select those attributes that have inﬂuence on the classiﬁcation (e.g.,
the data attribute “diagnosis” has been omitted in the resulting tree as it does
not a ﬀect the decision between dande). furthermore, they are able to auto-
matically ﬁnd split points in continuous-valued attributes such as the numeric
“age” attribute (i.e., to split at the point >60 and <= 60).
from a decision tree like the one shown in figure 6(b) we can now read o ﬀ
rules that can be related to the decisions in the process. this way, we can use
decision point analysis to extract knowledge about decision rules as shown in
figure 7. each of the three discovered decision points corresponds to one of the
choices in the running example. note that, because the choices taken at p2and
p3are dependent on each other, they yield the same rules. we can conclude that
the “ecg” is only needed for patients that are older than 60 years, or have an
asa greater than 2. furthermore, the “ct” is only required for patients with
the diagnosis “corpus carcinoma” or “ovarium carcinoma”, while an “mri” is
needed for patients with the diagnosis “vulva carcinoma” or “cervix carcinoma”.
11afirst visitlabtest
x rayecg
ecg not neededsecond visitct
mrithird visitbcdep2p3fghp5iagediagnosisasaif (age > 60) or (asa > 2) 
if (age <= 60) and (asa <= 2) if (diagnosis = corpus carcinoma) or (diagnosis = ovarium carcinoma) 
if (diagnosis = vulva carcinoma) or (diagnosis = cervix carcinoma) fig. 7. example model enhanced with the data perspective. decision rules for the
choice points in the process were derived based on data attributes provided during the
“first visit” of the patient
4.3 performance analysis
in the previous subsection we have discovered data-based rules for the decision
points in the process. now, we want to gain more insight into the performance
perspective of the process. more precisely, we want to enhance the process model
with information about execution times and waiting times for the activities.
the execution time is the time between the start and the completion of the
activity. the waiting time is the time between the point at which the last activity
that is a direct predecessor of this activity was completed and the moment at
which the execution of the activity itself is started. moreover, we also want to
enhance the process model with probabilities for taking alternative paths , and
with information about the case generation scheme . this scheme determines the
arrival process, e.g., how many new cases arrive per time unit (on average) at
the process.
extracting this information from the log is relatively easy because for each
‘start’ and ‘complete’ event in the event log the exact time stamp is given.
together with the discovered petri net we can replay6each process instance in
the petri net so that information about execution and waiting times is collected
for the activities in the process [22]. furthermore, for each decision point we can
derive the probabilities of alternative paths based on how often each path was
followed during log replay. finally, the arrival rate of cases can be easily derived
from the start times of the ﬁrst activity in each process instance.
during the replay of the log several statistics can be collected for the execu-
tion and waiting times, and for how many cases arrive at the process per time
unit. these statistics are values like minimum, maximum, mean, variance, etc.
6we assume that each process instance can be replayed correctly in the discovered
petri net (see [33] for further details). if, e.g. due to noise, not all instances ﬁt the
model, then the non-ﬁtting instances can easily be ignored.
12in general, we do not know the underlying distribution for the obtained execu-
tion and waiting times, and we assume that they follow a normal distribution.
however, we could easily have selected another distribution. similarly, we do
not know the “real” distribution of the case generation scheme, and we assume
a negative exponential distribution for the interarrival process (i.e., a so-called
poisson arrival process). to specify the execution and waiting times in terms
of a normal distribution, we need to calculate their mean and variance values
for each activity. the intensity parameter of the exponential distribution is ap-
proximated by the mean value of all measured inter-arrival times (i.e., the times
between the start of two new cases). all the values are measured in minutes.
afirst visitlabtest
x rayecg
ecg not neededsecond visitct
mrithird visitbcdefghi0.720.50.50.280.280.720.0167 new cases per minutew: n(0.0, 0.0)e: n(0.0, 0.0)w: n(7233.9, 468.0)e: n(60.4, 6.2)w: n(1450.8, 471.6)e: n(29.9, 5.1)w: n(4320.4, 486.1)e: n(45.1, 1.7)w: n(2894.5, 957.1)e: n(30.1, 5.2) w: n(0.008, 0.2)e: n(30.0, 5.1)w: n(30.1, 5.1)e: n(20.0, 1.6) e: n(45.2, 5.1)w: n(0.0, 0.0)
w: n(29.8, 4.9)e: n(20.1, 1.8)fig. 8. example model enhanced with the performance perspective. for each activ-
ity the execution time (e) and waiting time (w) are given as a normal distribution
n(arithmetic mean, standard deviation). moreover, the probabilistic values for select-
ing an alternative path at a decision point and the case arrival rate are provided
the collected values for the outpatient clinic example are shown in figure 8.
for example, one can see that the execution time of activity “ct” has a mean
of 45 .1 minutes and a standard deviation of 1 .7. similarly, the waiting time of
activity “ct” has a mean of 4320 .4 minutes and a standard deviation of 486 .1.
for the case generation scheme we have an intensity of about 0 .0167 new cases
arriving per minute, i.e., on average one case arrives per hour. moreover, in
figure 8 one can also see the probabilistic values for selecting an alternative
path at a decision point. for example, based on the observations from the log
it seems more likely that an “ecg” is needed (72% of the cases) than that it is
not needed (only 28%).
4.4 role discovery
now we move our focus onto the organizational perspective of the process. or-
ganizational mining aims at discovering both the organizational model (i.e., the
13relationships between resources and their roles or functional units) and assign-
ment rules (i.e., the relationships between roles or functional units and activ-
ities) [36]. an organizational model usually contains organizational units (e.g.,
functional units), roles (e.g., duty), resources, and their relationships (i.e., who
belongs to which functional unit, who plays what roles, hierarchy among organi-
zational units). by just using an event log, it is di ﬃcult to discover the di ﬀerences
between all of these notions. however, it is possible to derive resource groups
in which the people execute similar activities. from a “proﬁle” describing how
frequently individuals conduct speciﬁc activities, we can derive groups. such a
discovered group of resources may correspond to an organizational unit or a
union of people who perform the same roles in real life. in this paper, we will
mostly use the term “role” to refer to such a group of resources that have a
similar activity proﬁle.
in this paper, we applied the metrics based on joint activities proposed in [2]
to derive roles. metrics based on joint activities focus on the activities that
resources perform. we assume that people doing similar things are more closely
linked than people doing completely di ﬀerent activities. each individual has a
“proﬁle” in the originator by activity matrix based on how frequently it conducts
speciﬁc activities. table 1 shows a part of the originator by activity matrix
derived from the log in section 3.
table 1. a part of the originator by activity matrix, where it is shown how often each
resource performed each activity
originator first lab x ray ecg ecg not second ct mri third
visit test needed visit visit
... . . . . . . . . .
claire 0 310 0 0 0 0 0 0 0
jan 260 0 0 0 0 239 0 0 129
jane 0 0 154 0 0 0 47 45 0
jo 0 349 0 0 0 0 0 0 0
maria 0 0 158 0 0 0 40 41 0
martin 244 0 0 0 0 248 0 0 138
nigel 0 0 178 0 0 0 52 42 0
ralph 0 0 188 0 0 0 46 47 0
rose 239 0 0 0 0 250 0 0 140
... . . . . . . . . .
from this matrix, we can measure the “distance” between the proﬁles of
diﬀerent originators by comparing the corresponding row vectors. we calculated
pearson’s correlation coe ﬃcient to quantify this “distance”. pearson’s correlation
coeﬃcient produces values ranging from −1.0 to 1 .0. since the positive values
imply positive linear relationships between variables, we applied the threshold
value of 0 .0 and removed negative relationships. in this way, ﬁve clusters are
derived, namely {jan, martin, rose, vanessa },{claire, jo, valentine },{fred,
14wilma, vic },{alex, eric, jane, maria, nigel, ralph }, and {nobody }. these
clusters correspond to roles. note that the last role ( {nobody }) is a bit artiﬁcial
and stems from tasks that do not require any resource to be executed. then, we
assigned the clusters to activities based on an entity assignment method. if an
originator executed an activity, the activity is assigned to the cluster to which
the originator belongs. for example, according to the log fragment depicted in
figure 3 nigel executed the activity “x ray”, and, therefore, “x ray” is assigned
to the role of nigel , i.e., “radiology department”.
ecg not neededgynaecology departmentclinicalchemistrycardiologydepartmentradiologydepartmentfirst visitsecond visitthird visitlabtestecgx rayctmrinobodyvanessajanmartinroseclairejovalentinefredwilmavicalexericnigeljanemariaralphnobody
fig. 9. example model enhanced with the organizational perspective. the boxes rep-
resent activities, the pentagons represent roles, and the circles represent originators
figure 9 shows the derived roles, and the relationships between roles and
activities for the outpatient clinic example. the detected clusters correspond
to the “gynaecology department” (jan, martin, rose, and vanessa), “clinical
chemistry” (claire, jo, and valentine), “cardiology department” (fred, wilma,
and vic), and “radiology department” (alex, eric, jane, maria, nigel, and
ralph), respectively. the “gynaecology department” is involved in the “first
visit”, “second visit”, and “third visit” of the patient, while the “lab test” is
done by the “clinical chemistry”. the “cardiology department” is in charge of
the “ecg” activity, and the “radiology department” is related to the medical
imaging activities such as “x ray”, “ct”, and “mri”. the cluster “nobody”
does not contain a real resource from the outpatient clinic, but only a dummy
originator that was used for activity “ecg not needed” (in the case that activity
“ecg” can be skipped).
5 model integration and evaluation
in the previous section we have seen how di ﬀerent characteristics of a process
can be extracted from an event log. these characteristics can now be used to
construct a simulation model. in this section, we brieﬂy show how the di ﬀerent
perspectives are joined into a single model (section 5.1) and represented as a
15colored petri net (section 5.2). moreover, we will evaluate how good the cpn
model approximates these characteristics by generating event logs during the
simulation of the model in cpn tools, and the repeated analysis of this “second
pass” (section 5.3). for this, the same algorithms will be used as in section 4,
and the results of the “ﬁrst pass” and “second pass” will be compared to each
other.
5.1 merging perspectives
to get a better view on the process as a whole, it is useful to integrate the
discovered perspectives in one holistic model. this is fairly easy as long as the
discovered process characteristics are orthogonal to each other (i.e., there is no
conﬂicting information). they can be simply merged together. if there are con-
ﬂicting characteristics, then this becomes mainly a technical challenge. imagine,
for example, two performance analysis algorithms that ﬁt execution time distri-
butions in a di ﬀerent way. to integrate these two results we would need to either
select one of them on a per-activity basis, or to average them etc.
in the case of the running example, the discovered characteristics are largely
orthogonal. note that although the decision rules and the mined probabilities
are potentially conﬂicting as they both relate to the decision-making behavior
of the analyzed process, we still want to preserve them as they reside on di ﬀer-
ent levels of abstraction (i.e., the probabilities are inﬂuenced by the data value
distributions) and might want to use either of them when conﬁguring the sim-
ulation model later on. figure 10 shows the integrated model for the example
process. for example, activity “ecg” is only needed for patients who are older
than 60 or have an asa greater than 2, the corresponding execution time is
on average 30 minutes (with a standard deviation of 5.1), and the “cardiology
department” is in charge of the activity.
first visitlab testx rayecgecg not neededsecond visitctmrithirdvisitagediagnosisasaif (age > 60) or (asa > 2) 
if (age <= 60) and (asa <= 2) if (diagnosis = corpus carcinoma) or (diagnosis = ovarium carcinoma) 
if (diagnosis = vulva carcinoma) or (diagnosis = cervix carcinoma) radiology departmentradiology departmentradiology departmentgynaecology departmentgynaecology departmentgynaecology departmentcardiology departmentclinical chemistry
nobody w: n(29.8, 4.9) e: n(20.1, 1.8)w: n(0.0, 0.0)e: n(0.0, 0.0)w: n(7233.9, 468.0)e: n(60.4, 6.2) w: n(1450.8, 471.6) e: n(29.9, 5.1) w: n(4320.4, 486.1) e: n(45.1, 1.7)
 w: n(2894.5, 957.1) e: n(30.1, 5.2)w: n(0.008, 0.2) e: n(30.0, 5.1)w: n(30.1, 5.1) e: n(20.0, 1.6)  e: n(45.2, 5.1)w: n(0.0, 0.0)
0.720.50.50.280.280.720.0167 new cases per minute
fig. 10. example model with integrated data, organizational and performance view
165.2 cpn model
the integrated model now contains key characteristics of the outpatient clinic
process from di ﬀerent perspectives. as a next step, we want to represent these
characteristics in an actual, executable simulation model. it is clear that a simu-
lation model can only capture certain aspects of a process, and that simplifying
assumptions must be made to approximate the real behavior.
we selected colored petri nets (cpns) [23, 24] as a representation because
of their expressiveness and the strong simulation capabilities of cpn tools [38].
furthermore, the hierarchy concept allows for the composition of a cpn model
in a modular way (and, therefore, for di ﬀerent levels of abstraction). the time
concept and the availability of many probability distributions in cpn tools
allow for the modeling of performance aspects. moreover, by introducing resource
tokens also organizational and work distribution aspects can be modeled. finally,
data-related aspects can be modeled by introducing data tokens.
in [34], we proposed a cpn representation for business processes that is able
to capture di ﬀerent perspectives of a process. this cpn representation is generic
and suitable for automatic generation, while it remains readable for a human
analyst. we developed a cpn export plug-in, which can generate such cpn
models. to make use of the simulation facilities of cpn tools, the actual pro-
cess model is provided together with a simulation environment, which generates
cases, initializes data etc. furthermore, for each activity in the process, a sub-
page is created containing the actual simulation information. depending on the
selected process characteristics, these activity sub-pages may look very di ﬀerent.
as an example, the sub-page of activity “ct” is depicted in figure 11. it
covers information from all the perspectives that were previously discovered:
– the sub-page for the “ct” activity contains schedule ,start andcomplete
transitions to incorporate the waiting time and execution time of the activ-
ity. according to the time delay that is generated by the normal distribution
for the waiting time (cf. outgoing arc of the “ct schedule” transition), the
case token remains in place w(i.e., waiting state) while the model time pro-
gresses. similarly, a case token is forced to reside in place euntil the corre-
sponding execution time delay has passed (cf. outgoing arc of the “ct start”
transition).
– the “ct” activity may only be executed by people of the radiology de-
partment . this is modeled by deﬁning a separate color set with the name
radiology department, which contains only the people that belong
to this department. then, a variable “radiology department”, which is of
type radiology department, can be used to match the required role
for the activity. in this way, only the resources that belong to this color set
can be consumed by transition “ct start”, i.e., the selection of a token from
place “resources” is limited by the type of this variable. as soon as tran-
sition “ct start” is ﬁred, the corresponding resource token resides in the
place eand it is not available for concurrent executions of further activities,
until transition “ct complete” ﬁres and puts the token back.
17ct_schedule
resourcesresourcescase datacase data
ewp0incase data
resourcescp1outccase_idc[(#diagnosis data = corpus_carcinoma) orelse (#diagnosis data = ovarium_carcinoma)](c,data)c@+round(normal(4320.4,236262.4)*1.0)(c,radiology_department)
radiology_departmentradiology_department
["ralph", "nigel", "martin","vic", "eric", "vanessa", "wilma","jane", "valentine", "rose", "fred","claire", "jan", "alex", "maria","nobody", "jo"](c,radiology_department)@+round(normal(45.1,2.9))ct_startct_completecase_idxradiology_departmentcase_idxdata
case_idcase_idinout
resourcefig. 11. sub-page for the “ct” activity, showing how the simulation information re-
lated to the “ct” activity is represented in the cpn model
– the “ct” is only required for patients with diagnosis “corpus carcinoma”
or “ovarium carcinoma”. this is represented in the cpn by the guard that
belongs to the “ct schedule” transition. if this transition is enabled from
a control-ﬂow perspective, it additionally needs to satisfy the given guard
condition to be ﬁred. to check the value for the “diagnosis” data attribute,
a double arc is modeled between the “ct schedule” transition and the “case
data” place, which contains all data attributes.
note that in the combination of di ﬀerent process characteristics we have
to make choices. for example, in figure 11 one can see that the decision to
perform a ct (instead of an mri) is based on the value of a data attribute (i.e.,
the diagnosis of the patient). however, we could have also chosen to base the
decision on stochastic values (i.e., probabilities of alternative paths).
note that the integrated process and the cpn fragment shown in ﬁgures 10
and 11 are generated automatically without any human intervention or modeling.
however, users can inﬂuence the model generation by changing the settings or
adding explicit information.
5.3 evaluation “second pass”
the discovered simulation model can be used for all kinds of analysis (e.g., what-
if analysis for estimating the e ﬀects of some redesign). however, we assume that
18the reader is aware of the practical relevance of simulation. therefore, this section
focuses on the validation of the approach.
it is clear that the value of a simulation-based analysis largely depends on
the quality and validity of the simulation outcomes. the validity of the represen-
tation of the selected key characteristics is one important aspect that needs to
be ensured when approximating a real-life process by a simulation model. there-
fore, we want to evaluate how good our simulation model captures the discovered
process characteristics. other aspects, such as the validity of the recorded log
data (which is used as input for the described process discovery techniques),
are beyond the scope of this paper, and we assume that the event log contains
representative behavior for the original process.
the following approach has been taken: for the cpn model described in
the previous section, a simulation was run for 1000 cases. during the simulation
in cpn tools, separate event logs were generated for each case. these event
logs can be created by extending the cpn model with monitors, which log the
occurrence of each transition on the sub-page of an activity, as discussed in [15]
and [34]. note that our cpn export plug-in automatically adds monitors to
the cpn models, so that they produce simulation output that can be converted
into mxml using the cpn tools plug-in of the prom import framework. the
resulting mxml ﬁle can again be used as input for the mining algorithms. the
analysis of the simulated event log based on the discovered model is called the
“second pass”. in the “second pass”, the same algorithms as those used in sec-
tion 4 to discover the control-ﬂow, data, performance and resource perspective
are deployed, but now for the newly generated mxml ﬁle.
the results obtained for the control-ﬂow, data, and resource perspective are
exactly the same as in the previous analysis, i.e., they can be completely rediscov-
ered. the results obtained for the performance perspective are also very similar.
in the second pass, we have an intensity of about 0 .0163 (instead of 0 .0167) new
cases arriving per minute, and we get the same probability values for the alter-
native branches. figure 12 depicts the execution time and waiting time values
obtained from both the original log (ol) and the second pass (sp), which are
almost identical.
with regard to our artiﬁcial example, the discovered cpn model coincides
with the original model, i.e., it is possible to completely rediscover the model from
the event logs. this serves as a proof-of-concept, i.e., it is possible to discover
simulation models. in section 7, we will investigate this further by evaluating the
quality of the generated simulation models for two real-life examples. however,
we ﬁrst present the software supporting our approach.
6 simulation models in the prom framework
theprocessmining ( prom ) framework [1] is an extensible tool suite that sup-
ports a wide variety of process mining techniques in the form of plug-ins. in
this section, we describe how the presented discovery approach is supported by
prom. a set of plug-ins is available to discover and integrate di ﬀerent charac-
19fig. 12. execution time and waiting time results obtained for the original log (ol)
and the second pass (sp) of the running example. one can see that both the arithmetic
mean (mean) and the standard deviation (std) of ﬁrst and second pass are very close. in
fact, it is di ﬃcult to distinguish the lines relating to ol and sp because they coincide
in each of the three graphs
teristics of a process from an event log, and to generate a cpn model that can
be directly used for simulation. we shortly explain the functionality, and show
screenshots using the running example7.
as can be seen in figure 4, we start with an event log. to discover the control-
ﬂow perspective a number of di ﬀerent algorithms are available. we choose the
alpha algorithm plug-in, which constructs a process model in terms of a petri
net. based on this process model and the log, we can discover the performance
perspective of the process by applying the performance analysis with petri
netplug-in. a screenshot of the analysis results for the example process is shown
in figure 13(a). the plug-in evaluates the time stamps in the log and projects
the extracted performance information on places and transitions. it graphically
shows the bottlenecks by coloring places according to the time that is spent in
7note that the event log of the running example used in this paper can be downloaded
together with prom from www.processmining.org .
20this part of the process (red indicates a high waiting time, while blue means less
waiting time). furthermore, it provides performance indicators, such as average,
variance etc. of the execution time for an activity, or the time spent at a certain
place, or between two selected activities. for example, in figure 13(a), we can
see several statistics for the waiting, execution and sojourn time of the “second
visit” activity, which we have selected.
the data perspective of the process can be discovered using the decision
point analysis (also called decision miner) plug-in. this plug-in analyzes the
data attached to events and using classical decision tree analysis it is possible
to add decision rules to the petri net. these decision rules are presented as
conditions on arcs. a screenshot of the plug-in is shown in figure 13(b). for
example, in figure 13(b), we can see the decision tree that has been discovered
for the choice between “ecg” and “ecg not needed” in the outpatient clinic
process.
the resource perspective can be discovered by applying the organizational
miner plug-in. this plug-in analyzes information about resources in the event log
and returns information about the relationship between activities and origina-
tors, which can also be visualized. among others, resources that perform similar
activities or are working together can be discovered and grouped together. in
this way, allocation rules can be added to activities. a screenshot of the plug-in
is shown in figure 13(c), where the people that are working on activities in the
“gynaecology department” are shown (represented as minedgroup3 ).
these three discovery plug-ins now o ﬀer each a simulation model with ad-
ditional information about the process (e.g., the arrival rate of new cases), or
speciﬁc activities in the process (e.g., by which group of people it was performed).
but before we can integrate the di ﬀerent perspectives into one model, we ﬁrst
have to transform the discovered petri net model with the combine low-level
activities plug-in. this step is necessary because we start with a log that con-
tains transactional information (i.e., the start and completion of an activity). as
a consequence, each ‘start’ and ‘complete’ event in the log is represented as a
separate activity in the discovered process model (for example, in figure 13(a)
you can see both activity “ct start” and activity “ct complete”). however,
because we want to link the obtained information to activities as a whole, we
combine these low-level tasks that belong to one activity into a single transition
in the petri net model. since this is rather a technicality and not essential for
understanding the functionality, we will not elaborate on this.
as a next step, the di ﬀerent, now activity-based simulation models can be
integrated into one model with the help of the merge simulation models plug-
in. note that, although we use petri nets, a simulation model may be based
on any kind of process model and prom supports di ﬀerent model conversions.
for example, in event-driven process chains (epcs) activity-related informa-
tion could be mapped to functions, decision point-related information to xor
connectors etc. for this, a reference model is chosen among the input models as
a “template” for the output model (and the activities from the di ﬀerent input
models are mapped on their corresponding activities in the output model). for
21fig. 13. discovery plug-ins in the prom framework
22fig. 14. integration and export plug-ins in the prom framework
23each perspective, we can then determine from which of the (potentially con-
ﬂicting) input models the information should be included. for example, in the
screenshot in figure 14(a), we select to retain the characteristics delivered by
the decision miner for the data attributes in the merged simulation model.
finally, we want to generate a cpn from the integrated model, which can
be read and simulated by cpn tools. to this end, we use the cpn tools 2.0
export plug-in, which displays all the discovered process characteristics before
the actual export takes place. we can also modify the given settings (“what if”
analysis), and provide additional information. for example, we may choose to
give meaningful names to the discovered resource clusters, i.e., minedgroup3 =
“gynaecology department” etc. furthermore, it is possible to choose di ﬀerent
conﬁguration options. for example, each choice in the process may be either
based on data rules or stochastic properties, logging monitors can be generated
or not, and we can either include or exclude the modeling of explicit waiting
time (to include waiting time, a ‘schedule’ transition will be generated for each
sub page as shown in figure 11, otherwise it will be left out). a screenshot of the
plug-in is shown in figure 14(b), where one can see the provided data attributes,
associated resource group, and the execution time settings for activity “first
visit”. after exporting, cpn tools can be used to simulate the process without
adding any additional information to the generated model.
we have demonstrated that the discovery of a simulation model as presented
in this paper is completely supported by the prom framework. although a num-
ber of di ﬀerent plug-ins must be applied to arrive at the cpn model, sensible
default settings and a convenient user interface make it possible to quickly ex-
plore di ﬀerent variants.
7 case studies
to further validate the approach discussed in this paper, we have performed two
case studies. they are based on process logs from two di ﬀerent municipalities
in the netherlands. in these case studies, we focus on the quality of the simula-
tion models rather than on the discovered process characteristics. similar to the
running example, we ﬁrst perform process mining to discover several perspec-
tives (control-ﬂow, data, performance, and organizational), and generate a cpn
from the integrated model. then, an event log is generated during simulation in
cpn tools, and re-analyzed with prom to compare the results of this second
pass with the initial analysis results. we also investigate the results according
to diﬀerent simulation conﬁgurations.
7.1 case study i
the case study is conducted based on real-life logs from a municipality in
the netherlands. the municipality uses a workﬂow system developed using the
“eastman software workﬂow for nt”. this systems is, among others, used to
24handle complaints. we obtained a log from this workﬂow system for the com-
plaint handling process, which we converted to the mxml format via a plug-in
in the prom import framework [20]. when the municipality receives a complaint,
they ﬁrst initiate a process instance. then it is prepared (the case is investi-
gated) and assigned to a suitable activity out of four actual complaint handling
activities. then, the case is moved to the assigned activity and, after it has been
handled, the process is ﬁnished. the particular event log we use in this section
contains 363 cases. the number of total events is 1,817, and the log has ﬁve
diﬀerent activities. each activity is recorded by logging ‘start’ and ‘complete’
events. 13 employees participated in the process execution, and the log contains
15 di ﬀerent data elements such as the id of the case, queue of activities in the
workﬂow engine, priority of the task, etc.
figure 15 shows some screenshots of the mining results. we used the alpha
miner in prom to discover the process model. the resulting process model has
100% ﬁtness (i.e., every trace in the log complies with the discovered model).
the average waiting time of activities in this complaint handling process is 45.7
hours, while the average execution time of activities is only 5.1 hours. the overall
processing time is 72.6 hours, and a new case is generated every 12.4 hours (on
average). the decision point analysis result shows that the choice is based on
the value of the data attribute “queue” (which determines the activity that is
scheduled next in the workﬂow engine). from the discovered rules, it seems as
if the most frequent branch “ag08 gba afnemer”8, which is executed in 88%
of the cases, is also the default branch if none of the four complaint handling
activities has been explicitly scheduled (in this case the “queue” still contains
one of the previous activities). by the organizational miner, 6 roles are derived
and 13 originators are assigned to clusters based on the execution history in the
log.9
table 2. conﬁgurations of the three simulation models
m0 m1 m2
control flow include include include
organizational model include include include
decision rule data attribute data attribute probability
performance info execution time execution time execution time
no waiting time 95% waiting time 95% waiting time
from the mining results, three models are generated with di ﬀerent conﬁgura-
tions on decision rules and waiting time. table 2 summarizes the conﬁgurations
of the three models. the ﬁrst model (m0) and the second model (m1) combine
8note that, because there is no need to understand the process in detail, we did not
translate the dutch activity names.
9note that in figure 15(c) and figure 18(c) the names of the originators were erased
to ensure conﬁdentiality and privacy.
25fig. 15. mining results: (a) performance values (b) decision rules (c) organizational
model
26all the four mining results and use the data perspective from the decision miner
for the decision rule. in contrast, the third model (m2) uses probabilities (i.e.,
a stochastic approximation) to make the choice of the subsequent activity. fur-
thermore, the waiting time is determined only by resources in m0 (if all resources
of a certain type are occupied, an activity might have to wait until a resource
becomes available again and it can be started). in contrast, m1 and m2 contain
extra waiting time (95% of the observed waiting time) in addition to the waiting
time that results from the unavailability of resources.
note that waiting time may result from competing for resources with other
cases inside the same process and competition between processes. for example,
an employee may be involved in multiple processes that are all competing for
the employee’s attention. although the cpn model only considers the complaint
handling process, the employees of the municipality also work on other processes.
therefore, it is necessary to add waiting time in addition to the simulated queue-
ing time resulting from the competition with other complaints. since the total
waiting time is measured by prom, it is only natural to add part of this time.
therefore, we added 95%10of the observed waiting time to m1 and m2. note
that this is a necessary approximation when analyzing a process in isolation.
we perform simulations and analyze the generated process logs; each of them
contains 400 cases. we obtain the same process models and organizational mod-
els. the same decision rules are derived from the logs from m0 and m1 (since
m2 does not contain the data perspective, it has no information about data).
figure 16 shows the performance analysis results including the performance val-
ues from the original log (ol). figure 16(a) shows the execution times of the
activities. the values for all the three models are comparable to each other. fig-
ure 16(b) shows the waiting times. the values from m0 are much smaller than
the others. in the real world, resources deal with several activities in the organi-
zation and perform their work based on their own schedule. however, since we
handle not all processes but only one process, we cannot take this situation into
account. thus, the number of resources obtained from process logs is generally
large enough to immediately execute activities. to compensate this, we intro-
duce extra waiting time. if we add an additional delay of 95% of the observed
waiting time (m1, m2), waiting times are similar to the values from the original
log. note that the waiting time generated by the simulation model is the sum of
the delays resulting from the queuing of complaints and the added extra waiting
time.
figure 17 shows the probability values for choosing a particular path when
visiting the decision point shown in figure 15(b). the names on the horizontal
axis refer to the activities following the decision point. when we use probabilities
to make a decision (m2), the resulting probability values are almost identical to
10we ﬁnd the right degree of external waiting time by experimenting and evaluating
the results of the second pass as described in this paper. that is, we try to match
the simulated results with the original ones to ﬁnd out to which degree the waiting
time stems from competition within the process according to our model (here, this
was approx. 5%) and to which degree it is inﬂuenced by other factors (95%).
27fig. 16. performance analysis results based on the original log (ol) and the three
discovered simulation models
the original values. however, we can see that if we use decision rules based on
data attributes (m0, m1), the results are di ﬀerent. this is not desirable since the
probability of an alternative branch can, for example, inﬂuence the throughput
time of the process (e.g., through the increase of the probability of executing
an activity which has a long execution time, or because one branch has more
steps to be executed than the other). we found out that the di ﬀerences stem
from the fact that the values of the (nominal) decision variable “queue” are
randomly generated by the model, rather than being sampled from the actual
data value range distribution. note that in the running example the probabili-
ties did match because we generated the log with decisions based on randomly
distributed (nominal) data in the ﬁrst place. however, in this section we use a
real-life log where this is not the case, which enabled us to detect this ﬂaw. this
demonstrates the value of performing experiments based on real-life data.
fig. 17. probabilities for the decision point shown in figure 15(b)
287.2 case study ii
the second case study deals with a log that we obtained from the urban manage-
ment service of a local municipality of 90,000 citizens, situated in the northern
part of the netherlands. they have implemented their own custom-made work-
ﬂow system. from the workﬂow system, we extracted process logs and converted
them into the mxml format. we use the log of the handling of invoices in 2005.
the log data contains 570 cases. the number of total events is 6,616. the process
consists of 10 activities, and 110 employees participated in the process execution.
for the ﬁrst activity only ‘complete’ events are recorded, but the other activi-
ties record both ‘start’ and ‘complete’ events. the general procedure is that an
invoice is scanned and subsequently sent by the workﬂow management system
to the central ﬁnancial department. a clerk registers the invoice, after that it is
sent to the proper local ﬁnancial o ﬃce. depending on the kind of invoice, there
are various checks that need to take place: the person responsible for the budget
that is used for the purchase must approve (the budget keeper); the ﬁt between
the purchase with the supplier’s contract (if any) must be established; various
managers may be required to authorize the invoice depending on the amount of
money involved etc. eventually, a purchase may be paid by the central ﬁnancial
oﬃce.
from the process logs we derived a model for the control-ﬂow perspective
and extended the model with characteristics from the performance and orga-
nizational perspectives. note that, since the original log does not contain any
data, we cannot perform the decision point analysis. after integrating the dis-
covered models, we generate simulation models with di ﬀerent conﬁgurations of
the waiting time.
figure 18 shows the mining results. we generate the process model with the
heuristic miner in prom. figure 18(a) shows the generated model in terms of a
petri net11. the generated model has 100% ﬁtness with respect to the log (i.e.,
it completely captures the behavior from the log). to calculate performance in-
formation such as execution time and waiting time, we create a petri net model
including start andcomplete tasks and use the performance analysis plug-in.
figure 18(b) shows the results of this performance analysis. the overall process-
ing time is 182 hours (about a week), and a new case is started every 50 minutes,
on average respectively. we also generate an organizational model as shown in
figure 18(c). 10 roles are derived and employees are assigned to the roles. table 3
shows the performance analysis results for the ﬁve major activities in the pro-
cess. similar to the previous case study, one can observe that the waiting times
are by a multiple higher than the execution times in the process. this is very
typical for a real-life process, where much time is spent on administration, syn-
chronization, etc. the table also shows organizational mining results. it shows
the number of resources who are involved in the execution of each activity.
from the mining results, two models are generated with di ﬀerent conﬁgura-
tions on the waiting time. in the ﬁrst model (m0), the waiting time is determined
11note that the prom framework supports various conversions between modeling lan-
guages, such from petri nets to heuristic nets, epcs, yawl and vice versa.
29fig. 18. mining results: (a) control ﬂow (b) performance values (c) organizational
model
table 3. organizational mining and performance analysis results for the ﬁve main
activities in the process
execution time (minutes) waiting time (hours) # of resources
codfctbf 3.71 29.7 76
contruif 1.75 17.9 3
routefez 5.05 39.7 25
contrcod 2.71 22 24
fbconcod 2.85 66.5 7
30only by resources, while the second model (m1) contains extra waiting time
(100% of the observed waiting time). figure 19 shows the generated simulation
model (m0) in cpn tools. note that the petri net includes invisible activities
(i.e., transitions that do not correspond to an event in the log and that are only
executed to enable “real activities”). they are denoted as small tasks ﬁlled with
black color.
fig. 19. simulation model in cpn tools
with each simulation model, we generate 600 cases and analyze the generated
process logs with prom. in both cases, the process model discovered by the
heuristic miner from the simulated process log equals to the original model in
figure 18(a). the organizational model is also re-discovered. figure 20 shows
the performance analysis results. figure 20(a) shows the execution times of the
activities. as before, the results are very similar. figure 20(b) shows the waiting
times. in m0, no waiting times are observed due to the small execution times,
and the big number of available resources. again, the reason is that we observe
one process in isolation, i.e., we do not see the activities that resources perform
for other processes. hence, utilization of resources is low and there is hardly
any queueing due to competition between cases. since the processing times are
negligible compared to the observed waiting times, we add an extra delay of
100% of the observed waiting time (m1). as a result of this intervention, the
waiting times are similar to the values from the original log.
in these two case studies, we have generated simulation models from real-life
process logs with the method proposed in this paper. we have also investigated
the quality of the simulation models by analyzing the generated process logs
and comparing the results with the original mining results. the results are very
promising as they demonstrate that it is indeed possible to automatically con-
31fig. 20. performance analysis results for the original log (ol) and the two discovered
models (m0 and m1)
struct simulation models based on real-life event logs. furthermore, with the
proper conﬁguration these models could accurately reﬂect the real situation for
all the covered perspectives. however, the results also highlight a number of
challenges that must be addressed in the future. they are summarized in the
next section.
8 future challenges
the goal is to derive a simulation model that reﬂects the real process as precisely
as possible. however, instead of trying to “capture the whole world” (which obvi-
ously is an unachievable goal) we must ﬁnd simplifying but suitable approxima-
tions for the desired key characteristics and behaviors. process mining can help
to automatically extract the information that we need for these approximations
from log data.
clearly, the level of detail (e.g., the number of covered perspectives) of a simu-
lation model has an impact on the usefulness of a simulation model. for example,
we can approximate the routing behavior at a decision point in the process by
probabilities. however, this will not allow us to directly investigate the e ﬀect to
be expected by an increased proportion of cases with certain characteristics (as-
suming that these characteristics a ﬀect the routing behavior). similarly, solely
modeling the waiting time for an activity is a way to approximate all kinds of
delays that prevent the immediate execution of the activity (including the avail-
ability of suitable resources). however, with such a coarse approximation we are
not able to predict the eventual real e ﬀects of an increased case load, or the
allocation of more resources to the process. therefore, a simulation model needs
to cover di ﬀerent perspectives, such as control-ﬂow, data, resources, and time.
the organizational perspective is a very important and challenging aspect
to be covered in a simulation model. note that in the case studies people were
only working part-time on the processes at hand. as a result, we had to add
additional waiting time to the models based on an analysis of the log. however,
32this is not satisfactory since it does not really capture the way that people
actually work (and the high degree of additional waiting time needed to ﬁt the
real-life processes shows the relevance of getting more insight into the actual
root causes for these delays). numerous simulation studies, where, e.g., master
students model the business processes of organizations, have shown that initial
simulation results are typically very optimistic because the resources in the model
are too “eager”. for example, people work only part-time, or are involved in
multiple processes. however, even if we can correctly capture the availability of
a person, it does not mean that in reality he or she would start working on a
task as soon as it is possible. for example, certain tasks may be continuously
delayed due to prioritization issues. as a consequence, we need to ﬁnd better
ways to characterize human behavior without “imitating” the (very complex)
reality.
during our experiments we have also identiﬁed potential points of improve-
ment for our mining plug-ins. for example, we realized that we need to capture
data value range statistics from the execution log not only for numeric but also
nominal attributes. this could be easily addressed by recording frequency statis-
tics with respect to the di ﬀerent data values, and by including the corresponding
random value generators in the cpn models12. furthermore, it would be good
to ﬁnd ways to extract performance characteristics and decision rules without
the need of a (mined) process model as input because this often implies confor-
mance problems (i.e., if not all cases comply with the given process model, we
might not be able to use the data from these cases).
other directions of future work are the automated support of redesign (i.e.,
suggesting process improvements based on log analysis and simulation of alter-
natives [28]) and the use of simulation for real-time decision making (i.e., making
recommendations for current cases based on a mixture of process mining and
short-term simulation [30, 41]).
9 conclusion
this paper demonstrates that it is possible to automatically construct simula-
tion models based on event logs. these simulation models need to cover di ﬀerent
perspectives: control-ﬂow, data, resources, time, etc. therefore, we showed that
each of these perspectives can be discovered using existing process mining tech-
niques and that all these mining results can be merged into a single simulation
model.
the approach has been implemented in the context of prom and has been
tested using di ﬀerent examples. in this paper, we used an artiﬁcial example and
two case studies to evaluate our approach. based on this we can conclude that it
is indeed possible to automatically construct simulation models based on event
logs. the discovered models can be exported to cpn tools which allows for all
kinds of simulation. using the monitoring functionality of cpn it is possible
12this and other improvements will be available with the release 5.0 of prom.
33to do all kinds of measurements and to feed the results back to prom. in this
paper, we did not focus on the analysis of the processes of the two municipalities
(although extensive simulation studies have been done by students doing their
ﬁnal master projects in these two municipalities). the reason is that it is obvious
that good simulation models have a high practical value. therefore, we focused
on the validation of our approach.
given the relevance of simulation and the problems people have making good
simulation models, we will continue to work on the topics mentioned in this
paper. we are exploring various ways to improve the various plug-ins mentioned.
moreover, we would like to improve the modeling of human behavior as indicated
in the previous section.
acknowledgements
this research is supported by the technology foundation stw, eit, super,
nwo, and the iop program of the dutch ministry of economic a ﬀairs. fur-
thermore, the authors would like to thank all prom developers for their on-going
work on process mining techniques. we would also like to thank lisa wells and
kurt jensen for their support in using cpn tools.
references
1. w.m.p. van der aalst, b.f. van dongen, c.w. g¨ unther, r.s. mans, a.k. alves
de medeiros, a. rozinat, v. rubin, m. song, h.m.w. verbeek, and a.j.m.m.
weijters. prom 4.0: comprehensive support for real process analysis. in j. kleijn
and a. yakovlev, editors, application and theory of petri nets and other models of
concurrency (icatpn 2007) , volume 4546 of lecture notes in computer science ,
pages 484–494. springer-verlag, berlin, 2007.
2. w.m.p. van der aalst, h.a. reijers, and m. song. discovering social networks
from event logs. computer supported cooperative work , 14(6):549–593, 2005.
3. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
4. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining , special
issue of computers in industry, volume 53, number 3. elsevier science publishers,
amsterdam, 2004.
5. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128–1142, 2004.
6. r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
ﬂow logs. in sixth international conference on extending database technology ,
pages 469–483, 1998.
7. r. bergenthum, j. desel, r. lorenz, and s. mauser. process mining based on
regions of languages. in g. alonso, p. dadam, and m. rosemann, editors, bpm ,
volume 4714 of lecture notes in computer science , pages 375–383. springer, 2007.
348. m. castellanos, f. casati, m.c. shan, and u. dayal. ibom: a platform for in-
telligent business operation management. in icde ’05: proceedings of the 21st
international conference on data engineering (icde’05) , pages 1084–1095, wash-
ington, dc, usa, 2005. ieee computer society.
9. j.e. cook and a.l. wolf. automating process discovery through event-data
analysis. in international conference on software engineering , pages 73–82, 1995.
10. j.e. cook and a.l. wolf. discovering models of software processes from event-
based data. acm transactions on software engineering and methodology ,
7(3):215–249, 1998.
11. j.e. cook and a.l. wolf. event-based detection of concurrency. in proceedings
of the sixth international symposium on the foundations of software engineering
(fse-6) , pages 35–45, 1998.
12. j.e. cook and a.l. wolf. software process validation: quantitatively measuring
the correspondence of a process to a model. acm transactions on software
engineering and methodology , 8(2):147–176, 1999.
13. a. datta. automating the discovery of as-is business process models: proba-
bilistic and algorithmic approaches. information systems research , 9(3):275–301,
1998.
14. a.k. alves de medeiros. genetic process mining . phd thesis, eindhoven univer-
sity of technology, eindhoven, 2006.
15. a.k. alves de medeiros and c.w. guenther. process mining: using cpn tools
to create test logs for mining algorithms. in k. jensen, editor, proceedings of
the sixth workshop and tutorial on practical use of coloured petri nets and the
cpn tools , pages 177–190, 2005.
16. w. gaaloul and c. godart. mining workﬂow recovery from event based logs. in
w.m.p. van der aalst, a.h.m. ter hofstede, and m. weske, editors, international
conference on business process management (bpm 2005) , pages 169–185, 2005.
17. f. gottschalk, w.m.p. van der aalst, m.h. jansen-vullers, and h.m.w. verbeek.
protos2cpn: using colored petri nets for conﬁguring and testing business pro-
cesses. accepted for the seventh workshop and tutorial on practical use of
coloured petri nets and the cpn tools, 2006.
18. d. grigori, f. casati, m. castellanos, u. dayal, m. sayal, and m.-c. shan. business
process intelligence. computers in industry , 53(3):321–343, 2004.
19. d. grigori, f. casati, u. dayal, and m.c. shan. improving business process qual-
ity through exception understanding, prediction, and prevention. in p. apers,
p. atzeni, s. ceri, s. paraboschi, k. ramamohanarao, and r. snodgrass, ed-
itors, proceedings of 27th international conference on very large data bases
(vldb’01) , pages 159–168. morgan kaufmann, 2001.
20. c.w. g¨ unther and w.m.p. van der aalst. a generic import framework for process
event logs. in j. eder and s. dustdar, editors, business process management
workshops, workshop on business process intelligence (bpi 2006) , volume 4103
oflecture notes in computer science , pages 81–92. springer-verlag, berlin, 2006.
21. j. herbst. a machine learning approach to workﬂow management. in proceedings
11th european conference on machine learning , volume 1810 of lecture notes in
computer science , pages 183–194. springer-verlag, berlin, 2000.
22. p.t.g. hornix. performance analysis of business processes through process min-
ing. master’s thesis, eindhoven university of technology, department of computer
science, eindhoven, the netherlands, 2007.
23. k. jensen. coloured petri nets. basic concepts, analysis methods and practical
use. springer-verlag, 1997.
3524. k. jensen, l.m. kristensen, and l. wells. coloured petri nets and cpn tools
for modelling and validation of concurrent systems. international journal on
software tools for technology transfer , 9(3-4):213–254, 2007.
25. l.t. ly, s. rinderle, p. dadam, and m. reichert. mining sta ﬀassignment rules
from event-based data. in c. bussler et al., editor, business process management
2005 workshops , volume 3812 of lecture notes in computer science , pages 177–
190. springer-verlag, berlin, 2006.
26. t.m. mitchell. machine learning . mcgraw-hill, 1997.
27. h.r. motahari-nezhad, r. saint-paul, b. benatallah, and f. casati. protocol
discovery from imperfect service interaction logs. in data engineering, 2007.
icde 2007. ieee 23rd international conference on , pages 1405–1409, 2007.
28. m. netjes, i. vanderfeesten, and h.a. reijers. “intelligent” tools for workﬂow
process redesign: a research agenda. in c. bussler and a. haller, editors, busi-
ness process management workshops (bpm 2005) , volume 3812 of lecture notes
in computer science , pages 444–453. springer-verlag, berlin, 2006.
29. j.r. quinlan. c4.5: programs for machine learning . morgan kaufmann, 1993.
30. h.a. reijers and w.m.p. van der aalst. short-term simulation: bridging the gap
between operational control and strategic decision making. in m.h. hamza,
editor, proceedings of the iasted international conference on modelling and
simulation , pages 417–421. iasted/acta press, anaheim, usa, 1999.
31. a. rozinat and w.m.p. van der aalst. decision mining in business processes.
bpm center report bpm-06-10, bpmcenter.org, 2006.
32. a. rozinat and w.m.p. van der aalst. decision mining in prom. in s. dustdar,
j.l. fiadeiro, and a. sheth, editors, bpm 2006 , volume 4102 of lecture notes in
computer science , pages 420–425. springer-verlag, berlin, 2006.
33. a. rozinat and w.m.p. van der aalst. conformance checking of processes based
on monitoring real behavior. information systems , 33(1):64–95, 2008.
34. a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering col-
ored petri nets from event logs. international journal on software tools for
technology transfer (sttt) , 10(1):57–74, 2008.
35. v. rubin, c.w. g¨ unther, w.m.p. van der aalst, e. kindler, b.f. van dongen,
and w. sch¨ afer. process mining framework for software processes. in q. wang,
d. pfahl, and d.m. ra ﬀo, editors, software process dynamics and agility, icsp
2007, volume 4470 of lncs , pages 169–181, 2007.
36. m. song and w.m.p. van der aalst. towards comprehensive support for organi-
zational mining. beta working paper series, wp 211, eindhoven university of
technology, eindhoven, 2006.
37. s. subramaniam, v. kalogeraki, d. gunopulos, f. casati, m. castellanos,
u. dayal, and m. sayal. improving process models by discovering decision points.
information systems , 32(7):1037–1055, 2007.
38. a. vinter ratzer, l. wells, h.m. lassen, m. laursen, j.f. qvortrup, m.s. stissing,
m. westergaard, s. christensen, and k. jensen. cpn tools for editing, simulat-
ing, and analysing coloured petri nets. in w.m.p. van der aalst and e. best,
editors, applications and theory of petri nets 2003: 24th international confer-
ence, icatpn 2003 , volume 2679 of lecture notes in computer science , pages
450–462. springer verlag, 2003.
39. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models
from event-based data using little thumb. integrated computer-aided engi-
neering , 10(2):151–162, 2003.
40. i.h. witten and e. frank. data mining: practical machine learning tools and
techniques, 2nd edition . morgan kaufmann, 2005.
3641. m.t. wynn, m. dumas, c.j. fidge, a.h.m. ter hofstede, and w.m.p. van der
aalst. business process simulation for operational decision support. in a.h.m.
ter hofstede, b. benatallah, and h.-y. paik, editors, bpm 2007 workshops , volume
4928 of lecture notes in computer science , pages 66–77. springer-verlag, 2008.
37