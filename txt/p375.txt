discovering simulation models
a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst
eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands
{a.rozinat,r.s.mans,m.s.song,w.m.p.v.d.aalst }@tue.nl
abstract. process mining is a tool to extract non-trivial and useful in-
formation from process execution logs. these so-called event logs (also
called audit trails, or transaction logs) are the starting point for various
discovery and analysis techniques that help to gain insight into certain
characteristics of the process. in this paper we use a combination of pro-
cess mining techniques to discover multiple perspectives (namely, the
control-ﬂow, data, performance, and resource perspective) of the process
from historic data, and we integrate them into a comprehensive simu-
lation model. this simulation model is represented as a coloured petri
net (cpn) and can be used to analyze the process, e.g., evaluate the
performance of diﬀerent alternative designs. the discovery of simulation
models is explained using a running example. moreover, the approach
has been applied in two case studies; the workﬂows in two diﬀerent mu-
nicipalities in the netherlands have been analyzed using a combination
of process mining and simulation. furthermore, the quality of the cpn
models generated for the running example and the two case studies has
been evaluated by comparing the original logs with the logs of the gen-
erated models.
1 introduction
computer simulation is a useful and versatile tool to gain insight into the op-
eration of systems. next to, e.g., natural systems also human systems can be
subject to simulation. generally, a model that represents certain key character-
istics or behaviors of the system is analyzed to show the eventual real eﬀects of
alternative conditions and courses of action. the strength of simulation is that it
enables precisely this “what if” analysis, i.e., it allows to “look into the future”
under certain assumptions. in this paper, we focus on simulation models of oper-
ational processes. for example, in the context of a workﬂow management system
simulation can help to estimate the beneﬁt of an anticipated process redesign,
or to predict ﬂow times for an increasing number of incoming cases, a reduced
number of specialists for a certain task etc.
traditionally, such simulation models are created manually (cf. figure 1).
documentation, interviews and close observation help to get an understanding
of the real-world process of interest. this is a time-consuming activity, which is
likely to be error-prone as it is based on human perception of reality rather than
on reality itself. good knowledge of the observed operational process is inevitablefor drawing conclusions from a simulation run. therefore, we propose to use
process mining techniques to (semi-)automatically discover a simulation model
based on information that was recorded during process enactment. this way, we
can much quicker arrive at a ﬁrst simulation model (to be further evaluated and
potentially modiﬁed) than with the traditional approach. in addition, it is likely
to better represent reality as it is based on objective information.
explore process 
redesigns by simulating their effectssimulation
modelevent
logs
informatio n
system
real-world 
process
recordssupports /
controls
process miningmanual creation models
fig. 1. traditionally, simulation models are created manually. in this paper we aim at
the (semi-)automatic discovery of simulation models using process mining techniques
nowadays, many business processes are supported by information systems
that help coordinating the steps that need to be performed in the course of
the process. workﬂow systems, for example, assign work items to employees ac-
cording to their roles and the status of the process. typically, these systems
record events related to the activities that are performed, e.g., in audit trails
or transaction logs [2]. these event logs are the starting point for process min-
ing techniques, which, for example, construct a process model which reﬂects the
causal relations that have been observed among the activities. another example
is decision mining [20], which analyzes which properties (i.e., valuations of data
attributes) of a case might lead to taking certain paths in the process. in this pa-
per we use a combination of process mining techniques to discover and integrate
multiple perspectives of the process under consideration, namely control-ﬂow,
data, performance, and organizational perspective. in principle, further charac-
teristics can be incorporated (cf. figure 2). colored petri nets (cpns) [12] are
then used as a representation for the integrated model because of their expres-
siveness and the strong simulation capabilities of cpn tools [23].
the applicability of the approach presented in this paper stands of falls with
the availability of suitable logs. fortunately, it can be observed that more and
more events are being logged in a wide variety of systems. obviously, information
systems such as workﬂow management systems (e.g. staﬀware), erp systems
(e.g. sap), case handling systems (e.g. flower), pdm systems (e.g. windchill),
2event
logsimulation
modelcontrol-flow discovery
model 
integrationdata dependencies
performance characteristics
organizational characteristics 
...simulationsimulation
resultsprocess mining (prom) simulation (cpn tools)fig. 2. a combination of process mining techniques is used to discover and integrate
multiple perspectives of a process in a comprehensive simulation model
crm systems (e.g. microsoft dynamics crm), middleware (e.g., ibm’s web-
sphere), hospital information systems (e.g., chipsoft), etc. provide very detailed
information about the activities that have been executed. moreover, one can also
ﬁnd logs in situations where the information system is not directly noticeable.
examples are medical systems (e.g., x-ray machines), mobile phones, car en-
tertainment systems, production systems (e.g., wafer steppers), copiers, sensor
networks, etc. software plays an increasingly important role in such systems and,
already today, many of these systems record events. an example is the “cus-
tomercare remote services network” of philips medical systems (pms).
this is a worldwide internet-based private network that links pms equipment
to remote service centers. an event that occurs within an x-ray machine (e.g.,
moving the table, setting the deﬂector, etc.) is recorded and analyzed. another
example is the event logging infrastructure developed by asml. asml man-
ufactures chip-making equipment such as wafer scanners. its products are also
connected to the internet. this connection is used to distribute the events logged.
already during the testing phase of a wafer scanner in the factory, thousands of
events are recorded via an internet connection. this can be used for improving
the service, improving the products, and for improving the test processes. the
logging capabilities of the machines of pms and asml illustrate the omnipres-
ence of event logs, making process mining a reality. moreover, it is an important
motivation for the work in this paper: why construct simulation models by hand
based on assumptions if there is so much real data around?
to directly support the generation of a simulation model from event logs we
have implemented a cpn tools 2.0 export plug-in (in the remainder of this paper
referred to as cpn export plug-in) in the context of the prom framework1, which
oﬀers a wide range of tools related to process mining and process analysis. in [21]
we described the chosen cpn representation for business processes in detail, and
we presented the cpn export plug-in in prom. in this paper, we build on this
work and show how a comprehensive simulation model including characteristics
from the data, performance, and organizational perspective can be discovered
1both documentation and software (including the source code) can be downloaded
from www.processmining.org .
3from an event log. furthermore, we evaluate how well the generated cpn model
approximates these process characteristics by generating event logs during the
simulation of the model in cpn tools, and the repeated analysis of this “second
pass”, i.e., the behavior of the simulation model is compared with reality.
the paper is organized as follows. first, section 2 introduces the notion of
an event log and presents a simple example process that is used throughout this
paper. then, process mining techniques discovering diﬀerent perspectives of a
business process are described in section 3. subsequently, we show how these
perspectives can be integrated and represented as a cpn in section 4. section 5
presents a set of plug-ins in the prom framework that can be used to discover
and integrate all these perspectives. section 6 describes two case studies based
on real-life log data. finally, related work is discussed in section 7, and the paper
concludes by pointing out directions for future research.
2 event logs
most information systems, e.g., wfm, erp, crm, scm, and b2b systems,
provide some kind of event log (also referred to as transaction log or audit trail)
[2]. it contains log entries about activities which were executed for a business
process that is supported by the information system. every event refers to a
case (i.e., process instance) and an activity, whereas activities in real business
scenarios are often logged at a more ﬁne-grained level than the atomic execution
of that activity—they record, for example, the scheduling , the start, and the
completion of an activity2. furthermore, most systems also register a time stamp,
a performer, and some additional data.
figure 3 depicts a part of an event log in mxml3format, which is used as
a running example in the remainder of this paper. the logged process reﬂects
the medical examination ﬂow in an outpatient clinic for gynecological oncology,
whereas each process instance describes the examination history of one particular
patient. note that this artiﬁcial example is based on a real-life outpatient clinic
process of the amc hospital in the netherlands. the example has been simpliﬁed
for illustration purposes.
in figure 3 we show the beginning of the ﬁrst patient’s history. note that
the event log starts with the start and completion of the “first visit” to the
gynecologist, and the start of a subsequent “x ray” examination of this pa-
tient. one can observe that for each of the audit trail entries (i.e., events) the
time stamp is recorded (a), and that the involved personnel from the outpatient
clinic is registered in the originator ﬁeld (b). furthermore, the complete event
of activity “first visit” captures the “asa”, which is a rating of anesthetic risk
2the life cycle of an activity has been standardized by the mxml format for workﬂow
logs, which is used by the prom framework.
3both the corresponding schema deﬁnition and the prom import framework [9], which
converts logs from existing (commercial) process-aware information systems to the
mxml format used by prom, can be downloaded from www.processmining.org .
4fig. 3. log fragment in mxml format. the running example reﬂects the examination
ﬂow in an outpatient clinic and contains in total 1000 cases (i.e., patient histories)
ranging from 1 (low) to 5 (high), the “diagnosis”, and the “age” of the patient
in additional data attributes (c).
3 process mining from diﬀerent perspectives
based on the example log introduced in the previous section, we will now apply
a number of process mining algorithms to gain insight into diﬀerent perspectives
of the outpatient clinic process. the aim is to extract key characteristics that
can be used for the creation of a simulation model.
figure 4 visualizes the dependencies between the used process mining tech-
niques. first, a control-ﬂow discovery algorithm is applied to automatically cre-
ate a process model that reﬂects the causal relations between the examination
activities in the log (section 3.1). second, a decision point analysis is performed
based on the process model and the event log to discover decision rules for the
choice points in the outpatient clinic process (section 3.2). third, a performance
analysis is carried out to enhance the process model with information about ex-
ecution times and waiting times for the activities, and probabilities for taking
alternative paths (section 3.3). fourth, a role discovery algorithm is applied to
the event log to group resources into roles, and to associate the discovered roles
with the activities in the process (section 3.4).
finally, in section 4, the mining results enhanced with data, performance,
and organizational characteristics are integrated in one comprehensive simu-
lation model. during the simulation of this model in cpn tools we generate
5event
log
simulation
modelcontrol-flow 
discoverymodel 
integrationdecision 
point
analysis
performance 
analysisrole 
discovery
process
modelmodel incl.
probabilities
 and timemodel incl.
data depen-
denciesactivity set
incl. rolessection 3 section 4
log 
generation  
and 
“second 
pass”
what if analysis
utilization service level flow time waiting time...fig. 4. overview about the process mining techniques used in this paper
execution logs (similar to the original event log), and again apply the diﬀer-
ent process mining algorithms to see whether we can rediscover the previously
discovered information in this “second pass”. note that this “second pass” is
mainly relevant for the evaluation of our approach. in real-life applications of
our approach, the simulation model is used to gain insights and to evaluate and
compare diﬀerent redesigns, i.e., the focus is not on the quality of the discovered
simulation model. however, since such a “what if” analysis using simulation is
common practise, we will not elaborate on this and assume that the reader is
familiar with the role of simulation in business process analysis and redesign.
3.1 control-ﬂow discovery
control-ﬂow discovery aims at the automatic extraction of a process model from
an event log, i.e., the inference of a structural representation of the underlying
process based on historic data.
typically, events in these logs are only expected to (i) refer to an activity
from the business process, (ii) refer to a case (i.e., process instance), and (iii) be
totally ordered [2, 3]. therefore, the event log from section 2 can be considered
as a set of event sequences as shown in figure 5(a)4.
based on this information, the α-algorithm [4] automatically constructs the
petri net model depicted in figure 5(b). a petri net is a dynamic structure that
consists of a set of transitions , which are indicated by boxes and relate to some
4the letters a–ihave been introduced as a short-hand for the activity names in the
process.
6activity/task, or action that can be executed, a set of places , which are indicated
by circles and may hold one or more tokens (indicated as black dots), and a set
ofdirected arcs that connect these transitions and places with each other in a
bipartite manner. transitions are enabled as soon as all of their input places
(places connected to this transition via an incoming arc) contain a token. if a
transition is enabled, it may ﬁrewhereas it consumes a token from each of its
input places and produces a token for each of its output places (places connected
to this transition via an outgoing arc). this way, the ﬁring of a transition may
change the marking of a net, and therefore the state of the process, which is
deﬁned by the distribution of tokens over the places.
a
startp0
p1p6endfirst 
visitlab
test
x rayecg
ecg not 
neededsecond 
visitct
mrithird 
visit b
cd
ep2
p3f
p4g
hp5iabcdfgiacbdfgi
abcefgi
acbefgi
abcdfhiacbdfhi
abcefhi
acbefhilog traces
(a) event log (b) discovered process model
fig. 5. control-ﬂow discovery of the outpatient clinic example. a process model re-
ﬂecting the dependencies among the activities in the process is automatically created
the discovered model in figure 5(b) visualizes the ﬂow of examinations in
the outpatient clinic. to be more precise, the ﬁgure shows the diagnostic pro-
cess for gynaecological oncology patients, in which a diagnosis is made for the
patient and further investigated through a number of examinations. as soon as
the diagnostic process is completed, the treatment phase can be started. the di-
agnostic process starts with the ﬁrst visit of the patient to the outpatient clinic.
during this “first visit”, a blood sample is taken from the patient, which is
tested afterwards in the lab. in parallel to the “lab test”, the patient undergoes
an “x ray” examination, i.e., “lab test” and “x ray” may occur in any order.
after completing the “lab test” and the “x ray”, the patient is sent to make an
appointment for an electrocardiogram, i.e., an “ecg”, if this is needed. after
all these examinations, the patient has a follow-up visit in the outpatient clinic.
during this “second visit”, the doctor decides whether either a magnetic reso-
nance imaging (“mri”) examination, or a computed tomography (“ct”) scan
needs to be made. after the “mri” or “ct”, the diagnostic process is ﬁnished
with a “third visit” of the patient to the outpatient clinic.
it is important to keep in mind that the model in figure 5(b) is constructed
fully automatically based on the log referred to in ﬁgures 3 and 5(a).
73.2 decision point analysis
now that we have discovered a process model reﬂecting the causal relations
between the activities in the outpatient clinic process, we want to gain more
insight into the data perspective of that process. more precisely, we want to
discover data dependencies that inﬂuence the routing of a case. to analyze the
choices in a process we ﬁrst need to identify those parts of the model where the
process splits into alternative branches, also called decision points . based on data
attributes associated to the events in the log (cf. figure 3(c)), we subsequently
want to ﬁnd rules for following one route or the other [20].
in terms of a petri net, a decision point corresponds to a place with multiple
outgoing arcs. since a token can only be consumed by one of the transitions
connected to these arcs, alternative paths may be taken during the execution
of a process instance. the process model in figure 5(b) exhibits three such
decision points: p5(if there is a token, either gorhcan be performed), p2,
and p3(seen from the latter two places, either doremay be carried out).
the idea is to convert every decision point into a classiﬁcation problem [14, 16,
25], where the classes are the diﬀerent decisions that can be made. as training
examples we use the process instances in the log (for which it is already known
which alternative path they followed with respect to the decision point). the
attributes to be analyzed are the case data attributes contained in the log, and
we assume that all attributes that have been written before the choice construct
under consideration are relevant for the routing of a case at that point5.
however, because there is no explicit information in the log about which de-
cision was made at a decision point for some process instance, we ﬁrst have to
infer this information from the log. starting from the identiﬁcation of a choice
in the process model (i.e., a decision point) a decision can be detected if the
execution of an activity in the respective alternative branch of the model has
been observed, which requires a mapping from that activity to its “occurrence
footprint” in the event log. so, if a process instance contains the given “foot-
print”, this means that there was a decision for the associated alternative path
in the process. for simplicity we examine the occurrence of the ﬁrst activity
per alternative branch to classify the possible decisions. however, to successfully
conduct decision mining for real-life business processes several challenges posed
by, for example, invisible activities ,duplicate activities , and loops need to be ad-
dressed. we refer the interested reader to our technical report [19], where these
issues are addressed in detail.
after identifying a decision point in a business process and classifying the
decisions of all the process instances in the log, the next step is to determine
whether decisions might be inﬂuenced by case data, i.e., whether cases with
certain properties typically follow a speciﬁc route. to solve the formulated clas-
siﬁcation problem, various algorithms are available [14, 25]. we decided to use
an algorithm based on decision trees (the c4.5 algorithm [16] to be precise).
decision trees are a popular tool for inductive inference and the corresponding
5we also allow the user to set other scoping rules, e.g., only the data set in a directly
preceding activity, or all case data including the data that is set later.
8afirst 
visitlab
test
x rayecg
ecg not 
neededsecond 
visitct
mrithird 
visit b
cd
ep2
p3fg
hp5i
age
diagnosis
asaif (age > 60) 
or (asa > 2) 
if (age <= 60) 
and (asa <= 2) if (diagnosis = corpus carcinoma) 
or (diagnosis = ovarium carcinoma) 
if (diagnosis = vulva carcinoma) 
or (diagnosis = cervix carcinoma) fig. 6. example model enhanced with the data perspective. decision rules for the
choice points in the process were derived based on data attributes provided during the
“first visit” of the patient
algorithms have been extended in various ways to improve practical applicability.
for example, they are able to deal with continuous-valued attributes, missing at-
tribute values, and they include eﬀective methods to avoid over-ﬁtting the data
(i.e., that the tree is too much tailored towards the particular training examples).
using decision point analysis we can extract knowledge about decision rules
as shown in figure 6. each of the three discovered decision points corresponds
to one of the choices in the running example. note that, because the choices
taken at p2andp3are dependent on each other, they yield the same rules. we
can conclude that the “ecg” is only needed for patients that are older than 60
years, or have an asa greater than 2. furthermore, the “ct” is only required for
patients with the diagnosis “corpus carcinoma” or “ovarium carcinoma”, while
an “mri” is needed for patients with the diagnosis “vulva carcinoma” or “cervix
carcinoma”.
3.3 performance analysis
in the previous subsection we have discovered data-based rules for the decision
points in the process. now, we want to gain more insight into the performance
perspective of the process. more precisely, we want to enhance the process model
with information about execution times and waiting times for the activities.
the execution time is the time between the start and the completion of the
activity. the waiting time is the time between the point at which the last activity
that is a direct predecessor of this activity was completed and the moment at
which the execution of the activity itself is started. moreover, we also want to
enhance the process model with probabilities for taking alternative paths , and
with information about the case generation scheme . this scheme determines the
arrival process, e.g., how many new cases arrive per time unit (on average) at
the process.
9extracting this information from the log is relatively easy because for each
‘start’ and ‘complete’ event in the event log the exact time stamp is given.
together with the discovered petri net we can replay6each process instance in
the petri net so that information about execution and waiting times is collected
for the activities in the process [11]. furthermore, for each decision point we can
derive the probabilities of alternative paths based on how often each path was
followed during log replay. finally, the arrival rate of cases can be easily derived
from the start times of the ﬁrst activity in each process instance.
during the replay of the log several statistics can be collected for the execu-
tion and waiting times, and for how many cases arrive at the process per time
unit. these statistics are values like minimum, maximum, mean, variance, etc.
in general, we do not know the underlying distribution for the obtained execu-
tion and waiting times, and we assume that they follow a normal distribution.
however, we could easily have selected another distribution. similarly, we do
not know the “real” distribution of the case generation scheme, and we assume
a negative exponential distribution for the interarrival process (i.e., a so-called
poisson arrival process). to specify the execution and waiting times in terms
of a normal distribution, we need to calculate their mean and variance values
for each activity. the intensity parameter of the exponential distribution is ap-
proximated by the mean value of all measured inter-arrival times (i.e., the times
between the start of two new cases). all the values are measured in minutes.
afirst 
visitlab
test
x rayecg
ecg not 
neededsecond 
visitct
mrithird 
visit b
cd
efg
hi0.72
0.50.50.28
0.280.72
0.0167 new cases 
per minute
w: n(0.0, 0.0)e: n(0.0, 0.0)
w: n(7233.9, 468.0)e: n(60.4, 6.2)
w: n(1450.8, 471.6)e: n(29.9, 5.1)w: n(4320.4, 486.1)e: n(45.1, 1.7)
w: n(2894.5, 957.1)e: n(30.1, 5.2) w: n(0.008, 0.2)e: n(30.0, 5.1)
w: n(30.1, 5.1)e: n(20.0, 1.6)  e: n(45.2, 5.1)
w: n(0.0, 0.0)
w: n(29.8, 4.9)e: n(20.1, 1.8)
fig. 7. example model enhanced with the performance perspective. for each activ-
ity the execution time (e) and waiting time (w) are given as a normal distribution
n(arithmetic mean, standard deviation). moreover, the probabilistic values for select-
ing an alternative path at a decision point and the case arrival rate are provided
6we assume that each process instance can be replayed correctly in the discovered
petri net (see [18] for further details). if, e.g. due to noise, not all instances ﬁt the
model, then the non-ﬁtting instances can easily be ignored.
10the collected values for the outpatient clinic example are shown in figure 7.
for example, one can see that the execution time of activity “ct” has a mean
of 45 .1 minutes and a standard deviation of 1 .7. similarly, the waiting time of
activity “ct” has a mean of 4320 .4 minutes and a standard deviation of 486 .1.
for the case generation scheme we have an intensity of about 0 .0167 new cases
arriving per minute, i.e., on average one case arrives per hour. moreover, in
figure 7 one can also see the probabilistic values for selecting an alternative
path at a decision point. for example, based on the observations from the log
it seems more likely that an “ecg” is needed (72% of the cases) than that it is
not needed (only 28%).
3.4 role discovery
now we move our focus onto the organizational perspective of the process. or-
ganizational mining aims at discovering both the organizational model (i.e., the
relationships between resources and their roles or functional units) and assign-
ment rules (i.e., the relationships between roles or functional units and activ-
ities) [22]. an organizational model usually contains organizational units (e.g.,
functional units), roles (e.g., duty), resources, and their relationships (i.e., who
belongs to which functional unit, who plays what roles, hierarchy among organi-
zational units). by just using an event log, it is diﬃcult to discover the diﬀerences
between all of these notions. however, it is possible to derive resource groups
in which the people are allowed to execute similar activities. from a “proﬁle”
describing how frequently individuals conduct speciﬁc activities, we can derive
groups. such a discovered group of resources may correspond to an organiza-
tional unit or a union of people who perform the same roles in real life. in this
paper, we will mostly use the term “role” to refer to such a group of resources
that have a similar activity proﬁle.
in this paper, we applied the metrics based on joint activities proposed in [1]
to derive roles. metrics based on joint activities focus on the activities that
resources perform. we assume that people doing similar things are more closely
linked than people doing completely diﬀerent activities. each individual has a
“proﬁle” in the originator by activity matrix based on how frequently it conducts
speciﬁc activities. table 1 shows a part of the originator by activity matrix
derived from the log in section 2.
from this matrix, we can measure the “distance” between the proﬁles of dif-
ferent originators by comparing the corresponding row vectors. we calculated
pearson’s correlation coeﬃcient to quantify this “distance”. pearson’s correlation
coeﬃcient produces values ranging from −1.0 to 1 .0. since the positive values im-
ply positive linear relationships between variables, we applied the threshold value
of 0.0 and removed negative relationships. this way, ﬁve clusters are derived,
namely {jan, martin, rose, vanessa },{claire, jo, valentine },{fred, wilma,
vic},{alex, eric, jane, maria, nigel, ralph }, and {nobody }. these clusters
correspond to roles. note that the latter role ( {nobody }) is a bit artiﬁcial. then,
we assigned the clusters to activities based on an entity assignment method. if
an originator executed an activity, the activity is assigned to the cluster to which
11table 1. a part of the originator by activity matrix, where it is shown how often each
resource performed each activity
originator first lab x ray ecg ecg not second ct mri third
visit test needed visit visit
... . . . . . . . . .
claire 0 310 0 0 0 0 0 0 0
jan 260 0 0 0 0 239 0 0 129
jane 0 0 154 0 0 0 47 45 0
jo 0 349 0 0 0 0 0 0 0
maria 0 0 158 0 0 0 40 41 0
martin 244 0 0 0 0 248 0 0 138
nigel 0 0 178 0 0 0 52 42 0
ralph 0 0 188 0 0 0 46 47 0
rose 239 0 0 0 0 250 0 0 140
... . . . . . . . . .
the originator belongs. for example, according to the log fragment depicted in
figure 3 nigel executed the activity “x ray”, and, therefore, “x ray” is assigned
to the role of nigel , i.e., “radiology department”.
ecg not 
neededgynaecology 
departmentclinical
chemistrycardiology
departmentradiology
department
first 
visitsecond 
visitthird 
visitlab
testecg x ray ct mrinobodyvanessa
janmartin
roseclaire jovalentine fred
wilmavic
alexeric
nigel janemaria ralph
nobody
fig. 8. example model enhanced with the organizational perspective. the boxes rep-
resent activities, the pentagons represent roles, and the circles represent originators
figure 8 shows the derived roles, and the relationships between roles and
activities for the outpatient clinic example. the detected clusters correspond
to the “gynaecology department” (jan, martin, rose, and vanessa), “clinical
chemistry” (claire, jo, and valentine), “cardiology department” (fred, wilma,
and vic), and “radiology department” (alex, eric, jane, maria, nigel, and
ralph), respectively. the “gynaecology department” is involved in the “first
visit”, “second visit”, and “third visit” of the patient, while the “lab test” is
done by the “clinical chemistry”. the “cardiology department” is in charge of
the “ecg” activity, and the “radiology department” is related to the medical
12imaging activities such as “x ray”, “ct”, and “mri”. the cluster “nobody”
does not contain a real resource from the outpatient clinic, but only a dummy
originator that was used for activity “ecg not needed” (in the case that activity
“ecg” can be skipped).
4 model integration and evaluation
in the previous section we have seen how diﬀerent characteristics of a process
can be extracted from an event log. these characteristics can now be used to
construct a simulation model. in this section, we brieﬂy show how the diﬀerent
perspectives are joined into a single model (section 4.1) and represented as a
colored petri net (section 4.2). moreover, we will evaluate how good the cpn
model approximates these characteristics by generating event logs during the
simulation of the model in cpn tools, and the repeated analysis of this “second
pass” (section 4.3). for this, the same algorithms will be used as in section 3,
and the results of the “ﬁrst pass” and “second pass” will be compared to each
other.
4.1 merging perspectives
to get a better view on the process as a whole, it is useful to integrate the
discovered perspectives in one holistic model. note that in the case of the run-
ning example, this is fairly easy as the discovered process characteristics are
largely orthogonal to each other (i.e., there is no conﬂicting information). we
take the control-ﬂow perspective as a starting point for the integrated model.
subsequently, all information connected to an activity in the data, resource, and
performance perspective is attached to the same activity in the holistic model.
finally, process-related information, such as case generation scheme, roles, and
groups, is copied to the holistic model.
figure 9 shows the integrated model for our example process. for example,
activity “ecg” is only needed for patients who are older than 60 or have an
asa greater than 2, the corresponding execution time is on average 30 minutes
(with a standard deviation of 5.1), and the “cardiology department” is in charge
of the activity.
4.2 cpn model
the integrated model now contains key characteristics of the outpatient clinic
process from diﬀerent perspectives. as a next step, we want to represent these
characteristics in an actual, executable simulation model. it is clear that a simu-
lation model can only capture certain aspects of a process, and that simplifying
assumptions must be made to approximate the real behavior.
we selected colored petri nets (cpns) [12, 13] as a representation because
of their expressiveness and the strong simulation capabilities of cpn tools [23].
furthermore, the hierarchy concept allows for the composition of a cpn model
13first 
visitlab test
x rayecg
ecg not 
neededsecond 
visitct
mrithird
visit
age
diagnosisasaif (age > 60) 
or (asa > 2) 
if (age <= 60) 
and (asa <= 2) if (diagnosis = corpus carcinoma) 
or (diagnosis = ovarium carcinoma) 
if (diagnosis = vulva carcinoma) 
or (diagnosis = cervix carcinoma) radiology 
departmentradiology 
departmentradiology 
department
gynaecology 
departmentgynaecology 
departmentgynaecology 
departmentcardiology 
departmentclinical 
chemistry
nobody
 w: n(29.8, 4.9) e: n(20.1, 1.8)
w: n(0.0, 0.0)e: n(0.0, 0.0)
w: n(7233.9, 468.0)e: n(60.4, 6.2) w: n(1450.8, 471.6) e: n(29.9, 5.1)
 w: n(4320.4, 486.1) e: n(45.1, 1.7)
 w: n(2894.5, 957.1) e: n(30.1, 5.2)w: n(0.008, 0.2) e: n(30.0, 5.1)
w: n(30.1, 5.1) e: n(20.0, 1.6)   e: n(45.2, 5.1)
w: n(0.0, 0.0)
0.72
0.50.5 0.28
0.280.720.0167 
new cases per minutefig. 9. example model with integrated data, organizational and performance view
in a modular way (and, therefore, for diﬀerent levels of abstraction). the time
concept and the availability of many probability distributions in cpn tools
allow for the modeling of performance aspects. moreover, by introducing resource
tokens also organizational and work distribution aspects can be modeled. finally,
data-related aspects can be modeled by introducing data tokens.
in [21], we proposed a cpn representation for business processes that is able
to capture diﬀerent perspectives of a process. this cpn representation is generic
and suitable for automatic generation, while it remains readable for a human
analyst. we developed a cpn export plug-in, which can generate such cpn
models. to make use of the simulation facilities of cpn tools, the actual pro-
cess model is provided together with a simulation environment, which generates
cases, initializes data etc. furthermore, for each activity in the process, a sub-
page is created containing the actual simulation information. depending on the
selected process characteristics, these activity sub-pages may look very diﬀerent.
as an example, the sub-page of activity “ct” is depicted in figure 10. it
covers information from all the perspectives that were previously discovered:
– the sub-page for the “ct” activity contains schedule ,start and complete
transitions to incorporate the waiting time and execution time of the activ-
ity. according to the time delay that is generated by the normal distribution
for the waiting time (cf. outgoing arc of the “ct schedule” transition), the
case token is remains in place w(i.e., waiting state) while model time pro-
gresses. similarly, a case token resides in place efor a while until the corre-
sponding execution time delay has passed (cf. outgoing arc of the “ct start”
transition).
– the “ct” activity may only be executed by people of the radiology de-
partment . this is modeled by deﬁning a separate color set with the name
radiology department, which contains only the people that belong
14ct_schedule
resources
resourcescase data
case data
e w p0
incase data
resourcesc
p1
outc
case_idc
[(#diagnosis data = corpus_carcinoma)
 orelse (#diagnosis data = ovarium_carcinoma)](c,data)
c@+
round(normal(4320.4,236262.4)*1.0)
(c,radiology_department)
radiology_departmentradiology_department
["ralph", "nigel", "martin",
"vic", "eric", "vanessa", "wilma","jane", "valentine", "rose", "fred","claire", "jan", "alex", "maria","nobody", "jo"](c,radiology_department)@+
round(normal(45.1,2.9))
ct_start ct_complete
case_idxradiology_departmentcase_idxdata
case_idcase_idin out
resourcefig. 10. sub-page for the “ct” activity, showing how the simulation information re-
lated to the “ct” activity is represented in the cpn model
to this department. then, a variable “radiology department”, which is of
type radiology department, can be used to match the required role
for the activity. in this way, only the resources that belong to this color set
can be consumed by transition “ct start”, i.e., the selection of a token from
place “resources” is limited by the type of this variable. as soon as tran-
sition “ct start” is ﬁred, the corresponding resource token resides in the
place eand it is not available for concurrent executions of further activities,
until transition “ct complete” ﬁres and puts the token back.
– the “ct” is only required for patients with diagnosis “corpus carcinoma”
or “ovarium carcinoma”. this is represented in the cpn by the guard that
belongs to the “ct schedule” transition. if this transition is enabled from
a control-ﬂow perspective, it additionally needs to satisfy the given guard
condition to be ﬁred. to check the value for the “diagnosis” data attribute,
a double arc is modeled between the “ct schedule” transition and the “case
data” place, which contains all data attributes.
note that in the combination of diﬀerent process characteristics we have
to make choices. for example, in figure 10 one can see that the decision to
perform a ct (instead of an mri) is based on the value of a data attribute (i.e.,
the diagnosis of the patient). however, we could have also chosen to base the
decision on stochastic values (i.e., probabilities of alternative paths).
15note that the integrated process and the cpn fragment shown in ﬁgures 9
and 10 are generated automatically without any human intervention or modeling.
however, users can inﬂuence the model generation by changing the settings or
adding explicit information.
4.3 evaluation “second pass”
the discovered simulation model can be used for all kinds of analysis (e.g., what-
if analysis for estimating the eﬀects of some redesign). however, we assume that
the reader is aware of the practical relevance of simulation. therefore, this section
focuses on the validation of the approach.
it is clear that the value of a simulation-based analysis largely depends on
the quality and validity of the simulation outcomes. the validity of the represen-
tation of the selected key characteristics is one important aspect that needs to
be ensured when approximating a real-life process by a simulation model. there-
fore, we want to evaluate how good our simulation model captures the discovered
process characteristics. other aspects, such as the validity of the recorded log
data (which is used as input for the described process discovery techniques),
are beyond the scope of this paper, and we assume that the event log contains
representative behavior for the original process.
the following approach has been taken: for the cpn model described in the
previous section, a simulation was run for 1000 cases. during the simulation in
cpn tools, separate event logs were generated for each case. these event logs can
be created by extending the cpn model with monitors, which log the occurrence
of each transition on the sub-page of an activity, as discussed in [7] and [21]. note
that the export plug-in automatically adds monitors to the cpn models and
also produces output that can be converted into mxml using the prom import
framework. the resulting mxml ﬁles can again be used as input for the mining
algorithms. the analysis of the simulated event log based on the discovered
model is called the “second pass”. in the “second pass”, the same algorithms
as those used in section 3 to discover the control-ﬂow, data, performance and
resource perspective are deployed, but now for the newly generated mxml ﬁle.
the results obtained for the control-ﬂow, data, and resource perspective are
exactly the same as in the previous analysis, i.e., they can be completely rediscov-
ered. the results obtained for the performance perspective are also very similar.
in the second pass, we have an intensity of about 0 .0163 (instead of 0 .0167) new
cases arriving per minute, and we get the same probability values for the alter-
native branches. figure 11 depicts the execution time and waiting time values
obtained from both the original log (ol) and the second pass (sp), which are
almost identical.
with regard to our artiﬁcial example, the discovered cpn model coincides
with the original model, i.e., it is possible to completely rediscover the model from
the event logs. this serves as a proof-of-concept, i.e., it is possible to discover
simulation models. in section 6, we will investigate this further by evaluating the
quality of the generated simulation models for two real-life examples. however,
we ﬁrst present the software supporting our approach.
16fig. 11. execution time and waiting time results obtained for the original log (ol)
and the second pass (sp) of the running example. one can see that both the arithmetic
mean (mean) and the standard deviation (std) of ﬁrst and second pass are very close. in
fact, it is diﬃcult to distinguish the lines relating to ol and sp because they coincide
in each of the three graphs
5 simulation models in the prom framework
theprocessmining ( prom ) framework is an extensible tool suite that supports
a wide variety of process mining techniques in the form of plug-ins. in this section,
we describe how the presented discovery approach is supported by the prom tool.
a set of plug-ins is available to discover and integrate diﬀerent characteristics of
a process from an event log, and to generate a cpn model that can be directly
used for simulation. we shortly explain the functionality, and show screenshots
using the running example7.
as can be seen in figure 4, we start with an event log. to discover the control-
ﬂow perspective a number of diﬀerent algorithms are available. we choose the
alpha algorithm plug-in, which constructs a process model in terms of a petri
7note that the event log of the running example used in this paper can be downloaded
together with prom from www.processmining.org .
17net. based on this process model and the log, we can discover the performance
perspective of the process by applying the performance analysis with petri
netplug-in. a screenshot of the analysis results for the example process is shown
in figure 12(a). the plug-in evaluates the time stamps in the log and projects
the extracted performance information on places and transitions. it graphically
shows the bottlenecks by coloring places according to the time that is spent in
this part of the process (red indicates a high waiting time, while blue means less
waiting time). furthermore, it provides performance indicators, such as average,
variance etc. of the execution time of an activity, or the time spent at a certain
place or between two selected activities. for example, in figure 12(a), we can
see several statistics for the waiting, execution and sojourn time of the “second
visit” activity, which we have selected.
the data perspective of the process can be discovered using the decision
point analysis (also called decision miner) plug-in. this plug-in analyzes the
data attached to events and using classical decision tree analysis it is possible
to add decision rules to the petri net. these decision rules are presented as
conditions on arcs. a screenshot of the plug-in is shown in figure 12(b). for
example, in figure 12(b), we can see the decision tree that has been discovered
for the choice between “ecg” and “ecg not needed” in the outpatient clinic
process.
the resource perspective can also be discovered by applying the organiza-
tional miner plug-in. this plug-in analyzes information about resources in the
event log and returns information about the relationship between activities and
originators which can also be visualized. among others, resources that perform
similar activities or are working together can be discovered and grouped together.
in this way, allocation rules can be added to activities. a screenshot of the plug-
in is shown in figure 12(c), where the people that are working on activities in
the “gynaecology department” are shown (represented as minedgroup3 ).
these three discovery plug-ins now oﬀer each a simulation model with ad-
ditional information about the process (e.g., the arrival rate of new cases), or
speciﬁc activities in the process (e.g., by which group of people it was performed).
but before we can integrate the diﬀerent perspectives into one model, we ﬁrst
have to transform the discovered petri net model with the combine low-level
activities plug-in. this step is necessary because we start with a log that con-
tains transactional information (i.e., the start and completion of an activity). as
a consequence, each ‘start’ and ‘complete’ event in the log is represented as a
separate activity in the discovered process model (for example, in figure 12(a)
you can see both activity “ct start” and activity “ct complete”). however,
because we want to link the obtained information to activities as a whole, we
combine these low-level tasks that belong to one activity into a single transition
in the petri net model. since this is rather a technicality and not essential for
understanding the functionality, we will not elaborate on this.
as a next step, the diﬀerent, now activity-based simulation models can be
integrated into one model with the help of the merge simulation models plug-
in. note that, although we use petri nets, a simulation model may be based
18fig. 12. discovery plug-ins in the prom framework
19fig. 13. integration and export plug-ins in the prom framework
20on any kind of process model and prom supports diﬀerent model conversions.
for example, in event-driven process chains (epcs) activity-related informa-
tion could be mapped to functions, decision point-related information to xor
connectors etc. for this, a reference model is chosen among the input models as
a “template” for the output model (and the activities from the diﬀerent input
models are mapped on their corresponding activities in the output model). for
each perspective, we can then determine from which of the (potentially con-
ﬂicting) input models the information should be included. for example, in the
screenshot in figure 13(a), we select to retain the characteristics delivered by
the decision miner for the data attributes in the merged simulation model.
finally, we want to generate a cpn from the integrated model, which can
be read and simulated by cpn tools. to this end, we use the cpn tools 2.0
export plug-in, which displays all the discovered process characteristics before
the actual export takes place. we can also modify the given settings (“what if”
analysis), and provide additional information. for example, we may choose to
give meaningful names to the discovered resource clusters, i.e., minedgroup3 =
“gynaecology department” etc. furthermore, it is possible to choose diﬀerent
conﬁguration options. for example, each choice in the process may be either
based on data rules or stochastic properties, logging monitors can be generated,
and we can either include or exclude the modeling of explicit waiting time (to
include waiting time, a ‘schedule’ transition will be generated for each sub page
as shown in figure 10, otherwise it will be left out). a screenshot of the plug-
in is shown in figure 13(b), where one can see the provided data attributes,
associated resource group, and the execution time settings for activity “first
visit”. after exporting, cpn tools can be used to simulate the process without
adding any additional information to the generated model.
we have demonstrated that the discovery of a simulation model as presented
in this paper is completely supported by the prom framework. although a num-
ber of diﬀerent plug-ins must to be applied to arrive at the cpn model, sensible
default settings and a convenient user interface make it possible to quickly ex-
plore diﬀerent variants.
6 case studies
to further validate the approach discussed in this paper, we have performed two
case studies. they are based on process logs from two diﬀerent municipalities
in the netherlands. in these case studies, we focus on the quality of the simula-
tion models rather than on the discovered process characteristics. similar to the
running example, we ﬁrst perform process mining to discover several perspec-
tives (control-ﬂow, data, performance, and organization), and generate a cpn
from the integrated model. then, an event log is generated during simulation in
cpn tools, and re-analyzed with prom to compare the results of this second
pass with the initial analysis results. we also investigate the results according
to diﬀerent simulation conﬁgurations.
216.1 case study i
the case study is conducted based on real-life logs from a municipality in
the netherlands. the municipality uses a workﬂow system developed using the
“eastman software workﬂow for nt”. this systems is, among others, used to
handle complaints. we obtained a log from this workﬂow system for the com-
plaint handling process, which we converted to the mxml format via a plug-in
in the prom import framework [9]. when the municipality receives a complaint,
they ﬁrst initiate a process instance. then it is prepared (the case is investi-
gated) and assigned to a suitable activity out of four actual complaint handling
activities. then, the case is moved to the assigned activity and, after it has been
handled, the process is ﬁnished. the particular event log we use in this section
contains 363 cases. the number of total events is 1,817, and the log has ﬁve
diﬀerent activities. each activity is recorded by logging ‘start’ and ‘complete’
events. 13 employees participated in the process execution, and the log contains
15 diﬀerent data elements such as the id of the case, queue of activities in the
workﬂow engine, priority of the task, etc.
figure 14 shows some screenshots of the mining results. we used the alpha
miner in prom to discover the process model. the resulting process model has
100% ﬁtness (i.e., every trace in the log complies with the discovered model).
the average waiting time of activities in this complaint handling process is 45.7
hours, while the average execution time of activities is only 5.1 hours. the over-
all processing time is 72.6 hours, and a new case is generated every 12.4 hours
(on average). the decision point analysis result shows that the choice is pre-
dominantly based on the value of the data attribute “queue” (which determines
the activity that is scheduled next in the workﬂow engine). from the discovered
rules, it seems as if the most frequent branch “ag08 gba afnemer”8, which is
executed in 88% of the cases, is also the default branch if none of the four com-
plaint handling activities has been explicitly scheduled (in this case the “queue”
still contains one of the previous activities). from the organizational miner, 6
roles are derived and 13 originators are assigned to clusters based on the execu-
tion history in the log.9
table 2. conﬁgurations of the three simulation models
m0 m1 m2
control flow include include include
organizational model include include include
decision rule data attribute data attribute probability
performance info execution time execution time execution time
no waiting time 95% waiting time 95% waiting time
8note that, because there is no need to understand the process in detail, we did not
translate the dutch activity names.
9note that, figure 14(c) and figure 17(c), the names of originators are erased to
ensure conﬁdentiality and privacy.
22fig. 14. mining results: (a) performance values (b) decision rules (c) organizational
model
23from the mining results, three models are generated with diﬀerent conﬁgura-
tions on decision rules and waiting time. table 2 summarizes the conﬁgurations
of the three models. the ﬁrst model (m0) and the second model (m1) combine
all the four mining results and use the data perspective from the decision miner
for the decision rule. in contrast, the third model (m2) uses probabilities (i.e.,
a stochastic approximation) to make the choice of the subsequent activity. fur-
thermore, the waiting time is determined only by resources in m0 (if all resources
of a certain type are occupied, an activity might have to wait until a resource
becomes available again and it can be started). in contrast, m1 and m2 contain
extra waiting time (95% of the observed waiting time) in addition to the waiting
time that results from the unavailability of resources.
note that waiting time may result from competing for resources with other
cases inside the same process and competition between processes. for example,
an employee may be involved in multiple processes that are all competing for
the employee’s attention. although the cpn model only considers the complaint
handling process, the employees of the municipality also work on other processes.
therefore, it is necessary to add waiting time in addition to the simulated queue-
ing time resulting from the competition with other complaints. since the total
waiting time is measured by prom, it is only natural to add part of this time.
therefore, we added 95% of the observed waiting time to m1 and m2. note that
this is a necessary approximation when analyzing a process in isolation.
we perform simulations and analyze the generated process logs; each of them
contains 400 cases. we obtain the same process models and organizational mod-
els. the same decision rules are derived from the logs from m0 and m1 (since
m2 does not contain the data perspective, it has no information about data).
figure 15 shows the performance analysis results including the performance val-
ues from the original log (ol). figure 15(a) shows the execution times of the
activities. the values for all the three models are comparable to each other. fig-
ure 15(b) shows the waiting times. the values from m0 are much smaller than
the others. in the real world, resources deal with several activities in the organi-
zation and perform their work based on their own schedule. however, since we
handle not all processes but only one process, we cannot take this situation into
account. thus, the number of resources obtained from process logs is generally
large enough to immediately execute activities. to compensate this, we intro-
duce extra waiting time. if we add an additional delay of 95% of the observed
waiting time (m1, m2), waiting times are similar to the values from the original
log. note that the waiting time generated by the simulation model is the sum of
the delays resulting from the queuing of complaints and the added extra waiting
time.
figure 16 shows the probability values for choosing a particular path when
visiting the decision point shown in figure 14(b). the names on the horizontal
axis refer to the activities following the decision point. when we use decision
rules based on data attributes (m0, m1), the probability values are diﬀerent from
the original values. this is because the value on the decision variable is randomly
generated by the model. only if we use probability values, the result is almost
24fig. 15. performance analysis results based on the original log (ol) and the three
discovered simulation models
same. note that in the running example the probabilities did match because we
generated the log with decisions based on data in the ﬁrst place. however, in
this section we use a real-life log where this is not the case, thus explaining the
diﬀerences. note that the diﬀerences in the probabilities of an alternative branch
(i.e. m0, m1) also inﬂuence the throughput time of the process. for example, the
increase of the possibility of an activity, which has long waiting and execution
times, increases the throughput time of the process.
fig. 16. probabilities for the decision point shown in figure 14(b)
6.2 case study ii
the second case study deals with a log that we obtained from the urban manage-
ment service of a local municipality of 90,000 citizens, situated in the northern
part of the netherlands. they have implemented their own custom-made work-
ﬂow system. from the workﬂow system, we extracted process logs and converted
25them into the mxml format. we use the log of the handling of invoices in 2005.
the log data contains 570 cases. the number of total events is 6,616. the process
consists of 10 activities, and 110 employees participated in the process execution.
for the ﬁrst activity only ‘complete’ events are recorded, but the other activi-
ties record both ‘start’ and ‘complete’ event. the general procedure is that an
invoice is scanned and subsequently sent by the workﬂow management system
to the central ﬁnancial department. a clerk registers the invoice, after that it is
sent to the proper local ﬁnancial oﬃce. depending on the kind of invoice, there
are various checks that need to take place: the person responsible for the budget
that is used for the purchase must approve (the budget keeper); the ﬁt between
the purchase with the supplier’s contract (if any) must be established; various
managers may be required to authorize the invoice depending on the amount of
money involved etc. eventually, a purchase may be paid by the central ﬁnancial
oﬃce.
from the process logs we derived a model for the control-ﬂow perspective
and extended the model with characteristics from the performance and orga-
nizational perspectives. note that, since the original log does not contain any
data, we cannot perform the decision point analysis. after integrating the dis-
covered models, we generate simulation models with diﬀerent conﬁgurations of
the waiting time.
figure 17 shows the mining results. we generate the process model with the
heuristic miner in prom. figure 17(a) shows the generated model in terms of a
petri net10. the generated model has 100% ﬁtness with respect to the log (i.e.,
it completely captures the behavior from the log). to calculate performance in-
formation such as execution time and waiting time, we create a petri net model
including start and complete tasks and use the performance analysis plug-in.
figure 17(b) shows the results of this performance analysis. the overall process-
ing time is 182 hours (about a week). a new case is started every 50 minutes (on
average). we also generate an organizational model as shown in figure 17(c).
10 roles are derived and employees are assigned to the roles. table 3 shows the
performance analysis results for the ﬁve major activities in the process. similar
to the previous case study, one can observe that the waiting times are by a mul-
tiple higher than the execution times in the process. this is very typical for a
real-life process, where much time is spent on administration, synchronization,
etc. the table also shows organizational mining results. it shows the number of
resources who are involved in the execution of each activity.
from the mining results, two models are generated with diﬀerent conﬁgura-
tions on the waiting time. in the ﬁrst model (m0), the waiting time is determined
only by resources, while the second model (m1) contains extra waiting time
(100% of the observed waiting time). figure 18 shows the generated simulation
model (m0) in cpn tools. note that the petri net includes invisible activities
(i.e., transitions that do not correspond to an event in the log and that are only
10note that the prom framework supports various conversions between modeling lan-
guages, such from petri nets to heuristic nets, epcs, yawl and vice versa.
26fig. 17. mining results: (a) control ﬂow (b) performance values (c) organizational
model
table 3. organizational mining and performance analysis results for the ﬁve main
activities in the process
execution time (minutes) waiting time (hours) # of resources
codfctbf 3.71 29.7 76
contruif 1.75 17.9 3
routefez 5.05 39.7 25
contrcod 2.71 22 24
fbconcod 2.85 66.5 7
27executed to enable “real activities”). they are denoted as small tasks ﬁlled with
black color.
fig. 18. simulation model in cpn tools
with each simulation model, we generate 600 cases and analyze the gener-
ated process logs with the prom. the process model discovered by the heuristic
miner from the simulated process log equals to the original model in figure 17(a).
the organizational model is also re-discovered. figure 19 shows the performance
analysis results. figure 19(a) shows the execution times of the activities. as be-
fore, the results are very similar. figure 19(b) shows the waiting times. in m0, no
waiting times are observed due to the small execution times, and the big number
of available resources. the reason is that we observe one process in isolation, i.e.,
we do not see the activities that resources perform for other processes. hence,
utilization of resources is low and there is hardly any queueing due to compe-
tition between cases. since the processing times are negligible compared to the
observed waiting times, we add an extra delay of 100% of the observed waiting
time (m1). as a result of this intervention, the waiting times are similar to the
values from the original log.
in these two case studies, we have generated simulation models from real-life
process logs with the method proposed in this paper. we have also investigated
the quality of the simulation models by analyzing the generated process logs and
comparing the results with the original mining results. to derive a simulation
model that reﬂects the real situation as precisely as possible, the model should be
properly conﬁgured. for example, a proper decision policy must be chosen, and
adding extra waiting time may help to better approximate the timing behavior
in a simulation model.
28fig. 19. performance analysis results for the original log (ol) and the two discovered
models (m0 and m1)
7 related work
the work reported in this paper is related to earlier work on process mining,
i.e., discovering a process model based on some event log. the idea of applying
process mining in the context of workﬂow management was ﬁrst introduced in
[5]. cook and wolf have investigated similar issues in the context of software en-
gineering processes using diﬀerent approaches [6]. herbst and karagiannis also
address the issue of process mining in the context of workﬂow management using
an inductive approach [10]. they use stochastic task graphs as an intermediate
representation and generate a workﬂow model described in the adonis mod-
eling language. the αalgorithm [4, 24] was one of the ﬁrst algorithms to truly
capture concurrency. in [4] it is shown that this algorithm can be proven to be
correct for a large class of processes. over time many variants and extensions of
the αalgorithm have been proposed. in [24] a heuristic approach using rather
simple metrics is used to construct so-called “dependency/frequency tables” and
“dependency/frequency graphs”. this is used as input for the αalgorithm. as
a result it is possible to tackle the problem of noise. for more information on
process mining we refer to a special issue of computers in industry on process
mining [3] and a survey paper [2].
existing process mining approaches have been mainly focusing on the control-
ﬂow perspective. some initial work has been done for discovering social networks
in the context of process mining [1] and decision point analysis [20]. however,
these techniques do not provide an integrated view and do not aim at simulation.
this paper is mostly related to [21] where the cpn export of prom is described.
however, the focus of [21] is not on process mining and no case studies are given.
there is quite some work on the automatic generation of petri net models
for workﬂows. a typical example is described in [8] where the authors present a
translation of protos simulation models to cpn tools. in addition, three types
of data collector monitors (measuring the total ﬂow time per case, the waiting
time per task, and the resource availability/utilization per resource type), and
conﬁguration features enabling the dynamic elimination of unnecessary parts of
29the process model are generated. besides the work in [8], we are not aware of
further attempts to export business process models to cpn tools. the work
reported in this paper has a diﬀerent starting point as it is not limited by the
simulation information present in a protos model, but aims at discovering the
process characteristics to be simulated from the event logs of real process exe-
cutions.
8 conclusion
this paper demonstrates that it is possible to automatically construct simula-
tion models based on event logs. these simulation models need to cover diﬀerent
perspectives: control-ﬂow, data, resources, time, etc. therefore, we showed that
each of these perspectives can be discovered using existing process mining tech-
niques and that all these mining results can be merged into a single simulation
model.
the approach has been implemented in the context of prom and has been
tested using diﬀerent examples. in this paper, we used an artiﬁcial example and
two case studies to evaluate our approach. based on this we can conclude that it
is indeed possible to automatically construct simulation models based on event
logs. the discovered models can be exported to cpn tools which allows for all
kinds of simulation. using the monitoring functionality of cpn it is possible
to do all kinds of measurements and to feed the results back to prom. in this
paper, we did not focus on the analysis of the processes of the two municipalities
(although extensive simulation studies have been done by students doing their
ﬁnal master projects in these two municipalities). the reason is that it is obvious
that good simulation models have a high practical value. therefore, we focused
on the validation of our approach.
given the relevance of simulation and the problems people have making good
simulation models, we will continue to work on the topics mentioned in this
paper. we are exploring various ways to improve the various plug-ins mentioned.
moreover, we would like to improve the modeling of human behavior. note that
in the case studies people were only working part-time on the processes at hand.
as a result, we had to add additional waiting time to the models based on an
analysis of the log. however, this is not satisfactory since it does not really
capture the way that people actually work. other directions of future work are
the automated support of redesign (i.e., suggesting process improvements based
on log analysis and simulation of alternatives [15]) and the use of simulation for
real-time decision making (i.e., making recommendations for current cases based
on a mixture of process mining and short-term simulation [17]).
acknowledgements
this research is supported by the technology foundation stw, eit, super,
nwo, and the iop program of the dutch ministry of economic aﬀairs. fur-
thermore, the authors would like to thank all prom developers for their on-going
30work on process mining techniques. we would also like to thank lisa wells and
kurt jensen for their support in using cpn tools.
references
1. w.m.p. van der aalst, h.a. reijers, and m. song. discovering social networks
from event logs. computer supported cooperative work , 14(6):549–593, 2005.
2. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
3. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining , special
issue of computers in industry, volume 53, number 3. elsevier science publishers,
amsterdam, 2004.
4. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128–1142, 2004.
5. r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
ﬂow logs. in sixth international conference on extending database technology ,
pages 469–483, 1998.
6. j.e. cook and a.l. wolf. discovering models of software processes from event-
based data. acm transactions on software engineering and methodology ,
7(3):215–249, 1998.
7. a.k. alves de medeiros and c.w. guenther. process mining: using cpn tools
to create test logs for mining algorithms. in k. jensen, editor, proceedings of
the sixth workshop and tutorial on practical use of coloured petri nets and the
cpn tools , pages 177–190, 2005.
8. f. gottschalk, w.m.p. van der aalst, m.h. jansen-vullers, and h.m.w. verbeek.
protos2cpn: using colored petri nets for conﬁguring and testing business pro-
cesses. accepted for the seventh workshop and tutorial on practical use of
coloured petri nets and the cpn tools, 2006.
9. c.w. g¨ unther and w.m.p. van der aalst. a generic import framework for process
event logs. in j. eder and s. dustdar, editors, business process management
workshops, workshop on business process intelligence (bpi 2006) , volume 4103
oflecture notes in computer science , pages 81–92. springer-verlag, berlin, 2006.
10. j. herbst. a machine learning approach to workﬂow management. in proceedings
11th european conference on machine learning , volume 1810 of lecture notes in
computer science , pages 183–194. springer-verlag, berlin, 2000.
11. p.t.g. hornix. performance analysis of business processes through process min-
ing. master’s thesis, eindhoven university of technology, department of computer
science, eindhoven, the netherlands, 2007.
12. k. jensen. coloured petri nets. basic concepts, analysis methods and practical
use. springer-verlag, 1997.
13. k. jensen, l.m. kristensen, and l. wells. coloured petri nets and cpn tools
for modelling and validation of concurrent systems. international journal on
software tools for technology transfer , 9(3-4):213–254, 2007.
14. t. m. mitchell. machine learning . mcgraw-hill, 1997.
15. m. netjes, i. vanderfeesten, and h.a. reijers. “intelligent” tools for workﬂow
process redesign: a research agenda. in c. bussler and a. haller, editors, busi-
ness process management workshops (bpm 2005) , volume 3812 of lecture notes
in computer science , pages 444–453. springer-verlag, berlin, 2006.
3116. j. r. quinlan. c4.5: programs for machine learning . morgan kaufmann, 1993.
17. h.a. reijers and w.m.p. van der aalst. short-term simulation: bridging the gap
between operational control and strategic decision making. in m.h. hamza,
editor, proceedings of the iasted international conference on modelling and
simulation , pages 417–421. iasted/acta press, anaheim, usa, 1999.
18. a. rozinat and w.m.p. van der aalst. conformance testing: measuring the fit
and appropriateness of event logs and process models. in c. bussler et al., editor,
business process management 2005 workshops , volume 3812 of lecture notes in
computer science , pages 163–176. springer-verlag, berlin, 2006.
19. a. rozinat and w.m.p. van der aalst. decision mining in business processes.
bpm center report bpm-06-10, bpmcenter.org, 2006.
20. a. rozinat and w.m.p. van der aalst. decision mining in prom. in s. dustdar,
j.l. fiadeiro, and a. sheth, editors, bpm 2006 , volume 4102 of lecture notes in
computer science , pages 420–425. springer-verlag, berlin, 2006.
21. a. rozinat, r.s. mans, and w.m.p. van der aalst. mining cpn models: discover-
ing process models with data from event logs. in k. jensen, editor, proceedings of
the seventh workshop on the practical use of coloured petri nets and cpn tools
(cpn 2006) , volume 579 of daimi , pages 57–76, aarhus, denmark, august 2006.
university of aarhus.
22. m. song and w.m.p. van der aalst. towards comprehensive support for organi-
zational mining. beta working paper series, wp 211, eindhoven university of
technology, eindhoven, 2006.
23. a. vinter ratzer, l. wells, h. m. lassen, m. laursen, j. f. qvortrup, m. s.
stissing, m. westergaard, s. christensen, and k. jensen. cpn tools for editing,
simulating, and analysing coloured petri nets. in w.m.p. van der aalst and
e. best, editors, applications and theory of petri nets 2003: 24th international
conference, icatpn 2003 , volume 2679 of lecture notes in computer science ,
pages 450–462. springer verlag, 2003.
24. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models
from event-based data using little thumb. integrated computer-aided engi-
neering , 10(2):151–162, 2003.
25. i. h. witten and e. frank. data mining: practical machine learning tools and
techniques, 2nd edition . morgan kaufmann, 2005.
32