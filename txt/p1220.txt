privacy-preserving continuous event data
publishing
majid raei
/envelopeand wil m.p. van der aalst
chair of process and data science, rwth aachen university, aachen, germany
abstract. process mining enables organizations to discover and ana-
lyze their actual processes using event data. event data can be extracted
from any information system supporting operational processes, e.g., sap.
whereas the data inside such systems is protected using access control
mechanisms, the extracted event data contain sensitive information that
needs to be protected. this creates a new risk and a possible inhibitor
for applying process mining. therefore, privacy issues in process mining
become increasingly important. several privacy preservation techniques
have been introduced to mitigate possible attacks against static event
data published only once. however, to keep the process mining results
up-to-date, event data need to be published continuously. for example,
a new log is created at the end of each week. in this paper, we elaborate
on the attacks which can be launched against continuously publishing
anonymized event data by comparing dierent releases, so-called corre-
spondence attacks . particularly, we focus on group-based privacy preser-
vation techniques and show that provided privacy requirements can be
degraded exploiting correspondence attacks. we apply the continuous
event data publishing scenario to existing real-life event logs and report
the anonymity indicators before and after launching the attacks.
keywords: process mining Â·privacy preservation Â·correspondence at-
tacks Â·event data
1 introduction
process mining bridges the gap between data science and process science us-
ing event logs. event logs are widely available in dierent types of information
systems [1]. events are the smallest units of process execution which are char-
acterized by their attributes. process mining requires that each event contains
at least the following main attributes to enable the application of analysis tech-
niques: case id ,activity , and timestamp . the case id refers to the entity that the
event(s) belongs to, and it is considered as a process instance. the activity refers
to the activity associated with the event, and the timestamp is the exact time
when the activity was executed for the case. moreover, depending on the con-
text of a process, the corresponding events may contain more attributes. table 1
shows a part of an event log recorded by an information system in a hospital.
in table 1, each row represents an event. a sequence of events, associated
with a case id and ordered using the timestamps, is called a trace. table 2 shows2 majid raei and wil m.p. van der aalst
table 1: sample event log (each row represents an event).
case id activity timestamp resource disease
1 registration (re) 01.01.2019-08:30:00 employee1 flu
1 visit (vi) 01.01.2019-08:45:00 doctor1 flu
2 registration (re) 01.01.2019-08:46:00 employee1 corona
3 registration (re) 01.01.2019-08:50:00 employee1 cancer
... ... ... ... ...
1 release (rl) 01.01.2019-08:58:00 employee2 flu
3 visit (vi) 01.02.2019-10:15:00 doctor3 cancer
2 release (rl) 01.02.2019-14:00:00 employee2 corona
3 blood test (bt) 01.02.2019-14:15:00 employee5 cancer
... ... ... ... ...table 2: a simple event log derived
from table 1 (each row represents
a simple process instance).
case id trace disease
1hre; v i; :::; rli flu
2hre; :::; rli corona
3hre; :::; v i; bt; ::: icancer
... ... ...
a simple trace representation of table 1 where the trace attribute is a sequence
of activities. some of the event attributes may refer to individuals, e.g., the
case id refers to the patient whose data is recorded, and the resource refers to
the employees performing activities for the patients, e.g., surgeons. also, some
sensitive information may be included, e.g., the disease attribute in table 1.
when individuals' data are included in an event log, privacy issues emerge, and
organizations are obliged to consider such issues according to regulations, e.g.,
the european general data protection regulation (gdpr)1.
the privacy/condentiality issues in process mining are recently receiving
more attention. various techniques have been proposed covering dierent as-
pects, e.g., condentiality frameworks [19], privacy guarantees [5,18,11], inter-
organizational privacy issues [3], privacy quantication [20,16], etc. each of these
approaches considers a single event log shared at some point in time. this even
log is published considering the privacy/condentiality issues of a single log in
isolation. however, event logs are recorded continuously and need to be published
continuously to keep the results of process mining techniques updated.
continuous event data publishing lets an adversary launch new types of at-
tacks that are impossible when event data are published only once. in this paper,
we analyze the so-called correspondence attacks [7] that an adversary can launch
by comparing dierent releases of anonymized event logs when they are contin-
uously published. particularly, we focus on group-based privacy preservation
techniques (ppts) and describe three main types of correspondence attacks
including forward attack ,cross attack , and backward attack . we analyze the pri-
vacy/anonymity losses imposed by these attacks and show how to detect such
privacy losses eciently. the explained anonymity analyses could be attached to
dierent ppts to empower them against the attacks or to change the data pub-
lishing approaches to bound such attacks. we applied dierent continuous event
data publishing scenarios to several real-life event logs and report the anonymity
indicators before and after launching the attacks for an example event log.
the remainder of the paper is organized as follows. in section 2, we present
the problem statement. in section 3, the preliminaries are explained. dierent
types of correspondence attacks are analyzed in section 4. in section 5, we
explain the attack detection techniques and privacy loss quantication. section 6
presents the experiments. section 7 discusses dierent aspects to extend the
approach. section 8 discusses related work, and section 9 concludes the paper.
1http://data.europa.eu/eli/reg/2016/679/ojprivacy-preserving continuous event data publishing 3
fig. 1: the general data collection and publishing scenario.
2 problem statement
figure 1 shows our general data collection and publishing scenario. information
systems, e.g., sap, provide operational support for organizations and continu-
ously generate a lot of valuable event data. such data are continuously collected
and published, e.g., weekly, to be used by process mining tools, e.g., prom,
disco, etc. on the analysis side, process mining techniques are applied to event
logs to discover and analyze real processes supported by operational informa-
tion systems. with respect to the types of data holder's models, introduced in
[9], we consider a trusted model where the data holder , i.e., the business owner,
is trustworthy, but the data recipient , i.e., a process miner, is not trustworthy.
therefore, ppts are applied to event logs when they are published.
continuous data publishing is generally classied into three main categories:
incremental ,decremental , and dynamic [8]. continuous event data publishing is
considered as incremental , i.e., the events generated by an information system are
cumulatively collected, and they are not updated or deleted after the collection.
thus, the so-called correspondence knowledge is gained. if we assume that in
a continuous event data publishing scenario, the event logs are collected and
published weekly, the correspondence knowledge is as follows: (1) every case
started in the i-th week is in the i-th event log li, and must be in lj,i<j, and
(2) every case started in the j-th week is in the j-th event log lj, and cannot
be inli,i<j. although each single anonymized event log l0meets the privacy
guarantees specied in the corresponding ppt, the adversary, who has access to
the dierent releases of anonymized event logs, can exploit the correspondence
knowledge to degrade the provided privacy guarantees.
consider table 3 and table 4 as two anonymized event logs, l0
1andl0
2,
published at timestamps t1(week 1) and t2(week 2), respectively. note that
the case identiers are dummy identiers independently assigned to the cases of4 majid raei and wil m.p. van der aalst
table 3: an anonymized event log published at
timestampt1(e.g., week 1), meeting 2-anonymity
and 2-diversity when the assumed bk is a se-
quence of activities with the maximum length 3.
case id trace disease
1ha; b; c; dicorona
2ha; b; c; diflu
3ha; e; difever
4ha; e; dicoronatable 4: an anonymized event log published at
timestampt2(e.g., week 2), meeting 2-anonymity
and 2-diversity when the assumed bk is a se-
quence of activities with the maximum length 3.
case id trace disease
10ha; b; c; dicorona
20ha; b; c; diflu
30ha; b; c; dihiv
40ha; e; difever
50ha; e; dicorona
each release. if we assume that an adversary's background knowledge (bk) is
a sequence of activities with maximum length 3, both published event logs have
2-anonymity and 2-diversity. assume the situation where the adversary knows
thatha;b;ciis a subsequence of activities performed for a victim case, and that
the process of the case has been started in the second week, i.e., it should be
included in table 4. based on the correspondence knowledge, the only matching
case is 30. note that by a simple comparison of l0
1andl0
2based on the disease
attribute, it is obvious that cases 10 and 20 have to be started in the rst week
and cannot match the adversary's bk. this is called backward attack (b-attack)
which is a specic type of the correspondence attacks.
the provided attack scenario shows that when event logs are collected and
published continuously, the corresponding ppdp approaches need to be equipped
with some techniques to detect the potential attacks that can be launched by
an adversary who receives various anonymized event logs. in this paper, we fo-
cus on simple event logs and group-based ppts, i.e., k-anonymity, l-diversity,
t-closeness, etc. we rst describe the approach based on two releases of event
logs, then we explain the possible extensions for any number of releases.
3 preliminaries
we rst introduce some basic notations. for a given set a,ais the set of
all nite sequences over a. a nite sequence over aof lengthnis a mapping
2f1;:::;ng!a, represented as =ha1;a2;:::;aniwhereai=(i) for any 1in.
jjdenotes the length of the sequence. for 1;22a,1v2if1is a subse-
quence of2, e.g.,hz;b;c;xivhz;x;a;b;b;c;a;b;c;x i. for=ha1;a2;:::;ani,
pref()=fha1;:::;akij1kng, e.g.,ha;b;c;di2pref(ha;b;c;d;e;fi).
denition 1 (lcs and scs). let12aand22abe two sequences.
csb (1;2)=f2ajv1^v2gis the set of common subsequences, and
lcs (1;2)=f2csbj802csb (1;2)j0jjjgis the set of longest common
subsequences. lcs12denotes the length of a longest common subsequence for
1and2. also,csp (1;2)=f2aj1v^2vgis the set of common
super-sequences, and scs (1;2)=f2csbj802csp (1;2)j0jjjgis the set
of shortest common super-sequences. scs12denotes the length of a shortest
common super-sequence for 1and2.
denition 2 (event, event log). an event is a tuple e= (c;a;t;r;d 1;:::;dm),
wherec2cis the case id, a2a is the activity associated with the event, t2tprivacy-preserving continuous event data publishing 5
is the event timestamp, r2r is the resource, who is performing the activity,
andd1,...,dmis a list of additional attributes values, where for any 1i
m;di2di. we call=catrd 1:::dmthe event universe. for e=
(c;a;t;r;d 1;:::;dm),c(e)=c,a(e)=a,t(e)=t,r(e)=r, anddi(e)=di,1im,
are its projections. an event log islwhere events are unique.
in continuous event data publishing, event logs are collected and published
continuously at each timestamp ti,i2n1.liis the event log collected at the
timestamp ti, i.e.,li=fe2jt(e)tig. forliandlj, s.t.,i<j,ljcould con-
tain new events for the cases already observed in liand new cases not observed
inli. in the following, we dene a simple version of event logs which will later
be used for demonstrating the attacks and corresponding anonymity measures.
denition 3 (trace, simple trace). a trace=he1;e2;:::;eni2is a se-
quence of events, s.t., for each ei;ej2:c(ei)=c(ej), andt(ei)t(ej)ifi<j.
a simple trace is a trace where all the events are projected on the activity at-
tribute, i.e., 2a.
denition 4 (simple process instance). we denep=cas as the
universe of simple process instances, where sd 1[:::[dmis the domain of the
sensitive attribute. each simple process instance (c;;s )2prepresents a simple
trace=ha1;a2;:::;ani, belonging to the case cwithsas the sensitive attribute
value. forp=(c;;s )2p,c(p)=c,(p)=, ands(p)=sare its projections.
denition 5 (simple event log). letp=casbe the universe of simple
process instances. a simple event log is lp, s.t., if (c1;1;s1)2l,(c2;2;s2)2
l, andc1=c2, then1=2ands1=s2.
4 attack analysis
we analyze the correspondence attacks by focusing on two anonymized releases
obtained by applying group-based ppts to simple event logs. in general, group-
based ppts provide desired privacy requirements utilizing suppression and/or
generalization operations. particularly, the group-based ppts introduced for
the event data protection are mainly based on the suppression operation [5,18],
where some events are removed to provide the desired privacy requirements.
hence, apart from any specic privacy preservation algorithm, we dene a gen-
eral anonymization function that converts an event log to another one meeting
desired privacy requirements assuming a bound for the maximum number of
events that can be removed from each trace, so-called the anonymization param-
eter. note that this assumption is based on the minimality principle in ppdp
[21]. similar attack analysis can be done for the generalization operation as well.
denition 6 (anonymization). letpbe the universe of simple process in-
stances and n2n1be the anonymization parameter. we dene anonn22p!
2pas a function for anonymizing event logs. for all l;l0p,anonn(l)=l0
if there exists a bijective function f2l!l0, s.t., for any p=(c;;s )2land
p0=(c0;0;s0)2l0withf(p)=p0:0v,jj nj0j, ands0=s.6 majid raei and wil m.p. van der aalst
fig. 2:l1andl2are two simple event logs collected at timestamps t1andt2.l0
1andl0
2are the
corresponding anonymized releases of event logs given n=1 as the anonymization parameter. both
l0
1andl0
2have 5-anonymity and 2-diversity assuming a sequence of activities as the bk.
note that we assume the anonymization function promises to preserve all the
cases and not to produce new (fake) cases. figure 2 shows two simple event logs
that were published using the anonymization function given n= 1. specialization
is the reverse operation of the anonymization dened as follows.
denition 7 (specialization). letpbe the universe of simple process in-
stances and n2n1be the anonymization parameter. for p=(c;;s )2p and
p0=(c0;0;s0)2p, we saypis a specialization for p0w.r.t.n, denoted by p0np
i0v,jjj0j+n, ands=s0.
considerp0=(81;ha;b;ci;corona ) as a process instance from the anonymized
event logl0
2in figure 2. given n=1, the cases 1, 2, and 3 from l2could be a
specialization for p0which are possible original process instances. we assume
that the adversary's bk is a subsequence of activities performed for a victim
case which can be considered as the strongest assumable knowledge w.r.t. the
available information in simple event logs. given an anonymized event log and
the anonymization parameter, the adversary can distinguish a matching set in
the anonymized release containing all the process instances having at least one
specialization matching the adversary's knowledge. one of the process instances
included in such a matching set belongs to the victim case.
denition 8 (matching set, group). letn2n1be the anonymization pa-
rameter and l0be an anonymized event log. msl0;n2a!2l0retrieves a
set of matching process instances from l0. forbk2a,msl0;n(bk)=fp02l0j
9p2pp0np^bkv(p)g. agroupgin a matching set is a set of process in-
stances having the same value on the sensitive attribute.
considerbk=hd;eias the adversary's knowledge and n=1. for the anonymized
event logs in figure 2, msl0
1;n(bk)=l0
1, andmsl0
2;n(bk)=f(c0;0;s0)2l0
2jc02f11;21
;31;41;51gg. the elements of matching sets can be identied using the following
theorem without searching the space of specializations.
theorem 1 (elements of matching sets). letn2n1be the anonymization
parameter and l0be an anonymized event log. for bk2aandp0=(c0;0;s0)2l0,
p02msl0;n(bk)injbkj lcsbk
0.privacy-preserving continuous event data publishing 7
proof. theorem 1 follows because one needs to add at least jbkj lcsbk
0activ-
ities to generate a super-sequence of0, s.t.,bkv.can be considered as
the trace of a process instance pwhich is a specialization for p0. note that one
can always assign a value for the sensitive attribute of p0, s.t.,s(p)=s(p0).
consider a scenario where the data holder publishes l0
1andl0
2as two
anonymized event logs at timestamps t1andt2, respectively. an adversary, who
is one of the data recipients, attempts to identify a victim case vcfroml0
1or
l0
2. we assume that the adversary's knowledge is a subsequence of activities
performed for the vc, i.e.,bk2a, and the approximate time at which the pro-
cess of the vchas been started, which is enough to know the release(s) where
thevcshould appear. for example, if event logs are published weekly, then the
adversary knows that the process of the vchas been started in the second week.
thus, its data should appear in all the event logs published after the rst week.
the adversary has also the correspondence knowledge derived from the concept
of continuous event data publishing, as described in section 2. the following
correspondence attacks can be launched by the adversary.
forward attack ( f-attack) the adversary knows that the process of the
vchas been started at the approximate time t, s.t.,tt1, and tries to identify the
vcinl0
1exploitingl0
2andbk2aas the bk. the vcdue to its timestamp must
have a process instance in l0
1andl0
2. if there exists a p0
12l0
1, s.t.,p0
12msl0
1;n(bk)
for an anonymization parameter n, there must be a p0
22l0
2corresponding to p0
1.
otherwise, p0
1does not match the bk and can be excluded from msl0
1;n(bk).
example 1 considerl0
1andl0
2in figure 2. assume that the adversary's
knowledge is bk=hd;ei, and the anonymization parameter is n=1.msl0
1;n(bk)=l0
1
andmsl0
2;n(bk)=f(c0;0;s0)2l0
2jc02f11;21;31;41;51gg. both matching sets
meet 5-anonymity. however, by comparing l0
1andl0
2, the adversary learns that
one of the cases 10;20;30cannot have eafterd. otherwise, there must have been
three cases with corona in msl0
2;n(bk). therefore, the adversary can exclude one
of10;20;30. note that the choice among 10;20;30does not matter as they are
equal. consequently, kis degraded from 5to4.
cross attack ( c-attack) the adversary knows that the process of the vc
has been started at the approximate time t, s.t.,tt1, and attempts to iden-
tify thevcinl0
2exploitingl0
1andbk2aas the bk. the vcbecause of its
timestamp must have a process instance in l0
1andl0
2. if there exists a p0
22l0
2,
s.t.,p0
22msl0
2;n(bk) for an anonymization parameter n, there must be a p0
12l0
1
corresponding to p0
2. otherwise, p0
2either is started at timestamp t,t1<tt2, or
it does not match the bk and can be excluded from msl0
2;n(bk).
example 2 considerl0
1andl0
2in figure 2. assume that the adversary's
knowledge is bk=hd;ei, and the anonymization parameter is n=1.msl0
1;n(bk) =
l0
1andmsl0
2;n(bk)=f(c0;0;s0)2l0
2jc02f11;21;31;41;51gg. both matching sets
meet 5-anonymity. however, by comparing l0
1andl0
2, the adversary learns that
one of the cases 11;21;31must be started at timestamp t, s.t.,t1<tt2. other-
wise, there must have been three cases with hiv in msl0
1;n(bk). therefore, the8 majid raei and wil m.p. van der aalst
adversary can exclude one of 11;21;31. again, the choice among 11;21;31does
not matter as they are equal. consequently, kis degraded from 5to4.
backward attack ( b-attack) the adversary knows that the process of the
vchas been started at the approximate time t, s.t.,t1<tt2, and tries to identify
thevcinl0
2exploitingl0
1andbk2aas the bk. the vchas a process instance
inl0
2, but not in l0
1. hence, if there exists p0
22l0
2, s.t.,p0
22msl0
2;n(bk) for an
anonymization parameter n, andp0
2has to be a corresponding process instance
for some process instances in l0
1, thenp0
2must be started at timestamp t, s.t.,
tt1and can be excluded from the matching set msl0
2;n(bk).
example 3 considerl0
1andl0
2in figure 2. assume that the adversary's
knowledge is bk=hd;ci, and the anonymization parameter is n=1.msl0
1;n(bk)=l0
1
andmsl0
2;n(bk)=f(c0;0;s0)2l0
2jc02f61;71;81;91;95gg. both matching sets
meet 5-anonymity. however, by comparing l0
1andl0
2, the adversary learns that
at least one of the cases 81;91;95must be started at timestamp t,tt1. oth-
erwise, one of the cases 10;20;30cannot have a corresponding process instance
inl0
2. thus,kis degraded from 5to4. note that there are only two cases
with corona which are not in msl0
2;n(bk)and could be corresponding for cases
10;20;30. hence, at least one of 81;91;95must be started at timestamp t,tt1.
5 attack detection
the correspondence attacks mentioned in section 4 are based on making some
inferences about corresponding cases (process instances). however, there are
many possible assignments of corresponding cases and each of those implies
possibly dierent event logs, which are not necessarily the actual event logs
collected by the data holder. in this section, we demonstrate the attack detection
regardless of any particular choices. to this end, we rst need to dene a linker to
specify all the valid assignments. then, we provide formal denitions for dierent
types of correspondence attacks and corresponding anonymity indicators.
denition 9 (linker, buddy). letl0
1andl0
2be the anonymized event logs at
timestamps t1andt2, respectively, and n2n1be the anonymization parameter.
linkern2l0
1!l0
2is a total injective function that retrieves the corresponding
process instances. for p0
12l0
1andp0
22l0
2,linkern(p0
1)=p0
2i there exist p1;p22p,
s.t.,p0
1np1^p0
2np2^s(p1)=s(p2)^(p1)2pref((p2)).(p0
1;p0
2)is called
a pair of buddies if there exists a linker, s.t., linkern(p0
1)=p0
2.
denition 10 ( f-attack). letl0
1andl0
2be two anonymized event logs re-
leased at timestamps t1andt2,n2n1be the anonymization parameter, tt1be
the approximate time at which the process of the victim case has been started, and
bk2abe the bk. the f-attack attempts to identify xas the maximal excludable
cases from msl0
1;n(bk), s.t., for any linker, at least xcases from the matching
set cannot match the bk. xis considered as crack size based on f-attack.privacy-preserving continuous event data publishing 9
denition 11 ( c-attack). letl0
1andl0
2be two anonymized event logs re-
leased at timestamps t1andt2,n2n1be the anonymization parameter, tt1be
the approximate time at which the process of the victim case has been started,
andbk2abe the bk. the c-attack tries to identify x(crack size) as the max-
imal excludable cases from msl0
2;n(bk), s.t., for any linker, at least xcases from
the matching set cannot match the bk or the timestamp of the victim case.
denition 12 ( b-attack). letl0
1andl0
2be two anonymized event logs re-
leased at timestamps t1andt2,n2n1be the anonymization parameter, t1<tt2
be the approximate time at which the process of the victim case has been started,
andbk2abe the bk. the b-attack tries to identify x(crack size) as the max-
imal excludable cases from msl0
2;n(bk), s.t., for any linker, at least xcases from
the matching set cannot match the timestamp of the victim case.
based on the denitions for the correspondence attacks, the key for attack
detection is the crack size. for calculating the crack sizes, we follow the similar
approach introduced in [7] which is based on the concept of comparability . we
dene the comparability at the level of sequences ,process instances , and groups .
these denitions are later used to compute the crack sizes of attacks.
denition 13 (comparable sequences). let1;22abe two sequences of
activities. we say 1and2are comparable w.r.t. n2n1, denoted by 1n2, if
nis the minimum number of activities that needs to be added to 1and/or2to
generate a joint super-sequence, or if 1can be a prex of 2by adding at least
nactivities to 2.
theorem 2 (detecting comparable sequence). given1;22aandn2n1:
1n2()
nj1j lcs12if92lcs (1;2)2pref(2)
nscs12 min(j1j;j2j)otherwise
proof. if there exists a 2lcs (1;2), s.t.,2pref(2), thenj1j lcs12is the
minimum number of activities that needs to be added to 2, s.t.,12pref(2).
otherwise, since scs12is the length of a shortest common super-sequence, one
needs to add at least scs12 min(j1j;j2j) activities to the shorter sequence
to generate a joint super-sequence.
denition 14 (comparable process instances). letp1;p22pbe two pro-
cess instances. we say p1andp2are comparable w.r.t. n, denoted by p1np2, i
s(p1)=s(p2)^(p1)n(p2).
denition 15 (comparable groups). letl0
1andl0
2be two anonymized
event logs released at timestamps t1andt2,bk2abe the bk, and n2n1be the
anonymization parameter. we say two groups g0
1msl0
1;n(bk)andg0
2msl0
2;n(bk)
are comparable w.r.t. n, denoted by g0
1ng0
2, i8p0
12g0
18p0
22g0
2p0
1np0
2.
lemma 1. letl0
1andl0
2be two anonymized event logs at timestamps t1and
t2,bk2abe the bk, and n2n1be the anonymization parameter. consider
g0
1msl0
1;n(bk)andg0
2msl0
2;n(bk)as two groups, s.t., g0
1ng0
2. ifp0
12msl0
1;n(bk)
andp0
22msl0
2;n(bk)are buddies for a linker, then p0
12g0
1ip0
22g0
2.10 majid raei and wil m.p. van der aalst
lemma 2. letl0
1andl0
2be two anonymized event logs released at timestamps
t1andt2,bk2abe the bk, and n2n1be the anonymization parameter.
considerg0
1msl0
1;n(bk)andg0
2msl0
2;n(bk)as two groups, s.t., g0
1ng0
2. since
the buddy relationship is injective, at most min(jg0
1j;jg0
2j)process instances in
g0
1have a buddy in g0
2, and there are some linkers where exactly min(jg0
1j;jg0
2j)
process instances in g0
1have a buddy in g0
2.
theorem 3 (crack size based on f-attack). letbk2abe the bk, n2n1
be the anonymization parameter, and l0
1andl0
2be two anonymized event logs
released at timestamps t1andt2. letcg(msl0
1;n(bk);msl0
2;n(bk)) =f(g0
1;g0
2)j
g0
1msl0
1;n(bk)^g0
2msl0
2;n(bk)^g0
1ng0
2gbe the set of pair of comparable groups
in the matching sets. for (g0
1;g0
2)2cg(msl0
1;n(bk);msl0
2;n(bk)),g0
1has crack
sizecs=jg0
1j min(jg0
1j;jg0
2j).f(msl0
1;n(bk);msl0
2;n(bk)) =pcsis the number
of excludable cases from msl0
1;n(bk)exploiting the f-attack, wherepis over
(g0
1;g0
2)2cg(msl0
1;n(bk);msl0
2;n(bk)).
proof. consider (g0
1;g0
2)2cg(msl0
1;n(bk);msl0
2;n(bk)). based on lemma 2, if
jg0
1j>jg0
2j, at leastjg0
1j min(jg0
1j;jg0
2j) process instances in g0
1do not have a
buddy ing0
2for any linker. also, according to lemma 1, these process instances
cannot match the given bk. otherwise, they must have had buddies in g0
2.
example 4 considerl0
1andl0
2in figure 2,n=1, andbk=hd;ei.jg0
1j=3and
jg0
2j=2for the corona groups in msl0
1;n(bk)andmsl0
2;n(bk), respectively. cs=3 
min(3;2)is the crack size of msl0
1;n(bk)based onf-attack.
denition 16 ( f-anonymity). letl0
1andl0
2be two anonymized event logs
att1andt2, andn2n1be the anonymization parameter. the f-anonymity of
l0
1andl0
2isfan(l0
1;l0
2) = min
bk2ajmsl0
1;n(bk)j f(msl0
1;n(bk);msl0
2;n(bk)).
theorem 4 (crack size based on c-attack). letbk2abe the bk, n2n1
be the anonymization parameter, and l0
1andl0
2be two anonymized event logs
released at timestamps t1andt2. letcg(msl0
1;n(bk);msl0
2;n(bk)) =f(g0
1;g0
2)j
g0
1msl0
1;n(bk)^g0
2msl0
2;n(bk)^g0
1ng0
2gbe the set of pair of comparable groups
in the matching sets. for (g0
1;g0
2)2cg(msl0
1;n(bk);msl0
2;n(bk)),g0
2has crack
sizecs=jg0
2j min(jg0
1j;jg0
2j).c(msl0
1;n(bk);msl0
2;n(bk)) =pcsis the number
of excludable cases from msl0
1;n(bk)exploiting the c-attack, wherepis over
(g0
1;g0
2)2cg(msl0
1;n(bk);msl0
2;n(bk)).
proof. consider (g0
1;g0
2)2cg(msl0
1;n(bk);msl0
2;n(bk)). based on lemma 2, if
jg0
2j>jg0
1j, at leastjg0
2j min(jg0
1j;jg0
2j) process instances in g0
2do not have a
buddy ing0
1for any linker. such process instances either cannot match the given
bk, according to lemma 1, or they have been started at timestamp t,t1<tt2.
example 5 considerl0
1andl0
2in figure 2,n=1, andbk=hd;ei.jg0
1j=2and
jg0
2j=3for the hiv groups in msl0
1;n(bk)andmsl0
2;n(bk), respectively. cs=3 
min(2;3)is the crack size of msl0
2;n(bk)based onc-attack.privacy-preserving continuous event data publishing 11
denition 17 ( c-anonymity). letl0
1andl0
2be two anonymized event logs
att1andt2, andn2n1be the anonymization parameter. the c-anonymity of
l0
1andl0
2iscan(l0
1;l0
2) = min
bk2ajmsl0
2;n(bk)j c(msl0
1;n(bk);msl0
2;n(bk)).
lemma 3. letl0
1andl0
2be two anonymized event logs released at timestamps
t1andt2,bk2 abe the bk, and n2n1be the anonymization parame-
ter. consider g0
2msl0
2;n(bk),g0
1=fp0
12l0
1j9p0
22g0
2p0
1np0
2g, andg0
2=fp0
22l0
2j
9p0
12g0
1p0
1np0
2g. every process instance in g0
2is comparable to all records in g0
1
and only those records in g0
1.
theorem 5 (crack size based on b-attack). letbk2abe the bk,n2n1
be the anonymization parameter, and l0
1andl0
2be two anonymized event logs re-
leased at timestamps t1andt2. letg0
2msl0
2;n(bk),g0
1=fp0
12l0
1j9p0
22g0
2p0
1np0
2g,
andg0
2=fp0
22l0
2j9p0
12g0
1p0
1np0
2g.g0
2has crack size cs=max(0;jg0
1j (jg0
2j jg0
2j)).
b(msl0
2;n(bk);l0
1;l0
2) =p
g0
22msl0
2;n(bk)csis the number of excludable cases
frommsl0
2;n(bk)exploitingb-attack.
proof. according to lemma 3, all process instances in g0
1and only those process
instances can have a buddy in g0
2. therefore, each process instance in g0
1has a
buddy either in g0
2org0
2 g0
2. ifjg0
1j>jg0
2j jg0
2j, thenjg0
1j (jg0
2j jg0
2j) process
instances in g0
2must be started at timestamp t,tt1.
example 6 considerl0
1andl0
2in figure 2,n=1, andbk=hd;ci.jg0
2j=3for
the corona group in msl0
2;n(bk),g0
1=fp0
12l0
1jc(p0
1)2f10;20;30gg, andg0
2=
fp0
22l0
2jc(p0
2)2f41;51;81;91;95gg.cs=max(0;3 (5 3))is the crack size of
msl0
2;n(bk)based onb-attack.
denition 18 ( b-anonymity). letl0
1andl0
2be two anonymized event logs
att1andt2, andn2n1be the anonymization parameter. ban(l0
1;l0
2) =
min
bk2ajmsl0
2;n(bk)j b(msl0
2;n(bk);l0
1;l0
2)is theb-anonymity of l0
1andl0
2.
givenn2n1as the anonymization parameter, kan(l0)= min
bk2ajmsl0;n(bk)jis
thek-anonymity of an anonymized event log l0w.r.t.n. assuming l0
1andl0
2as
two anonymized event logs at timestamps t1andt2, we calculate the proportion
of the cracked cases (pocs) after launching the correspondence attacks as fol-
lows:fcn(l0
1;l0
2)=(kan(l0
1) fan(l0
1;l0
2))
kan(l0
1),ccn(l0
1;l0
2)=(kan(l0
2) can(l0
1;l0
2))
kan(l0
2),and
bcn(l0
1;l0
2)=(kan(l0
2) ban(l0
1;l0
2))
kan(l0
2).
6 experiments
in this section, we employ sepsis [10] as a real-life event log and simulate dierent con-
tinuous event data publishing scenarios. we report privacy losses and anonymity values
based on the correspondence attacks. note that sepsis is one of the most challenging12 majid raei and wil m.p. van der aalst
(a)the anonymity values when the gap between
two releases is1%, i.e.,l0
1andl0
2were obtained
froml1(99) andl2(100), respectively.
(b)the anonymity values when the gap between
two releases is5%, i.e.,l0
1andl0
2were obtained
froml1(95) andl2(100), respectively.
(c)the anonymity values when the gap between
two releases is10%, i.e.,l0
1andl0
2were ob-
tained from l1(90) andl2(100), respectively.
(d)the anonymity values when the gap between
two releases is25%, i.e.,l0
1andl0
2were ob-
tained from l1(75) andl2(100), respectively.
fig. 3: the anonymity values for dierent variants of pairs of anonymized releases in scenario i.
ka(l0
1) isk-anonymity of l0
1,ka(l0
2) isk-anonymity of l0
2,faisk-anonymity of l0
1after launch-
ingf-attack,caisk-anonymity of l0
2after launching c-attack, and baisk-anonymity of l0
2after
launchingb-attack.
event logs for ppts [5,18,11]. we consider two main scenarios to cover various situa-
tions w.r.t. event data volume and velocity of event data publishing . in both scenarios,
we consider two releases to be published.
inscenario i , we consider the entire event log as the second collection of events
l2(100). keeping the second collection of events as l2(100), we generate four dierent
variants for the rst collection of events named l1(99),l1(95),l1(90), andl1(75), s.t.,
l1(x) containsx% of cases. note that we ignore the decimal points for percentages,
e.g., 90% could be 90.01% or 90.95%. in scenario ii , we lter 50% of cases as the rst
collection of events l1(50). keeping the rst collection of events as l1(50), we generate
four dierent variants for the second collection of events named l2(51),l2(55),l2(60),
andl2(75), s.t.,l2(x) containsx% of cases. to lter the event logs, we use time-frame
ltering where the start time is always the start time of the event log and the end time
is changed to pick the desired percentage of cases.
in both scenarios, the gap between two collections varies, s.t., it contains at most
1%, 5%, 10%, or 25% new cases. we focus on the percentage of cases rather than a
xed time window, e.g., daily, weekly, etc., because a xed time window could contain
dierent amount of data in dierent slots. we employ the extended version of tlkc-
privacy model [17] as the group-based ppt where one can adjust power and type of
bk.2the model removes events from traces w.r.t. utility loss and privacy gain to
provide the desired privacy requirements. we consider all the possible sequences of
activities in the event log with the maximal length 5 as the candidates of bk, and
2https://github.com/m4jidraei/tlkc-privacy-extprivacy-preserving continuous event data publishing 13
fig. 4: let x be the maximal gap between two anonymized releases. fc x%, cc x%, and bc x%
show the pocs exploiting f-attack,c-attack, and b-attack, respectively. for each anonymization
parameter, the rst, the second, and the third 4 bars show the results for f-attack,c-attack, and
b-attack, respectively.
k=20 as the lower bound for k-anonymity, i.e., the privacy model guarantees that a
single release of the event log meets at least 20-anonymity for all the candidates of
bk. on the data recipient's side, in each scenario, four dierent pairs of anonymized
releases are received. we developed a python program to detect the attacks and report
the anonymity values. the source code and other resources are available on github.3
figure 3 shows the anonymity values before and after launching the attacks in
scenario i. note that when nis equal to the length of the bk, all cases already fall
into the matching sets. therefore, the maximal value for the anonymization parameter
is 5 which is the maximal length assumed for the bk. figure 3a shows that when the
gap is at most 1% and n=1, the anonymized release l0
2has 90-anonymity. however,
after launching the b-attack, 81 cases are cracked, i.e., 90% of cases, and k-anonymity
is degraded to 9, i.e., ba1(l0
1;l0
2)=9. forn>1, theb-anonymity is 1, i.e., there exists
a sequence of activities of the maximal length 5 that can be used to uniquely identify a
case assuming that at most n>1 activities have been removed by the ppt. note that
the second release includes only 1 new case when the gap is at most 1%.
figure 4 shows how the pocs are changed when we vary the anonymization pa-
rameternin scenario i. each pair of the anonymized releases is indicated with the
percentage of the gap, e.g., 1% in scenario i indicates two releases obtained from
l1(99) andl2(100). when the gap between two releases is small, the b-attack results
in much higher values for the pocs compared to the other attacks. however, when the
gap becomes larger, the pocs of the b-attack decreases. this happens because for the
smallerl0
1s, there exist fewer cases that can be excluded from the matching sets in
l0
2because of their timestamps. the c-attack shows dierent behavior that is due to
the assumed timestamp for the victim case, i.e., for the larger gaps, there exist more
cases that their timestamps comply with the second release l0
2and cannot have a cor-
responding case in l0
1. thef-attack cracks fewer cases, which is expected because its
target release is l0
1, and it only exploits the bk mismatching. note that greater values
for the anonymization parameter mean that the adversary assumes higher data distor-
tion which results in greater values for the anonymity. we had similar observations for
scenario ii, and the results are available in our github repository.
3https://github.com/m4jidraei/pp cedp14 majid raei and wil m.p. van der aalst
7 extensions
the two releases scenario can be extended to the general scenario where more re-
leases are involved. in the general scenario, we consider m2n>2collections of events
l1;l2;:::;lmcollected at timestamps t1;t2;:::;tmand published as l0
1;l0
2;:::;l0
m.
the correspondence knowledge is also extended, s.t., every case in l0
ihas a correspond-
ing case inl0
j,i<jm. consider the introduced attacks based on two releases as micro
attacks . given more than two releases, the adversary can launch two other types of
attacks, so-called optimal micro attacks and composition of micro attacks [7].
optimal micro attacks: the idea is to nd the best background release which
results in the largest possible crack size. for instance, consider the f-attack on l0
i.
the adversary can choose any l0
j,i<jm, as the background release. let bk2abe
the background knowledge, n2n1be the anonymization parameter, and csijbe the
crack size of a pair of comparable groups ( g0
i;g0
j)2cg(msl0
i;n(bk);msl0
j;n(bk)). the
optimal crack size of g0
iis max
i<jmcsij.
composition of micro attacks: the idea is to compose multiple micro attacks to
increase the crack size of a group. the micro attacks are launched one after the other.
note that the composition is not possible for any arbitrary choice of micro attacks. it is
possible only if all the micro attacks in the composition assume the same timestamp for
the victim case, and the required correspondence knowledge holds for the next attack
after the previous attack [7]. hence, considering l0
i,l0
j, andl0
l, as the anonymized
releases, s.t., i<j<lm, only two compositions are possible: (1) b-attack on l0
iand
l0
jfollowed by f-attack on l0
jandl0
l, and (2)b-attack on l0
iandl0
jfollowed by
c-attack onl0
jandl0
l.
here, we focused on k-anonymity which is the foundation for the group-based ppts.
the proposed approach can be extended to cover all the extensions of k-anonymity
introduced to deal with attribute linkage attacks, e.g., l-diversity, ( ;k)-anonymity,
condence bounding, etc. the measures of such ppts can be modied to consider the
cracked cases. moreover, new group-based ppts for process mining can be designed to
considerf=c=b -anonymity. for example, a naive algorithm is to start with the max-
imal possible anonymity, i.e., having only one trace variant, e.g., the longest common
subsequence, and then adding events w.r.t. their eect on data utility and privacy loss.
8 related work
privacy/condentiality in process mining is growing in importance. the work having
been done covers dierent aspects of the topic including the challenges [2,4,13], con-
dentiality frameworks [19], privacy by design [12], privacy guarantees [11,6,18,5], inter-
organizational privacy issues [3], and privacy quantication [20,16]. condentiality is
one of the important challenges of the bigger sub-discipline of process mining called
responsible process mining (rpm) [2]. in [13], the authors focus on data privacy and
utility requirements for healthcare event data. a general framework for condentiality
in process mining is proposed in [19]. in [12], the goal is to propose a privacy-preserving
system design for process mining. in [14], the authors introduce a privacy-preserving
method for discovering roles from event logs. in [5], k-anonymity and t-closeness are
adopted to preserve the privacy of resources in event logs. in [11,6], the notion of dif-
ferential privacy is utilized to provide privacy guarantees. in [18], the tlkc-privacy is
introduced to deal with high variability issues in event logs for applying group-basedprivacy-preserving continuous event data publishing 15
anonymization techniques. a secure multi-party computation solution is proposed in
[3] for preserving privacy in an inter-organizational setting. in [20], the authors propose
a measure to evaluate the re-identication risk of event logs. also, in [16], a general
privacy quantication framework, and some measures are introduced to evaluate the
eectiveness of ppts. in [15], the authors propose a privacy extension for the xes
standard to manage privacy metadata.
9 conclusion
in practice, event data need to be published continuously to keep the process mining
results up-to-date. in this paper, for the rst time, we focused on the attacks appearing
when anonymized event data are published continuously. we formalized three dierent
types of the so-called correspondence attacks in the context of process mining: f-attack,
c-attack, and b-attack. we demonstrated the attack detection techniques to quantify
the anonymity of event logs published continuously. we simulated the continuous event
data publishing for real-life event logs using various scenarios. for an example event
log, we showed that the provided privacy guarantees can be degraded exploiting the
attacks. the attack analysis and detection techniques can be adjusted and attached
to dierent group-based ppts to enhance the privacy guarantees when event data
are published continuously. in this paper, we mainly focused on suppression as the
anonymization operation. in future, other anonymization operations such as addition
orswapping could be analyzed. similar attack analysis can be done for other types of
ppts, e.g., dierential privacy , in the context of process mining to protect provided
privacy guarantees. moreover, one could evaluate the eect of continuous publishing
scenarios on privatized process mining results.
acknowledgment
funded under the excellence strategy of the federal government and the l ander. we
also thank the alexander von humboldt stiftung for supporting our research.
references
1. van der aalst, w.m.p.: process mining - data science in action, second edition.
springer (2016). https://doi.org/10.1007/978-3-662-49851-4
2. van der aalst, w.m.p.: responsible data science: using event data in a \people
friendly" manner. in: international conference on enterprise information systems.
pp. 3{28. springer (2016)
3. elkoumy, g., fahrenkrog-petersen, s.a., dumas, m., laud, p., pankova, a., wei-
dlich, m.: secure multi-party computation for inter-organizational process mining.
in: enterprise, business-process and information systems modeling - 21st inter-
national conference, bpmds. springer (2020)
4. elkoumy, g., fahrenkrog-petersen, s.a., sani, m.f., koschmider, a., mannhardt,
f., von voigt, s.n., raei, m., von waldthausen, l.: privacy and condentiality in
process mining - threats and research challenges. corr abs/2106.00388 (2021),
https://arxiv.org/abs/2106.0038816 majid raei and wil m.p. van der aalst
5. fahrenkrog-petersen, s.a., van der aa, h., weidlich, m.: pretsa: event log san-
itization for privacy-aware process discovery. in: international conference on pro-
cess mining, icpm 2019, aachen, germany (2019)
6. fahrenkrog-petersen, s.a., van der aa, h., weidlich, m.: pripel: privacy-
preserving event log publishing including contextual information. in: business pro-
cess management - 18th international conference, bpm. lecture notes in com-
puter science, vol. 12168, pp. 111{128 (2020)
7. fung, b.c.m., wang, k., fu, a.w., pei, j.: anonymity for continuous data publish-
ing. in: 11th international conference on extending database technology. acm
international conference proceeding series, vol. 261, pp. 264{275 (2008)
8. fung, b.c., wang, k., fu, a.w.c., philip, s.y.: introduction to privacy-preserving
data publishing: concepts and techniques. chapman and hall/crc (2010)
9. gehrke, j.: models and methods for privacy-preserving data analysis and publish-
ing. in: proceedings of the 22nd international conference on data engineering,
icde. p. 105. ieee computer society (2006)
10. mannhardt, f.: sepsis cases-event log. eindhoven university of technology (2016)
11. mannhardt, f., koschmider, a., baracaldo, n., weidlich, m., michael, j.: privacy-
preserving process mining - dierential privacy for event logs. business & informa-
tion systems engineering 61(5), 595{614 (2019)
12. michael, j., koschmider, a., mannhardt, f., baracaldo, n., rumpe, b.: user-
centered and privacy-driven process mining system design for iot. in: information
systems engineering in responsible information systems. pp. 194{206 (2019)
13. pika, a., wynn, m.t., budiono, s., ter hofstede, a.h., van der aalst, w.m.p., rei-
jers, h.a.: privacy-preserving process mining in healthcare. international journal
of environmental research and public health 17(5), 1612 (2020)
14. raei, m., van der aalst, w.m.p.: mining roles from event logs while preserving
privacy. in: business process management workshops - bpm 2019 international
workshops, vienna, austria. pp. 676{689 (2019)
15. raei, m., van der aalst, w.m.p.: privacy-preserving data publishing in process
mining. in: business process management forum - bpm forum 2020. pp. 122{138.
springer (2020). https://doi.org/10.1007/978-3-030-58638-6 8
16. raei, m., van der aalst, w.m.p.: towards quantifying privacy in process min-
ing. in: international conference on process mining - icpm 2020 international
workshops, padua, italy, october 4-9, 2020 (2020)
17. raei, m., van der aalst, w.m.p.: group-based privacy preservation tech-
niques for process mining. data & knowledge engineering 134, 101908 (2021).
https://doi.org/https://doi.org/10.1016/j.datak.2021.101908
18. raei, m., wagner, m., van der aalst, w.m.p.: tlkc-privacy model for process
mining. in: research challenges in information science - 14th international con-
ference, rcis. pp. 398{416. springer international publishing (2020)
19. raei, m., von waldthausen, l., van der aalst, w.m.p.: supporting condentiality
in process mining using abstraction and encryption. in: data-driven process dis-
covery and analysis - 8th ifip wg 2.6 international symposium, simpda 2018,
and 9th international symposium, simpda 2019, revised selected papers (2019)
20. von voigt, s.n., fahrenkrog-petersen, s.a., janssen, d., koschmider, a.,
tschorsch, f., mannhardt, f., landsiedel, o., weidlich, m.: quantifying the re-
identication risk of event logs for process mining - empiricial evaluation paper.
in: advanced information systems engineering, caise (2020)
21. wong, r.c.w., fu, a.w.c., wang, k., pei, j.: minimality attack in privacy pre-
serving data publishing. in: proceedings of the 33rd international conference on
very large data bases. pp. 543{554 (2007)