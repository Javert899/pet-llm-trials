conformance testing: measuring the fit and
appropriateness of event logs and process
models
a. rozinat1,2and w.m.p. van der aalst1
1department of technology management, eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands.
w.m.p.v.d.aalst@tm.tue.nl
2department of business process technology, hpi university of potsdam
p.o. box 900460, d-14440, potsdam, germany.
a.rozinat@tm.tue.nl
abstract most information systems log events (e.g., transaction logs,
audit trails) to audit and monitor the processes they support. at the
same time, many of these processes have been explicitly modeled. for
example, sap r/3 logs events in transaction logs and there are epcs
(event-driven process chains) describing the so-called reference models.
these reference models describe how the system should be used. the co-
existence of event logs and process models raises an interesting question:
“does the event log conform to the process model and vice versa?”. this
paper demonstrates that there is not a simple answer to this question. to
tackle the problem, we distinguish two dimensions of conformance: ﬁtness
(the event log may be the result of the process modeled) and appropri-
ateness (the model is a likely candidate from a structural and behavioral
point of view). diﬀerent metrics have been deﬁned and a conformance
checker has been implemented within the prom framework.
1 introduction
new legislation such as the sarbanes-oxley (sox) act [15] and increased em-
phasis on corporate governance and operational eﬃciency has triggered the need
for improved auditing systems. to audit an organization, business activities need
to be monitored. buzzwords such as bam (business activity monitoring), bom
(business operations management), bpi (business process intelligence) illus-
trate the interest of vendors to support the monitoring and analysis of business
activities. the close monitoring of processes can be seen as a second wave follow-
ing the wave of business process modeling and simulation. in the ﬁrst wave the
emphasis was on constructing process models and analyzing them. the many no-
tations (e.g., petri nets, uml activity diagrams, epcs, idef, bpmn, and not
to mention the vendor or system speciﬁc notations) illustrate this. this creates
the interesting situation where processes are being monitored while at the same
time there are process models describing these processes. the focus of this paper
is on conformance , i.e., “is there a good match between the recorded events andthe model?”. a term that could be used in this context is “business alignment”,
i.e., are the real process (reﬂected by the log) and the process model (e.g., used
to conﬁgure the system) aligned properly.
most information systems, such as wfm, erp, crm, scm, and b2b sys-
tems, provide some kind of event log (also referred to as transaction log or audit
trail) [5]. typically such an event log registers the start and/or completion of
activities. every event refers to a case (i.e., process instance) and an activity,
and, in most systems, also a timestamp, a performer, and some additional data.
in this paper, we only use the ﬁrst two attributes of an event, i.e., the identity of
the case and the name of the activity. meanwhile, any organization documents
its processes in some form. the reasons for making these process models are
manifold. process models are used for communication, iso 9000 certiﬁcation,
system conﬁguration, analysis, simulation, etc. a process model may be of a de-
scriptive or of a prescriptive nature. descriptive models try to capture existing
processes without being normative. prescriptive models describe the way that
processes should be executed. in a workﬂow management (wfm) system pre-
scriptive models are used to enforce a particular way of working using it [2].
however, in most situations prescriptive models are not used directly by the in-
formation system. for example, the reference models in the context of sap r/3
[12] and aris [16] describe the “preferred” way processes should be executed.
people actually using sap r/3 may deviate from these reference models.
in this paper, we will use petri nets [9] to model processes. although the
metrics are based on the petri net approach, the results of this paper in general
can be applied to any modeling language that can be equipped with executable
semantics. an event log is represented by a set of event sequences, also referred
to as traces. each case in the log refers to one sequence. the most dominant
requirement for conformance is ﬁtness . an event log and petri net “ﬁt” if the
petri net can generate each trace in the log. in other words: the petri net should
be able to “parse” every event sequence. we will show that it is possible to
quantify ﬁtness, e.g., an event log and petri net may have a ﬁtness of 0.66.
unfortunately, a good ﬁtness does not imply conformance. as we will show, it
is easy to construct petri nets that are able to parse any event log. although
such petri nets have a ﬁtness of 1 they do not provide meaningful information.
therefore, we introduce a second dimension: appropriateness . appropriateness
tries to capture the idea of occam’s razor , i.e., “one should not increase, beyond
what is necessary, the number of entities required to explain anything”. clearly,
this dimension is not as easy to quantify as ﬁtness. we will distinguish between
structural appropriateness (if a simple model can explain the log, why choose a
complicated one) and behavioral appropriateness (the model should not be too
generic). using examples, we will show that both the structural and behavioral
aspects need to be considered to measure appropriateness adequately.
to actually measure conformance, we have developed a tool called confor-
mance checker . it is part of the prom framework3, which oﬀers a wide range of
tools related to process mining, i.e., extracting information from event logs [5].
3both documentation and software can be downloaded from www.processmining.org .
2this paper is organized as follows. section 2 introduces a running example
that will be used to illustrate the concept of conformance. section 3 discusses
the need for two dimensions. the ﬁtness dimension is discussed in section 4.
the appropriateness dimension is elaborated in section 5. section 6 shows how
these properties can be veriﬁed using the conformance checker in prom. finally,
some related work is discussed and the paper is concluded.
2 running example
the example model used throughout the paper concerns the processing of a
liability claim within an insurance company (cf. figure 1(a)).
at ﬁrst there are two tasks bearing the same label “set checkpoint”. this can
be thought of as an automatic backup action within the context of a transactional
system, i.e., activity a is carried out at the beginning to deﬁne a rollback point
enabling atomicity of the whole process, and at the end to ensure durability of
the results. then the actual business process is started with the distinction of
low-value claims and high-value claims, which get registered diﬀerently ( bor
c). the policy of the client is checked anyway ( d) but in the case of a high-
value claim, additionally, the consultation of an expert takes place ( g), and then
the ﬁled liability claim is being checked in more detail ( h). finally, the claim is
completed according to the former choice between bandc(i.e., eorf).
figures 1(b)-(d) show three example logs for the process described in fig-
ure 1(a) at an aggregate level. this means that process instances exhibiting the
same event sequence are combined as a logical log trace, memorizing the number
of instances to weigh the importance of that trace. that is possible since only the
control ﬂow perspective is considered here. in a diﬀerent setting like, e.g., mining
social networks [4], the resources performing an activity would distinguish those
instances from each other.
3 two dimensions of conformance: fitness and
appropriateness
measurement can be deﬁned as a set of rules to assign values to a real-world
property, i.e., observations are mapped onto a numerical scale. in the context of
conformance testing this means to weigh the “distance” between the behavior
described by the process model and the behavior actually observed in the work-
ﬂow log. if the distance is zero, i.e., the real business process exactly matches
the speciﬁed behavior, one can say that the log ﬁtsthe model. with respect to
the example model m1this applies for event log l1, since every log trace can be
associated with a valid path from start toend. in contrast, event log l2does
not match completely as the traces achdfa andacdhfa lack the execution
of activity g, while event log l3does not even contain one trace correspond-
ing to the speciﬁed behavior. somehow l3seems to ﬁt “worse” than l2, and
the degree of ﬁtness should be determined according to this intuitive notion of
conformance, which might vary for diﬀerent settings.
3figure 1. example models and logs
4but there is another interesting — rather qualitative — dimension of con-
formance, which can be illustrated by relating the process models m2andm3,
shown in figure 1(e) and (f), to event log l2. although the log ﬁts both models
quantitatively, i.e., the event streams of the log and the model can be matched
perfectly, they do not seem to be appropriate in describing the insurance claim
administration.
the ﬁrst one is much too generic as it covers a lot of extra behavior, allowing
for arbitrary sequences containing the activities a,b,c,d,e,f,g, orh, while
the latter does not allow for more sequences than those having been observed
but only lists the possible behavior instead of expressing it in a meaningful way.
therefore, it does not oﬀer a better understanding than can be obtained by just
looking at the aggregated log. we claim that a “good” process model should
somehow be minimal in structure to clearly reﬂect the described behavior, in
the following referred to as structural appropriateness , and minimal in behavior
to represent as closely as possible what actually takes place, which will be called
behavioral appropriateness .
apparently, conformance testing demands for two diﬀerent types of metrics,
which are:
–fitness , i.e., the extent to which the log traces can be associated with exe-
cution paths speciﬁed by the process model, and
–appropriateness , i.e., the degree of accuracy in which the process model
describes the observed behavior, combined with the degree of clarity in which
it is represented.
4 measuring fitness
diﬀerent ways are conceivable to measure the ﬁt between event logs and process
models. a rather naive approach would be to generate all execution sequences
allowed by the model and then compare them to the log traces using string
distance metrics. unfortunately the number of ﬁring sequences increases very
fast if a model contains parallelism and might even be inﬁnite if we allow for
loops. therefore, this is of limited applicability.
another possibility is to replay the log in the model and somehow measure
the mismatch, which subsequently is described in more detail. the replay of
every logical log trace starts with marking the initial place in the model and
then the transitions that belong to the logged events in the trace are ﬁred one
after another. while doing so we count the number of tokens that had to be
created artiﬁcially (i.e., the transition belonging to the logged event was not
enabled and therefore could not be successfully executed ) and the number of
tokens that had been left in the model, which indicates the process not having
properly completed .
letkbe the number of diﬀerent traces from the aggregated log, nthe number
of process instances combined as one of these traces, mthe number of missing
tokens, rthe number of remaining tokens, cthe number of consumed tokens,
andpthe number of produced tokens during log replay, then the token-based
ﬁtness metrics fis formalized as follows.
5f=1
2(1−/summationtextk
i=1nimi/summationtextk
i=1nici) +1
2(1−/summationtextk
i=1niri/summationtextk
i=1nipi) (1)
note that, for all i,mi≤ciandri≤pi, and therefore 0 ≤f≤1. using
the metrics fwe can now calculate the ﬁtness between the event logs l1,l2,
l3, and the process description m1, respectively. the ﬁrst event log l1shows
three diﬀerent log traces that all correspond to possible ﬁring sequences of the
petri net with one initial token in the start place. thus, there are neither tokens
left nor missing in the model during log replay and the ﬁtness measurement
yields f(m1, l1) = 1. replaying the event log l2fails for the last two traces
achdfa andacdhfa , since the model requires activity gbeing performed
before activating task h. therefore, in both cases one token remains in place
c6, and one token needs to be created artiﬁcially in place c7for ﬁring transition
h(i.e., m1=r1=m2=r2=m3=r3= 0, and m4=r4=m5=r5= 1).
counting the tokens being produced and consumed in the petri net model (i.e.,
c1=p1= 7, and c2=c3=p2=p3= 9, and c4=c5=p4=p5= 8), and
with the number of process instances per trace, given in figure 1(c), the ﬁtness
can be measured as f(m1, l2)≈0.995. for the last event log l3the ﬁtness
measurement yields f(m1, l3)≈0.540.
besides measuring the degree of ﬁtness pinpointing the site of mismatch is
crucial for giving useful feedback to the analyst. in fact, the place of missing
and remaining tokens during log replay can provide insight into problems, such
as figure 1(j) visualizes some diagnostic information obtained for event log l2.
because of the remaining tokens (whose amount is indicated by a + sign) in place
c6transition ghas stayed enabled, and as there were tokens missing (indicated
by a−sign) in place c7transition hhas failed seamless execution.
note that this replay is carried out in a non-blocking way and from a log-
based perspective, i.e., for each log event in the trace the corresponding transition
is ﬁred, regardless whether the path of the model is followed or not. this leads
to the fact that — in contrast to directly comparing the event streams of models
and logs — a concatenation of missing log events is punished by the ﬁtness
metrics fjust as much as a single one, since it could always be interpreted as a
missing link in the model.
as a prerequisite of conformance analysis model tasks must be associated
with the logged events, which may result in duplicate tasks , i.e., multiple tasks
that are mapped onto the same kind of log event, and invisible tasks , i.e., tasks
that have no corresponding log event. duplicate tasks cause no problems during
log replay as long as they are not enabled at the same time and can be seamlessly
executed, but otherwise one must enable and/or ﬁre the right task for progressing
properly. invisible tasks are considered to be lazy, i.e., they are only ﬁred if they
can enable the transition in question. in both cases it is necessary to partially
explore the state space of the model but a detailed description is beyond the
scope of this paper.
65 measuring appropriateness
generally spoken, determining the degree of appropriateness of a workﬂow pro-
cess model strongly depends on subjective perception, and is highly correlated
to the speciﬁc purpose. there are aspects like the proper semantic level of ab-
straction, i.e., the granularity of the described workﬂow actions, which can only
be found by an experienced human designer. the notion of appropriateness ad-
dressed by this paper rather relates to the control ﬂow perspective and therefore
is approachable to measurement but there still remains a subjective element.
the overall aim is to have the model clearly reﬂect the behavior observed in
the log, whereas the degree of appropriateness is determined by both structural
properties of the model and the behavior described by it. figure 1(g) shows m4,
which is a good model for the event log l2as it exactly generates the observed
sequences in a structurally suitable way.
in the remainder of this section, both the structural and the behavioral part
of appropriateness are considered in more detail.
5.1 structural appropriateness
the desire to model a business process in a compact and meaningful way is
diﬃcult to capture by measurement. as a ﬁrst indicator we will deﬁne a sim-
ple metrics that solely evaluates the size of the graph and subsequently some
constructs that may inﬂate the structure of a process model are considered.
given the fact that a business process model is expected to have a dedicated
start andend place, the graph must contain at least one node for every task
label, plus two places (the start and end place). let tbe the number of diﬀer-
ent task labels, and nthe number of nodes (i.e., places and transitions) in the
petri net model, then the structural appropriateness metrics asis formalized as
follows.
as=t+ 2
n(2)
calculating the structural appropriateness for the model m3yields as(m3)≈
0.170, which is a very bad value caused by the many duplicate tasks. for the good
model m4the metrics yields as(m4) = 0 .5. with as(m5)≈0.435 a slightly
worse value is calculated for the behaviorally (trace) equivalent model m5in
figure 1(h), which is now used to consider some constructs that may decrease
the structural appropriateness as.
(a)duplicate tasks . duplicate tasks that are used to list alternative execu-
tion sequences tend to produce models like the extreme m3.m5(a) indicates an
example situation in which a duplicate task is used to express that after per-
forming activity ceither the sequence ghorhalone can be executed. m4(b)
describes the same process with the help of an invisible task, which is only used
for routing purposes and therefore not visible in the log. one could argue that
this model supports a more suitable perception namely activity gis not obliged
to execute but can be skipped, but it somehow remains a matter of taste. how-
ever, excessive usage of duplicate tasks for listing alternative paths reduces the
7appropriateness of a model in preventing desired abstraction. in addition, there
are also duplicate tasks that are necessary to, e.g., specify a certain activity
taking place exactly at the beginning and at the end of the process like task a
inm4(a).
(b)invisible tasks . besides the invisible tasks used for routing purposes like,
e.g., shown in m4(b), there are also invisible tasks that only delay visible tasks,
such as the one depicted in m5(b). if they do not serve any model-related purpose
they can simply be removed, thus making the model more concise.
(c)implicit places . implicit places are places that can be removed without
changing the behavior of the model. an example for an implicit place is given
inm5(c). again, one could argue that they should be removed as they do not
contribute anything, but sometimes it can be useful to insert such an implicit
place to, e.g., show document ﬂows. note that the place c5is not implicit as it
inﬂuences the choice made later on between eandf. both c5andc10aresilent
places , with a silent place being a place whose directly preceding transitions are
never directly followed by one of their directly succeeding transitions (i.e., the
model is unable to produce an event sequence containing beoraa). mining
techniques by deﬁnition are unable to detect implicit places, and have problems
detecting silent places.
5.2 behavioral appropriateness
besides the structural properties that can be evaluated on the model itself ap-
propriateness can also be examined with respect to the behavior recorded in
the log. assuming that the log ﬁts the model, i.e., the model allows for all the
execution sequences present in the log, there remain those that would ﬁt the
model but have not been observed. assuming further that the log satisﬁes some
notion of completeness, i.e., the behavior observed corresponds to the behavior
that should be described by the model, it is desirable to represent it as precisely
as possible. when the model gets too general and allows for more behavior than
necessary (like in the “ﬂower” model m2) it becomes less informative in actually
describing the process.
one approach to measure the amount of possible behavior is to determine
the mean number of enabled transitions during log replay. this corresponds to
the idea that for models clearly reﬂecting their behavior, i.e., complying with
the structural properties mentioned, an increase of alternatives or parallelism
and therefore an increase of potential behavior will result in a higher number of
enabled transitions during log replay.
letkbe the number of diﬀerent traces from the aggregated log, nthe number
of process instances combined as one of these traces, mthe number of labeled
tasks (i.e., does not include invisible tasks, and assuming m > 1) in the petri net
model, and xthe mean number of enabled transitions during log replay (note
that invisible tasks may enable succeeding labeled tasks but they are not counted
themselves), then the behavioral appropriateness metrics abis formalized as
follows.
8ab= 1−/summationtextk
i=1ni(xi−1)
(m−1)·/summationtextk
i=1ni(3)
calculating the behavioral appropriateness with respect to event log l2for
the model m2yields ab(m2, l2) = 0, which indicates the arbitrary behavior
described by it. for m4, which exactly allows for the behavior observed in the
log, the metrics yields ab(m4, l2)≈0.967. as an example it can be compared
with the model m6in figure 1(i), which additionally allows for arbitrary loops of
activity gand therefore exhibits more potential behavior. this is also reﬂected
by the behavioral appropriateness measure as it yields a slightly smaller value
than for the model m4, namely ab(m6, l2)≈0.964.
5.3 balancing fitness and appropriateness
having deﬁned the three metrics f,as, and ab, the question is now how to put
them together. this is not an easy task since they are partly correlated with each
other. so the structure of a process model may inﬂuence the ﬁtness metrics fas,
e.g., due to inserting redundant invisible tasks the value of fincreases because
of the more tokens being produced and consumed while having the same amount
of missing and remaining ones. but unlike asandabthe metrics fdeﬁnes an
optimal value 1 .0, for a log that can be parsed by the model without any error.
therefore we suggest a conformance testing approach carried out in two
phases. during the ﬁrst phase the ﬁtness of the log and the model is ensured,
which means that discrepancies are analyzed and potential corrective actions are
undertaken. if there still remain some tolerable deviations, the log or the model
should be manually adapted to comply with the ideal or intended behavior, in
order to go on with the so-called appropriateness analysis. within this second
phase the degree of suitability of the respective model in representing the process
recorded in the log is determined.
table 1. diagnostic results.
m1 m2 m3 m4 m5 m6
f= 1.0 f= 1.0 f= 1.0 f= 1.0 f= 1.0 f= 1.0
l1 as= 0.5263 as= 0.7692 as= 0.1695 as= 0.5 as= 0.4348 as= 0.5556
ab= 0.9740 ab= 0.0 ab= 0.9739 ab= 0.9718 ab= 0.9749 ab= 0.9703
f= 0.9952 f= 1.0 f= 1.0 f= 1.0 f= 1.0 f= 1.0
l2 as= 0.5263 as= 0.7692 as= 0.1695 as= 0.5 as= 0.4348 as= 0.5556
ab= 0.9705 ab= 0.0 ab= 0.9745 ab= 0.9669 ab= 0.9706 ab= 0.9637
f= 0.5397 f= 1.0 f= 0.4947 f= 0.6003 f= 0.6119 f= 0.5830
l3 as= 0.5263 as= 0.7692 as= 0.1695 as= 0.5 as= 0.4348 as= 0.5556
ab= 0.8909 ab= 0.0 ab= 0.8798 ab= 0.8904 ab= 0.9026 ab= 0.8894
regarding the example logs given in figure 1(b)-(d) this means that we only
evaluate the appropriateness measures of those models having a ﬁtness value f=
1.0 (cf. table 1) and therefore completely discard event log l3, which only ﬁts the
trivial model m2, and the model m1for event log l2. for event log l1andl2
9we now want to ﬁnd the most adequate process model among the remaining ones,
respectively. given the fact that neither the structural appropriateness metrics
asnor the behavioral appropriateness metrics abdeﬁnes an optimal point (note
that for the process model m2theasvalue is very high while the abvalue is
very low and vice versa for the other extreme model m3) they both must be
understood as an indicator to be maximized without decreasing the other. a
possible outcome of such a qualitative analysis could be that m1is selected for
l1while m4is selected for l2. more test cases are needed to properly balance
the three metrics.
6 adding conformance to the prom framework
the main concepts discussed in this paper have been implemented in a plug-in
for the prom framework. the conformance checker replays an event log within
a petri net model in a non-blocking way while gathering diagnostic information
that can be accessed afterwards. it calculates the token-based ﬁtness metrics f,
taking into account the number of process instances represented by each logical
log trace, the structural appropriateness as, and the behavioral appropriateness
ab. furthermore, the diagnostic results can be visualized from both a log-based
and model-based perspective.
figure 2. screenshot of the conformance analysis plug-in
during log replay the plug-in takes care of invisible tasks that might enable
the transition to be replayed next, and it is able to deal with duplicate tasks.
the lower part of figure 2 shows the result screen of analyzing the conformance
of event log l2and process model m1. as discussed before, for replaying l2the
model lacks the possibility to skip activity g, which also becomes clear in the
visualization of the model augmented with diagnostic information. in the other
window the process speciﬁcation m4is measured to ﬁt with event log l1.
107 related work
the work reported in this paper is closely related to earlier work on process
mining, i.e., discovering a process model based on some event log. for more
information we refer to a special issue of computers in industry on process
mining [6] and a survey paper [5]. given the scope of this paper, we are unable
to provide a complete listing of the many papers published in recent years.
the work of cook et al. [8,7] is closely related to this paper. in [8] the concept
of process validation is introduced. it assumes an event stream coming from the
model and an event stream coming from real-life observations, both streams
are compared. here the time-complexity is problematic as the state-space of
the model needs to be explored. in [7] the results are extended to include time
aspects. the notion of conformance has also been discussed in the context of
security [3], business alignment [1], and genetic mining [13]. however, in each of
the papers mentioned only ﬁtness is considered and appropriateness is mostly
ignored. in [10] the process mining problem is faced with the aim of deriving a
model which is as compliant as possible with the log data, accounting for ﬁtness
(called completeness) and also behavioral appropriateness (called soundness).
process mining and conformance testing can be seen in the broader con-
text of business (process) intelligence (bpi) and business activity monitoring
(bam). tools such as described in [11,14], however, often focus on performance
measurements rather than monitoring (un)desirable behavior.
8 conclusion
given the presence of both process models and event logs in most organizations
of some complexity, it is interesting to investigate the notion of conformance as
it has been deﬁned in this paper. conformance is an important notion in the
context of business alignment, auditing (cf. sarbanes-oxley (sox) act [15]),
and business process improvement. therefore, the question “does the event log
conform to the process model and vice versa?” is highly relevant.
we have shown that conformance has two dimensions: ﬁtness and appropri-
ateness. fitness can be captured in one metrics ( f). for measuring appropriate-
ness we introduced two metrics: structural appropriateness asand behavioral
appropriateness ab. together these three metrics allow for the quantiﬁcation of
conformance. the metrics deﬁned in this paper are supported by the confor-
mance checker , a tool which has been implemented within the prom framework.
an interesting direction for future research is to exploit log data on a more
ﬁne-grained level (e.g., stating the start and endof activities) and to include
other perspectives such as time, data, and resources. for example, in some ap-
plication the timing of an event is as important as its occurrence.
acknowledgements
the authors would like to thank ton weijters, boudewijn van dongen, ana
karla alves de medeiros, minseok song, laura maruster, eric verbeek, monique
jansen-vullers, hajo reijers, michael rosemann, huub de beer, peter van den
brand, et al. for their on-going work on process mining techniques.
11references
1. w.m.p. van der aalst. business alignment: using process mining as a tool for
delta analysis. in j. grundspenkis and m. kirikova, editors, proceedings of the 5th
workshop on business process modeling, development and support (bpmds’04) ,
volume 2 of caise’04 workshops , pages 138–145. riga technical university, 2004.
2. w.m.p. van der aalst and k.m. van hee. workﬂow management: models, methods,
and systems . mit press, cambridge, ma, 2002.
3. w.m.p. van der aalst and a.k.a. de medeiros. process mining and security:
detecting anomalous process executions and checking process conformance. in
n. busi, r. gorrieri, and f. martinelli, editors, second international workshop
on security issues with petri nets and other computational models (wisp 2004) ,
pages 69–84. star, servizio tipograﬁco area della ricerca, cnr pisa, italy, 2004.
4. w.m.p. van der aalst and m. song. mining social networks: uncovering interac-
tion patterns in business processes. in j. desel, b. pernici, and m. weske, editors,
international conference on business process management (bpm 2004) , volume
3080 of lecture notes in computer science , pages 244–260. springer-verlag, 2004.
5. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
6. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining , special
issue of computers in industry, volume 53, number 3. elsevier science publishers,
amsterdam, 2004.
7. j.e. cook, c. he, and c. ma. measuring behavioral correspondence to a timed
concurrent model. in proceedings of the 2001 international conference on soft-
ware mainenance , pages 332–341, 2001.
8. j.e. cook and a.l. wolf. software process validation: quantitatively measuring
the correspondence of a process to a model. acm transactions on software
engineering and methodology , 8(2):147–176, 1999.
9. j. desel, w. reisig, and g. rozenberg, editors. lectures on concurrency and petri
nets, volume 3098 of lecture notes in computer science . springer-verlag, 2004.
10. g. greco, a. guzzo, l. pontieri, and d. sacc´ a. mining expressive process models
by clustering workﬂow traces. in proc of advances in kowledge discovery and
data mining, 8th paciﬁc-asia conference (pakdd 2004) , pages 52–62, 2004.
11. d. grigori, f. casati, m. castellanos, u. dayal, m. sayal, and m.c. shan. business
process intelligence. computers in industry , 53(3):321–343, 2004.
12. g. keller and t. teufel. sap r/3 process oriented implementation . addison-
wesley, reading ma, 1998.
13. a.k.a. de medeiros, a.j.m.m. weijters, and w.m.p. van der aalst. using ge-
netic algorithms to mine process models: representation, operators and results.
beta working paper series, wp 124, eindhoven university of technology, 2004.
14. m. zur m¨ uhlen and m. rosemann. workﬂow-based process monitoring and con-
trolling - technical and organizational issues. in r. sprague, editor, proceedings
of the 33rd hawaii international conference on system science (hicss-33) , pages
1–10. ieee computer society press, los alamitos, california, 2000.
15. p. sarbanes, g. oxley, and et al. sarbanes-oxley act of 2002, 2002.
16. a.w. scheer. aris: business process modelling . springer-verlag, berlin, 2000.
12