federated process mining: exploiting event data
across organizational boundaries
wil m.p. van der aalst
process and data science (informatik 9), rwth aachen university, aachen, germany and
fraunhofer-institut f ¨ur angewandte informationstechnik (fit), sankt augustin, germany
email: wvdaalst@pads.rwth-aachen.de
abstract —many organizations use process mining to improve
their internal processes. however, many processes span multiple
organizations, e.g., organizations that form a supply chain or a
global production network. in order to improve processes across
different parties, one cannot assume a single overall event log.
organizations may not be willing to share event data and may use
different identiﬁers and logging conventions. federated process
mining aims to tackle these problems by creating views on the
cross-organizational processes such that analysis is possible. a
federated event log transparently maps multiple organization-
speciﬁc event logs into a single uniﬁed representation. using
such a federated event log, it is possible to apply a range of
existing process mining techniques and tools. if organizations
are not willing to share raw event data, they need to resort to
event log abstractions. in such settings, federated process mining
approaches merge these abstractions to create an overall view on
the process. this paper provides a framework to reason about
the different forms of federated process mining enabling inter-
organizational process transparency and improvement.
index terms —process mining, event data, data management,
object-centric processes, supply chains, production networks
i. i ntroduction
process mining research started in the late 1990-ties [1] as a
response to problems related to process modeling and process
automation. many organizations that tried to adopt workﬂow
management (wfm) or business process management (bpm)
systems experienced major problems. wfm/bpm technology
was expensive and doomed to fail when organizations used
idealized models to conﬁgure them [21]. process mining
uses event data to learn and improve the real processes [1].
discovered process models tend to be very different from
hand-made models. conformance checking techniques can be
used to detect and explain deviations between models and
reality. process mining is evidence-based and complements
preexisting process management practices.
currently, there are over 35 providers of commercial process
mining tools (e.g., celonis, fluxicon, minit, mehrwerk, myin-
venio, pafnow, signavio, qpr, and many more) and several
open-source initiatives (e.g., prom, pm4py, rapidprom, and
bupar). the adoption of process mining in practice increased
rapidly in recent years [15]. the main reasons to use process
mining are process transparency, process improvement, cost
reduction, compliance, throughput time reduction, and digital
transformation [10]. however, most applications of process
mining are intra-organizational . typical use cases are found in
procurement, sales, accounting, logistics, production, customerservice, payments, controlling, after-sales, and marketing [10].
process mining is rarely applied in an inter-organizational
setting. this is mostly caused by conﬁdentiality concerns and
interoperability problems. given the huge potential of process
mining as a tool for improving cross-organizational processes,
we present an initial framework for federated process mining .
fig. 1. a network of organizations collecting event data while engaging in
cross-organizational processes.
figure 1 sketches the problem we are trying to address.
consider, for example, a complex supply chain or a global
production network involving multiple organizations. to get an
idea of the complexity of such networks, consider the supply
pyramid of a car manufacturer like bmw. bmw is a so-
called oem (original equipment manufacturer) which gets
system parts from so-called tier-1 suppliers such as bosch,
continental, denso, magna, and zf. these tier-1 suppliers
get components from tier-2 suppliers, which in turn may
get smaller parts from tier-3 suppliers. a single bmw may
have over 30,000 parts, counting every part down to the
smallest screws. bmw’s global production network consists
of 3,200 suppliers at 4,500 production locations in more than
50 countries. in figure 1, all organizations store their own
event data. the challenge is to monitor and improve the overall
process.
the term federated process mining refers to solutions that
transparently map event data from multiple autonomous data
sources into a single federated data source with the goal to
monitor, analyze, and improve cross-organizational processes .
the idea is similar to creating a federated database system
composed of a collection of cooperating database systems that
are autonomous and possibly heterogeneous [22]. the goal of
a federated database system is to provide a uniﬁed view, hiding
irrelevant technical details. in federated process mining, we
have the additional challenge that event data are potentiallyhighly sensitive. a tier-1 supplier may not want to reveal
its internal processes to the oem. however, there are also
many similarities. for example, different organizations may
use different identiﬁers that refer to the same object or concept.
we consider two types of federated process mining . both
start from the assumption that we have norganizations that
collect event data about one or multiple processes. c=
fl1;l2;:::;lngis an event log collection where liis the
event log of organization i2f1;:::;ng. event data may be
stored using standard formats like xes [14] or ocel [13].
however, existing approaches assume a single event log and
not a collection of events logs. how to analyze the overall
process(es) starting from c?
event 
log
l1
event 
log
l2event 
log
l3event 
log
l4event 
log
ln
federated event log...
merge event log collection
process mining 
software
fig. 2. a network of organizations collecting event data while engaging in
cross-organizational processes (type i - federated process mining).
the ﬁrst type of federated process mining is depicted in
figure 2. here the assumption is that the organizations are
willing to share event data. note that these data may have
been ﬁltered to hide certain aspects. the goal is to create a
federated event log. this involves several challenges, as will
be explained later.
the second type of federated process mining is depicted in
figure 3. here the assumption is that the organizations are
notwilling to share event data. instead, only abstractions can
be shared [2]. for example, the different organizations may
be willing to share so-called directly-follows graphs (dfgs)
[3]. a dfg only shows aggregate information and cannot be
used to reconstruct individual process instances.
this paper discusses both types of federated process mining
and introduces a formal framework to reason about process
mining in a cross-organizational setting. the remainder is
organized as follows. section ii introduces basic notations for
process mining in general and event data in particular. we rely
on so-called object-centric event logs (ocel) [13] to ensure
ﬂexibility and handle divergence and convergence in processes
[4]. section iii deﬁnes the problem starting from a collection
of ocel-based data sources. section iv discusses the ﬁrst
event 
log
l1
event 
log
l2event 
log
l3event 
log
l4event 
log
ln
federated event log...
abstraction -based federated process mining softwarela1 la2 la3 la4 lan ...fig. 3. a network of organizations sharing only abstractions of their event
data (type ii - federated process mining).
type of federated process mining which aims at creating a
uniﬁed federated event log. the second type of federated
process mining is discussed in section v. in this scenario
only process-based abstractions [2] are shared. section vi
concludes the paper.
ii. e vent data
event data provide the starting point for process mining .
using process discovery techniques, event data can be used to
uncover the actual processes. using conformance checking ,
differences and commonalities between modeled and real
processes can be analyzed. process discovery and conformance
checking provide the basis for advanced forms of process
mining such as comparative process mining (understanding
performance differences between two processes or the same
process in different periods), predictive process mining (using
the discovered models to predict performance and compli-
ance problems), and action-oriented process mining (turning
insights into actions).
in this paper, we use so-called object-centric event logs
based on the ocel (object-centric event log) standard
[13], see ocel-standard.org for details and examples. to keep
the notations as simple as possible, we use a simpliﬁed
formalization that captures the essence of ocel. the reason
for using ocel rather than xes (http://xes-standard.org/) is
that in cross-organizational settings, it is often unclear what
the case notion should be. in [4], we elaborate on the need for
such a format. we cannot assume that there is a single case
notion, instead we use multiple case notions (called object
types) and each event may refer to any number of objects
corresponding to different object types .
one can convert an object-centric event log into a standard
event log (e.g., in xes format) by picking an object type andreplicating each event for each object of the selected type.
the resulting event log is called the ﬂattened event log. this
approach is often used and works well, however, also has
three possible problems: (1) deﬁciency , (2) convergence , and
(3)divergence . deﬁciency means that events in the original
event log have no corresponding events in the ﬂattened event
log. hence, events may disappear from the data set. con-
vergence refers to the fact that events referring to multiple
objects of the selected type are replicated, possibly leading
to unintentional duplication. for example, when computing
costs or resource usage such replicated events can be very
misleading. divergence points to the more subtle problem that
events referring to different objects of a type not selected as
the case notion are considered to be causally related. for
example, two events refer to the same purchase order but
different products, or two events refer to the same patient but
different blood samples. this creates loops that do not really
exist (interleaving of causally unrelated events). to avoid such
problems, we developed techniques for object-centric process
mining , e.g., learning object-centric petri nets that do not have
the three problems mentioned [5]. although this is outside the
scope of this paper, it is important to note that, in a cross-
organizational setting, we cannot assume a single case notion
or start from a ﬂattened event log.
first, we deﬁne universes for event identiﬁers, object iden-
tiﬁers, attribute names, attribute values, activities, timestamps,
attribute name value mappings, and object types. activities
and timestamps can be seen as special values.
deﬁnition 1 (universes): eis the universe of event identi-
ﬁers,ois the universe of object identiﬁers (such that e\o =
;),nis the universe of attribute names, vis the universe of
attribute values,av is the universe of activities, t v
is the universe of timestamps (totally ordered), m=n6!v
is the set of attribute name value mappings, and ot is the
universe of object types.
an attribute name value mapping f2m =n6!v is a
partial function mapping attribute names onto attribute values.
this allows us to compactly deﬁne a simpliﬁed object-centric
event log . deﬁnition 2 captures the essence of the ocel
(object-centric event log) standard [13], see ocel-standard.
org. a simpliﬁed object-centric event log refers to a collection
of related events and objects. each event has an activity name
and timestamp. next to the timestamps there may be a partial
order that may be stricter or more liberal, but should not be
conﬂicting.
deﬁnition 2 (simpliﬁed object-centric event logs): a
simpliﬁed object-centric event log l= (e;;o;r; )is
composed of a set of events e e , a strict partial order
ee,1a set of objects oo , a relationreo,
a function2(e[o)!m such that for any e2e:
fact;timeg dom((e)),(e)(act)2a, and(e)(time)2
t, for anyo2o:ftypeg dom((o)),(o)(type)2ot .
lis the universe of simpliﬁed object-centric event logs.
1a strict partial order is irreﬂexive, transitive, and asymmetric. hence, for
anye; e1; e2; e32e:ee(irreﬂexivity), if e1e2ande2e3, then
e1e3(transitivity), and if e1e2, then e2e1(asymmetry).to improve readability, we use the notation x(e) =
(e)(x)andy(e) =(o)(y)to refer to an event attribute
xofeand an object attribute yofo. for example, act(e) =
(e)(act)is the activity performed by event e,time(e) =
(e)(time)is the timestamp of event e,type(o) =(o)(type)
is the object type of object o. instead of writing “simpliﬁed
object-centric event log”, we simply refer to l2l as an event
log, knowing that it is not a conventional event log.
consider an example event log l= (e;;o;r; )with:
e=fe1;e2;e3;e4;:::gis the set of events,
=f(e1;e2);(e1;e3);(e1;e4);:::gis the strict partial
order,
o=fo1;o2;o3;o4;:::gis the set of objects,
r =f(e1;o1);(e1;o2);(e1;o3);(e1;o4);(e2;o2);
(e3;o3);(e4;o4);:::grelates events and objects,
dom((e1)) = dom((e2)) = dom((e3)) =
dom((e4)) =fact;time;:::g,
dom((o1)) =ftype;price;:::gand dom((o2)) =
dom((o3)) = dom((o4)) =ftype;prod;:::g,
act(e1) = place order ,act(e2) =act(e3) =
act(e4) =pick item , etc.
time(e1) = 14:23,time(e2) = 14:55,time(e3) =
15:05,time(e4) =15:10, etc.
type(o1) = order ,type(o2) =type(o3) =
type(o4) =item , etc.
price(o1) =$825.23,prod(o2) =iphone,prod(o3) =
ipad,prod(o4) =ipod, etc.
note that event e1refers to one order and three items (one
iphone, one ipad, and one ipod). events e2,e3, ande3refer
to a single item.
to be as general as possible, events have timestamps and are
partially ordered. note that may express causalities. also,
timestamps may be coarse-granular, e.g., just a date (or even
a week number or year). therefore, two events that happen on
the same day may have the same timestamp. it is also possible
that events are not ordered according to . in fact, it is possible
that=;(i.e., no ordering relations). the other extreme
is thatis a strict total ordering. we typically require that
both ordering relations (time-based and ) are not conﬂicting,
leading to the notion of consistency.
deﬁnition 3 (consistent): letl= (e;;o;r; )2 l
be an event log. lis consistent if for any e1;e22esuch
thate1e2:time(e1)time(e2)(i.e., partial order and
timestamps do not disagree). lis time-constrained if for any
e1;e22e:e1e2)time(e1)<  time(e2).lis order-
constrained if for any e1;e22e:time(e1)<  time(e2))
e1e2.
as mentioned earlier, event logs can be ﬂattened by picking
an object type as a case notion.
deﬁnition 4 (flattened event log): letl= (e;;
o;r; )2l be an event log and ot2ot be an object
type.oot=fo2ojtype(o) = otgare the objects
of type ot.lot2oot!emaps each object of type
otonto a sequence of events such that for any o2oot
andlot(o) =o=he1;e2;:::;ejojithe following holds
fe1;e2;:::;ejojg=fe2ej(e;o)2rg, and for any 1i < jjoj:ei6=ej,eiej, andtime(ei)time(ej).
lotis an ot-ﬂattened event log of l.
a ﬂattened event log lotmaps each object oonto a
sequence of events lot(o). this implies that within such a
sequence, events are totally ordered. since the timestamps and
ordering relationonly provide a partial order, this total order
may be non-deterministic.
using our example event log and picking object type
item .oitem=fo2;o3;o4;:::g,litem(o2) =he1;e2;:::i,
litem(o3) =he1;e3;:::i,litem(o4) =he1;e4;:::i, etc.
to apply standard process mining techniques (e.g., basic
control-ﬂow discovery), we aim for an event log that is
represented as a multiset of traces (i.e., sequences of activities).
therefore, we map events onto their activity names.
deﬁnition 5 (log simpliﬁcation): letl= (e;;
o;r; )2 l be an event log and lot2oot!e
anot-ﬂattened event log of l.ot
act(l) = [act(lot(o))j
o2oot]is a multiset of activity sequences with
act(he1;e2;:::;eni) =hact(e1);act(e2);:::; act(en)i,
i.e., each event is replaced by the corresponding activity.
using our example event log, we get item
act(l) = [
hplace order;pick item;:::i;hplace order;pick item;
:::i;hplace order;pick item;:::i;:::]. note that in such a
multiset the same trace may appear many times.
there exist a few process mining techniques that work
directly on object-centric event logs [5]. however, the majority
of tools and techniques require ﬂattened event logs. hence, one
should be aware of possible interpretations problems due to
divergence and convergence [5].
fig. 4. dfg discovered by celonis for the road trafﬁc fine management
(rtfm) event log in [8].
to illustrate what one can do with ﬂattened event logs, we
use a publicly available event log [8] taken from an italian
information system managing road trafﬁc ﬁnes. the event
log has 561,470 events containing information about 150,370
trafﬁc violations. figure 4 shows a directly-follows graph
(dfg) generated by celonis (www.celonis.com). the samegraph could have been generated by any of the commercial
and open-source systems mentioned earlier (e.g., prom, disco,
minit, myinvenio, pafnow, and qpr).
fig. 5. conformance checking results for the rtfm event log in [8] and the
bpmn model in figure 6.
fig. 6. bpmn model discovered using the inductive miner in celonis for the
rtfm event log in [8].
figure 5 shows conformance diagnostics for the event log
and the bpmn model shown in figure 6. celonis discovered
19 unique deviations between the model and log. 98% of the
cases are conforming. the 2560 non-conforming cases take, on
average, 121 days longer and have three more steps. detailed
diagnostics are provided for each deviation. the process model
in figure 6 was discovered using the inductive miner [16]
in celonis based on the most frequent variants. to check
conformance, we could also have modeled the process by
hand.
figures 4, 5, and 6 illustrate that process mining can be used
to discover processes, check compliance, analyze bottlenecks,
etc. process mining results can be particularly valuable in
processes crossing organizational boundaries. however, this
is problematic, as mentioned in the introduction. therefore,
we elaborate on techniques for federated process mining.
iii. e vent logcollection
figures 2 and 3 illustrate the problem we are trying to
address in this paper. there are norganizations each logging
events. how to use a heterogeneous collection of nlocal event
logs to make statements about the overall process?deﬁnition 6 (event log collection): an event log collection
c=fl1;l2;:::;lngl is a set of event logs such that the
sets of events are pairwise disjoint. li= (ei;i;oi;ri;i)
refers to the i-th object-centric event log and for any 1i<
jn:ei\ej=;.
we assume that all local events have a unique identiﬁer, i.e.,
an event identiﬁer can only appear in one event log. object
identiﬁers may be shared among different event logs. given
an event log collection c=fl1;l2;:::;lng, we would like
to make statements about cross-organizational processes. for
example, what is the cause of a new bottleneck or what will
the resource load be tomorrow. without information sharing,
organization ican only see liwhereas performance and
compliance problems may be caused by behavior in lj(with
j6=i).
in this paper, we consider two types of federated process
mining. the ﬁrst type (depicted in figure 2) creates a federated
event log by merging the different event logs. the second
type of federated process mining (depicted in figure 3) uses
abstractions, i.e., the different parties do not share events,
but use aggregated statements about processes like dfgs or
similar. these abstractions are merged to make statements
about the overall processes.
before we discuss possible solutions, we ﬁrst mention some
of the main challenges.
the different event logs may use different object identi-
ﬁers. object linkage (also known as record linkage, data
matching, entity resolution, etc.) is the task of ﬁnding
objects in different data sources that refer to the same
object.
we assume that each event appears in only one event
log (unique identiﬁers). however, recorded events on the
interface of two or more organizations may refer to the
same logical event (e.g., a send event and a receive
event that refer to the same message of a procedure call
recorded by the caller and callee).
the different organizations may use different clocks and
record at different levels of granularity . for example,
one organziation only records dates whereas another
organization records events with millisecond precision.
there may be many conﬁdentiality considerations pre-
venting organizations from sharing data. as a result,
events may be suppressed or other conﬁdentiality pre-
serving operations may be performed (e.g., adding noise)
[19], [20].
some initial work has been done on applying process
mining in an inter-organizational setting. in [9], we presented
the edimine framework for enabling the application of pro-
cess mining techniques in the ﬁeld of edi-supported inter-
organizational business processes, and for supporting inter-
organizational performance evaluation using business infor-
mation from edi messages, event logs, and process models.
in [17], we describe seven basic patterns to capture modeling
concepts that arise commonly in supply chains. these patterns
can be combined to build an overall petri net that can be
analyzed using dependency graphs and simulation. the paper[18], was the ﬁrst work considering the application of process
mining in supply chains. in [11] a standard for processing
radio frequency identiﬁcation (rfid) events was proposed
to make supply chain data accessible for process mining. the
same authors provide a more detailed paper [12] focusing
on different case notions in supply chains where objects are
grouped (e.g., items into packages and packages into contain-
ers). however, none of the approaches mentioned addresses
the problem of federated process mining in a comprehensive
manner. also, there has been tremendous progress in process
mining, not only in terms of techniques for process discovery
and conformance checking, but also in new logging formats
like ocel. therefore, this paper provides a framework for
federated process mining starting from ocel-like event logs.
in the remainder, we discuss the two types of federated
process mining. section iv shows how to create a uniﬁed event
log and section v assumes that parties only share process-
based abstractions rather than event logs.
iv. c reating a f ederated event log
as shown in figure 2, the ﬁrst type of federated process
mining creates a federated event log . the naive approach
would be to simply merge the nevent logs. however, the
organizations may use different identiﬁers to refer to the same
object or events. hence, we use a mapping cto relate both.
deﬁnition 7 (federated event log): letc =
fl1;l2;:::;lng  l be an event log collection with
li= (ei;i;oi;ri;i)for1in.e=s
1ineiand
o=s
1inoi. letc2(e[o)6!((e[o)ndom(c)).
cis a partial function, i.e., dom(c)e[o. we require
that for any e2dom(c)\e:c(e)2e, and for any
o2dom(c)\o:c(o)2o.
givenc, we create the federated event log lc= (e0;0;
o0;r0;0)2l with
e0=endom(c),
~c(x) =c(x)ifx2dom(c)and~c(x) =xif
x62dom(c),
0=f(~c(e1);~c(e2))j91in9(e1;e2)2ee1ie2g+,
o0=ondom(c),
r0=f(~c(e);~c(o))j(e;o)2rg, and
02(e0[o0)!m such that for any x2e0[o0:
0(x) =l
1inl
y2ei[oijc(y)=xi(y).2
mappingcplays a key role in deﬁnition 7. events in
e00=e\dom(c)and objects in o00=o\dom(c)do
not appear in the federated event log. only the events e0=
endom(c)and objectso0=ondom(c)remain. however,
properties of the events in e00and objects o00are transferred
to their “surviving counterparts”. this includes the attributes
(0) and the event-object relationships ( r0).
0merges the relations in iand takes the transitive closure
of the strict partial orders. due to this and the mapping c,
the result may not be a strict partial order (e.g., a cycle is
2letf1andf2be two functions, f=f1f2merges both such that
dom (f) = dom (f1)[dom (f2)and for any x2dom (f1)ndom (f2):
f(x) =f1(x), and x2dom (f2):f(x) =f2(x).l
1infi=f1
f2: : :fn.introduced). therefore, there may be different ways of merging
iwith 1ininto0such that the results is again a
strict partial order.
similar challenges need to be addressed with respect to
time. the individual event logs may be consistent, but consider
time at different levels of granularity. one organization may
record time in days, the other in hours, and the third one
in seconds. when merging the event data, this may lead
to inconsistencies. this can be addressed by choosing the
coarsest level of time granularity and further strengthen the
strict partial orders to not lose information.
deﬁnition 7 does not allow for the creation of new events
or objects. of course, one can also think of the addition of
new events or objects. moreover, events or objects can also be
discarded completely (without mapping them). however, the
main idea of the ﬁrst type of federated process mining should
be clear: an event log collection c=fl1;l2;:::;lngis
turned into an overall object-centric event log l.
such an overall object-centric event log lmay be material-
ized (i.e., a new event log is created and stored) or only exist
as a virtual event log like in a federated database system [22].
v. f ederated process mining using abstractions
often, it is unfeasible to share event data, e.g., for conﬁden-
tiality reasons. in such settings, organizations may still share
abstractions. this is similar to using multi-echelon inventory
models in logistics [7]. multi-echelon inventory models use
aggregated inventory levels across the supply chain taking into
account stocks at other echelons. these models are used to
determine safety stock buffers across the entire supply chain,
taking into account aggregated information on downstream
and upstream inventory levels. for example, low inventory
levels in a central warehouse need to be considered in relation
to inventory levels in warehouses closer to the customer.
there is no need to increase stock when downstream stock is
accumulating. in such multi-echelon inventory models there
is no need to know the unique identiﬁers of products, only
quantities sufﬁce.
such ideas can also be applied to cross-organizational
process mining. instead of sharing event data, one can use
abstractions [2].
deﬁnition 8 (log abstraction): la is the universe of log
abstractions (e.g., log statistics, dfgs, footprints, etc.). an
abstraction function abs2l!la is a function that maps
event logs onto an abstraction. for any la2la :abs 1(la) =
fl2lj abs(l) =lagis the set of all event logs having the
same abstraction la.
in [2] the notion of event log and process model abstraction
was discussed in detail. three characteristic abstractions used
in the context of process mining are: directly-follows graphs
(dfgs), transition systems (and other types of automata),
and cardinality constraint models [2]. for example, figure 4
shows a dfg generated by celonis based on 561,470 events
related to 150,370 trafﬁc ﬁnes [4]. there are many event logs
that return the dfg shown in figure 4. this is the idea of
abs 1(la):l2abs 1(la)if and only if abs(l) = la. thisshows that the dfg provides information without relating it
to individual ﬁnes.
to construct a dfg, we need to pick a case notion (i.e.,
ﬂatten the object-centric event log). in case of multiple object
types, the abstraction could be an array of dfgs (one for each
object type) or higher-level representations as described in [5].
anabstraction collection is a set of abstractions in the sense
of [2]. just like in multi-echelon inventory models, the goal is
to only share aggregated information and still make informed
decisions.
deﬁnition 9 (abstraction collection): letc=fl1;l2;
:::;lngl be an event log collection with li= (ei;i
;oi;ri;i)for1in.a=fla1;la2;:::; langis a set
of abstractions such that lai=abs(li).
for the second type of federated process mining, depicted
in figure 3, we merge the different abstractions.
deﬁnition 10 (merging abstractions): leta=fla1;
la2;:::; langbe an abstraction collection based on nevent
logs. merge (a)2la is an overall abstraction obtained by
merging the individual abstractions.
how this is done is a topic of ongoing research. there
is clearly a need for dedicated abstraction-based federated
process mining software (cf. figure 3). since merge (a)2la
and abs 1(merge (a))characterizes the set of all possible
federated event logs, both types of federated process mining
can be related.
vi. c onclusion
this paper introduced the notion of federated process min-
ingand provided a formal framework to reason about cross-
organizational process mining. we discussed the challenges
and identiﬁed two different types of federated process mining:
(1) approaches where we create a federated event log and
(2) approaches based on merging abstractions without sharing
event data. the topic is also related to the so-called internet-of-
production (iop) developed in aachen as part of the german
excellence strategy [6]. within iop, process mining plays a
key role to create so-called “digital shadows” that can be
used to analyze and improve operational processes. thus far,
the focus within iop was on intra-organizational operational
processes. however, as discussed in this paper, the importance
ofnetworks of organizations and processes is rising. therefore,
we would like to develop dedicated techniques and tools for
both types of federated process mining.
acknowledgment
the author thanks the alexander von humboldt (avh)
stiftung and the deutsche forschungsgemeinschaft (dfg,
german research foundation) under germany’s excellence
strategy–exc-2023 internet of production (390621612) for
supporting our research.
references
[1] w.m.p. van der aalst. process mining: data science in action . springer-
verlag, berlin, 2016.
[2] w.m.p. van der aalst. process discovery from event data: relating
models and logs through abstractions. wires data mining and
knowledge discovery , 8(3), 2018.[3] w.m.p. van der aalst. a practitioner’s guide to process mining:
limitations of the directly-follows graph. in international conference
on enterprise information systems (centeris 2019) , volume 164 of
procedia computer science , pages 321–328. elsevier, 2019.
[4] w.m.p. van der aalst. object-centric process mining: dealing with
divergence and convergence in event data. in p.c. ¨olveczky and
g. sala ¨un, editors, software engineering and formal methods (sefm
2019) , volume 11724 of lecture notes in computer science , pages 3–25.
springer-verlag, berlin, 2019.
[5] w.m.p. van der aalst and a. berti. discovering object-centric petri
nets. fundamenta informaticae , 175(1-4):1–40, 2020.
[6] w.m.p. van der aalst, t. brockhoff, a. farhang, m. pourbafrani, m.s.
uysal, and s. j. van zelst. removing operational friction using process
mining: challenges provided by the internet of production (iop). in
s. hammoudi and c. quix, editors, data management technologies
and applications (data 2020) , volume 1446 of communications in
computer and information science , pages 1–31. springer-verlag, berlin,
2021.
[7] t de kok, c. grob, m. laumanns, s. minner, j. rambau, and k. schade.
a typology and literature review on stochastic multi-echelon inven-
tory models. european journal of operational research , 269(3):955–
983, 2018.
[8] m. de leoni and f. mannhardt. road trafﬁc fine man-
agement process (4tu.researchdata). https://doi.org/10.4121/uuid:
270fd440-1057-4fb9-89a9-b699b47990f5, 2015.
[9] r. engel, w. krathu, m. zapletal, c. pichler, j.c. bose, w.m.p. van
der aalst, h. werthner, and c. huemer. analyzing inter-organizational
business processes. information systems and e-business management ,
14(3):577–612, 2016.
[10] g. galic and m. wolf. global process mining survey 2021: delivering
value with process analytics - adoption and success factors of process
mining . deloitte, 2021. https://www2.deloitte.com/de/de/pages/ﬁnance/
articles/global-process-mining-survey-2021.html.
[11] k. gerke, a. claus, and j. mendling. process mining of rfid-based
supply chains. in ieee conference on commerce and enterprise
computing , pages 285–292, 2009.
[12] k. gerke, j. mendling, and k. tarmyshov. case construction formining supply chain processes. in a. abramowicz, editor, business
information systems (bis 2009) , volume 21 of lecture notes in business
information processing , pages 181–192. springer-verlag, berlin, 2009.
[13] a.f. ghahfarokhi, g. park, a. berti, and w.m.p. van der aalst. ocel
standard. www.ocel-standard.org, 2021.
[14] ieee task force on process mining. xes standard deﬁnition.
www.xes-standard.org, 2016.
[15] m. kerremans. gartner market guide for process mining, research
note g00733123. www.gartner.com, 2020.
[16] s.j.j. leemans, d. fahland, and w.m.p. van der aalst. scalable process
discovery and conformance checking. software and systems modeling ,
17(2):599–631, 2018.
[17] e. liu, a. kumar, and w.m.p. van der aalst. a formal modeling
approach for supply chain event management. decision support
systems , 43(3):761–778, 2007.
[18] l. maruster, j.c. wortmann, a.j.m.m. weijters, and w.m.p. van der
aalst. discovering distributed processes in supply chains. in h. jagdev,
j.c. wortmann, and h.j. pels, editors, collaborative systems for
production management , pages 219–243. elsevier science publishers,
amsterdam, 2003.
[19] m. raﬁei, m. wagner, and w.m.p. van der aalst. tlkc-privacy model
for process mining. in f. dalpiaz, j. zdravkovic, and p. loucopoulos,
editors, international conference on research challenges in informa-
tion science (rcis 2020) , volume 385 of lecture notes in business
information processing , pages 398–416. springer-verlag, berlin, 2020.
[20] m. raﬁei, l. von waldthausen, and w.m.p. van der aalst. supporting
conﬁdentiality in process mining using abstraction and encryption. in
p. ceravolo, m. van keulen, and m.t. gomez lopez, editors, postpro-
ceedings international symposium on data-driven process discovery
and analysis , volume 379 of lecture notes in business information
processing , pages 101–123. springer-verlag, berlin, 2020.
[21] h.a. reijers, i.t.p. vanderfeesten, and w.m.p. van der aalst. the
effectiveness of workﬂow management systems: a longitudinal study.
international journal of information management , 36(1):126–141, 2016.
[22] a.p. sheth and j.a. larson. federated database systems for managing
distributed, heterogeneous, and autonomous databases. acm computing
surveys , 22(3):183–236, 1990.