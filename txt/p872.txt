event abstraction for process mining using supervised
learning techniques
tax, n.; sidorova, n.; haakma, r.; van der aalst, w.m.p.
published in:
proceedings of the sai intelligent systems conference (intellisys 2016), 21-22 september 2016, london,
united kingdom
published: 01/08/2017
document version
accepted manuscript including changes made at the peer-review stage
please check the document version of this publication:
• a submitted manuscript is the author's version of the article upon submission and before peer-review. there can be important differences
between the submitted version and the official published version of record. people interested in the research are advised to contact the
author for the final version of the publication, or visit the doi to the publisher's website.
• the final author version and the galley proof are versions of the publication after peer review.
• the final published version features the final layout of the paper including the volume, issue and page numbers.
link to publication
citation for published version (apa):
tax, n., sidorova, n., haakma, r., & van der aalst, w. m. p. (2017). event abstraction for process mining using
supervised learning techniques. in y. bi, s. kapoor, & r. bhatia (eds.), proceedings of the sai intelligent
systems conference (intellisys 2016), 21-22 september 2016, london, united kingdom (pp. 251-269). (lnns;
vol. 15). dordrecht: springer netherlands.
general rights
copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners
and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.
            • users may download and print one copy of any publication from the public portal for the purpose of private study or research.
            • you may not further distribute the material or use it for any profit-making activity or commercial gain
            • you may freely distribute the url identifying the publication in the public portal ?
take down policy
if you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately
and investigate your claim.
download date: 14. jan. 2018sai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
event abstraction for process mining using
supervised learning techniques
niek tax
eindhoven university of technology
department of mathematics and computer science
p.o. box 513, 5600mb eindhoven
the netherlands
email: n.tax@tue.nl
natalia sidorova
eindhoven university of technology
department of mathematics and computer science
p.o. box 513, 5600mb eindhoven
the netherlands
email: n.sidorova@tue.nlreinder haakma
philips research
prof. holstlaan 4
5665 aa eindhoven
the netherlands
email: reinder.haakma@philips.com
wil m. p. van der aalst
eindhoven university of technology
department of mathematics and computer science
p.o. box 513, 5600mb eindhoven
the netherlands
email: w.m.p.v.d.aalst@tue.nl
abstract —process mining techniques focus on extracting in-
sight in processes from event logs. in many cases, events recorded
in the event log are too ﬁne-grained, causing process discovery
algorithms to discover incomprehensible process models or pro-
cess models that are not representative of the event log. we show
that when process discovery algorithms are only able to discover
an unrepresentative process model from a low-level event log,
structure in the process can in some cases still be discovered by
ﬁrst abstracting the event log to a higher level of granularity. this
gives rise to the challenge to bridge the gap between an original
low-level event log and a desired high-level perspective on this
log, such that a more structured or more comprehensible process
model can be discovered. we show that supervised learning can
be leveraged for the event abstraction task when annotations with
high-level interpretations of the low-level events are available for
a subset of the sequences (i.e., traces). we present a method
to generate feature vector representations of events based on
xes extensions, and describe an approach to abstract events in
an event log with condition random fields using these event
features. furthermore, we propose a sequence-focused metric to
evaluate supervised event abstraction results that ﬁts closely to
the tasks of process discovery and conformance checking. we
conclude this paper by demonstrating the usefulness of supervised
event abstraction for obtaining more structured and/or more
comprehensible process models using both real life event data
and synthetic event data.
keywords —process mining, event abstraction, probabilistic
graphical models
i. i ntroduction
process mining is a fast growing discipline that combines
knowledge and techniques from computational intelligence,
data mining, process modeling and process analysis [1]. pro-
cess mining focuses on the analysis of event logs, which
consists of sequences of real-life events observed from process
executions, originating e.g. from logs from erp systems. an
important subﬁeld of process mining is process discovery,
which is concerned with the task of ﬁnding a process model
fig. 1: an excerpt of a ”spaghetti”-like process model.
that is representative of the behavior seen in an event log.
many different process discovery algorithms exist ([2], [3],
[4], [5], [6]), and many different types of process models can
be discovered by process discovery methods, including bpmn
models, petri nets, process trees, and statecharts.
as event logs are often not generated speciﬁcally for the
application of process mining, events granularity of the event
log at hand might be too low level. it is vital for successful
application of process discovery techniques to have event
logs at an appropriate level of abstraction. process discovery
techniques when the input event log is too low level might
result in process model with one or more undesired properties.
first of all, the resulting process model might be ”spaghetti”-
like, as shown in figure 1, containing of an uninterpretable
mess of nodes and connections. the aim of process discovery
is to discover a structured, ”lasagna”-like, process model as
shown in figure 2, which is much more interpretable than a
”spaghetti”-like model. secondly, the activities in the process
ieee 1 jp a g earxiv:1606.07283v1  [cs.lg]  23 jun 2016sai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
fig. 2: a structured, or ”lasagna”-like, process model.
model might have too speciﬁc, non-meaningful, names. third,
as we show in section iv, process discovery algorithms are
sometimes not able to discover a process model that represents
the low-level event log well, while being able to discover to
discover a representative process model from a corresponding
high-level event log. the problems mentioned illustrate the
need for a method to abstract too low-level event logs into
higher level event logs.
several methods have been explored within the process
mining ﬁeld that address the challenge of abstracting low-level
events to higher level events ([7], [8], [9]). existing event ab-
straction methods rely on unsupervised learning techniques to
abstract low-level into high-level events by clustering together
groups of low-level events into one high-level event. however,
using unsupervised learning introduces two new problems.
first, it is unclear how to label high-level events that are
obtained by clustering low-level events. current techniques
require the user / process analyst to provide high-level event
labels themselves based on domain knowledge, or generate
long labels by concatenating the labels of all low-level events
incorporated in the cluster. however, long concatenated labels
quickly become unreadable for larger clusters, and it is far
from trivial for a user to come up with sensible labels man-
ually. in addition, unsupervised learning approaches for event
abstraction give no guidance with respect to the desired level of
abstraction. many existing event abstraction methods contain
one or more parameters to control the degree in which events
are clustered into higher level events. finding the right level
of abstraction providing meaningful results is often a matter
of trial-and-error.
in some cases, training data with high-level target labels
of low-level events are available, or can be obtained, for a
subset of the traces. in many settings, obtaining high-level
annotations for all traces in an event log is infeasible or too
expensive. learning a supervised learning model on the set oftraces where high-level target labels are available, and applying
that model to other low-level traces where no high-level labels
are available, allows us to build a high-level interpretation of
a low-level event log, which can then be used as input for
process mining techniques.
in this paper we describe a method for supervised event
abstraction that enables process discovery from too ﬁne-
grained event logs. this method can be applied to any event
log where higher level training labels of low level events
are available for a subset of the traces in the event log. we
start by giving an overview of related work from the activity
recognition ﬁeld in section ii. in section iii we introduce basic
concepts and deﬁnitions used throughout the rest of the paper.
section iv explains the problem of not being able to mine
representative process models from low-level data in more
detail. in section v we describe a method to automatically
retrieve a feature vector representation of an event that can
be used with supervised learning techniques, making use of
certain aspects of the xes standard deﬁnition for event logs
[10]. in the same section we describe a supervised learning
method to map low-level events into target high-level events.
sections vi and vii respectively show the added value of
the described supervised event abstraction method for process
mining on a real life event log from a smart home environment
and on a synthetic log from a digital photocopier respectively.
section viii concludes the paper.
ii. r elated work
supervised event abstraction is an unexplored problem in
process mining. a related ﬁeld is activity recognition within
the ﬁeld of ubiquitous computing. activity recognition focuses
on the task of detecting human activity from either passive
sensors [11], [12], wearable sensors [13], [14], or cameras [15].
activity recognition methods generally work on discrete time
windows over the time series of sensor values and aim to map
each time window onto the correct type of human activity,
e.g.eating orsleeping . activity recognition methods can be
classiﬁed into probabilistic approaches [11], [12], [13], [14]
and approaches based on ontology reasoning [16], [17]. the
strength of probabilistic system based approaches compared to
methods based on ontology reasoning is their ability to handle
noise, uncertainty and incomplete in sensor data [16].
tapia [12] was the ﬁrst to explore supervised learning
methods to infer human activity from passive sensors, using
a naive bayes classiﬁer. more recently, probabilistic graphical
models started to play an important role in the activity recog-
nition ﬁeld [11], [18]. van kasteren et al. [11] explored the use
conditional random fields [19] and hidden markov models
[20]. van kasteren and kr ¨ose [18] applied bayesian networks
[21] on the activity recognition task. kim et al. [22] found
hidden markov models to be incapable of capturing long-
range or transitive dependencies between observations, which
results in difﬁculties recognizing multiple interacting activities
(concurrent or interwoven). conditional random fields do not
posses these limitations.
the main differences between existing work in activity
recognition and the approach presented in this paper are the
input data on which they can be applied and the generality
of the approach. activity recognition techniques consider the
ieee 2 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
input data to be a multidimensional time series of the sensor
values over time based on which time windows are mapped
onto human activities. an appropriate time window size is
determined based on domain knowledge of the data set. in
supervised event abstraction we aim for a generic method that
works for all xes event logs in general. a time window
based approach contrasts with our aim for generality, as no
single time window size will be appropriate for all event logs.
furthermore, the durations of the events within a single event
log might differ drastically (e.g. one event might take seconds,
while another event takes months), in which case time window
based approaches will either miss short events in case of larger
time windows or resort to very large numbers of time windows
resulting in very long computational time. therefore, we map
each individual low-level event to a high-level event and do
not use time windows. in a smart home environment context
with passive sensors, each change in a binary sensor value can
be considered to be a low-level event.
iii. p reliminaries
in this section we introduce basic concepts used throughout
the paper.
we use the usual sequence deﬁnition, and denote a se-
quence by listing its elements, e.g. we write ha1;a2;:::;a ni
for a (ﬁnite) sequence s:f1;:::;ng!sof elements from
some alphabet s, wheres(i) =aifor anyi2f1;:::;ng.
a. xes event logs
we use the xes standard deﬁnition of event logs, an
overview of which is shown in figure 3. xes deﬁnes an
event logas a set of traces , which in itself is a sequence of
event s. the log, traces and events can all contain one or more
attribute s, which consist of a keyand a value of a certain
type. event or trace attributes may be global , which indicates
that the attribute needs to be deﬁned for each event or trace
respectively. a log contains one or more classiﬁer s, which can
be seen as labeling functions on the events of a log, deﬁned on
global event attributes. extension s deﬁne a set of attributes on
log, trace, or event level, in such a way that the semantics
of these attributes are clearly deﬁned. one can view xes
extensions as a speciﬁcation of attributes that events, traces,
or event logs themselves frequently contain. xes deﬁnes the
following standard extensions:
concept speciﬁes the generally understood name
of the event/trace/log (attribute ’con-
cept:name’).
lifecycle speciﬁes the lifecycle phase (attribute
’lifecycle:transition’) that the event rep-
resents in a transactional model of their
generating activity. the lifecycle exten-
sion also speciﬁes a standard transac-
tional model for activities.
organizational speciﬁes three attributes for
events, which identify the actor
having caused the event (attribute
’organizational:resource’), his
role in the organization (attribute
’organizational:role’), and the group or
department within the organization
fig. 3: xes event log meta-model, as deﬁned in [10].
where he is located (attribute
’organizational:group’).
time speciﬁes the date and time at
which an event occurred (attribute
’time:timestamp’).
semantic allows deﬁnition of an activity meta-
model that speciﬁes higher-level aggre-
gate views on events (attribute ’seman-
tic:modelreference’).
we introduce a special attribute of type string with key label ,
which represents a high-level version of the generally under-
stood name of an event. the concept name of a event is then
considered to be a low-level name of an event. the semantic
extension closely resembles the label attribute, however, by
specifying relations between low-level and high-level events
in a meta-model, the semantic extension assumes that all
instances of a low-level event type belong to the same high-
level event type. the label attribute speciﬁes the high-level
label for each event individually, allowing for example one
low-level event of low-level type dishes & cups cabinet to
be of high-level type taking medicine , and another low-level
event of the same type to be of high-level type eating . note
that for some traces high-level annotations might be available,
in which case its events contain the label attribute, while other
traces might not be annotated. high-level interpretations of
unannotated traces, by inferring the label attribute based on
information that is present in the annotated traces, allow the use
of unannotated traces for process discovery and conformance
checking on a high level.
b. petri nets
a process modeling notation frequently used as output of
process discovery techniques is the petri net. petri nets are
ieee 3 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
directed bipartite graphs consisting of transitions and places,
connected by arcs. transitions represent activities, while places
represent the status of the system before and after execution
of a transition. labels are assigned to transitions to indicate
the type of activity that they represent. a special label is
used to represent invisible transitions, which are only used for
routing purposes and do not represent any real activity.
deﬁnition 1 (labeled petri net): a labeled petri net is a
tuplen= (p;t;f;r;` )wherepis a ﬁnite set of places, t
is a ﬁnite set of transitions such that p\t=;, andf
(pt)[(tp)is a set of directed arcs, called the ﬂow
relation,ris a ﬁnite set of labels representing event types,
with =2ris a label representing an invisible action, and
`:t!r[is a labeling function that assigns a label to
each transition.
the state of a petri net is deﬁned w.r.t. the state that a
process instance can be in during its execution. a state of a
petri net is captured by the marking of its places with tokens. in
a given state, each place is either empty, or it contains a certain
number of tokens. a transition is enabled in a given marking
if all places with an outgoing arc to this transitions contain
at least one token. once a transition ﬁres (i.e. is executed),
a token is removed from all places with outgoing arcs to the
ﬁring transition and a token is put to all places with incoming
arcs from the ﬁring transition, leading to a new state.
deﬁnition 2 (marking, enabled transitions, and firing):
a marked petri net is a pair (n;m ), where
n = (p;t;f;l;` )is a labeled petri net and where
m2b(p)denotes the marking of n. forn2(p[t)we
usenandnto denote the set of inputs and outputs of n
respectively. let c(s;e)indicate the number of occurrences
(count) of element ein multiset s. a transition t2tis
enabled in a marking mof netnif8p2t:c(m;p )>0.
an enabled transition tmay ﬁre, removing one token from
each of the input places tand producing one token for each
of the output places t.
figure 4 shows three petri nets, with the circles repre-
senting places, the squares representing transitions. the black
squares represent invisible transitions, or, transitions. places
annotated with an fbelong to the ﬁnal marking, indicating that
the process execution can terminate in this marking.
the topmost petri net in figure 4 initially has one token in
the placep1, indicated by the dot. firing of silent transition t1
takes the token from p1and puts a token in both p2andp3,
enabling both t2andt3. whent2ﬁres, it takes the token from
p2and puts a token in p4. whent3ﬁres, it takes the token
fromp3and puts a token in p5. aftert2andt3have both
ﬁred, resulting in a token in both p4andp5,t4is enabled.
executingt4takes the token from both p4andp5, and puts
a token inp6. the findicates that the process execution can
stop in the marking consisting of this place. alternatively, it
can ﬁret5, taking the token from p6and placing a token in p2
andp5, which allows for execution of mc andwto reach the
marking consisting of p6again. we refer the interested reader
to [23] for an extensive review of petri nets.
c. conditional random field
we view the recognition of high-level event labels as
a sequence labeling task in which each event is classiﬁedp1 t1p2
p3mc
t2
dcc
t3p4
p5wt4
fp6t5
process of taking medicine.
fcd dcc
d
process of eating.taking medicine
eatingf
high-level process.
fig. 4: a high-level process consisting of two unstructured
subprocesses that overlap in event types.
as one of the higher-level events from a high-level event
alphabet. conditional random fields (crfs) [19] are a type
of probabilistic graphical model which has become popular
in the ﬁelds of language processing and computer vision for
the task of sequence labeling. a conditional random field
models the conditional probability distribution of the label
sequence given an observation sequence using a log-linear
model. we use linear-chain conditional random fields, a
subclass of conditional random fields that has been widely
used for sequence labeling tasks, which takes the following
form:
p(yjx) =1
z(x)exp(p
t=1p
kkfk(t;yt 1;yt;x))
wherez(x)is the normalization factor, x=hx1;:::;x ni
is an observation sequence, y=hy1;:::;y niis the associated
label sequence, fkandkrespectively are feature functions
and their weights. feature functions, which can be binary
or real valued, are deﬁned on the observations and are used
to compute label probabilities. in contrast to hidden markov
models [20], feature functions are not assumed to be mutually
independent.
iv. m otivating example
figure 4 shows on a simple example how a process can be
structured at a high level while this structure is not discoverable
from a low-level log of this process. the bottom right petri
net shows the example process at a high-level. the high-level
process model allows for any ﬁnite length alternating sequence
oftaking medicine andeating activities. the taking medicine
high-level activity is deﬁned as a subprocess, corresponding
ieee 4 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
to the topmost petri net, which consists of low-level events
medicine cabinet (mc) ,dishes & cups cabinet (dcc) , and
water (w) . the eating high-level event is also deﬁned as a
subprocess, shown in the bottom left petri net, which consists
of low-level events dishes & cups cabinet (dcc) andcutlery
drawer (cd) that can occur an arbitrary number of times in
any order and low-level event dishwasher (d) which occurs
exactly once, but at an arbitrary point in the eating process.
when we apply the inductive miner process discovery
algorithm [6] to low-level traces generated by the hierarchical
process of figure 4, we obtain the process model shown in
figure 5. the obtained process model allows for almost all pos-
sible sequences over the alphabet fcd;d;dcc;mc;w g,
as the only constraint introduced by the model is that dcc
and dare required to be executed starting from the initial
marking to end up with the same marking. firing of all
other transitions in the model can be skipped. behaviorally
this model is very close to the so called ”ﬂower” model [1],
the model that allows for all behavior over its alphabet. the
alternating structure between taking medicine andeating that
was present in the high-level process in figure 4 cannot be
observed in the process model in figure 5. this is caused by
high variance in start and end events of the high-level event
subprocesses of taking medicine andeating as well as by the
overlap in event types between these two subprocesses.
when the event log would have consisted of the high-
level eating and taking medicine events, process discovery
techniques have no problems to discover the alternating struc-
ture in the bottom right petri net of figure 4. to discover
the high-level alternating structure from a low-level event log
it is necessary to ﬁrst abstract the events in the event log.
through supervised learning techniques the mapping from
low-level events to high-level events can be learned from
examples, without requiring a hand-made ontology. similar
approaches have been explored in activity recognition in the
ﬁeld of ubiquitous computing, where low-level sensor signals
are mapped to high-level activities from a human behavior
perspective. the input data in this setting are continuous time
series from sensors. change points in these time series are
triggered by low-level activities like opening/closing the fridge
door , and the annotations of the higher level events (e.g.
cooking ) are often obtained through manual activity diaries.
in contrast to unsupervised event abstraction, the annotations
in supervised event abstraction provide guidance on how to
label higher level events and guidance for the target level of
abstraction.
v. e vent abstraction as a sequence labeling
task
in this section we describe an approach to supervised
abstraction of events based on conditional random fields.
additionally, we describe feature functions on xes event logs
in a general way by using xes extensions. figure 6 provides
a conceptual overview of the supervised event abstraction
method. the approach takes two inputs, 1) a set of annotated
traces, which are traces where the high-level event that a low-
level event belongs to (the label attribute of the low-level
event) is known for all low-level events in the trace, and 2)
a set of unannotated traces, which are traces where the low-
level events are not mapped to high-level events. conditional
fig. 6: conceptual overview of supervised event abstraction.
random fields are trained of the annotated traces to create
a probabilistic mapping from low-level events to high-level
events. this mapping, once obtained, can be applied to the
unannotated traces in order to estimate the corresponding
high-level event for each low-level event (its label attribute).
often sequences of low-level events in the traces with high-
level annotations will have the same label attribute. we make
the working assumption that multiple high-level events are
executed in parallel. this enables us to interpret a sequence
of identical label attribute values as a single instance of a
high-level event. to obtain a true high-level log, we collapse
sequences of events with the same value for the label attribute
into two events with this value as concept name, where the
ﬁrst event has a lifecycle ’start’ and the second has the lifecycle
’complete’. table i illustrates this collapsing procedure through
an input and output event log.
the method described in this section is implemented and
available for use as a plugin for the prom 6 [25] process
mining toolkit and is based on the grmm [26] implementation
of conditional random fields.
we now show for each xes extension how it can be trans-
lated into useful feature functions for event abstraction. note
that we do not limit ourselves to xes logs that contain all xes
extensions; when a log contains a subset of the extensions, a
subset of the feature functions will be available for the super-
vised learning step. this approach leads to a feature space of
unknown size, potentially causing problems related to the curse
of dimensionality, therefore we use l1-regularized conditional
random fields. l1 regularization causes the vector of feature
weights to be sparse, meaning that only a small fraction of the
features have a non-zero weight and are actually used by the
prediction model. since the l1-norm is non-differentiable, we
use owl-qn [27] to optimize the model.
a. from a xes log to a feature space
1) concept extension: the low-level labels of the preced-
ing events in a trace can contain useful contextual information
for high-level label classiﬁcation. based on the n-gram of n
last-seen events in a trace, we can calculate the probability
that the current event has a label l. a multinoulli distribution
is estimated for each n-gram of nconsecutive events, based
ieee 5 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
fig. 5: result of the inductive miner on the low-level traces, reduced using murata reduction rules [24].
table i: left: a trace with predicted high-level annotations ( label ) and, right: the resulting high-level log after collapsing
subsequent identical label values.
case time:timestamp concept:name label
1 03/11/2015 08:45:23 medicine cabinet taking medicine
1 03/11/2015 08:46:11 dishes & cups cabinet taking medicine
1 03/11/2015 08:46:45 water taking medicine
1 03/11/2015 08:47:59 dishes & cups cabinet eating
1 03/11/2015 08:47:89 dishwasher eating
1 03/11/2015 17:10:58 dishes & cups cabinet taking medicine
1 03/11/2015 17:10:69 medicine cabinet taking medicine
1 03/11/2015 17:11:18 water taking medicinecase time:timestamp concept:name lifecycle:transition
1 03/11/2015 08:45:23 taking medicine start
1 03/11/2015 08:46:45 taking medicine complete
1 03/11/2015 08:47:59 eating start
1 03/11/2015 08:47:89 eating complete
1 03/11/2015 17:10:58 taking medicine start
1 03/11/2015 17:11:18 taking medicine complete
on the training data. the conditional random field model
requires feature functions with numerical range. a concept
extension based feature function with two parameters, nand
l, is valued with the multinoulli-estimated probability of the
current event having high-level label lgiven the n-gram of the
lastnlow-level event labels.
2) organizational extension: similar to the concept exten-
sion feature functions, multinoulli distributions can be esti-
mated on the training set for n-grams of resource ,role, or
group attributes of the last nevents. likewise, an organiza-
tional extension based feature function with three parameters,
n-gram size n,o2fresource;role;group g, and label l, is
valued with the multinoulli-estimated probability of label l
given the n-gram of the last nevent resources/roles/groups.
3) time extension: in terms of time, there are several
potentially existing patterns. a certain high-level event might
for example be concentrated in a certain parts of a day, of a
week, or of a month. this concentration can however not be
modeled with a single gaussian distribution, as it might be the
case that a high-level event has high probability to occur in
the morning or in the evening, but low probability to occur
in the afternoon in-between. therefore we use a gaussian
mixture model (gmm) to model the probability of a high-level
labellgiven the timestamp. bayesian information criterion
(bic) [28] is used to determine the number of components
of the gmm, which gives the model an incentive to not
combine more gaussians in the mixture than needed. a gmm
is estimated on training data, modeling the probabilities of
each label based on the time passed since the start of the day,
week or month. a time extension based feature function with
two parameters, t2fday;week;month;::: gand labell, is
valued with the gmm-estimated probability of label lgiven
thetview on the event timestamp.4) lifecycle extension & time extension: the xes stan-
dard [10] deﬁnes several lifecycle stages of a process. when
an event log possesses both the lifecycle extension and the time
extension, time differences can be calculated between different
stages of the life cycle of a single activity. for a complete
event for example, one could calculate the time difference
with the associated start event of the same activity. finding
the associated start event becomes nontrivial when multiple
instances of the same activity are in parallel, as it is then
unknown which complete event belongs to which start event.
we assume consecutive lifecycle steps of activities running in
parallel to occur in the same order as the preceding lifecycle
step. for example, when we observe two start events of an
activity of type ain a row, followed by two complete events
of type a, we assume the ﬁrst complete to belong to the ﬁrst
start, and the second complete to belong to the second start.
we estimate a gaussian mixture model (gmm) for each
tuple of two lifecycle steps for a certain activity on the time
differences between those two lifecycle steps for this activity.
a feature based on both the lifecycle and the time extension,
with a label parameter land lifecycle c, is valued with the
gmm-estimated probability of label lgiven the time between
the current event and lifecycle c. bayesian information cri-
terion (bic) [28] is again used to determine the number of
components of the gmm.
b. evaluating high-level event predictions for process min-
ing applications
existing approaches in the ﬁeld of activity recognition take
as input time windows where each time window is represented
by a feature vector that describes the sensor activity or status
during that time window. hence, evaluation methods in the
activity recognition ﬁeld are window-based, using evaluation
metrics like the percentage of correctly classiﬁed time slices
ieee 6 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
[12], [18], [11]. there are two reasons to deviate from this
evaluation methodology in a process mining setting. first, our
method operates on events instead of time windows. second,
the accuracy of the resulting high level sequences is much
more important for many process mining techniques (e.g.
process discovery, conformance checking) than the accuracy
of predicting each individual minute of the day.
we use levenshtein similarity that expresses the degree
in which two traces are similar using a metric based on
the levenshtein distance (also known as edit distance) [29],
which is deﬁned as levenshtein similarity (a;b) = 1 
levenshtein distance (a;b)
max (jaj;jbj). the division of the levenshtein dis-
tance bymax (jaj;jbj), which is the worst case number of edit
operations needed to transform any sequence of length jajinto
any sequence of length jbj, causes the result to be a number
between 0(completely different traces) and 1(identical traces).
vi. c ase study 1: s mart home environment
we use the smart home environment log described by
van kasteren et al. [11] to evaluate our supervised event
log abstraction method. the van kasteren log consists of
multidimensional time series data with all dimensions binary,
where each binary dimension represents the state of an in-
home sensor. these sensors include motion sensors, open/close
sensors, and power sensors (discretized to 0/1states).
a. experimental setup
we transform the multidimensional time series data from
sensors into events by regarding each sensor change point as
an event. cases are created by grouping events together that
occurred in the same day, with a cut-off point at midnight.
high-level labels are provided for the van kasteren data set.
the generated event log based on the van kasteren data
set has the following xes extensions:
concept the sensor that generated the event.
time the time stamp of the sensor change point.
lifecycle start when the event represents a sensor value
change from 0to1and complete when it
represents a sensor value change from 1to
0.
note that annotations are provided for all traces in the
obtained event log. to evaluate how well the supervised
event abstraction method generalized to unannotated traces, we
artiﬁcially use a part of the traces to train the abstraction model
and apply them on a test set where we regard the annotations
to be non-existent. we evaluate the obtained high-level labels
against the ground truth labels. we use a variation on leave-
one-out-cross-validation where we leave out one trace to
evaluate how well this mapping generalizes to unseen events
and cases.
b. results
figure 7a shows the result of the inductive miner [6] for
the low-level events in the van kasteren data set. the resulting
process model starts with many parallel activities that can
be executed in any order and contains many unobservable
transitions back. this closely resembles the ﬂower model,which allows for any behavior in any arbitrary order. from the
process model we can learn that toilet ﬂush andcups cupboard
frequently co-exists. furthermore, the process model indicates
that groceries cupboard is often followed by dishwasher .
there seems to be very little structure on this level of event
granularity.
the average levenshtein similarity between the predicted
high-level traces in the leave-one-trace-out-cross-validation
experimental setup and the ground truth high-level traces is
0:7042 , which shows that the supervised event abstraction
method produces traces which are fairly similar to the ground
truth.
figure 7b shows the result of the inductive miner on the
aggregated set of predicted test traces. figure 7b shows that
the process discovered at the high level of granularity is more
structured than the process discovered at the original level
of granularity (figure 7a). in figure 7b, we can see that the
main daily routine starts with breakfast, followed by a shower,
after which the subject leaves the house to go to work. after
work the subject prepares dinner and has a drink. the subject
mainstream behavior is to go to the toilet before going to bed,
but he can then wake up later to go to the toilet and then
continue sleeping. note that the day can also start with going
to bed. this is related to the case cut-off point of a trace at
midnight. days when the subject went to bed after midnight
result in a case where going to bed occurs at the start of the
trace. on these days, the subject might have breakfast and then
perform the activity sequence use toilet, take shower, and leave
house, possibly multiple times. another possibility on days
when the subject went to bed after midnight is that he starts
by using the toilet, then has breakfast, then has the possibility
to leave the house, then takes a shower, after which he always
leaves the house. prepare dinner activity is not performed on
these days.
this case study shows that we can ﬁnd a structured high-
level process from a low-level event log where the low-level
process is unstructured, using supervised event abstraction and
process discovery.
vii. c ase study 2: a rtificial digital photocopier
bose et al. [30], [31] created a synthetic event log based on
a digital photocopier to evaluate his unsupervised methods of
event abstraction. in this case study we show that the described
supervised event abstraction method can accurately abstract to
high-level labels.
a. experimental setup
we annotated each low-level event with the correct high-
level event using domain knowledge from the actual process
model as described by bose et al. [30], [31]. this event log
is generated by a hierarchical process, where high-level events
capture image ,rasterize image ,image processing andprint
image are deﬁned in terms of a process model. the print
image subprocess amongst others contains the events writing ,
developing and fusing , which are themselves deﬁned as a
subprocess. in this case study we set the task to transform
the log such that subprocesses capture image ,rasterize im-
ageandimage processing ,writing ,fusing anddeveloping .
ieee 7 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
(a) inductive miner result on the low-level events from the low-level van kasteren event log.
(b) inductive miner result on the high-level events discovered from the low-level van kasteren event log.
fig. 7: comparison of process models discovered from the low-level and high-level van kasteren event log.
subprocesses writing and developing both contain the low-
level event types drum spin start anddrum spin stop . in this
case study we focus in particular on the drum spin start and
drum spin stop events, as they make the abstraction task non-
trivial in the sense that no one-to-one mapping from low-level
to high-level events exists.
the artiﬁcial digital photocopier data set has the concept,
time and lifecycle xes extensions. on this event log anno-
tations are available for all traces. on this data set we use a
10-fold cross-validation setting on the traces to evaluate how
well the supervised event abstraction method abstracts low-level events to high-level events on unannotated traces, as this
data set is larger than the van kasteren data set and leave-
one-out-cross validation would take too much time.
b. results
the confusion matrix in table ii shows the aggregated
results of the mapping of low-level events drum spin start and
drum spin stop to high-level events developing andwriting .
the results show that the supervised event abstraction method
is capable of detecting the many-to-many mappings between
the low-level and high-level labels, as it maps these low-level
ieee 8 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
(a) inductive miner result on the low-level artiﬁcial digital photo copier event log.
(b) inductive miner result on the discovered high-level events on the artiﬁcial digital photo copier event log.
fig. 8: comparison of process models discovered from the low-level and high-level artiﬁcial digital photo copier event log.
table ii: confusion matrix for classiﬁcation of drum spin
start and drum spin stop low-level events into high-level
events writing anddeveloping .
developing writing
developing 6653 0
writing 0 917
events to the correct high-level event without making errors.
the levenshtein similarity between the aggregated set of test
fold high-level traces and the ground truth high-level traces is
close to perfect: 0.9667.
figure 8a shows the process model obtained with the
inductive miner on the low-level events in the artiﬁcial digital
photocopier dataset. the two sections in the process model
that are surrounded by dashed lines are examples of high-level
events within the low-level process model. even though the
low-level process contains structure, the size of the process
model makes it hard to comprehend. figure 8b shows the
process model obtained with the same process discovery
algorithm on the aggregated high-level test traces of the 10-
fold cross validation setting. this model is in line with the
ofﬁcial artiﬁcial digital photocopier model speciﬁcation, with
theprint image subprocess unfolded, as provided in [30],
[31]. in contrast to the event abstraction method described by
bose et al. [31] which found the high-level events that match
speciﬁcation, supervised event abstraction is also able to ﬁnd
suitable event labels for the generated high-level events. this
allows us to discover human-readable process models on the
abstracted events without performing manual labeling, whichcan be a tedious task and requires domain knowledge.
instead of event abstraction on the level of the event log,
unsupervised abstraction methods that work on the level of a
model (e.g. [32]) can also be applied to make large complex
models more comprehensible. note that such methods also do
not give guidance on how to label resulting transitions in the
process model. furthermore, such methods do not help in cases
where the process on a low-level is unstructured, like in the
case study as described in section vi.
this case study shows that supervised event abstraction
can help generating a comprehensible high-level process model
from a low-level event log, when a low-level process model
would be too large to be understandable.
viii. c onclusion
in this paper we described a method to abstract events in
a xes event log that is too low-level, based on supervised
learning. the method consists of an approach to generate a
feature representation of a xes event, and of a conditional
random field based learning step. an implementation of the
method described has been made available as a plugin to the
prom 6 process mining toolkit. we introduced an evaluation
metric for predicted high-level traces that is closer to process
mining than time-window based methods that are often used
in the sequence labeling ﬁeld. using a real life event log
from a smart home domain, we showed that supervised event
abstraction can be used to enable process discovery techniques
to generate high-level process insights even when process
models discovered by process mining techniques on the orig-
inal low-level events are unstructured. finally, we showed on
ieee 9 jp a g esai intelligent systems conference 2016
september 20-22, 2016 jlondon, uk
a synthetic event log that supervised event abstraction can
be used to discover smaller, more comprehensible, high-level
process models when the process model discovered on low
level events is too large to be interpretable.
references
[1] w. m. p. van der aalst, process mining: discovery, conformance and
enhancement of business processes . springer science & business
media, 2011.
[2] w. m. p. van der aalst, a. j. m. m. weijters, and l. maruster,
“workﬂow mining: discovering process models from event logs,” ieee
transactions on knowledge and data engineering , vol. 16, no. 9, pp.
1128–1142, 2004.
[3] c. w. g ¨unther and w. m. p. van der aalst, “fuzzy mining–adaptive
process simpliﬁcation based on multi-perspective metrics,” in business
process management . springer, 2007, pp. 328–343.
[4] j. m. e. m. van der werf, b. f. van dongen, c. a. j. hurkens, and
a. serebrenik, “process discovery using integer linear programming,”
inapplications and theory of petri nets . springer, 2008, pp. 368–387.
[5] a. j. m. m. weijters and j. t. s. ribeiro, “flexible heuristics miner
(fhm),” in proceedings of the 2011 ieee symposium on computational
intelligence and data mining . ieee, 2011, pp. 310–317.
[6] s. j. j. leemans, d. fahland, and w. m. p. van der aalst, “discov-
ering block-structured process models from event logs - a constructive
approach,” in application and theory of petri nets and concurrency ,
ser. lncs. springer, 2013, pp. 311–329.
[7] r. p. j. c. bose and w. m. p. van der aalst, “abstractions in process
mining: a taxonomy of patterns,” in business process management ,
ser. lncs. springer, 2009, pp. 159–175.
[8] c. w. g ¨unther, a. rozinat, and w. m. p. van der aalst, “activity
mining by global trace segmentation,” in business process management
workshops , ser. lnbip. springer, 2010, pp. 128–139.
[9] b. f. van dongen and a. adriansyah, “process mining: fuzzy cluster-
ing and performance visualization,” in business process management
workshops , ser. lnbip. springer, 2010, pp. 158–169.
[10] c. w. g ¨unther and h. m. w. verbeek, “xes-standard deﬁnition,”
bpmcenter.org , 2014.
[11] t. van kasteren, a. noulas, g. englebienne, and b. kr ¨ose, “accurate
activity recognition in a home setting,” in proceedings of the 10th
international conference on ubiquitous computing . acm, 2008, pp.
1–9.
[12] e. m. tapia, s. s. intille, and k. larson, “activity recognition in the
home using simple and ubiquitous sensors,” in pervasive computing ,
ser. lncs, a. ferscha and f. mattern, eds. springer, 2004, pp. 158–
175.
[13] l. bao and s. s. intille, “activity recognition from user-annotated
acceleration data,” in pervasive computing , ser. lncs, a. ferscha and
f. mattern, eds. springer, 2004, pp. 1–17.
[14] j. r. kwapisz, g. m. weiss, and s. a. moore, “activity recognition us-
ing cell phone accelerometers,” acm sigkdd explorations newsletter ,
vol. 12, no. 2, pp. 74–82, 2011.
[15] r. poppe, “a survey on vision-based human action recognition,” image
and vision computing , vol. 28, no. 6, pp. 976–990, 2010.
[16] l. chen and c. nugent, “ontology-based activity recognition in intelli-
gent pervasive environments,” international journal of web information
systems , vol. 5, no. 4, pp. 410–430, 2009.
[17] d. riboni and c. bettini, “owl 2 modeling and reasoning with
complex human activities,” pervasive and mobile computing , vol. 7,
no. 3, pp. 379–395, 2011.
[18] t. van kasteren and b. kr ¨ose, “bayesian activity recognition in
residence for elders,” in proceedings of the 3rd iet international
conference on intelligent environments . ieee, 2007, pp. 209–212.
[19] j. lafferty, a. mccallum, and f. c. n. pereira, “conditional random
ﬁelds: probabilistic models for segmenting and labeling sequence data,”
inproceedings of the 18th international conference on machine
learning . morgan kaufmann, 2001.
[20] l. r. rabiner and b.-h. juang, “an introduction to hidden markov
models,” assp magazine , vol. 3, no. 1, pp. 4–16, 1986.[21] n. friedman, d. geiger, and m. goldszmidt, “bayesian network
classiﬁers,” machine learning , vol. 29, no. 2-3, pp. 131–163, 1997.
[22] e. kim, s. helal, and d. cook, “human activity recognition and pattern
discovery,” pervasive computing , vol. 9, no. 1, pp. 48–53, 2010.
[23] w. reisig, petri nets: an introduction . springer science & business
media, 2012, vol. 4.
[24] t. murata, “petri nets: properties, analysis and applications,” proceed-
ings of the ieee , vol. 77, no. 4, pp. 541–580, 1989.
[25] h. m. w. verbeek, j. c. a. m. buijs, b. f. van dongen, and w. m. p.
van der aalst, “prom 6: the process mining toolkit,” in proceedings
of the business process management demonstration track , ser. ceur-
ws.org, 2010, pp. 34–39.
[26] c. sutton, “grmm: graphical models in mallet,” implementation
available at http://mallet.cs.umass.edu/grmm , 2006.
[27] g. andrew and j. gao, “scalable training of l1-regularized log-
linear models,” in proceedings of the 24th international conference
on machine learning . acm, 2007, pp. 33–40.
[28] g. schwarz, “estimating the dimension of a model,” the annals of
statistics , vol. 6, no. 2, pp. 461–464, 1978.
[29] v . i. levenshtein, “binary codes capable of correcting deletions, in-
sertions, and reversals,” soviet physics doklady , vol. 10, pp. 707–710,
1966.
[30] r. p. j. c. bose, h. m. w. verbeek, and w. m. p. van der aalst,
“discovering hierarchical process models using prom,” in is olympics:
information systems in a diverse world , ser. lnbip. springer, 2012,
pp. 33–48.
[31] r. p. j. c. bose, “process mining in the large: preprocessing, discovery,
and diagnostics,” ph.d. dissertation, technische universiteit eindhoven,
2012.
[32] j. vanhatalo, h. v ¨olzer, and j. koehler, “the reﬁned process structure
tree,” data & knowledge engineering , vol. 68, no. 9, pp. 793–818,
2009.
ieee 10 jp a g e
view publication statsview publication stats