discovering signature patterns from event logs 
r.p. jagadeesh chandra bose 
eindhoven university of technology 
the netherlands 5600 mb 
email: j.c.b.rantham.prabhakara@tue.nlwil m.p. van der aalst 
eindhoven university of technology 
the netherlands 5600 mb 
email: w.m.p.v.d.aalst@tue.nl 
abstract —more and more information about processes is 
recorded in the form of so-called “event logs”. high-tech systems 
such as x-ray machines and high-end copiers provide their 
manufacturers and services organizations with detailed event 
data. larger organizations record relevant business events for 
process improvement, auditing, and fraud detection. traces in 
such event logs can be classiﬁed as desirable or undesirable 
(e.g., faulty or fraudulent behavior). in this paper, we present 
a comprehensive framework for discovering signatures that can
be used to explain or predict the class of seen or unseen traces. 
these signatures are characteristic patterns that can be used 
to discriminate between desirable and undesirable behavior. as 
shown, these patterns can, for example, be used to predict 
remotely whether a particular component in an x-ray machine 
is broken or not. moreover, the signatures also help to improve 
systems and organizational processes. 
our framework for signature discovery is fully implemented 
in prom and supports class labeling, feature extraction and selec- 
tion, pattern discovery, pattern evaluation and cross-validation, 
reporting, and visualization. a real-life case study is used to 
demonstrate the applicability and scalability of the approach. 
key words: process mining, signature patterns, event log, 
discriminatory patterns 
i. i ntroduction 
many of today’s information systems record an abundance 
of event logs. such event logs often contain data indicating 
the health of a process or the status of a case, etc. one can 
consider such health indicators as class labels. for example, 
an x-ray machine event log might contain information on 
system failures and broken parts/components; an insurance 
claim event log might contain information on whether a claim 
is fraudulent or not. organizations are interested in gaini ng 
further insights on such health indicators such as learning 
whether there are any common patterns among the cases with 
a certain class label or whether there are any discriminatory 
patterns between cases of different classes. signature discovery 
is concerned with ﬁnding such patterns. 
signature discovery is a process mining technique [1].
process mining aims to discover, monitor and improve real- 
life processes by extracting knowledge from event logs readily 
available in today’s (information) systems. signature discovery 
examines traces in such event logs and aims to diagnose 
differences and predict the class of unclassiﬁed traces. there 
are many applications for signature discovery. we mention two 
motivating examples: 
•fault diagnosis of high-tech systems: high-tech systems
such as medical devices, copier machines, and wafer scanners, all generate event logs capturing their day- 
to-day operations [2]. these systems may malfunction 
when they are used abnormally (operational processes 
deviating signiﬁcantly from their normal/intended usage). 
malfunctions are also noticed when parts/components in 
the system encounter faults and/or deteriorate. system 
event logs are often the primary source of information for 
diagnosing (and predicting) the causes of failures in these 
systems. early detection and diagnosis of system mal- 
functions can help avoid catastrophic failures and reduce 
productivity loss. for large and complex systems such as 
these, there is a pressing need for better techniques for 
processing, understanding, and analyzing these data [3]. 
•detecting fraudulent claims: insurance companies across 
all sectors (e.g., healthcare, automobile, property, etc.) are 
plagued by fraudulent claims costing billions of dollars 
annually [4]. detecting fraud and abuse relies heavily 
on analysts/auditors inspection of claims in conjunction 
with domain knowledge. automated fraud detection is 
only viable if complex patterns can be uncovered in 
massive amounts of low-level data [5]. there is a need 
for analytical techniques for effective detection of fraud 
[6], [7], [8], [9]. assuming that there exists a historical 
database where we have “cases” comprising the evidence 
collected so far that indicates fraud, one can try to learn 
patterns/characteristics of behavior in such cases that 
discriminate them from normal behavior and use the 
uncovered patterns for monitoring future instances. 
in this paper we present a framework for automated dis- 
covery of signature patterns from event logs where some or 
all cases carry a label indicating the class that they belong 
to. we evaluate the goodness of this framework on a real-life 
case study on ﬁnding patterns that can be correlated to part 
replacements in an x-ray machine. 
the rest of the paper is organized as follows. section ii 
discusses our framework for signature discovery while sec- 
tion iii presents the realization of the framework. a real-life 
case study of discovering signature patterns for diagnosing 
faults in x-ray machines is presented in section iv. related 
work is presented in section v. finally, section vi concludes 
the paper.
ii. s ignature discovery framework 
we propose the framework depicted in fig. 1 for discov- 
ering patterns that discriminate between different classes of 
111 978-1-4673-5895-8/13/$31.00 c/circlecopyrt2013 ieee behavior. starting point is an event log consisting of events. 
each event refers to an activity or action (i.e., a well-deﬁned 
step in some process) and is related to a particular case (i.e., a
process instance ). the events belonging to a case are ordered .
therefore, cases are represented as traces of events that 
correspond to “runs” of a possibly unknown process. events 
may have all kinds of attributes (e.g., timestamp, resources 
used, temperature, costs, etc.). the proposed framework in 
fig. 1 is generic and works for any event log with labeled cases
(signifying different classes of behavior) with a provision for 
some of the cases remaining unlabeled. we now explain the 
constituents of our signature discovery framework. 
event log 
class labeling 
feature extraction 
and selection 
discover patterns 
classiﬁcation & association 
evaluation 
reporting and 
visualization 
fig. 1. framework for signature discovery. the block depicted in dashed 
rectangle is an optional step that is to be considered when some of the cases 
in an event log are unlabeled. 
a. class labeling 
when event logs contain some cases that are unlabeled, an 
important question to address is how can we assign labels to 
those unlabeled instances? efﬁcient means to automatically 
or semi-automatically derive labels need to be designed. we 
propose the use of clustering and/or classiﬁcation techniques, 
such as the k-nearest neighbor [10] and one-class support
vector machines (svm) [11], in machine learning to assist 
in class labeling. for example: 
•if the unlabeled instances are to be assigned one of the 
class labels already present in the event log, then one may 
consider the k-nearest neighbor approach. the basic idea 
is to determine the k-nearest labeled instances for each 
of the unlabeled instances and assign the majority class 
of the kinstances as the class label for the unlabeled 
instance.
•if the labeled instances in the event log belong to only 
one class and we are interested in labeling the unlabeled 
instances to utmost two-classes, e.g., fraudulent and non- 
fraudulent as in the case of insurance claims, an inter- 
esting approach is the use of one-class support vector 
machines. here, we assume that the instances of one-class 
(e.g., non-fraudulent) are labeled. one-class svms work 
with the assumption that all positive (non-fraudulent) in- 
stances are alike while each negative (fraudulent) instanc e can be negative in its own way, i.e., the distribution of 
the negative instances is unknown. once a one-class svm 
is built over the non-fraudulent instances, any unlabeled 
instance can be evaluated to either belonging to the non- 
fraudulent class or not and labeled accordingly. 
after the execution of this step, all instances in the event 
log should have a class label . after this preprocessing step, 
we can discover patterns that are speciﬁc for each class and 
discriminatory between the classes. 
b. feature extraction and selection 
this step corresponds to extracting the features from an 
event log, which form the basis for signature patterns. once 
features are deﬁned, each instance in the event log is to be 
transformed into a vector space where the elements of the 
vector correspond to the value of the selected feature in the 
instance. we argue that a wide variety of feature types need 
to be considered and the choice of the feature type largely 
depends on the nature of the problem and its manifestation in 
the event log. domain knowledge can assist us in selecting 
an appropriate feature. we recommend the consideration of 
individual events ,sequence features (tandem arrays, maximal
repeats and its variants), and alphabet features deﬁned in [12], 
[13] as features. sequence features are important when an 
occurrence of a particular sequence of events in the system log 
deﬁnes a symptomatic pattern, e.g., when a part malfunctions, 
the components that depend on/interact with this faulty part 
retries and seeks for a response from the part. retries often 
manifest as loops , which are captured with tandem arrays [12], 
[13]. as discussed in [13], alphabet features are derived from 
sequence features by relaxing the ordering of events. sequence 
features that are deﬁned over the same set of activities (events) 
are considered to be equivalent under an alphabet feature. in 
addition to the above features, one may also consider features 
catering to other perspectives such as data (e.g., data objects 
and their values in each trace). 
if the number of features extracted is large, then it leads 
to the problem of curse of dimensionality [14]. feature selec- 
tion techniques deal with removing irrelevant and redundant 
features. one can adopt simple ﬁltering techniques such as 
removing infrequent features to advanced dimensionality re- 
duction techniques such as principal component analysis [15] 
for feature selection. once the feature extraction and selection 
is done, we transform the event log into a vector space as 
depicted in table i. 
c. discover patterns 
given a dataset as depicted in table i, the goal of this step 
is to discover the patterns over the features, which are strongly 
correlated to the class label (e.g., normal or faulty). we adopt 
standard data mining techniques, i.e., decision tree learning 
[16], [17] and association rule mining [18], [19]. these two 
learning algorithms are chosen primarily for three reasons: 
•they are non-parametric, i.e,. no speciﬁc data distribution 
(of the input dataset) is assumed 
112 2013 ieee symposium on computational intelligence and data mining (cidm) table i 
the labeled cases in an event log are transformed into a 
vector space based on the chosen features (f1,f 2,...,f m). o ne 
can choose between a nominal (binary )representation (where 
the value for a feature in a case corresponds to the 
presence /absence of the feature in that case )and a numeric 
representation (where the values correspond to the 
frequency of the feature in the case ). 
instance f1f2 . . . fm class
131 . . . 0 n
206 . . . 1 f
310 . . . 4 f
...............
n 22 . . . 0 n
•they generate simple, understandable rules that are easy 
to interpret by domain experts 
•they can easily handle imbalanced datasets, i.e., datasets 
where the instances of each class are not approximately 
equally represented
for the association rule mining, we adopt the special subset 
called the class association rules [19], which is an integration 
of classiﬁcation rule mining and association rule mining. we 
do not present the details of these algorithms in this paper. 
the interested reader is referred to [16], [17], [18], [19], [14]. 
the result of this step are rules such as: 
if f1≥v11 and f3=v31 and f7=v72 then f or 
if f2=v26 and f4=v47 then n or 
if f5=v50 then f
where the vij ’s are the values for the corresponding features. 
d. evaluation 
we adopt standard metrics in data mining such as the 
number of true positives (tp), false positives (fp), true neg- 
atives (tn), and false negatives (fn), and derived metrics 
from these such as accuracy, sensitivity, speciﬁcity, precision, 
and f1-score to evaluate the goodness of the discovered 
signatures. models with sensitivity and speciﬁcity close to 1.0
are preferred [14].
for a given dataset, one can build many classiﬁers. the 
differences mainly stem from the choice of parameter values 
for the learning algorithm (e.g., split criterion in decision 
trees, minimum support and minimum conﬁdence constraints
in association rule mining, etc.). an important characteristic of 
any learned model is its generalizability . generalization refers 
to the performance of a learned model over unseen examples 
[14]. if the entire dataset is used for learning the signatures, 
then the uncovered signatures may be overﬁtting . as a result, 
the learned model may perform well on the input dataset, but 
performs poorly on unseen examples. therefore, we adopt 
cross-validation techniques during the learning phase in the 
above step. 
cross-validation [14], [20] is a model selection technique 
where the input dataset is divided into two subsets, viz., a 
training set and a validation set . the model is learned on the 
training set and evaluated on the validation set. a special case 
of cross-validation is the k-folds cross validation technique where the input dataset is split into ksubsets, and the model
is learned on the training data comprising of k−1subsets and
validated on the last subset. this is repeated ktimes with k
different splits between the training and validation data. the 
cross-validation performance is the average of the results (with 
respect to metrics such as accuracy) on all the splits. we prefer 
signature patterns with a better cross-validation performance. 
if the performance is not satisfactory, one may change the 
parameter settings for the learning algorithm and re-learn the
signatures.
e. reporting and visualization 
the last step in the framework reports the ﬁndings and 
visualizes the results. automated reports eliciting the signature
patterns along with their performance metrics are generated.
apart from reports, one may depict the results in pictorial 
forms such as pie-charts and scatter plots. for example, fig. 2 
depicts the projection of a two-class multi-dimensional data 
onto the top two principal components obtained using principal 
component analysis [15]. such a visualization helps in assess- 
ing the goodness of a feature set. in the ﬁgure, we can see 
that the two classes (normal and faulty) are clearly separable 
thereby indicating that the chosen feature set representation 
for the cases is good enough to ﬁnd discriminatory patterns. 
-1 -0.8 -0.6 -0.4 -0.2  0  0.2  0.4 
-0.8 -0.6 -0.4 -0.2  0  0.2  0.4  0.6 principal component 2 (pc2) 
principal component 1 (pc1) normal faulty 
fig. 2. visualization of dataset using principal components. 
iii. i mplementation 
we have implemented the framework presented in the pre- 
vious section as the ‘signature discovery’ plug-in in prom 1.
given an event log where the cases are labeled (indicating 
different classes of behavior), this plug-in uncovers discrimi- 
natory patterns that distinguish between the different classes
of behavior. this plug-in assumes that the label of a case is 
provided as an attribute value with the key “class” in the event 
log. fig. 3 depicts the conﬁguration step for class labeling 
while figs. 4 and 5 depict the conﬁguration steps for feature 
extraction/selection and learning algorithm respectively. fig. 6 
shows the results provided by the plug-in. 
1prom is an extensible framework that provides a comprehensive set of 
tools/plug-ins for the discovery and analysis of process models from event 
logs. see http://www.processmining.org for more information and to download 
prom. 
2013 ieee symposium on computational intelligence and data mining (cidm) 113 techniques for labelin g: 
k-nearest nei ghb or an d
one-class svm 
parameter conﬁguratio n
for one-class sv m
fig. 3. conﬁguration step for labeling unlabeled instances in an event log. 
the plug-in supports two algorithms, viz., k-nearest neighbor and one-class
svm for class labeling.
feature type selection: 
se quence or al phabet 
feature selection: boa, k grams, 
tandem re peats, and maximal 
repeat var iants 
binary or numeric feature count 
fig. 4. conﬁguration step for feature extraction and selection. different 
types of features are supported, e.g., sequence and alphabet features: tandem 
arrays, maximal repeats and variants, and individual events. 
pattern discovery tec hniques :
dec isiontrees a nd class assoc ia-
tion r ules 
parameter conﬁguratio n
for the pattern discovery 
tec hni que s
eva luation tec hni ques 
fig. 5. conﬁguration step for the learning algorithm for discovering signature 
patterns. two classes of algorithms, viz., decision trees and association rule 
mining are supported.
iv. c ase study 
in this section, we present the case study of fault diagnosis 
of x-ray machines from philips healthcare, a global leader in 
professional and consumer healthcare. although it is undesir- 
able for these systems to malfunction, in reality, these systems 
discove red 
sig nature s
met ric s assessin g th th egoodn ess o f
signatures: true (fa (fa lse )positives, 
true (false )negatives, and derive d
metr ics
expor t
signatures i t 
sho w in w in sta sta nce nce s th th at a s
sat at isf sy th he se se lected satisfy the selected 
sig natures 
fig. 6. results of the ‘signature discovery’ plug-in. the plug-in estimates 
different quality metrics for each of the discovered signatures. 
do malfunction during their lifetime. however, when they do, 
it is important that these problems are quickly and predictably 
corrected. the x-ray machines considered in this study are 
installed across the globe and continuously log all major events 
(e.g., system operations, warnings, errors, etc.). moreover, 
problems (customer complaints) and the actions performed
to rectify them are logged as job sheets. the combination 
of both data sources (logs and job sheets) provide a rich 
source of historical service data. the organization sees an
opportunity of improving their system maintenance through 
log-based fault diagnosis . more speciﬁcally, they are interested 
in investigating whether the diagnostic value of system logs 
can be improved by discovering patterns that can be corre- 
lated to known problems and/or corrective actions with high 
conﬁdence . in this case study, we conﬁne ourselves to the task 
of ﬁnding symptomatic patterns in the event logs that can be 
associated to a malfunction requiring the replacement of parts 
in an x-ray machine . parts that can be replaced in the system 
are called field replaceable units (frus). 
a. data selection 
the data selection process starts with ﬁrst choosing the 
fru we are interested in, e.g., frus for which the variation 
in mean-time-to-repair (mttr) is large. this fru could 
have been replaced in many systems as part of corrective 
maintenance in the past. we can identify all such systems from 
the job sheets database. furthermore, each system can have 
multiple calls associated with this fru replacement, i.e., it 
could be the case that the same part had to be replaced several 
times on a particular system at different periods of time. 
since the system could have undergone version upgrades, it is 
recommended (by domain experts) that the (system, call) pairs 
are segregated based on their versions. each call is associa ted 
with a call open date and a call close date. furthermore, the 
system event logs are recorded every day. for each call, we 
consider logs from the corresponding system a few days before 
the call open date and a few days after the close date for 
analysis. the rationale is that if there exists a symptomatic 
pattern, it should have manifested in the system logs prior 
to and during the life time of the complaint and that they 
disappear in the event logs after the part replacement. the 
114 2013 ieee symposium on computational intelligence and data mining (cidm) number of days that one should consider before (after) the 
call open (close) date is largely dependent on the nature of the 
fru and is to be chosen on a trial and error basis guided by 
domain knowledge. for example, a malfunction in a critical 
part such as an x-ray tube is noticed immediately whereas 
a malfunction in hard disk may not be noticed immediately. 
thus it may be sufﬁcient to consider just a couple of days 
before/after the call open/close date for the x-ray tube while
for the hard disk, a larger time window is recommended. 
b. deﬁning cases–scoping and filtering 
during a single day of machine operation, the system could 
have been (re)started or shutdown multiple times. a session of 
system’s operation constitutes the sequence of events during 
the normal operation mode between startup and shutdown as 
illustrated in fig. 7. sessions form the basis for deﬁning a 
case. the events that are recorded in the x-ray system are 
date time 
call 
open 
date call 
close 
date 3 days 
before 3 days 
after normal oper- 
ation mode other modes 
fig. 7. events during normal operation mode signify the events during the 
regular usage of the system and constitute the focus of analysis. the system 
could have been restarted multiple times during a single day. each sequence of 
events during the normal operation mode surrounded by other system modes 
deﬁnes a session. in this example, we consider the log ﬁles 3days before/after
the call open/close date of a part replacement in a particular system. 
very ﬁne-grained. this makes the total number of events that 
are logged in a single day/session quite large, in the order of a 
few thousands. identifying the symptomatic patterns pertaining 
to the malfunction of a fru in the ﬁne-grained event logs log 
is a challenging task. this can be attributed to the fact that the 
events that potentially bear an indication of the abnormality 
form a small fraction of the overall event data. considering 
the whole log can induce a huge amount of unrelated events 
thereby making the task of signature discovery analogous 
to searching for a needle in a haystack . domain experts 
suggest that a malfunction in a fru reﬂects as error and/or 
warning events in the log pertaining to the component (unit) 
it belongs to and/or components with which it interacts with. 
accordingly, we pre-process the log as follows: 
•for a given fru for which we are interested in identifying 
the symptomatic patterns in the log, we ﬁrst identify 
(based on domain knowledge) the units (components) that 
are related to the fru, e.g., if x-ray tube is chosen as the 
fru, the units related to this are x-ray control, x-ray 
generator, and geometry. 
•only the error/warning events pertaining to the units 
related to the fru during a session are considered as mentioned earlier, the symptomatic patterns are expected to 
have manifested in the system logs prior to and during the life 
time of the complaint, i.e., on/before the call close date, and 
disappear in the event logs after the part replacement (call 
close date). therefore, our problem of signature discovery 
is to uncover patterns consistent across the different calls 
(pertaining to that part replacement), which appear only in 
the event logs prior to the corresponding call close dates and 
disappear in the event logs after the call close date. it is 
important to note that the manifestation of patterns pertaining 
to a problem occurs only when that functionality or behavior 
is invoked on the system. in other cases, we see a normal 
behavior of the system. hence in the time-period prior to 
the call-close date (i.e., the time period between which the 
customer sees some abnormality and the time at which the 
problem is supposed to have been resolved), it is quite possible 
that the system reﬂects a normal behavior during some of 
the sessions. however, it is unknown which sessions exhibit 
normal behavior.
we propose a means of transforming the system logs to 
labeled cases. for this case study, we expect the cases to be 
labeled as normal (n) and faulty (f). we use the juxtaposed
sessions approach to transform system logs into labeled cases. 
the juxtaposed sessions approach creates two cases per call. 
the sessions on/before the call close date are all appended
into a single case with a distinct delimiter (i.e., special char- 
acters/symbols out of the activity alphabet) between them and 
labeled as faulty (f). similarly, the sessions after the call close 
date are appended together with a distinct delimiter between 
them and labeled as normal (n). the distinct delimiter is 
essential to ensure that patterns do not overlap across sessions 
during the discovery process. fig. 8 depicts this approach. 
date time 
call 
open 
date call 
close 
date 3 days 
before 3 days 
after =⇒... f
... n
distinct 
delimiter 
fig. 8. scenario where each call deﬁnes two cases. the sessions on/before 
the call close date are juxtaposed and assigned the label ‘faulty’ (f) whereas 
the case deﬁned by the juxtaposed sessions after the call close date can 
be considered to be ‘normal’ (n). delimiters are used to distinguish the 
boundaries between sessions. 
at the end of this process, we have an event log with cases 
that carry a class label indicating a particular class of behavior. 
we now proceed to uncovering the signature patterns in the 
next section. 
c. signature discovery 
in this section, we discuss the application of the proposed 
framework in uncovering signatures for two of the frus, 
2013 ieee symposium on computational intelligence and data mining (cidm) 115 which we anonymize as fru i and fru ii. first, we discuss 
the results for fru i. for learning the signature patterns, we 
considered this fru’s replacements that happened in the years 
2008 and 2009. as discussed earlier, since different versions of 
the system can have different signatures, we split the systems 
according to their versions and discover the signatures for 
each version separately 2. from the jobsheets, we identiﬁed 
the systems and the dates when this fru was replaced and 
selected system log ﬁles between three days before the call
open date and three days after the call close date for these
systems. we considered the error/warning events from three 
units, which we anonymize (for conﬁdentiality reasons) as 
unit a, unit b, and unit c. these three units are considered 
to be the most relevant for this fru by the domain experts. 
we used the juxtaposed sessions approach for deﬁning the 
cases and class labels. using this procedure, we created cases 
with two labels, i.e., normal or faulty, for each system type 
and version, e.g., there are 32 instances for the system version 
4.3.5.
we discovered the signature patterns from these instances 
using the framework described in section ii. we used a combi- 
nation of tandem repeat alphabet and maximal repeat alphabet 
features [13] in conjunction with the class association rules 
for learning the signature patterns. a couple of anonymized 
signatures for the faulty class are provided in table ii. the 
two signatures differ in the last two events. the interpretation 
for this is that this fru has multiple failure modes and the 
manifestation of failure modes differs in the system event logs. 
each of the signatures in table ii captures one of these 
failure modes. 
table ii 
anonymized signature patterns for fru i. 
if xxxxxxxx1 warning from unit a is present and 
then faulty xxxxxxxx2 error from unit a is present and 
xxxxxxxx4 warning from unit b is present and 
xxxxxxxx4 warning from unit a is present and 
xxxxxxxx5 error from unit a is present 
if xxxxxxxx1 warning from unit a is present and 
then faulty xxxxxxxx2 error from unit a is present and 
xxxxxxxx4 warning from unit b is present and 
xxxxxxxx6 warning from unit a is present and 
xxxxxxxx7 error from unit a is present 
we have evaluated the goodness of the signature patterns on 
an independent test set of system logs between jan 2010 and
jun2011 (note that the signatures were discovered using logs 
from2008 and2009 ). signatures of a particular system type 
and version are evaluated against systems of the same type an d 
version. table iii depicts the performance of the signatures 
for two different versions of systems. the interpretation of 
the true positives, false positives, true negatives, and fa lse 
negatives are as follows: 
•tp:the signature is present in one or more log instances 3
2it could be the case that for two different versions, the signatures are the 
same (this implies that there is no change between these versions with respect 
to this fru) 
3a log instance is one session of the system log in the normal operation 
mode of a system and there is a fru replacement in the 
system subsequently and the signature disappears after 
the replacement,
•fp:the signature is present in one or more log instances 
of a system but there is no fru replacement in the 
system (or) the signature is present in one or more log 
instances of a system and there is a fru replacement 
in the system subsequently but the signature does not 
disappear after the replacement,
•tn: the signature is not present in a log instance of a 
system and there is no fru replacement in this system, 
and
•fn: the signature is not present in a log instance of a 
system but there is a fru replacement in the system. 
false negatives indicate that the discovered signatures are not 
complete and that there might be other symptomatic patterns 
which we are not able to uncover. this results when the 
training data does not represent all manifestations of failure 
modes of the fru. false negatives are not devastating whereas
false positives are. false positives have serious repercussions 
and need to be minimized. false positives can lead to false re- 
placements. false negatives affect the sensitivity and f1-sc ore 
metrics while false positives affect the speciﬁcity, precision, 
and f1-score metrics.
from table iii, we can see that the uncovered signatures 
perform quite well with a very high accuracy (above 98%). 
note that our evaluation involved a large set of independent 
systems ( 743 in number) with logs considered in a different 
time period from that of the training data. the uncovered 
signatures for version 3.1.7are able to detect all but one of 
the required replacements and there are no false positives. the 
discovered signatures for version 4.3.5are able to indicate 
a problem in this fru for 24 of the 32 replacements and 
could not capture the rest 8replacements. the part could have 
exhibited a failure mode different from that of the captured 
signatures in these 8replacements. furthermore, we see just 
two false positives in this case. 
as another example, we considered a different fru, 
anonymized as fru ii. just like in the previous scenario, 
we considered part replacements in 2008 and2009 . event 
logs from systems with this part replacement were used for 
learning the signature patterns. signatures discovered using 
the class association rule mining algorithm on the individual 
events (as the feature set) performed better when compared 
to other features and learning algorithms on the training data. 
we evaluated the uncovered signatures on an independent set 
of system logs between jan 2010 and jun2011 . table iii 
depicts the performance of the discovered signatures for two 
different versions of systems. we can see that, even in this 
case, the uncovered signatures perform good as reﬂected by 
the high accuracy (above 98%). the uncovered signatures for 
version 3.1.7are able to detect all but one of the required 
replacements and there are no false positives. as mentioned 
before, false negatives potentially indicate different fai lure 
modes, the signatures of which are not captured in our dis- 
covery phase, primarily due to lack of representative instances 
116 2013 ieee symposium on computational intelligence and data mining (cidm) table iii 
performance of the discovered signatures for the two fru replacements on an independent test set of systems . v arious metrics 
such as the true positives (tp), false positives (fp), true negatives (tn), false negatives (fn), and derived metrics such as 
accuracy ,sensitivity ,specificity ,precision ,and f1- score are measured .
part version no. tp fp tn fn accuracy sensitivity (r) speciﬁcity precision (p) f1-score
systems tp +tn 
no.systems %tp 
tp +fn %tn 
tn +fp %tp 
tp +fp %2∗p∗r
p+r%
fru i 3.1.7120 30116 1 99 .16 75 .00 100 .00 100 .00 85 .71 
4.3.5623 24 2589 8 98 .39 75 .00 99 .66 92 .30 82 .75 
fru ii 3.1.7120 70112 1 99 .16 87 .50 100 .00 100 .00 93 .33 
4.3.5623 47 2564 10 98 .07 82 .45 99 .64 95 .92 88 .67 
for this failure mode in the training phase. systems of version 
4.3.5had a larger number of fru ii replacements and the 
discovered signatures are able to detect a problem in the fru 
ii in 82% of the cases (sensitivity metric). the discovered 
signatures resulted in only two false positives, but do not cover 
all failure modes. this is reﬂected by the 10 false negatives. 
as mentioned earlier, false negatives are less problematic t han 
false positives. the signatures for these failure modes also 
can be discovered when event logs representing these failure 
modes are provided in the training dataset. to summarize, the 
proposed framework for signature discovery shows signiﬁcant 
promise in fault diagnosis of x-ray machines. 
the discovered signatures can be added to a knowledge base 
and the logs of systems scanned for the presence of signature 
patterns. this can assist the field service engineers (fses)
during their diagnostic efforts. the fses can be provided with 
log analyzer tools that check for the presence of signatures. 
the manifestations of signature patterns suggest potential 
problematic parts (frus) corresponding to the signature. since 
diagnostics are considered to be the most time consuming 
and the most difﬁcult task, such an automated assistance is 
expected to reduce the mttr signiﬁcantly. 
v. r elated work 
any framework or methodology that attempts at discov- 
ering signature patterns, which discriminate between classes
of behavior, is bound to use machine learning/data mining 
techniques. the differences between the solutions mainly
stem from the nature of application/domain, input data and 
its treatment, and the deﬁnition and scope of patterns. the 
problem of signature discovery can essentially be viewed as 
one aimed at inducing a classiﬁer for an event log with labeled 
traces. folino et al. [21] have proposed a decision tree based 
predictive model deﬁned over a set of attributes. the approach 
that we present in this paper is generic and is based on standard 
classical machine learning techniques: decision trees [16], [17]
and association rule mining [18], [19]. however, our approach 
differs from [21] in four ways: (i) we start from event logs 
rather than tabular data, (ii) in addition to decision trees, our 
approach also considers association rules between attributes
and the class labels, (iii) our approach also addresses the
scenario where only a subset of traces in the event log has 
a label, and (iv) we adopt several context-aware attributes 
over common execution patterns manifested in the traces. an 
approach based on sequence patterns and execution time is presented in [22] for identifying failures in business processes 
where failure patterns are deﬁned to be those sequence patterns 
that manifest in failure instances and not in normal instances. 
there are several differences of this approach with the one 
proposed in this paper. unlike our approach, [22] assumes that 
all cases are labeled and supports failure patterns deﬁned only 
in the form of sequence patterns [23] (on the contrary, our 
approach supports a wide variety of features). furthermore, 
[22] is less robust to noise and does not deﬁne/use any means 
of assessing the signiﬁcance of one failure pattern over others 
(e.g., it does not use metrics like the support or conﬁdence). 
common or discriminatory patterns can also be uncovered 
using trace alignment [24], [25] by aligning the traces and 
identifying differences between traces of different classes. 
however, this requires manual inspection of the alignment to 
uncover the discriminating patterns. inspecting for patterns is 
cumbersome for large datasets. therefore, in this paper, we 
explore the feasibility of automatically extracting signature 
patterns from event logs, which can be associated to a partic- 
ular class .
in the remainder of this section, we focus on related work in 
the context of fault diagnosis in alignment with our case study. 
event correlation based approaches for failure diagnosis have 
been proposed in [26], [27], [28]. there are also commercial 
tools such as hp’s openview self-healing services [29] and 
ibm’s trivoli [30] for network management. these methods 
and tools rely on either an existing rule base (typically derived 
from the failure mode and effect analysis (fmea) [31]) 
or some known dependency models about the system. either 
of these is hard to obtain for complex distributed systems 
and/or ﬂexible systems such as medical systems. automated 
identiﬁcation of probable causes of performance problems in 
large server systems was proposed in [32]. this approach relies 
on the availability of well deﬁned measurements on known 
metrics relevant to performance problems. techniques such 
as these work well when one knows apriori what is to be 
measured; the analysis then focuses mainly on ﬁnding corre- 
lations over the measured values. however, event logs from 
high-tech systems such as x-ray machines capture all events 
that are triggered on/by/within the system and are typically
designed for multiple applications (e.g., understanding system
usage, debugging software bugs, etc.). these event logs tend 
to be ﬁne-granular making the analysis challenging. such ﬁne- 
grained event logs ﬁrst require elaborate preprocessing such 
as deﬁning abstractions and selecting an appropriate scope for 
2013 ieee symposium on computational intelligence and data mining (cidm) 117 analysis, which can vary depending on the domain and applica- 
tion. techniques based on the assumption that deviations exist 
in component interaction patterns during system/application 
failures have been proposed in [33], [34], [35]. however, these 
techniques cannot be applied to event logs that do not capture 
component interactions explicitly. 
vi. c onclusions 
in this paper, we explored the feasibility of automatically 
identifying signature patterns that can discriminate between
different classes of behavior. we demonstrated that the pro- 
posed framework works well, i.e., it is able to uncover 
signatures with a high accuracy as was illustrated by a real-life 
case study on malfunctioning x-ray machines. the resulting 
signatures remain highly accurate even on unseen instances. 
this indicates that the suggested framework has the potential 
to become a powerful tool for the diagnosis of failures in 
x-ray systems. the proposed framework is generic and can 
be applied in many other domains ranging from embedded 
systems to forensics and auditing. 
acknowledgements 
the authors are grateful to philips healthcare for funding 
the research in process mining. the authors would also like 
to thank fan liu for her support. 
references 
[1] w. m. p. van der aalst, process mining: discovery, conformance and 
enhancement of business processes . springer-verlag, 2011. 
[2] a. rozinat, i. s. m. de jong, c. w. günther, and w. m. p. van der 
aalst, “process mining applied to the test process of wafer scanners 
in asml,” ieee transactions on systems, man and cybernetics, part 
c, vol. 39, no. 4, pp. 474–479, 2009. 
[3] a. oliner and j. stearley, “what supercomputers say: a study of 
five system logs,” in proceedings of the 37th annual ieee/ifip 
international conference on dependable systems and networks (dsn) ,
2007, pp. 575–584. 
[4] r. a. derrig, “insurance fraud,” the journal of risk and insurance ,
vol. 69, no. 3, pp. 271–287, 2002. 
[5] w. j. rudman, j. s. eberhardt, w. peirce, and s. hart-hester, “health- 
care fraud and abuse,” perspectives in health information management ,
vol. 6, 2009. 
[6] r. j. bolton and d. j. hand, “statistical fraud detection: a review,” 
statistical science , vol. 17, no. 3, pp. 235–249, 2002. 
[7] m. jans, n. lybaert, and k. vanhoof, “internal fraud risk reduction: 
results of a data mining case study,” international journal of ac- 
counting information systems , vol. 11, no. 1, pp. 17–41, 2010. 
[8] e. kirkos, c. spathis, and y .manolopoulos, “data mining techniques 
for the detection of fraudulent financial statements,” expert systems
with applications , vol. 32, no. 4, pp. 995–1003, 2007. 
[9] w. s. yang and s. y . hwang, “a process mining framework for 
the detection of healthcare fraud and abuse,” expert systems with 
applications , vol. 31, no. 1, pp. 56–68, 2006. 
[10] t. cover and p. hart, “nearest neighbor pattern classiﬁcation,” ieee 
transactions on information theory , vol. 13, no. 1, pp. 21–27, 1967. 
[11] b. schölkopf, j. c. platt, j. shawe-taylor, a. j. smola, and r. c. 
williamson, “estimating the support of a high-dimensional distribu- 
tion,” neural computation , vol. 13, no. 7, pp. 1443–1471, 2001. 
[12] r. p. j. c. bose and w. m. p. van der aalst, “abstractions in process 
mining: a taxonomy of patterns,” in business process management ,
ser. lncs, u. dayal, j. eder, j. koehler, and h. reijers, eds., vol. 
5701. springer-verlag, 2009, pp. 159–175. 
[13] ——, “trace clustering based on conserved patterns: towards achiev- 
ing better process models,” in bpm 2009 international workshops, ulm, 
germany, september 7, 2009. revised papers , ser. lnbip, s. rinderle- 
ma, s. sadiq, and f. leymann, eds., vol. 43, 2009, pp. 170–181. [14] j. han and m. kamber, data mining: concepts and techniques .
morgan kaufmann, 2006. 
[15] i. t. jolliffe, principal component analysis , 2nd ed., ser. springer series 
in statistics. springer-verlag, berlin, 2002. 
[16] j. r. quinlan, “induction of decision trees,” machine learning , vol. 1, 
no. 1, pp. 81–106, 1986. 
[17] ——, c4.5: programs for machine learning . morgan kaufmann, 1993. 
[18] r. agrawal and r. srikant, “fast algorithms for mining association 
rules,” in proceedings of the 20th international conference on very 
large data bases (vldb) , vol. 1215, 1994, pp. 487–499. 
[19] b. liu, w. hsu, and y . ma, “integrating classiﬁcation and association 
rule mining,” in fourth international conference on knowledge dis- 
covery and data mining (kdd) . the aaai press, 1998, pp. 80–86. 
[20] r. kohavi, “a study of cross-validation and bootstrap for accuracy 
estimation and model selection,” in international joint conference on 
artiﬁcial intelligence (ijcai) , vol. 2. morgan kaufmann, 1995, pp. 
1137–1145. 
[21] f. folino, g. greco, a. guzzo, and l. pontieri, “mining usage scenarios 
in business processes: outlier-aware discovery and run-time predic- 
tion,” data & knowledge engineering , vol. 70, no. 12, pp. 1005 ˝u–1029, 
2011. 
[22] g. c. ruiz and m. sepulveda, “discovering potential failures in 
business processes extending process mining techniques,” in xxx 
international conference of the chilean computer science society ,
2011. 
[23] p. t. g. hornix, “performance analysis of business processes through 
process mining,” master’s thesis, eindhoven university of technology, 
2007. 
[24] r. p. j. c. bose and w. m. p. van der aalst, “trace alignment in 
process mining: opportunities for process diagnostics,” in proceedings 
of the 8th international conference on business process management 
(bpm) , ser. lncs, r. hull, j. mendling, and s. tai, eds., vol. 6336. 
springer-verlag, 2010, pp. 227–242. 
[25] ——, “process diagnostics using trace alignment: opportunities, 
issues, and challenges,” information systems , vol. 37, no. 2, pp. 117– 
141, 2012. 
[26] a. t. bouloutas, s. calo, and a. finkel, “alarm correlation and 
fault identiﬁcation in communication networks,” ieee transactions 
on communications , vol. 42, no. 234, pp. 523–533, 1994. 
[27] l. mariani and f. pastore, “automated identiﬁcation of failure causes,” 
in proceedings of the 20th international symposium on software reli- 
ability engineering (issre) . ieee computer society, 2008, pp. 117– 
126. 
[28] i. rouvellou and g. w. hart, “automatic alarm correlation for fault 
identiﬁcation,” in proceedings of the fourteenth annual international 
conference on computer communications (ieee infocom) . ieee 
computer society, 1995, pp. 553–561. 
[29] hewlett-packard, “hp openview self-healing services,” 2006, www. 
managementsoftware.hp.com/services/selfhealing_whitepaper.pdf.
[30] ibm, “ibm-integrated service management software-trivoli,” www. 
ibm.com/software/trivoli. 
[31] d. h. stamatis, failure mode and effect analysis: fmea from theory 
to execution . asq quality press, 2003. 
[32] c. huang, i. cohen, j. symons, and t. abdelzaher, “achieving scalable 
automated diagnosis of distributed systems performance problems,” 
hewlett-packard development company, tech. rep. hp-2006-160(r.1), 
2007. 
[33] h. chen, g. jiang, c. ungureanu, and k. yoshihira, “online track- 
ing of component interactions for failure detection and localization 
in distributed systems,” ieee transactions on systems, man, and 
cybernetics-part c: applications and reviews , vol. 37, no. 4, pp. 644– 
651, 2007. 
[34] i. lee and r. k. iyer, “diagnosing rediscovered software problems 
using symptoms,” ieee transactions on software engineering , vol. 26, 
no. 2, pp. 113–127, 2000. 
[35] d. yuan, h. mai, w. xiong, l. tan, y . zhou, and s. pasupath y, 
“sherlog: error diagnosis by connecting clues from run-time logs,” 
in proceedings of the 15th international conference on architectural 
support for programming languages and operating systems (asplos) ,
j. c. hoe and v . s. adve, eds. acm, 2010, pp. 143–154. 
118 2013 ieee symposium on computational intelligence and data mining (cidm) 