simplifying mined process models: an approach based
on unfoldings
dirk fahland and wil m.p. van der aalst
eindhoven university of technology, the netherlands
d.fahland@tue.nl, w.m.p.v.d.aalst@tue.nl
abstract. process models discovered using process mining tend to be complex
and have problems balancing between overﬁtting and underﬁtting. overﬁtting
models are not general enough while underﬁtting models allow for too much be-
havior. this paper presents a post-processing approach to simplify discovered
process models while controlling the balance between overﬁtting and underﬁt-
ting. the discovered process model, expressed in terms of a petri net, is unfolded
into a branching process using the event log. subsequently, the resulting branch-
ing process is folded into a simpler process model capturing the desired behavior.
keywords: process mining, model simpliﬁcation, petri nets, branching processes
1 introduction
information systems are becoming more and more intertwined with the operational pro-
cesses they support. while supporting these processes multitudes of events are recorded,
cf. audit trails, database tables, transaction logs, data warehouses. the goal of process
mining is to use such event data to extract process-related information, e.g., to auto-
matically discover a process model by observing events recorded by some information
system. the discovery of process models from event logs is a relevant, but also chal-
lenging, problem [1, 2].
input for process discovery is a collection of traces. each trace describes the life-
cycle of a process instance (often referred to as case). output is a process model that
is able to reproduce these traces. the automated discovery of process models based on
event logs helps to jump-start process improvement e orts and provides an objective
up-to-date process description. moreover, information from the log can be projected on
such models, e.g., showing bottlenecks and deviations.
the main problem of process discovery from event logs is to balance between over-
ﬁtting andunderﬁtting . a model is overﬁtting if it is too speciﬁc, i.e., the example
behavior in the log is included, but new instances of the same process are likely to
be excluded by the model. for instance, a process with 10 concurrent tasks has 10!
=3628800 potential interleavings. however, event logs typically contain less cases.
moreover, even if there are 3628800 cases in the log, it is extremely unlikely that all
possible variations are present. hence, an overﬁtting model (describing exactly these
cases) will not capture the underlying process. a model is underﬁtting when it over-
generalizes the example behavior in the log, i.e., the model allows for behaviors very
dierent from what was seen in the log. process discovery is challenging because (1)p_12 
p_10 p_40 p_38 
p_32 
p_34 p_36 
p_24 p_22 
p_3 p_11 p_37 p_31 p_23 
p_6 
p_19 p_16 
p_2 p_5 
p_13 
p_18 p_35 p_27 
p_15 p_9 
p_39 p_14 
p_8 
p_25 p_26 p_29 
p_1 p_4 
p_30 p_7 
p_17 p_20 p_28 
p_21 
p_33  
 
  
  
 
  
   
   
p_14 p_10 
  
p_26 p_13 p_6 p_17 p_9 
p_25 p_38 
    
 
  
  
   fig. 1. hospital patient treatment process after process mining (left) and after subsequent simpli-
ﬁcation using the approach presented in this paper (right).
p_28 
p_27 p_5 p_18 
p_10 
p_17 p_16 
p_7 p_25 
p_26 p_22 
p_21 
p_4 
p_8 p_19 
p_13 p_23 
p_1 
 p_15 
p_14  
p_12 p_11 p_20 
p_9 p_3 
p_29 p_6 p_24 p_2 
   
  
 
  
  
 
 
 
    
    
 
 
p_3 
p_20 
p_4 p_8 p_22 
p_12 
p_10 p_19 p_25 p_16 
p_18 p_21 
p_28 
fig. 2. municipality complaint process after process mining (left) and after subsequent simpliﬁ-
cation (right).
the log typically only contains a fraction of all possible behaviors, (2) due to concur-
rency, loops, and choices the search space has a complex structure , and (3) there are no
negative examples (i.e., a log shows what has happened but does not show what could
not happen) [1].
a variety of approaches has been proposed to address these challenges. technically,
all these approaches extract ordering constraints on tasks which are then expressed as
control-ﬂow constructs in the resulting process model. usually, infrequent (exceptional)
behavior in the log leads to complex control-ﬂow constructs in the model. di erent ap-
proaches cope with this problem in di erent ways.
(1) heuristic mining [3] and fuzzy mining [4] abstract from infrequent behavior to sim-
plify the model. genetic algorithms [5] use evolution to ﬁnd suitable models. as a
downside, the resulting model describes only an abstraction of the log .
(2) approaches that do not abstract from infrequent behavior tend to over-generalize
to create a model that is able to replay the entire log. the approach presented in [6]
guarantees that all traces in the log can be reproduced by the model. in [7] an approach
based on convex polyhedra is proposed. here the parikh vector of each preﬁx in the
log is seen as a polyhedron. by taking the convex hull of these convex polyhedra one
obtains an over-approximation of the possible behavior.
(3) other approaches generalize by restricting the most general model as much as pos-
sible. techniques based on language-based regions [8, 9] use the property that adding
a place in a petri net restricts its behavior, i.e., a place can be seen as a constraint on
the model’s behavior. the petri net with transitions tand without any places can re-
produce any event log over t. as shown in [9] a system of inequations can be solved
to add places that do not exclude behavior present in the log. none of these approaches
(2) and (3) allows the user to control the balance between overﬁtting and underﬁtting.
moreover, the resulting models tend to be convoluted as illustrated by fig. 1 and 2.
2fig. 3. the hospital process (fig. 1) discovered by [10] (left) can be simpliﬁed (right).
(4) in [10] an approach to balance overﬁtting and underﬁtting is proposed. first, a tran-
sition system is constructed from the log; the user may balance generalization by in-
ﬂuencing how states are generated from the log. then, a petri net is derived from this
transition system. but this approach requires expert knowledge to specify from the log
transition system states that yield a balanced model. if applied correctly, this technique
yields simpler models (compare fig. 3 (left) and fig. 1 (left)), but even these models
are still convoluted and can be simpliﬁed as shown by fig. 3 (right).
the problem that we address in this paper is to structurally simplify a mined pro-
cess model nwhile preserving that n can replay the entire log l from which it was
generated ; a model is simpler if it shows less interconnectedness between its nodes,
see figs. 1-3. in the following, we propose a technique for re-adjusting the generaliza-
tion done by process mining algorithms, and to cut down involved process logic to the
logic that is necessary to explain the observed behavior. starting point for our approach
is an event log land a discovered process model n=m(l) where the mining algo-
rithmmguarantees a ﬁtting model, i.e., all traces in lcan be replayed on n.1next
we generate a compact representation of the behavior of the process model nw.r.t.
the log lfrom which nwas discovered. we then deliberate this representation from
unnecessary dependencies, and apply generalization techniques that do not introduce
new dependencies unless motivated by a speciﬁc generalization aim.
technically, we use petri nets to represent process models; is the branching pro-
cess of the petri net nrepresenting the traces in l. we (1) deﬁne operations to fold
to a more explicit representation n0of the process logic compared to n, (2) reduce
superﬂuous control-ﬂow structures by removing implicit places from n0, and (3) deﬁne
abstraction operations to simplify the structure of n0and generalize the described be-
havior in a controlled way. our technique leads to a modular technique for transforming
nto a model n0that has a simpler structure than n. moreover, if the original model n
exhibits all behavior of l, then also the simpliﬁed model n0exhibits l. fig. 4 illustrates
1if the mining algorithm does not guarantee a perfectly ﬁtting model, we can still use the tech-
nique presented in [11] to create a ﬁtting event log.
/mt101/mt118/mt101/mt110/mt116/mt32/mt108/mt111/mt103/mt109/mt105/mt110/mt105/mt110/mt103
/mt97/mt108/mt103/mt111/mt114/mt105/mt116/mt104/mt109/mt112/mt114/mt111/mt99/mt101/mt115/mt115
/mt109/mt111/mt100/mt101/mt108/mt115/mt105/mt109/mt112/mt108/mt105/mt102/mt105/mt101/mt100
/mt112/mt114/mt111/mt99/mt101/mt115/mt115
/mt109/mt111/mt100/mt101/mt108
fig. 4. overview on the approach to simplify mined process models.
3our approach which is supported by the process mining toolkit prom .2we validated
the feasibility of our technique in a number of experiments to simplify benchmark pro-
cesses as well as process models from industrial case studies. figs. 1 and 2 illustrate the
eectiveness of our technique.
in the remainder of this paper, we ﬁrst introduce preliminaries regarding petri nets,
partially ordered runs, and branching processes. sect. 3 deﬁnes the operations for sim-
plifying a mined process model illustrated by a running example. we report on experi-
mental results in sect. 4. sect. 5 discusses related work and sect. 6 concludes the paper.
2 causal behavior of process models w.r.t. a log
this section recalls some notions from petri net theory. in particular the notion of a
branching process will be vital for our approach.
2.1 petri nets and logs
initially, we assume some log lto be given, consisting of the cases l=fl1;:::; lngover
the actions (l). each case li2(l)is a ﬁnite sequence of actions, i=1;:::; n. in
practice, a log may contain multiple identical cases; however we will not exploit this
kind of information in the following. a mining algorithm mreturns for a log la petri
netn=m(l). in the following, we consider the case where (1) each action t2(l)
deﬁnes one transition tofn, and (2) the behavior of n contains all cases in l. that is,
each l2lis an occurrence sequence of n.
deﬁnition 1 (petri net). a petri net (p;t;f)consists of a set p of places , a set t
oftransitions disjoint from p, and a set of arcs f (pt)[(tp). amarking
m of n assigns each place p 2p a natural number m (p)oftokens . anet system
n=(p;t;f;m0)is a petri net (p;t;f)with an initial marking m 0.
/mt97
/mt120
/mt99
/mt122 /mt117/mt118/mt98
/mt121
/mt119/mt100 /mt101
/mt102
/mt103 /mt104
fig. 5. a net system n.we writey:=fxj(x;y)2fgandy:=fxj(y;x)2
fgfor the pre- and the post-set ofy, respectively.
fig. 5 shows a slightly involved net system nwith
the initial marking [ a;b].nwill serve as our running
example as its structural properties are typical for re-
sults of a mining algorithm.
the semantics of a net system nare typically
given by a set of sequential runs . a transition tof
nisenabled at a marking mofnim(p)1, for
allp2t. iftis enabled at m, then tmay occur
in the step mt  !mtofnthat reaches the successor
marking m twith mt(p)=m(p) 1 if p2tnt,
mt(p)=m(p)+1 ifp2tnt, and mt(p)=m(p) oth-
erwise, for each place pofn. a sequential run of nis a sequence m0t1  !m1t2  !m2:::
of steps miti+1  !mi+1;i=0;1;2;:::ofnbeginning in the initial marking m0ofn. the
2prom, including the new plug-in ’uma’, can be downloaded from www.processmining.org
4sequence t1t2:::is an occurrence sequence ofn. for example, in the net nof fig. 5
transitions xandyare enabled at the initial marking [ a;b]; the occurrence of xresults
in marking [ c;d;b] where z,u, and yare enabled; xzyuwyz is a possible occurrence
sequence of n.
2.2 partially ordered runs and branching processes
in the following, we study the behavior of nin terms of its partially ordered runs. we
will use so-called branching processes to represent sets of partially ordered runs, e.g.,
an event log will be represented as a branching process. we ﬁrst illustrate the idea of a
partially ordered run of nby an example and then deﬁne the branching processes of n.
/mt97 /mt98
/mt120 /mt121
/mt99 /mt100
/mt122
/mt103/mt117
/mt104
/mt119
/mt99/mt102/mt98/mt101
/mt121
/mt98/mt101
/mt122
/mt103/mt101/mt49/mt98/mt49 /mt98/mt50
/mt101/mt50
/mt98/mt51 /mt98/mt52 /mt98/mt53 /mt98/mt54
/mt101/mt51 /mt101/mt52 /mt101/mt53
/mt98/mt55/mt98/mt56
/mt98/mt57 /mt98/mt49/mt48 /mt98/mt49/mt49
/mt101/mt54
/mt98/mt49/mt50
/mt101/mt55
/mt98/mt49/mt51
fig. 6. a partially ordered run 1
ofnof fig. 5.partially ordered runs. a partially ordered run or-
ders occurrences of transitions by a partial order —
in contrast to a sequential run where occurrences are
totally ordered. a partially ordered run is again rep-
resented as a petri net. such a petri net is labeled and,
since it describes just one run of the process, the pre-
set (postset) of a place contains at most one element.
the net1in fig. 6 describes a partially ordered run
of the net nto the left. a partially ordered run of a
net system nhas the following properties:
–the places and transitions of arelabeled with
the places and transitions of n, respectively.
–a place bofwith label pdescribes a token on
p, the places of with an empty pre-set describe
the initial marking of n;bis called condition .
–a transition eofwith label tdescribes an occur-
rence of transition twhich consumes the tokens
efrom the placestand produces the tokens e
on the places t;eis called event .
for example, event e2of1in fig. 6 describes an occurrence of yconsuming token
b2from place band producing token b5oneand a new token b6onb. the events
of1are partially ordered: e5depends on e 2whereas neither e1depends on e2nore2
one1. that is, e1ande2occur concurrently . the partially ordered run 1describes
the occurrence sequence xzyuwyz — and several other sequences that order concurrent
events di erently such as yyxuzwz .
branching processes. the partial order behavior of a net system nis the setof its
partially ordered runs. a branching process represents a set of distributed runs in a
single structure; we will use it to calculate on the behavior of n.
a branching process ofnresembles an execution tree: each path of an execution
tree denotes a run, all runs start in the same initial state, and whenever two runs diverge
they never meet again. in a “path” denotes a distributed run of nand we can read 
as a special union of distributed runs of n: all runs start in the same initial marking,
and whenever two runs diverge (by alternative events), they never meet again (each
5condition of has at most one predecessor). fig. 7 depicts an example of a branching
process representing two distributed runs 1and2.1is shown in fig. 6, 2consists of
the white nodes of fig. 7. both runs share b1-b11ande1-e5, and diverge at the alternative
events e6ande8which compete b9(i.e., a token in h) and also for b8andb5.
a branching process of nis formally a labeled petri net=(b;e;g;); each b2b
(e2e) is called condition (event ),assigns each node x2b[ea label.
/mt97 /mt98
/mt120 /mt121
/mt99 /mt100
/mt122
/mt103/mt117
/mt104
/mt119
/mt99/mt102
/mt118/mt98/mt101
/mt121
/mt98/mt101
/mt100/mt102
/mt117
/mt104
/mt119
/mt99/mt122
/mt103
/mt122
/mt103/mt101/mt49/mt98/mt49 /mt98/mt50
/mt101/mt50
/mt98/mt51 /mt98/mt52 /mt98/mt53 /mt98/mt54
/mt101/mt51 /mt101/mt52 /mt101/mt53
/mt98/mt55/mt98/mt56
/mt98/mt57 /mt98/mt49/mt48 /mt98/mt49/mt49
/mt101/mt54 /mt101/mt56
/mt98/mt49/mt50 /mt98/mt49/mt52 /mt98/mt49/mt53
/mt101/mt57
/mt98/mt49/mt54
/mt101/mt49/mt48
/mt98/mt49/mt55/mt101/mt55
/mt98/mt49/mt51
/mt98/mt49/mt56/mt101/mt49/mt49
fig. 7. a branching process the
petri net nof fig. 5.here, we give the constructive deﬁnition of the
branching processes of n[12]. to begin with, we
need some preliminary notions. two nodes x1;x2of
are in causal relation , written x1x2, ithere is
path from x1tox2along the arcs gof.x1andx2are
inconﬂict , written x1#x2, ithere exists a condition
b2bwith distinct post-events e1;e22b;e1,e2
ande1x1ande2x2.x1andx2areconcurrent ,
written x1jjx2ineither x1x2, nor x2x1, nor
x1#x2. for example in fig. 7 e2ande9are in causal
relation ( e2e9),e7ande9are in conﬂict ( e7#e9),
ande3ande9are concurrent ( e3jje9).
the branching processes of a petri net n=
(p;t;f;m0) are deﬁned inductively:
base. letb0:=s
p2pfb1
p;:::; bk
pjm0(p)=k;(bi
p)=
pgbe a set of conditions representing the initial mark-
ingofn. then:=(b0;;;;;) is a branching pro-
cess of n.
assumption. let=(b;e;g;) be a branching pro-
cess of n. let t2twitht=fp1;:::; pkg. let
fb1;:::; bkg bbe pair-wise concurrent conditions
(i.e., bijjbj, for all 1i<jk) with(bi)=pi,
fori=1;:::; k. the conditions b1;:::; bktogether
represent tokens in the pre-set of t.
step. if there is no post-event eofb1;:::; bkthat rep-
resents an occurrence of t, then a new occurrence of tcan be added to . formally, if
there is no post-event e2tk
i=1biwith(e)=t, then tisenabled atfb1;:::; bkg. then
the petri net 0=(b[c;e[feg;g0;0) is obtained from by adding
–a fresh event e(not in) with label 0(e)=twithe=fb1;:::; bkg, and
–a fresh post-condition for each of the output places of t, i.e., for t=fq1;:::; qmg,
the set of conditions c=fc1;:::; cmgis added to 0such that0(ci)=qi,ci=feg
fori=1;:::; m;
0is a branching process of n. for example, assume the branching process of fig. 7
without e10;b17;e11;b18to be given. the conditions fb7;b14;b16;b10gare pair-wise con-
current and represent tokens inwofnof fig. 6. appending e10(labeled w) and b17
(labeled c) represents an occurrence of w; event e11ofzis added in the same way.
the arcs of a branching process ofnform a partial order, and any two nodes x1
andx2are either in causal relation, in conﬂict, or concurrent [12]. moreover, every petri
6netnhas a unique, possibly inﬁnite, maximal branching process (n) which contains
every other branching process of nas a preﬁx [13].
3 operations to simplify process models
returning to our problem setting, we consider now the behavior of a petri net n=m(l)
that was discovered from a log lby a mining algorithm m. usually, each action in (l)
becomes a transition of n. for the results of this paper, we assume that each case of l
is an occurrence sequence of ni.e., each case of lcan be replayed on n. for instance,
the class of ilp-based mining algorithms returns nets of this kind [9].
as explained in sect. 1, the net ncan be structurally complex because of how m
generalizes the behavioral information in l. in this section, we contribute a technique
to balance the generalization done by mand simplify the structure of n.
the starting point to balance generalization is an overﬁtting netn(l), which is de-
rived from nand replays exactly each case of l(and all cases obtainable by reordering
concurrent tasks of l.) we deﬁne several operations that generalize the behavior of n(l)
andsimplify its structure . the structural complexity ofnis its simple graph complexity
c(n)=jfj
jpj+jtjwhich correlates with the perceived complexity of the net, e.g., the com-
plexities in fig. 1 are 4.01 (left) and 1.46 (right). each operation transforms a net n0
into a net n00guaranteeing that (1) n0exhibits at least each case of n00(generalization),
and (2) c(n00)c(n0) (simpliﬁcation).
3.1 starting point: an overﬁtting model
the maximal branching process (n) ofnintroduced in sect. 2.2 describes all behavior
ofn, not only the cases recorded in l. this additional behavior was introduced by the
mining algorithm mwhich discovered nfrom l. to re-adjust the generalization, we
restrict the behavior (n) toland derive an overﬁtting process model n(l) that exhibits
exactly this behavior.
the restriction of (n) to the cases lis the branching process (l) that we obtain
by restricting the inductive deﬁnition of the branching processes of nto the cases in l.
beginning with =(b0;;;;;0), iterate the following steps for each case l=t1t2:::tn2
l. initially, let m:=b0,i:=1.
1. letfp1;:::; pkg=ti.
2. if there existsfb1;:::; bkgmwith(bj)=pj,j=1;:::; kande2tk
j=1bjwith
(e)=ti, then m:=(mne)[e.
[the occurrence e of t iis already represented at fb1;:::; bkg; compute the successor
marking of m by consuming the tokense from the pre-placestiand producing the
tokens eon t i.]
3. otherwise, choose fb1;:::; bkgmwith(bj)=pj,j=1;:::; k, and append a
new event e;(e)=tito all bj;j=1;:::; k, and append a new condition ctoe(with
(c)=q) for each q2t.m:=(mne)[e.
[add a new occurrence e of t iatfb1;:::; bkgand compute the successor marking.]
4.i:=i+1, and return to step 1 if in.
7this procedure is sound as nreplays each l2l. by construction, (l) is a smallest
preﬁx of(n) that represents each l2l. step 3 is non-deterministic when marking m
puts more than one token on a place. the results in this paper were obtained by treating
mas a queue: the token that is produced ﬁrst is also consumed ﬁrst.
for example, the branching process of fig. 7 is the branching process =(l) of
netnof fig. 5 for the log l=fxzuywz;xzuyvuywz;xzyuwz;xyzuvuywz;xuzywz;
xuzyywz;yyxuvuzwz;:::g.
(l) already deﬁnes a petri net that exhibits (l) not only succinctly represents
l,but also all cases that di er from l by reordering concurrent actions . the min-
ing algorithm that returned ndetermines whether two actions are concurrent. fur-
ther,(l) already deﬁnes a petri net that exhibits exactly the log l. by putting a to-
ken on each minimal condition bof(l) withb=;, we obtain a labeled petri net
n(l)=(b;e;g;;m0) that exhibits (l), i.e., n(l) restricts the behavior of ntol.
3.2 generalizing and simplifying an overﬁtting model
the algorithm of the preceding section yields for a petri net ndiscovered from a log l,
an overﬁtting net n(l) that exhibits exactly the branching process (l), i.e., the cases
l. in the following, we present our main contribution: a number of operations that gen-
eralize n(l) (introduce more behavior) and simplify the structure compared to n. each
operation addresses generalization and simpliﬁcation in a di erent way and is indepen-
dent of the other operations. so, a user may balance between the overﬁtting model n(l)
and the complex model nby choosing from the available generalization and simpliﬁ-
cation operations. we provide three kinds of operations which are executed by default
in the given order.
(1)n(l) describes the cases lin an explicit form, i.e., only observed behavior is cap-
tured. we fold n (l) to a more compact petri net by identifying loops, and by merging
similar behavior after an alternative choice. this partly generalizes behavior of n(l);
the folded net is as most as complex as n.
(2) then we structurally simplify the folded net by removing implicit places. an im-
plicit place does not constrain whether a transition is enabled and hence can be re-
moved [14]. repeatedly removing implicit places can signiﬁcantly simplify the net.
(3) finally, the net may have speciﬁc structures such as chains of actions of the same
kind or places with a large number of incoming and outgoing arcs. we provide tech-
niques to replace such structures by simpler structures. this allows us to generalize the
behavior of n(l) in a controlled way.
3.3 folding an overﬁtting model
our ﬁrst step in creating a simpliﬁed process model is to fold the overﬁtting net n(l)
to a petri net nf(l).nf(l) exhibits more behavior than n(l) (generalization) and has a
simpler structure than the original net n.
technically, we fold the underlying branching process (l)=(b;e;g;) ofn(l)
by an equivalence relation onb[ethat preserves labels of nodes, and the local
8/mt97
/mt117/mt98
/mt97 /mt99/mt118
/mt99
/mt122
/mt98/mt122
/mt98/mt120
/mt97/mt101/mt49/mt98/mt49 /mt98/mt50
/mt98/mt51 /mt98/mt52 /mt98/mt53
/mt98/mt56 /mt98/mt55 /mt98/mt54/mt101/mt50
/mt101/mt51 /mt101/mt52 /mt101/mt53
/mt97
/mt99
/mt122
/mt98/mt120/mt98
/mt117 /mt118
/mt97
/mt97
/mt99/mt122 /mt120/mt98
/mt117 /mt118fig. 8. the branching process 2(left) can be folded to di erent nets n2(middle) and n0
2(right)
using di erent folding equivalences.
environments of events. we write hxi:=fx0jxx0gfor the equivalence class of node
x.hxi=fhxijx2xgis a set of equivalence classes.
deﬁnition 2 (folding equivalence). letbe a branching process of n. an equivalence
relationon the nodes of is afolding equivalence i
1. x 1x2implies(x1)=(x2), for all nodes x 1;x2of, and
2. e 1e2implieshe1i=he2iandhe1i=he2i, for all events e 1;e2of.
trivial folding equivalences are (1) the identity, and (2) the equivalence induced by the
labeling:x1x2i(x1)=(x2). sect. 3.4 will present a folding equivalence tailored
towards process mining. every folding equivalence of a branching process induces a
folded petri net which is in principle the quotient of under.
deﬁnition 3 (folded petri net). letbe a branching process of n, let be a folding
equivalence of . the folded petri net (w.r.t.) is:=(p;t;f;m)where p:=
fhbijb2bg, t:=fheije2eg, f:=f(hxi;hyi)j(x;y)2fg, and m(hbi) :=
jfb02hbijb0=;gj, for all b2b.
for example, on 2of fig. 8 we can deﬁne a folding equivalence b6b1,b4b5,
e4e5, ,b7b8(and each node equivalent to itself). the corresponding folded net 2

isn2of fig. 8. the coarser folding equivalence deﬁned by the labeling , i.e., xy
i(x)=(y), yields the net n0
2of fig. 8 (right). this example indicates that choosing
a ﬁner equivalence than the labeling equivalence yields a more explicit process model.
regardless of its explicitness, each folded net exhibits the original behavior (l).
lemma 1. let n be a petri net. let be a branching process of n with a folding
equivalence. let n 2:=be the folded petri net of w.r.t.. then the maximal
branching process (n2)containsas a preﬁx.
proof (sketch). by def. 2, all nodes of n2carry the same label, and the pre-set (post-
set) of each transition tofn2is isomorphic to the pre-set (post-set) of each event of
deﬁning t. thus,(n2) is built from the same events as . by induction follows that
n2can mimic the construction of : for each event ewith post-set that is added when
constructing , the transition t=heiofn2leads to an isomorphic event e2that is added
when constructing (n2). thus, we can reconstruct (up to isomorphism) in (n2).n2
may allow to add more events to (n2) than represented in . these additional events
are always appended to , sois a preﬁx of (n2).
9/mt97 /mt98
/mt120 /mt121
/mt99 /mt100
/mt122
/mt103/mt117
/mt104
/mt119
/mt99/mt102
/mt118/mt98/mt101
/mt121
/mt98
/mt122
/mt103/mt101/mt49/mt98/mt49 /mt98/mt50
/mt101/mt50
/mt98/mt51 /mt98/mt54
/mt101/mt51 /mt101/mt53
/mt98/mt55/mt98/mt56/mt44
/mt98/mt49/mt52
/mt98/mt49/mt49
/mt101/mt56/mt98/mt52/mt44
/mt98/mt49/mt53/mt98/mt53/mt44
/mt98/mt49/mt48
/mt101/mt52/mt44
/mt101/mt57
/mt98/mt57/mt44
/mt98/mt49/mt54
/mt101/mt54/mt44
/mt101/mt49/mt48
/mt98/mt49/mt50/mt44
/mt98/mt49/mt55
/mt101/mt55/mt44
/mt101/mt49/mt49
/mt98/mt49/mt51/mt44
/mt98/mt49/mt56
/mt97
/mt120
/mt99
/mt122 /mt117
/mt118/mt98
/mt121
/mt119/mt100 /mt101
/mt103/mt104
/mt99/mt101/mt98
/mt121
/mt101/mt98
/mt122
/mt103
/mt97
/mt120
/mt99
/mt122 /mt117 /mt118/mt98
/mt121
/mt119/mt100 /mt101
/mt103/mt104
/mt99
/mt122
/mt103fig. 9. folding the branching process of fig. 7 by future () yields the petri net nf() (left). re-
moving places of the implicit conditions b8andb14yield the petri net ni() (middle). abstracting
the chain of ytransitions yields the net nc() (right).
3.4 the future equivalence
the following procedure future () constructs a folding equivalence (def. 2) that speciﬁ-
cally suits the simpliﬁcation of discovered process models. the principle idea is to make
all conditions that represent a token on a ﬁnal place of the process model n(i.e., with
an empty post-set) equivalent, and then to extend the equivalence as much as possible.
to this end, we assume to be ﬁnite which is the case for (l) introduced in sect. 2.
1. begin with the identity x1x2ix1=x2, for all nodes x1;x2of.
2. whilechanges:
for any two conditions b1;b2ofwith(b1)=(b2) and b1=b2=;, setb1b2.
3. whilechanges:
for any two events e1;e2ofwith(e1)=(e2) and e1=fy1;:::; ykg,e2=
fz1;:::; zkgwith yizi, for i=1;:::; k, set e1e2, and set uv, for any two
pre-conditions u2e1,v2e2with the same label (u)=(v).
4. return future () :=.
foldingalong=future () merges the maximal conditions of , i.e., rebuilds the
ﬁnal places of the process model of n, and then winds up backwards as much as
possible. this way, we also identify loops in the process model as illustrated in fig. 9.
takingof fig. 7 as input, the algorithm sets b13b18in step 2, b11remains
singleton. in the third step, ﬁrst e7e11andb12b17are set because of b13b18;
then e6e10andb7b7,b8b14,b9b16;b5b10. the equivalence b9b16
introduces a loop in the folded model. step 3 continues with e4e9andb4b15, so
thate8(v) has now b4(d) in the post-set. folding by this equivalence yields the net
nf() of fig. 9. it di ers from nof fig. 5 primarily in representing action ztwice in
dierent contexts. this example illustrates the main e ect of future (): to make process
ﬂow w.r.t. termination more explicit.
complexitywise, future () has at mostjejsteps where events are merged; merging
e1with another event requires to check at most jejevents e2; whether e1ande2are
10/mt97
/mt121
/mt98/mt120
/mt99
/mt100/mt117 /mt118/mt119
/mt101/mt122
/mt97
/mt120
/mt99 /mt117
/mt97/mt98
/mt121
/mt97/mt100
/mt99
/mt117
/mt97
/mt122
/mt101/mt118
/mt101
/mt119
/mt101/mt101/mt49/mt98/mt49
/mt98/mt55
/mt98/mt49/mt49/mt101/mt55/mt98/mt52
/mt101/mt52
/mt98/mt56/mt98/mt50
/mt98/mt51
/mt98/mt53/mt101/mt50
/mt101/mt51
/mt98/mt54/mt101/mt54
/mt98/mt49/mt48
/mt101/mt53
/mt98/mt57
/mt97
/mt120
/mt99/mt98
/mt121/mt100
/mt117
/mt97
/mt122/mt118/mt97
/mt119
/mt101/mt101/mt49/mt98/mt49
/mt98/mt52
/mt101/mt52/mt98/mt50
/mt101/mt51/mt101/mt54/mt98/mt51/mt44
/mt98/mt55/mt101/mt50/mt44
/mt101/mt55
/mt98/mt49/mt49/mt44
/mt98/mt53
/mt98/mt57/mt44/mt98/mt54/mt44/mt98/mt49/mt48/mt101/mt53/mt98/mt56fig. 10. the unsafe net n3(left) has among others the non-deterministic branching process 3
(middle); a deterministic future equivalence merges transitions and results in a deterministic net
nd(3)=3
det(future (3))(right).
merged depends on the equivalence classes of their post-sets. hence, future () runs in
o(jej2k) where kis the size of the largest post-set of an event.
the folded model exhibits the behavior and possibly additional behavior. some
of this additional behavior may be problematic: if the original model nreaches an
unsafe marking (i.e., a place has more than two tokens), the folded model nf()=
may reach a corresponding marking which enables two transitions t1,t2with the same
label a2(l). however, when replaying l2lone can select the wrong transition,
potentially resulting in a deadlock. fig. 10 illustrates the situation.
the net n3of fig. 10 and the log l3=fxuzyw;xyvuw;xyuzwgyield the branching
process3=(n3) shown in the middle. the future equivalence future (3) would only
join b9b6b10. when replaying the third case xyuzw in3, we have to choose
whether e7ore2shall occur; the choice determines whether the net can complete the
case with zor ends in a deadlock.
we can solve the problem by determinizing the equivalenceusing the following
procedure det():
whilechanges do, for any two events e1;e2of,e16e2with(e1)=(e2), if there
exist conditions b1b2with b12e1;b22e2, then
(1) set e1e2,
(2) set c1c2, for all c12e1;c22e2with(c1)=(c2),
(3) set c1c2, for all c12e1;c22e2with(c1)=(c2).
the resulting equivalence relation det(future ()) is a folding equivalence that is
coarser than the trivial equivalence deﬁned by the identity on and ﬁner than the equiv-
alence deﬁned by the labeling of . for example, determinizing future (3) of fig. 10 sets
additionally b7b3,e7e2,b11b5. note that we can merge the two ulabeled events
because b2b2,b22e7, and b22e2the resulting folded net nd(3)=3
det(future (3))
of fig. 10 (right) is indeed deterministic and can replay the entire log l3.
the folded net det(future ())exhibits(by lem. 1) and possibly more behavior be-
cause the folding inferred loops from and merged nondeterministic transitions, which
defers unobservable choices. for our running example ( in fig. 7), nf() is already
deterministic (cf. fig. 9), i.e., nd()=nf().
11the preceding operations of unfolding a mined net nto its log-induced branching
process(l) and refolding (l) tond(l) :=(l)det(future ((l)))yields a net that can re-
play all cases in l(by lem. 1). the structure of nd(l) is at most as complex as the
structure of the original net n— when(l) completely folds back to n. we observed
in experiments that this operation reduces the complexity of nby up to 30%.
3.5 removing implicit places
a standard technique for structurally simplifying a petri net nwhile preserving its
behavior is to remove places that do not restrict the enabling of a transition. such places
are called implicit .
deﬁnition 4 (implicit place). let n be a petri net. a pre-place p of a transition t of n
isimplicit iwhenever n reaches a marking m with tokens on each pre-placetnfpg,
then also p has a token.
in other words, whether tis enabled only depends ontnfpg. removing an implicit place
pfrom npreserves the behavior of nup to tokens on p[14]. in the running example
of fig. 5, place fis implicit. this yields our second simpliﬁcation operation: remove
all implicit places from the folded net nd(). finding implicit places is a well-known
problem and several techniques are applicable, e.g., [14].
although being a standard technique, we learned from experiments that removing
implicit places yields signiﬁcant structural reduction on mined process models. in some
cases, the structure simpliﬁed by up to 72%; up to 95% of the places were implicit.
3.6 controlled generalization of process models
the previously presented two operators, unfolding /refolding and removing implicit
places, generalized and simpliﬁed nalong the structure of nas it was deﬁned by the
mining algorithm mthat returned n. next, we present two operators to generalize n
bychanging n ’s structure.
abstracting chains of unrestricted transitions. mined petri nets often contain several
unrestricted transitions which are always enabled such as transition yin fig. 5. the
branching process then contains a chain of occurrences of these transitions that often
cannot be folded to a more implicit structure as illustrated by e2ande5of fig. 9.
yet, we can abstract such a chain t1:::tnof unrestricted transitions with the same
label ato a loop of length 1: (1) replace t1:::tnwith a new transition tlabeled a,
(2) add a new place pin the pre- and post-set of t, and (3) for each place pwhich
had a tiin its pre-set and no other transition tj,tiin its post-set, add an arc ( t;p).
fig. 9 illustrates the abstraction: abstracting the chain of y-labeled transition of ni()
(middle) yields the net nc() (right); we observed signiﬁcant e ects of this abstraction
in industrial case studies.
the new transition tcan mimic the chain t1:::tn:tis always enabled and an oc-
currence of thas the combined e ect of all t1;:::; tn. for this reason, a chain-abstracted
net exhibits at least the behavior of the original net and possibly more. for longer chains
this results in a signiﬁcant reduction in size and complexity.
12splitting ﬂower places. the last operation in this paper deals with a speciﬁc kind of
places that are introduced by some mining algorithms and cannot be abstracted with the
previous techniques.
/mt119/mt97
/mt98/mt99
/mt120
/mt121
/mt100/mt122
/mt101/mt102
/mt119/mt97
/mt98/mt99
/mt120
/mt121
/mt100/mt122
/mt101/mt102/mt102/mt44/mt122
fig. 11. the ﬂower place fin the net on the left
sequentializes occurrences of wandz. splitting
fand removing self-loops yields the structurally
simpler net on the left with more behavior.aﬂower place p is place which has
many transitions that contain pin their
pre- and their post-set. mostly, ponly
sequentializes occurrences of these tran-
sitions as can be seen in fig. 11 to the
left:zmay occur arbitrarily often before
or after w, though only after xand be-
foreyoccurred. while fin fig. 11 cer-
tainly has an important function w.r.t. z,
its eect on wis limited.
based on this observation we may
(1) remove self-loops of transitions that
are still restricted by another pre-place
such as w, and (2) split the ﬂower place
for a transition tthat has no other pre-place, i.e., to create a new place pin the pre-
and post-set of t. the net in fig. 11 to the right shows the result of this abstraction. the
resulting net exhibits more behavior than the original net. some of this behavior may
even be wrong. for example, wmay occur now before xand after y. yet, the transfor-
mation may help to signiﬁcantly reduce the number of synchronizing arcs in the mined
process model.we observed structural simpliﬁcation of up to 55% in experiments.
3.7 a parameterized process model simpliﬁcation algorithm
all operations presented in the preceding sections together yield the following algo-
rithm for simplifying a mined petri net n=m(l).
1. construct the branching process (l) ofnthat represents all cases l2l; construct
the folding equivalence =det(future ((l))); fold nd:=(l).
2. remove implicit places from nd.
3. abstract chains of unrestricted actions from nd.
4. split ﬂower-places of nd.
the technique is modular . by design, the result of each transformation step is a net that
is structurally simpler than the preceding net and can replay the entire log l, i.e., the
resulting model n0recalls each case of l. moreover, starting from (l) which is an
overﬁtting model of l, each step also generalizes (l) towards an underﬁtting model
ofl. the degree to which n0allows more behavior than lis measured by a precision
metric [15, 16]. each of the four steps can be applied selectively. this way it is possible
to balance between precision, generalization, and complexity reduction.
4 experimental results
we implemented our approach as a plugin for the process mining toolkit prom. the
user picks as input a log and a petri net that was mined from this log, the plugin then
13table 1. experimental results.
original simpliﬁed difference runtime
jpj/jtj/jfj/c jpj/jtj/jfj/c jpj/jfj/c in sec
a22n0 21/ 22/ 61/ 1.41 21/ 22/ 55/ 1.27 0%/ -10%/ 1.11 1
a22n5 38/ 22/ 204/ 3.40 22/ 25/ 81/ 1.72 -42%/ -60%/ 1.98 4.1
a22n10 52/ 22/ 429/ 5.79 16/ 22/ 79/ 2.07 -69%/ -82%/ 2.80 89.2
a22n20 74/ 22/ 569/ 5.92 12/ 22/ 53/ 1.55 -84%/ -91%/ 3.82 389.5
a22n50 91/ 22/ 684/ 6.05 12/ 22/ 43/ 1.26 -87%/ -94%/ 4.80 639.7
a32n0 32/ 32/ 76/ 1.18 33/ 32/ 75/ 1.15 3%/ -1%/ 1.03 0.423
a32n5 44 32/ 228/ 3.00 33/ 32/ 96/ 1.47 -25%/ -58%/ 2.04 7.9
a32n10 68/ 32/ 543/ 5.43 20/ 32/ 89/ 1.71 -71%/ -84%/ 3.18 362.0
a32n20 90/ 32/ 613/ 5.02 25/ 32/ 87/ 1.52 -72%/ -86%/ 3.30 361.1
a32n50 110/ 32/ 868/ 6.11 20/ 32/ 84/ 1.61 -82%/ -90%/ 3.80 584.2
hc1 41/ 15/ 225/ 4.01 11/ 15/ 38/ 1.46 -73%/ -83%/ 2.75 0.119
hc2 20/ 14/ 140/ 4.11 12/ 16/ 39/ 1.39 -40%/ -72%/ 2.96 0.008
hc3 23/ 14/ 123/ 3.32 10/ 15/ 38/ 1.52 -57%/ -69%/ 2.18 0.004
hc4 43/ 17/ 224/ 3.73 11/ 17/ 45/ 1.60 -74%/ -80%/ 2.33 0.030
hc5 89/ 26/ 959/ 8.33 10/ 26/ 51/ 1.41 -89%/ -95%/ 5.91 0.298
m1 58/ 55/ 359/ 3.17 67/ 88/ 205/ 1.32 16%/ -43%/ 2.40 0.299
m2 31/ 23/ 256/ 4.74 16/ 23/ 55/ 1.41 -48%/ -79%/ 3.36 0.116
shows a panel, where the user can conﬁgure the simpliﬁcation of the net by disabling
any of the steps as discussed in sect. 3.7. by default, all steps are enabled and fully
automatic requiring no petri net knowledge from the user for model simpliﬁcation. htodo: reviewer
1:the nature of the
sample instances
should be described.
where exactly do they
come from? how have
they been chosen?
are they well-known
in literature? are
there previous results
on these instances
in literature? if they
are benchmarks, who
else has used them
and what were the
results?iusing this plugin, we validated our approach in a series of experiments on bench-
mark logs, and logs obtained in industrial case studies. for each experiment, we gener-
ated from a given log la petri net nwith the ilp miner [9] using its default settings;
the log was notpre-processed beforehand. we then applied the simpliﬁcation algorithm
of sect. 3.7 on nusing the original log l. figs. 1 and 2 illustrate the e ect of our algo-
rithm on industrial processes: the algorithm balances the control-ﬂow logic of a mined
process model by removing up to 89% of the places, and up to 95% of the arcs.
htodo: reviewer 1:
since there have been
other approaches to
this problem, it would
be interesting to show
how this approach per-
forms in comparison.
(re-run with ts-miner) itable 1 gives some more details. the logs named a xnyare benchmark logs having
xdierent activities; the a xn0 are logs of highly structured processes. yis the per-
centage of random noise events introduced into the log a xn0. the remaining logs were
obtained in case studies in the health care domain (hc) and from municipal adminis-
trations (m). we compared the nets in terms of the numbers jpj,jtj, andjfjof places,
transition and arcs, and their simple graph complexity c=jfj
jpj+jtjwhich roughly corre-
lates with the perceived complexity of the net. the e ect of the algorithm is measured as
the percentage of places jpjand arcsjfjremoved from (or added to) the original net, and
the factor by which the graph complexity simpliﬁed, i.e., cdifference =coriginal=csimpliﬁed .
htodo: reviewer 1:
i do not understand
how the authors make
sure the resulting net
is not an underﬁtting
model.i
htodo: reviewer 2:
while the paper de-
scribes a measure for
identifying the simpler
model, the more gen-
eral model is not clear.
i
htodo: reviewer 4:
but would have liked
a comparison between
original and produced
model in terms of
tracesithe numbers show that almost all models could be reduced signiﬁcantly in terms of
places and arcs (up to 87% and 94%). we observed that some models (a22n0, a32n0,
m1) grew slightly in size, i.e., more places and transitions were introduced. we found
unrolled loops of length greater than 2 that occur only once in the branching process
to be responsible for the growth in size. our algorithm cannot fold back these singular
loops; though the algorithm could be extended to handle such patterns (see sect. 3.6).
yet, even in case of larger nets, our technique reduced each petri net’s graph complexity
cby a factor between 1.07 and 5.91 resulting in graph complexities of 1.26 to 2.07. a
modeler is able to inspect models of this complexity and gain an understanding of the
modeled process as illustrated by figs. 1 and 2 which show the models of hc1 and m2.
14we observed that splitting ﬂower places is responsible for about 10% of the removed
arcs in logs with a noise level of 10% or more. chain reduction removed between 12%
and 51% of the transitions in logs with 5% noise and in m1. runtimes correlate with the
size of the branching processes constructed by the algorithm, we observed branching
processes of up to 192,000 nodes and 360,000 arcs in the benchmarks and 4,800 and
9,800 arcs in the case studies. altogether, the case study processes demonstrate the
feasibility of the technique in practice in terms of simpliﬁcation and runtime.
5 related work
in the last decade, process mining emerged as a new research disciple combining tech-
niques from data mining, process modeling, and process analysis. process discovery,
i.e., constructing a process model based on sample behavior, is the most challenging
process mining task [1] and many algorithms have been proposed. examples are the 
algorithm [1], heuristic mining [3], genetic mining [5], fuzzy mining [4], etc. of partic-
ular interest for this paper are the process discovery algorithms that guarantee a model
with ﬁtness 1 [8, 7, 6, 9], e.g. several process mining techniques based on language-
based regions have been proposed [8, 9]. see [2] for a recent survey.
the approach of [10] allows to balance between overﬁtting and underﬁtting of
mined process models, controlled by the user. however, this approach requires expert
knowledge to ﬁnd the right balance. our approach is easier to conﬁgure, and yields
signiﬁcant simpliﬁcation in the fully automatic setting. moreover, our approach even
simpliﬁes models produced by [10] as shown in fig. 3.
conformance checking techniques [16, 15], like the post-processing approach pre-
sented in this paper, use a log and a model as input. in [15] the log is replayed on the
petri net to see where the model and reality diverge. in [16] the behavior of the model
restricted to the log is computed. the border between the log’s and model’s behavior
highlights the points where the model deviates from the log.
the goal of this paper is to simplify and structure discovered process models. this is
related to techniques transforming unstructured processes models in structured models
[17, 18]. however, these techniques do not consider the real observed behavior.
the problem coped with in this paper resembles the problem of restricting a system
(here n) to admissible behaviors (here l) by means of a controller , e.g., [19]. however,
these approaches require nto have a ﬁnite state space, which usually does not hold for
mined process models. additionally, our aim is also to structurally simplify n, not only
to restrict it to l.
6 conclusion
htodo: reviewer
1: the authors claim
to show feasability. i
wonder what exactly
feasability is in this
context. what does
this mean in practice? i
htodo: reviewer 3:
a question arise here:
is it possible to de-
velop a mining ap-
proach (and not only a
post-processing step)
based on the same
idea.ithe approach presented in this paper can be combined with any process discovery tech-
nique that produces a petri net that can reproduce the event log. extensive experimen-
tation using real-life event logs show that our post-processing approach is able to dra-
matically simplify the resulting models. moreover, the approach allows users to balance
between overﬁtting and underﬁtting. unnecessary generalization is avoided and the user
can guide the simpliﬁcation /generalization process.
15acknowledgements. the research leading to these results has received funding from the euro-
pean community’s seventh framework programme fp7 /2007-2013 under grant agreement no
257593 (acsi).
references
1. van der aalst, w.: process mining: discovery, conformance and enhancement of business
processes. springer (2011)
2. van dongen, b., de medeiros, a.a., wen, l.: process mining: overview and outlook of
petri net discovery algorithms. topnoc 2(2009) 225–242
3. weijters, a., van der aalst, w.: rediscovering workﬂow models from event-based data
using little thumb. integrated computer-aided engineering 10(2) (2003) 151–162
4. g ¨unther, c., van der aalst, w.: fuzzy mining: adaptive process simpliﬁcation based on
multi-perspective metrics. in: bpm 2007. v olume 4714 of lncs., springer (2007) 328–
343
5. medeiros, a., weijters, a., van der aalst, w.: genetic process mining: an experimental
evaluation. data mining and knowledge discovery 14(2) (2007) 245–304
6. van dongen, b., van der aalst, w.: multi-phase process mining: building instance graphs.
in: er 2004. v olume 3288 of lncs., springer (2004) 362–376
7. carmona, j., cortadella, j.: process mining meets abstract interpretation. in balcazar, j.,
ed.: ecml /pkdd 210. v olume 6321 of lecture notes in artiﬁcial intelligence., springer
(2010) 184–199
8. bergenthum, r., desel, j., lorenz, r., mauser, s.: process mining based on regions of
languages. in: bpm 2007. v olume 4714 of lncs., springer (2007) 375–383
9. van der werf, j., van dongen, b., hurkens, c., serebrenik, a.: process discovery using
integer linear programming. fundamenta informaticae 94(2010) 387–412
10. van der aalst, w., rubin, v ., verbeek, h., van dongen, b., kindler, e., g ¨unther, c.w.: pro-
cess mining: a two-step approach to balance between underﬁtting and overﬁtting. software
and system modeling 9(1) (2010) 87–111
11. adriansyah, a., van dongen, b., van der aalst, w.: towards robust conformance checking.
in muehlen, m., su, j., eds.: bpm 2010 workshops, proceedings of the sixth workshop on
business process intelligence (bpi2010). v olume 66 of lnbip., springer (2011) 122–133
12. esparza, j., r ¨omer, s., v ogler, w.: an improvement of mcmillan’s unfolding algorithm.
formal methods in system design 20(3) (2002) 285–310
13. engelfriet, j.: branching processes of petri nets. acta informatica 28(6) (1991) 575–591
14. colom, j., silva, m.: improving the linearly based characterization of p /t nets. in: ad-
vances in petri nets 1990. v olume 483 of lncs. springer (1991) 113–145
15. rozinat, a., van der aalst, w.: conformance checking of processes based on monitoring
real behavior. information systems 33(1) (2008) 64–95
16. mu ˜noz-gama, j., carmona, j.: a fresh look at precision in process conformance. in:
bpm’10. v olume 6336 of lncs., springer (2010) 211–226
17. polyvyanyy, a., garc ´ıa-ba ˜nuelos, l., dumas, m.: structuring acyclic process models. in:
bpm’10. v olume 6336 of lncs., springer (2010) 276–293
18. vanhatalo, j., v ¨olzer, h., koehler, j.: the reﬁned process structure tree. data knowledge
engineering 68(9) (2009) 793–818
19. l ¨uder, a., hanisch, h.: synthesis of admissible behavior of petri nets for partial order
speciﬁcations. in: wodes’00, kluwer (2000) 409 – 431
16