questioning bpm?  
 
 respondent name: wil van der aalst  
  
 
     
 
 
  question #4  
to understand the current business process market, it is good 
consider the roots of today's business process management (bpm) sy s-
tems. in the seventies, people like skip ellis, anatol holt, and m i-
chael zisman already worked on so -called office i nformation (oi) 
systems , which were driven by explicit process models . ellis et al. 
developed oi prototype  system s such as officetalk -zero and o f-
ficetalk -d at xerox parc in the late 1970- ties. these systems 
used variants of petri nets to model processes. another example 
from the same period is scoop (system for computerizing of 
office processes), developed by michael zisman. scoop also 
used petri nets to represent business processes. office talk, 
scoop and ot her oi systems were created in a time where wor k-
ers were typically not connected to a  network.  consequently , these 
systems were not widely adopted. nevertheless,  it is good to rea l-
ize that  the vision still driving today's bpm systems was already 
present  in the late 1970- ties. 
a second wave of bpm -like systems emerged in the mid -
nineties . numerous vendors  started to offer generic workflow 
management (wfm) systems . there was the expectation that wfm 
systems would get a role comparable to dat abase management 
(dbm) systems, i.e., data would be subcontracted to dbm sy s-
tems and processes would be subcontracted to wfm  systems.  
dbm systems managed to become an integral part of almost all 
information systems since the 1970 -ties. however, wfm systems  
were not widely adopted and (unlike dbm systems) did not  man-
age to become an integral part of the typical  infor mation system 
of an organization.  the early wfm systems were focusing too 
much on automation, not acknowledging the management aspects and the n eed for flexibil ity. p rocesses can also be captured using  
conventional programming languages. indeed,  most w orkflows are 
hard-coded and hidden in application programs . 
as mentioned, one of the pitfalls of the classical wfm sy s-
tems was the lack of managemen t support . the focus was on autom a-tion rather than the ability to analyze, manage, and control sy s-
tems. at the turn of the century, a third wave of bpm -like systems 
emerged. these systems had a broader scope  than wfm -
technology : from process automation and process analysis to o p-
erations management and the organization of work. the trend to 
provide better management support is still ongoing  in current sy s-
tems. also there have been various attempts to make these sy s-
tems more flexible than wfm systems. declarative bpm/wfm systems and case management approaches signify this trend  to-
wards more flexibility .  
 
office information systems
(1970 -1990 )
wfm systems
(1985 -2005 )
bpm systems
(2000 -2020 )• mostly pioneering prototypes 
• vision : information systems 
driven by process models
• focus on model -based process 
automation
• many commercial systems 
• often rather inflexible 
• limited support for management 
and analytics
• more attention for management 
and flexibility 
• increasing support for process analytics
 
figure 1 .1: three "waves" of process -aware information systems  
 bpm should aim at  improving  operational business processes, 
with or without  bpm systems. for example, by modeling a business 
process and analyzing it using simulation, management may get ideas on how to reduce costs while improving service levels.  it is 
often not necessary to introduce a full -fledged bpm system. more 
important, bpm approaches  should exploit the event data widely 
available in today's organizations. many bpm authors (including 
smith and fingar in their 2003 book) fail( ed) to see the i m-portance of business process intelligence and process mining. di s-
cussio ns on the definition of bpm and the references to the pi 
calculus  now seem silly. most process improvements and innov a-
tions are driven by data. unfortunately, processes are not at the 
forefront in most data science and  big data initiatives. the bpm 
communi ty should take on the challenge to make these initiatives 
more process -centric.  
   
question #12  
bpm requires close collaboration between it specialists, 
management, domain experts, and workers . processes need to be 
modeled, enacted, analyzed, and managed. figure 1.2 shows the 
four main types of activit y in any larger bpm effort : model  (creat-
ing a process model to be used for analysis or enactment), enact  
(using a process model to control and support concrete cases), 
analyze  (analyzing a process using a process model and/or event 
logs), and manage  (setting goals, adjusting the process, reallocating 
resources , controlling, etc.).  each of these activities combines it 
aspects with business/organizational aspects. one cannot expe ct 
all involved actors to be bpm experts. however, one would e x-
pect that self -proclaimed bpm professionals to master all the ba-
sics of process management. for example, it is remarkable that 
basic concepts such as the workflow pat terns and the difference 
between process /activity  instance and type  are not well unde r-
stood by many bpm professionals. solid bpm education is of the 
utmost importance to improve maturity of our discipline.  
 model
enactanalyze
manage
 
figure 1 .2: bpm professionals should be educate d to fully unde r-
stand the it aspects with business/organizational aspects of the 
four main puzzle pieces of bpm.  
in the context of bpm we can identify at least three groups 
of actors : 
1. bpm specialists : the group of people full -time i n-
volved in bpm and part  of some central group (for 
example a center of excellence) not connected to a 
specific process and not involved in the actual oper a-
tional processes. ideally, bpm specialists have an ac a-
demic degree  in computer science or industrial eng i-
neering with a speci al focus on process management 
and business information systems . 
2. bpm facilitators : the group of people involved in 
bpm projects, but not considered to be bpm specia l-
ists (working only part -time on bpm) . people in this 
group need to be able to model processes, define 
kpis, use bi tools, and understand the it -
implications of process chang e. bpm facilitators  are 
added to project teams that aim to improve  existing 
processes or develop new  processes.  certification or 
internal training  programs can be used to ensure su f-
ficient bpm knowledge.  
3. bpm -aware managers and workers : the group of 
people that use the fruits of bpm. these are workers  performing the actual activities in the processes and 
the people managing them. people in this group just 
need to be aware of bpm concepts.  
in terms of required skills, major changes can be anticipated  
due to the increased availability of process -related event data.  de-
velopments related to big data (in the broadest sense), will impact process management.  bpm professionals will need to acquire 
more data -science skills. bpm will become more "evidence based" 
and less subjective.  
in recent years, "data science" has become a common term to 
refer to the emerging discipline revolving around the abundance 
of data in modern organizations . we would like to confront " data 
science " with the umbrella term " process science " which refers to  
the broader discipline that combines knowledge from information technology and knowledge from management scienc e to improv e 
and run operational processes . data 
mining
process
mining
visualization
data 
sciencebehavioral /
social
sciences
domain
knowledgemachine 
learning
large scale 
distributed
computingstatistics industrial
engineeringdatabases
stochastics
privacyalgorithms
visual 
analytics
formal 
methods
bpm /wfm
systems
concurrencyscientific 
management
process 
science
model
checkingoperations 
research
 
figure 1 .3: bpm professionals should combine " process science " 
and " data science " skills  
figure 1.3 shows some of the key ingredients of both data 
science and process science. bpm professionals should master the 
basics of both groups of ingredients. for example, basic 
knowledge of large -scale distributed computing is needed when 
participating in big data projects. knowledge of visualization 
techniques is beneficial when presenting the effects of process improvement projects. figure 1.3 also shows that process mining 
is the bridge between process science and data science. data sc i-
ence approaches  tend to be process agonistic whereas process sc i-
ence approaches tend to be model -driven without considering the 
"evidence" hidden in the data. obviously, both worlds need to be 
connected and integrated and process mining is one of the key technologies to achieve this.  
process mining  aims to discover , monitor and improve real pr o-
cesses by extracting knowledge from event logs readily available in 
today's information systems. starting point for process mining is an event log . event data can be used to conduc t three types of pr o-
cess mining: process discovery  (finding out what is really happing in 
the process and representing this as a process model ready for 
analysis), conformance checking  (understanding where and why pr o-
cesses deviate  and whether these deviat ions are harmful ), and e n-
hancement  (extending models with performance and conformance 
information and generating process improvement ideas) .  
interestingly, process mining (and other data -driven bpm 
technologies) will help to improve collaboration between it sp e-
cialists, management, domain experts, and workers. the moment the real processes are properly visualized, discussion become more 
focused and fact -driven.  
 
   
question # 14 
process modeling can  be a valuable activity. often the activity 
of modeling is more important than the resulting models.  mode l-
ing forces people to elicit assumptions, requirements, and goals. 
moreover, process modeling  is a great tool to stimulate discu s-
sions on process improvements. however, too much energy is 
wasted on nota tional issues . bpm professionals  tend to be almost 
religious about the process notations  they use . bpmn, petri nets, 
workflow nets, epcs, bpel, and uml activity diagrams are just 
a few examples of the many languages used. debates on which notation to use are seldom productive and definitely do not con-tribute to concrete process improvements. in recent years, bpmn has become the de -facto standard for p rocess modeling , but pe o-
ple tend to  use only a tiny subset of the bpmn  language (the l i-
on's share of bpmn modeling elements  are unknown or deemed 
irrelevant) . moreover, many bpm professionals lack good mode l-
ing skills. this is reflected by the many errors in process models. 
models have internal inconsistencies such as deadlocks and liv e-
locks or different types of process instances are mixed in the same diagram  (e.g., activities related to customer orders and order -line 
items are connected thus blurring the instance notion) . 
the return on investment of modeling depends on (1) the 
quality of the team making the models and (2) the bpm maturity 
or ambition level of the organization. flawed models have little added value , and will not be taken seriously . moreover, organiz a-
tions at one of the lower bpm maturity levels tend to use process 
models merely as "wallpa per". if p rocesses are documented wit h-
out a clear purpose and the models tend to be outdated, then modeling is a waste of time . models are most effective wh en they 
are used actively , for example to drive a bpm system  or to project 
event data on . models should also be  used continuously . models can 
be compared to (geographic) maps. there is no need to make maps without actively using them in day -to-day operatio ns. the 
constant confrontation of maps with reality will help to keep them 
up-to-date. if organizations are not taking models seriously, the 
"return on modeling" will be limited.  
 
figure 1 .4: positioning process mining as an alt ernative to pure 
modeling approaches . 
compared to business process modeling, data -driven bpm 
approaches such as process mining are likely to provide a higher return on investment. in a time where organizations are drowning in event data, it seems foolish t o model processes by hand not 
considering the "evidence" in databases, transaction logs, and au-dit trails. the growing importance of big d ata and data science 
signify a trend towards more data -driven approaches. data should 
not just be used within  processes, but also to learn more about  pro-
cesses.  recent breakthroughs in process mining  research make it 
possible to discover, analyze, and improve business processes based on event data.  process mining results can be viewed as x -rays showing what is really  going on inside  processes. such x -rays 
can be used to diagnose problems and suggest proper treatment.  
process mining  is likely to provide higher returns on inves t-
ment than traditional process modeling approaches:  the threshold 
to get started is low an d process mining results are real . unlike 
modeling, process mining  provides insights  and diagnostics based 
on facts. through process mining, process models can be "con-
fronted " with the actual processes  (through event data) . as a r e-
sult, process models do n ot end up in drawers or serve as wallp a-
per. visualizing detailed performance and conformance diagnos-
tics on pr ocess models on a day -to-day basis  is a potential key as-
set for any bpm  initia tive. it is a great tool to make workers aware 
of bpm. unfortunately , traditional bpm professionals ( the " bpm 
dinosaurs ") have difficulties transitioning to more data -centric 
forms of bpm.  
   
question #4  
effective business processes must be able to accommodate 
changes in the environment in which they operate, e.g., new law s, 
changing workloads, changes in business strategy, or emerging 
technologies. the ability to support  such changes is definitely a 
key concern of bpm . unsurprising,  flexibility has been one of the 
hot topics in bpm/wfm research since the mid 1990- ties. recent 
discussions on case management, ibpm, cmmn, etc. tend to for-get about seminal work done in the last two decades.  many ap-
proaches have been proposed, some more mature than others . in 
general there is a huge gap between the claims of wfm/bpm vendors and actual flexibility support  provided by their systems . 
newcomers to the field should have an open eye for novel flex i-
bility approaches, but also understand why previous approaches failed. it is also crucial to realize that solutions  cannot be found in  
new standard ization proposals  like cmmn. moreover, discussions 
on notation (bpmn versus x yz) will not assist in capturing the 
complexity and dynamicity of real processes!   
to put things in a historic perspective and to provide point-
ers for newcomers in the fi eld, let u s consider a few  papers  related 
to flexibility in bpm : 
[1] c.a. ellis, k. keddara, and g. rozenberg. dynamic change 
within workflow systems.  proceedings of the conference on o r-
ganizational computing systems, pages 10 -21, milpitas, cali-
fornia, augus t 1995. acm sigois, acm press, new york.  
[2] m. reichert and p. dadam. adeptflex: supporting dynamic 
changes of workflow without loosing control.  journal of intelligent 
information systems, 10(2):93- 129, 1998.  
[3] w.m.p. van der aalst and p.j.s. berens. beyond workflow ma n-
agement: product -driven case handling.  international acm 
siggroup conference on supporting group work (group 2001), pages 42 -51. acm press, new york, 2001.  [4] w.m.p. van der aalst, m. weske, and d. grünbauer. case 
handling: a new paradigm for busine ss process support.  data and 
knowledge engineering, 53(2):129- 162, 2005.  
[5] m. pesic, m. h. schonenberg, n. sidorova, and w.m.p. van 
der aalst. constraint -based workflow models: change made easy.  
proceedings of the otm conference on cooperative infor-
mation systems (coopis 2007), volume 4803 of lecture 
notes in computer science, pages 77 -94. springer -verlag, 
berlin, 2007. 
[6] w.m.p. van der aalst, m. pesic, and h. schonenberg. declar a-
tive workflows: balancing between flexibility and support. computer science -  research and development, 23(2):99- 113, 2009.  
[7] w.m.p. van der aalst and s. jablonski. dealing with workflow change: identification of issues and solutions. international journal 
of computer systems, science, and engineering, 15(5):267-276, 2000.  
[8] w.m.p. van der aalst. business process management: a comprehe n-
sive survey.  isrn software engineering, pages 1 -37, 2013. 
 in [1] the problem of workflow flexibility was first discussed 
at a level allowing to reason about the foundational limits of change. t he "dynamic change bug" was identified . since 1995 
many wfm systems have been developed to provide flexibility 
and to deal with phenomena like the "dynamic change bug". the adept system [2] developed at the university of ulm is prob a-
bly the system that pro vided and still provides the most powerful 
flexibility features. systems like adept are still driven by proc e-
dural models, i.e., process notations similar to bpmn, petri nets, 
workflow nets, epcs, and uml activity diagrams. alternative 
(non- procedural) approaches  that are interesting to consider i n-
clude: (1) data -driven case handling approaches  [3,4] and (2) declarative 
approaches  [5,6]  
case handling  approaches [3,4] supported by systems such as 
bpm|one (perceptive) and the earlier flower (pallas athena) 
emerged around the turn of the century. the core features of case handling , as defined in [3,4] , can be described as follows : 
• avoid context tunneling  by providing all information 
available (i.e., present the case as a whole rather than 
showing just bits and pieces),  
• decide which activities are enabled on the basis of the information available rather than the activities already executed (i.e., processes are data-driven  rather than 
control -flow centric),  
• separate work distribution from authorization  and allow f or 
additional types of roles, not just the execute role  
(e.g., skip, redo, etc.) , 
• allow workers to view and add/modify data before  or 
after the corresponding activities have been executed 
(e.g., information can be provided the moment it be-comes available).  
these case handling features aim to provide the flexibility 
needed. this way the pitfalls of traditional production- style wfm 
systems can be avoided. the lengthy debates on case management 
conducted between 2000 and 2005 (roughly one decade  (!) after 
the definition of case handling [3,4]) did not clarify the unde r-
standing of case management /handling . numerous parties pr o-
vided alternative definitions for the term  case management. ho w-
ever, the impact on bpm products was limited and the "new" 
funct ionalities provided were often trivial and far from surprising  
(comparable to the "goto" in programming) . 
declarative  approaches  such a declare  [5,6] aim for a better ba l-
ance between support and flexibility. traditional approaches use procedural process models to specify the execution procedure  ex-
plicitly (i.e., step -by-step). declare  is based on constraints , i.e., anything 
is possible as long as it is not explicitly forbidden . constraint -based mod-
els implicitly  specify the execution procedure by listing a collection 
of (hard or soft)  constraints: a ny process execution that does not 
violate the constraints is possible.  languages like declare are typ i-
cally grounded in some temporal logic (e.g., ltl) to formulate behavioral constraints. it is possible to speci fy that an activity 
should always be preceded by another one or that two activities 
should never be executed for the same case. standardization pr o-
posals like omg's case management model and notation 
(cmmn)  claim to be declarative, but it is less clear what this 
means. in fact there  is controversy about the level of difference 
between bpmn and cmmn, and whether the standards should 
be merged or not.  
flexibility 
by 
definitionprocess 
definition
process 
instancedegree of impact
design time runtime
time at which flexibility is addedflexibility 
by 
deviationflexibility by 
underspecificationflexibility by change
 
figure 1 .5: taxonomy of process flexibility identifying four main 
flexibility ty pes: (1) flexibility by definition, (2) flexibility by devi a-
tion, (3) flexibility by underspecification, and (4) flexibility by 
change.  
rather than debating on standards, it seems more worthwhile 
to provide a taxonomy  of process flexibility based on [7,8]  here. 
the taxonomy shown in figure 1.5 identifies four main flexibility 
types: (1) flexibility by definition , (2) flexibility by deviation , (3) flexibility 
by underspecification , and (4) flexibility by change . 
flexibility by definition  is the ability to incorporate alternative execution paths within a process definition at design time such 
that selection of the most appropriate execution path can be made at runtime for each process instance. for example, parallelism d e-
fined at design time leaves the actual  ordering of activities open 
and thus provides more flexibility than sequential routing. all wfm/bpm systems support this type of flexibility. however, de-clarative languages make it easier to defer choices to runtime  (any-
thing is possible unless there is a  constraint preventing it) . 
flexibility by deviation  is the ability for a process instance to de-
viate at runtime from the execution path prescribed by the original process without altering the process definition itself. the devi a-
tion can only encompass cha nges to the execution sequence for a 
specific process instance, and does not require modifications of the process definition. the case handling approach [3,4] suppor t-
ed by systems like bpm|one allows for such forms of flexibility. it is possible to undo, r edo, and skip an activity . moreover, data can 
be entered earlier or later because the state is continuously reco m-
puted based on the available data.  
flexibility by underspecification  is the ability to execute an inco m-
plete process specification, i.e., a mod el that does not contain suf-
ficient information to allow it to be executed to completion. an incomplete process specification contains one or more so- called 
placeholders. these placeholders are nodes which are marked as underspecified (i.e., "holes" in the  specification) and whose co n-
tent is specified during the execution of the process. the unde r-
specified parts are filled in through late binding or late modeling.  
flexibility by change  is the ability to modify a process definition 
at run -time such that one  or all of the currently executing process 
instances are migrated to a new process definition. changes may be introduced both at the process  instance  and the process  type lev-
els. a momentary change  (also known as change at the instance level) 
is a change affecting the execution of one or more selected pr o-
cess instances. an evolutionary change  (also known as change at the 
type level) is a change caused by modification of the process def i-
nition, potentially affecting all new process instances. a typical examp le of the evolutionary change is the redesign of a business 
process to improve the overall performance characteristics by al-
lowing for more concurrency. running process instances that are impacted by an evolutionary or a momentary change need to be 
handled properly. if a running process instance is transferred to 
the new process, then there may not be a corresponding state 
(called the "dynamic change bug" mentioned earlier ). see adept 
[2] and declare [5,6] for approaches supporting a wide range of process c hanges.  
for each of the four types of flexibility identified in figure 
1.5, there exists a range of articles and (prototype) systems. these show that dynamic and complex processes are difficult to support. 
instead of  proposing new standards like cmmn , the bpm co m-
munity should offer systems that actually support flexibility and 
provide empirical evidence for it.  
  short bio  
prof.dr.ir. wil van der aalst is a full professor of information 
systems at the technische universiteit eindhoven (tu/e). at 
tu/e he is  the scientific director of the data science center 
eindhoven (dsc/e). since 2003 he holds a part -time position at 
queensland university of technology (qut). his personal r e-
search interests include workflow management, process mining, 
petri nets, business process management, process modeling, and process analysis. wil van der aalst has published more than 180 journal papers, 18 books (as author or editor), 400 refereed con-ference/workshop publications, and 60 book chapters. many of 
his papers are highly cit ed (he one of the most cited computer sc i-
entists in the  world and has an h- index of 119  according to 
google scholar) and his ideas have influenced researchers, sof t-
ware developers, and standardization committees working on pr o-
cess support. he has been a co- chair of many conferences inclu d-
ing the business process management conference, the intern a-
tional conference on cooperative information systems, the i n-
ternational conference on the application and theory of petri nets, and the ieee international conferenc e on services co m-
puting. he is also editor/member of the editorial board of several 
journals, including computing, distributed and parallel databases, software and systems modeling, the international journal of business process integration and management, the international journal on enterprise modelling and information systems archi-
tectures, computers in industry, business & information systems engineering, ieee transactions on services computing, lecture 
notes in business information processing, and trans actions on 
petri nets and other models of concurrency. in 2012, he r e-
ceived the degree of doctor honoris causa from hasselt university 
in belgium. he served as scientific director of the international laboratory of process -aware information systems of the natio n-
al research university, higher school of economics in moscow. in 2013, he was appointed as distinguished university professor 
of tu/e and was awarded an honorary guest professorship at tsinghua university. in 2015, he was appointed as honorary pr o-
fessor at the national research university, higher school of ec o-
nomics in moscow. he is also a member of the royal netherlands academy of arts and sciences (koninklijke nederlandse akad e-
mie van wetenschappen), royal holland society of sciences and humanities (koninklijke hollandsche maatschappij der wete n-
schappen) and the academy of europe (academia europaea).  