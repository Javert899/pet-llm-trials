stage-based process performance analysis
chiao-yun li1, sebastiaan j. van zelst1;2, and wil m.p. van der aalst1;2
1fraunhofer fit, 53754 sankt augustin, germany
fchiao-yun.li,sebastiaan.van.zelst,wil.van.der.aalst g@fit.fraunhofer.de
2rwth aachen university, templergraben 55, 52062 aachen, germany
fs.j.v.zelst,wvdaalst g@pads.rwth-aachen.de
abstract. process performance mining utilizes the event data gener-
ated and stored during the execution of business processes. for the
successful application of process performance mining, one needs reliable
performance statistics based on an understandable representation of the
process. however, techniques developed for the automated analysis of
event data typically solely focus on one aspect of the aforementioned
requirements, i.e., the techniques either focus on increasing the anal-
ysis interpretability or on computing and visualizing the performance
metrics. as such, obtaining performance statistics at the higher level
of abstraction for analysis remains an open challenge. hence, using the
notion of process stages, i.e., high-level process steps, we propose an
approach that supports human analysts to analyze the performance at
the process-stage-level. an extensive set of experiments shows that our
approach, without much eort from users, supports such analysis with
reliable results.
keywords: process performance analysis Â·event abstraction Â·process
stage Â·performance visualization.
1 introduction
the goal of all the business is to maximize the return on investment, which
can be realized through improving the eciency of their business processes [10].
analyzing process eciency enables companies to locate and diagnose the causes
of the bottlenecks in order to optimize workload scheduling and the distribution
of resources. process mining is a technology that empowers companies to analyze
a process by exploiting an event log, i.e., records of events executed during the
execution of a process [20]. process performance mining is a subeld that focuses
on the process performance, often referred to as the time dimension, to identify
and diagnose the ineciencies during the operation of a business process [4].
the eectiveness of the analysis of the process performance depends on two
aspects, i.e., interpretability of the results as well as the reliability of the per-
formance metrics provided. to achieve this, most process performance mining
techniques project the performance information on a discovered or predened
process model [5,9,21]. however, as the behavior in a process becomes more2 c. li et al.
fig. 1: performance projection at activity level using disco [5].
complex, the results may be no longer reliable and interpretable for human an-
alysts. for example, as shown in fig. 1, each of the bottlenecks highlighted only
occurs once and the graph is dicult to read. as such, diagnosis remains dicult.
problem statement. consider the medical domain, where specic activities
are performed prior ,during , and after the surgery. in some cases, the exact
scheduling of activities within such a part of the process might be arbitrary,
leading to the complex behavior. such complexity results from the original level
of granularity of the process, i.e., activities. as shown in fig. 1, the complexity
leads to the unreliable diagnosis due to the noninterpretable results and the
relatively low frequency of the bottlenecks.
moreover, an eective diagnosis of the ineciencies in a process requires
the context of cases. consider the same example of performing a surgery in
the medical domain. assume that the average duration of conducting a surgery
(during ) is 5 hours and preparation for a surgery ( prior ) is 15 minutes. suppose
that the eciency of conducting a surgery depends on how much the necessary
materials or information are prepaid for the surgery in advance. without the
performance statistics presented in the context of a case, the bottleneck may be
identied as performing the surgery. however, the cause of the bottleneck, i.e.,
how well the surgery is prepared in advance, may not be diagnosed. the paper
aims to enable analysts to locate and diagnose the ineciencies in complex
processes by addressing the following questions:
q1. what is the major part in a complex process that forms the bottleneck
which actually causes the additional costs in the process?
q2. what causes the bottleneck and how does the bottleneck impact the fol-
lowing parts of the process?
q3. how reliable is the performance statistics given?
solution overview. in this paper, we formally dene such parts as the concept
ofstages to elevate the analysis of process performance to the stage level. by
only consider the activities that would determine the performance of a stage,
we provide an overview of the stage performance with the throughput time of a
stage and the time that the stage is in active in a process. the details of a stage,
i.e., the executions within the stage, are not of concern considering such details
may result in losing the focus of the big picture as shown in fig. 1. then, we
visualize the performance metrics for the diagnosis at the stage level.
by doing so, the process can be easier understood and, thus, diagnosed at
a higher level of abstraction. moreover, the reliability of the results can be en-
hanced by including a sucient number of performance measurements (com-
pared with the bottleneck that occurs only once in the process). meanwhile, tostage-based process performance analysis 3
support the diagnosis, the visualizations emphasize on the performance statistics
in the context of cases. to summarize, the proposed approach supports an an-
alyst to identify the bottlenecks at the stage level and diagnose the root causes
before drilling down the process at the original granularity level.
our implementation and the datasets used for evaluation are available for
replicating the experiments. we evaluate our solution by analyzing two event
logs and compare the results with the existing techniques. the contributions are
summarized as follows:
1. we develop an approach to extract the execution of stages dened by a user.
according to our evaluation, the proposed approach reaches the balance
between the usability and the reliability of the results compared with the
existing techniques.
2. provided the denition of stages, we introduce performance metrics that are
straightforward for a user, allowing one to perform an unbiased analysis.
3. we provide a visualization that shows the evolution of the performance at the
stage level and the interaction between stages. meanwhile, the performance
distribution of cases are presented together at a glance for diagnosis.
the remainder of the paper is organized as follows. section 2 introduces re-
lated work in the eld of process mining. the proposed approach is presented
in section 3. in section 4, we perform analysis of stage performance by experi-
menting with various techniques and summarize the paper in section 5.
2 related work
to the best of our knowledge, this is the rst work that focuses on the perfor-
mance analysis at a coarser granularity level by extracting the instances at the
corresponding abstraction level and compute and visualize the duration accord-
ingly. using the existing techniques, such analysis may be performed by applying
ltering or combining dierent techniques. filtering based on per target coarse-
granular instance may result in biased performance results. alternatively, one
may combine dierent techniques, which we classied into event abstraction and
performance analysis techniques, to analyze the performance based on the in-
stances extracted at a coarser granularity level.
event abstraction. based on the output of the techniques, the event abstrac-
tion techniques can be further classied into model-based and non model-based.
in [15], the authors decompose a process model into groups of activities , i.e.,
well-dened process steps, by mimicking the intuition of a human analyst iden-
tifying stages according to the modularity of the graph. mannhardt and tax
identify the coarse-granular instances based on user-dened patterns which are
represented by process models [14]. however, both approaches do not guarantee
the availability of the results as shown in the experiments.
other approaches do not require a process model. a supervised learning
technique predicts the stage of an event using a probabilistic model [18,19].
the prediction model is trained with an event log in which all the events are4 c. li et al.
labeled with the target instances at the coarser granularity level. assuming that
there exist patterns of the occurrence of the activities within a user-dened time
interval, de leoni and d undar cluster activities and annotate the corresponding
clusters to the events [12]. to analyze the performance of the process at the
abstracted level, one has to apply other performance analysis techniques on top
of the results of using the event abstraction techniques. for example, one may
discover a process model at a higher granularity level from an abstracted event
log and project the performance statistics on the model [11,9,21].
performance analysis. similarly, we categorize the techniques into model-
based and non model-based. model-based techniques project the performance
statistics on a predened or discovered process model [5,9,21]. the performance
can be analyzed with the context that is presented with the model. neverthe-
less, due to the modeling formalism, i.e., certain process models do not allow
for expressing all possible control-ow behaviors, the resulting process behav-
ior highly depends on the discovery technique or the modeling method applied.
the performance metrics may, thus, present biased results. also, the aggregated
performance metrics on a model limits the depth of the diagnosis. one needs to
look into the cases in order to identify the root causes.
other performance analysis techniques do not require a process model. the
objectives of such methods vary and, therefore, it is hard to point out a common
technique applied. generally speaking, they aim to present unbiased results by
showing the raw performance measures. for example, the dotted chart is a sim-
ple, yet powerful, technique that allows batched executions to be observed [17].
however, additional calculation is required to quantify the observed behavior and
the context, i.e., relationship between activities, is lost. another work focuses
on the process performance over time with a parallel plot showing the duration
of each process step on a absolute timeline [2,3]. the batched executions, which
are often the causes of the delays in a process, can be easily observed and some
behaviors, e.g., the overtake of the activities, may be discovered. the visual-
ization emphasizes on the performance of and the interaction between process
steps. however, without the context of a case, some diagnosis may be limited.
for example, the inuence of the performance of a process step to another one
which is not directly following the one may not be observed and compared at
the case level. the work is extended by incorporating a process model such that
the performance of a process step can be analyzed with the context and more
advanced process behavior may be presented with the model [1]. however, using
a model suers from the modeling formalism mentioned. in [16], the authors
visualize the metrics such as the number of cases that arrive at each phase of
a process per day. the workload and the eciency in a phase over a specic
time frame can then be observed. however, every event in an event log must be
assigned to a phase and the phases must occur in a specic order, i.e., no phase
could be skipped and no parallel phases is possible.
the existing event abstraction techniques may suer from the biased results
due to the modeling formalism or the assumptions of a process which the tech-
niques are developed based on. the current performance analysis techniques arestage-based process performance analysis 5
either insucient for analyzing the inuence of bottlenecks in the context of
cases, one of the objectives of our research, or restricted to the assumed process
behavior. to conclude, simply combining the existing techniques is insucient
to analyze the process performance at a coarser granularity level.
3 stage-based performance mining
an overview of the approach is presented in fig. 2. it is a two-fold approach,
which extracts stage instances, i.e., the execution of stage classes, and visual-
izes the performance metrics. the approach consists of four core components:
mine for stage instances ,compute stage performance metrics visualize stage
performance evolution and visualize stage performance summary . based on
the stage classes specied by a user, mine for stage instances extracts the stage
instances. the performance metrics is computed and visualized with visualize
stage performance evolution and visualize stage performance summary . this
section formally denes the terms mentioned and explains the components shown
in fig. 2 after briey introducing the basic concept used in our approach.
3.1 preliminaries
given an arbitrary set x, we write p(x)=fx0jx0xgto denote its pow-
erset. a sequence of length noverxis a function :f1;2;:::ng!x. letx
denote the set of all sequences over x. we write =hx1;x2;:::;xni2x, where
(1)=x1;(2)=x2;:::; (n)=xn. given a sequence 2x,jjdenotes the length
of the sequence. the empty sequence is written as hi, i.e.,jhij=0. we overload
the set notation and write x2if and only if91ijj 
(i)=x
.
in a process, an execution of an activity is recorded as an event with the
timestamp of the execution in the context of a process instance, i.e., a case. the
events of a process are collected in an event log , the input for any process mining
technique. in practice, many additional data attributes can be associated with
an event. for example, event data typically captures the resource executing the
activity, the cost of such an activity, etc. in this paper, we represent an event
by a paire=(a;t) executed in the context of a case represented by a trace. the
denitions of an event, trace, and event logs are as follows.
denition 1 (event, trace & event log). letadenote the universe of
process activities and tdenote the universe of time. an event e=(a;t)2at
represents the execution of activity aat timet. we let e=atdenote the
fig. 2: schematic overview of the proposed approach.6 c. li et al.
fig. 3: a trace of a medical process of a patient in a hospital.
universe of events. given e=(a;t)2e, we letact(e)=aandts(e)=t. atrace
is a sequence of events, i.e., 2e, such that81i<jjj(ts((i))ts((j))).
anevent loglis a collection of traces, i.e., le.3
3.2 mine for stage instances
a natural way to analyze the performance of a complex process is to rstly
elevate the process to the stage level. the performance of such a stage might
not be impacted (signicantly) by the arbitrary scheduling of activities inside a
stage. therefore, only the activities that a stage might start and end with are
of interest when analyzing the performance at a higher level of abstraction, i.e.,
at the stage level .
meanwhile, the level of abstraction of a process depends on the organiza-
tion and the analysis objectives. for example, for a process operated by several
companies, a stage can be dened as the part of the process within a specic
company or a department of a company. this depends on the question of in-
terest. to support such an analysis, the proposed approach allows analysts to
specify the stages with the activities that a stage class may start and end with.
the execution of stage classes, i.e., stage instances , are the actual operations in
a case. we formally dene a stage class and a stage instance below.
denition 2 (stage class). a stage class sis a pair of non-empty sets of dis-
joint activities, i.e., s=(as;ac)2(p(a)nf;g)(p(a)nf;g)^as\ac=;, where
as(start activities) represents the activities that the stage class may start with
andac(end activities) represents the activities that the stage class may end
with. we lets=(p(a)nf;g)(p(a)nf;g)denote the set of all stage classes.
denition 3 (stage instance). let2ebe a trace and s=(as;ac)2sa stage
class. we dene a function :es!p(ee)that returns a set of pairs of
events such that (;s)f((i);(j))j1i<jjj^act((i))2as^act((j))2acg.
each pair of events si=(e;e0)2(;s)is a stage instance. for simplicity, we write
(;s)as(s).
how to extract the stage instances depends on the business context of the
analysis. consider an example of a medical process. suppose that we are inter-
ested in the duration of a patient being registered in the hospital until the doctor
consultation and the time for the laboratories to examine the blood sampled from
the patient. we dene two stage classes, s1=(fregisteredg;fconsult doctorg) and
3we assume that an event can only appear once in a trace and that no two cases have
the same trace in an event log. this can be enforced by adding more event attributes.stage-based process performance analysis 7
s2=(fsample collectedg;fexamine done by lab g), wheredenotes any string
tting the pattern. fig. 3 illustrate the trace of a case, where the dots denote
the events in the trace. the events of interest are labeled and colored in blue
and green for two stage classes. the grey dots are the activities, e.g., consulting
nurses, that are not of concern for the analysis. the stage instances are the pairs
of events connected with the dashed lines. the example shows that there are
many possible ways to extract stage instances, depending on the process and
the objectives of analysis.
the realization of extracting stage instances is by applying a generic tech-
nique that we developed in [13]. we extract the maximal number of stage in-
stances in a trace. considering the scenario mentioned, we allow one to exibly
dene how the events of the start and the end activities should be mapped. we
assume that the closer two events are, the more likely they form a stage instance.
such distance between events can be specied based on domain knowledge. with-
out the knowledge of how the events should be paired and the distance specied,
we assume one-to-one mapping of events and use the order of the events in a
trace by assuming that the closer two events are in a trace, the more possible
that they belong to the same stage instance.
3.3 compute stage performance metrics
given the stage instances extracted, the duration of a stage instance i, i.e., cycle
time is naturally derived, which indicates the duration that a stage class is in
active . to dierentiate the duration that a stage class is actually being executed
and the idle time of a stage class, we dene ow time as the rst occurrence of any
start activity of the stage class until the last occurrence of anyend activity of the
stage class. moreover, to quantify the behavior among stage classes executed,
we introduce the metrics for inter-stage performance. the metrics is formally
dened as follows.
denition 4 (cycle time). given an event log land a stage class s, cycle
time (ct) is the duration of a stage instance si2(s)where2l, i.e.,cts(si) =
ts(si(2)) ts(si(1)). for each trace, we aggregate all the cts(si);8si2(s),
intoctstat
s(), wherestat stands for the target statistics, e.g., ctavg
s()refers to
the average duration of cts(si);8si2s(). for the process, we collect all the
cycle time of sinl, i.e.,cts(l)=[cts(si)j8si2(s);2l], and aggregate into
ctstat
s(l).
fig. 4: a trace of a medical process of a patient in a hospital.8 c. li et al.
table 1: implication of behavior between two stage classes s1ands2in a trace
based on the inter-stage performance metrics.
metrics relation implication of stage behavior in a trace 
lf(s1;s2)()>0 s2starts after s1terminates permanently.
(s1;s2)()>0 s2terminates permanently before s1starts.
lf(s1;s2)()<0^(s1;s2)()>0s2may be executed in parallel with s1.
denition 5 (flow time). given an event log lof a process and a stage class
s=(as;ac), ow time (ft) is the duration that a stage class lasts in a case, i.e.,
81i<jjjwhere2l,fts()=ts((max(fjjact((j))2acg))) ts((min
(fijact((i))2asg)))if and only (s)6=;. in other words, ow time only exists
whensis executed, i.e., (s)6=;. for the process, we aggregate all the ow time
ofsinlintoftstat
s(l), wherestat stands for the target statistics.
consider a process of applying for a mortgage. an application, i.e., a case with
its trace, is nally approved after several rejections and re-submissions ( s). the
ow timefts() represents the duration from the rst submission until it is -
nally approved and the duration that the application is under review is ctsum
s().
denition 6 (inter-stage performance metrics). given a trace and a
stage class s=(as;ac)which(s)6=;,81i<jjj, we obtain two timestamps
tmin
s()=ts((min(fijact((i))2asg)))andtmax
s()=ts((max(fjjact((j))
2acg))). lets1ands2be two stage classes which ()(s1)6=;^()(s2)6=;. we
compute the performance between s1ands2with the following metrics:
{(s1;s2)() =tmin
s2() tmin
s1()
{(s1;s2)() =tmax
s2() tmin
s1()
{lf(s1;s2)() =tmin
s2() tmax
s1()
{ll(s1;s2)() =tmax
s2() tmax
s1()
given the similar scenario in a hospital with a trace of a case, we dene
s1=(fregisteredg,fconsult doctorg) ands2=(fexamine start by lab ,examine
done by labg. fig. 4 visualizes the four metrics, (s1;s2)(),(s1;s2)(),
lf(s1;s2)(), and ll(s1;s2)(). since lf(s1;s2)() is greater than zero , we know
that, after the consultation, the rst examination of the blood sample starts
roughly 5 hours later. table 1 summarizes the implication of the behavior be-
tween two stage classes based on the inter-stage performance metrics.
3.4 visualize stage performance metrics
we introduce two visualizations, stage performance evolution and stage perfor-
mance summary . the rst one demonstrates the evolution of performance over
stages executed, allowing for further diagnosis. the latter one summarizes the
statistics of the performance of all the stage classes dened. this section intro-
duces the visualizations and demonstrates how the analysis can be performed
with the visualizations using an event log land four stage classes s=fapply ,
claim ,travel ,declareg.stage-based process performance analysis 9
fig. 5: stage performance evolution.
 fig. 6: stage performance summary.
stage performance evolution. it may occur that some cases execute some
stages while others do not. we consider that the execution of stage classes reects
the business context. it is not reasonable to compare the performance of the cases
without identifying dierent scenarios. thus, we visualize the performance based
on dierent types of cases according to the stage classes executed.
for each combination of stage classes executed, we visualize the stage per-
formance metrics for the cases executing all the stage classes in the combination
using parallel coordinates as shown in fig. 5 [7]. the leftmost coordinate is the or-
ganization handling the cases and the rightmost one is the total case throughput
time classied into very slow ,slow,fast, and very fast . between the two co-
ordinates, the performance metrics of each trace 2fj82l8s2s;(s)6=;gis
plotted with a horizontal folded line in the order of ctsum
apply (),lf(apply;claim )(),
ctsum
claim (),lf(claim;travel )(),ctsum
travel (),lf(travel;declare )(),ctsum
declare () in
the gure. the visualization can be applied interactively as below:
{the order of the coordinates can be exibly arranged and the metrics of
every stage class or between two stage classes can be changed to the ow
time or other metrics, which allows for exploring the behavior of the stage
performance from dierent angles.
{depending on the use cases, the leftmost and rightmost coordinates may
be replaced with any case attributes for analyzing the relationships between
the attributes, e.g., the nancial costs of handling a case, and the stage
performance evolution.
{the scale of the coordinates for the performance metrics can be set the same
(absolute ) for identifying the bottlenecks, or the maximum value for each
metrics ( relative ) such that the cause of the bottlenecks may be diagnosed.
fig. 5 shows the visualizations using relative performance with the analysis.
suppose one assumes that the stages are executed one after another, i.e., no
parallelism of stages. in fig. 5, the bottleneck and the most severe deviation are
identied based on the stage performance distribution of the cases.
stage performance summary. to have an overview of the performance of
all the stage classes dened, we summarize the performance for all the cases in
l. as shown in fig. 6, the summary is presented with the statistics of ftstat
s(l)
andctstat
s(l) for every stage class s2s.10 c. li et al.
4 evaluation
with the aim of supporting analysts to identify the bottlenecks and perform the
diagnosis of a complex process, we conduct a comparative evaluation based on
two criteria: the ease of use of a method and the reliability of the metrics. a
method that requires much preparation, manipulation of an event log, or the
domain knowledge hampers an analyst to perform an eective analysis. the
metrics that contains only a few measurements may cause misleading conclusion
of the bottlnecks. in the evaluation, we conduct experiments by applying various
techniques to perform analysis at a coarser granular level of a process. the
techniques are compared with the following questions:
{how much is the manipulation of an event log required to analyze the process
performance at a coarser granular level?
{how much domain knowledge is required for the abstraction of an event log?
{how reliable is the resulting performance metrics?
to the best of our knowledge, the stage performance evolution proposed is
the only visualization that supports our goal for such analysis. therefore, we
conduct the experiments by using various event abstraction techniques of which
our visualization is applied on top. table 2 lists the implementations of the
techniques evaluated with their abbreviations for convenience. except for the
proposed approach4, other techniques are available in prom [24]. this section
presents the evaluation from the aspects of the ease of use and the reliability by
analyzing two event logs, permitlog [23] and bpic15 1[22].
fig. 7: a schematic overview of analyzing performance at a coarser granular level
using dierent event abstraction techniques.
4the implementation and the datasets used for experiments are in https://github.
com/chiaoyunli/spm .stage-based process performance analysis 11
table 2: overview: techniques used for experiments.
techniques abbreviation
- proposed approach pa
- abstract event labels using linear chaining [18,19] crf
- conditional random field (grmm)
- log abstraction - abstract log based on patterns [16] pnp
- session-based log abstraction [12] sess
- stage mining (sm) [15] sm
4.1 evaluation on ease of use
the ease of use of a tool is evaluated from two aspects, the amount of the
domain knowledge required and the necessity of the manipulation of an event
log. the inputs and outputs of the event abstraction techniques vary. therefore,
for each technique, we manipulate the event logs for performance analysis at the
abstracted level if necessary.
external eort required. fig. 7 presents the overview of the steps to ana-
lyze the performance at the coarser granularity level using the techniques. the
dashed line indicates the data ow and the solid line refers to the control ow.
each box represents a step and the steps that require human intervention are
emphasized with the green outline of the steps. we further group the steps and
annotate the groups with the corresponding techniques. since the existing event
abstraction techniques are not specically designed for performance analysis, we
manipulate the output of the event abstraction techniques to compute the per-
formance metrics ( transform step). if the output does not contain the attribute
to indicate the instance of a concept at a coarser level of a process, we consider
the continuous events with the same targeting instance at a coarser granularity
level as an instance, i.e., the duration between the rst and the last event of
such instance corresponds to the cycle time in our approach. for other metrics,
we apply the same denition in our approach, e.g., ow time of an instance of a
higher level concept is the duration from the rst to the last event of which the
activities are contained in the high-level concept identied. as shown in fig. 7,
the proposed approach, i.e., pa, requires the least steps and does not require any
transformation for the performance visualization. note that other performance
analysis techniques can be applied to analyze other aspects of the performance.
in this case, our approach can, alternatively, generate an event log consisting of
the events in the stage instances and the transform step should be applied like
the other techniques.
domain knowledge required. the domain knowledge required for each
technique varies. for example, to train a prediction model, crf requires an
event log with every event being labeled; for pnp, a coarse-granular instance
is extracted with a pattern of the activities. to compare the domain knowledge
quantitatively, we calculate the percentage of the activities required to extract a
coarse-granular instance. table 3 shows how the domain knowledge is required
for every technique evaluated and the corresponding number of activities in the12 c. li et al.
table 3: overview: techniques used for experiments.
domain knowledge required#activities required (%)
(permitlog /bpic15 1)
crf all events labeled with the coarse-granular instance for training 1/1
pnp behavior of the activities of every concept at a coarser granular level 0.71/0.9
pa start and end activities of a stage class 0.37/0.78
sess parameters tuning 0/0
sm minimum number of activities in a concept at a coarser granular level 0/0
input of the techniques in the experiments. our approach outperforms the crf
and pnp. however, it is inferior to sess and sm since the two techniques are
unsupervised. nevertheless, sess requires exhaustively tuning of the parameters
and the results are non deterministic. sm, as presented in the next section,
cannot guarantee the availability of the results.
4.2 evaluation on metrics reliability
we perform analysis using the methods based on the steps illustrated in fig. 7.
to evaluate the results, generally speaking, the accuracy is an ideal indicator of
the reliability of the results. however, due to the assumptions of dierent tech-
niques, e.g., some are supervised while others are unsupervised approaches, it is
unfair to compare the accuracy for the reliability. therefore, the experiments are
conducted on a best eort basis and we consider the number of measurements
included as the indicator for the reliability of the metrics, i.e., the more measure-
ments and cases used to compute a performance metrics, the more reliable the
results are. note that, except for sm of which the results are unavailable, all the
techniques require a user to determine the number of concepts in a coarser gran-
ular level, i.e., the number of stage classes in terms of the proposed approach.
therefore, for the concepts at a coarser granular level, we dene four concepts for
a travel reimbursement management process for permitlog [8] and nine phases
which are implied in activity code in a dutch municipality for bpic15 1[6]. the
quality of the results are examined from two perspectives, whether the number
of the concepts identied matches with the number of the concepts dened and
the amount of the measurements.
table 4 presents the performance statistics with the number of the mea-
surements for the cycle time and the cases executing the concepts at a coarser
granular level, i.e., # ft. for both event logs, crf and sess cannot extract the
exact number of concepts dened. crf identies too many concepts which in-
clude the events that the technique fails to predict (none) using permitlog and
too less concepts using bpic15 1. sess extracts less clusters despite the fact
that the numbers of clusters desired are specied with the parameter. therefore,
only pnp generates the same number of concepts at a coarser granular level as
specied. however, only the results using permitlog are available while they
are inferior to the proposed approach in terms of the number of measurements
included. to conclude, the proposed approach provides the most reliable metrics
compared with the other techniques in the experiments.stage-based process performance analysis 13
table 4: number of measurements per high-level concept identied using per-
mitlog and bpic15 1. nan indicates that the results are unavailable.
(a)permitlog
high-level concept identied (#ct/#ft)
crf pnp pa sess sm
- apply (7911/7062) - apply (7911/7062) - apply (7911/7062) - start trip+ (5406/3965) nan
- claim (1715/1336) - claim (1605/1296) - claim (2026/1314) - permit final approved
- travel (7843/7065) - travel (6331/633) - travel (7065/7065) - by supervisor+ (5715/4095)
- declare (5980/5718) - declare (5043/4963) - declare (7401/5569) - request payment+ (10512/5856)
- none (1276/1276)
(b)bpic15 1
high-level concept identied (#ct/#ft)
crf pnp pa sess sm
- phase 1 (29/29) nan - phase 0 (1992/1199) - register submission date nan
- phase 2 (29/29) - phase 1 (3967/1119) - request+complete (901/670)
- phase 3 (193/178) - phase 2 (2727/969 ) - enter senddate decision environmental
- phase 4 (200/178) - phase 3 (2573/1028) - permit+complete (1498/948)
- phase 5 (180/176) - phase 4 (3397/925) - registration date publication+complete (105/102)
- phase 8 (1027/1027) - phase 5 (2054/899) - enter senddate procedure
- phase 6 (1/1) - conrmation+complete (100/97)
- phase 7 (138/138) - enter senddate acknowledgement+complete (106/102)
- phase 8 (156/153) - generate publication document decision
- environmental permit+complete (154/147)
- create subcases completeness+complete (18/18)
4.3 experiments summary
we perform a comparative evaluation by analyzing stage performance using
various techniques. we compare the ease of the use of the techniques and the
reliability of the resulting performance metrics. in terms of the ease of use, our
approach requires the least eort from a user. however, we still require some
domain knowledge in comparison with the unsupervised techniques. the relia-
bility of the metrics is based on whether the number of the concepts at a coarser
granular level is the same as specied and the number of measurements. the
proposed approach outperforms all the other techniques evaluated. to conclude,
the results show that our approach meets the balance between the ease of use
and the reliability of the metrics.
4.4 threats to validity
the existing techniques are not designed for analyzing the performance at a high
level of a process. therefore, some information that is required to compute the
duration of a coarse-granular instance, i.e., the start and complete time of the
instance, is left for users to determine. consider two interleaving instances of
two concepts at a coarser granular level. such behavior may result in multiple
cycle time for each instance in the transform step. however, in fact, only two
measurements should be extracted. thus, despite the best eort to apply the
techniques, the results may not be accurate due to the manipulation.14 c. li et al.
for the proposed approach, the implementation allows an analyst to dene
only the stage classes with the distance and the mapping of events congured as
default. however, there may be some scenarios where the parameters may not
be dened easily and, thus, require further eort to congure the parameters
to obtain reliable results. in addition, the performance of stage instances is
aggregated at the case level. which metrics makes sense for the analysis depends
on the context. for example, in terms of stage instances of a stage class executed
in parallel, the average cycle time may not be a reasonable choice for some
processes. nevertheless, consider the scenario in fig. 3, the average can be used
to compute the costs for hiring the sta in the laboratories. such decision requires
analysts to be aware of the context.
5 conclusion
the diagnosis of ineciencies requires performance metrics provided based on
interpretable results. we elevate the analysis to the stage level and visualize
the performance accordingly. existing techniques are insucient for stage per-
formance analysis. the evaluation shows that combining existing techniques re-
quires additional manipulation of an event log and domain knowledge from a
user. moreover, the results may be unreliable or unavailable. we propose an ap-
proach that supports performance analysis at the stage level by extracting events
that are critical for the metrics. as such, our approach minimizes the eort from
users while providing the most reliable results compared to the existing works.
meanwhile, the technique can be exibly combined with other visualization to
analyze other aspects of a process. to facilitate the analysis at the stage level,
further research aims at automatic identication of stage classes.
references
1. van der aalst, w., unterberg, d.t.g., denisov, v., fahland, d.: visualizing to-
ken ows using interactive performance spectra. in: international conference on
applications and theory of petri nets and concurrency (2020)
2. denisov, v., belkina, e., fahland, d., van der aalst, w.: the performance spec-
trum miner: visual analytics for ne-grained performance analysis of processes. in:
bpm (dissertation/demos/industry) (2018)
3. denisov, v., fahland, d., van der aalst, w.: unbiased, ne-grained description of
processes performance from event data. in: international conference on business
process management (2018)
4. dumas, m., la rosa, m., mendling, j., reijers, h.a.: fundamentals of business
process management (2018)
5. g unther, c.w., rozinat, a.: disco: discover your processes. bpm (demos) (2012)
6. van der ham, u.: benchmarking of ve dutch municipalities with process mining
techniques reveals opportunities for improvement (2015)
7. haziza, d., rapin, j., synnaeve, g.: hiplot, interactive high-dimensionality plots.
https://github.com/facebookresearch/hiplot (2020)stage-based process performance analysis 15
8. hobeck, r., pufahl, l., binetruy, p., chada, w., digtiar, m., g ulle, k.j., slarzyn-
ska, m., stiehle, f., weber, i.: performance, variant, and conformance analysis of
an academic travel reimbursement process (2020)
9. hornix, p.t.: performance analysis of business processes through process mining.
master's thesis, eindhoven university of technology (2007)
10. kasim, t., haracic, m., haracic, m.: the improvement of business eciency
through business process management. economic review: journal of economics
and business (2018)
11. leemans, s.j., fahland, d., van der aalst, w.: discovering block-structured pro-
cess models from event logs containing infrequent behaviour. in: international con-
ference on business process management (2013)
12. de leoni, m., d undar, s.: event-log abstraction using batch session identication
and clustering. in: proceedings of the 35th annual acm symposium on applied
computing (2020)
13. li, c.y., van zelst, s.j., van der aalst, w.: a generic approach for process per-
formance analysis using bipartite graph matching. in: international conference on
business process management (2019)
14. mannhardt, f., tax, n.: unsupervised event abstraction using pattern abstraction
and local process models. arxiv preprint arxiv:1704.03520 (2017)
15. nguyen, h., dumas, m., ter hofstede, a.h., la rosa, m., maggi, f.m.: stage-
based discovery of business process models from event logs. information systems
(2019)
16. nguyen, h., dumas, m., ter hofstede, a., la rosa, m., maggi, f.: business process
performance mining with staged process ows. in: international conference on
advanced information systems engineering (2016)
17. song, m., van der aalst, w.: supporting process mining by showing events at a
glance. in: proceedings of the 17th annual workshop on information technologies
and systems (2007)
18. tax, n., sidorova, n., haakma, r., van der aalst, w.: mining process model de-
scriptions of daily life through event abstraction. in: proceedings of sai intelligent
systems conference (2016)
19. tax, n., sidorova, n., haakma, r., van der aalst, w.: event abstraction for process
mining using supervised learning techniques. in: proceedings of sai intelligent
systems conference (2016)
20. van der aalst, w.: process mining: data science in action. springer (2016)
21. van der aalst, w., adriansyah, a., van dongen, b.: replaying history on process
models for conformance checking and performance analysis. wiley interdisciplinary
reviews: data mining and knowledge discovery (2012)
22. van dongen, b.: bpi challenge 2015 municipality 1 (2015).
https://doi.org/"10.4121/uuid:a0addfda-2044-4541-a450-fdcc9fe16d17"
23. van dongen, b.: bpi challenge 2020: travel permit data (2020).
https://doi.org/10.4121/uuid:ea03d361-a7cd-4f5e-83d8-5fbdf0362550
24. van dongen, b., de medeiros, a.k.a., verbeek, h., weijters, a., van der aalst, w.:
the prom framework: a new era in process mining tool support. in: international
conference on application and theory of petri nets (2005)