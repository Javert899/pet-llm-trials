process mining 
discovering workflow models from event-based data 
a.j.m.m. weijters      w.m.p van der aalst  
eindhoven university of technology, p.o. box 513, nl-5600 mb, 
eindhoven, the netherlands, +31 40 2473857/2290 
 
abstract 
contemporary workflow management systems are driven by explicit process models, 
i.e., a completely specified workflow design is required in order to enact a given workflow process. creating a workflow design is a complicated time-consuming process and typically there are discrepancies between the actual workflow processes 
and the processes as perceived by the management. therefore, we propose a technique 
for process mining. this technique uses workflow logs to discover the workflow process as it is actually being executed. the process mining technique proposed in this paper can deal with noise and can also be used to validate workflow processes by 
uncovering and measuring the discrepancies between prescriptive models and actual 
process executions.  
1. introduction 
during the last decade workflow management concepts and technology [2, 9, 10] have 
been applied in many enterprise information systems. workflow management systems 
such as staffware, ibm mqseries, cosa, etc. offer generic modeling and enactment 
capabilities for structured business processes. by making graphical process definitions, i.e., models describing the life-cycle of a typical case (workflow instance) in isolation, one can configure these systems to support business processes. besides pure workflow management systems many other software systems have adopted workflow technology. 
despite its promise, many problems are encountered when applying workflow 
technology. as indicated by many authors, workflow management systems are 
inflexible and have problems dealing with change [2]. in this paper we take a different perspective with respect to the problems related to flexibility. we argue that many problems are resulting from a discrepancy between workflow design  (i.e., the 
construction of predefined workflow models) and workflow enactment (the actual 
execution of workflows). workflow designs are typically made by a small group of 
consultants, managers and specialists. as a result, the initial design of a workflow is 
often incomplete, subjective, and at a too high level. therefore, we propose to “reverse the process”. instead of starting with a workflow design, we start by gathering information about the workflow processes as they take place. we assume that it is possible to record events such that (i) each event refers to a task (i.e., a well-defined step in the workflow), (ii) each event refers to a case (i.e., a workflow instance), and (iii) events are totally ordered. any information system using transactional systems such as 
erp, crm, or workflow management systems will offer this information in some form. 
we use the term process mining  for the method of distilling a structured process 
description from a set of real executions. 
the remainder of this paper is as follows. first we discuss related work and 
introduce some preliminaries including a modeling language for workflow processes and the definition of a workflow log. then we present a new technique for process mining. finally, we conclude the paper by summarizing the main results and pointing 
out future work.   
2. related work and preliminaries 
the idea of process mining is not new [3, 4, 5, 8]. however, most results are limited to 
sequential behavior. cook and wolf extend their work to concurrent processes in [5]. they also propose specific metrics (entropy, event type counts, periodicity, and 
causality) and use these metrics to discover models out of event streams. this approach 
is similar to the one presented in this paper. however, our metrics are quite different and our final goal is to find explicit representations for a broad range of process models, i.e., we generate a concrete petri net rather than a set of dependency relations between events.  
compared to existing work we focus on workflow processes with concurrent 
behavior, i.e., detecting concurrency is one of our prime concerns. therefore, we want to 
distinguish and/or splits/joins explicitly. to reach this goal we combine techniques from machine learning with workflow nets (wf-nets, [1]). wf-nets are a subset of petri nets. note that petri nets provide a graphical but formal language designed for modeling concurrency. moreover, the correspondence between commercial workflow 
management systems and wf-nets is well understood [1, 2, 7, 9, 10]. 
 
sb
se p10
p8p9
p7p6 p4
p5 p3p2p1
t4t12
t9
t7t13 t11
t10t8
t6t5 t3 t2t1
 
figure 1: example of a workflow process modeled as a petri net. 
workflows are by definition case-based , i.e., every piece of work is executed for a 
specific case. examples of cases are a mortgage, an insurance claim, a tax declaration, 
an order, or a request for information. the goal of workflow management is to handle cases as efficient and effective as possible. a workflow process is designed to handle similar cases. cases are handled by executing tasks  in a specific order. the workflow 
process model specifies which tasks need to be executed and in what order. petri nets [6] 
constitute a good starting point for a solid theoretical foundation of workflow management. clearly, a petri net can be used to specify the routing of cases (workflow 
instances). tasks  are modeled by transitions  and causal dependencies  are modeled by 
places  and arcs. as a working example we use the petri net shown in figure 1.  
the transitions t1, t2, …, t13  represent tasks, the places sb, p1, …, p10, se  
represent the causal dependencies. in fact, a place corresponds to a condition that can be used as pre- and/or post-condition for tasks. an and-split corresponds to a transition with two or more output places (from t2 to p2 and p3), and an and-join corresponds 
to a transition with two or more input places (from p8 and p9 to t11). or-splits/or-
joins correspond to places with multiple outgoing/ingoing arcs (from p5 to t6 and t7, 
and from t7 and t10 to p8). at any time a place contains zero or more tokens , drawn as 
black dots. transitions are the active components in a petri net: they change the state of the net according to the following firing rule : 
(1) a transition t is said to be enabled  iff each input place of t contains at least one 
token. 
(2) an enabled transition may fire. if transition t fires, then t consumes one token 
from each input place p of t and produces one token for each output place p of t. 
a petri net which models the control-flow dimension of a workflow, is called a 
workflow net  (wf-net) [1]. a wf-net has one source place ( sb) and one sink place ( se) 
because any case (workflow instance) handled by the procedure represented by the wf-
net is created when it enters the workflow management system and is deleted once it is 
completely handled, i.e., the wf-net specifies the life-cycle of a case. an additional requirement is that there should be no “dangling tasks and/or conditions”, i.e., tasks and conditions which do not contribute to the processing of cases. therefore, all the nodes of the workflow should be on some path from source to sink. 
although wf-nets are very simple, their expressive power is impressive. in this 
paper we restrict our self to so-called sound  wf-nets [1]. a workflow net is sound if the 
following requirements are satisfied: (i) termination is guaranteed, (ii) upon termination, no dangling references (tokens) are left behind, and (iii) there are no dead tasks, i.e., it should be possible to execute an arbitrary task by following the appropriate route. soundness is the minimal property any workflow net should satisfy.  
in this paper, we use workflow logs to discover workflow models expressed in terms 
of wf-nets. a workflow log is a sequence of events. for reasons of simplicity we 
assume that there is just one workflow process. note that this is not a limitation since the case identifiers can be used to split the workflow log into separate workflow logs for each process. therefore, we can consider a workflow log as a set of event sequences 
where each event sequence is simply a sequence of task identifiers. formally, wl⊆t* 
where wl is a workflow log and t is the set of tasks. an example event sequence of the 
petri net of figure 1 is given below: 
t1, t2, t4, t3, t5, t9, t6, t3, t5, t10, t8, t11, t12, t2, t4, t7, t3, t5, t8, t11 ,t13 
using the definitions for wf-nets and event logs we can easily describe the problem 
addressed in this paper: given a workflow log wl we want to discover a wf-net that (i) 
potentially generates all event sequence appearing in wl, (ii) generates as few event 
sequences of t*\wl as possible, (iii) captures concurrent behavior, and (iv) is as simple 
and compact as possible. moreover, to make our technique practical applicable we want to be able to deal with noise.  3. process mining technique 
in this section we present the details of our process mining technique. we can 
distinguish three mining steps: step (i) the construction of a dependency/frequency table 
(d/f-table), step (ii) the induction of a d/f-graph out of a d/f-table, and step (iii) the 
reconstruction of the wf-net out of the d/f-table and the d/f graph.  
3.1 construction of the dependency/frequency table 
the starting point of our workflow mining technique is the construction of a d/f-table. for each task a the following information is abstracted out of the workflow log: (i) the 
overall frequency of task a (notation #a), (ii) the frequency of task a directly preceded 
by another task b (notation b<a ), (iii) the frequency of a directly followed by another 
task b (notation a>b ), (iv) the frequency of a directly or indirectly preceded by another 
task b but before the next appearance of a (notation b<<<a ), (v) the frequency of a 
directly or indirectly followed by another task b but before the next appearance of a 
(notation a>>>b ), and finally (vi) a metric that indicates the strength of the causal 
relation between task a and another task b (notation a
æb). 
 
 #b b<a a>b b<<<a a>>>b a ææææb 
t10 1035 0 581 348 1035 0.803 
t5 3949 80 168 677 897 0.267 
t11 1994 0 0 528 1035 0.193 
t13 1000 0 0 0 687 0.162 
t9 1955 50 46 366 538 0.161 
t8 1994 68 31 560 925 0.119 
t3 3949 146 209 831 808 0.019 
t6 1035 0 0 348 348 0.000 
t7 959 0 0 264 241 -0.011 
t12 994 0 0 528 505 -0.093 
t1 1000 0 0 687 0 -0.246 
t2 1994 0 0 1035 505 -0.487 
t4 1994 691 0 1035 505 -0.825 
table 1: an example d/f-table for task t6. 
metric (i) through (v) seems clear without extra explanation. the underlying 
intuition of metric (vi) is as follows. if it always the case that, when task a occurs, 
shortly later task b also occurs, than it is plausible that task a causes the occurrence of 
task b. on the other hand, if task b occurs (shortly) before task a it is implausible that 
task a is the cause of task b.  bellow we define the formalization of this intuition. if, in 
an event stream, task a occurs before task b and n is the number of intermediary events 
between them, the aæb-causality counter is incremented with a factor (δ)n. δ is a 
causality fall factor (δ in [0.0…1.0]).  in our experiments δ is set to 0.8. the effect is that 
the contribution to the causality metric is maximal 1 (if task b appears directly after task 
a then n=0) and decreases if the distance increases. the process of looking forward from 
task a to the occurrence of task b stops after the first occurrence of task a or task b. if 
task b occurs before task a and n is again the number of intermediary events between them, the aæb-causality counter is decreased with a factor (δ)n. after processing the 
whole workflow log the aæb-causality counter is divided by the overall frequency of 
task a (#a).   
given the process model of figure 1 a random workflow log with 1000 event 
sequences (23573 event tokens) is generated. as an example table 1 shows the above-defined metrics for task t6. notice that the task t6 belongs to one of two concurrent 
event streams (the and-split in t2). it can be seen from table 1 that (i) only the 
frequency of t6 and t10 are equal (#t6=#t10=1035) , (ii) t6 is never directly preceded 
by t10 (b<a=0),  (iii) t6 is often directly followed by t10 (a>b=581),  (iv) t6 is 
sometimes preceded by t10 (b<<<a = 348) , and (v) always preceded by t10 (a>>>b 
= #t6=1035).  finally, (vi) there is strong causality relation from t6 to t10 (0.803) and 
to a certain extent to t5 (0.267) . however, t6 is from time to time directly preceded by 
t5 (b<a = 80) . in the next section we will use the d/f-table in combination with a 
relatively simple heuristic to construct a d/f-graph. 
3.2 induction of dependency/frequency graphs 
in the previous section we observed that the information in the t6-d/f-table strongly 
suggests that task t6 is the cause for task t10 because the causality between t6 and t10 
is high, and t6 is never directly preceded by t10 and frequently (directly) followed by 
t10. our first heuristic rule is in line with this observation:   
if ((aæb ≥ n) and (a>b ≥ σ) and (b<a ≤ σ)) then <a,b> ∈ t (1) 
the first condition (aæb ≥ n) uses the noise factor  n (default value 0.05). if we expect 
more noise we can increase this factor. the first condition calls for a higher positive causality between task a and b than the value of the noise factor. the second condition 
(a>b 
≥ σ) contains a threshold value σ. if we know that we have a workflow log that is 
totally noise free, then every task-patron-occurrence is informative. however, to protect 
our induction process against inferences based on noise, only task-patron-occurrences 
above a threshold frequency σ are reliable enough for our induction process. to limit the 
number of parameters the value σ is automatically calculated using the following 
equation: σ =1+round (n*#l/#t). n  is the noise factor, #l is the number of trace lines 
in the workflow log, and #t is the number of elements (different tasks) in the node set t. 
in our working example σ =1+ round(0.05*1000/13)=5. it is clear now that the second 
condition demands that the frequency of a>b  is equal or higher than the threshold value 
σ. finally, the third condition states the requirement that the frequency of b<a  is equal 
or higher than σ. applying this simple rule on the d/f-table based on the figure 1 
workflow-log results in the d/f-graph of figure 2. if we compare the d/f-graph of 
figure 2 with the petri net of figure 1 it can be seen that all the connections between de nodes are in accordance with underlying workflow model (all connections are correct and there are no missing connections).  
however, the heuristic rule formulated above will not recognize recursion (in figure 
1, move the t9-p2  arrow to p6) or short loops (in figure 1, move the t9-p2 arrow to 
p4). after all, the recursion in t9 will result in patterns like t5, t4, t9, t9, t6, t9, t8 . 
because t9 seems both cause for, and result from t9 the frequency of the casualty 
relation t9
æt9 is about zero. however we can recognize the recursion relatively simple: it will result in both a high and equal frequency of t9>t9  and t9<t9  and a high 
and equal frequency of t9>>>t9  and t9<<<t9 .  
 
t1
1000t2
1994t3
3949t4
1994t6
1035
t5
3949t7
959
t12
994t13
1000t11
1994
t8
1994t9
1995t10
1035
1.000
0.4200.502
0.8430.309
0.453 0.2470.7320.386
1.000
0.104
0.4230.4750.428
0.667
1.000 
figure 2: the automatically mined d/f-graph. 
the short loop from t9 to t5 will result in patterns like t5, t4, t9, t5, t9, t6, t5, 
t8. again t5 seems both cause for, and result from t9. however, short loops can be 
recognized by observing that both a high and about equal frequency of t5>t9  and 
t9<t5  and a high and about equal frequency of t5>>>t9  and t9<<<t5 . in line with 
this observations our first heuristic rule (1) is extended with rule (2) and (3):  
if ((aæa ≈ 0) and (a<a + a>a > 0.5 * #a)  and    (2) 
      (a<a – a>a ≈ 0)) then <a,a> ∈ t 
if ((aæb ≈ 0) and (a>b ≥ σ) and (b<a ≈ a>b) and   (3) 
 (a>>>b ≥ 0.4 * #a)  and (b<<<a ≈ a>>>b)  then <a,b> ∈ t 
to prevent our heuristic from breaking done in the case of some noise, we use an about 
symbol ( ≈) instead of the equality symbol (=). again, the noise factor n is used to 
specify what we mean with ‘about equal’: x ≈ y iff the relative difference between them 
is less than n.  
3.3 generating wf-nets from d/f-graphs 
given a workflow log it appears relatively simple to find the corresponding d/f-graph. 
but, the types of the splits and joins are not yet represented in the d/f-graph. however 
information in the d/f-table contains useful information to indicate the type of a join or 
a split. for instance, if we have to detect the type of a split from a to b and/or c, we 
can look in the d/f-table to the values of c<b and b>c . if a is an and-split we expect 
a positive value for both c<b and b>c  (because the pattern b, c and the pattern c, b 
can appear). if it is a or-split the patterns b,c and c,b  will not appear. 
the pseudo code for an algorithm based on this heuristic is given in table 2. 
suppose, task a is directly preceded by the task b1 to bn. set 1  to set n are empty sets. 
after applying the algorithm all or-related tasks are collected in a set set i. all not 
empty sets are in the and-relation.   
we can apply an analogue algorithm to reconstruct the type of a join. for instance, 
applying the algorithm on the t11-join will result in two sets {t7, t10}  and {t8} or in 
proposition-format ( (t7 or t10) and  t8). using this algorithm we were able to 
reconstruct the types of the splits and joins appearing in our working example and to 
reconstruct the complete underlying wf-net. in the next section we will report our experimental results of applying the above-defined heuristics on other workflow logs, 
with and without noise. 
for i:=1 to n  do 
 for j:=1 to n do    ok:=false;   repeat 
   if 
∀ x∈ set j [(bi>x < σ) and  (x>b i < σ )]  then  
   begin  set j := set j ∪ {b i }; ok:=true end; 
  until ok; 
 end j do; end i do; 
table 2: the pseudo code used to reconstruct the types of the splits and joins of 
a d/f-graph. 
3.4 experiments 
to test our approach we use the petri-net-representations of six different workflow 
models. the complexity of these models range from comparable with the complexity of 
our working model of figure 1 (13 tasks) to models with 16 tasks. all models contain concurrent processes and loops. for each model we generated three random workflow logs with 1000 event sequences: (i) a workflow log without noise, (ii) one with 5% noise, and (iii) a log with 10% noise. below we explain what we mean with noise. 
to incorporate noise in our workflow logs we define four different types of noise 
generating operations: (i) delete the head of a event sequence, (ii) delete the tail of a 
sequence,  (iii) delete a part of the body, and finally (iv) interchange two random chosen events. during the deletion-operations minimal one event, and maximal one third of the sequence is deleted. the first step in generating a workflow log with 5% noise is a normal random generated workflow log. the next step is the random selection of 5% of 
the original event sequences and applying one of the four above described noise 
generating operations on it.  
due to lack of space it is not possible to describe all workflow models and the 
resulting d/f-graphs in detail. however, applying the above method on the six noise free workflow logs results in six perfect d/f-graphs (i.e. all the connections are correct and there are no missing connections), and exact copies of the underlying wf-nets.  if 
we add 5% noise to the workflow logs, the resulting d/f-graphs and wf-nets are still 
perfect. however, if we add 10% noise to the workflow logs one d/f-graph is still perfect, five d/f-graphs contains one error. all errors are caused by the low threshold 
value σ=5 in rule (1), resulting in an unjustified applications of this rule. if we increase 
the noise factor value to a higher value (n=0.10 ), the automatically calculated threshold 
value σ increases to 9 and all five errors disappear and no new errors occur. 
4. conclusion 
in this paper we introduced the context of workflow processes and process mining, some 
preliminaries including a modeling language for workflow processes, and a definition of a workflow log. hereafter, we presented the details of the three steps of our process 
mining technique: step (i) the construction of the d/f-table, step (ii) the induction of a 
d/f-graph out of a d/f-table, and step (iii) the reconstruction of the wf-net out of the 
d/f-table and the d/f graph.  
in the experimental section we applied our technique on six different sound 
workflow models with about 15 tasks. all models contain concurrent processes and loops. for each workflow model we generated three random workflow logs with 1000 event sequences: (i) without noise, (ii) with 5% noise, and (iii) with 10% noise. using 
the proposed technique we were able to reconstruct the correct d/f-graphs and wf-nets. 
the experimental results with the workflow logs with noise indicate that our technique seems robust in case of noise.   
notwithstanding the reported results there is a lot of future work to do. first, the 
reported results are based on a limited number of experimental results; more 
experimental work must be done. secondly, we will try to improve the quality and the 
theoretical basis of our heuristics. can we for instance prove  that our heuristic is 
successful applicable to logs from for instance free-choice wf-nets? finally, we will extend our mining technique in order to enlarge the set of underlying wf-nets that can be successfully mined. 
references 
[1] w.m.p. van der aalst. the application of petri nets to workflow management. the journal 
of circuits, systems and computers, 8 (1):21-66, 1998. 
[2] w.m.p. van der aalst, j. desel, and a. oberweis, editors. business process management: 
models, techniques, and empirical studies , volume 1806 of lecture notes in computer 
science. springer-verlag, berlin, 2000. 
[3] r. agrawal, d. gunopulos, and f. leymann. mining process models from workflow logs . in 
the proceedings of the sixth international conference on extending database tec hnology, 
pages 469-483, 1998. 
[4] j.e. cook and a.l. wolf. discovering models of software processes from event-based 
data, acm transactions on software engineering and methodology , 7(3):215-249, 1998. 
[5] j.e. cook and a.l. wolf. event-based detection of concurrency. in proceedings of the  
sixth international symposium on the foundations of software engineering (fse-6), 
orlando, fl, november 1998, pp. 35-45.  
[6] j. desel and j. esparza. free choice petri nets , volume 40 of cambridge tracts in 
theoretical computer science. cambridge university press, cambridge, uk, 1995. 
[7] c.a. ellis and g.j. nutt. modelling and enactment of workflow systems. in m. ajmone 
marsan, editor, application and theory of petri nets 1993, volume 691 of lecture notes in 
computer science, pages 1-16. springer, berlin, germany, 1993. 
[8] j. herbst. a machine learning approach to workflow management.  in 11th european 
conference on machine learning, volume 1810 of lecture notes in computer science, 
pages 183-194, springer, berlin, germany, 2000. 
[9] s. jablonski and c. bussler. workflow management: modeling concepts, architecture, and 
implementation.  international thomson computer press, 1996. 
[10] p. lawrence (editor). workflow handbook 1997, workflow management coalition. john 
wiley and sons, new york, 1997. 