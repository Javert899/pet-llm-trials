root cause analysis with enriched process logs
s. suriadi1, c. ouyang1, w.m.p. van der aalst1;2, and a.h.m. ter hofstede1;2
1queensland university of technology, australia
{s.suriadi,c.ouyang,a.terhofstede} @qut.edu.au
2eindhoven university of technology, the netherlands
{w.m.p.v.d.aalst,a.h.m.ter.hofstede} @tue.nl
abstract. in the eld of process mining, the exploitation of event logs
for the purpose of root cause analysis is a relatively unexplored area. this
paper proposes an approach to enrich and transform process-based logs
for the purpose of root cause analysis through the application of classi-
cation techniques. this approach facilitites an objective identication of
the root cause(s) of various incidents as it is grounded on what has actu-
allyhappened, thus, minimizing the inuence of subjective perceptions
in the results. the approach proposed in this paper is formalized and
its applicability has been validated using both self-generated logs and a
publicly-available log.
topic classication: mining of business processes
keywords: process mining, root cause analysis, event logs, business
process management
1 introduction
a recent survey by gartner shows that risk management is one of the top strate-
gic business priorities for ceos and senior executives [2]. a common way to
mitigate risks is to remove or minimize the presence of key factors which are
known to contribute to the occurrence of unwanted risk events. for example,
it is well-established that pilot fatigue is one of the key factors contributing to
airline safety issues [3]. thus, measures to mitigate the chance of pilots being
fatigued during working hours have routinely been implemented
root cause analysis (rca) has been applied widely in organisations and
many techniques have been developed, including the use of ow charts, spider
charts, brainstorming, and others [1]. through rca, one aims to nd an expla-
nation of risk incidents, preferably an explanation involving a minimal number
of factors. as many events are recorded in logs nowadays (e.g. by devices or
software applications) one can exploit this data for the purpose of rca with
the added advantage that the data reects reality and not a perception (e.g.
in the form of a model) of reality. as we focus on operational rocesses in this
paper, one can take post-execution event data as a starting point and compare
features, recorded as attributes, of cases (i.e. process instances) that were classi-
ed as successful with those features of cases that were classied as unsuccessful.2 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
this way we can dene a classication problem whose results provide valuable
input for rca.
the features which may be the root cause(s) of risk incidents may come from
various context, including instance context, process context, social context, and
environmental context [19]. however, raw data from post-execution logs (com-
monly known as event logs), may not readily contain the necessary information
to explain the possible root cause(s) of risk incidents.
in this paper, we propose an rca approach that starts with an existing event
log and enriches it with relevant contextual information for explaining possible
root cause(s) of risk incidents. this enriched log can then be manipulated further
such that it can be analyzed using established classication techniques. in other
words, we transform a process mining problem, i.e. rca based on event logs,
into a standard classication problem. in this paper, we focus on the approach
and not on the selection of variables (features). in fact, in order to illustrate
our approach and also to scope our paper, we investigate the eect of workload
on `overtime' (long-running) cases. here we may draw on the yerkes dodson
law [21, pp. 485-486] which captures the relationship between the stress level
of resources and their performance. this relationship can be visualised as an
inverted letter `u' in a diagram with performance on the y-axis and degree of
stress level on the x-axis, indicating that both low and high stress levels are
related to low performance.
in the remainder of the paper, we rst explain our approach in detail and
present a formalisation. this is then followed by an application of the approach
to rca with workload-enriched logs. finally the approach is validated with a
publicly available log to demonstrate its applicability.
2 approach
in this section, we describe our approach to mining the root cause of risk in-
cidents (such as budget overrun and long running/overtime cases) through the
transformation of a process mining problem into a standard classication prob-
lem. our approach starts with determining relevant information that is needed
to explain the root cause of a risk incident, followed by the enrichment of the
related event log with the necessary information to ensure that sucient infor-
mation for rca is captured. through the application of aggregation functions
and other renement procedures, we transform this enriched event log into a
form that is suitable to be analysed by classication techniques. fig. 1 depicts
our approach - the details of which are explained in this section.
rca data requirements. as a requirement from classication techniques, rca
uses a response variable for the labelling of `successful/unsuccessful' cases. an
example of a response variable can be seen as a feature in a log which states the
outcome of a case as either being `on-time' or `overtime'. the features which may
inuence the occurrence of `successful/unsuccessful' cases are labelled as predic-2 approach 3
raw event log enrich aggregate
data mining
  analysislae enriched event log
la'ecase log
l*ac classification-ready log
l*a'c refine
response / predictor
         variablesinforms informs contains
fig. 1: approach diagram.
torvariables. an example of a predictor variable can be specied by workload
which may have impact on the occurrence of long-running (over-time) cases.
thus, the very rst step of our approach is to determine the response vari-
able capturing the risk incident we want to analyze, and the set of predictor
variables which may contribute to the occurrence of such risk incident. the
determination of these attributes must of course be informed by established
management theories and studies as well as from a company's risk registries.
in process mining, these variables may be taken from various context, including
instance context (e.g. size of an insurance claim), process context (e.g. total num-
ber of resources involved), social context (e.g. stress level), and external context
(e.g. weather) [19].
enrich raw event log. once the predictor and response variables are deter-
mined, we need to verify if our raw event log contains sucient information to
captures those variables. it is possible that some information may not be read-
ily available in the raw event log, but can be derived from the data in the raw
event log. there are also situations when the required information needs to be
obtained from external sources and be correlated to the raw event log. once the
above information is obtainable, we can then extend the raw event log with such
information thus resulting in an enriched event log).
denition 1 (event log). anevent log consists of a set of events. events
are characterised by various attributes, e.g., an event may have a timestamp,
correspond to an activity, etc. let ae=fa1;:::;a ngbe a set of event attributes.
for each attribute ai2ae(16i6n),di=dom(ai) (i.e. the domain of ai),
e.g., the domain of attribute timestamp is the set of all possible time values.
lae2d1:::dnis an event log based on the set of attributes ae. for any
evente2land attribute a2ae: #a(e) is the value of attribute afor evente.
denition 2 (event log enrichment). letlaebe an event log based on the
set of attributes ae. letadbe a set of derivable attributes whose value can be
calculated from ae, i.e. for each attribute d2ad,lae[fdg=d(lae) where
dis a derivative function that computes the value of attribute dfor all events
inlae. letakbe a set of correlatable attributes whose value can be obtained
from external sources based on some key attributes in ae, i.e. for each attribute
k2ae,lae[fkg=!k(lae) where!kis a correlative function that retrieves the
value of attribute kfor all events in lae.la0
ewherea0
e=ae[ad[ak, is an
enriched event log with a set of extended (derivable and correlatable) attributes.4 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
from event log to case log. the next step is to transform the event log into a
case log. this is necessary because rca is normally performed at case level.
denition 3 (case log). acase log comprises a set of cases. cases, like
events, have attributes, e.g., a case has a case identier, corresponds to a trace
(i.e. a sequence of events), etc. let ac=fs1;:::;s mgbe a set of case attributes,
including a mandatory attribute named case idwhich uniquely identies a case.
for eachsi2ac(16i6m),di=dom(si) where dom(case id) =c(i.e. the
set of all possible case identiers). l
ac2d1:::c:::dmis a case log based on
the set of attributes ac. for any case c2l
acand attribute s2ac: #s(c) is the
value of attribute sfor casec. for anyc1;c22l
ac, #case id(c1)6= # case id(c2).
denition 4 (aggregation of event log to case log). letlaebe an event
log based on the set of event attributes aewhere case id2ae. a corresponding
case logl
acbased on the set of attributes accan be generated from laeas:
(1) the set of case identierss
c2l
ac#case id(c) =s
e2lae#case id(e); and (2) for
each casec2l
acand attribute s2acnfcase idg, #s(c) =s(lae;#case id(c))
wheresis an aggregation function that calculates the value of attribute sin
casecfrom the relevant events in lae.
get case log ready for classication. forclassication techniques to work,
there are often requirements imposed on the structure of the data. for example,
most classication techniques require the response variable to be presented in a
categorial (nominal) form. if our data is not already in the correct format, we
need to further transform the attributes in a case log accordingly.
denition 5 (classication-ready case log). letl
acbe a case log based
on the set of (normal) attributes ac. leta
cbe a set of classication attributes
(e.g. capturing response variables) whose value is of categorial form and can be
computed from the set of case attributes ac.l
a0
cwherea0
c=ac[a
c, is
aclassication-ready case log . for each case c2l
a0
cand attribute q2a
c:
#q(c) =q(l
ac;c) whereqis a classication function that derives the value
of attribute qin casecbased on the corresponding case data in l
ac.
rca with classication techniques. through the process detailed so far, we
have now transformed a raw event log into a case log in a format that is suitable
for classication analysis. the enriched case log now has the values of both the
response andpredictor variables of interest. one can feed these data into various
data mining algorithms to nd the root cause(s) of a risk incident.
3 rca with workload-enriched logs
in this section, we apply our approach to the analysis of overtime cases using
event logs enriched with workload information. according to dictionary, workload
is dened as \the amount of work assigned to or expected from a person in a3 rca with workload-enriched logs 5
specied time period"1. in the context of business processes, workload has been
dened and computed in dierent ways (e.g. [21, chapter 11] [12]). in this paper,
we consider workload as a list of work items that have been allocated to and/or
started by a resource in a specied time period .
workload is usually not recorded directly in a raw event log but can be
derived from a set of basic event attributes that capture the information about
resource, activity, timestamp, and transaction type (which refers to the life-cycle
of activities, e.g. start, complete) associated with each event. below, we precisely
dene workload based on the information in a given event log of any process.
denition 6 (workload). letlbe an event log based on the set of event at-
tributes including fcase id;resource;activity;time;transg, where dom(trans ) =
fallocate;start;completeg. for any resource r2f#resource (e)je2lg, the work-
load ofrin time period ( ts;te), is dened as wlts;te
l(r) =wlts
l(r)[wl(ts;te)
l (r).
{ rst of all, assume three short notations:
{lr;ts=fe2lj#resource (e) =r^#time(e)<tsg
{lr;ts;te=fe2lj#resource (e) =r^ts6#time(e)6teg
{8e2l;wi(e) = (# activity (e);#case id(e)). then:
{wlts
l(r) =fwi(e)je2lr;ts^#trans(e)2fallocate;startggnf wi(e)je2lr;ts^
#trans(e) =completeg, i.e. the list of work items that have been allocated to
and/or started but not yet completed by resource rat timets; and
{wl(ts;te)
l (r) =fwi(e)je2lr;ts;te^#trans(e)2fallocate;startggnwlts
l(r),
i.e. the list of additional work items that are allocated to and/or started by
resourcerwithin time period ( ts;te).
consider a raw event log laewith a set of existing event attributes ae.
following the approach in sect. 2, we enrich log laewith workload information.
a derivable attribute resworkload captures the workload of all resources in the
log within certain time periods. each time period is specied by referencing the
timestamp of an individual event in laeand using the average activity duration
(aad) of the process as the time duration. we assume an existing function
avgactduration which takes an event log and returns the corresponding aad2.
algorithm 1 denes how to compute the value of attribute resworkload based
on the raw event log lae. first, a relation rwl, i.e. a set of ( time,resworkload )
tuples, is derived capturing the workload of all resources each time an event is
recorded in lae. by denition, an event log can be treated as a relation where
the set of event attributes specify its relation scheme. hence, in algorithm 1 three
relational algebra operators [10] are used to dene certain log operations: the
selection () of a set of events that saties specic conditions in the log; the pro-
jection () of all events in the log restricted to a set of attributes; and nally the
natural join (./) for combining all events in laeand all tuples in rwlon their
common attribute time to yield the workload-enriched log lae[fresworkloadg.
1http://www.thefreedictionary.com/workload
2the underlying computation for such function is already supported by a number of
log pre-processing tools, such as nitro (see http://www.fluxicon.com/nitro/ ).6 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
algorithm 1: generation of workload-enriched event log based on an in-
stantiation of derivative function in denition 2.
input : an event log laeand a derivable attribute resworkload
output : a workload-enriched event log lae[fresworkload g
begin
rwl:=;;/*rwlis a relation of ftime;resworkloadg*/
r:=f#resource (e)je2laeg;
t:=f#time(e)je2laeg;
dh:=avgactduration (lae)=2;
fort2tdo
rwl:=;;
ts:=t dh;
te:=t+dh;
forr2rdo
lr:=resource =r(lae);
/* calculate allocated/started but not completed work items at time ts*/
lr;ts:=time<ts(lr);
fortr2fallocate;start;completegdo
ltr
wi:=fcase id;activity g(trans =tr(lr;ts))
rwl:=rwl[f(r;(lallocate
wi[lstart
wi)nlcomplete
wi )g;
/* calculate allocated/started work items within time period (ts;te)*/
lr;ts;te
m :=ts6time6te(lr);
fortr2fallocate;startgdo
ltr
wi:=fcase id;activity g(trans =tr(lr;ts;te))
rwl:=rwl[f(r;(lallocate
wi[lstart
wi))g
rwl:=rwl[f(t;rwl )g
lae[fresworkload g=./ftimeg(lae;rwl)
now consider the set of event attributes ac=fcase id;time start;time end;
avgworkload;resourcesgthat are required for deriving the value of predictor and
response variables in the next step. we generate case log l
acfrom (the above
enriched) event log lae[fresworkloadg. for each case c2l
ac, we calculate:
{ # time start(c) =min(ftimeg(case id=# case id(c)(lae)))
{ # time end(c) =max(ftimeg(case id=# case id(c)(lae)))
{ # resources (c) =f#resource (e)je2case id=# case id(c)(lae)g
{ # avgworkload (c) =f(r;(p
ei2lc
aejworkload (r;ei)j)=jlc
aej)jr2rgwhere
{r=f#resource (e)je2laegis the set of all resources in lae,
{lc
ae=#time start(c)6timestamp 6#time end(c)(lae) is the set of all events in lae
that occurred between the start and the end of case c,
{workload (r;ei) is the workload of resource rat the time of event ei, which
is specied in # resworkload (ei).
finally, two examples of classication-ready attributes are a
c=fisovertime;
isclerkinvolvedg, where isovertime signals if a case (time) duration exceeds a
specic threshold value, and isclerkinvolved indicates if resource named clerk4 validation of approach 7
is involved in a case. both returns a value of boolean type (a valid categorial
form). hence, for each case c2l
a0
cwherea0
c=ac[a
c,
{ # isovertime (c) = ((# time end(c) #time start(c)>threshold )
{ # isclerkinvolved (c) = (clerk2#resources (c))
4 validation of approach
two rounds of approach validation were conducted. the rst validation round
was based on a self-generated synthetic log. it was conducted during the devel-
opment of our approach (w.r.t the enrichment of event log with workload infor-
mation) to facilitate step-by-step validation and renement of our approach. the
second evaluation round was conducted to demonstrate the general applicability
of our approach in a less controlled environment by applying our approach to
a log whose generation was beyond our control. the rst validation round is
briey described in sect. 4.1, while a more elaborate description of the second
evaluation round is provided in sect. 4.2.
log quality. to derive workload information, we assume the existence of an
event log of certain quality: (1) a minimum of 3-star log quality (as dened
in the process mining manifesto [18]), (2) the existence of a number of open
xes-equivalent attributes: (a) concept:name (at trace and event level), (b)
lifecycle:transition ,org:resource ,time:timestamp (at event level), and
(3) the recording of start (orassign ) and complete transition of each activity.
4.1 validation with synthetic log
the rst validation round was conducted using a purchase order scenario. a
synthetic log was generated using a coloured petri net (cpn) [9] model of
the purchase order process through the application of the mxml-log-generator
plug-in [11]. this log records the assign ,start , and complete transitions for
each activity. this log le was imported to a mysql database such that relevant
relational algebra operations can be performed. the workload derivation function
and case log aggregation functions (as dened in sect. 3) were implemented as
ajava program which interacted with the database. the nal classication-
ready case log was successfully fed into the weka data mining tool such that
the root cause of `overtime' cases can be analyzed by the application of various
classication algorithms (e.g. j48[13] and jrip [4]). the classication analysis
result from this log showed that average resources' workload was a key factor in
the occurence of `overtime' cases.
this validation round conrms the applicability of our approach in perform-
ing an rca through the enrichment and transformation of a process log such
that root cause(s) of a risk incident can be identied by applying classication
techniques. the details of this validation round are available in appendix a.8 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
4.2 validation with public log
while the rst validation round was necessary to conrm the applicability of our
approach, it was weak as it was based on a log that we generated ourselves. to
demonstrate the general applicability of our approach, we conducted a second
validation round using an event log that was generated by other people and is
available from the process mining website.3equally important, while further re-
nement is still needed, the second validation round conrms the generalizability
of the java program developed in enriching and transforming event log with re-
sources' workload and involvement information. thus, it is possible to automate
and streamline (to a certain degree) the approach proposed in this paper.
the log used in this validation round was generated from a telephone repair
process. this log contains the necessary attributes as dened in m. there are
four activities in this log: `analyze defects' ,`repair (complex)' ,`repair
(simple)' , and `test repair' . there are 12 resources in the log: solverc1,
solverc2, solverc3, solvers1, solvers2, solvers3, tester1, tester2,
..., tester6 . there are more than 1100 cases (mostly completed cases).
log enrichment with workload the log used in this validation round meets
the minimum log quality as stated earlier. thus, we can proceed to enrich the
log with workload information. this log was imported to a mysql database table
(called eventlog table) so that it could be manipulated using relational algebra
operators (see table 1 for a snippet of the table).
caseid activity eventtype timestamp resource
18 analyze defect start 1970-01-01 15:36:00 tester6
18 analyze defect complete 1970-01-01 15:44:00 tester6
15 repair (complex) start 1970-01-01 19:29:00 solverc3
.... ... ... ... ...
table 1: a snippet of the eventlog database table.
the workload derivation function (algorithm 1 from sect. 3) was imple-
mented in a java program (which interacted with the eventlog through sql
queries). this program outputs a table called workloadstarted which captures
the workload information of each resource (i.e. the realization of rwlrelation).
the average activity duration used is 450 seconds. the log used in our valida-
tion only contains the start andcomplete transition, thus, workloadstarted
only reects the work items that were still being executed by a particular re-
source at a point in time when an event was recorded in the log. a snippet
of the workloadstarted table is provided in table 2. the content of each eld
named after each resource identier (e.g. solverc1 andsolverc3 ) represents the
workload of the corresponding resource at its corresponding timestamp. for ex-
ample, using 1970-01-03 00:37:00 as a reference time, resource solverc1 had
no work items being executed (or assigned to) between the period of 1970-01-03
00:33:15 and 1970-01-03 00:40:45 , while resource solvers3 had two work
items that were either being executed or assigned (that is, the activity `repair
3http://www.processmining.org/_media/tutorial/repairexample.zip4 validation of approach 9
(simple)' for case number 70 and 34) over the same period. the workload-
enriched event log (i.e. la0
e) is obtained by joining table 2 and table 1 on
timestamp eld.
timestamp workload solverc 1 ...workload solverc 3 workload solvers 3 ...
1970-01-03 00:37:00 (empty) ...(empty) (70:repair (simple)), ...
(34:repair (simple)) ...
... ... ...... ... ...
1970-01-03 14:10:00 (36:repair (complex)) ...(60:repair (complex)) (empty) ...
... ... ...... ... ...
table 2: a snippet of the workloadstarted table (rwl)
aggregation to case log the workload-enriched event log obtained so far
contains the workload information of each resource at every timestamp in the log.
given that a case may consist of more than one event, we need to aggregate the
workload information among all relevant events (that make up one case) in the
log. we have implemented the necessary functions to obtain the # time start(c),
#time end(c), # resources (c), and # avgworkload (c) case attributes (dened in sect.
3). in our implementation, the average workload for each resource (quantied as
the number of work items) is stored in a separate eld, each named using the
following format: avgwl rx, whererxis a resource's identier (see table 3). the
results of the application of these aggregation functions were stored in another
table, called the caselog table (which is a manifestation of l
ac).
classication-ready case log finally, we transformed caselog into a form
that is ready for classication analysis. currently, caselog does not contain a
proper response variable: we know the start and end of each case; however, we
still need to further rene this information to obtain the duration of the case and
then to categorize each case to `on-time' or `overtime'. in other words, we need
to implement a function to obtain the # isovertime (c)attribute (dened in sect.
3). in our implementation, `on-time' cases were labeled with a `0'value, while
`overtime' cases were labelled with a `1'value. the threshold value which
determines if a case is overdue or not is set to 1 hour.4
we have also implemented a function to obtain the # isrxinvolved (c)value
(dened in sect. 3) to ensure that the information regarding the involvement
(or non-involvement) of each resource is presented as a distinct predictor vari-
able. forn-number of resources, this function creates nnew eld, named as
isinvolved rx(whererxis a resource's identier). each of these elds can now
be labelled individually as a distinct predictor variable.
we then extended the caselog table with the results of the application of
these two functions. a snippet of the nal classication-ready case log table is
shown in table 3. this table is a manifestation of l
a0
c
4this number is chosen based on the fact that most cases completed within 1 hour
(of course, the assumption here is that the majority of cases do not run overtime).10 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
caseid start end isoverdue avgwl solverc 1...avgwl tester 6isinvolved solverc 1...
1070 1970-01-23 20:58:00 ...1 1.36364 ...0 false ...
1075 1970-01-24 13:22:00 ...0 0.782609 ...1.6087 false ...
table 3: a snippet of a classier-ready case log (l
a0
c).
rca with classication techniques we fed the classication-ready case
log into weka [23]. weka supports classication algorithms, such as j.48 [13],
jrip [4], and many others. we started the analysis by just using the average
workload of all resources as predictor variables. an example of the results of the
decision tree learning analysis (using the j.48 algorithm [13] under 10-fold cross
validation mode [17, chapter 3]) is shown in fig. 2 (top part). for example, line
3 in fig. 2 shows that if the average workload of resource solvers1 is equal or
less than 0.117647 and the average workload for tester4 is equal to or less than
0.909091 (line 5), then the rules generated by the algorithm say that all 248
cases which fulll these criteria should be classied as `on-time' (represented as
`0'). while the records in the log show that this rule misclassied 42 cases, this
rule is correct in the majority of cases (202 cases out of 248).
however, the accuracy of the classication result is rather low. for example,
for `on-time' cases, the true positive (tp) rate (that is, the proportion of all
`on-time' cases which were correctly classied as `on-time') is 70% ; however,
the false positive (fp) rate (that is, the proportion of all `overtime' cases which
were incorrectly classied as `on-time') is as high as 51%. for `overtime' cases,
the tp rate (that is, the percentage of `overtime' cases which were correctly
classied as `overtime') is 48%, while the fp rate is as high as 29%. fig. 3
shows the full accuracy metrics. this analysis result suggests that the average
workload for a number of resources seem to have an inuence the occurrence of
long-running cases, however, the correlation seems rather weak.
beyond workload - adding another predictor variable we decided to include
another predictor variable in our analysis, namely the resource involvement infor-
mation (recall that this information was already calculated in our classication-
ready case log). the same j.48 algorithm was executed, except that this time,
we used both workload and resource involvement information as predictor vari-
ables. the result obtained was much more accurate: 92% tp rate/ 14% fp
rate (for `on-time' cases), and 85% tp rate/7% fp rate (for overtime cases).
both predictor variables were used in the generated classication tree; however,
the complexity of the generated classication tree is high - this may suggest an
overtting model (the decision tree is not shown in this paper).
we also applied a rule-based classication algorithm to the same data set,
namely, the jrip algorithm. the result obtained was much simpler than the one
obtained from j.48 algorithm (only 4 rules - see fig. 2 bottom part). for exam-
ple, the rule in line 28 states that all 201 cases in which solverc3 is involved
will run `overtime' (in reality, this rule only misclassied 6 cases). more inter-
estingly, however, is that the generated rules do not include resources' workload
as a factor in lovertime cases (although they were included in the analysis). the
accuracy of the result was also comparable: 92%/14% (tp/fp rate) for `on-4 validation of approach 11
1 j.48 classification tree - predictor variables: only average workload for all resources
2 =======================================================================================
3 avgwl_solvers1 <= 0.117647
4 | avgwl_tester4 <= 0.981818
5 | | avgwl_tester4 <= 0.909091: 0 (248.0/42.0)
6 | | avgwl_tester4 > 0.909091: 1 (67.0/24.0)
7 | avgwl_tester4 > 0.981818
8 | | avgwl_tester4 <= 1.05882: 0 (204.0/50.0)
9 | | avgwl_tester4 > 1.05882
10 | | | avgwl_tester1 <= 0.909091: 1 (6.0)
11 | | | avgwl_tester1 > 0.909091
12 | | | | avgwl_tester2 <= 0.914286: 1 (3.0)
13 | | | | avgwl_tester2 > 0.914286
14 | | | | | avgwl_tester3 <= 0.9: 0 (8.0)
15 | | | | | avgwl_tester3 > 0.9
16 | | | | | | avgwl_solverc1 <= 0.818182: 0 (3.0)
17 | | | | | | avgwl_solverc1 > 0.818182: 1 (4.0)
18 avgwl_solvers1 > 0.117647
19 | avgwl_tester4 <= 0.310345
20 | | avgwl_solvers2 <= 1.08333: 0 (174.0/65.0)
21 | | avgwl_solvers2 > 1.08333
22 | | | avgwl_tester2 <= 0.324324: 0 (2.0)
23 | | | avgwl_tester2 > 0.324324: 1 (9.0)
24 | avgwl_tester4 > 0.310345: 1 (376.0/155.0)
25
26 jrip algorithm - predictor variables: average workload and resources involvement
27 ==================================================================================
28 (isinvolved_solverc3 = 1) => isoverdue=1 (201.0/6.0)
29 (isinvolved_solvers1 = 1) => isoverdue=1 (206.0/41.0)
30 (isinvolved_solverc2 = 1) and (isinvolved_solverc1 = 1) => isoverdue=1 (22.0/3.0)
31 => isoverdue=0 (675.0/64.0)
fig. 2: j.48 classication tree - analysis results
1 full accuracy metrics
2 =====================
3 correctly classified instances 684 61.9565 %
4 incorrectly classified instances 420 38.0435 %
5 kappa statistic 0.1981
6 mean absolute error 0.4323
7 root mean squared error 0.4932
8 relative absolute error 89.9536 %
9 root relative squared error 100.6253 %
10 total number of instances 1104
11
12 === detailed accuracy by class ===
13
14 tp rate fp rate precision recall f-measure roc area class
15 0.708 0.512 0.673 0.708 0.69 0.633 0
16 0.488 0.292 0.528 0.488 0.507 0.633 1
17 weighted avg. 0.62 0.424 0.615 0.62 0.617 0.633
18
19 === confusion matrix ===
20
21 a b <-- classified as
22 468 193 | a = 0
23 227 216 | b = 1
24
fig. 3: full accuracy metrics for the j.48 classication tree (from fig. 2 - top
part)
time' cases, and85%/7% (tp/fp rate) for `overtime' cases. fig. 4 shows the
full accuracy metrics of the jrrip rules.12 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
1 full accuracy metrics
2 =====================
3 correctly classified instances 989 89.5833 %
4 incorrectly classified instances 115 10.4167 %
5 kappa statistic 0.782
6 mean absolute error 0.1806
7 root mean squared error 0.3027
8 relative absolute error 37.5884 %
9 root relative squared error 61.7519 %
10 total number of instances 1104
11
12 === detailed accuracy by class ===
13
14 tp rate fp rate precision recall f-measure roc area class
15 0.924 0.147 0.904 0.924 0.914 0.888 0
16 0.853 0.076 0.883 0.853 0.868 0.888 1
17 weighted avg. 0.896 0.118 0.896 0.896 0.896 0.888
18
19 === confusion matrix ===
20
21 a b <-- classified as
22 611 50 | a = 0
23 65 378 | b = 1
fig. 4: full accuracy metrics for the jrip rules (from fig. 2 - bottom part)
by comparing these results, we may say that both workload and resource
involvement may be the root causes of overtime cases in our log; however, the
nature of resource involvement alone may already be sucient to explain the
occurrence of `overtime' cases in most instances.
5 related work
traditional rca techniques have been frequently applied in the domain of busi-
ness and risk management (e.g. andersen and fagerhaug [1] and wilson et
al. [22]), as well as manufacturing industries (e.g. horev [8]). similarly, the use
of data mining techniques in business domain has also been heavily studied and
applied (e.g. cao et al. [5]). however, the use of data mining techniques to sys-
tematically perform an rca of business process-related issues is still a relatively
unexplored area in the eld of process mining (and business process management
in general), although a limited number of related studies have started to emerge.
for example, heravizadeh et al [7] proposed a technique to understand the root
cause of business processes based on business process models and augmented
it with concepts from requirement engineering - this is in contrast with our
approach which is based on post-execution data.
rozinat and van der aalst [16] proposed the use of classication technique
to nd the correlation between data attributes and the routing choices made
in business processes. this approach is dierent from ours in that our approach
focuses on the enrichment and transformation of event logs to classication-ready
log for the purpose of rca. of course, the classication-ready log can alwaysreferences 13
be used to nd the `root cause' of various routing decisions; however, it is not
limited to such cases only.
furthermore, in the work by nakatumba and van der aalst [12], a form of
rca which seeked to study the correlation between resources' workload and their
performance were performed using process mining techniques and data mining
technique (linear regression). similarly, in the work by rozinat et al. [15], the
results obtained from a process mining exercise were used to explain the root
cause of the occurence of idle times in a manufacturing test process. nevertheless,
the focus of both approaches was on the rca itself, instead of the approach taken
to facilitate such an analysis. the approach proposed in this paper attempts to
ll this gap.
6 conclusions
we have presented and formalized an approach to enrich and transform event
log into a form that allows an rca based on classication techniques. the ap-
plicability of our approach to facilitate rca of risk incidents has been validated
using both self-generated synthetic log and publicly available log. future work
include the validation of our approach using real-life log, as well as the packaging
of our approach as a plug-in to the process mining tool (prom). the application
of optimization techniques to select the best set of features as the root cause(s)
of a risk incident will also be considered.
references
1. bjorn andersen and tom fagerhaug. root cause analysis: simplied tools and
techniques . asq quality press, 2nd edition, 2006. isbn-12 978-0-87389-692-4.
2. french caldwell. ceo survey 2012: cios must link risk management and compli-
ance to business priorities. gartner , (g00226165), march 2012.
3. stephanie chen. pilot fatigue is like `having too much to drink'. cnn news , may
2009.
4. william w. cohen. fast eective rule induction. in proceedings of 12th interna-
tional conference on machine learning , pages 115{123. morgan kaufmann, 1995.
5. longbing cao et al., editor. data mining for business applications . springer,
2009.
6. christian w. g unther and wil m. p. van der aalst. a generic import framework for
process event logs. in bpm workshops on business process intelligence , volume
4103. lncs, 2006.
7. mitra heravizadeh et al. root cause analysis in business processes. technical
report, queensland university of technology, 2008.
8. menachem horev. root cause analysis in process-based industries . traord
publishing, 2008.
9. kurt jensen and lars m. kristensen. coloured petri nets - modelling and vali-
dation of concurrent systems . springer, 2009.
10. david maier. the theory of relational databases . computer science press, 1983.14 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
11. ana k.a. de medeiros and christian w. g unther. process mining: using cpn
tools to create test logs for mining algorithms. in 6th workshop and tutorial on
practical use of coloured petri nets and the cpn tools , pages 177{190, 2005.
12. joyce nakatumba and wil m. p. van der aalst. analyzing resource behavior using
process mining. in stefanie rinderle-ma et al., editor, bpm workshops , volume 43
oflnbip , pages 69{80. springer, 2009.
13. john r. quinlan. c4.5: programs for machine learning . morgan kaufmann pub-
lishers inc., san francisco, ca, usa, 1993.
14. anne ratzer et al. cpn tools for editing, simulating, and analysing coloured petri
nets. in icatpn 2003 , volume 2679 of lncs , pages 450{462. springer, 2003.
15. anne rozinat et al. process mining applied to the test process of wafer scan-
ners in asml. ieee transactions on systems, man, and cybernetics, part c:
applications and reviews , 39(4):474 {479, 2009.
16. anne rozinat and wil m. p. van der aalst. decision mining in prom. in business
process management , volume 4102 of lncs , pages 420{425. springer, 2006.
17. wil m. p. van der aalst. process mining - discovery, conformance and enhance-
ment of business processes . springer, 2011.
18. wil m. p. van der aalst et al. process mining manifesto. in florian daniel et al.,
editor, bpm workshops (1) , volume 99 of lnbip , pages 169{194. springer, 2011.
19. wil m.p. van der aalst and schahram dustdar. process mining put into context.
ieee internet computing , 16:82{86, 2012.
20. voluntary inter-industry commerce solutions association. voluntary inter-
industry commerce standard (vics). last accessed: 22 may 2012.
21. christopher d. wickens and justin g. hollands. engineering psychology and
human performance . prentice-hall inc., new jersey, 3rd edition, 2000.
22. paul f. wilson et al. root cause analysis: a tool for total quality management .
asq quality press, 1993.
23. ian h. witten et al. weka: practical machine learning tools and techniques with
java implementations, 1999.
a validation with synthetic log
we use the case study of a purchase order process based on the voluntary
inter-industry commerce solutions (vics) (voluntary inter-industry commerce
solutions) industry reference model [20]. the risk incident whose root cause(s)
are to be mined is the deadline expiry event (i.e. the response variable), using a
derivable predictor variable, namely the resources' workload information detailed
in section 3.
a synthetic log was generated from the corresponding model of the pur-
chase order process (modelled using the formal language of coloured petri
nets (cpn) [9] and aided by the cpn tools [14]). the mxml-log-generator
plug-in [11] was used to generate an mxml-formatted log le that we used to
evaluate our approach to root cause mining. the details of the approach valida-
tion are provided in the remainder of this section.
a.1 purchase order scenario - cpn model and mxml logs
figure 5 shows the cpn model from which the synthetic log (used for the val-
idation of our approach) was generated. this process consists of four manuala validation with synthetic log 15
activities: create purchase order ( create po ), approve purchase order ( approve
po), modify purchase order ( modify po ), and conrm purchase order ( confirm
po). this process also consists of two automated activities: order timeout ( order
timeout ) and process termination activity ( terminate order process (see fig-
ure 5). since they are automated, the model assumes that they are completed
as soon as they are assigned. when a transition representing a process activ-
ity (those transitions with thicker border in figure 5) is red, a corresponding
code-region code is executed to add relevant event log entry to the log le (for
example, see the code region for the transition terminate order process in
bottom-right of figure 5).
figure 6 shows the details of the manual activity model (the same model is
instantiated for all manual activities in the model). this model captures three
activity lifecycle events: the assignment/allocation of an activity to a resource,
thestart of the activity execution by the assigned resource, and the completion
of the activity by the resource. the model logs the occurrence of each of these
events in the code region (not shown in figure 6) of the corresponding activities
(`allocate task' ,`start task' ,`complete task' ) .
a resource can be allocated with an activity at any time, regardless of
whether the resource is `busy' or `free'. as the resource starts to execute an
activity, its status is set to `busy' and it cannot execute other assigned activ-
ities. upon the completion of the activity, the resource's status is set to `free'
again. the duration of the execution of each manual activity is set to follow
a normal distribution pattern. these rules are collectively expressed in the arc
inscriptions and transition guards shown in figure 6.
we congured our model to simulate the execution of 129 process instances.
at the end of the simulation, 129 log les were generated (one for each process
instance). we then used the prom import framework tool [6] to merge those
les into a single mxml le to be used for our subsequent analysis.
a.2 enriching event log with workload
we have implemented the log enrichment process using the synthetically-generated
log. firstly, we transformed the generated mxml le (from the cpn model)
into a form that is suitable for relational algebra transformation, such as sql
queries. to this end, a raw event log table (called eventlog table) was created
using the mysql database system and the mxml log le was then imported
into the table. a snippet of the mysql table is shown in table 4.
once the log data was in a proper form, we applied the worklist derivation
functions (dened in section 3). the generated workload table is shown in table
5.16 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
po
poid
initiatepo(id)
popo
pomodify
po
task lifecycle
confirm
po
task lifecycleapprove
po
task lifecycle
process
approval
status[(#approved(po))]create
po
task lifecyclegenerate
log file@+(realtoint(uniform(0.0,540.0)))
[not 
(#approved(
po))]
[istimedout(
 #timeout(po))]create 
po name1`"create po"
string
modify
po name1`"modify po"
string
confirm
po name1`"confirm po"
stringapprove
po name1`"approve po"
stringstart
log int
resource
approved
po
end
ordering
popurchase
order
approval
poapprove po
created
pocreate po task
created
po
task lifecycle
task lifecycle
task lifecycletask lifecycle
poterminate
order 
processorder
timeoutinput (po);
output ();
action
(addate((#orderid(po)), 
"terminate order process", 
["complete"], 
calculatetimestamp(), 
"automated", []));resourceinput (id);
output ();
action
(createcasefile(id));
1
1
1170
10
fig. 5: cpn model of a purchase order process
a.3 transforming enriched event log to classication-ready case
log
the aggregation functions to derive the start time of a case, the end time of a
case, the resources involved in a case, as well as the average workload of each
resource as dened in section 3 have also been implemented.
for a classication algorithm to work, the response variable must also be
properly expressed in a categorical format. therefore, we have also imple-
mented the getisoverdue function (dened in section 3). the thresholda validation with synthetic log 17
freeresource(resource,taskname,po)tasknameresourcesetbusyresource(
resource)tasknameallocateresource(taskname,
resource,po)
resourcetaskname
popopo
poposelectaction(po,taskname)resourceallocate
task[selectallocatetaskguard(
resource,taskname,po)]
complete 
task[needallocated(
resource,taskname,
po) andalso
(#isbusy(resource))]start
task@+setdelay(taskname,resource)[selectstarttaskguard(
resource,taskname,po)]
task
nameinstringtask
allocated
po
task
in progress
poresource
i/oresourcetask
createdinpo
task
completed
outpooutin
i/o in11`"create po"10
fig. 6: cpn model of purchase order manual activity lifecycle
value is set to 30 hours in this case study. similarly, the involvement or non-
involvment of each resource should be presented as a distinct predictor variable
in the classication-ready case log. therefore, we have also implemented the
getisresourceinvolved function dened in section 3. a snippet of the nal
classication-ready case log is provided in table 6
a.4 rca with classication techniques
theoretically, by following the event log transformation process described so far,
the data that reside in table 6 should now be usable for various decision tree18 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
caseid activity eventtype timestamp resource
1 create po assign 1970-01-01 18:14:00 8
1 create po start 1970-01-02 22:31:00 8
1 create po complete 1970-01-02 23:22:00 8
2 approve po assign 1970-01-02 23:22:00 3
1 approve po start 1970-01-02 23:22:00 3
4 approve po complete 1970-01-02 23:30:00 3
8 modify po assign 1970-01-02 23:40:00 10
... ... ... ... ...
table 4: a snippet of imported mxml log into the eventlog mysql database
timestamp r1 ...r2 r3 ...
1970-01-01 23:39:00 (103:conrm po),(3:modify po), ...(54:approve po) (104:create po) ...
(56:conrm po),(126:create po) ...
... ... ...... ... ...
table 5: a snippet of the workloadstarted table
caseid start end isoverdue isinvolved r1...avgwl r1avgwl r2...
95 1970-01-01 11:38:00 ...1 false ...1.66427 0.988299 ...
116 1970-01-01 12:38:00 ...1 false ...1.61429 0.957895 ...
table 6: a snippet of a classier-ready case log.
learning algorithms. as expected, the data imported data from the classication-
ready caselog table into the data mining tool (called weka [23]) tool can be
used to perform many classication analysis, including j.48, ladtree, simple-
cart, and many others.
a representative example of the results of the decision tree learning analysis
(using the j.48 decision tree learning algorithm [13] over 10-fold cross validation
mode) is shown in figure 7 (top part). in the beginning, we only used the aver-
age resource workload of each resource as the predictor variables. the accuracy
of the result obtained is quite high: 86% true positive (tp) rate for `on-time'
cases (that is, the proportion of all `on-time' cases that were correctly classied
as `on-time'), and 13% false positive rate for the `on-time' class (that is, the
proportion of all `overtime' cases which were incorrectly classied as `on-time').
table 8 shows the full accuracy measures of the generated j.48 classication tree.
this result may suggest that there were some signicant correlation between av-
erage workload of resources and the occurence of `overtime'/long-running cases.
next, we included the information regarding the involvement (or non-involvement)
of every resource in the analysis. nevertheless, the result obtained (through the
application of the same j.48 algorithm) is similar to the previous one (see figure
7 - bottom part). most importantly, the accuracy of the result is only slightly
better.
finally, we excluded the average workload information to see if the infor-
mation regarding the involvement/non-involvement of resources is enough to
explain long running cases. using the same algorithm, the result obtained wasa validation with synthetic log 19
j.48 classification tree - cpn log - only average workload - 10 fold cross validation
=====================================================================================
avgwl_r8 <= 2.78346
| avgwl_r6 <= 0.989781
| | avgwl_r10 <= 0.978002: 1 (3.0)
| | avgwl_r10 > 0.978002
| | | avgwl_r1 <= 1.44237: 0 (12.0)
| | | avgwl_r1 > 1.44237
| | | | avgwl_r1 <= 1.49053: 1 (3.0)
| | | | avgwl_r1 > 1.49053
| | | | | avgwl_r10 <= 0.997361: 1 (4.0/1.0)
| | | | | avgwl_r10 > 0.997361: 0 (16.0/2.0)
| avgwl_r6 > 0.989781: 1 (47.0/6.0)
avgwl_r8 > 2.78346: 0 (44.0)
j.48 classification tree - cpn log - average workload + resource involvement
10-fold cross validation
============================================================================
avgwl_r8 <= 2.78346
| avgwl_r6 <= 0.989781
| | resource7 = 0
| | | avgwl_r8 <= 1.90742: 1 (3.0/1.0)
| | | avgwl_r8 > 1.90742: 0 (17.0)
| | resource7 = 1
| | | resource6 = 0
| | | | resource8 = 1: 1 (4.0)
| | | | resource8 = 0
| | | | | resource2 = 0
| | | | | | avgwl_r1 <= 1.59603: 0 (6.0/1.0)
| | | | | | avgwl_r1 > 1.59603: 1 (2.0)
| | | | | resource2 = 1: 1 (2.0)
| | | resource6 = 1: 0 (4.0)
| avgwl_r6 > 0.989781
| | avgwl_r3 <= 1.64218: 1 (45.0/4.0)
| | avgwl_r3 > 1.64218: 0 (2.0)
avgwl_r8 > 2.78346: 0 (44.0)
fig. 7: j.48 classication tree - analysis results
much poorer:68% tp rate (on average), with false positive rate going up to
37% (on average). figure 9 shows the generated classication tree and the full
accuracy metrics.
based on these analysis results, we may say that workload is the main root
cause for explaining long running cases.
by showing the details of our validation process, we have thus demonstrated
theapplicability of our approach in transforming a process mining problem into
a problem that can be solved using a relatively rich and matured classication
techniques from the eld of data mining.20 s. suriadi, c. ouyang, w.m.p. van der aalst, and a.h.m. ter hofstede
accuracy measures
=================
correctly classified instances 112 86.8217 %
incorrectly classified instances 17 13.1783 %
kappa statistic 0.7287
mean absolute error 0.1901
root mean squared error 0.3566
relative absolute error 39.4584 %
root relative squared error 72.6615 %
total number of instances 129
=== detailed accuracy by class ===
tp rate fp rate precision recall f-measure roc area class
0.865 0.13 0.818 0.865 0.841 0.851 1
0.87 0.135 0.905 0.87 0.887 0.851 0
weighted avg. 0.868 0.133 0.87 0.868 0.869 0.851
=== confusion matrix ===
a b <-- classified as
45 7 | a = 1
10 67 | b = 0
fig. 8: accuracy measures for the j.48 classication tree (shown in figure 7)a validation with synthetic log 21
j48 pruned tree - resource involvement only
===========================================
r7 = 0: 0 (62.0/17.0)
r7 = 1
| r2 = 0
| | r10 = 1: 0 (17.0/4.0)
| | r10 = 0
| | | r3 = 1
| | | | r4 = 1
| | | | | r6 = 0: 1 (5.0/1.0)
| | | | | r6 = 1: 0 (2.0)
| | | | r4 = 0: 0 (5.0)
| | | r3 = 0: 1 (20.0/6.0)
| r2 = 1: 1 (18.0/5.0)
number of leaves : 7
size of the tree : 13
accuracy metrics
================
correctly classified instances 88 68.2171 %
incorrectly classified instances 41 31.7829 %
kappa statistic 0.3204
mean absolute error 0.4045
root mean squared error 0.4821
relative absolute error 83.9634 %
root relative squared error 98.2446 %
total number of instances 129
=== detailed accuracy by class ===
tp rate fp rate precision recall f-measure roc area class
0.519 0.208 0.628 0.519 0.568 0.625 1
0.792 0.481 0.709 0.792 0.748 0.625 0
weighted avg. 0.682 0.371 0.676 0.682 0.676 0.625
=== confusion matrix ===
a b <-- classified as
27 25 | a = 1
16 61 | b = 0
fig. 9: generated j.48 classication tree and the accuracy metrics - resources
involvement as predictor variable