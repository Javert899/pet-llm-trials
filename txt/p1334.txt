high-level event mining: a framework
bianka bakullari, wil m.p. van der aalst
chair of process and data science (pads)
department of computer science, rwth aachen university
{bianka.bakullari, wvdaalst }@pads.rwth-aachen.de
abstract —process mining methods often analyze processes in
terms of the individual end-to-end process runs. process behavior,
however, may materialize as a general state of many involved
process components, which can not be captured by looking at the
individual process instances. a more holistic state of the process
can be determined by looking at the events that occur close
in time and share common process capacities. in this work, we
conceptualize such behavior using high-level events and propose a
new framework for detecting and logging such high-level events.
the output of our method is a new high-level event log, which
collects all generated high-level events together with the newly
assigned event attributes: activity, case, and timestamp. existing
process mining techniques can then be applied on the produced
high-level event log to obtain further insights. experiments on
both simulated and real-life event data show that our method
is able to automatically discover how system-level patterns such
as high traffic and workload emerge, propagate and dissolve
throughout the process.
index terms —high-level events, high-level event log, process
performance, workload
i. i ntroduction
a. motivation
process mining techniques aim at getting insight into pro-
cesses and improving them by using real event data that
are extracted from information systems. event data contain
events that occurred during process executions. such process
executions involve various tasks, resources, facilities, costs,
etc. each event may concern a particular set of these process
aspects. this information is usually provided in the event
attributes . in particular, the activity attribute indicates the
process task that was executed during the occurrence of
the corresponding event. each event belongs to a unique
instantiation of the process, which is indicated in the case
attribute of the event. most process mining methods analyze
the process in terms of its process instances, and claims
about the process as a whole are often obtained as an ag-
gregation of what was observed at the level of the individual
cases. e.g., process performance is assessed by aggregating
the duration of individual process instances, and bottlenecks
are identified by looking at the average time spent between
activities. process behavior, however, is not necessarily a
property of the individual cases as these are not isolated from
each other. their corresponding events may demand common
process capacities simultaneously. for this reason, a more
complete view on the process is necessary. in this work, we
we thank the alexander von humboldt (avh) stiftung for supporting our
research.attempt to analyze processes using a more holistic and system-
aware view. instead of focusing on the behavior of end-to-
end process runs, we provide insights over the emergence,
propagation and dissolution of states that concern the system
as a whole. the state of the system is determined by the events
that take place close in time.
figure 1: a visualization of the approach: on top, the input event
data showing the runs of three process instances (blue, red and green).
the time scope is split into time windows (step 1), and the events
within the same time window may produce certain process patterns.
these patterns are captured as high-level events (step 2) which are
then collected into a high-level event log (step 3).
fig. 1 provides an overview of our approach. the input
event log contains 12 events belonging to three different cases
(depicted in blue, red and green). the time scope of the
process is split into time windows (step 1). the events that
occur within the same window may cause emergent process
behavior. e.g., in the second window, the resource depicted
in gray is overloaded with work and there are many cases
that recently finished activity band are waiting for activity d
to happen. we explicitly capture such behavior in the form
ofhigh-level events (step 2), which similarly to “normal”
events, describe what happened and when it happened in the
process. the generated high-level events are collected into
the so-called high-level event log (step 3) where a new case
perspective is introduced (the output log in fig. 1 contains two
cases depicted in red and blue). the event log format enablesapplying existing process mining techniques to gain insights
over the captured high-level process behavior.
b. example
consider the following scenario: the service desk of a
traveling agency handles questions and requests by their cus-
tomers. for each request, a report is filed and an answer is sent
to the customer. if the answer is delayed, customers may send
a follow-up question asking about the status of their request.
these questions require the same attention that new requests
do and they cause additional traffic in the overall process.
when many such questions are received, the added workload
delays the responses even further, leading to even more follow-
up questions. jane is one of the resources who answers
customers’ requests. whenever she sees requests piling up,
she prefers to first finish all the paperwork by filing the reports
and only answers the customers afterwards. while waiting for
a reply, these customers tend to become impatient and send
a follow-up question. the agency is interested in discovering
whether there are certain patterns in the process executions
that often correlate with high numbers of follow-up questions.
a helpful insight to the agency would be to see how jane’s
workload, her workflow, and the number of follow-up requests
are related to each-other (fig. 2).
figure 2: a directed graph visualizing the process patterns behind
the undesired behavior explained in the example: when jane has
high workload (violet resource icon), she tends to execute many
“report” tasks (indicated by the ticks beside activity “report”).
thus, multiple requests accumulate in-between tasks “report” and
“answer” (depicted with the blue arrows). this causes high waiting
times in this segment (red timer icon), which triggers more “follow-
up” activities (indicated by the ticks beside activity “follow-up”).
the introduced example points out that process behavior
can have the following properties: 1) it may concern different
parts of the process (activities, resources, states between two
activities) which are not properties of the cases themselves, 2)
it is not necessarily persistent; it can emerge and dissolve at
different time periods, and 3) it is not isolated; it may be both
the consequence and cause of other process behavior.
c. approach
in our work, we assume we are provided with an event
log, which is a collection of recorded events and their at-
tributes. we address each of the aforementioned points in a
dedicated step: first, we define new features which capture
both the kind of detected behavior and the activity, resource,
or process location it affects. we also refer to the latter as the
underlying component of the feature. second, we determine
non-overlapping time-windows and partition the events into
the time windows within which they occurred. every feature ofinterest is then evaluated over each time-window. each outlier
measurement generates a dedicated high-level event . third,
any pair of components underlying the features is assigned a
proximity value that reflects how “close” those components are
in terms of process executions. e.g., a pair of activities that are
always executed subsequently are close, whereas any resource
is distant from the activities it never executes. a high-level
event propagates to another high-level event in the subsequent
time window whenever their underlying components are close
enough. any maximal sequence of high-level events connected
to each other through propagation forms a cascade . 4) we log
all high-level events and generate a new event log, which we
call a high-level event log . for any high-level event, the activity
attribute reflects the feature for which the outlier value was
measured, the timestamp corresponds to the time window in
which the high-level event emerged, whereas the case attribute
coincides with the cascade the high-level event belongs to.
the configurable parts of the framework include the choice
of the features and the thresholds which determine the emer-
gence and correlation of the high-level events.
ii. r elated work
performance analysis techniques typically concern the time
perspective, aiming to obtain insights regarding duration, bot-
tlenecks, and delays [1]. an initial approach demonstrating
how time information is aggregated from all end-to-end pro-
cess runs is shown in [2]. when a new case is still running,
a prediction for the remaining time is estimated from the
remaining times of past cases similar to the current one, and
any interplay between different cases is not considered. more
refined methods compute delays and waiting times separately
for cases that occur within different contexts [3]. these
approaches, however, view the effect of any particular context
on performance as a static property of the process which is sat-
isfied by all or most cases happening within that context. using
theperformance spectrum [4], one can detect arising system-
level behavior such as high loads, delays or batching [5] using
visual analysis. this technique can visualize the load and
waiting times only for the cases that run through a particular
pair of activities, while dependencies between the performance
patterns concerning different activity pairs may not be visible.
in [6], the authors assume each case in the process goes
through a sequence of stages, and they visualize how queues,
incoming- and outgoing rates in each stage develop over time.
in contrast, we do not make any assumption about the control-
flow of the process, and any outlier measurement regarding
performance is conceptualized and logged as an event of its
own. the authors in [7] were the first to propose a method that
explicitly captures undesired system-level behavior such as
blockages and delays in the form of system-level events. each
system-level event is characterized by the process location
and the outlier behavior (high load or long waiting time)
measured in that location during a particular time window.
events that are immediately close both in time and location are
connected into sequences called cascades . the most frequent
cascades reveal how undesired system-level behavior arisesand propagates throughout the process. we take this approach
further by introducing a framework within which these system-
level events are naturally incorporated and extended. they
are conceptualized as a specific type of high-level events that
concern congestion features. in addition, we capture resource
behavior in terms of workload and task execution, and also
define a new proximity function which exploits the control-
flow of the process to determine “how” close the underlying
process components are. this proximity value is then used to
decide whether two high-level events should be connected into
a cascade. similar work extending the idea from [7] was done
in [8] where dbscan is used to find frequent sequences of
anomalies arising as system-level behavior. in our approach,
we instead collect the generated high-level events and log
them into a new event log, where the cascade membership
is incorporated in the case identifier. this way, one can
exploit the rich body of existing process mining techniques to
analyze the higher-level behavior. the authors in [9] recognize
queueing as a consequence of inter-case dependencies that
may lead to delays in the process. they predict these delays
for running cases using techniques referred to as queue mining .
in our work, large accumulations of process instances waiting
to be served are captured using dedicated types of high-level
events, and our focus is not on predicting the remaining time
for a specific case, but rather discovering the development and
dependencies among the high-level events themselves. the
work by van zelst et al. in [10] provides a good overview
over event abstraction techniques in process mining. these
techniques mainly aim to alter the granularity level of the
provided event data by bringing it closer to the level of detail
that enables correct and understandable process insights. the
authors in [11] proposed an approach for defining aggregated
process variables and calculating them over time steps. the
calculated measurable aspects of processes, also known as
coarse-grained process logs, present event logs at a higher level
of granularity than event logs. these process logs are used
for higher-level simulation and prediction of process states.
our generated high-level events are not coarser representations
of the input event data, but rather events describing new
emergent behavior caused by the combination of “low-level
events”—none of which displays the behavior individually.
concept drift detection techniques [12] aim at identifying pro-
cess changes that happen while the process is being analyzed.
in our framework, significant process changes may become
apparent as they cause the type of generated high-level events
to also vary over time.
iii. p reliminaries
in the remainder, for any set x, setp(x)denotes the power
set of x,b(x)denotes the set of all multisets over set x,
andx∗denotes all sequences over set x.
definition 1 (events, event attributes) .uevis the universe of
events, uactis the universe of activities, ucase is the universe
of cases, utime is the universe of timestamps, and uresis
the universe of resources. uvalis the universe of values, andumap=uatt̸→ u valis the universe of event attribute-value
mappings. we assume that {act,case,time,res} ⊆ u attand
uact,ucase,utime,ures⊆ uval.
definition 2 (event log) .anevent log is a tuple l= (e, π)
where e⊆ uevis the set of events and π∈e→ u map such
that for any e∈e:{act,case,time,res} ⊆dom(π(e))and
π(e)(case)∈ ucase is the case of e,π(e)(act)∈ uactis the
activity of e,π(e)(time)∈ utime is the timestamp of e, and
π(e)(res)∈ uresis the resource of e.
for any x∈ u attand any event e∈eof a given log
l= (e, π), we write πx(e)instead of π(e)(x).
definition 3 (steps) .given an event log l= (e, π),
the set steps (l) ={(e1, e2)∈e×e|πcase(e1) =
πcase(e2)∧πtime(e1)< πtime(e2)∧ ∀e∈e\{e1,e2}πcase(e) =
πcase(e1)⇒πtime(e)≤πtime(e1)∨πtime(e)≥πtime(e2)}
contains the steps of event log l. moreover, for any (e1, e2)∈
steps (l), we say that event e1triggers e2. conversely, e2is
triggered by e1.
two events of a given log constitute a step if they belong
to the same case and no other event of that case occurred in-
between. these pairs are equivalent to the so-called “directly-
follows” event pairs of a log.
definition 4 (framing) .aframing is a non-decreasing func-
tionϕ∈ utime→n. for any w∈rng(ϕ),⌊w⌋=min{t∈
utime|ϕ(t) =w}and⌈w⌉=max{t∈ u time|ϕ(t) =
w}denote the minimal and maximal timestamps assigned
tow. given an event log land a framing ϕ, the set
wl,ϕ={w∈n|min{ϕ(πtime(e))|e∈e} ≤ w≤
max{ϕ(πtime(e))|e∈e}}is called the window set of event
loglw.r.t. ϕ. each w∈wl,ϕis called a window and
for any e∈e, we say eoccurred during wwhenever
⌊w⌋ ≤πtime(e)<⌈w⌉.
iv. m ethod
a. defining high-level events
the choice of the high-level features determines the type
of the high-level events that can emerge in the process.
each feature is evaluated at every time window, and outlier
measurements are captured in the form of high-level events.
definition 5 (feature evaluation) .uhlfis the universe of high-
level feature names. given an event log land framing ϕ,
thefeature evaluation oflat any window w∈wl,ϕis a
partial function eval(l, w)∈ u hlf̸→rwhich maps high-
level features to real numbers.
for any hlf∈ uhlf, for simplicity we write eval hlf(l, w)
instead of eval(l, w)(hlf).
definition 6 (high-level events) .letlbe an event log and
ϕa framing. let hlf⊆ u hlfbe a set of high-level features
andthresh ∈hlf→ra function mapping each feature
onto a corresponding threshold. the set hl,ϕ,hlf,thresh =
{(hlf, w)∈hlf×wl,ϕ|eval hlf(l, w)≥thresh (hlf)}
contains all high-level events obtained from log l, framingϕ, and feature set hlf with threshold function thresh . i.e.,
a feature-window pair (hlf, w)generates a high-level event
whenever the value assigned to hlfat window wis higher
than or equal to the corresponding threshold.
as congestion is a universal property of processes that
emerges on a system-level, we instantiate our framework by
defining high-level features that are related to congestion. in
the following, we explain the motivation behind the choice of
those high-level features.
for each case in a process, there is a sequence of events
describing its process run. consider the process visualized
in fig. 3. suppose that the event sequence ⟨ea, eb, ec, ed⟩
executing activities ⟨a, b, c, d ⟩was recorded during the run of
some case in this process. at any moment between the first and
last event of the sequence, we can determine the last previous
event and the first next event of the case. assume that at a
given time, ebwas the last recorded event. thus, the next event
to occur is ec. in terms of congestion, the case is “located”
between activities bandc. at any timestamp tbetween
πtime(eb)andπtime(ec), this case influences congestion at
segment (b, c)by increasing the load by one and the current
waiting time by t−πtime(eb). in the mean time, this indicates
a new task piling up for the resource that will execute the next
activity (here c). whenever a resource executes an activity, the
load in the process is shifted from the previous segment to the
next segment. in this example, as soon as coccurs, the case
moves on to occupy the next segment (which for this case is
(c, d)). this continues until the case is complete.
figure 3: some process visualized as a road map with activities
depicted as landmarks. each activity has a corresponding responsible
resource. there are two possible runs through this process: one ex-
ecuting activities ⟨a, b, c, d ⟩, and one executing activities ⟨a, b, c, e ⟩.
the path of some running case is ⟨a, b, c, d ⟩(the black dashed line).
currently, this case occupies segment (b, c)(the red pin).
at any time interval throughout the process, each activity
may be executed multiple times in the context of several
different cases. moreover, each resource has a specific set
of new tasks piling up and/or being executed within that
time interval. how long each case has to wait for the next
activity to occur likely depends on the current workload of the
responsible resource. the process run of any case is both in-
fluencing and influenced by the other process instances which
have overlapping life cycles and share common resources or
paths through the process. we refer to activities, resources,
and process segments as the congestion components of any
process.
definition 7 (activities, resources, segments) .given anevent log l= (e, π),a(l) :={πact(e)|e∈e}is the
activity set ofl,r(l) :={πres(e)|e∈e}is the resource
setofl, and s(l) :={(πact(e1), πact(e2))|(e1, e2)∈
steps (l)}is the segment set ofl. the segment set of an
event log consists of all activity pairs that correspond to a
step in the log. additionally, for any a∈a(l), we define
e↾a:={e∈e|πact(e) =a}as the a-events ofl, for
anyr∈r(l), we define e↾r:={e∈e|πres(e) =r}
as the r-events ofl, and for any s= (a1, a2)∈s(l),
we define steps (l)↾s:={(e, e′)∈steps (l)|πact(e) =
a1∧πact(e′) =a2}as the s-steps ofl.
next, we define some high-level features which relate to
congestion patterns on the activity-, resource-, and segment-
level. for each of those features, we describe how the value
eval of that feature is computed given an event log and a time
window.
suppose we are given an event log land window set
wl,ϕw.r.t. some framing ϕ. for any a∈a(l), feature
exec-a∈ uhlfstands for the number of executed a-events, and
for any w∈wl,ϕ:eval exec -a(l, w) =|{e∈e↾a| ⌊w⌋ ≤
πtime(e)<⌈w⌉}|. similarly, for any r∈r(l), the feature
do-r∈ uhlfstands for the number of r-events, and for any
w∈wl,ϕ:eval do-r(l, w) =|{e∈e↾r| ⌊w⌋ ≤πtime(e)<
⌈w⌉}|. for any step (e, e′)∈steps (l), the execution of e
triggers a new task (namely πact(e′)) for resource πres(e′). for
anyr∈r(l), we capture such new workload using feature
todo -r. for any w∈wl,ϕ,eval todo -r(l, w) =|{e′∈e↾r|
∃e∈e(e, e′)∈steps (l)∧ ⌊w⌋ ≤ πtime(e)<⌈w⌉}|is
the number of r-events that are triggered during w. the total
workload of any resource r∈r(l)during some window is
the sum of all r-events that either occur or are waiting to
be handled by rat that time window. we capture the total
workload of any r∈r(l)using feature wl-r, where for any
w∈wl,ϕ:eval wl-r(l, w) =|{e′∈e↾r| ⌊w⌋ ≤πtime(e′)<
⌈w⌉ ∨ ∃ e∈e(e, e′)∈steps (l)∧πtime(e)<⌈w⌉ ∧
πtime(e′)>⌊w⌋}|. the congestion in a particular segment of
the log can be captured by e.g., looking at the number of steps
that enter, exit or cross the segment during a particular window.
for any segment s= (a1, a2)∈s(l), let arrive (s, w) =
{(e, e′)∈steps (l)↾s| ⌊w⌋ ≤πtime(e)<⌈w⌉}be the set
of steps that arrive at sduring w, letleave(s, w) ={(e, e′)∈
steps (l)↾s| ⌊w⌋ ≤πtime(e′)<⌈w⌉}be the set of steps that
leave sduring w, and cross (s, w) ={(e, e′)∈steps (l)↾s|
πtime(e)<⌈w⌉ ∧ πtime(e′)≥ ⌊w⌋}the set of steps that
cross sduring w. note that arrive (s, w)andleave(s, w)are
subsets of cross (s, w). for any s∈s(l), the number of steps
entering, exiting or being in progress at sat any window
w∈wl,ϕis indicated by the values eval(l, w)assigns to
features enter -s,exit-sandprogr -srespectively. here, we
have eval enter -s(l, w) =|arrive (s, w)|,eval exit -s(l, w) =
|leave(s, w)|, and eval progr -s(l, w) =|cross (s, w)|. lastly,
we introduce feature delay -sfor any s∈s(l)which stands
for the delay at segment s. its value is computed as the
average waiting time that has accumulated from all the steps
in progress at sduring a given time window. more precisely,for any w∈wl,ϕ:eval delay -s(l, w) =1
eval progr -s(l,w )·p
(e,e′)∈leave (s,w)πtime(e′)−πtime(e) +
p
(e,e′)∈cross (s,w)\leave (s,tw)⌈w⌉ −πtime(e)
.
each of these congestion features describes congestion in
terms of a particular view (e.g., number of executions, work-
load, delay) on a particular component (activities, resources,
segments). to determine the threshold of any of these features,
we can consider the multiset of values that eval assigns to all
features of the same view across all windows. using some
p∈[0,1], the value of thresh can be the smallest value
of this multiset that is equal or greater than the p∗100-th
percentile. for example, given event log land framing ϕ,
the delay at some segment s∈s(l)at window w∈wl,ϕ
generates a high-level event if it is high enough compared
to all delays measured over all segments across the windows
wl,ϕ. ifp= 0.9, then only the 10% highest measured delays
will generate high-level events, whereas if p= 0.7, the 30%
highest measured delays will generate high-level events.
b. correlating high-level events
definition 8 (proximity, propagation) .lethl,ϕ,hlf,thresh be
the set of high-level events obtained from event log l, framing
ϕ, and feature set hlf with threshold function thresh .
for any two high-level events hle1,hle2∈ h l,ϕ,hlf,thresh ,
▷ ◁l(hle1,hle2)∈[0,1]yields the proximity between hle1
andhle2with 0 being the farthest and 1 being the closest.
moreover, for some λ∈[0,1], there is a propagation from
hle1tohle2w.r.t. λ(denoted hle1⇝λhle2) if and only if
▷ ◁l(hle1,hle2)≥λ. i.e., one high-level event propagates to
another if and only if they are closer to each other than some
threshold λ.
the proximity values describe how close any pair of high-
level events are. the higher the proximity value, the higher the
chance that the pair of high-level events will be considered as
correlated. when two high-level events are close enough w.r.t.
some threshold, we say that the earlier event propagated to
the later one. note that by the definition of the high-level
events, how “proximity” between any two high-level events is
measured can depend both on the underlying features, as well
as on the time windows that generated them.
definition 9 (cascade) .lethl,ϕ,hlf,thresh be the set of
high-level events generated from event log l, framing ϕ, and
feature set hlf with threshold function thresh . given some
λ∈[0,1], any function casc λ∈ h l,ϕ,hlf,thresh→nis
called a cascade identifier function if and only if for any two
high-level events hle,hle′∈ h l,ϕ,hlf,thresh , the following
holds:
casc λ(hle) =casc λ(hle′)⇔hle⇝λhle′∨
∃hle1,...,hlen∈hl,ϕ, hlf,threshhle⇝λhle1∧hlen⇝λhle′∧
∀1≤i<nhlei⇝λhlei+1.
that is, a cascade identifier assigns two high-level events the
same number if and only if there is either a direct or indirect
propagation from one high-level event to the other.in the following, we propose a way for computing proximity
values between all high-level event pairs whose underlying
features correspond to those introduced in the last subsec-
tion (iv-a). when correlating high-level events that emerge
from the congestion-related features introduced previously, we
abstract from the view of the feature (e.g., delay, workload,
etc.) and only evaluate proximity based on the underlying
component (activity, resource or segment). on one hand, this
way we naturally incorporate the knowledge about the control-
flow and work distribution that is present in the log. on
the other hand, we avoid making assumptions on how the
features correlate to each other, as this is in fact part of
the high-level process behavior that we wish to discover.
moreover, for simplicity, we assume propagation only occurs
between subsequent time windows and thus, assign positive
proximity values only to high-level events of adjacent time
windows. this way, any two high-level events from non-
adjacent windows can only be correlated indirectly through
a chain of propagation. the high-level events we generate all
have a process component they relate to: an activity, a resource
or a segment. in terms of congestion, all these components are
related—resources execute the activities, the execution of an
activity “moves” the corresponding case from one segment
to another, and new work piles up for the resource that
must handle the next activity. traffic that arises at some time
window may persist across multiple time windows that follow,
and moreover, it can trigger more traffic in its “neighborhood”.
for any pair of components, we determine a link value
which reveals how closely connected these components are
based on the provided event data. the proximity value of
any pair of congestion-related high-level events that emerge in
adjacent time windows is then equal to the link value of their
underlying components. we reuse the road map metaphor from
fig. 3 to motivate how we determine the link values. each
activity requires a responsible resource and its execution either
increases or decreases the load from its adjacent segments (e.g.
executions of bfrom fig. 3 affect the orange resource and
segments (a, b)and(b, c)). resources immediately affect the
load shifts between the segments whose underlying activities
they are responsible for executing (e.g. when the orange
resource from fig. 3 executes c, it removes load from (b, c)
and shifts it towards (c, d)or(c, e), depending on the path
of the current case). resources also influence each other’s
workload if they execute neighboring activities (e.g. whenever
the orange resource from fig. 3 executes c, a new task piles up
for the green resource who is responsible for activities dand
e). the link values reflect how connected component pairs are
by exploiting the frequency of these dependencies.
next, we show how one can compute the link values
and thus, the proximity values for high-level event
pairs. let l= (e, π)be an event log. for any two
components x1, x2∈a(l)∪r(l)∪s(l)with x1̸=x2,
linkl({x1, x2})∈[0,1]shows how connected x1and
x2are in the process with 0 being the farthest and 1
being the closest. if x1, x2∈a(l)orx1, x2∈r(l),
then linkl({x1, x2}) = max{|steps (l)↾(x1,x2)|/|e↾x1|,|steps (l)↾(x2,x1)|/|e↾x2|}, where steps (l)↾(r1,r2) =
{(e, e′)∈steps (l)|πres(e) =r1∧πres(e′) =r2}for
any resource pair r1, r2∈r(l). i.e., activity pairs and
resource pairs are closer the more often they correspond to
events that directly follow each-other. for any a∈a(l)and
r∈r(l),linkl({a, r}) = max{|e↾a∩e↾r|/|e↾a|,
|e↾a∩e↾r|/|e↾r|}. i.e., a resource-activity pair is
closer the more often it is that resource executing
the activity, or it is that activity being executed when
the resource is working. for any a∈a(l)and
s= (a1, a2)∈s(l), ifa∈ {a1, a2}then linkl({a, s}) =
max{|steps (l)↾(a1,a2)|,|steps (l)↾(a2,a1)|}/|e↾a|. else,
linkl({a, s}) = 0 . in other words, each activity can
only be close to its adjacent segments. the linkl
value of any activity-segment pair reflects how often
the occurrence of the activity indicates a case that is
entering or exiting the segment. for any r∈r(l)and
s= (a1, a2)∈s(l), let steps (l)↾s,r:={(e, e′)∈
steps (l)↾s|e∈e↾r∨e′∈e↾r}. then, linkl({r, s}) =
max{|steps (l)↾s,r|/|e↾r|,|steps (l)↾s,r|/|steps (l)↾s|}.
i.e., a resource-segment pair is closer the more
often the resource executes one of the activities
of the segment. lastly, for any a1, a2, a3∈a(l)
such that s= (a1, a2), s′= (a2, a3)∈s(l), let
steps (l)↾(a1,a2,a3):={(e1, e2, e3)∈e×e×e|
(e1, e2)∈steps (l)↾s∧(e2, e3)∈steps (l)↾s′}. then,
linkl({s, s′}) = max{|steps (l)↾(a1,a2,a3)|/|steps (l)↾s,
|steps (l)↾(a1,a2,a3)|/|steps (l)↾s′|}. otherwise, for
anys= (a1, a2), s′= (a′
1, a′
2)∈s(l)such that
{a1, a2} ∩ { a′
1, a′
2}=∅,linkl({s, s′}) = 0 . i.e., only
segments that share a common activity can be close. the
linklvalue of any such pair of segments reflects the fraction
of cases which cross both segments from those that cross at
least one of the segments.
c. generating a high-level event log
definition 10 (high-level event log) .lethl,ϕ,hlf,thresh be
the set of high-level events generated from log l, framing
ϕ, and feature set hlf with threshold function thresh . for
some λ∈[0,1], the high-level event log corresponding
tohl,ϕ,hlf,thresh is a new event log l′= (e′, π′)such
thate′={ehlf,w|(hlf, w)∈ h l,ϕ,hlf,thresh}and
{act,case,time} ⊆ dom(π′(e))for all e∈e′. for any
ehlf,w∈e′:πact(ehlf,w) =hlf,πtime(ehlf,w) =⌊w⌋, and
πcase(ehlf,w) =casc λ((hlf, w)).
there is a one-to-one correspondence between the high-
level events and the events in the generated high-level event
log. the activity attribute (which we refer to as the high-level
activity ) describes the high-level feature, the timestamp indi-
cates the time window in which the high-level event emerged,
whereas the case identifier is determined by the cascade it
belongs to. note that high-level events that emerge within the
same time window are assigned the same timestamp. thus,
events of the same case in the high-level event log may be
partially ordered.v. e valuation
the method is available as a python implementation1. it
can automatically generate a high-level event log from any
given event log. the user can determine the set of features
and components they wish to focus on, and select the feature
thresholds and λ. in our evaluation, we use cortado [13] to
visualize the most frequent variants in the high-level event log,
as this tool can handle partially ordered event data. by using
a fixed total order between all generated high-level activities,
all partially-ordered cascades can be flattened into sequences
of totally ordered high-level events. we use the flattened log
to obtain a directly-follows graph (dfg) that displays the
typical high-level activity sequences in the newly created event
log.
a. simulated log
we evaluate our method on a simulated log that displays
the behavior of the process we described in the example in
section i. the log was simulated using cpn tools [14] and
is available on github. each case in the event log represents
a customer request. for each request there is a report that has
to be filed (activity report ) and the customer must receive a
reply (activity answer ). if the reply takes too long, customers
may send a follow-up question (activity follow ). jane is one
of the resources who answers customers’ requests. when jane
has a high workload, she first files all the reports of the
queueing requests and only answers the customers afterwards.
this behavior increases the probability of a waiting customer
to send a follow-up question. in our log, new requests arrive
at different rates across 7 weeks (see table i). during weeks
1,4,5, and 7, a new case arrives every 10–15 minutes. weeks
2,3, and 6 are busier with a new case arriving every 3–5
minutes. assuming all resources are available and no follow-
up question is sent, each case can take between 4–10 minutes
to complete. some customers wait at least three hours before
sending a follow-up question, whereas others wait no longer
than one hour. table i summarizes the number of initial events,
high-level events, high-level activities and their average values
for each week. whenever there are many high-level events
related to jane’s high workload, the numbers of cases entering
and being delayed in the segment between report andanswer
are also higher (see weeks 2, 3 and 6). this demonstrates how
the two concurrent activities report and answer are mostly
executed in this order when jane is busy. the busy weeks
2, 3 and 6 are also reflected in the number of occurrences
of activity follow . when looking at the absolute amounts of
the generated high-level events (the “count” columns), it is
obvious that they are particularly high (low) when the number
of initial events is high (low). this variance in the process
traffic is, however, invisible when looking at the average values
among the weeks. the only exception is the number of follow-
up requests whose average values still reflect that variance.
this demonstrates how (un)desired behavior can be clearly
visible in a process (similar to the follow-up requests), but
1https://github.com/biankabakullari/hlem-frameworkenter-(report, answer) delay-(report, answer) workload-jane exec-follow
week # events # hle count avg. value (visits) count avg. value (hours) count avg. value (tasks) count avg. value (executions)
1 2451 4 4 3.25 - - - - - -
2 17608 1624 250 3,77 439 1,41 340 36 404 9.29
3 9408 724 118 3.75 191 1,50 146 39 175 9.79
4 8750 191 80 3.46 - - - - 80 5.05
5 5791 102 31 3.13 - - - - 63 6.19
6 13016 1150 190 3.84 288 1.44 227 37 300 8.97
7 2577 251 39 3.64 72 1.34 48 33 59 9.47
table i: a summary of the data appearing in the high-level event log obtained from the process described in section i. the columns show
for each week, the number of events in the initial log, the number of high-level events, and the counts (i.e. absolute amounts) and average
values for the most frequent high-level activities. empty entries should be interpreted as zeros.
the patterns that lead to that behavior may disappear if one
looks at the general picture which considers all cases within a
broad time scope. high-level events manage to capture process
behavior that is dynamic, possibly short in its lifespan, but with
significant consequences for the process. fig. 4 displays the
discovered cascades as partially ordered sequences of high-
level activities. we also flattened the log and used celonis to
discover the dfg in fig. 5. in both figures, the high-level
activities are colored according to the legend shown in fig. 4.
figure 4: the seven most frequent variants of the high-level cases
visualized with cortado [13]. each colored chevron shows a high-
level activity, and activities depicted within the same gray chevron
occurred at the same time window. the two most frequent vari-
ants show that activities enter-(report,answer) andexec-follow often
emerge for a single time window, followed by a third variant where
exec-follow emerges in two subsequent windows. the variants with
partially ordered activities show how the workload of jane often
emerges simultaneously with a high entering load and long delay in
the segment (report, answer) . afterwards, exec-follow also appears
in the cascade.
b. real-life event log
we also applied our method on the real-life event log bpi
challenge 20152. the data are provided by five dutch munic-
ipalities and concern building permit applications. here, we
analyze the ‘objections and complaints’ subprocess recorded
210.4121/uuid:31a308ef-c844-48da-948c-305d167a0ec1
figure 5: the dfg discovered from the flattened high-level event
log using celonis . the four high-level activities wl-jane ,exec-follow ,
enter-(report, answer) , and delay-(report, answer) , which were shown
to happen simultaneously in the partially ordered log, appear in a
cycle in the dfg of the flattened log. the similar frequencies of the
arcs connecting those activities, reveal that the same cycle appears
over and over in the process.
for municipalities 2 and 5. the most frequent variants are
depicted in fig. 6 and 7. even though the process and the typ-
ical activities are the same among the two municipalities, the
results reveal that congestion arises in different process parts.
for municipality 2 (fig. 6), the phase between activities lodge
appeal andrevoke decision seems to have long delays (yellow)
most often. also, many cases enter the phase identified with
activity permission irrevocable (dark green). there are often
simultaneous persisting delays between this phase and the
phase identified with activity decision irrevocable (violet) or
activity lodge objection (green) which follow. for municipality
5 (fig. 7), there are often persisting delays between activity
injunction requested and the activities affect contention (or-
ange) and permit irrevocable (blue). in both municipalities,
the involved resources often underlie workload-related high-
level events: e.g., resources 560458 (blue), 560530 (pink) in
municipality 2 and 560613 (green), 560602 (pink), and 560429
(violet) in municipality 5. the presence of these high-level
events shows that the workload for many resources varies
strongly throughout the process. in municipality 5, resources
with id 560429 and 560613 are often affected simultaneouslyby a high workload, which might indicate common responsi-
bilities or high handover of work between them.
figure 6: the most frequent variants of the high-level events obtained
from the ‘objections and complaints’ subprocess of municipality 2 in
bpi challenge 2015.
figure 7: the most frequent variants of the high-level events obtained
from the ‘objections and complaints’ subprocess of municipality 5 in
bpi challenge 2015.
vi. c onclusion and future work
in this work, we introduced a new framework for detecting,
logging and interpreting process behavior that can not be
captured in terms of individual process runs. such behavior
emerges on the system level, it arises and dissolves at different
time periods, and it may trigger other, similar behavior. we
conceptualized this behavior in terms of high-level events,
which similar to the “normal” events indicate what happened
and when it happened. we used congestion as a universal
trait of processes, to demonstrate what a high-level event can
describe and how it can be detected from the event data.
moreover, we showed how one can exploit the control-flow
information present in the data to correlate the detected high-
level events. we evaluated the approach both on simulated data
and on real-life event data. the results show that the method
is able to discover high-level patterns that may be invisible
when using traditional case-oriented techniques.
this work can be extended in many directions. on a more
technical side, the method can be improved to be more robust
to the parameter configuration. finding a good setting ableto detect most interesting patterns on the right level of detail
requires good knowledge of the process at hand. considering
only directly-follows steps to determine the position of a case
in the overall “process map” has the following advantages: on
one hand, every case can only occupy one segment simulta-
neously. thus, the estimated load for segments and resources
simply reflects the number of cases, making it easy to interpret.
on the other hand, this also enables considering the stage
between concurrent activities as a location in itself with its
own load and waiting time. this way, we were able to detect
the particular resource behavior in the simulated log. however,
if the concurrent activities are independent from each other,
the high-level events they produce should not be correlated
despite their consecutive occurrences. another challenge is to
visualize such data in a more intuitive and interactive way.
on the conceptual side, high-level behavior in processes does
not have to be related to congestion. moreover, high-level
behavior concerning activities and other process entities may
not necessarily need a (unique) case notion present in the data.
lastly, the method should be further evaluated on real life
processes prone to congestion and costly errors.
references
[1] f. milani and f. m. maggi, “a comparative evaluation of log-based pro-
cess performance analysis techniques,” in bis, proceedings . springer,
2018.
[2] w. m. p. van der aalst, m. h. schonenberg, and m. song, “time
prediction based on process mining,” inf. syst. , pp. 450–475, 2011.
[3] b. hompes, j. c. a. m. buijs, and w. m. p. van der aalst, “a generic
framework for context-aware process performance analysis,” in coopis,
c&tc, and odbase, proceedings , 2016, pp. 300–317.
[4] v . denisov, d. fahland, and w. m. p. van der aalst, “unbiased, fine-
grained description of processes performance from event data,” in bpm,
proceedings , vol. 11080. springer, 2018, pp. 139–157.
[5] e. l. klijn and d. fahland, “performance mining for batch processing
using the performance spectrum,” in bpm workshops . springer, 2019,
pp. 172–185.
[6] h. nguyen, m. dumas, a. h. m. ter hofstede, m. l. rosa, and
f. m. maggi, “business process performance mining with staged process
flows,” in caise, proceedings . springer, 2016, pp. 167–185.
[7] z. toosinezhad, d. fahland, ¨o. k ¨oroglu, and w. m. p. van der aalst,
“detecting system-level behavior leading to dynamic bottlenecks,” in
icpm . ieee, 2020, pp. 17–24.
[8] a. wimbauer, f. richter, and t. seidl, “perrcas: process error cascade
mining in trace streams,” in icpm workshops , ser. lecture notes in
business information processing, j. munoz-gama and x. lu, eds.
springer, 2021, pp. 224–236.
[9] a. senderovich, m. weidlich, a. gal, and a. mandelbaum, “queue
mining - predicting delays in service processes,” in caise 2014 .
springer, 2014, pp. 42–57.
[10] s. j. van zelst, f. mannhardt, m. de leoni, and a. koschmider, “event
abstraction in process mining: literature review and taxonomy,” granular
computing , pp. 719–736, 2020.
[11] m. pourbafrani and w. m. p. van der aalst, “extracting process features
from event logs to learn coarse-grained simulation models,” in caise
2021 . springer international publishing, 2021, pp. 125–140.
[12] d. m. v . sato, s. c. d. freitas, j. p. barddal, and e. e. scalabrin, “a
survey on concept drift in process mining,” acm comput. surv. , pp.
189:1–189:38, 2022.
[13] d. schuster, s. j. van zelst, and w. m. p. van der aalst, “cortado—an
interactive tool for data-driven process discovery and modeling,” in petri
nets. springer international publishing, 2021, pp. 465–475.
[14] a. v . ratzer, l. wells, h. m. lassen, m. laursen, j. f. qvortrup, m. s.
stissing, m. westergaard, s. christensen, and k. jensen, “cpn tools for
editing, simulating, and analysing coloured petri nets.” springer-verlag,
2003, p. 450–462.