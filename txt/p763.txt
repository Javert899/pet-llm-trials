discovering and navigating a collection of
process models using multiple quality
dimensions
j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
eindhoven university of technology, the netherlands
{j.c.a.m.buijs,b.f.v.dongen,w.m.p.v.d.aalst}@tue.nl
abstract. process discovery algorithms typically aim at discovering a
process model from an event log that best describes the recorded be-
havior. however, multiple quality dimensions can be used to evaluate a
process model. in previous work we showed that there often is not one
single process model that describes the observed behavior best in all qual-
ity dimensions. therefore, we present an extension to our exible etm
algorithm that does not result in a single best process model but in a col-
lection of mutually non-dominating process models. this is achieved by
constructing a pareto front of process models. we show by applying our
approach on a real life event log that the resulting collection of process
models indeed contains several good candidates. furthermore, by pre-
senting a collection of process models, we show that it allows the user to
investigate the dierent trade-os between dierent quality dimensions.
key words: process mining, process model quality, process model col-
lection
1 introduction
the goal of process discovery in process mining is to automatically discover
process models that accurately describe processes by considering only an or-
ganization's records of its operational processes [1]. such records are typically
captured in the form of event logs , consisting of cases and events related to these
cases. over the last decade, many such process discovery techniques have been
developed [1, 5], producing process models in various forms, such as petri nets,
bpmn models, epcs, yawl models etc. furthermore, many authors have com-
pared these techniques by focussing on the properties of the models produced,
while at the same time the applicability of various techniques have been com-
pared in case-studies. however, currently no algorithm produces a collection of
process models for the user to choose from. therefore, in this work we extend our
genetic discovery algorithm to construct not a single, but a collection of process
models. by using the notion of a pareto front, only the best process models are
kept that show dierent trade-os between the quality dimensions.
four quality dimensions are generally used to discuss the results of process
discovery [1,5], namely:2 j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
replay tness quanties the extent to which the discovered model can accu-
rately reproduce the cases recorded in the log.
precision quanties the fraction of the behavior allowed by the model which is
not seen in the event log.
generalization assesses the extent to which the resulting model will be able to
reproduce future (unseen) behavior of the process.
simplicity quanties the complexity of a process model (e.g. number of nodes).
surprisingly, many process discovery algorithms only focus on one or two of
these dimensions [5]. therefore, we proposed the etm-algorithm (which stands
forevolutionary tree miner ) in [5, 6] to seamlessly include dierent quality
dimensions in the discovery process. however, until now, weights needed to be
given to the dierent dimensions. although assigning weights is a common way of
aggregating multiple tness values to a single one, there are some disadvantages.
for instance beforehand the impact of a change in the process model on the value
in a particular dimension is not known. this makes assigning weights to measures
dicult, especially since the sensitivity of each measurement to changes in the
process model is dierent.
the remainder of the paper is structured as follows. next, in section 2, the
pareto front is explained in more detail and common ways to construct such a
pareto front of candidates are discussed. then, in section 3, we briey explain
the etm-algorithm and how it has been extended to build a pareto front of
mutually non-dominating process models. section 4 then presents a case study
where the number of edits from a reference process model is used as a fth
quality dimension. section 5 concludes the paper.
2 multi-objective optimization
optimizing multiple objectives at the same time is a common challenge in opti-
mization problems [7]. one of the simplest solutions is to use a weighted average
over all the quality dimensions to produce a single quality measure. however,
this method has several drawbacks:
1. determining the correct weights upfront is dicult: structural changes on
the candidates have unknown eects on the value for a dimension.
2. values need to be normalized for comparison: a common way to x the previ-
ous issue is by normalizing the values. however, dimensions can still respond
dierently to changes. furthermore, a normalized value often provides less
information than the absolute value.
3. only one solution is provided: only the candidate with the best weighted
average is presented. however, no insights in the dierent trade-os among
the dimensions is provided to the user.
the so-called pareto front is often used as an alternative to the weighted
sum [7,16]. the general idea of a pareto front is that all members are mutuallytitle suppressed due to excessive length 3
non-dominating . a member dominates another member if for all quality dimen-
sions it is at least equal or better and for one strictly better, than the dominated
member. since all members in the pareto front are mutually non-dominating
(neither of them dominates another member) they represent dierent trade-os
in the quality dimensions sacricing on one quality dimension to improve on
another. this concept was originally proposed by vilfredo pareto to explain
economic trade-os [11].
an example of a pareto front in two dimensions is shown in fig. 1. each
dot in the graph represents a process model with a certain replay tness and
precision value, the two quality dimensions used for this pareto front. for each
dimension a bigger value indicates a better candidate, e.g. the goal is to obtain
a process model in the top right corner of the chart. however, often there is no
single model that is able to score perfectly on all dimensions. the open dots
in the lower middle area of fig. 1 are non-optimal process models, e.g. one of
the dimensions can be improved without reducing the quality in (any of) the
other dimension. the closed black dots represent the current estimation of the
pareto front. for these process models there is currently no model known where
one dimension has a better score without reducing one of the other dimensions.
the bigger dots show the seven most diverse process models in the current front,
which can be used to truncate the pareto front by keeping only one representative
for a group of similar process models. the ideal or real pareto front, as indicated
by the curved line, shows that some improvements can still be made.
the construction of a pareto front has been frequently applied in evolution-
ary algorithms. as described in [7], an evolutionary multi-objective optimization
(emo) algorithm aims at both converging close to the real, yet unknown, pareto
front while at the same time maintain a good diversity among the candidates
replay fitnessp
r 
e
c
i 
s
i 
o
n(partly unknown)
pareto frontnon-optimal
process modelstruncated 
members
bcd
efgab c d f a g
fig. 1: pareto front of the two quality dimensions replay tness and precision.
the hollow dots are non-optimal process models, the small black dots are dis-
covered process models representing the current pareto front and the big black
dots are the 7 most diverse among the currently known process models.4 j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
on the current pareto front. the two most common, state-of-the-art, evolution-
ary algorithms that build a pareto front of candidates are the nsga-ii [8] and
spea2 [18] emo algorithms. between the two there is a slight but important dif-
ference in the way the tness evaluation is performed and how the pareto front is
truncated. in short, spea2 calculates the tness using both the dominance and
the density of the population. the dominance includes the number of individuals
dominated by that candidate. but also the number of individuals dominating the
candidate. furthermore, dominators are given a weight by using the total num-
ber of candidates they dominate. the density of the whole population is obtained
by rst calculating the distances between all candidates, and then considering
the distance between a candidate and the kclosest candidate. the nsga-ii
algorithm denes the tness of a candidate by the `non-domination rank' (e.g.
the number of candidates dominating the current candidate, candidates with a
non-domination rank of 0 are on the `actual' pareto front). nsga-ii also has the
notion of (crowding) distance which they calculate by taking the distance to the
candidate better and the candidate worse in each dimension. these distances are
normalized by the total value range of that dimension. the overall crowding dis-
tance of a candidate is the average over all dimensions. however, candidates that
are at the extremes of a particular dimension, get very low (good) distance val-
ues. in this way the extreme candidates are always maintained. both approaches
select the candidates for the new population of the next generation according to
a binary tournament using the tness assignment. they also allow for truncation
of the pareto front using the same tness function. nsga-ii and spea2 have
been extensively compared regarding performance but no clear overall winner
can be announced [4,10,13]. however, for our particular situation the crowding
distance of the nsga-ii algorithm is chosen. the most important reason is the
fact that extremes in each dimension are maintained, providing the user with
extreme examples.
exclusive choice
parallellism
loop
or choice
sequence
fig. 2: process trees operators and their
block-structured bpmn translation.
stop?changeselect
compute 
fitnessevent
 logpareto
front
update
pareto frontfig. 3: the dierent phases of the ge-
netic algorithm.title suppressed due to excessive length 5
3 extending the etm to discover a pareto front
the etm ( evolutionary tree miner ) is a exible evolutionary process discovery
algorithm [5]. the etm-algorithm is able to discover tree-like process mod-
els that are sound and block-structured. examples of the dierent process tree
constructs are shown in fig. 2. overall the etm-algorithm follows the genetic
process shown in fig. 3. the input of the algorithm is an event log describing
the observed behavior and, optionally, one or more reference process models.
first, dierent quality dimensions for each candidate in the current population
are calculated. then, for each new candidate, the pareto front is updated. in
the next step, certain stop criteria are tested such as exceeding a time limit or
whether the user canceled execution. if none of the stop criteria are satised, a
new selection of candidates from the pareto front is made, which forms the new
population. the candidates in this population are then changed, the tness for
each of the quality dimensions is again calculated and they are presented to the
pareto front for possible inclusion. this process is continued until at least one
stop criterion is satised and the current pareto front is then returned. more
details on the etm-algorithm and the process tree notation used can be found
in [5,6].
the etm-algorithm is able to incorporate dierent quality dimensions. in
general the four standard process discovery quality dimensions of replay t-
ness, precision, generalization and simplicity are included. however, the etm-
algorithm is also able to incorporate other quality dimensions during discovery.
examples are the conformance of a process model to a given set of rules [3,9,14],
the predicted risk [12, 15] of a process model, the predicted cost for handling a
case with the given process model [17], the overall performance of the process
model [2], etc. as long as a quality dimension can be calculated by considering
the process model and possibly the event log, and can be inuenced by changing
the process model, it is valid for inclusion in the quality evaluation of a process
discovery algorithm.
in the original etm-algorithm the weights for each quality dimension, as
provided by the user, are used to calculate a single tness value per candidate
and sort them accordingly. furthermore, when the etm-algorithm terminates,
only the best candidate is returned. in this work the etm-algorithm is extended
with a pareto front cache that maintains the current pareto front during the
dierent generations of the etm-algorithm. at the end of each generation the
currently evolved and evaluated population is added to the pareto front, if they
are not dominated by any element currently in the pareto front. at the beginning
of the next iteration a xed number of candidates is selected from the pareto
front, since the front can grow larger than the desired population size.
in order to select the best candidate from the pareto front for the popula-
tion/input of the new generation, a tness value is calculated. here we use a
tness calculation inspired by the crowding distance used in the nsga-ii [8]
algorithm, as was discussed in sec. 2. this tness metric consists of two parts:
calculating the number of candidates that dominate the current candidate and
calculating the crowding distance of the candidate. the rst part of the metric6 j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
results in an integer value, namely the number of candidates in both the pareto
front and the current population that dominate the particular candidate. the
second part of the metric results in a value between 1 and 0 inclusive and rep-
resents the `crowding distance' of a candidate. a value close to 0 indicates that
the candidate is not in a crowded area, and a value of 0 indicates the candidate
is at one of the extremes for at least one dimension. the crowding distance is
calculated per dimension by considering the distance of a candidate with the
next candidate that is worse and the next that is better. by normalizing this
distance by the overall distance between the worst and best candidate of that
dimension, a relative value is obtained. it is important however to assign bound-
ary solutions, e.g. solutions that are best or worst in at least one dimension, a
good crowding distance (e.g. a low value) to ensure that they are kept in the
pareto front. the crowding distance thus favors candidates that are diverse, for
instance during the selection of candidates for mutation. the etm with the
pareto front extension is implemented in the prom framework1.
4 application on a real life event log
in this section we demonstrate our pareto extended approach using the four
quality dimensions of replay tness, precision, generalization and simplicity. ad-
ditionally, we use the edit distance quality dimension as a fth dimension to eval-
uate the similarity to a given process model [6]. the etm-algorithm is started
from a given process model and keeps track of the number of edits (add, remove,
or update of a single node) made to this model. this allows the user to select
a process model that is more or less similar to the reference process model that
was provided. we apply the etm-algorithm as presented in [6] on the same data
set used there, but now with our pareto extension.
the input of the etm-algorithm is an event log describing the processing
of building permits within a municipality. this event log comes from one of the
municipalities participating in the coselog project2. the event log contains
1;434 cases with 8 ;577 events in total and 27 dierent event classes or activi-
ties. the provided reference model, as is shown in fig. 4, is very detailed with
many checks that the employees in practice did not always perform (usually with
good reasons). therefore, the municipality is interested to know where the main
deviations are with respect to the reference process model.
the etm-algorithm was run for 5 ;000 generations evolving 200 candidates
per generation, which took a total of 22 hours and 50 minutes. the experiment
was performed on a computation server running fedora 14 64-bit, with 8 cores
running at 2 ghz and 12 gb memory, of which max. 8 gb was used by the etm.
the four default quality dimensions of replay tness, precision, generalization
1prom is available for download from http://www.processmining.org/ , the etm
algorithm is included in the `evolutionarytreeminer' package.
2more information about the coselog project can be found at http://www.win.
tue.nl/coselog/title suppressed due to excessive length 7
!
^
!


!
z!
	
x!
y	
xwv!
u!
	
s!
t	
sr!
p	
_
!
!
!
jih!
gf!
ke!
d	
bc
f: 0.701 p: 0.894 #edits
s: 0.947 g: 0.724 0
fig. 4: reference model for the case study
and simplicity are considered. additionally, as a fth dimension, the number of
low-level edits made to a provided reference process model is counted as a tness
metric for the similarity dimension. this resulted in a pareto front containing
2;562 process trees, considering 5 dimensions.
visualizing ve dimensions at once is very dicult, therefore the pareto front
can be viewed using charts where the dimensions can be plotted on the x and
y axes. fig. 5 shows plots using the dimensions replay tness and precision.
the dot plot of fig. 5a shows the distribution of candidates when considering
the dimensions replay tness and precision. each dot represents a process model
with that particular combination of values for the two selected dimensions. the
lines on the top right connect those process models that are on the sub pareto
front, i.e. the pareto front only considering the dimensions replay tness and
precision. all process models contained in the pareto front are on a sub pareto
front considering one or more of the quality dimensions. this chart shows that
there is not a single process model which has a very good score (i.e. 1 :000)
for both precision and replay tness. currently, the reference process model is
selected in the chart, which is indicated by the dotted horizontal and vertical
lines.
additionally, a third dimension could be included in this chart by coloring
the dots. this is shown in fig. 5b where the color indicates the number of edits.
a dark color means few edits and the lightest grey color indicates the maximum
number of 61 edits observed. again, the reference process model is selected in
this chart. from this enhanced dot plot is becomes clear that the best process
models are colored light, meaning that they require more than just a few edits.
furthermore, surrounding the selected reference process model is a `cloud' of
darker dots, indicating that only small changes in precision and replay tness
can be achieved if the process model can only be changed slightly.
of course, the municipality wants to know how the reference model can be
improved. fig. 5c shows a zoomed-in view of the dot plot of fig. 5a, where only
the process models with better scores for precision and replay tness than the
reference model are shown. this plot makes the trade-os between replay tness
and precision clear. on the bottom right for instance we see the process models
which have a good replay tness, but at the cost of a bad precision score. the
almost straight lines indicate that with only a very small reduction in replay8 j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
(a) pareto front on the dimensions replay
tness and precision
(b) pareto front on the dimensions replay
tness and precision, colored by number of
edits (darker means less edits)
(c) pareto front on the dimensions replay
tness and precision, showing only models
with better scores than the reference model^
!

!
p	

!
oh!
k
ea!
d!
cl
f: 0.906 p: 0.955 # edits
s: 0.826 g: 0.744 43
(d) process tree with good replay
tness and precision balance
fig. 5: views on the pareto front considering replay tness and precision
tness, the precision score can be improved signicantly. this trade-o works
until a precision of roughly 0 :955 is achieved, then precision can only be improved
by sacricing signicantly on replay tness. which is indicated by the almost
horizontal lines between the process models.
therefore, one of the process models with the best trade-o between replay
tness and precision is the one indicated in fig. 5c by the dotted vertical and
horizontal lines. this process tree is shown in fig. 5d. the process tree is able
to replay most of the behavior observed in the ve event logs, with reasonable
precision. however, it required 43 edits from the reference process model. the
main change is the removal of large parts of the process model, indicating thattitle suppressed due to excessive length 9
indeed some activities are skipped often. furthermore some frequent activities,
such as activity l, are added to, or relocated within, the process model.
when looking in more detail at the pareto front as shown in fig. 5a it
can be observed that most process models are clustered around certain values
for replay tness. for instance there is a cluster of process models around the
reference process model. then there is another cluster or models between a tness
replay score of 0 :780 and 0 :820, with only few process models in between. closer
investigation of the event log showed that there are six activities ( a, c, d, e, l
and p ) that are executed at least 1 ;200 times each. the other activities in the
event log are executed at most 55 times each. therefore these clusters consist of
process models where one of the six frequent activities are in a particular good
control ow construct. since these activities are observed often, changing the
control ow has a relatively large inuence on the replay tness value. the value
(a) pareto front with maximum 20 edits
!
_
!
^


!
z!
	
!
y	
!
wv!
u!
	
s^
!
t	
sr!
p	

!
ke!
d	
bcl
f: 0.833 p: 0.964 # edits
s: 0.860 g: 0.704 19
(b) best process model with maximum 20 edits allowed
fig. 6: pareto front ltered to at most 20 edits from the reference process model10 j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
of replay tness for these models can still be inuenced by repositioning one of
the less frequent activities, but this impact is less.
the process model shown in fig. 5d has little resemblance to the reference
process model. therefore we lter the pareto front to only contain process models
with at most 20 edits from the reference process models. fig. 6a shows the dot
plot of the ltered pareto front on the dimensions precision and replay tness,
using the same scales as in fig. 5c. it is clear to see that the overall quality of
the process models is worse, which can be observed by comparing the size of
the area under the lines between the dots. when only 20 edits are allowed less
improvements can be made. the trade-os are also stronger, as is indicated by
the almost vertical and horizontal lines between the candidates on this subfront.
the process model with the best trade-o in precision and replay tness is
selected and shown in fig. 6b. with 19 edits, a replay tness of 0 :906 and a
precision of 0 :955 can be obtained. this is an improvement with respect to the
reference process model, especially for replay tness. interestingly, this process
tree is also on the sub pareto front as shown in fig. 5c. however, when more
edits are allowed, better quality models are discovered and smaller trade-os can
be made, resulting in a bigger and more detailed pareto front.
the limitations mentioned in sec. 2 are all resolved by using a pareto front.
the rst issue of determining the weights upfront is solved by only requiring
which dimensions to consider, not how to weight them against each other. as
shown in fig. 5, and the related discussion, it is possible to visualize and compare
two or three dimensions, even if one is not normalized. this solves the second
issue mentioned. the third issue of having only a single result is also clearly
solved by presenting a pareto front. for example between fig. 5 and fig. 6 it
was easy to compare dierent trade-os between the number of edits allowed
and the resulting scores for replay tness and precision. these insights were ob-
tained without iteratively calling a discovery algorithm with dierent parameter
settings. moreover, by inspecting the pareto front, a selection of process models
can be made that satisfy a certain criteria, for instance at least as good precision
and replay tness scores as the reference process model.
5 conclusions
in this paper we used the etm-algorithm to construct a collection of process
models that are mutually non-dominating, and thus form a pareto front. each
of the process models in the pareto front either scores very good in one of
the considered quality dimensions or is able to balance the dierent quality
dimensions well. we applied this extension on a real-life event log. by selecting
dierent views on the pareto front, we have shown that several insights can be
gained and dierent complementary models can be inspected. this allows the
user to decide which process model is best and should be used further. moreover,
the user is aware of the trade-os to be made rather than giving full control to
the discovery algorithm.title suppressed due to excessive length 11
furthermore, by applying the pareto front, more quality dimensions and
metrics can be used by the etm-algorithm. since there is no requirement any
more to normalize and weight the values, absolute numbers can also be provided.
this makes the etm-algorithm extendable to use quality dimensions that are
not directly related to process discovery. examples are the discovery of process
models that comply to a certain extend to rules, or to discover process models
that minimize cost or expected risk.
another benet of using the pareto front is the increase in diversity of the
population. previously the whole population would be focussed towards a specic
combination of quality dimensions. however, with the diversity introduced by
the pareto front the etm-algorithm has a large set of process models to choose
from to evolve further. this is especially noticeable in the early generations of
the etm-algorithm where the pareto front makes quick progress.
in the future we plan to further improve the visualization and navigation
options for the pareto front. it is critical that the user can navigate the collection
of process models with ease and quickly gain insights. moreover we plan to
improve the selection of candidates for further evolution. this can be used to
speed up the discovery of good process models. it will also help in a quick
approach of the estimated pareto front to the actual pareto front.
references
1. w.m.p. van der aalst. process mining: discovery, conformance and enhancement
of business processes . springer, 2011.
2. w.m.p. van der aalst, a. adriansyah, and b. f. van dongen. replaying history
on process models for conformance checking and performance analysis. wires
data mining and knowledge discovery , 2(2):182{192, 2012.
3. a. awad, g. decker, and m. weske. ecient compliance checking using bpmn-
q and temporal logic. in bpm 2008 , pages 326{341, 2008.
4. l.t. bui, d. essam, h.a. abbass, and d. green. performance analysis of evolu-
tionary multi-objective optimization methods in noisy environments. in proceed-
ings of the 8th asia pacic symposium on intelligent and evolutionary systems ,
pages 29{39, 2004.
5. j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst. on the role of
fitness, precision, generalization and simplicity in process discovery. in on the
move to meaningful internet systems: otm 2012 , lecture notes in computer
science, pages 305{322. springer, 2012.
6. j.c.a.m. buijs, m. la rosa, h.a. reijers, b.f. van dongen, and w.m.p. van
der aalst. improving business process models using observed behavior. in sec-
ond international symposium on data-driven process discover and analysis, post
proceedings . springer, 2013 (to appear).
7. k. deb. multi-objective optimization. in e.k. burke and g. kendall, editors,
search methodologies , pages 273{316. springer us, 2005.
8. k. deb, s. agrawal, a. pratap, and t. meyarivan. a fast elitist non-dominated
sorting genetic algorithm for multi-objective optimization: nsga-ii. lecture notes
in computer science , 1917:849{858, 2000.12 j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
9. g. governatori and a. rotolo. an algorithm for business process compliance. in
jurix , pages 186{191, 2008.
10. t. hiroyasu, s. nakayama, and m. miki. comparison study of spea2+, spea2,
and nsga-ii in diesel engine emissions and fuel economy problem. in evolu-
tionary computation, 2005. the 2005 ieee congress on , volume 1, pages 236{242
vol.1, 2005.
11. vilfredo pareto. cours d'economie politique, volume i and ii . f. rouge, lau-
sanne, 1896.
12. a pika, w.m.p. aalst, c.j. fidge, a.h.m. ter hofstede, and m.t. wynn. predict-
ing deadline transgressions using event logs. in business process management
2012 workshops , volume 132. 2013.
13. l. raisanen and r.m. whitaker. comparison and evaluation of multiple objective
genetic algorithms for the antenna placement problem. mobile networks and
applications , 10(1-2):79{88, 2005.
14. e. ramezani, d. fahland, b.f. van dongen, and w.m.p. van der aalst. diagnostic
information for compliance checking of temporal compliance requirements. in
caise forum . lncs, springer, 2013 (to appear).
15. s. suriadi, c. ouyang, w.m. p. van der aalst, and a.h.m. ter hofstede. root
cause analysis with enriched process logs. in business process management
workshops , pages 174{186, 2012.
16. d.a. van veldhuizen and g.b. lamont. evolutionary computation and conver-
gence to a pareto front. in late breaking papers at the genetic programming
1998 conference , pages 221{228, 1998.
17. m.t. wynn, w.z. low, and w. nauta. a framework for cost-aware process
management: generation of accurate and timely management accounting cost
reports. in asia-pacic conference on conceptual modelling .
18. e. zitzler, m. laumanns, and l. thiele. spea2: improving the strength pareto
evolutionary algorithm for multiobjective optimization. in evolutionary meth-
ods for design, optimisation and control with application to industrial problems.
proceedings of the eurogen2001 conference, athens, greece, september 19-21,
2001.