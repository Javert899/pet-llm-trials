mining conﬁgurable process models from collections
of event logs
j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
eindhoven university of technology, the netherlands
fj.c.a.m.buijs,b.f.v.dongen,w.m.p.v.d.aalst g@tue.nl
abstract. existing process mining techniques are able to discover a speciﬁc pro-
cess model for a given event log. in this paper, we aim to discover a conﬁgurable
process model from a collection of event logs, i.e., the model should describe a
family of process variants rather than one speciﬁc process. consider for example
the handling of building permits in different municipalities. instead of discovering
a process model per municipality, we want to discover one conﬁgurable process
model showing commonalities and differences among the different variants. al-
though there are various techniques that merge individual process models into a
conﬁgurable process model, there are no techniques that construct a conﬁgurable
process model based on a collection of event logs. by extending our etm genetic
algorithm, we propose and compare four novel approaches to learn conﬁgurable
process models from collections of event logs. we evaluate these four approaches
using both a running example and a collection of real event logs.
1 introduction
different organizations or units within a larger organization may need to execute similar
business processes. municipalities for instance all provide similar services while being
bound by government regulations [6]. large car rental companies like hertz, avis and
sixt have ofﬁces in different cities and airports all over the globe. often there are sub-
tle (but sometimes also striking) differences between the processes handled by these
ofﬁces, even though they belong to the same car rental company. to be able to share de-
velopment efforts, analyze differences, and learn best practices across organizations, we
need conﬁgurable process models that are able to describe families of process variants
rather than one speciﬁc process [8, 16].
given a collection of event logs that describe similar processes we can discover a
process model using existing process mining techniques [1]. however, existing tech-
niques are not tailored towards the discovery of a conﬁgurable process model based on
acollection of event logs. in this paper, we compare four approaches to mine conﬁg-
urable models. the ﬁrst two approaches use a combination of existing process discovery
and process merging techniques. the third approach uses a two-phase approach where
the fourth approach uses a new, integrated approach. all four approaches have been
implemented in the prom framework [18].
the remainder of the paper is organized as follows. in section 2, we discuss related
work on process discovery, conﬁgurable process models and current model merging
techniques. in section 3 we describe the four different approaches to mine conﬁgurableprocess models in more detail. there we also describe how our genetic process dis-
covery algorithm (etm) has been extended to perform each of the four different ap-
proaches. then we apply each of the approaches on a running example in section 4.
in section 5 we apply the four approaches on a real-life event log collection to demon-
strate the applicability of each of the approaches in practice. section 6 concludes the
paper and suggests directions for future work.
2 related work
the goal of process discovery in the area of process mining is to automatically discover
process models that accurately describe processes by considering only an organization’s
records of its operational processes [1]. such records are typically captured in the form
ofevent logs , consisting of cases and events related to these cases. over the last decade,
many such process discovery techniques have been developed. for a complete overview
we refer to [1]. however, until now, no process mining technique exists that is able to
discover a single, conﬁgurable, process model that is able to describe the behavior of a
collection of event logs .
aconﬁgurable process model describes a family of process models, i.e., variants of
the same process. a conﬁguration of a conﬁgurable process model restricts its behav-
ior, for example by hiding orblocking activities. hiding means that an activity can be
skipped. blocking means that a path cannot be taken anymore. most formalisms allow
operators to be made more restrictive (e.g., an or-split is changed into an xor-split).
by conﬁguring the conﬁgurable process model a (regular) process model is obtained.
a conﬁgurable process model aims to show commonalities and differences among dif-
ferent variants. this facilitates reuse and comparison. moreover, development efforts
can be shared without enforcing a very particular process. different notations and ap-
proaches for process conﬁguration have been suggested in literature [4,8,11,15–17]. in
this paper we use a representation based on [17].
conﬁgurable process models can be constructed in different ways. they can be de-
signed from scratch, but if a collection of existing process models already exist, a con-
ﬁgurable process model can be derived by merging the different variants. the original
models used as input correspond to conﬁgurations of the conﬁgurable process model.
different approaches exist to merge a collection of existing process models into a
conﬁgurable process model. a collection of epcs can be merged using the technique
presented in [9]. the resulting conﬁgurable epc may allow for additional behavior,
not possible in the original epcs. la rosa et al. [12] describe an alternative approach
that allows merging process models into a conﬁgurable process model, even if the input
process models are in different formalisms. in such merging approaches, some conﬁgu-
rations may correspond to an unsound process model. li et al. [13] discuss an approach
where an existing reference process model is improved by analyzing the different vari-
ants derived from it. however, the result is not a conﬁgurable process model but an
improved reference process model, i.e., variants are obtained by modifying the refer-
ence model rather than by process conﬁguration. the cosenet [17] approach has been
designed for merging a collection of block structured process models. this approach
always results in sound and reversible conﬁgurable process models.step 2b:
process
configurationevent
log 1
event
log 2
event
log n
configurable
process modelc1
c2
cn
...
step 2a:
process 
model 
mergingstep 1:
process 
miningprocess 
model 1
process 
model 2
process 
model n(a) approach 1: merge individually
discovered process models
step 1c:
process
individual-
izationevent
log 1
event
log 2
event
log n
common
process modelc1
c2
cn
...
step 1b:
process 
miningstep 1a:
merge
event 
logsmerged 
event logprocess 
model 1
process 
model 2
process 
model n
step 1d:
process 
model 
mergingstep 2: 
process 
configurationconfigurable
process model(b) approach 2: merge similar discovered process models
step 2:
process
configurationevent
log 1
event
log 2
event
log n
configurable
process modelc1
c2
cn
...
step 1b:
process 
miningstep 1a:
merge
event 
logsmerged 
event log
(c) approach 3: first discover a single pro-
cess model then discover conﬁgurations
event
log 1
event
log 2
event
log n
configurable
process modelc1
c2
cn
...
step 1&2:
process 
mining
& 
process 
configuration(d) approach 4: discover process model and
conﬁgurations at the same time
fig. 1: creating a conﬁgurable process model from a collection of event logs.
another way of obtaining a conﬁgurable process model is not by merging process
models but by applying process mining techniques on a collection of event logs. this
idea was ﬁrst proposed in [10], where two different approaches were discussed, but
these were not supported by concrete discovery algorithms. the ﬁrst approach merges
process models discovered for each event log using existing process model merge tech-
niques. in the second approach the event logs are ﬁrst merged and then a combined
process model is discovered and individualized for each event log.
3 mining a conﬁgurable process model
in this section we present different approaches to mine a conﬁgurable process model
from a collection of event logs. we also present the algorithm used for the discovery of
process models.
3.1 approaches
as mentioned in section 1, we consider four approaches to discover a conﬁgurable
process model from a collection of event logs.
the ﬁrst approach, as is shown in figure 1a, applies process discovery on each input
event log to obtain the corresponding process model. then these processes models are
merged using model merge techniques. this approach was ﬁrst proposed in [10].since the process models of the ﬁrst approach are discovered independently of each
other, they might differ signiﬁcantly hence merging them correctly becomes more dif-
ﬁcult. therefore we propose a second approach as an improvement of the previous
approach. the overall idea is shown in figure 1b. from the input event logs ﬁrst one
process model is discovered that describes the behavior recorded in all event logs. then
the single process model is taken and individualized for each event log. for this we use
the work presented in [7] to improve a process model within a certain edit distance.
in the next step these individual process models are merged into a conﬁgurable pro-
cess model using the approach of [17]. by making the individual process models more
similar, merging them into a conﬁgurable process model should be easier.
the third approach, as shown in figure 1c, is an extension of the second approach
presented by gottschalk et al. in [10]. a single process model is discovered that de-
scribes the behavior of all event logs. then, using each individual event log, conﬁgura-
tions are discovered for this single process model. in this approach the common process
model should be less precise than other process models since we can only restrict the
behavior using conﬁgurations, but not extend it. therefore the process discovery algo-
rithm applied needs to put less emphasis on precision.
the fourth approach is a new approach where the discovery of the process model
and the conﬁguration is combined, see figure 1d. this approach is added to overcome
the disadvantages of the other three approaches. by providing an integrated approach,
where both the process model and the conﬁguration options are discovered simultane-
ously, better trade-offs can be made.
the third and fourth approaches require an algorithm that is able to balance trade-
offs in control ﬂow, and optionally in conﬁguration options. in previous work we pre-
sented the etm-algorithm [5] that is able to seamlessly balance different quality dimen-
sions. therefore, in this paper the etm-algorithm is extended such that it can discover
a single process tree using a collection of event logs. together with the process tree a
conﬁguration for each of the event logs is also discovered. in order to be able to com-
pare the results of the different approaches, the etm-algorithm is used as the process
discovery algorithm in all four approaches.
3.2 the etm algorithm
in this section we brieﬂy introduce our evolutionary algorithm ﬁrst presented in [5]. the
etm ( evolutionary tree miner ) algorithm is able to discover tree-like process models
that are sound and block-structured. the ﬁtness function used by this genetic algorithm
can be used to seamlessly balance different quality dimensions. in the remainder of this
section we only discuss the etm-algorithm on a high-level together with the extensions
made, to prevent repetition. all details of the etm-algorithm can be found in [5].
overall the etm algorithm follows the genetic process shown in figure 2. the
input of the algorithm is one or more event logs describing the observed behavior and,
optionally, one or more reference process models. first, different quality dimensions for
each candidate currently in the population are calculated, and using the weight given
to each quality dimension, the overall ﬁtness of the process tree is calculated. in the
next step certain stop criteria are tested such as ﬁnding a tree with the desired overall
ﬁtness, or exceeding a time limit. if none of the stop criteria are satisﬁed, the candidatesin the population are changed and the ﬁtness is again calculated. this is continued until
at least one stop criterion is satisﬁed and the best candidate (highest overall ﬁtness) is
then returned.
the etm-algorithm works on process trees, which are a tree-like representation of
a process model. the leafs are activities and the other nodes represent one of several
predeﬁned control-ﬂow constructs.
to measure the quality of a process tree, we consider one metric for each of the four
main quality dimensions described in literature [1–3] (see fig. 3). we have shown in [5]
that the replay ﬁtness dimension is the most important of the four in process discovery.
the replay ﬁtness dimension expresses how much of the observed behavior in the event
log can be replayed in the process model. the precision dimension indicates how much
additional behavior is possible in the process model but is not observed in the event
log. the simplicity dimension assesses how simple the process model description of the
behavior is. the generalization dimension is added to penalize “overﬁtting”, i.e., the
model should allow for unseen but very likely behaviors.
for the simplicity dimension we use a slightly different metric than in previous
work. simplicity is based on occam’s razor, i.e., the principle that says that when all
other things are equal the simplest answer is to be preferred. size is one of the simplest
measures of complexity [14] since bigger process models are in general more com-
plex to understand. unfortunately, the ideal size of the process tree cannot directly be
calculated, as control ﬂow nodes can have multiple children. furthermore, it might be
beneﬁcial for other quality dimensions, such as replay ﬁtness or precision, to duplicate
certain parts. therefore, in the genetic algorithm, we use the fraction of the process tree
that consists of ‘useless’ nodes as a simplicity metric since it does not inﬂuence the
other quality dimensions. a node is useless if it can be removed without changing the
behavior of the tree. useless nodes are operators with only one child, leafs in a!or
^construct, non-ﬁrst ’s in an_construct and 	’s consisting of one 	as a child and
two’s as other children.
each of the four metrics is computed on a scale from 0to1, where 1is optimal.
replay ﬁtness, simplicity and precision can reach 1as optimal value. generalization
can only reach 1in the limit, i.e., the more frequent nodes are visited, the closer the
value gets to 1.
stop?changecombineselectsave elite
select
bestcompute 
fitness
event
 logevent
 logevent
 logevent
 log
fig. 2: the phases of the genetic algorithm.
“able to replay event log” “occam’s razor”
“not overfitting the log” “not underfitting the log”fig. 3: quality dimensions for discovery
[1, 2].3.3 conﬁguring process trees
in this paper, we extend process trees [5] with conﬁguration options. a node in a pro-
cess tree can be not conﬁgured, blocked, hidden or ‘downgraded’ for each of the input
event logs. the blocking and hiding operations are as speciﬁed in existing conﬁgura-
tion languages [8, 16, 17] (see section 2) and either block a path of execution or hide
a part of the process. however, we add the conﬁguration option that operators can be
downgraded . by downgrading an operator, the behavior of the operator is restricted to a
subset of the initially possible behavior. the 	operator for instance can be downgraded
to a!. this is done by removing the ‘redo’ part of the 	operator and putting the ‘do’
and ‘exit’ children of the loop in a sequence.
another operator that can be downgraded is the _operator which can be down-
graded to an^(forcing all children to be executed), (only allowing for one child
to be executed), and a !(executing all its children in a particular order). however,
since in one conﬁguration the order of the children might be different than in another,
we also added the  operator, representing a reversed sequence , which simply exe-
cutes the children in the reversed order, i.e. from right to left. finally, also the ^can be
downgraded to an!or operator.
thequality of the conﬁguration perspective should also be incorporated in the ﬁt-
ness function of the etm-algorithm. this is partly done by applying the conﬁguration
options on the overall (i.e. conﬁgurable) process tree before evaluating the main four
quality dimensions. for instance, when an activity that is not present in an event log
is hidden from the process tree, this is reﬂected by replay ﬁtness. the four quality di-
mensions are calculated for each individual event log and then a weighted average is
calculated using the size of each event log. however, as part of the quality of the conﬁg-
uration, the number of nodes that have a conﬁguration option set should be considered
(otherwise all nodes can be made conﬁgurable without any penalty). therefore, we add
a new quality dimension for conﬁguration that simply measures the fraction of nodes in
the process tree for which no conﬁguration option exist. the other four quality dimen-
sions are more important than the conﬁguration ﬁtness, but if a conﬁgurable process tree
exists with fewer conﬁguration options and the same quality in the other dimensions,
then the latter process tree is preferred.
4 running example
our running example [7] is based on four variants of the same process describing a
simple loan application process of a ﬁnancial institute, providing small consumer credit
through a webpage. the four bpmn process models describing the variants are shown
in figure 4. the event logs that were obtained through simulation are shown in 1.
in the ﬁrst variant the process works as follows: when a potential customer ﬁlls in a
form and submits the request on the website, the process is started by activity awhich
is sending an e-mail to the applicant to conﬁrm the receipt of the request. next, three
activities are executed in parallel. activity bis a check of the customer’s credit history
with a registration agency. activity cis a computation of the customer’s loan capacity
and activity dis a check whether the customer is already in the system. this check istable 1: four event logs for the four different variants of the loan application process
of figure 4.
trace # trace #
a b c d e g 6 a d c b f g 4
a b c d f g 38 a c d b f g 2
a b d c e g 12 a d b c f g 1
a b d c f g 26 a d b c e g 1
a b c f g 8 a c b f g 1
a c b e g 1
(a) event log for variant 1trace #
a b1 b2 c d2 e g 20
a b1 b2 c d2 f g 50
(b) event log for
variant 2trace #
a c b e 120
a c b f 80
(c) event
log for
variant 3trace #
a b1 d b2 c e 45
a b1 d2 b2 c f 60
(d) event log for
variant 4
skipped if the customer ﬁlled in the application while being logged in to the personal
page, since then it is obsolete. after performing some computations, a decision is made
and communicated to the client. the loan is accepted (activity e, covering about 20%
of the cases) or rejected (activity f, covering about 80% of the cases). finally, activity
g(archiving the request) is performed.
the second loan application variant is simpler than the ﬁrst process. most notable
is the absence of parallelism. furthermore, activity bhas been split into the activities
b1(send credit history request to registration agency) and b2(process response of
registration agency). activity dof the original process has been replaced by d2which
is checking the paper archive.
the third variant of the loan application process is even simpler where after send-
ing the conﬁrmation of receipt (activity a) the capacity is calculated (activity c) and
the credit is checked (activity b). then the decision is made to accept (activity e) or
reject (activity f) the application. the application is not archived; hence no activity g
is performed.
(a) variant 1
 (b) variant 2
(c) variant 3
 (d) variant 4
fig. 4: four variants of a loan application process. ( a= send e-mail, b= check credit, b1
= send check credit request, b2= process check credit request response, c= calculate
capacity, d= check system, d2= check paper archive, e= accept, f= reject, g= send
e-mail).in the fourth and ﬁnal variant of this process, after sending the conﬁrmation of
receipt (activity a), the request for the credit history is sent to the agency (activity b1).
then either the system archive (activity d) or paper archive (activity d2) is checked.
next the response of the credit history check is processed (activity b2) and next the
capacity is calculated (activity c). then the decision is made to accept (activity e) or
reject (activity f) the application. the application is not archived (i.e., no activity gin
model).
although the four variations of the loan application process seem similar, automat-
ically discovering a conﬁgurable process model is far from trivial.
4.1 experimental setup
in the remainder of this section we use the etm algorithm as our discovery technique
to construct a process model, in the form of a process tree, from an event log. we ran the
experiments for 20;000generations on each individual event log for approaches 1 and
2. because in approaches 3 and 4 we consider all four event logs at once, we increased
the number of generations to 80;000to get a stable result. each generation contained a
population of 20trees out of which the best six were kept unchanged between genera-
tions, i.e. the elite. the quality dimensions of replay ﬁtness and simplicity were given
a weight of ten, since we want a small process model with a good relation to the event
log. a weight of ﬁve for precision makes sure the model does not allow for too much
additional behavior and a weight of one-tenth for generalization makes the models more
general.
4.2 approach 1: merge individually discovered process models
the results of applying the ﬁrst approach on the running example are shown in figure 5.
each of the individual process models (see figures 5a through 5d) clearly resemble
each of the individual event logs. the combined conﬁgurable process model however
is nothing more than a choice between each of the individual input process models. in
this conﬁgurable process model those nodes that are conﬁgured have a grey ‘callout’
added, indicating for each conﬁguration whether that node is not conﬁgured (‘-’), hid-
den (‘h’) or blocked (‘b’). the table shown in figure 5f shows the different quality
scores for both the conﬁgurable process models as well as for each of the conﬁgura-
tions. moreover, the simplicity statistics of size, number of conﬁguration points (#c.p.)
and similarity of the conﬁgured process model w.r.t. the conﬁgurable process model is
shown. the fact that the four conﬁguration options block a big part of the process model
is reﬂected in the low similarity of the conﬁgured process models with the conﬁgurable
process model. this is also shown by the relatively large size of the process tree.
4.3 approach 2: merge similar discovered process models
in the second approach we try to increase similarity by discovering a common process
model from all event logs combined, of which the result is shown in figure 6a. this
process model has difﬁculties to describe the combined behavior of the four variants.the four individual process models derived from this common process model are shown
in figures 6b through 6e. each individual process model has a high similarity with the
common process model, while some changes are made to improve the overall ﬁtness for
that particular event log. for the ﬁrst three variants the discovered process models are
identical to the one of approach 1. the process of the fourth variant however differs too
much from the common model, hence the similar process model is not as good as the
one found in approach 1. the combined process tree is shown in figure 6f. despite the
similarity of the individual process models, the combined conﬁgurable process model
is still a choice of the four input process models. the overall ﬁtness of this model is
slightly worse than that of approach 1, mainly due to the process model of variant 4.
similar to the previous approach, the number of conﬁguration points is low. unfortu-
nately, also the similarity between the conﬁgured process model and the conﬁgurable
process model is low.
(a) process model mined on event log 1
 (b) process model mined on event log 2
(c) process model mined on event log 3
 (d) process model mined on event log 4

!

!
ecb2d!
fc!
b2d2b1a!
!

feb!
ca!
g!
!

ef!
d2!
!
cb2b1a!
g!

ef!
^
d^
cba[-,b,b,b] [b,-,b,b] [b,b,-,b] [b,b,b,-]
(e) conﬁgurable process model obtained after merging models (a) through (d)
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.989 0.999 0.999 0.981 0.220 53 4 -
variant 0 0.986 0.995 0.995 0.981 0.235 14 3 0.418
variant 1 0.989 1.000 1.000 0.981 0.263 16 3 0.464
variant 2 0.989 1.000 1.000 0.981 0.174 10 3 0.317
variant 3 0.989 1.000 1.000 0.981 0.264 16 3 0.464
(f) quality statistics of the conﬁgurable process model of (e)
fig. 5: results of merging seperate discovered process models on the running example(a) process model discovered from combined event log
(b) process model individualized for event log 1
 (c) process model individualized for event log 2
(d) process model individualized for event log 3
 (e) process model individualized for event log 4

!
g
ef^

bd2cb2b1a!

ef!

bca!
g
efd2!
cb2!
b1a!
g
ef!
^
bdca[-,b,b,b] [b,-,b,b] [b,b,-,b] [b,b,b,-]
(f) conﬁgurable process model obtained after merging models (b) through (e)
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.958 0.974 0.921 0.968 0.212 46 4 -
variant 0 0.981 0.995 0.995 0.968 0.232 12 3 0.414
variant 1 0.984 1.000 1.000 0.968 0.246 13 3 0.441
variant 2 0.984 1.000 1.000 0.968 0.180 10 3 0.357
variant 3 0.869 0.886 0.649 0.968 0.232 14 3 0.467
(g) quality statistics of the conﬁgurable process model of (f)
fig. 6: results of merging the similar process models on the running example
4.4 approach 3: first discover a single process model then discover
conﬁgurations
the resulting conﬁgurable process model is shown in figure 7. from this model it can
be seen that we relaxed the precision weight, in order to discover an ‘overly ﬁtting’ pro-
cess model. then, by applying conﬁgurations, the behavior is restricted in such a way
that the model precisely describes each of the variants, as is indicated by the perfect
replay ﬁtness. this process model also scores relatively high for precision and simplic-
ity. the process tree however has a similar large size as the two previous approaches.
nonetheless, the similarity of each of the individual process models to the conﬁgurable
process model is higher than in the previous two approaches since only small parts are
conﬁgured.4.5 approach 4: discover process model and conﬁgurations at the same time
the result of applying the fourth, integrated approach is shown in figure 8. this process
model is smaller and therefore simpler than previous models, a result of the weight of
ten for the simplicity dimension. moreover, it clearly includes the common parts of
all variants only once, e.g. always start with aand end with a choice between eandf,
sometimes followed by g. this process model correctly hides activities that do not occur
in certain variants, for instance gfor variants 3 and 4 and the b,b1andb2activities.
moreover, it correctly discovered the parallelism present in variant one, where the other
variants are conﬁgured to be sequential. as a trade-off, it did not include activity d2,
which is the least occurring activity in the event logs, and occurs in different locations
in the process.
the discovered conﬁgurable process model can be further improved by increasing
the replay ﬁtness, making sure that all behavior can be replayed. this results in the con-
ﬁgurable process model as shown in 9. this process model is able to replay all behavior,
something that only was achieved in the two-phase mining approach. however, this re-
sults in a process model with a lot of 	and_constructs, which are then blocked for
particular conﬁgurations. moreover, the resulting process model is rather large, contains
many conﬁguration points and has mediocre similarity scores. this is a clear trade-off
of aiming for a higher replay ﬁtness value. however, the two-phase approach produced
a better model with perfect replay ﬁtness.
4.6 comparison of the four approaches
the results of applying the four different approaches on the running example are very
different. all discovered models have similar scores for replay ﬁtness and precision and
there are (almost) no useless nodes. however, there are noticeable differences in gener-
alization, size and similarity between the conﬁgurable and the conﬁgured models. the
!

!

gef!
gf!


!
!
cb2db1^
bdc
!
cb2!
d2b1!
d2!
c!
b2b1^
bca
[-,b,!,b][b,-,b,-]
[h,-,-,b]
[h,b,h,-][-, ,h,b] [-,b,b,-][-,-,b,b]
[b,h,h,-][b,b,-,-]
[b,b,-,h][-,-,b,b]
(a) conﬁgurable process model discovered using the two-phase approach
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.988 1.000 0.981 0.986 0.374 42 11 -
variant 0 0.990 1.000 0.990 0.986 0.400 20 6 0.645
variant 1 0.992 1.000 1.000 0.986 0.408 20 7 0.645
variant 2 0.992 1.000 1.000 0.986 0.285 13 8 0.473
variant 3 0.977 1.000 0.922 0.986 0.496 24 6 0.727
(b) quality statistics of the conﬁgurable process model of (a)
fig. 7: results of the two-phase mining approach on the running example!
g
ef^
bcb2db1a[-,!,!,!]
[h,-,h,-] [-,h,h,-] [h,-,h,-] [-,h,-,h][-,-,h,h]
(a) conﬁgurable process model discovered using the integrated discovery
approach
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.983 0.962 0.999 1.000 0.684 12 6 -
variant 0 0.996 0.995 0.994 1.000 0.738 10 2 0.909
variant 1 0.957 0.894 1.000 1.000 0.723 10 3 0.909
variant 2 0.998 1.000 1.000 1.000 0.614 8 5 0.800
variant 3 0.961 0.905 1.000 1.000 0.741 10 3 0.909
(b) quality statistics of the conﬁgurable process model of (a)
fig. 8: results of the integrated mining approach on the running example
[b,b,b,-]
[b,-,b,b][-,!,-,-]
[-,-,!,-]
[b,b,-,-]
[b,-,b,b][-,b,-,b]
[-,-,b,b]
[b,h,b,h][b,b,b,b][-,b,b,b]
[,,-,h]
[b,-,-,!]
[-,b,-,b][-,b,b,-]
[b,-,b,h][!,-,-,b]
[b,b,b,h][!,!,b,b][!,-,h,!][b,b,-,b][b,-,b,b][!,!,-,-]
[,,-,-]
[-,b,b,b]
[b,b,b,-][!,-,-,!]
[-,b,b,-][-,h,b,b][-,b,h,b][b,h,b,-]	

	

	
g
	
ebf	
b1	
_
	

	
	
ac_
	
d
	
b	
c	
b	
fd_
	
	
a
	
bd_
ca_
!
d2cfb2f
(a) conﬁgurable process model discovered with more weight on replay ﬁtness
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.980 1.000 0.767 0.993 0.345 82 31 -
variant 0 0.985 1.000 0.826 0.993 0.534 54 20 0.794
variant 1 0.974 1.000 0.696 0.993 0.306 30 21 0.527
variant 2 0.986 1.000 0.850 0.993 0.349 31 20 0.549
variant 3 0.973 1.000 0.680 0.993 0.261 24 21 0.453
(b) quality statistics of the conﬁgurable process model of (a)
fig. 9: result of the integrated mining approach when improving replay ﬁtness
ﬁrst two approaches score relatively poor on generalization, because the merge operator
used introduces speciﬁc submodels for each log, which limits the number of visits per
node during replay. also, due to duplication, the models are signiﬁcantly larger, and
because in the conﬁguration large parts are blocked, the conﬁgured models are dissim-
ilar to the conﬁgurable one. mining a process model and then mining conﬁgurations
improves the similarity, but still the conﬁgurable model remains larger than necessary.
furthermore, the number of conﬁguration points is very high. however, it is easier to
aim for higher replay ﬁtness values the ﬁnal approach, where the conﬁgurations are
discovered simultaneously with the conﬁgurable model reduces the size signiﬁcantly,table 2: case study event log statistics
#traces #events #activities
combined 1214 2142 28
l1 54 131 15
l2 302 586 13
l3 37 73 9
l4 340 507 9
l5 481 845 23
table 3: statistics of merging the separate process models on the case study event logs
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.979 0.973 0.962 0.997 0.560 1555 5 -
variant 0 0.977 0.977 0.949 0.996 0.362 581 4 0.544
variant 1 0.973 0.967 0.944 0.998 0.617 201 4 0.229
variant 2 0.991 1.000 0.993 0.988 0.234 72 4 0.089
variant 3 0.984 0.978 0.974 0.998 0.690 455 4 0.453
variant 4 0.978 0.971 0.964 0.997 0.480 250 4 0.277
thus improving the similarity score. however, this comes at a minor cost of replay ﬁt-
ness.
the ﬁrst two approaches seem to struggle with merging process models based on
their behavior. because they only focus on the structure of the model, the frequencies of
parts of the process model being visited are not considered during the merge. the third
and fourth approach both directly consider the behavior and frequencies as recorded
in the event log. this seems to be beneﬁcial for building a conﬁgurable process model
since these latter two approaches outperform the ﬁrst two. in the next section we apply
all four approaches on a collection of real-life event logs to validate these ﬁndings.
5 case study
to validate our ﬁndings we use a collection of ﬁve event logs from the coselog
project1, each describing a different process variant. the main statistics of the event
logs are shown in table 2. the event logs were extracted from the it systems of ﬁve
different municipalities. the process considered deals with objections related to build-
ing permits.
the result of both the ﬁrst (individually discovered process models that are then
merged) and the second approach (making sure the models are similar) result in process
trees with more than 200or even 1;500nodes. both process models however again
consist of anoperator as the root with each of the ﬁve original models as its children
that are then blocked, similar to the running example results. we therefore only show
the statistics in table 3 and 4 since the process models are unreadable.
the third approach, where the etm-algorithm ﬁrst discovers a common process
model that is not very precise, and then applies conﬁguration options, results in the
process tree as shown in fig. 10a. the statistics for this process model are shown in
1more information can be found at http://www.win.tue.nl/coselog/wiki/starttable 4: statistics of merging the similar process models on the case study event logs
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.980 0.989 0.936 0.998 0.540 236 5 -
variant 0 0.973 0.992 0.894 0.999 0.337 65 4 0.432
variant 1 0.977 0.969 0.958 0.998 0.598 34 4 0.252
variant 2 0.966 0.991 0.863 0.998 0.533 24 4 0.185
variant 3 0.991 0.999 0.968 0.999 0.461 48 4 0.338
variant 4 0.977 0.994 0.909 0.998 0.582 69 4 0.452
[b,b,b,b,b] [b,b,b,b,b] [^,-,-,-,-]
[-,-,b,-,-]
[b,-,-,-,b][-,-,!,!,-]
[!,!,-,!,-]
[h,-,h,h,-] [h,h,h,h,h][b,-,b,b,b]
[b,b,b,b,-][-,-,-,-,h][-,-,-,h,-]
[-,h,h,h,-]
[-,h,h,h,h][-,^,b,^,-][b,-,b,b,b]
	
 546 680_

	
_
!
560 550590	
!
766 755!
730
	
!
700 640 670630
	
 775 540_

540 6307657705501	
 6501 6502
(a) results of the two-phase mining approach
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.973 0.965 0.951 0.999 0.451 46 17 -
variant 0 0.947 0.943 0.862 0.999 0.319 31 10 0.792
variant 1 0.979 0.968 0.971 0.999 0.452 36 8 0.878
variant 2 0.961 0.932 0.958 0.999 0.267 25 12 0.690
variant 3 0.980 0.990 0.934 0.999 0.390 30 13 0.763
variant 4 0.970 0.950 0.961 0.999 0.522 34 8 0.850
(b) statistics of the two-phase mining result
fig. 10: results of the two-phase mining approach on the real-life event logs
table 10b. this process tree is rather compact and has reasonable scores for replay
ﬁtness, precision and simplicity.
the fourth approach, where the control ﬂow and conﬁguration points are discovered
simultaneously, results in the process tree as shown in fig. 11a. the statistics are shown
in table 11b. with only 4conﬁguration points, and similar quality scores as the previous
result, this process tree is even smaller and hence simpler.
the application of the different approaches on the real-life event logs show similar
results as on the running example. the ﬁrst two approaches seem to have difﬁculties in
merging the process models based on the behavior of the process model.
6 conclusion
in this paper we presented and compared four approaches to construct a conﬁgurable
process model from a collection of event logs. we applied all four approaches on both
a running example and a real-life collection of event logs. our results show that the
naive approach of ﬁrst discovering a process model for each event log separately and_
_
_
!

730630540770765[b,-,b,-,-][^,-,-,-,-]
[,-,,-,-]
[b,-,h,h,h]
(a) result of the integrated mining approach
overall fitness precision simplicity generalization size #c.p. similarity
combined 0.966 0.952 0.929 1.000 0.839 11 4 -
variant 0 0.945 0.866 1.000 1.000 0.622 9 4 0.900
variant 1 0.970 0.958 0.935 1.000 0.861 11 0 1.000
variant 2 0.955 0.920 0.942 1.000 0.651 10 3 0.952
variant 3 0.974 0.975 0.923 1.000 0.845 11 1 1.000
variant 4 0.962 0.945 0.921 1.000 0.860 11 1 1.000
(b) statistics result
fig. 11: results of the integrated mining approach on the real-life event logs
then merging the discovered models yields large conﬁgurable models to which the indi-
vidual conﬁgurations are not very similar. it is slightly better to ﬁrst discover a process
model on the combination of the event logs and then conﬁgure this model for each log.
however, both of these approaches struggle with merging the modeled behavior of the
input process models into a conﬁgurable process model. the other two approaches that
directly discover a conﬁgurable process model from the event log seem to be able to
use the recorded behavior to better generalize the behavior into a conﬁgurable process
model. the approach where both the control ﬂow and the conﬁguration options are
changed together seems to have more ﬂexibility than the approach where ﬁrst a control
ﬂow is discovered which is then conﬁgured.
using the results presented in this paper we can improve model merging techniques
by considering the actual intended behavior instead of the process model structure. we
also plan to develop more sophisticated techniques for the etm-algorithm to directly
mine conﬁgurable models from collections of event logs. for example, we plan to add
conﬁguration-speciﬁc mutation operators and learn good parameter settings (using large
collections of real-life event logs from the coselog project). moreover, we plan to
consider other perspectives (e.g., data-, resource- and time-related aspects) and further
develop the new area of cross-organizational mining [6]. the ultimate goal is to support
organizations in selecting a suitable conﬁguration based on their recorded behavior.
references
1. w.m.p. van der aalst. process mining: discovery, conformance and enhancement of busi-
ness processes . springer, 2011.
2. w.m.p. van der aalst, a. adriansyah, and b. van dongen. replaying history on process
models for conformance checking and performance analysis. wires data mining and
knowledge discovery , 2(2):182–192, 2012.3. a. adriansyah, b. van dongen, and w.m.p. van der aalst. conformance checking using
cost-based fitness analysis. in proceedings of edoc , pages 55–64. ieee computer soci-
ety, 2011.
4. j¨org becker, patrick delfmann, alexander dreiling, ralf knackstedt, and dominik kuropka.
conﬁgurative process modeling–outlining an approach to increased business process
model usability. in proceedings of the 15th irma international conference , 2004.
5. j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst. on the role of fitness, preci-
sion, generalization and simplicity in process discovery. in proceedings of coopis , lncs.
springer, 2012.
6. j.c.a.m buijs, b.f. van dongen, and w.m.p. van der aalst. towards cross-organizational
process mining in collections of process models and their executions. in business process
management workshops , pages 2–13. springer, 2012.
7. j.c.a.m. buijs, m. la rosa, h.a. reijers, b.f. dongen, and w.m.p. van der aalst. im-
proving business process models using observed behavior. in proceedings of the second
international symposium on data-driven process discovery and analysis , lnbip. springer,
2013 (to appear).
8. f. gottschalk, w.m.p. van der aalst, m.h. jansen-vullers, and m. la rosa. conﬁgurable
workﬂow models. international journal of cooperative information systems (ijcis) , 17(2),
2008.
9. f. gottschalk, w.m.p. van der aalst, and m.h. jansen-vullers. merging event-driven process
chains. in otm 2008, part i, coopis 2008 , volume 5331 of lecture notes in computer
science , pages 418–426, berlin heidelberg, 2008. springer verlag.
10. f. gottschalk, w.m.p. van der aalst, and m.h. jansen-vullers. mining reference process
models and their conﬁgurations. in otm 2008 workshops , volume 5333 of lecture notes
in computer science , pages 263–272, berlin heidelberg, 2008. springer verlag.
11. alena hallerbach, thomas bauer, and manfred reichert. capturing variability in business
process models: the provop approach. journal of software maintenance , 22(6-7):519–546,
2010.
12. m. la rosa, m. dumas, r. uba, and r. dijkman. business process model merging: an
approach to business process consolidation. acm transactions on software engineering
and methodology , 22(2), 2012.
13. c. li, m. reichert, and a. wombacher. the minadept clustering approach for discover-
ing reference process models out of process variants. international journal of cooperative
information systems , 19(3-4):159–203, 2010.
14. j. mendling, h.m.w. verbeek, b.f. van dongen, w.m.p. van der aalst, and g. neumann.
detection and prediction of errors in epcs of the sap reference model. data and knowl-
edge engineering , 64(1):312–329, 2008.
15. m. la rosa, f. gottschalk, m. dumas, and w.m.p. van der aalst. linking domain models
and process models for reference model conﬁguration. in j. becker and p. delfmann,
editors, informal proceedings of the 10th international workshop on reference modeling
(refmod 2007) , pages 13–24. qut, brisbane, australia, 2007.
16. m. rosemann and w.m.p. van der aalst. a conﬁgurable reference modeling language.
information systems , 32(1):1–23, 2007.
17. d. schunselaar, e. verbeek, w.m.p. van der aalst, and h. reijers. creating sound and
reversible conﬁgurable process models using cosenets. in w. abramowicz, d. kriksciu-
niene, and v . sakalauskas, editors, business information systems (bis 2012) , volume 117 of
lnbip , pages 24–35. springer, 2012.
18. h. m. w. verbeek, j. c. a. m. buijs, b. f. van dongen, and w. m. p. van der aalst. xes,
xesame, and prom 6. in information system evolution , volume 72, pages 60–75. springer,
2011.