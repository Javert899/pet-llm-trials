discovery of frequent episodes in event logs
maikel leemans and wil m.p. van der aalst
m.leemans@tue.nl,w.m.p.v.d.aalst@tue.nl
eindhoven university of technology,
p.o. box 513, 5600 mb, eindhoven, the netherlands.
abstract. lion's share of process mining research focuses on the discov-
ery of end-to-end process models describing the characteristic behavior
of observed cases. the notion of a process instance (i.e., the case) plays
an important role in process mining. pattern mining techniques (such as
traditional episode mining, i.e., mining collections of partially ordered
events) do not consider process instances. in this paper, we present a
new technique (and corresponding implementation) that discovers fre-
quently occurring episodes in event logs, thereby exploiting the fact that
events are associated with cases. hence, the work can be positioned in-
between process mining and pattern mining. episode discovery has its
applications in, amongst others, discovering local patterns in complex
processes and conformance checking based on partial orders. we also
discover episode rules to predict behavior and discover correlated behav-
iors in processes, and apply our technique to other perspectives present
in event logs. we have developed a prom plug-in that exploits ecient
algorithms for the discovery of frequent episodes and episode rules. ex-
perimental results based on real-life event logs demonstrate the feasibility
and usefulness of the approach.
keywords: episode discovery, partial order discovery, process dis-
covery
1 introduction
process mining provides a powerful way to analyze operational processes based
on event data. unlike classical purely model-based approaches (e.g., simulation
and verication), process mining is driven by \raw" observed behavior instead
of assumptions or aggregate data. unlike classical data-driven approaches, pro-
cess mining is truly process-oriented and relates events to high-level end-to-end
process models [1].
in this paper, we use ideas from episode mining [2] and apply these to the
discovery of partially ordered sets of activities in event logs .event logs serve as
the starting point for process mining. an event log can be viewed as a multiset
oftraces [1]. each trace describes the life-cycle of a particular case (i.e., a process
instance ) in terms of the activities executed. often event logs store additional
information about events, e.g., the resource (i.e., the person or device) executing
or initiating the activity, the timestamp of the event, or data elements (e.g., cost
or involved products) recorded with the event.2 discovery of frequent episodes in event logs
each trace in the event log describes the life-cycle of a case from start to
completion. hence, process discovery techniques aim to transform these event
logs into end-to-end process models . often the overall end-to-end process model
is rather complicated because of the variability of real life processes. this results
in \spaghetti-like" diagrams. therefore, it is interesting to also search for more
local patterns in the event log { using episode discovery { while still exploiting
the notion of process instances. another useful application of episode discovery
is discovering patterns while using other perspectives also present the event log.
lastly, we can use episode discovery as a starting point for conformance checking
based on partial orders [3].
since the seminal papers related to the apriori algorithm [4, 5, 6], many
pattern mining techniques have been proposed. these techniques do not con-
sider the ordering of events [4] or assume an unbounded stream of events [5, 6]
without considering process instances. mannila et al. [2] proposed an extension
of sequence mining [5, 6] allowing for partially ordered events. an episode is a
partially ordered set of activities and it is frequent if it is \embedded" in many
sliding time windows. unlike in [2], our episode discovery technique does not
use an arbitrary sized sliding window. instead, we exploit the notion of process
instances. although the idea is fairly straightforward, as far as we know, this
notion of frequent episodes was never applied to event logs.
numerous applications of process mining to real-life event logs illustrate that
concurrency is a key notion in process discovery [1, 7, 8]. one should avoid show-
ing all observed interleavings in a process model. first of all, the model gets too
complex (think of the classical \state-explosion problem"). second, the result-
ing model will be overtting (typically one sees only a fraction of the possible
interleavings). this makes the idea of episode mining particularly attractive.
the remainder of this paper is organized as follows. section 2 positions the
work in existing literature. the novel notion of episodes and the corresponding
rules are dened in section 3. section 4 describes the algorithms and correspond-
ing implementation in the process mining framework prom , available through
theepisode miner package [9]. the approach and implementation are evaluated
in section 5 using several publicly available event logs. section 6 concludes the
paper.
2 related work
the notion of frequent episode mining was rst dened by mannila et al. [2].
in their paper, they applied the notion of frequent episodes to (large) event se-
quences. the basic pruning technique employed in [2] is based on the frequency
of episodes in an event sequence. mannila et al. considered the mining of se-
rial and parallel episodes separately, each discovered by a distinct algorithm.
laxman and sastry improved on the episode discovery algorithm of mannila by
employing new frequency calculation and pruning techniques [10]. experiments
suggest that the improvement of laxman and sastry yields a 7 times speedup
factor on both real and synthetic datasets.
related to the discovery of episodes or partial orders is the discovery of end-
to-end process models able to capture concurrency explicitly. the algorithmdiscovery of frequent episodes in event logs 3
[11] was the rst process discovery algorithm adequately handling concurrency.
several variants of the algorithm have been proposed [12, 13]. many other dis-
covery techniques followed, e.g., heuristic mining [14] able to deal with noise and
low-frequent behavior. the heuristicsminer is based on the notion of causal nets
(c-nets). moreover, completely dierent approaches have been proposed, e.g.,
the dierent types of genetic process mining [15, 16], techniques based on state-
based regions [17, 18], and techniques based on language-based regions [19, 20]. a
frequency-based approach is used in the fuzzy mining technique, which produces
a precedence-relation-based process map [21]. frequencies are used to lter out
infrequent paths and nodes. another, more recent, approach is inductive process
mining where the event log is split recursively [22]. the latter technique always
produces a block-structured and sound process model. all the discovery tech-
niques mentioned are able to uncover concurrency based on example behavior
in the log. additional feature comparisons are summarized in table 1. based on
the above discussion we conclude that episode discovery is the only technique
whose results focus on local behavior while exploiting process instances.
table 1. feature comparison of discussed discovery algorithms
exploits process instancesdiscovers end-to-end modelfocus onlocalbehavior
soundness guaranteedsequencechoiceconcurrencysilent (tau) transitionsduplicate activities
agrawal, sequence mining [4] - - - n.a. + - - - -
manilla, episode mining [2] - - + n.a. + - + - -
leemans m., episode discovery + - + n.a. + - + - +
maggi, declare miner [23, 24, 25] + +/- - n.a. + + + - +
van der aalst, -algorithm [11] + + - - + + + - -
weijters, heuristics mining [14] + + - - + + + - -
de medeiros, genetic mining [15, 16] + + - - + + + + +
sol e, state regions [17, 18] + + - - + + + - -
bergenthum, language regions [19, 20] + + - - + + + - -
g unther, fuzzy mining [21] + + - n.a. + +/- +/- - -
leemans s.j.j., inductive [22] + + - + + + + + -
the discovery of declarative process models, as presented in [23, 24, 25], aims
to discover patterns to describe an overall process model. the underlying model
is the declare declarative language. this language uses ltl templates that
can be used to express rules related to the ordering and presence of activities.
this discovery technique requires the user to limit the constraint search-space by
selecting rule templates to search for. that is, the user selects a subset of pattern
types (e.g., succession, not-coexists, etc.) to search for. however, the underly-
ing discovery technique is pattern-agnostic, and simply generates all pattern
instantiations (using apriori-based optimization techniques), followed by ltl4 discovery of frequent episodes in event logs
evaluations. the major downside of this approach is a relatively bad runtime
performance, and we will also observe this in section 5.4.
the discovery of patterns in the resource perspective has been partly tack-
led by techniques for organizational mining [26]. these techniques can be used
to discover organizational models and social networks. a social network is a
graph/network in which the vertices represent resources (i.e., a person or device),
and the edges denote the relationship between resources. a typical example is
the handover of work metric. this metric captures that, if there are two subse-
quent events in a trace, which are completed by resource aandbrespectively,
then it is likely that there is a handover of work from atob. in essence, the
discovery of handover of work network yields the \end-to-end" resource model,
related to the discovery of episodes or partial orders on the resource perspective.
the episode mining technique presented in this paper is based on the discov-
ery of frequent item sets. a well-known algorithm for mining frequent item sets
and association rules is the apriori algorithm by agrawal and srikant [4]. one
of the pitfalls in association rule mining is the huge number of solutions. one
way of dealing with this problem is the notion of representative association rules,
as described by kryszkiewicz [27]. this notion uses user specied constraints to
reduce the number of `similar' results. both sequence mining [5, 6] and episode
mining [2] can be viewed as extensions of frequent item set mining.
3 denitions: event logs, episodes, and episode rules
this section denes basic notions such as event logs, episodes and rules. note
that our notion of episodes is dierent from the notion in [2] which does not
consider process instances.
3.1 preliminaries
multisets multisets are used to describe event logs where the same trace may
appear multiple times.
we denote the set of all multisets over some set aasb(a). we dene b(a)
for some multiset b2b(a) as the number of times element a2aappears in
multisetb. for example, given a=fx;y;zg, a possible multiset b2b(a) is
b= [x;x;y ]. for this example, we have b(x) = 2,b(y) = 1 andb(z) = 0. the
sizejbjof a multiset b2b(a) is the sum of appearances of all elements in the
multiset, i.e.:jbj=a2ab(a).
note that the ordering of elements in a multiset is irrelevant.
sequences sequences are used to represent traces in an event log.
given a set x, a sequence over xof lengthnis denoted as =ha1;a2;:::;ani2
x. we denote the empty sequence as hi.
note that the ordering of elements in a sequence is relevant.
functions given sets xandy, we write f:x7!yfor the function with
domain domfxand range ranf=ff(x)jx2xgy. in this context,
the7!symbol is used to denote a specic function.discovery of frequent episodes in event logs 5
as an example, the function f:n7!ncan be dened as f=fx7!x+ 1jx2ng.
for thisfwe have, amongst others, f(0) = 1 and f(1) = 2 (i.e., this fdenes
a succession relation on n).
3.2 event logs
activities and traces letauabe the alphabet of activities occurring in the
event log. a trace is a sequence =ha1;a2;:::;ani2aof activities ai2a
occurring at time index irelative to the other activities in .
event log an event log l2b(a) is a multiset of traces. note that the same
trace may appear multiple times in an event log. each trace corresponds to an
execution of a process, i.e., a case orprocess instance . in this simple denition
of an event log, an event refers to just an activity . often event logs store addi-
tional information about events, such as the resource (i.e., the person or device)
executing or initiating the activity, and the timestamp of the event.
note that, in this paper, we assumed simple event logs using the default
activity classier, yielding partial orders on activities. it should be noted that
the technique discussed in this paper is classier-agnostic. as a result, using
alternative classiers, partial orders on other perspectives can be obtained. an
example is the ow of work between persons by discovering partial orders using
a resource classier on the event log.
3.3 episodes
episode an episode is a partially ordered collection of events. a partial order
is a binary relation which is reexive, antisymmetric and transitive. episodes
are depicted using the transitive reduction of directed acyclic graphs, where the
nodes represent events, and the edges imply the partial order on events. note
that the presence of an edge implies serial behavior. figure 1 shows the transitive
reduction of an example episode.
formally, an episode = (v;;g) is a triple, where vis a set of events
(nodes),is a partial order on v, andg:v7! a is a left-total function
from events to activities, thereby labeling the nodes/events [2]. for two vertices
u;v2vwe haveu<v iuvandu6=v.
note that ifjvj1, then we got a singleton or empty episode. for the rest
of this paper, we ignore empty episodes. we call an episode parallel when there
are two or more vertices, and no edges.
subepisode and equality an episode = (v0;0;g0) is a subepisode of =
(v;;g), denoted, i there is an injective mapping f:v07!vsuch that:
(8v2v0:g0(v) =g(f(v))) all vertices in are also in
^(8v;w2v0^v0w:f(v)f(w)) all edges in are also in
an episode equals episode , denotedi^. an episode 
is a strict subepisode of , denoted, i^6.6 discovery of frequent episodes in event logs
a
(a1)
b
(b)c
(c)a
(a2)
d
(d)
fig. 1. shown is the transitive reduction of the partial order for an example episode.
the circles represent nodes (events), with the activity labeling imposed by ginside the
circles, and an event id beneath the nodes in parenthesis. in this example, events a1
andbcan happen in parallel (as can a2andd). however, event ccan only happen
after both an a1and abhave occurred, and a2anddcan only happen after an c
has occurred.
episode construction two episodes = (v;;g) and= (v0;0;g0) can be
`merged' to construct a new episode = (v00;00;g00).is a smallest (i.e.,
smallest sets v00and00) such that and.
the smallest sets criterion implies that every event v2v00and ordered pair
v;w2v00^v00wmust be represented in and/or(i.e., have a witness, see
also the formulae below). formally, an episode =i there exists injective
mappingsf:v7!v00andf0:v07!v00such that:
= (v00;00;g00)
00=f(f(v);f(w))j(v;w)2 g
[f(f0(v);f0(w))j(v;w)2 0g order witness
g00: (8v2v:g(v) =g00(f(v)))^(8v02v0:g0(v0) =g00(f0(v0))) correct mapping
v00:8v002v00: (9v2v:f(v) =v00)_(9v02v0:f0(v0) =v00) node witness
observe that \order witness" and \correct mapping" are based on and
. note that via \note witness" it is ensured that every vertex in v00is
mapped to a vertex in either vorv0. every vertex in vandv0should be
mapped to a vertex in v00. this is ensured via \correct mapping".
occurrence an episode = (v;;g) occurs in an event trace =ha1;a2;:::;ani,
denotedv, i there exists an injective mapping h:v7!f1;::;ngsuch that:
(8v2v:g(v) =ah(v)2) all vertices are mapped correctly
^(8v;w2v^vw:h(v)h(w)) the partial order is respected
in figure 2 an example of an \event to trace map" hfor occurrence checking is
given. note that multiple mappings might exists. intuitively, if we have a trace
tand an episode with uv, then the activity g(u) must occur before activity
g(v) int.discovery of frequent episodes in event logs 7
event indices:
episode:trace:
a (a1)
b
(b)c
(c)a(a2)
d
(d)a1
b2
a3
c4
a5
d6
mapping 1a (a1)
b
(b)c
(c)a(a2)
d
(d)a1
b2
a3
c4
a5
d6
mapping 2
fig. 2. shown are two possible mappings h(the dotted arrows) for checking occurrence
of the example episode in a trace. the shown graphs are the transitive reduction of
the partial order of the example episode. note that with the left mapping ( mapping 1 )
also an episode with the partial order a1< b occurs in the given trace, in the right
mapping ( mapping 2 ) the same holds for an episode with the partial order b<a 1.
frequency the frequency freq() of an episode in an event log l2b(a) is
dened as:
freq() =j[2ljv]j
jlj
given a frequency threshold minfreq , an episode is frequent i freq()
minfreq . during the actual episode discovery, we use the contrapositive of the
fact given in lemma 1. that is, we use the observation that if not all subepisodes
are frequent, then the episode is also not frequent.
lemma 1 (frequency and subepisodes). if an episode is frequent in an
event logl, then all subepisodes withare also frequent in l. formally,
we have for a given :
(8:freq()freq())
3.4 episode and event log measurements
activity frequency the activity frequency actfreq (a) of an activity a2ain an
event logl2b(a) is dened as:
actfreq (a) =j[2lja2]j
jlj
given a frequency threshold minactfreq , an activity ais frequent i actfreq (a)
minactfreq .8 discovery of frequent episodes in event logs
trace distance given episode = (v;;g) occurring in an event trace =
ha1;a2;:::;ani, as indicated by an event to trace map h:v7!f1;::;ng. then
the trace distance tracedist (;h) is dened as:
tracedist (;h) = maxfh(v)jv2vg minfh(v)jv2vg
in figure 2, the left mapping h1yields tracedist (;h1) = 6 1 = 5, and the
right mapping h2yields tracedist (;h2) = 6 2 = 4.
given a trace distance interval [ mintracedist ;maxtracedist ], an episode 
is accepted in trace with respect to the trace distance interval i there exists
a mapping hsuch that mintracedisttracedist (;h)maxtracedist .
informally, the conceptual idea behind a trace distance interval is that we
are interested in a partial order on events occurring relatively close in time.
eventually-follows relation the eventually-follows relation lfor an event log
land two activities a;b2ais dened as:
alb=
2l90i<j<jj:(i) =a^(j) =b	
informally, the eventually-follows valuation for albequals the amount
of traces in which ahappens (at timestamp i), and is followed by bat a later
moment (at timestamp jwithi<j ).
if we evaluate the eventually-follows relation for every a;b2a, we obtain
the eventually-follows matrix. in table 2 the eventually-follows matrix is given
for an example event log.
table 2. the eventually-follows matrix for the following example event log:
l= [ha;b;a;c;a;di;ha;b;a;di;hb;di]. each cell gives the valuation for rowlcolumn ,
where rowis the activity shown to the left, and column is the activity shown on the
top of the table.
la b c d
a2 2 1 2
b2 0 1 3
c1 0 0 1
d0 0 0 0
lemma 2 (eventually-follows relation and episode frequency).
the eventually-follows valuation g(u)lg(v)for any two vertices u;v2v
withuvis an upper bound for the frequency of the episode = (v;;g)in
event logl. formally:
(8u;v2v^uv:g(u)lg(v)
jljfreq())
consequently, if an episode = (v;;g)is frequent in an event log l, then
for any two vertices u;v2vwithuvalso the eventually follows valuation
forg(u)lg(v)is frequent.discovery of frequent episodes in event logs 9
based on lemma 2, the eventually-follows relation can be used as a fast
approximation of early occurrence checking. concretely, by contraposition, we
know that if there exists u;v2vwithuvfor whichg(u)lg(v)
jlj<minfreq ,
then the episode cannot be frequent. we use this fact as an optimization
technique in the realization of our episode discovery technique.
3.5 episode rules
episode rule an episode rule is an association rule )withstating
that after seeing , then likely the larger episode will occur as well.
the condence of the episode rule )is given by:
conf()) =freq()
freq()
given a condence threshold minconf , an episode rule )is valid i
conf())minconf . during the actual episode rule discovery, we use
lemma 3.
lemma 3 (condence and subepisodes). if an episode rule )is valid
in an event log l, then for all episodes 0with0the event rule 0)
is also valid in l. formally:
(80:conf())conf(0)))
episode rule magnitude let the graph size size() of an episode be denoted
as the sum of the nodes and edges in the transitive reduction of the episode. the
magnitude of an episode rule is dened as:
mag()) =size()
size()
intuitively, the magnitude of an episode rule )represents how much
episode`adds to' or `magnies' episode . the magnitude of an episode rule
allows smart ltering on generated rules. typically, an extremely low (approach-
ing zero) or high (approaching one) magnitude indicates a trivial episode rule.
4 realization
the denitions and insights provided in the previous section have been used to
implement an episode (rule) discovery plug-in in the process mining framework
prom , available through the episode miner package [9]. to be able to analyze
real-life event logs, we need ecient algorithms. these are described next.10 discovery of frequent episodes in event logs
4.1 notation in realization
in the listed algorithms, we will reference to the elements of an episode =
(v;;g) as:v,:and:g.
for the implementation, we rely on ordered sets, i.e., lists of unique elements.
the order of a set is determined by the order in which elements are added to the
sets, which is leveraged to make the algorithms ecient. we assume individual
elements can be accessed via an index, with indexing starting at zero. we use
the following operations and notations in the algorithms to come:
a=fx;y;zgwithx<y<z note:n=jaj= 3
a[0] =x access the rst element
a[n 1] =z access the last element
(a[fvg) =fx;y;z;vgwithx<y<z<v adding new elements to a set
(a[fxg) =a every element is unique
(a[fvg)[n] =v access the new last element
a[0::n 2] =fx;ygwithx<y access a subset of a set
4.2 frequent episode discovery
discovering frequent episodes is done in two phases. the rst phase discovers
parallel episodes (i.e., nodes only); the second phase discovers partial orders (i.e.,
adding the edges). the main routine for discovering frequent episodes is given
in algorithm 1.
algorithm 1: episode discovery
input: an event log l, an activity alphabet a, a frequency threshold minfreq .
output: a set of frequent episodes  
description: two-phase episode discovery. each phase alternates between recognizing
frequent candidates in the event log ( fl), and generating new candidate episodes ( cl).
proof of termination: note that candidate episode generation with fl=;will yield
cl=;. since each iteration the generated episodes become strictly larger (in terms of v
and), eventually the generated episodes cannot occur in any trace. therefore, always
eventuallyfl=;, and thus we will always terminate.
episodediscovery (l;a;minfreq )
(1) =;
(2) // phase 1: discover parallel episodes
(3)l= 1// tracks the number of nodes
(4) // initialize: create a candidate episode for every activity in a
(5)cl=f(v;;g)jjvj= 1;=;; g=fv7!ag; v2v; a2ag
(6) // step: recognize and construct larger episodes from smaller episodes
(7) whilecl6=;
(8) fl=recognizefrequentepisodes (l;cl;minfreq )
(9)  = [fl
(10) cl=generatecandidateparallel (l;fl)
(11) l=l+ 1
(12) // phase 2: discover partial orders
(13)l= 1// tracks the number of edges
(14) // initialize: create candidate episodes based on results from phase 1
(15)cl=f(:v;;:g)j2 ;=f(v;w)g; v;w2:v; v6=wg
(16) // step: recognize and construct larger episodes from smaller episodes
(17) whilecl6=;
(18) fl=recognizefrequentepisodes (l;cl;minfreq )
(19)  = [fl
(20) cl=generatecandidateorder (l;fl)
(21) l=l+ 1
(22) return discovery of frequent episodes in event logs 11
4.3 episode candidate generation
the generation of candidate episodes for each phase is an adaptation of the well-
known apriori algorithm over an event log. given a set of frequent episodes fl,
we can construct a candidate episode by combining two partially overlapping
episodesandfromfl. note that this implements the episode construction
operation=.
for phase 1, we have flcontains frequent episodes with lnodes and no edges.
a candidate episode will havel+1 nodes, resulting from episodes andthat
overlap on the rst l 1 nodes. this generation is implemented by algorithm 2.
for phase 2, we have flcontains frequent episodes with ledges. a candidate
episodewill havel+ 1 edges, resulting from episodes andthat overlap on
the rstl 1 edges and have the same set of nodes. this generation is imple-
mented by algorithm 3. note that, formally, the partial order is the transitive
closure of the set of edges being constructed.
algorithm 2: candidate episode generation { parallel
input: a set of frequent episodes flwithlnodes.
output: a set of candidate episodes cl+1withl+ 1 nodes.
description: generates candidate episodes by merging overlapping episodes and(i.e.,
=). for parallel episodes, overlapping means: sharing l 1 nodes.
generatecandidateparallel (l;fl)
(1)cl+1=;
(2) fori= 0tojflj 1
(3) forj=itojflj 1
(4) =fl[i]
(5) =fl[j]
(6) // check if andoverlap (see also description, index start at 0)
(7) if80il 2 ::g(:v[i]) =:g(:v[i])
(8) // create candidate =
(9) = (v;;g)wherev= (:v[0::l 1][:v[l 1]);=;; g=:g[:g
(10) cl+1=cl+1[fg
(11) else
(12) break
(13) returncl+1
algorithm 3: candidate episode generation { partial order
input: a set of frequent episodes flwithledges.
output: a set of candidate episodes cl+1withl+ 1 edges.
description: generates candidate episodes by merging overlapping episodes and(i.e.,
=). for partial order episodes, overlapping means: sharing all nodes and l 1 edges.
generatecandidateorder (l;fl)
(1)cl+1=;
(2) fori= 0tojflj 1
(3) forj=i+ 1tojflj 1
(4) =fl[i]
(5) =fl[j]
(6) // check if andoverlap (see also description, index start at 0)
(7) sharingallnodes = (:v=:v^:g=:g)
(8) overlappingedges = (:[0::l 2] =:[0::l 2])
(9) ifsharingallnodes ^overlappingedges
(10) // create candidate =
(11) = (:v;;:g)where= (:e[0::l 1][:e[l 1])
(12) cl+1=cl+1[fg
(13) else
(14) break
(15) returncl+112 discovery of frequent episodes in event logs
4.4 frequent episode recognition
in order to check if a candidate episode is frequent, we check if freq()
minfreq . the computation of freq() boils down to counting the number of
traceswithv. algorithm 4 recognizes all frequent episodes from a set
of candidate episodes using the above described approach. note that for both
parallel and partial order episodes we can use the same recognition algorithm.
recall that an event log is a multiset of traces. based on this observation, we
note that particular trace variants typically occur more than once in an event
log. we use this fact to reduce the number of iterations in algorithm 4, and
consequently the number of occurrence checks performed (i.e., occurs () in-
vocations). instead of iterating over all the process instances on line 2 of the
algorithm, we consider each trace variant only once. for the support count we
use thel() multiset operation to get the correct number of process instances.
algorithm 4: recognize frequent episodes
input: an event log l, a set of candidate episodes cl, a frequency threshold minfreq .
output: a set of frequent episodes fl
description: recognizes frequent episodes, by ltering out candidate episodes that do not occur
frequently in the log.
note: iffl=;, thencl=;.
recognizefrequentepisodes (l;cl;minfreq )
(1) support = [0;:::; 0]withjsupportj=jclj
(2) foreach2l
(3) fori= 0tojclj 1
(4) ifoccurs (cl[i];)then support [i] =support [i] +l()
(5)fl=;
(6) fori= 0tojclj 1
(7) ifsupport [i]
jljminfreq thenfl=fl[fcl[i]g
(8) returnfl
checking whether an episode occurs in a trace =ha1;a2;:::;aniis done
via checking the existence of the mapping h::v7!f1;::;ng. this results
in checking the two propositions shown below. algorithm 5 implements these
checks.
{checking whether each node v2:vhas a unique witness in trace .
{checking whether the (injective) mapping hrespects the partial order indi-
cated by:.
for the discovery of an injective mapping hfor a specic episode and trace
we use the following recipe. first, we declare the class of models h:a7!p (n)
such that for each activity a2awe get the set of indices iat whicha=ai2.
next, we try all possible models derivable from h. a modelh::v7!f1;::;ng
is derived from hby choosing an index i2h(f(v)) for each node v2:v. with
such a model h, we can perform the actual partial order check against :.discovery of frequent episodes in event logs 13
algorithm 5: occurrence checking for an episode
input: an episode , a trace.
output: true iv
description: implements occurrence checking based on nding an occurrence proof in the form of
a mappingh::v7!f1;::;ng.
occurs (= (v;;g);)
(1) // hindicates for each activity aall the indices iat whicha=ai2
(2)h=fa7!fija=ai2gja2ag
(3)h=;
(4) return checkmodel (;h;h )
algorithm 6: this algorithm implements occurrence checking via recursive
discovery of the injective mapping has per the occurrence denition.
input: an episode , a class of mappings h:a 7! p (n), and an intermediate map-
pingh::v7!f1;::;ng.
output: true i there is a mapping h, as per the occurrence denition, derivable from h
description: recursive implementation for nding hbased on induction to the number of mapped
vertices:
base case ( if-part): every v2vis mapped ( v2domh).
step case ( else-part): (ih) nvertices are mapped, step by adding a mapping for a vertex v =2domh.
checkmodel (= (v;;g);h;h )
(1) if8v2v:v2domh
(2) // everyv2vis mapped, check the edge relation
(3) return (8(v;w)2:h(v)h(w))
(4) else
(5) // choose a mapping for a vertex v =2domh
(6) pickv2vwithv =2domh
(7) // compute9i2h(g(v)) :checkmodel (vmapped toi)
(8) exists =false
(9) foreachi2h(g(v))doexists_checkmodel (;h[g(v)7!h(g(v))nfig];h[v7!i])
(10) returnexists
4.5 time complexity analysis
the theoretical time complexity of the provided algorithms is dominated by two
aspects: 1) the apriori-style iterations in algorithm 1, and 2) the occurrence
checking in algorithm 6. for the worst case time complexity we will rst investi-
gate the occurrence checking, and then briey display the total time complexity.
analysis of occurence checking (alg 6) consider trace = [a1;a2;:::;an]
and episode with v=fv1;v2;:::;vmg. worst case, m=n.
finding mapping his done by, for each vind aajsuch that the order con-
dition holds. checking the order condition takes o(jj). worst case, we check
mappings in ascending order ( v1!a1;:::v 1!an) where only the last mapping
is valid. hence, we need n! attempts, resulting in worst case complexity o(n!jj).
total time complexity of algorithm 1 the total worst case running time
consists of o(phase1 ) +o(phase2 ), and is given by:
o(tl2jajtl+1
jajtl+1+jljtl
l=1(l 1)!
+tl51
2tl2 1
2tl
l=1tl(tl 1)
l
tl(tl 1)
l
+jlj(tl 1)!
)14 discovery of frequent episodes in event logs
where:tl= maxfjjj2lgis the max trace size in log, jljis the size of
event log (# trace variants), and jajis the size of alphabet (# event classes).
note that, despite the theoretical worst case time complexity, our episode
discovery algorithm is very fast in practice. see also the evaluation in section 5.
4.6 pruning
using the pruning techniques described below, we reduce the number of gener-
ated episodes (and thereby computation time and memory requirements) and l-
ter out uninteresting results. these techniques eliminate less interesting episodes
by ignoring infrequent activities and skipping partial orders on events not occur-
ring relatively close in time. in addition, for pruning based on the antisymmetry
ofand the eventually-follows relation, we leverage the fact that it is cheaper
to prune candidates during generation than to eliminate them via occurrence
checking.
activity pruning based on the frequency of an activity, uninteresting episodes
can be pruned in an early stage. this is achieved by replacing the activity al-
phabetawith the largest set a0 a satisfying (8a2 a0:actfreq (a)
minactfreq ), on line 5 in algorithm 1. this pruning technique allows the episode
discovery algorithm to be more resistant to logs with many infrequent activities,
which are indicative of exceptions or noise. note that, if minactfreq is set too
high, we can end up with a0=;. in this case, no episodes are discovered.
trace distance pruning the pruning of episodes based on a trace distance
interval can be achieved by adding the trace distance interval check to line 3
of algorithm 6. note that if there are two or more interpretations for h, with
one passing and one rejected by the interval check, then we will nd the correct
interpretation thanks to the 9on line 7.
pruning based on the antisymmetry of during candidate generation in
algorithm 3 we can leverage the antisymmetry of . recall that in algorithm 3
we generate candidate episodes from merging episodes andoverlapping
on the rst l 1 edges. if we extend the predicate on line 9 with the check
reverse (:[l 1])=2:we ensure that we don't generate candidate episodes 
that violate the antisymmetry of . (note: reverse ((a;b)) = (b;a).)
pruning based on the eventually-follows relation during seeding the
partial order candidates in algorithm 1 on line 15 we can utilize the eventually-
follows relation as a fast approximation of early occurrence checking. using this
relation, we can extend the predicate on line 15 with the checkalb
jljminfreq ,
wherea=g(v)^b=g(w).
in practice, we pre-calculate the eventually-follows matrix, having a space-
complexity ofjaj2, wherejajthe number of unique activities in the event log.
this allows us to compute the eventually-follows values only once in a linear
scan over the log, and reuse values, accessing them in constant time.discovery of frequent episodes in event logs 15
4.7 episode rule discovery
the discovery of episode rules is done after discovering all the frequent episodes.
for all frequent episodes , we consider all frequent subepisodes with
for the episode rule ).
for eciently nding potential frequent subepisodes , we use the notion of
\discovery tree", based on episode construction. each time we recognize a fre-
quent episode created from combining frequent episodes and", we recognize
as a child of and". similarly, and"are the parents of . see figure 3 for
an example of a discovery tree.
using the discovery tree we can walk from an episode along the discovery
parents of. each time we nd a parent with, we can consider the par-
ents and children of . as a result of lemma 3, we cannot apply pruning in either
direction of the parent-child relation based on the condence conf()). this
is easy to see for the child direction. for the parent direction, observe the dis-
covery tree in figure 3 and . if for episode we would stop before visiting
the parents of , we would never consider (which has ).
this principle of traversing the discovery tree is implemented by algorithm 7.
this implementation uses a discovery front queue for traversing the discovery
tree, similar to the queue used in the breadth-rst search algorithm. the dis-
covery tree is traversed for each discovered episode (each 2 ). hence, we
consider the discovery tree as a partial order on the set  , and use that struc-
ture to eciently nd sets of subsets.
algorithm 7: discovering episode rules
input: a list of episodes  , a condence threshold minconf and a magnitude interval specied by
minmag andmaxmag .
output: a set of valid episode rules r
description: episode rule discovery. for each discovered episode (each 2 ), the discovery tree
is traversed in a breadth-rst search style, searching for candidate episodes yielding episode rules
).
rulediscovery ( ;minconf;minmag;maxmag )
(1)r=;
(2) foreach2 
(3) discovered =;
(4) letfront be an empty fifo queue
(5) foreach parent2:parents
(6) discovered =discovered[fparentg
(7) front:enque (parent )
(8) while front6=;
(9) =front:deque ()
(10) foreach parent2:parents
(11) discovered =discovered[fparentg
(12) front:enque (parent )
(13) if
(14) // prune siblings of 
(15) if =2:parents
(16) foreach child2:children^child=2discovered
(17) discovered =discovered[fchildg
(18) front:enque (child )
(19) ifconf())minconf^minmagmag())maxmag
(20) r=r[f)g16 discovery of frequent episodes in event logs
a
cbc
a
cba
c
ba
c
"
 
fig. 3. part of an example discovery tree. each block denotes an episode. the dashed
arrows between blocks denote a parent-child relationship. in this example we have,
amongst others: ,","and(not shown as a parent-child relation).
4.8 implementation consideration
we implemented the episode discovery algorithm as a prom 6 plug-in (see also
figure 7), written in java. since the occurs () algorithm (5) is the biggest
bottleneck, this part of the implementation was considerably optimized.
5 evaluation
this section reviews the feasibility of the approach using both synthetic and
real-life event data.
5.1 methodology
we used three dierent event logs for our experiment. the rst event log, bigger-
example.xes , is an articial event log from chapter 5 of [1] and available via http:
//www.processmining.org/event_logs_and_models_used_in_book . the sec-
ond and third event logs, bpi challenge 2012.xes andbpi challenge 2013.xes ,
are real life event logs available via doi:10.4121/uuid:3926db30-f712-4394-
aebc-75976070e91f anddoi:10.4121/uuid:500573e6-accc-4b0c-9576-aa54
68b10cee respectively. the experiment consists of two parts: rst a series of tests
focused on performance and the number of discovered episodes, and second, a
case study focused on comparing our technique with existing discovery tech-
niques. for these experiments we used a laptop with a core i7-4700mq cpu
(2.40 ghz), java se runtime environment 1.7.0 67 (64 bit) with 4 gb ram.
5.2 performance and number of discovered episodes
in table 3 some key characteristics of the event logs are given. we examined the
eects of the parameters minfreq ,minactfreq andmaxtracedist on the runningdiscovery of frequent episodes in event logs 17
time, the discovered number of episodes (number of results), and the total num-
ber of intermediate candidate episodes. in figure 7 an indication (screenshots)
of the prom plugin output is given.
table 3. metadata for the used event logs.
events / trace
# traces # variants # activities avg. min. max.
bigger-example.xes 1;391 21 8 5 :42 5 17
bpi challenge 2012.xes (bpic 2012) 13;087 4;366 36 20 :05 3 175
bpi challenge 2013.xes (bpic 2013) 7;554 2;278 13 8 :68 1 123
in figures 4, 5, and 6 the results of the experiments are given.
the metric \# episodes (result)" indicates the size of the end result. this
metric is given by j jin algorithm 1. the metric \# candidate episodes" indi-
cates the size of the intermediate results, after episode construction and pruning,
but before occurrence checking. this metric is calculated by summing jcljacross
iterations in both discovery phases in algorithm 1. the \runtime", indicates the
average running time of the algorithm, and its associated 95% condence inter-
val. note that the scale of the runtime is in milliseconds.
as can be seen in the experimental results, we see that the running time is
strongly related to the discovered number of episodes. note that if some param-
eters are poorly chosen, like high minfreq in figure 4(b), then a relatively large
class of episodes seems to become frequent, thus increasing the running time
dramatically.
for a reasonably low number of frequent episodes ( <500, more will a human
not inspect), the algorithm turns out to be quite fast (under one second). we
noted a virtual nonexistent contribution of the parallel episode mining phase to
the total running time. this can be explained by a simple combinatorial argu-
ment: there are far more partial orders to be considered than there are parallel
episodes. also note the increasing number of candidate episodes in figure 5(b),
which consists solely of parallel episodes, but there is no signicant change in
the runtime.
an analysis of the eects of changing the minfreq parameter (figure 4(a),
4(b), and 4(c)) shows that a poorly chosen value results in many episodes. in
addition, the minfreq parameter gives us ne-grained control of the number of
results. it gradually increases the total number of episodes for lower values. note
that, especially for the bpic 2012 event log, low values for minfreq can dramat-
ically increase the running time. this is due to the large number of (candidate)
episodes being generated.
secondly, note that for the minactfreq parameter (figure 5(a), 5(b), and 5(c)),
there seems to be a cuto point that separates frequent from infrequent activi-
ties. small changes around this cuto point may have a noticeable eect on the
number of episodes discovered.
finally, for the maxtracedist parameter (figure 6(a), 6(b), and 6(c)), we see
that this parameter seems to have a sweet-spot where a low { but not too low {18 discovery of frequent episodes in event logs
number of episodes are discovered. chosen a value for maxtracedist just after
this sweet-spot yields a large number of episodes.
when comparing the articial and real life event logs, we see a remarkable
pattern. the articial event log ( bigger-example.xes ), shown in figure 4(a) ap-
pears to be far more ne-grained than the real life event log ( bpic 2012 ) shown
in figure 4(b) and 4(c). in the real life event log there appears to be a clear
distinction between frequent and infrequent episodes. in the articial event log
a more ne-grained pattern occurs. most of the increase in frequent episodes,
for decreasing minfreq , is again in the partial order discovery phase.
table 4. case study results { comparison of discovered sub-patterns per discovery
algorithm. in the top part of this table, an x in two consecutive rows aandbindicate
a sub-pattern ab. in the bottom part of this table, a + indicates the corresponding
patterns was revealed by the corresponding discovery algorithm output.
activities
and pattern8
>>>>><
>>>>>:asubmitted+complete x
apartlysubmitted+complete x x x
apreaccepted+complete x x
wcomplementeren aanvraag+schedule x x
wcomplementeren aanvraag+start x
adeclined+complete x
discovery
algorithms8
>>><
>>>:episode discovery + + + + +a
-algorithm [11] +
heuristics miner [14] + + +
inductive miner [22] + +b+b+ +b
declare miner [23] + +c+ + +c
aindicates the pattern was revealed, but only after increasing maxtracedist .
bindicates the pattern was revealed, but obfuscated by choice constructs.
cdue to the aggregated overview of the declare model, it is not immediately clear
that these patterns are disjoint.
5.3 case study { pattern discovery compared with existing
algorithms
as noted in the introduction, often the overall end-to-end process models are
rather complicated. therefore, the search for local patterns (i.e., episodes) is
interesting. in this section we perform a short case study using the bpi chal-
lenge 2012, an event log of a loan application process. we explored this event
log using: the -algorithm [11], heuristics miner [14], inductive miner [22], de-
clare miner [23], and our episode discovery technique. for this case study,
we assume no prior knowledge about this event log. instead, we want to get ini-
tial insight into the recorded behavior, and are interested in the most important
patterns. for all the algorithms we use the default parameter settings and the
\activity classier" dened in the event log (the default values are provided indiscovery of frequent episodes in event logs 19
-50510152025
0100200300400500600700
1 0,95 0,9 0,85 0,8 0,75 0,7 0,65 0,6 0,55 0,5 0,45 0,4 0,35 0,3 0,25 0,2 0,15 0,1 0,05
time (ms) [95% conf. interval]  # episodes  
minfreq  bigger -example.mxml -- minfreq  
# episodes (results) # candidate episodes runtime
(a) event log: bigger-example.mxml , minactfreq = 1:0,maxtracedist = 4
01000200030004000500060007000
05001000150020002500
1 0,95 0,9 0,85 0,8 0,75 0,7 0,65 0,6 0,55 0,5 0,45 0,4 0,35 0,3 0,25 0,2 0,15 0,1 0,05
time (ms) [95% conf. interval]  # episodes  
minfreq  bpi challenge 2012 -- minfreq  
# episodes (results) # candidate episodes runtime
(b) event log: bpi challenge 2012 , minactfreq = 1:0,maxtracedist = 4
050100150200250300350400450
020406080100120140
1 0,95 0,9 0,85 0,8 0,75 0,7 0,65 0,6 0,55 0,5 0,45 0,4 0,35 0,3 0,25 0,2 0,15 0,1 0,05
time (ms) [95% conf. interval]  # episodes  
minfreq  bpi challenge 2013, incidents -- minfreq  
# episodes (results) # candidate episodes runtime
(c) event log: bpi challenge 2013, incidents , minactfreq = 1:0,maxtracedist = 4
fig. 4. eects of the parameter minfreq on the number of results and candidate
episodes. observe that the minfreq parameter gives us ne-grained control of the
number of results. note that for less than 500 result episodes, the runtime is less than
one second.20 discovery of frequent episodes in event logs
01234567
020406080100120140
1 0,95 0,9 0,85 0,8 0,75 0,7 0,65 0,6 0,55 0,5 0,45 0,4 0,35 0,3 0,25 0,2 0,15 0,1 0,05
time (ms) [95% conf. interval]  # episodes  
minactfreq  bigger -example.mxml -- minactfreq  
# episodes (results) # candidate episodes runtime
(a) event log: bigger-example.mxml , minfreq = 0:45,maxtracedist = 4
010203040506070
01020304050607080
1 0,95 0,9 0,85 0,8 0,75 0,7 0,65 0,6 0,55 0,5 0,45 0,4 0,35 0,3 0,25 0,2 0,15 0,1 0,05
time (ms) [95% conf. interval]  # episodes  
minactfreq  bpi challenge 2012 -- minactfreq  
# episodes (results) # candidate episodes runtime
(b) event log: bpi challenge 2012 , minfreq = 0:50,maxtracedist = 4
050100150200250300350
60616263646566676869
1 0,95 0,9 0,85 0,8 0,75 0,7 0,65 0,6 0,55 0,5 0,45 0,4 0,35 0,3 0,25 0,2 0,15 0,1 0,05
time (ms) [95% conf. interval]  minactfreq  
minactfreq  bpi challenge 2013, incidents -- minactfreq  
# episodes (results) # candidate episodes runtime
(c) event log: bpi challenge 2013, incidents , minfreq = 0:45,maxtracedist = 4
fig. 5. eects of the parameter minactfreq on the number of results and candidate
episodes. observe that there seems to be a cuto point that separates frequent from
infrequent activities. note that the runtime is never greater than a third of a second.discovery of frequent episodes in event logs 21
012345678
020406080100120140
0 1 2 3 4 5 6 7 8 9
time (ms) [95% conf. interval]  # episodes  
maxtracedist  bigger -example.mxml -- maxtracedist  
# episodes (results) # candidate episodes runtime
(a) event log: bigger-example.mxml , minfreq = 0:45,minactfreq = 0:65
0102030405060708090
020406080100120140
0 1 2 3 4 5 6 7 8 9
time (ms) [95% conf. interval]  # episodes  
maxtracedist  bpi challenge 2012 -- maxtracedist  
# episodes (results) # candidate episodes runtime
(b) event log: bpi challenge 2012 , minfreq = 0:50,minactfreq = 0:55
050100150200250300350
0102030405060708090
0 1 2 3 4 5 6 7 8 9
time (ms) [95% conf. interval]  # episodes  
maxtracedist  bpi challenge 2013, incidents -- maxtracedist  
# episodes (results) # candidate episodes runtime
(c) event log: bpi challenge 2013, incidents , minfreq = 0:45,minactfreq = 1:00
fig. 6. eects of the parameter maxtracedist on the number of results and candidate
episodes. observe that maxtracedist seems to have a sweet-spot where a low { but not
too low { number of episodes are discovered. note that the runtime is never greater
than a third of a second.22 discovery of frequent episodes in event logs
the footnotes). the observations made below are summarized in table 4. ex-
periments show that only the episode discovery was able to unobfuscated and
unambiguously discover all the mentioned patterns.
episode discovery with our episode discovery technique we get a small overview
of twelve frequent episodes (figure 7(a)). inspecting these episodes more closely,
we nd two frequent patterns: the order asubmitted+complete 
apartlysubmitted+complete apreaccepted+complete , and the order
apreaccepted+complete  wcomplementeren aanvraag+schedule 
wcomplementeren aanvraag+start (figure 7(b)). the interpretation of these
patterns is twofold. one, frequently whenever a loan application is submitted
it either preaccepted or declined. and two, frequently whenever a loan applica-
tion is preaccepted, additional information is requested (\complementeren aan-
vraag"). clearly, we found a simple overview of the most important patterns in
the event log. after increasing the maxtracedist parameter to fty (50), we also
discover the pattern apartlysubmitted+complete adeclined+complete (see
figure 7(c)). in the remaining paragraph, we focus on nding patterns using
other discovery techniques, and we are particularly interested in nding similar
patterns.
-algorithm1figure 8(a) shows the overall petri net model produced by the
-algorithm [11]. closer inspection of the bottom-left part (figure 8(b)) reveals
the sub-pattern asubmitted+complete apartlysubmitted+complete . the
remaining of the previously discovered frequent patterns are not clearly visible
in this model. no other patterns were discovered.
heurisitcs miner2the heuristics net in figure 9(a) is produced by the heuristics
miner [14]. closer inspection of this net (figure 9(b)) reveals two sub-patterns:
the order asubmitted+complete apartlysubmitted+complete , and the
order apreaccepted+complete wcomplementeren aanvraag+schedule 
wcomplementeren aanvraag+start . however, the sub-pattern apartlysubmitted+
completeapreaccepted+complete and apartlysubmitted+complete 
adeclined+complete were not clearly visible in this model. no other patterns
were discovered.
inductive miner3figure 10(a) shows the overall process model (a process tree)
produced by the inductive miner [22]. all frequent patterns can be found in
this model. however, as can be seen in the close-up in figure 10(b), the choice
constructs obfuscate these patterns. after detailed inspection of this model, and
armed with our results from the episode discovery technique, we discovered one
1plugin action: \mine for a petri net using alpha-algorithm".
parameters: n/a
2plugin action: \mine for a heuristics net using heuristics miner".
parameters: activity classier, relative-to-best = 5.0, dependency = 90.0, length-one-loops =
90.0, length-two-loops = 90.0, long distance = 90.0, all tasks connected = on, long distance
dependency = o, ignore loop dependency tresholds = on
3plugin action: \mine process tree with inductive miner".
parameters: variant = inductive miner - infrequent, noise threshold = 0.20, event classier =
event namediscovery of frequent episodes in event logs 23
(a) view of discovered episodes (twelve in total)
(b) the two most interesting episodes
(c) additional pattern, discovered after increasing the maxtracedist parameter to
fty (50).
fig. 7. algorithm: episode discovery. result in prom for the bpic 2012 event log.
(a) overall process model
 (b) zoomed-in on bottom-left part of model
fig. 8. algorithm: -algorithm [11]. result in prom for the bpic 2012 event log.24 discovery of frequent episodes in event logs
(a) overall process model
(b) zoomed-in on the left part of the model
fig. 9. algorithm: heuristics miner [14]. result in prom for the bpic 2012 event log.
less frequent pattern. we rephrase our rst interpretation of the episode dis-
covery results as: \whenever a loan application is submitted it frequently either
preaccepted or declined, or in some rare cases followed by a fraud detection"
(\beoordelen fraude").
(a) overall process model
(b) zoomed-in on the bottom-left part of the model
fig. 10. algorithm: inductive miner [22]. result in prom for the bpic 2012 event log.
declare miner4finally, in figure 11, the declare model is given, as
produced by the declare miner [23]. in this case we did change the fol-
lowing parameters: we chose the succession template and set the min support
to 50 (comparable to the default settings of episode miner). as can be ob-
served, all the frequent patterns can be found. however, note that due to the
aggregated overview of the declare model, it is not immediately clear that
4plugin action: \declare maps miner".
parameters: selected templates = fsuccessiong, all activities (considering event types), min.
support = 50, alpha = 0, control flow = on, time = odiscovery of frequent episodes in event logs 25
the patterns apartlysubmitted+complete apreaccepted+complete and
apartlysubmitted+complete adeclined+complete are disjoint. no other
patterns were discovered.
fig. 11. algorithm: declare miner [23]. result in prom for the bpic 2012 event
log, using the succession template and a min support of 50.
as demonstrated in this case study, and summarized in table 4, overall end-
to-end process models can be rather complicated, and the search for local pat-
terns (i.e., episodes) quickly reveals important insight into recorded behavior.
5.4 case study { runtime compared with existing algorithms
after showing the insights that can be gained by our algorithm, we now compare
the running time of our approach with existing algorithms. we revisit the same
set of algorithms, and investigate the average running time on all three event
logs. the same (default) parameter settings are used as in the previous section
(see footnotes footnotes 1{4).
the resulting running times are compared in figure 12. note that the runtime
is shown in milliseconds, on a logarithmic scale. broadly speaking, the discovery
algorithms can be grouped in three classes, based on their runtime. our episode
miner and the alpha miner form the fastest class of discovery algorithms. next is
the class of algorithms to which the heuristics and inductive miner belong. these
algorithms are roughly ten times slower than the rst class. finally, there is the
class of the declare miner. this algorithm is roughly a hundred times slower than
the rst class.
looking at the dierence between the bpic 2012 and 2013 logs, we see ob-
serve the 2012 log has more event classes (36 for 2012, 13 for 2013), more traces
(13,087 for 2012, 7,554 for 2013), and longer traces (avg. 20.05 for 2012, avg.
8.68 for 2013). this increase in size is directly observable in terms of running
time for the existing algorithms, but has a less eect on the running time of the
episode miner (with default settings).
we conclude that our episode discovery realization is among the fastest of
algorithms. in particular, it is orders of magnitude faster than the declare miner
congured to discover only succession relations.
5.5 case study { episode rules
continuing with our case study of the bpi challenge 2012 event log, we also take
a look at the discovery of association rules. here we use the episode rule genera-
tion feature of our episode discovery prom plugin, and used the default settings.26 discovery of frequent episodes in event logs
 1  10  100  1.000  10.000  100.000  1.000.000episode mineralpha minerheuristics minerinductive minerdeclare miner
runtime (ms) [95% confidence interval], logarithmic scale  running time comparison -- bpic 2012, bpic 2013, bigger -example  
bpi challenge 2012 bpi challenge 2013 bigger-example
fig. 12. comparison of the running time for the dierent discovery algorithms used
in the case study. the runtime is shown in milliseconds, on a logarithmic scale. we
distinguish three classes based on runtimes: 1) our episode miner and the -miner, 2)
the class of algorithms to which the heuristics and inductive miner belong, and 3) the
class of the declare miner.
the result consists of six episode rules, one of which is shown in figure 13.
the interpretation of the shown episode rule is as follows: \if we saw
apartlysubmitted+complete apreaccepted+complete occurring, we likely
will also see wcomplementeren aanvraag+schedule occurring next". in other
words, whenever a partially submitted request was preaccepted, it is likely that
we will request additional information (\complementeren aanvraag").
similar, episode rules can be used in an online setting to predict likely follow-
up activities using episodes discovered in historical data.
fig. 13. episode rules discovered in prom for the bpic 2012 event log. the black solid
line indicates the assumed partial order (the in)), the red dashed line indicates
the added pattern (the ).
5.6 case study { alternative perspective: resources
we conclude our case study of the bpi challenge 2012 event log with mining
patterns in the ow of work between persons. for this we used the resource
classier dened in the event log. we explored this perspective using: the induc-
tive miner [22], handover of work social network miner [26], and our episode
discovery technique.discovery of frequent episodes in event logs 27
the discovered episodes are shown in figure 14. the vertices in these re-
sults represent resources instead of activities. the rst pattern shows that the
resource 112is present in all traces (based on the observation that freq(112112112) =
1:0). furthermore, we also discover that in most cases work is passed from the
resource 112to tasks without a recorded resource (e.g., automated tasks). ac-
tivities conducted by \no recorded resource" can be observed in figure 14 as
empty vertices.
figure 15(a) shows the overall process model (a process tree) for the resource
perspective, produced by the inductive miner [22]. at rst glance no obvious pat-
tern is visible. in the close-up in figure 15(b), the resource 112and \no recorded
resource"/\empty resource" are visible, but no clear patterns are visible.
in figure 15(c) the handover of work social network is given, as produced by
the organizational miner [26]. most of the resources are forming one big tightly-
connected cluster. the \no recorded resource"/\empty resource" is completely
disconnected, but the resource 112is not easily found (it is in the top-left cor-
ner). the patterns found by the episode miner cannot be deduced from this
social network.
by using the resource perspective in combination with episode discovery, we
gained insight into the most important resources, and the ow of work between
resources. this demonstrates that episode discovery is not only useful in the
activity-focused control-ow perspective, but also in other perspectives. while
we only showed pattern discovery in the control-ow and resource domain, other
perspectives are possible. one example is discovering the ow of work between
event locations (e.g., system components or organization departments generating
the events). another example is discovering the relations between data attributes
(e.g., which information is used in which order).
fig. 14. episodes discovered in prom for the bpic 2012 event log, using the resource
classier. in total, forty episodes were discovered. note that the vertices in these results
represent resources instead of activities. the empty vertices indicate the absence of a
recorded resource (e.g., automated tasks).
6 conclusion and future work
in this paper, we considered the problem of discovering frequently occurring
episodes in an event log. an episode is a collection of events that occur in a28 discovery of frequent episodes in event logs
(a) inductive miner:
overall process model
(b) inductive miner: zoomed-in on the
top part of the model
(c) social network model
fig. 15. result in prom for the bpic 2012 event log, using the resource classier.
algorithms: inductive miner [22], handover of work social network miner [26].
given partial order. we presented ecient algorithms for the discovery of fre-
quent episodes and episode rules occurring in an event log, and presented exper-
imental results.
our experimental evaluation shows that, for a reasonably low number of fre-
quent episodes, the algorithm turns out to be quite fast (under one second); typ-
ically faster than existing many algorithms. the main problem is the correct set-
ting of the episode pruning parameters minfreq ,minactfreq , and maxtracedist .
in addition, comparison with existing discovery algorithms has shown the benet
of episode mining in getting insight into recorded behavior. moreover, we have
demonstrated the usefulness of episode rules that can be discovered. finally,
the applicability of episode discovery for other perspectives (like the resources
perspective) was shown.
during the development of the algorithm for prom 6, special attention was
paid to optimizing the occurs () algorithm (algorithm 5) implementation, which
proved to be the main bottleneck. future work could be to prune occurrence
checking based on the parents of an episode, leveraging the fact that an episode
cannot occur in a trace if a parent also did occur in that trace.
another approach to improve the algorithm is to apply the generic divide and
conquer approach for process mining , as dened in [28]. this approach splits the
set of activities into a collection of partly overlapping activity sets. for each ac-
tivity set, the log is projected onto the relevant events, and the regular episode
discovery algorithm is applied. in essence, the same trick is applied as used by the
minactfreq parameter (using an alphabet subset), which is to create a dierent
set of initial 1-node parallel episodes to start discovering with.
the main bottleneck is the frequency computation by checking the occurrence
of each episode in each trace. typically, we have a small amount of episodes to
check, but many traces to check against. using the mapreduce programming
model developed by dean and ghemawat, we can easily parallelize the episodediscovery of frequent episodes in event logs 29
discovery algorithm and execute it on a large cluster of commodity machines
[29]. the mapreduce programming model requires us to dene map andreduce
functions. the map function, in our case, accepts a trace and produces [episode,
trace] pairs for each episode occurring in the given trace. the reduce function
accepts an episode plus a list of traces in which that episode occurs, and outputs
a singleton list if the episode is frequent, and an empty list otherwise. this way,
the main bottleneck of the algorithm can be eectively parallelized.
references
[1] van der aalst, w.m.p.: process mining: discovery, conformance and enhance-
ment of business processes. springer-verlag, berlin (2011)
[2] mannila, h., toivonen, h., verkamo, a.i.: discovery of frequent episodes in
event sequences. data mining and knowledge discovery 1(3) (1997) 259{289
[3] lu, x., fahland, d., van der aalst, w.m.p.: conformance checking based on
partially ordered event data. to appear in business process intelligence 2014,
workshop sbs (2014)
[4] agrawal, r., srikant, r.: fast algorithms for mining association rules in large
databases. in: proceedings of the 20th international conference on very large
data bases. vldb '94, san francisco, ca, usa, morgan kaufmann publishers
inc. (1994) 487{499
[5] agrawal, r., srikant, r.: mining sequential patterns. in: proceedings of the
eleventh international conference on data engineering. icde '95, washington,
dc, usa, ieee computer society (1995) 3{14
[6] srikant, r., agrawal, r.: mining sequential patterns: generalization and
performance improvements. in: proceedings of the 5th international conference
on extending database technology: advances in database technology. edbt
'96, london, uk, uk, springer-verlag (1996) 3{17
[7] lu, x., mans, r.s., fahland, d., van der aalst, w.m.p.: conformance checking
in healthcare based on partially ordered event data. in grau, a., zurawski,
r., eds.: ieee emerging technology and factory automation (etfa 2014),
ieee computer society (2014) 1{8
[8] fahland, d., van der aalst, w.m.p.: model repair: aligning process models to
reality. volume 47. (january 2015) 220{243
[9] leemans, m.: episode miner. https://svn.win.tue.nl/repos/prom/packages/
episodeminer/ [online, accessed 9 januari 2015].
[10] laxman, s., sastry, p.s., unnikrishnan, k.p.: fast algorithms for frequent
episode discovery in event sequences. in: proceedings of the 3rd workshop on
mining temporal and sequential data. sigkdd, seattle, wa, usa, association
for computing machinery, inc. (august 2004)
[11] van der aalst, w.m.p., weijters, a.j.m.m., maruster, l.: workow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering 16(9) (2004) 1128{1142
[12] de medeiros, a.k.a., van der aalst, w.m.p., weijters, a.j.m.m.: workow
mining: current status and future directions. in meersman, r., tari, z., schmidt,
c.d., eds.: on the move to meaningful internet systems 2003: coopis, doa,
and odbase. volume 2888 of lecture notes in computer science. springer
berlin heidelberg (2003) 389{406
[13] wen, l., van der aalst, w.m.p., wang, j., sun, j.: mining process models with
non-free-choice constructs. data mining and knowledge discovery 15(2) (2007)
145{18030 discovery of frequent episodes in event logs
[14] weijters, a.j.m.m., van der aalst, w.m.p., de medeiros, a.k.a.: process mining
with the heuristics miner-algorithm. beta working paper series, wp 166,
eindhoven university of technology, eindhoven (2006)
[15] de medeiros, a.k.a., weijters, a.j.m.m., van der aalst, w.m.p.: genetic
process mining: an experimental evaluation. data mining and knowledge
discovery 14(2) (2007) 245{304
[16] buijs, j.c.a.m., van dongen, b.f., van der aalst, w.m.p.: on the role of
fitness, precision, generalization and simplicity in process discovery. in meers-
man, r., rinderle, s., dadam, p., zhou, x., eds.: otm federated conferences,
20th international conference on cooperative information systems (coopis
2012). volume 7565 of lecture notes in computer science., springer-verlag,
berlin (2012) 305{322
[17] sol e, m., carmona, j.: process mining from a basis of state regions. in:
applications and theory of petri nets (petri nets 2010). volume 6128 of lecture
notes in computer science., springer-verlag, berlin (2010) 226{245
[18] van der aalst, w.m.p., rubin, v., verbeek, h.m.w., van dongen, b.f., kindler,
e., g unther, c.w.: process mining: a two-step approach to balance between
undertting and overtting. software and systems modeling 9(1) (2010) 87{111
[19] bergenthum, r., desel, j., lorenz, r., mauser, s.: process mining based on
regions of languages. in alonso, g., dadam, p., rosemann, m., eds.: interna-
tional conference on business process management (bpm 2007). volume 4714
of lecture notes in computer science., springer-verlag, berlin (2007) 375{383
[20] van der werf, j.m.e.m., van dongen, b.f., hurkens, c.a.j., serebrenik, a.:
process discovery using integer linear programming. fundamenta informaticae
94(2010) 387{412
[21] g unther, c.w., van der aalst, w.m.p.: fuzzy mining - -adaptive process simpli-
cation based on multi-perspective metrics. in: business process management.
springer (2007) 328{343
[22] leemans, s.j.j., fahland, d., van der aalst, w.m.p.: discovering block-
structured process models from incomplete event logs. in ciardo, g., kindler,
e., eds.: applications and theory of petri nets 2014. volume 8489 of lecture
notes in computer science., springer-verlag, berlin (2014) 91{110
[23] maggi, f.m., mooij, a.j., van der aalst, w.m.p.: user-guided discovery of
declarative process models. in: computational intelligence and data mining
(cidm), 2011 ieee symposium on, ieee (2011) 192{199
[24] maggi, f.m., bose, r.p.j.c., van der aalst, w.m.p.: ecient discovery of
understandable declarative process models from event logs. in: advanced
information systems engineering, springer (2012) 270{285
[25] maggi, f.m., bose, r.p.j.c., van der aalst, w.m.p.: a knowledge-based
integrated approach for discovering and repairing declare maps. in: advanced
information systems engineering, springer (2013) 433{448
[26] song, m., van der aalst, w.m.p.: towards comprehensive support for organiza-
tional mining. decision support systems 46(1) (2008) 300{317
[27] kryszkiewicz, m.: fast discovery of representative association rules. in
polkowski, l., skowron, a., eds.: rough sets and current trends in computing.
volume 1424 of lecture notes in computer science. springer berlin heidelberg
(1998) 214{222
[28] van der aalst, w.m.p.: decomposing petri nets for process mining: a generic
approach. distributed and parallel databases 31(4) (2013) 471{507
[29] dean, j., ghemawat, s.: mapreduce: simplied data processing on large
clusters. communications of the acm 51(1) (2008) 107{113