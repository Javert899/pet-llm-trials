towards privacy-preserving process mining in
healthcare
anastasiia pika1?, moe t. wynn1, stephanus budiono1, arthur h.m. ter
hofstede1, wil m.p. van der aalst2;1, and hajo a. reijers3;1
1queensland university of technology, brisbane, australia
fa.pika,m.wynn,sn.budiono,a.terhofstede g@qut.edu.au
2rwth aachen university, aachen, germany, wvdaalst@pads.rwth-aachen.de
3utrecht university, utrecht, netherlands, h.a.reijers@uu.nl
abstract. process mining has been successfully applied in the health-
care domain and helped to uncover various insights for improving health-
care processes. while benets of process mining are widely acknowledged,
many people rightfully have concerns about irresponsible use of personal
data. healthcare information systems contain highly sensitive informa-
tion and healthcare regulations often require protection of privacy of
such data. the need to comply with strict privacy requirements may
result in a decreased data utility for analysis. although, until recently,
data privacy issues did not get much attention in the process mining
community, several privacy-preserving data transformation techniques
have been proposed in the data mining community. many similarities
between data mining and process mining exist, but there are key dier-
ences that make privacy-preserving data mining techniques unsuitable
to anonymise process data. in this article, we analyse data privacy and
utility requirements for healthcare process data and assess the suitability
of privacy-preserving data transformation methods to anonymise health-
care data. we also propose a framework for privacy-preserving process
mining that can support healthcare process mining analyses.
keywords: process mininghealthcare process data data privacy
1 introduction
technological advances in the elds of business intelligence and data science
empower organisations to become \data-driven" by applying new techniques to
analyse large amounts of data. process mining is a specialised form of data-
driven analytics where process data, collated from dierent it systems typically
available in organisations, are analysed to uncover the real behaviour and per-
formance of business operations [1]. process mining was successfully applied in
the healthcare domain and helped to uncover insights for improving operational
eciency of healthcare processes and evidence-informed decision making [4, 6,
?corresponding author2 a. pika et al.
11, 12, 14]. a recent literature review [6] discovered 172 articles which report
applications of various process mining techniques in the healthcare domain.
while the potential benets of data analytics are widely acknowledged, many
people have grave concerns about irresponsible use of their data. an increased
concern of society with protecting the privacy of personal data is reected in the
growing number of privacy regulations that have been recently introduced or
updated by governments around the world. healthcare data can include highly
sensitive attributes (e.g., patient health outcomes/diagnoses, the type of treat-
ments being undertaken), and hence privacy of such data needs to be protected.
the need to consider data privacy in process mining and develop privacy-
aware tools was raised at an early stage in the process mining manifesto [3].
however, the process mining community has, until recently, largely overlooked
the problem. a few recent articles highlight \a clear gap in the research on
privacy in the eld of process mining" [10] and make rst attempts to address
some privacy-related challenges [5, 7, 9, 10, 13] yet, signicant challenges remain.
privacy considerations are quite well-known in the eld of data mining and
a number of privacy-preserving data transformation techniques have been pro-
posed [2, 17] (e.g., data swapping, generalisation or noise addition). although
there are many similarities between data mining and process mining, some key
dierences exist that make some of the well-known privacy-preserving data min-
ing techniques unsuitable to transform process data. for example, the addition
of noise to a data set may have an unpredictable impact on the accuracy of all
kinds of process mining analyses.
in this article, we present related work (section 2), analyse data privacy
and utility requirements for process data typically recorded in the healthcare
domain (section 3) and then assess the suitability of privacy-preserving data
transformation methods proposed in the data mining and process mining elds
to anonymise healthcare process data (section 4). we show that the problem
of privacy protection for healthcare data while preserving data utility for pro-
cess mining analyses is challenging and we propose a privacy-preserving process
mining framework as a possible solution to address this problem in section 5.
section 6 concludes the paper.
2 related work
privacy-preserving data mining. privacy, security, and access control con-
siderations are quite well-known in the general eld of data mining. a number
of data transformation techniques, access control mechanisms and frameworks
to preserve data privacy have been proposed [2, 8, 17]. in order to preserve data
privacy, privacy-preserving methods usually reduce the representation accuracy
of the data [2]. such data modications can aect the quality of analyses results.
the eectiveness of the transformed data for analyses is often quantied explic-
itly as its utility and the goal of privacy-preserving methods is to \maximize
utility at a xed level of privacy" [2]. for example, privacy guarantees can betowards privacy-preserving process mining in healthcare 3
specied in terms of k-anonymity : each record in a data set is indistinguishable
from at least k-1other records.
privacy-preserving data mining techniques can be generic or specic [17].
generic approaches modify data in such a way that \the transformed data can
be used as input to perform any data mining task" [17]. these approaches can
provide anonymisation4by modifying records without introducing new values
(e.g., data swapping) or they can modify original values (e.g., by adding noise). in
specic approaches privacy preservation is embedded in specic data mining al-
gorithms (e.g., privacy-preserving decision tree classication) [17]. furthermore,
outputs of some data mining algorithms can also be sensitive and methods that
anonymise such outputs have been proposed (e.g., association rule hiding) [2].
finally, distributed privacy-preserving methods are proposed for scenarios in
which multiple data owners wish to derive insights from combined data without
compromising privacy of their portions of the data [2]. such methods often use
cryptographic protocols for secure multi-party computations (smc) [2].
below, we describe traditional generic privacy-preserving data transforma-
tion approaches, such as data swapping, suppression, generalisation and noise
addition [2]. data swapping involves enacting privacy to a dataset by the exis-
tence of uncertainty. uncertainty is introduced into individual records by swap-
ping the true values of sensitive attributes between subsets of records [8]. sup-
pression anonymises data by omission. values can be removed under three types
of data suppression [2]. the most common type is column suppression which
targets the presence of highly sensitive attributes whose values directly iden-
tify an individual (e.g., patient names). alternatively, row suppression is used
when outlier records are infrequent and dicult to anonymise. value suppression
omits selected sensitive attribute values. generalisation methods dene values
approximately making it dicult for adversaries to identify records with full
condence [2]. the process of generalising usually includes the construction of
a generalisation hierarchy, which is a predened classication of values at de-
creasing levels of granularity. for numeric data, values are sorted into numerical
ranges. for categorical data, a domain expert creates semantically meaningful
generalisations using a tree structure. noise addition can be used for both nu-
merical and categorical data [17]. numerical values are often anonymised by
factoring randomly and independently generated \white noise" into the original
data [2]. white noise is generated using a random distribution, often either uni-
form or gaussian. adding noise to categorical values is more complex, and can
be achieved, for example, using clustering-based techniques [17].
privacy-preserving process mining. a few recent articles made rst at-
tempts to address some privacy-related process mining challenges [5, 7, 9, 10, 13,
15, 16]. mannhardt et al. [10] analysed privacy challenges in human-centered in-
dustrial environments and provided some generic guidelines for privacy in process
mining. liu et al. [9] presented a privacy-preserving cross-organisation process
discovery framework based on access control. tillem et al. [15, 16] presented inter-
active two-party protocols for discovery of process models from encrypted data,
4in this article, anonymisation refers to any method that can protect data privacy.4 a. pika et al.
which are based on multiple communication rounds (and have high computation
costs). the rst privacy-preserving data transformation approach presented in
the process mining community [5] proposes to use deterministic encryption meth-
ods for anonymisation of event log attribute values. (such methods are also a
part of the condentiality framework proposed by raei et al. [13].) timestamps
are treated as numeric values and are encrypted in a way that preserves the order
of events. deterministic encryption methods produce \the same ciphertext for a
given plaintext" and preserve dierences between values, which is important for
process mining [13]. encryption only provides weak data privacy protection and
\could be prone to advanced de-anonymization techniques" [5]. more advanced
privacy-preserving process mining approaches proposed by raei et al. [13] and
fahrenkrog-peterse et al. [7] will be discussed in detail in section 4.
in this article, we focus on protecting privacy of process data in a healthcare
organisation. distributed privacy scenarios are not considered in this work.
3 data privacy and utility requirements: healthcare
in order to realise our objective of privacy-preserving process mining for the
healthcare domain, we rst analyse privacy requirements for process data typi-
cally recorded in the healthcare domain, which is then followed by a discussion of
data requirements of process mining approaches to analyse healthcare processes.
healthcare process data. process mining uses process data in the form
of an event log, which represents collated and aggregated data from it systems
available in organisations. an event log contains events where each event refers
to a case, an activity, a point in time, transaction type (e.g., start orcomplete )
and (optionally) a resource and data attributes. an event log can be seen as a
collection of cases and a case can be seen as a sequence of events.
cases in healthcare processes typically refer to patients receiving treatments
in a healthcare setting (e.g., a patient's pathway) and resources refer to medical
personnel involved in the process. figure 1 depicts an example event log which
contains six events (represented by rows) related to two cases ( 1and 2) where
patient identiers are already hidden. for example, we can see that case 1refers
to a patient whose age is 56, who speaks english and was diagnosed with pancre-
atitis; activity register is completed in this case; activity blood test was started
on13/01/2019 at17:01 byrobert ; and treatment code 3456 is associated with
activity triage in case 1. data attributes can refer to cases (e.g., age, language
and diagnosis) or to events (e.g., treatment codes are recorded for events asso-
ciated with activity triage ). data attributes used in this example are recorded
in two publicly available healthcare logs. the healthcare mimic data set5con-
tains information about language and diagnosis (as well as ethnicity, religion,
marital status and insurance). the dutch academic hospital event log6contains
information about age, diagnosis and treatment codes.
5https://mimic.physionet.org/mimicdata/
6https://data.4tu.nl/repository/uuid:d9769f3d-0ab0-4fb8-803b-0d1120cf54towards privacy-preserving process mining in healthcare 5
fig. 1. example of an event log with typical healthcare data attributes.
legislative requirements. an increased concern of people with protecting
the privacy of their data is reected in the growing number of privacy regula-
tions that have been recently introduced (e.g., the eu general data protection
regulation (gdpr) 2018, the california consumer privacy act of 2018) or
updated by governments around the world (e.g., australian privacy regulation
2013 under the privacy act 1988). in addition, data privacy requirements are of-
ten included in legislation governing specic sectors, e.g., australian healthcare
identiers act 2010.
guidance for de-identication of protected health information in the us is
provided in the health insurance portability and accountability act (hipaa)
privacy rule. for example, the \safe harbor" de-identication method of the
hippa privacy rule prescribes removal of all elements of dates (except year)
related to an individual (e.g., admission or discharge dates)7. in australia, the
oce of australian information commissioner provides guidelines for the use
of health information for research. the guidelines prescribe de-identication of
personal information by \removing personal identiers, such as name, address,
d.o.b. or other identifying information" and \removing or altering other infor-
mation that may allow an individual to be identied, for example, because of
a rare characteristic of the individual, or a combination of unique or remark-
able characteristics"8. furthermore, the recently introduced my health records
amendment (strengthening privacy) bill 2018 allows australians to opt out of
having an electronic health record and allows the deletion of their records perma-
nently at any time. whilst providing strong privacy protections for australians;
for analysis purposes, they also introduce data quality issues such as missing and
incomplete data; thus reducing the utility of data and the accuracy of results.
privacy of public healthcare data is typically protected by replacing sensitive
attribute values with anonymised values (e.g., treatment codes are used in a
publicly available dutch academic hospital event log and subject ids are used in
the healthcare mimic data set) or by removing sensitive attributes from data
(e.g., employee information is removed from both dutch hospital and mimic
data sets). all timestamps in the mimic data set were shifted to protect pri-
vacy: dates are randomly distributed, but consistent for each patient. the former
7https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-
identication/index.html#protected
8https://www.oaic.gov.au/engage-with-us/consultations/health-privacy-
guidance/business-resource-collecting-using-and-disclosing-health-information-
for-research6 a. pika et al.
method only provides weak privacy protection while the latter methods can sig-
nicantly decrease data utility.
privacy requirements for healthcare process data. healthcare pro-
cess data can contain sensitive information such as patient or employee names
or identiers. other attributes in the event log can also reveal patient or em-
ployee identities when combined with background knowledge about the process.
for example, accident or admission time, a rare diagnosis or treatment, or a
combination of age and language could potentially identify a patient. an em-
ployee could be identied by a combination of an activity name and execution
time (e.g., when a blood test is always performed by the same employee during a
shift). hence, typical event log attributes such as case id, activity, time, resource
and many data attributes (e.g., a patient's personal and treatment information)
can contribute to identity disclosure.
furthermore, relations between events in a log can contribute to identity
disclosure and this is especially pertinent for a healthcare event log due to the
high variability of process paths typical for the sector [4]. consider, for example,
the dutch hospital event log where 82% of cases follow unique process paths.
hence, someone with knowledge of the process could link these cases to individual
patients. moreover, cases which follow the same process path can include other
atypical behaviors. in the dutch hospital log, the fth most frequent process
variant is followed by 8 cases: 7 cases are related to only one organisational group
(\obstetrics and gynecology clinic") and only one case is also related to the
\radiotherapy" group. although the case does not follow a unique process path,
the relation to the \radiotherapy" group is unique and could be used by someone
with knowledge of the process to identify the patient. other examples of atypical
process behaviour which could contribute to a patient's identity disclosure include
abnormally short or long execution times of activities or cases, or an abnormally
low or high number of resources involved in a case.
data requirements for process mining approaches. all process min-
ing algorithms require case ids and activities to be recorded accurately in the
log and most algorithms also require (accurate) timestamps. a recent literature
review [6] discovered that the following types of process mining analyses were
frequently used in healthcare: discovery techniques (which include process discov-
ery as well as organisational mining approaches such as social network mining),
conformance checking, process variant analysis and performance analysis.
{process discovery techniques usually take as input a multi-set of traces
(i.e., ordered sequences of activity labels) and do not require timestamps;
however, timestamps are typically used to order events.
{most academic process conformance and performance analysis techniques
(e.g., alignment-based approaches) use formal models and require that com-
plete traces are recorded in the log. most commercial process mining tools (as
well as some prom plugins) convert the log to directly follows graphs (dfg)
annotated with frequencies and times, which show how frequently dierent
activities follow each other and average times between them. dfg-basedtowards privacy-preserving process mining in healthcare 7
tools do not require complete traces and only require that \directly-follows"
relations between activities are preserved in the log.
{organisational mining techniques require resource information to be recorded
in the log (in addition to case ids, activities and timestamps). moreover, re-
source and data attributes can also be required by conformance checking
approaches that consider dierent process perspectives.
{process variant analysis, which is concerned with comparing process be-
haviour and performance of dierent cohorts, often uses case data attributes
to distinguish between cohorts.
in order to comply with strict privacy requirements for healthcare data, one
would need to consider anonymising 1) event log attribute values and 2) atyp-
ical process behaviour . however, many process mining techniques require that
healthcare process data is accurate and representative. that is: 1) all events be-
long to a particular case ;2) attributes that represent case identiers and activity
labels are accurate; and 3) timestamps are reliable and accurate . thus, the need
to balance the privacy requirements of healthcare data and the utility require-
ments of process mining techniques is paramount. in the following section, we
assess whether existing privacy-preserving data transformation approaches can
preserve the attribute values and relations between events discussed above.
4 anonymising healthcare process data
4.1 anonymising sensitive attribute values
as discussed in section 3, typical event log attributes such as case, activity,
time, resource and many data attributes could contribute to identity disclosure.
below, we discuss how these attributes could be anonymised using generic data
transformation approaches described in section 2. we evaluate the suitability
of deterministic encryption (referred to here as encryption), which was used
to anonymise event log data [5, 13], and other traditional data transformation
approaches proposed in the data mining community such as data swapping,
value suppression, generalisation and noise addition (which, to the best of our
knowledge, have not been applied to event logs). figure 2 depicts how some of
these techniques can be applied to the event log in figure 1.
case identiers can be encrypted (as well as other event log attributes);
however, encryption does not provide strong data privacy protection (and may
not be suitable to protect sensitive healthcare data). an underlying assumption
of all process mining algorithms is that case identiers are unique, which makes
the application of value suppression and generalisation not suitable (these meth-
ods are used to hide infrequent attribute values). adding noise to case identiers
can yield values that are no longer unique, which can decrease the accuracy of all
process mining algorithms. data swapping can be applied to case ids without
impact on process mining results.
activity labels can be encrypted; however, encrypted labels can be identied
by someone with knowledge of the process (e.g., most or least frequent activi-
ties [13]). moreover, encryption makes it dicult to interpret analysis results.8 a. pika et al.
fig. 2. application of data transformation techniques to the event log in figure 1: case
id: swapping; time: noise addition; resource: generalisation; diagnosis: suppression.
in addition, one must also encrypt process model labels when applying process
mining algorithms that use process models as input (e.g., many process perfor-
mance and conformance analysis approaches). application of value suppression
and generalisation to activity labels may aect the accuracy of process mining
results where the utility loss depends on the process mining algorithm used. for
example, removing infrequent activity labels may not have a signicant eect on
process discovery results (as process models often capture mainstream process
behavior); however, process conformance analysis results may become invalid.
one can use generalisation to hide some sensitive activities (e.g., replace activi-
ties \hiv test" and \hepatitis c test" with activity \blood test"). the result of
process discovery performed on such logs will be correct; however, the discovered
process model will be on a higher level of granularity. noise addition and swap-
ping activity labels will invalidate the results of all process mining algorithms.
for example, if activity labels in a log are swapped, the resulting traces will
consist of random activity sequences; hence, discovered process models will be
incorrect, as well as other process mining results.
timestamps can be treated as numerical values and encrypted using meth-
ods which preserve the order of events. such encryption will not aect the results
of process mining algorithms that work with ordered events and do not require
timestamps (such as many process discovery algorithms). on the other hand,
an event log with encrypted timestamps will not be suitable for performance
analysis. value suppression and generalisation can be used to anonymise sensi-
tive timestamps (e.g., as discussed in section 3, according to the hipaa privacy
rule admission and discharge times must be anonymised). this will aect the
accuracy of most process mining algorithms. for example, if value suppression
is applied to admission times, the discovered process model will not include ac-
tivity \admission". on the other hand, if generalisation is applied to admission
times (by only leaving year as prescribed by the hipaa privacy rule), process
discovery may not be aected; however, process performance analysis results
may become invalid (as time between admission and other activities in the pro-
cess will no longer be correct). adding noise to timestamps or swapping their
values will yield incorrect process mining results (as the order of events in the
transformed log is no longer preserved).
resource information can be encrypted without impacting organisational
mining results, while noise addition and swapping will invalidate such results
(as resources will no longer be related to correct events and cases). one cantowards privacy-preserving process mining in healthcare 9
apply generalisation to resource information (e.g., by replacing individual iden-
tiers with team identiers), which will yield the analysis on a team level. value
suppression can aect the accuracy of organisational mining techniques (e.g., a
discovered social network may have fewer nodes).
data attributes can be encrypted, though encryption of numerical values
can make it dicult to conduct some analyses. for example, if ageis encrypted,
one can no longer compare process variants for dierent age cohorts. value sup-
pression can decrease the accuracy of process mining algorithms that use data
(e.g., when infrequent age values are removed, the corresponding cases will not
be included in process variant analysis). using generalisation may decrease the
accuracy of conformance analysis that consider data; however, it may not have
any impact on variant analysis (e.g., when comparing dierent age groups). noise
addition and data swapping will nullify results of the methods that use data.
table 1 summarises the suitability of dierent data transformation approaches
to anonymising event log attribute values. encryption has a minimal eect on
data utility for most process mining algorithms; however, it may not provide a
required level of privacy protection. data swapping can be used to anonymise
case ids; however, application of this method to other event log attributes will
invalidate process mining results. noise addition will nullify all process mining
results. value suppression and generalisation are not suitable for case ids (as
they have unique values), these methods can be applied to other attributes;
however, the accuracy of process mining results may be aected.
table 1. suitability of privacy-preserving data transformation approaches to
anonymising event log attributes: na: not applicable; `+': does not aect process min-
ing results; `-': can be used to anonymise an attribute, however invalidates process
mining results; `+/-': can decrease the accuracy of some process mining methods.
case id activity time resource data
encryption (deterministic) + + +/- + +/-
swapping + - - - -
noise addition - - - - -
value suppression na +/- +/- +/- +/-
generalisation na +/- +/- +/- +/-
4.2 anonymising atypical process behaviour
as discussed in section 3, relations between events in the log (such as event
order or grouping of events by case identiers) can be used to identify atypical
process behaviour (which could be linked to individuals). there could be many
dierent types of atypical process behaviour (e.g., infrequent activity sequences,
abnormal number of resources or atypical durations). below, we evaluate two
approaches which target anonymisation of atypical process behaviour: a con-
dentiality framework [13] and pretsa [7].10 a. pika et al.
thecondentiality framework for process mining [13] combines a few
data transformation techniques. the rst step of the framework is ltering out all
cases \that do not reach the minimal frequencies" [13]. the framework changes
the structure of an event log: a new attribute \previous activity" is added (which
species for each event the preceding activity in a case) and case ids are removed.
since events in the transformed log are no longer related to cases, it is impossible
to identify traces (and atypical process behaviour). however, the transformed log
can no longer be used by process mining algorithms that require complete traces;
it is only suitable for dfg-based tools (e.g., commercial process mining tools).
moreover, as discussed in section 3, healthcare processes are often highly variable
and in some processes all traces in the log may be unique. the condentiality
framework (which proposes to lter out traces with infrequent process behaviour)
may not be suitable to anonymise event log data from such healthcare processes.
pretsa [7] is a log sanitisation algorithm, which represents a log as a pre-
x tree and then transforms the tree until given privacy guarantees are met while
striving to preserve directly follows relations. the approach allows to anonymise
two types of atypical process behaviour: infrequent traces and atypical activity
execution times. the article [7] evaluates the impact of the log transformation
on the results of process discovery and performance analysis algorithms using
three real-life logs. it also compares the performance of pretsa with a \base-
line" approach which lters out infrequent traces. the evaluation showed that
pretsa outperforms the baseline approach on all logs and data utility losses
are minimal for event logs which do not have many unique traces. however, for
a log in which most traces are unique the utility of the transformed log is signif-
icantly decreased, even more so for stricter privacy requirements (which means
that the algorithm may not be suitable for healthcare process data).
5 privacy-preserving process mining framework
on the one hand, the healthcare sector needs to comply with strict data pri-
vacy requirements; on the other hand, healthcare process data often contain
many sensitive attributes and highly variable process behaviour that presents
additional threats to privacy. ensuring high levels of privacy protection for such
data while also preserving data utility for process mining purposes remains an
open challenge for the healthcare domain.
the analysis of the suitability of existing data transformation approaches
to anonymise healthcare process data (presented in section 4) highlighted the
trade-o between data privacy and utility. the methods that preserve higher
data utility for process mining purposes (e.g., encryption) do not provide strong
privacy protection. on the other hand, the methods that can satisfy stricter pri-
vacy requirements (e.g., value suppression and generalisation) can decrease the
accuracy of results. the magnitude of the data utility loss depends on charac-
teristics of a particular log and varies for dierent process mining algorithms.
furthermore, performing analyses on anonymised process data without under-
standing how the data was transformed can yield unpredictable results.towards privacy-preserving process mining in healthcare 11
we propose a privacy-preserving process mining framework (figure 3) which
uses a history of privacy-preserving data transformations to quantify their im-
pact and improve the accuracy of process mining results. the proposed frame-
work can be applied to the healthcare domain as well as other domains with high
privacy needs. the rst two steps of the framework (i.e., data anonymisation and
creation of privacy metadata) are performed by the data owner or a trusted rep-
resentative. the third step (i.e., conducting privacy-preserving process mining
analysis) can be performed by (not trusted) third parties.
fig. 3. privacy-preserving process mining framework.
the rst step of the framework is anonymising sensitive information such as
sensitive attribute values and atypical process behavior. anonymisation of sensi-
tive attribute values could be achieved using data transformation approaches dis-
cussed in section 4.1. some atypical process behaviours can be anonymised using
approaches discussed in section 4.2; however, methods which could anonymise
dierent types of atypical process behaviour in highly variable processes while
preserving data utility for dierent algorithms are yet to be developed.
the second step of the framework is creating privacy metadata , which
maintains the history of privacy-preserving data transformations in a standard-
ised and machine readable way. such metadata can be stored in a privacy exten-
sion to the ieee xes log format used for process mining. this privacy metadata
will also assist in formally capturing the log characteristics that inuence the
anonymisation eorts for various forms of process mining.
the third step of the framework is conducting privacy-preserving pro-
cess mining analysis of the anonymised event log with privacy metadata. the
privacy metadata can be exploited by new \privacy-aware" process mining tech-
niques to improve mining results. privacy-aware process mining methods could
also quantify data privacy and utility (e.g., by providing condence measures).
finally, results of process mining techniques could also threaten privacy (by iden-
tifying patterns which are linked to individuals). to the best of our knowledge,
anonymisation methods for process mining outputs are yet to be developed.12 a. pika et al.
6 conclusion
keeping healthcare process data private while preserving data utility for process
mining presents a challenge for the healthcare domain. in this article, we anal-
ysed data privacy and utility requirements for healthcare process data, assessed
the suitability of existing privacy-preserving data transformation approaches and
proposed a privacy-preserving process mining framework that can support pro-
cess mining analyses of healthcare processes. a few directions for future work
include: an empirical evaluation of the eects of privacy-preserving data trans-
formation methods on healthcare logs, the development of privacy extensions for
logs and the development of privacy-aware process mining algorithms.
references
1. van der aalst, w.: process mining: data science in action. springer-verlag, berlin
(2016), http://www.springer.com/978-3-662-49850-7
2. aggarwal, c.c.: data mining: the textbook. springer (2015)
3. van der aalst et al., w.: process mining manifesto. in: bpm 2011 workshops
proceedings. lnbip, springer-verlag, berlin (2011)
4. andrews, r., suriadi, s., wynn, m., ter hofstede, a.: healthcare process analysis.
process modelling and management for healthcare; crc press, usa (2017)
5. burattin, a., conti, m., turato, d.: toward an anonymous process mining. in:
ficloud 2015. pp. 58{63. ieee (2015)
6. erdogan, t.g., tarhan, a.: systematic mapping of process mining studies in
healthcare. ieee access 6, 24543{24567 (2018)
7. fahrenkrog-petersen, s.a., van der aa, h., weidlich, m.: pretsa: event log
sanitization for privacy-aware process discovery. icpm (accepted) (2019)
8. fienberg, s.e., mcintyre, j.: data swapping: variations on a theme by dalenius
and reiss. in: int. workshop on psd. pp. 14{29. springer (2004)
9. liu, c., duan, h., qingtian, z., zhou, m., lu, f., cheng, j.: towards comprehen-
sive support for privacy preservation cross-organization business process mining.
ieee transactions on services computing (2016)
10. mannhardt, f., petersen, s.a., oliveira, m.f.: privacy challenges for process min-
ing in human-centered industrial environments. in: ie 2018. pp. 64{71. ieee (2018)
11. mans, r.s., van der aalst, w.m., vanwersch, r.j.: process mining in healthcare:
evaluating and exploiting operational healthcare processes. springer (2015)
12. partington, a., et al.: process mining for clinical processes: a comparative analysis
of four australian hospitals. acm (tmis) 5(4), 19 (2015)
13. raei, m., von waldthausen, l., van der aalst, w.: ensuring condentiality in
process mining. in: simpda 2018 (2018)
14. rojas, e., sep ulveda, m., munoz-gama, j., capurro, d., traver, v., fernandez-
llatas, c.: question-driven methodology for analyzing emergency room processes
using process mining. applied sciences 7(3), 302 (2017)
15. tillem, g., erkin, z., lagendijk, r.l.: privacy-preserving alpha algorithm for soft-
ware analysis. in: sitb 2016 (2016)
16. tillem, g., erkin, z., lagendijk, r.l.: mining sequential patterns from outsourced
data via encryption switching. in: pst 2018. pp. 1{10. ieee (2018)
17. toshniwal, d.: privacy preserving data mining techniques for hiding sensitive data:
a step towards open data. in: data science landscape, pp. 205{212. springer
(2018)