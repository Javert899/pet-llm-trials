using process mining to
learn from process changes
in evolutionary systems
christian w. g¨ unther*
faculty of technology management,
eindhoven university of technology, the netherlands
e-mail: c.w.gunther@tue.nl
*corresponding author
stefanie rinderle-ma
department of databases & information systems,
university of ulm, germany
e-mail: stefanie.rinderle@uni-ulm.de
manfred reichert
faculty of electrical engineering, mathematics and comput er science,
university of twente, the netherlands
e-mail: m.u.reichert@ewi.utwente.nl
wil m.p. van der aalst
faculty of technology management,
eindhoven university of technology, the netherlands
e-mail: w.m.p.v.d.aalst@tue.nl
jan recker
faculty of information technology,
queensland university of technology, australia
e-mail: j.recker@qut.edu.au
abstract: traditional information systems struggle with the require ment to provide
ﬂexibility and process support while still enforcing some d egree of control. accordingly,
adaptive process management systems (pmss) have emerged that provid e some ﬂexi-
bility by enabling dynamic process changes during runtime. based on the assumption
that these process changes are recorded explicitly, we pres ent two techniques for mining
change logs in adaptive pmss; i.e., we do not only analyze the execution logs of the
operational processes, but also consider the adaptations m ade at the process instance
level. the change processes discovered through process min ing provide an aggregated
overview of all changes that happened so far. using process m ining as an analysis tool
we show in this paper how better support can be provided for tr uly ﬂexible processes
by understanding when andwhyprocess changes become necessary.
keywords: process-aware information systems; process mining; chang e mining.
reference to this paper should be made as follows: g¨ unther, c.w., rind erle-ma,
s., reichert, m., van der aalst, w.m.p. and recker, j. (2007) ‘using process mining
to learn from process changes in evolutionary systems’, int . j. business process
integration and management, vol. 1, nos. 1/2/3, pp.111–111 .
biographical notes: christian w. g¨ unther is a phd candidate at the information
systems group at the technische universiteit eindhoven (tu /e). he received his
bsc and msc in software engineering from the hasso plattner- institute in potsdam
(germany). his research interests include process mining, ﬂexible and unstructured
processes, and process analysis.
stefanie rinderle-ma obtained her phd in computer science a t the institute of
databases and information systems, university of ulm (germ any) where she is cur-
rently teaching and working on her habilitation. during her postdoc stefanie stayed
at the university of twente (the netherlands), the universi ty of ottawa (canada),
and the technical university of eindhoven (the netherlands ) where she worked on
several projects on process visualization and modeling as w ell as on process mining.
her research interests include adaptive process managemen t systems, semantic aspects
of process management, and the controlled evolution of orga nizational structures and
access rules.
manfred reichert holds a ph.d. in computer science and is cur rently associate profes-1 introduction
the notion of ﬂexibility has emerged as a pivotal research
topic in business process management (bpm) over the
last years (bider, 2005; reichert and dadam, 1998; sof-
fer, 2005). the need for more ﬂexibility, in general, stems
from the observation that organizations often face contin-
uous and unprecedented changes in their business environ-
ment (quinn, 1992; strong and miller, 1995). to deal with
such disturbances and perturbations of business routines,
corresponding business processes as well as their support-
ing information systems need to be quickly adaptable to
environmental changes.
in this context, business process ﬂexibility denotes the
capability to reﬂect externally triggered change by modify -
ing only those aspects of a process that need to be changed,
while keeping the other parts stable; i.e., the ability to
change or evolve the process without completely replacing
it (regev and wegmann, 2005; soﬀer, 2005; bider, 2005).
in particular, we have to deal with the essential require-
ment for maintaining a close “ﬁt” between the real-world
business processes and the workﬂows as supported by pro-
cess management systems (pmss), the current generation
of which is known under the label of process-aware infor-
mation systems (paiss) (dumas et al., 2005).
1.1 problem statement
recently, many eﬀorts have been undertaken to make
paiss more ﬂexible and several approaches for adaptive
process management, like adept (reichert and dadam,
1998), cbrflow (weber et al., 2004) or wasa (weske,
2001), have emerged in this context (an overview is pro-
vided by rinderle et al. (2004)). the basic idea behind
these approaches is to enable users to dynamically evolve
oradapt process schemes such that they ﬁt to changed real-
world situations. more precisely, adaptive pmss support
dynamic changes of diﬀerent process aspects (e.g., control
and data ﬂow) at diﬀerent levels (e.g., process instance
and process type level). in particular, ad-hoc changes con-
ducted at the instance level (e.g., to add, delete or move
process steps during runtime) allow to adapt single process
instances to exceptional or changing situations (reichert
and dadam, 1998). usually, such ad-hoc deviations are
recorded in change logs rinderle et al. (2006), which re-
sults in more meaningful log information when compared
to traditional paiss.
so far, adaptive process management technology has not
addressed the fundamental question what we can learn
from the additional change log information (e.g., how to
derive potential process schema optimizations from a col-
lection of individually adapted process instances (aalst
et al., 2006)). in principle, process mining techniques
(aalst et al., 2004) oﬀer promising perspectives for this.
however, current mining algorithms have not been de-
signed with adaptive processes in mind, but have focused
on the analysis of pure execution logs instead (i.e., taking
copyright c/circlecopyrt200x inderscience enterprises ltd.a behavioral and operational perspective).
obviously, mining ad-hoc changes in adaptive pmss of-
fers promising perspectives as well. by enhancing adap-
tive processes with advanced mining techniques we aim
at a pms framework, which enables full process life cycle
support . however, the practical implementation of such a
framework in a coherent architecture, let alone the integra -
tion of process mining and adaptive processes is far from
trivial. in particular, we have to deal with the following
three challenges. first, we have to determine which run-
time information about ad-hoc deviations has to be logged
and how this information should be represented to achieve
optimal mining results. second, we have to develop ad-
vanced mining techniques that utilize change logs in addi-
tion to execution logs. third, we have to integrate the new
mining techniques with existing adaptive process manage-
ment technology. this requires the provision of integrated
tool support allowing us to evaluate our framework and to
compare diﬀerent mining variants.
1.2 contribution
in our previous work, with adept (reichert and dadam,
1998) and prom (dongen et al., 2005) we have developed
two separate frameworks for adaptive processes and for
process mining respectively. while adept has focused
on the support of dynamic process changes at diﬀerent
levels, prom has oﬀered a variety of process mining tech-
niques, e.g., for discovering a petri net model or an event
process chain (epc) describing the behavior observed in
an execution log. so far, no speciﬁc prom extension has
been developed to mine for process changes.
this paper contributes new techniques for mining ad-
hoc process changes in adaptive pmss and discusses the
challenges arising in this context. we ﬁrst describe what
constitutes a process change, how respective information
can be represented in change logs, and how these change
logs have to be mined to deliver insights into the scope and
context of changes. this enables us, for example, to better
understand how users deviate from predeﬁned processes.
we import adept change logs in prom, and introduce
mining techniques for discovering change knowledge from
these logs. as result, we obtain an abstract change process
represented as a petri net model. this abstract process
reﬂects all changes applied to the instances of a particular
process type. more precisely, a change process comprises
change operations (as meta process steps) and the causal
relations between them. we introduce two diﬀerent mining
approaches based on diﬀerent assumptions and techniques.
the ﬁrst approach uses multi–phase mining, but utilizes
further information about the semantics of change oper-
ations (i.e., commutativity). the second approach maps
change logs to a labeled state transition system, and then
constructs a compact petri net model from it.
the remainder of this paper is organized as follows: sec-
tion 2 provides background information on process mining
and adaptive process management, which is needed for the
understanding of this paper. in section 3 we present a
2general framework for integrating these two technologies.
section 4 deals with the representation of process changes
and corresponding change logs. based on this, section 5
introduces two diﬀerent approaches for mining changs logs.
section 6 discusses related work and section 7 concludes
with a summary and an outlook.
2 background information
this paper is based on the integration of two existing
technologies: process mining andadaptive process manage-
ment. this section gives background information needed
to understand the implications and leverages of their com-
bination.
2.1 process mining
although the focus of this paper is on analyzing change
processes in the context of adaptive process management
systems, process mining is applicable to a much wider
range of information systems. there are diﬀerent kinds of
process-aware information systems (paiss) that produce
event logs recording events. examples are classical work-
ﬂow management systems (e.g. staﬀware), erp systems
(e.g. sap), case handling systems (e.g. flower), pdm
systems (e.g. windchill), crm systems (e.g. microsoft dy-
namics crm), middleware (e.g. ibm’s websphere), hospi-
tal information systems (e.g. chipsoft), etc. these system s
all provide very detailed information about the activities
that have been executed. the goal of process mining is
to extract information (e.g., process models, or schemas)
from these logs.
process mining addresses the problem that most “pro-
cess owners” have very limited information about what is
actually happening in their organization. in practice ther e
is often a signiﬁcant gap between what is predeﬁned or
supposed to happen, and what actually happens. only
a concise assessment of the organizational reality, which
process mining strives to deliver, can help in verifying pro -
cess schemas, and ultimately be used in a process redesign
eﬀort.
as indicated, process mining starts with the existence
of event logs. the events recorded in such a logs should
be ordered (e.g., based on timestamps) and each event
should refer to a particular case (i.e., a process instance)
and a particular activity. this is the minimal information
needed. however, in most event logs more information
is present, e.g., the performer or originator of the event
(i.e., the person / resource executing or initiating the act iv-
ity), the timestamp of the event, or data elements recorded
with the event (e.g., the size of an order). in this paper,
we assume that event logs are stored in the mxml format
(dongen et al., 2005). mxml is an xml-based format
for representing and storing event log data, which is sup-
ported by process mining tools such as prom. using our
promimport tool, it is easy to convert data originating
from a wide variety of systems to mxml (g¨ unther andaalst, 2006). for more information about the mxml for-
mat we refer to (dongen et al., 2005) and (g¨ unther and
aalst, 2006).
models
analyzesrecords
events, e.g., 
messages,
transactions,
etc.specifies
configures
implements
analyzessupports/
controls
people machines
organizationscomponentsbusiness processes
figure 1: overview showing three types of process mining:
(1) discovery, (2) conformance, and (3) extension.
the idea of process mining is to discover, monitor and
improve real processes (i.e., not assumed processes) by ex-
tracting knowledge from event logs (e.g., in mxml for-
mat). clearly process mining is relevant in a setting where
much ﬂexibility is allowed and/or needed and therefore
this is an important topic in this paper. the more ways
in which people and organizations can deviate, the more
variability and the more interesting it is to observe and
analyze processes as they are executed. we consider three
basic types of process mining (cf. figure 1):
•discovery : there is no a-priori process schema, i.e.,
based on an event log some schema is constructed. for
example, using the alpha algorithm a process schema
can be discovered based on low-level events (aalst
et al., 2004).
•conformance : there is an a-priori process schema.
this schema is used to check if reality conforms to
the schema. for example, there may be a process
schema indicating that purchase orders of more than
one million euro require two checks. another exam-
ple is the checking of the four-eyes principle. confor-
mance checking may be used to detect deviations, to
locate and explain these deviations, and to measure
the severity of these deviations (rozinat and aalst,
2006a).
•extension : there is an a-priori process schema. this
schema is extended with a new aspect or perspective,
i.e., the goal is not to check conformance but to en-
rich the schema. an example is the extension of a pro-
cess schema with performance data, i.e., some a-priori
process schema is used to project the bottlenecks on.
another example is the detection of data dependen-
cies that aﬀect the routing of a case and adding this
information to the model in the form of decision rules
(rozinat and aalst, 2006b).
3at this point in time there are mature tools such as
the prom framework, featuring an extensive set of anal-
ysis techniques which can be applied to real process en-
actments while covering the whole spectrum depicted in
figure 1 (dongen et al., 2005). any of the analysis tech-
niques of prom can be applied to change logs (i.e., event
logs in the context of adaptive process management sys-
tems). moreover, this paper also presents two new process
mining techniques exploiting the particularities of chang e
logs.
2.2 adaptive process management
in recent years several approaches for realizing adap-
tive processes have been proposed and powerful proof-of-
concept prototypes have emerged (weske, 2001; reichert
and dadam, 1998; casati et al., 1998; ellis et al., 1995;
rinderle et al., 2004). adaptive pmss like adept2 (re-
ichert et al., 2005) or wasa (weske, 2001), for example,
provide comprehensive runtime information about process
changes not explicitly captured in current execution logs.
basically, process changes can take place at the type as well
as the instance level: changes of single process instances
may have to be carried out in an ad-hoc manner to deal
with an unforeseen or exceptional situation. process type
changes, in turn, refer to the change of a process schema at
the type level in order to adapt the pais to evolving busi-
ness processes. especially for long-running processes, su ch
type changes often require the migration of a collection of
running process instances to the new process schema.
pms frameworks like adept2 (reichert and dadam,
1998; reichert et al., 2005) support both ad-hoc changes
of single process instances and the propagation of process
type changes to running instances. examples of ad-hoc
changes are the insertion, deletion, movement, or replace-
ment of activities. in adept, such ad-hoc changes do
not lead to an unstable system behavior, i.e., none of the
guarantees achieved by formal checks at build-time are vi-
olated due to the dynamic change. adept oﬀers a com-
plete set of operations for deﬁning instance changes at a
high semantic level and ensures correctness by introducing
pre-/post-conditions for these operations. finally, all c om-
plexity associated with the adaptation of instance states,
the remapping of activity parameters, or the problem of
missing data is hidden from users. to deal with business
process changes adept also enables schema adaptations
at the process type level. in particular, it is possible to ef -
ﬁciently and correctly propagate type changes to running
instances.
3 a framework for integration
both process mining and adaptive processes address fun-
damental issues prevalent in the current practice of bpm
implementations. these problems stem from the fact that
thedesign ,enactment , andanalysis of a business processare commonly interpreted, and implemented, as detached
phases .
although both techniques are valuable on their own, we
argue that their full potential can only be harnessed by
tight integration. while process mining can deliver reli-
able information about how process schemas need to be
changed, adaptive pmss provide the tools to safely and
conveniently implement these changes. thus, we propose
the development of process mining techniques, integrated
into adaptive pmss as a feedback cycle . on the other side,
adaptive pmss need to be equipped with functionality to
exploit this feedback information.
the framework depicted in figure 2 illustrates how such
an integration could be realized. adaptive pmss, visual-
ized in the upper part of this model, operate on pre-deﬁned
process schemas. the evolution of these schemas over time
spawns a set of process changes, i.e., results in multiple
process variants . like in every pais, enactment logs are
created, which record the sequence of activities executed
for each case. on top of that, adaptive pmss can addi-
tionally log the sequence of change operations imposed on
a process schema for every executed case, producing a set
ofchange logs . process mining techniques that integrate
into such system in form of a feedback cycle may be posi-
tioned in one of three major categories:
•change analysis: process mining techniques from
this category make use of change log information, be-
sides the original process schemas and their variants.
one goal is to determine common and popular vari-
ants for each process schema, which may be promoted
to replace the original schema. possible ways to pur-
sue this goal are through statistical analysis of changes
or their abstraction to higher-level schemas. from
the initially used process schema and a sequence of
changes, it is possible to trace the evolution of a pro-
cess schema for each case. based on this informa-
tion, change analysis techniques can derive abstract
and aggregate representations of changes in a system.
these are valuable input for analysis and monitoring,
and they can serve as starting point for more involved
analysis (e.g., determining the circumstances in which
particular classes of change occur, and thus reasoning
about the driving forces for change).
•integrated analysis: this analysis uses both change
and enactment logs in a combined fashion. possible
applications in this category could perform a context-
aware categorization of changes as follows. change
process instances, as found in the change logs, are
ﬁrst clustered into coherent groups, e.g. based on the
similarity of changes performed, or their environment.
subsequently, change analysis techniques may be used
to derive aggregate representations of each cluster.
each choice in an aggregate change representation can
then be analyzed by comparing it with the state of
each clustered case, i.e. the values of case data objects
at the time of change, as known from the original pro-
cess schema and the enactment logs. a decision-tree
4adaptive workflow 
process mining context-aligned 
changes / variants process models <refers to>process 
instantiation case 
(data)
context-
aware 
adaptation enactment 
process 
modelling continuous 
adaptation data 
updates 
ad-hoc 
adaptation 
enactment logs change logs 
change analysis 
integrated analysis 
enactment analysis 
figure 2: integration of process mining and adaptive proces s management
analysis of these change clusters provides an excellent
basis for guiding users in future process adaptations,
based on the peculiarities of their speciﬁc case.
•enactment analysis: based solely on the inspec-
tion of enactment logs, techniques in this category can
pinpoint parts of a process schema which need to be
changed, e.g. paths having become obsolete. tradi-
tional process mining techniques like control ﬂow min-
ing and conformance checking can be adapted with
relative ease to provide valuable information in this
context. for example, conformance checking, i.e. de-
termining the “ﬁt” of the originally deﬁned process
schema and the recorded enactment log, can show
when a speciﬁc alternative of a process schema has
never been executed. consequently, the original pro-
cess schema may be simpliﬁed by removing that part.
statistical analysis of process enactment can also high-
light process deﬁnitions, or variants thereof, which
have been rarely used in practice. these often clut-
ter the user interface, by providing too many options,
and they can become a maintenance burden over time.
removing (or hiding) them after a human review can
signiﬁcantly improve the eﬃciency of a process man-
agement system.
these examples give only directions in which the devel-
opment of suitable process mining techniques may proceed.
of course, their concrete realization depends on the nature
of the system at hand. for example, it may be preferable to
present highlighted process schemas to a specialist before
their deletion or change, rather than having the systemperform these tasks autonomously. also, some users may
ﬁnd it useful to have the system provide active assistance
in adapting a process deﬁnition, while others would prefer
the system not to intervene without their explicit request.
in every case, the change feedback cycle should provide
and store extensive history information , i.e. an explicit log
of actions performed in the feedback cycle, and their inter-
mediate results. this enables users and administrators to
trace the motivation for a change, and thereby to under-
stand the system. the progress of autonomous adaptation
can thereby be monitored both by administrative staﬀ, and
ultimately by the system itself.
when such feedback cycle is designed and implemented
consistently, the resulting system is able to provide user
guidance and autonomous administration to an unprece-
dented degree. moreover, the tight integration of adaptive
pmss and process mining technologies provides a powerful
foundation, on which a new generation of truly intelligent
and increasingly autonomous paiss can be built.
4 anatomy of change
in this section we provide basic deﬁnitions for process
schema ,schema change , andchange log . we assume that a
process change will be accomplished by applying a sequence
of change operations to the respective process schema over
time(reichert and dadam, 1998). respective change op-
erations modify a process schema, either by altering the
set of activities or by changing their ordering relations.
thus, each application of a change operation to a process
5schema results in another schema. the challenging ques-
tion is how to represent this change information within
change logs. independent from the applied (high-level)
change operations (e.g., adding, deleting or moving activi -
ties) we could translate the change into a sequence of basic
change primitives (i.e., basic graph primitives like addnode
ordeleteedge ). this still would enable us to restore pro-
cess structures, but also result in a loss of information
about change semantics and therefore limit change anal-
ysis signiﬁcantly. therefore, change logs should explicit ly
maintain information about high-level change operations,
which combine basic primitives in a certain way.
a process schema can be described formally without se-
lecting a particular notation, i.e., we abstract from the
concrete operators of the process modeling language and
usetransition systems to deﬁne the possible behavior.
deﬁnition 1 (transition system) .a (labeled) transition
system is a tuple ts= (s, e, t, s i)where sis the set of
states, eis the set of events, t⊆s×e×sis the transition
relation, and si∈sis the initial state.
an example of a simple transition system is ts=
(s, e, t, s i) with s={a, b, c}(three states), e=
{x, y, z }(three events), t={(a, x, a ),(a, y, b),(b, z, a),
(b, y, c),(c, z, b),(c, y, c)}(six transitions), and si=a. fig-
ure 3 shows this transition system graphically. the seman-
tics of a transition system are simple, i.e., starting from
the initial state, any path through the transition system
is possible. for example, /an}bracketle{tx, x, x, y, z, x /an}bracketri}ht,/an}bracketle{ty, y, y, z, z, x /an}bracketri}ht,
and/an}bracketle{t/an}bracketri}ht(the empty sequence) are possible behaviors of the
transition system depicted in figure 3.
figure 3: example transition system
a process schema is deﬁned in terms of a transition sys-
tem with a designated ﬁnal state.
deﬁnition 2 (process schema) .a process schema is a
tupleps= (a, sstart, send, ts)where
•ais a set of activities,
•sstartis the initial state of the process,
•sendis the ﬁnal state of the process, and
•ts= (s, e, t, s i)is labeled transition system where
sis the set of states, e=a∪ {τ}is the set of events
(i.e., all activities extended with the so-called “silent
step” τ),t⊆s×e×sis the transition relation,
sstart=siis the initial state, and send∈sis the
ﬁnal state of the process.
pis the set of all process schemas.the behavior of a process is described in terms of a tran-
sition system tswith some initial state sstartand some
ﬁnal state send. the transition system does not only deﬁne
the set of possible traces (i.e., execution orders); it also cap-
tures the moment of choice. moreover, it allows for “silent
steps”. a silent step, denoted by τ, is an activity within
the system which changes the state of the process, but is
not observable in execution logs. this way we can distin-
guish between diﬀerent types of choices (internal/externa l
or controllable/uncontrollable). note that senddenotes the
correct , and thus desirable, ﬁnal state of a process. if the
process schema is incorrectly speciﬁed or executed, there
may be further possible ﬁnal states. however, we take the
correctness of process schemas as precondition, and there-
fore the assumption of a single ﬁnal state is valid. a simple
example of a process schema, consisting of a sequence of
ﬁve activities, is shown in figure 4.
note that figure 4 uses some ad-hoc notation inspired
by the adept system. this does not mean that we advo-
cate a particular modeling language. any process modeling
language having operational semantics can be mapped onto
a labeled transition system. we only assume that such
a mapping exists. the choice of a suitable language is a
topic by itself. for example, some authors advocate a more
goal driven approach (bider et al., 2002; soﬀer and wand,
2004) while others stress concurrency aspects (glabbeek
and weijland, 1996; kiepuszewski, 2002). however, in this
paper we abstract from these issues and focus on process
changes independent of the language chosen.
based on deﬁnition 2, change logs can be deﬁned as
follows:
deﬁnition 3 (change log) .letpbe the set of possible
process schemas and cthe set of possible process changes,
i.e., any process change ∆is an element of c. achange log
instance σis a sequence of process changes performed on
some initial process schema ps∈ p, i.e., σ∈ c∗(where
c∗is the set of all possible sequences over c). achange
loglis a set of change log instances, i.e., l⊆ c∗.
note that a change log is deﬁned as a set of instances.
it would be more natural to think of a log as a multi-
set (i.e., bag) of instances because the same sequence of
changes may appear multiple times in a log. we abstract
from the number of times the same sequence occurs in the
change log for the sake of simplicity. in this paper we only
consider the presence of changes and not their frequency,
to simplify matters. note that in tools like prom the fre-
quency deﬁnitely plays a role and is used to deal with noise
and to calculate probabilities.
figure 4 shows an example of a change log in column
b). this log is composed of nine change log instances cli1
–cli9. the ﬁrst change log instance cli1, for example,
consists of two consecutive change operations op1 and op2.
changes can be characterized as operations, which are
transforming one process schema into another one. the
same holds for sequences of change operations, i.e. change
log instances. this can be formalized as follows:
6a) process instances                 b) change log instances 
examine
patientdeliver
reportinform
patientprepare
patientinstance i1:lab test
enter
ordercli1= (
op1:=insert(ps, lab test, examinepatient, deliverre port),
op2:=move(ps, informpatient, preparepatient, examin epatient))
cli2= (
op3:=insert(ps, xray, informpatient, preparepatient ), 
op4:=delete(ps, xray),  
op5:=delete(ps, inform patient),
op6:=insert(ps, informpatient, examinepatient, deli verreport), 
op2 =move(ps, informpatient, prepare patient, examin epatient),
op1 =insert(ps, lab test, examinepatient, deliver re port))examine
patientdeliver
reportinform
patientprepare
patientinstance i2:
enter
order
examine
patientdeliver
reportinform
patientprepare
patientinstance i3:lab test
enter
ordercli3= (
op2 =move(ps, informpatient, prepare patient, examin epatient),
op1 =insert(ps, lab test, examinepatient, deliver re port))
examine
patientdeliver
reportinform
patientprepare
patientinstance i4:lab test
enter
ordercli4= (
op1 =insert(ps, lab test, examinepatient, deliver re port))
examine
patientdeliver
reportinform
patientprepare
patientinstance i5:
enter
ordercli5= (
op1 =insert(ps, lab test, examinepatient, deliver re port,
op7:=delete(ps, deliverreport))lab test
lab test
examine
patientdeliver
reportinform
patientprepare
patientinstance i6:lab test
enter
ordercli6= (
op1 =insert(ps, lab test, examinepatient, deliver re port),
op2 =move(ps, informpatient, prepare patient, examin e
patient),
op7 =delete(ps, deliverreport))
cli7= (
op8:= insert(ps, xray, examinepatient, deliverrepor t))
examine
patientdeliver
reportinform
patientprepare
patientinstance i7:
enter
order
examine
patientdeliver
reportinform
patientprepare
patientinstance i8:lab test
enter
ordercli8= (
op2 =move(ps, informpatient, prepare patient, examin epatient),
op8 =insert(ps, xray, examine patient, deliver report ),
op9:=insert(ps, lab test, xray, deliverreport))
examine
patientdeliver
reportinform
patientprepare
patientinstance i9:lab test
enter
ordercli9= (
op1 =insert(ps, lab test, examinepatient, deliver re port),
op10:=insert(ps, xray, examine patient, lab test))xray
xray
xray
figure 4: modiﬁed process instances and associated change l og instances
deﬁnition 4 (change in process schemas) .let
ps, ps′∈ pbe two process schemas, let ∆∈ cbe a pro-
cess change, and σ=/an}bracketle{t∆1,∆2, . . .∆n/an}bracketri}ht ∈ c∗be a change
log instance.
•ps[∆/an}bracketri}htif and only if ∆is applicable to ps, i.e., ∆is
possible in ps.
•ps[∆/an}bracketri}htps′if and only if ∆is applicable to ps
(i.e., ps[∆/an}bracketri}ht) and ps′is the process schema result-ing from the application of ∆tops.
•ps[σ/an}bracketri}htps′if and only if there are process schemas
ps1, ps2, . . .ps n+1∈ pwithps=ps1,ps′=
psn+1, and for all 1≤i≤n:psi[σ/an}bracketri}htpsi+1.
•ps[σ/an}bracketri}htif and only if there is a ps′∈ psuch that
ps[σ/an}bracketri}htps′.
the applicability of a change operation to a speciﬁc pro-
cess schema is deﬁned in table 1, and is largely dictated
7by common sense. for example, an activity xcan only be
inserted into a schema ps, between the node sets aand
b, if these node sets are indeed contained in psand the
activity xis not already contained in ps. note that we do
not allow duplicate tasks, i.e. an activity can be contained
only once in a process schema.
for an example, consider the ﬁrst process instance i1,
and its associated change log instance cli1, in figure 4 .
the ﬁrst change performed, op1, is inserting a new activ-
ity “lab test” between activities “examine patient” and
“deliver report”. obviously, this change is applicable to
the original process schema (the horizontal sequence of ﬁve
activities), the resulting process schema being a sequence
of six activities including “lab test”. the second change
operation, op2, moves the second activity “inform patient”
one position to the right, between activities “prepare pa-
tient” and “examine patient”. this change is applicable
to the process schema resulting from change operation op1,
which in turn makes the sequence cli1applicable to the
original process schema.
any change log refers to a speciﬁc process schema, which
has been the subject of change. thus, whether a speciﬁc
change log is valid can only be determined by also taking
into account the original process schema:
deﬁnition 5 (valid change log) .letps∈ pbe a pro-
cess schema and l⊆ c∗a change log for ps.lis valid
with respect to psif for all σ∈l:ps[σ/an}bracketri}ht.
figure 4 shows an example for a valid change log in
column b), consisting of nine change log instances cli1
–cli9, which are all applicable to the original process
schema.
as mentioned, in this paper we represent change log en-
tries by means of high-level change operations since we
want to exploit their semantical content (see figure 4 for
an example). however, basically, the mining approaches
introduced later can be adapted to change primitives as
well. table 1 presents examples of high-level change oper-
ations on process schemas which can be used at the process
type as well as at the process instance level to create or
modify process schemas. although the change operations
are exemplarily deﬁned on the adept meta model (see
?for details) they are generic in the sense that they can
be easily transferred to other meta models as well (e.g.
(reichert et al., 2003)).
5 change mining
in this section we describe novel approaches for analyz-
ing change log information, as found in adaptive pmss.
first, we describe how change logs can be mapped onto
the mxml format used for process mining. this makes
it possible to evaluate the application of traditional pro-
cess mining algorithms to change logs. subsequently, we
explore the nature of change logs in more detail. this is fol-
lowed by an introduction to the concept of commutativitybetween change operations in section 5.4. this commu-
tativity relation provides the foundation for our ﬁrst min-
ing algorithm for change processes, as introduced in sec-
tion 5.5. a second algorithm for mining change processes
based on the theory of regions is presented in section 5.6,
and section 5.7 compares both approaches. finally, sec-
tion 5.8 sketches how context information may be used to
investigate the drivers for change (i.e., whychanges occur)
in future work.
5.1 mapping change logs to mxml
change log information can be structured on a number of
diﬀerent levels. most of all, change events can be grouped
by the process deﬁnition they address. as we are focusing
on changes applied to cases, i.e. executed instances of a
process deﬁnition, the change events referring to one pro-
cess can be further subdivided with respect to the speciﬁc
case in which they were applied (i.e. into change process
instances). finally, groups of change events on a case level
are naturally sorted by the order of their occurrence.
the described structure of change logs ﬁts well into
the common organization of enactment logs, with instance
traces then corresponding to consecutive changes of a pro-
cess schema, in contrast to its execution. thus, change logs
can be mapped to the mxml format with minor modiﬁ-
cations. listing 1 shows an mxml audit trail entry de-
scribing the insertion of a task “lab test” into a process
schema, as e.g. seen for instance i1in figure 4.
<audittrailentry>
<data>
<attribute name="change.postset">deliver_report
</attribute>
<attribute name="change.type">insert
</attribute>
<attribute name="change.subject">lab_test
</attribute>
<attribute name="change.rationale">ensure that
blood values are within specs.
</attribute>
<attribute name="change.preset">examine_patient
</attribute>
</data>
<workflowmodelelement>insert.lab_test
</workflowmodelelement>
<eventtype>complete
</eventtype>
<originator>n.e.body
</originator>
</audittrailentry>
listing 1: example of a change event in mxml.
change operations are characterized by the type
(e.g., “insert”) of change, the subject which has been
primarily aﬀected (e.g., the inserted task), and the syntac-
tical context of the change. this syntactical context con-
tains the change operation’s pre-andpost-set , i.e., adjacent
process schema elements that are either directly preceding
or following the change subject in the process deﬁnition.
as these speciﬁc properties are not covered by the mxml
format, they are stored as attributes in the “data” ﬁeld.
the set of attributes for a change event is completed by an
optional rationale ﬁeld, storing a human-readable reason,
8table 1: examples of high-level change operations on process schema s
change operation ∆applied to s optype subject paramlist
insert(ps, x, a, b, [sc]) insert x ps, a, b, [ sc]
eﬀects on ps: inserts activity x between node sets a and b (it is a condition al insert if scis speciﬁed)
preconditions: node sets a and b must exist in ps, and x must not be contained in ps yet
(i.e., no duplicate activities!)
delete(ps, x) delete x ps
eﬀects on ps: deletes activity x from ps
preconditions: activity x must be contained exactly once in ps
move(ps, x, a, b, [sc]) move x ps, a, b, [ sc]
eﬀects on ps: moves activity x from its original position between node set s a and b
(it is a conditional insert if scis speciﬁed)
preconditions: activity x and node sets a and b must be contained exactly once in ps
replace(ps, x, y) replace x y
eﬀects on ps: replaces activity x by activity y
preconditions: activity x must be contained exactly once in ps, and activiti es x and y
must be of the same type (e.g., have the same input / output par ameters)
or incentive, for this particular change.
theoriginator ﬁeld is used for the person having applied
the respective change, while the timestamp ﬁeld describes
the concise date and time of occurrence. change events
have the event type “complete” by default, because they
can be interpreted as atomic operations. in order to re-
tain backward compatibility of mxml change logs with
traditional process mining algorithms, the workﬂow model
element needs to be speciﬁed for each change event. as
the change process does not follow a predeﬁned process
schema, this information is not available. thus, a concate-
nation of change type and subject, uniquely identifying the
class of change, is used.
once the change log information is mapped and con-
verted to mxml, it can be mined by any process mining
algorithm, e.g. in the prom framework. the next section
investigates the appropriateness of traditional process m in-
ing algorithms in the context of change logs.
5.2 evaluation of existing mining techniques
as discussed in the previous subsection, mapping process
change logs to the existing mxml format for execution
logs enables the use of existing mining algorithms (e.g.,
as implemented within the prom framework) for mining
change logs as well. in the following we discuss how “well”
these algorithms perform when being applied to change
logs. the underlying evaluation has been carried out using
an extension of the adept demonstrator (waimer, 2006).
for evaluation purposes, the change processes generated
by the diﬀerent mining algorithms are compared along se-
lected quality criteria. the most important criterion is
how ”well” a change process reﬂects the actual depen-
dencies between the operations contained within the input
change log. as for process instance i2, for example, change
operation op4depends on previous change operation op3
(cf. figure 4). this dependency should be reﬂected as
a sequence op3− →op4within the resulting change pro-cess. contrary, independent change operations should be
ordered in parallel within the resulting change process.
in our evaluation we analyzed the αalgorithm, the
multi-phase miner, and the heuristics miner (waimer,
2006). all of these algorithms reﬂect the actual dependen-
cies between the change operations quite “well” for simple
processes and a restricted set of change operations. the
quality of the mined change processes decreases rapidly
(i.e., dependencies are generated by the mining algorithms
which are actually not existing and the change processes
become less and less meaningful) if diﬀerent change op-
erations are applied and the underlying processes become
more complex. the fundamental problem is that process
changes tend to be rather infrequent, i.e., compared to
regular logs there are relatively few cases to learn from.
therefore, the completeness of change logs, i.e. their prop-
erty to record independent (i.e. parallel) activities in an y
possible order, cannot be taken for granted due to their
limited availability. this has been simulated by using an
incomplete subset of change logs, as can be expected in a
real-life situation.
our experiments with applying existing process mining
algorithms to change logs have shown that their suitabil-
ity in this context is limited. in the following section, we
explore the nature of change in an adaptive system and
the associated logs in more detail to ﬁnd a more suitable
means for detecting whether an observed ordering relation
is actually necessary.
5.3 motivation: characterization of change logs
change logs, in contrast to regular enactment logs, do not
describe the execution of a deﬁned process. this is obvi-
ous from the fact that, if the set of potential changes would
have been known in advance, then these changes could have
already been incorporated in the process schema (mak-
ing dynamic change obsolete). thus, change logs must be
interpreted as emerging sequences of activities which are
9taken from a set of change operations.
in section 5.1 it has been deﬁned that each change op-
eration refers to the original process schema through three
associations, namely the subject ,pre-set , and post-set of
the change. as all these three associations can theoret-
ically be bound to any subset from the original process
schema’s set of activities1, the set of possible change oper-
ations grows exponentially with the number of activities in
the original process schema. this situation is fairly diﬀer -
ent from mining a regular process schema, where the num-
ber of activities is usually rather limited (e.g., up to 50–1 00
activities). hence, the mining of change processes poses an
interesting challenge. summarizing the above characteris -
tics, we can describe the meta-process of changing a pro-
cess schema as a highly unstructured process, potentially
involving a large number of distinct activities . these prop-
erties, when faced by a process mining algorithm, typically
lead to overly precise and confusing “spaghetti-like” mod-
els. in order to come to a more compact representation of
change processes, it is helpful to abstract from a certain
subset of ordering relations between change operations.
when performing process mining on enactment logs (i.e.,
the classical application domain of process mining), the
state of the mined process is treated like a “black box”.
this is necessary because enactment logs only indicate
transitions in the process, i.e. the execution of activities.
however, the information contained in change logs allows
totrace the state of the change process , which is in fact
deﬁned by the process schema that is subject to change.
moreover, one can compare the eﬀects of diﬀerent (se-
quences of) change operations. from that, it becomes pos-
sible to explicitly detect whether two consecutive change
operations can also be executed in the reverse order with-
out changing the resulting state.
the next section introduces the concept of commuta-
tivity between change operations, which is used to reduce
the number of ordering relations by taking into account
the semantic implications of change events.
5.4 commutative and dependent change opera-
tions
when traditional process mining algorithms are applied
to change logs, they often return very unstructured,
“spaghetti-like” models of the change process (cf. sec-
tion 5.3). this problem is due to a large number of or-
dering relations which do not reﬂect actual dependencies
between change operations. the concept of commutativity
is an eﬀective tool for determining, whether there indeed
exists a causal relation between two consecutive change
operations.
as discussed in section 4 (cf. deﬁnition 4), change op-
erations (and sequences thereof) can be characterized as
transforming one process schema into another one. thus,
in order to compare sequences of change operations, and to
1in this paper we assume that the subject ﬁeld is limited to one
activity.derive ordering relations between these changes, it is help -
ful to deﬁne an equivalence relation for process schemas.
deﬁnition 6 (equivalent process schemas) .let≡be
some equivalence relation. for ps1, ps2∈ p:ps1≡
ps2if and only if ps1andps2are considered to be equiv-
alent.
there exist many notions of process equivalence. the
weakest notion of equivalence is trace equivalence (kie-
puszewski, 2002; rinderle et al., 2004), which regards two
process schemas as equivalent if the sets of observable
traces they can execute are identical. since the number
of traces a process schema can generate may be inﬁnite,
such comparison may be complicated. moreover, since
trace equivalence is limited to comparing traces, it fails
to correctly capture the moment at which choice occurs in
a process. for example, two process schemas may gener-
ate the same set of two traces {abc, abd }. however,
the process may be very diﬀerent with respect to the mo-
ment of choice, i.e. the ﬁrst process may already have a
choice after ato execute either bcorbd, while the sec-
ond process has a choice between canddjust after b.
branching bisimilarity is one example of an equivalence,
which can correctly capture this moment of choice. for a
comparison of branching bisimilarity and further equiva-
lences the reader is referred to (glabbeek and weijland,
1996). in the context of this paper, we abstract from a
concrete notion of equivalence, as the approach described
can be combined with diﬀerent process modeling notations
and diﬀerent notions of equivalence.
based on the notion of process equivalence we can now
deﬁne the concept of commutativity between change oper-
ations.
deﬁnition 7 (commutativity of changes) .letps∈ p
be a process schema, and let ∆1and∆2be two process
changes. ∆1and∆2are commutative in psif and only
if:
•there exist ps1, ps2∈ psuch that ps[∆1/an}bracketri}htps1and
ps1[∆2/an}bracketri}htps2,
•there exist ps3, ps4∈ psuch that ps[∆2/an}bracketri}htps3and
ps3[∆1/an}bracketri}htps4,
•ps2≡ps4.
two change operations are commutative if they have
exactly the same eﬀect on a process schema, regardless of
the order in which they are applied. if two change opera-
tions are not commutative, we regard them as dependent ,
i.e., the eﬀect of the second change depends on the ﬁrst
one. the concept of commutativity eﬀectively captures
the ordering relation between two consecutive change op-
erations. if two change operations are commutative ac-
cording to deﬁnition 7 they can be applied in any given
order, therefore there exists no ordering relation between
them.
in the next subsection we demonstrate that existing pro-
cess mining algorithms can be enhanced with the concept
10of commutativity, thereby abstracting from ordering rela-
tions that are irrelevant from a semantical point of view
(i.e., their order does not inﬂuence the resulting process
schema).
5.5approach 1: enhancing multi-phase mining
with commutativity
mining change processes is to a large degree identical to
mining regular processes from enactment logs. therefore,
we have chosen not to develop an entirely new algorithm,
but rather to base our ﬁrst approach on an existing pro-
cess mining technique. among the available algorithms,
themulti-phase algorithm (dongen and aalst, 2004) has
been selected, which is very robust in handling ambiguous
branching situations (i.e., it can employ the “or” seman-
tics to split and join nodes, in cases where neither “and”
nor “xor” are suitable). although we illustrate our ap-
proach using a particular algorithm, it is important to note
that any process mining algorithm based on explicitly de-
tecting causalities can be extended in this way (e.g., also
the diﬀerent variants of the α-algorithm).
the multi-phase mining algorithm is able to construct
basic workﬂow graphs, petri nets, and epc models from
the causality relations derived from the log. for an in-
depth description of this algorithm, the reader is referred
to (dongen and aalst, 2004). the basic idea of the multi-
phase mining algorithm is to discover the process schema
in two steps. first a model is generated for each individ-
ual process instance. since there are no choices in a single
instance, the model only needs to capture causal depen-
dencies. using causality relations derived from observed
execution orders and the commutativity of speciﬁc change
operations, it is relatively easy to construct such instanc e
models. in the second step these instance models are ag-
gregated to obtain an overall model for the entire set of
change logs.
the causal relations for the multi-phase algorithm (don-
gen and aalst, 2004) are derived from the change log as
follows. if a change operation ais followed by another
change bin at least one process instance, and no instance
contains bfollowed by a, the algorithm assumes a possible
causal relation from atob(i.e., “ amay cause b”). in
the example log introduced in figure 4, instance i2features
a change operation deleting “inform patient” followed by
another change, inserting the same activity again. as no
other instance contains these changes in reverse order, a
causal relation is established between them.
figure 5 shows a petri net model (desel et al., 2004) of
the change process mined from the example change log in-
stances in figure 4. the detected causal relation between
deleting and inserting “inform patient” is shown as a di-
rected link between these activities. note that in order
to give the change process explicit start and end points,
respective artiﬁcial activities have been added. although
the model contains only seven activities, up to three of
them can be executed concurrently. note further that the
process is very ﬂexible, i.e. all activities can potentiall y beskipped. from the very small data basis given in figure 4,
where change log instances hardly have common subse-
quences, this model delivers a high degree of abstraction.
when two change operations are found to appear in both
orders in the log, it is assumed that they can be executed
in any order. an example for this is inserting “xray” and
inserting “lab test”, which appear in this order in instance
i8, and in reverse order in instance i9. as a result, there
is no causal relation, and thus no direct link between these
change operations in the model shown in figure 5.
apart from observed concurrency, as described above,
we can introduce the concept of commutativity-induced
concurrency , using the notion of commutativity introduced
in the previous subsection (cf. deﬁnition 7). from the
set of observed causal relations, we can exclude causal re-
lations between change operations that are commutative.
for example, instance i2features deleting activity “xray”
directly followed by deleting “inform patient”. as no other
process instance contains these change operations in re-
verse order, a regular process mining algorithm would es-
tablish a causal relation between them.
however, it is obvious that it makes no diﬀerence in
which order two activities are removed from a process
schema. as the resulting process schemas are identical,
these two changes are commutative . thus, we can safely
discard a causal relation between deleting “xray” and
deleting “inform patient”, which is why there is no link
in the resulting change process shown in figure 5.
commutativity-induced concurrency removes unneces-
sary causal relations, i.e. those causal relations that do
not reﬂect actual dependencies between change operations.
extending the multi-phase mining algorithm with this con-
cept signiﬁcantly improves the clarity and quality of the
mined change process. if it were not for commutativity-
induced concurrency, every two change operations would
need to be observed in both orders to ﬁnd them concur-
rent. this is especially signiﬁcant in the context of change
logs, since one can expect changes to a process schema to
happen far less frequently than the actual execution of the
schema, resulting in less log data.
5.6approach 2: mining change processes with
regions
the second approach towards mining change logs uses an
approach based on the theory of regions (cortadella et al.,
1998) and exploits the fact that a sequence of changes de-
ﬁnes a state , i.e., the application of a sequence of changes
to some initial process schema results in another pro-
cess schema. the observation that a sequence of changes
uniquely deﬁnes a state and the assumption that changes
are “memoryless” (i.e., the process schema resulting after
the change is assumed to capture all relevant information)
are used to build a transition system . using the theory or
regions, this transition system can be mapped onto a pro-
cess model (e.g., a petri net) describing the change process .
in deﬁnition 2 we already used the concept of a transi-
tion system to describe the behavioral aspect of a process
11start
insert labtest
( op1 )
delete deliver report
( op7 )
end insert xray 
( op3 )
delete xray 
( op4 )delete inform patient 
( op5 )
insert inform patient 
( op6 )
move inform patient 
( op2 )
figure 5: mined example process (petri net notation)
schema. however, now we use it as an intermediate for-
mat for representing change processes. as indicated in sec-
tion 4 we do not advocate transition systems as an end-user
language. any modeling language having formal semantics
can be mapped onto a transition system. the reverse is
less obvious, but quite essential for our approach. there-
fore, we ﬁrst explain the “theory of regions” (cortadella
et al., 1998; ehrenfeucht and rozenberg, 1989) which al-
lows us to translate a transition system into a graphical
process model.
as indicated at the start of this section, transition sys-
tems can be mapped onto petri nets using synthesis tech-
niques based on the so-called regions (cortadella et al.,
1998; ehrenfeucht and rozenberg, 1989). an example of a
tool that can create a petri net for any transition system
using regions is petrify (cortadella et al., 1997).
the theory of regions takes a transition system and con-
verts it into an equivalent petri net. in this paper we do
not elaborate on the theory and only present the basic idea.
given a transition system ts= (s, e, t, s i), a subset of
states s′⊆sis aregion if for all events e∈eone of the
following properties holds:
•all transitions with event eenter the region , i.e., for
alls1, s2∈sand (s1, e, s2)∈t:s1/ne}ationslash∈s′ands2∈s′,
•all transitions with event eexit the region , i.e., for all
s1, s2∈sand (s1, e, s2)∈t:s1∈s′ands2/ne}ationslash∈s′, or
•all transitions with event edo not “cross” the region ,
i.e., for all s1, s2∈sand (s1, e, s2)∈t:s1, s2∈s′
ors1, s2/ne}ationslash∈s′.
the basic idea of using regions is that each region s′
corresponds to a place in the corresponding petri net and
that each event corresponds to a transition in the corre-
sponding petri net. all the events that enter a particularregion are the transitions producing tokens for the corre-
sponding place and all the events that leave the region
are the transitions consuming tokens from this place. in
the original theory of regions (ehrenfeucht and rozenberg,
1989) many simplifying assumptions are made and it was
impossible to have multiple petri net transitions with the
same label and silent steps could no be handled. however,
tools such as petrify (cortadella et al., 1997) based on the
approach described in (cortadella et al., 1997, 1998) can
deal with any transition system.
to illustrate the idea consider the transition system
shown in figure 6. using regions we obtain the petri net
shown in figure 7. this petri net was obtained automat-
ically using a combination of prom and petrify. clearly
this petri net reveals the behavior implied by figure 6 in
a compact and readable manner. this example shows the
potential of applying logs to transition systems with more
parallelism. note that although the process in figure 7 is
represented in terms of a petri net, the idea is not limited
to petri nets. using prom we can easily map the model
onto another notation e.g. epcs, bpmn, yawl, bpel,
etc. note that all of this functionality has been realized in
prom.
figures 6 and 7 illustrate the idea of folding a transition
system into a process model like e.g. a petri net. therefore,
the challenge of mining changes process is reduced to the
construction of a transition system based on a change log.
to do this we ﬁrst introduce some useful notations.
deﬁnition 8 (useful notations) .letps∈ pbe a process
schema and let σ=/an}bracketle{t∆1,∆2, . . .∆n/an}bracketri}ht ∈lbe a change log
instance from some valid log l.
•σ(k) = ∆ kis the kthelement of σ(1≤k≤n),
•hd(σ, k) =/an}bracketle{t∆1,∆2, . . .∆k/an}bracketri}htis the sequence of the ﬁrst
kelements ( 0≤k≤n) ofσ(with hd (σ,0) =/an}bracketle{t /an}bracketri}ht),
12s0
s1
op3start
s4 s2s9
s5s12op1
op2
s6 s7
s8
se
ends13
s14s3s11 s10
s15op2op3
op1op3
op2
op1
op3op2op1
op4op5op6
op6 op7
op7op6
op9
op10
figure 6: a transition system with more parallelism
figure 7: screenshot of prom showing the petri net obtained f or the transition system depicted in figure 6
•state(ps, σ, k ) =ps′where ps[hd(σ, k)/an}bracketri}htps′, i.e.,
ps′is the process schema after the ﬁrst kchanges
have been applied.
deﬁnition 8 shows that given an initial process schema
psand a change log instance σ, it is possible to construct
the process schema resulting after executing the ﬁrst k
changes in σ.state(ps, σ, k ) is the state after applying
∆1,∆2, . . .∆k. note that state(ps, σ, 0) =psis the ini-
tial process and state(ps, σ, n ) is the state after applying
all changes listed in σ.
using the notations given in deﬁnition 8 it is fairly
straightforward to construct a transition system based on
an initial process schema and a log. the basic idea is as
follows. the states in the transition system correspond
to all process schemas visited in the log, i.e., the initial
process schema is a possible state, all intermediate proces s
schemas (after applying some but not all of the changes)
are possible states, and all ﬁnal process schemas are pos-
sible states of the resulting transition system. there is a
transition possible from a state ps1in the transition sys-
tem to another state ps2if in at least one of the change
log instances ps1is changed into ps2.
deﬁnition 9 (transition system of a change log) .let
ps∈ pbe a process schema and la valid change log for
ps.ts(ps,l)= (s, e, t, s i)is the corresponding transi-tion system , where s={state(ps, σ, k )|σ∈l∧0≤
k≤ |σ|}is the state space, e={σ(k)|σ∈l∧1≤
k≤ |σ|}is the set of events, t={(state(ps, σ, k ), σ(k+
1),state(ps, σ, k + 1)) |σ∈l∧0≤k <|σ|}is the
transition relation, and si=psis the initial state (i.e.,
the original process schema).
note that this approach assumes that changes are mem-
oryless , i.e., the set of possible changes depends on the
current process schema and not on the path leading to
the current process schema. this means that if there are
multiple “change paths” leading to a state ps′, then the
next change in any of these paths is possible when one is
in state ps′. in other words: only the current process
schema for the change process matters and not the way it
was obtained. note that this assumption is similar, but
also diﬀerent, from the assumption in the ﬁrst approach:
there commutative changes are assumed to occur in any
order even when this has not been observed.
for technical reasons it is useful to add a unique start
event start and state s0and a unique end event endand
statese. this can be achieved by adding start andendto
respectively the start and end of any change log instance.
it can also be added directly to the transition system.
deﬁnition 10 (extended transition system of a change
log).letps∈ pbe a process schema and la valid
13change log for ps.ts(ps,l)= (s, e, t, s i)is as de-
ﬁned in deﬁnition 9. let s0,se,start, and endbe fresh
identiﬁers. ts∗
(ps,l)= (s∗, e∗, t∗, s∗
i)is the extended
transition system , where s∗=s∪ {s0, se},e∗=e∪
{start, end },t∗=t∪(/uniontext
σ∈l{(s0, start, state(ps, σ, 0)),
(state(ps, σ, |σ|), end, s e)}), and s∗
i=s0.
figure 8 shows the transition system obtained by ap-
plying deﬁnition 10 to the running example, i.e., the
change log depicted in figure 4 (consisting of nine change
log instances and ten diﬀerent change operations) is used
to compute ts∗
(ps,l). for convenience we use short-
hands for activity names: eo = enter order ,ip = in-
form patient ,pp = prepare patient ,ep = examine pa-
tient,dr = deliver report ,lt = lab test , and xr
= x-ray . figure 4 deﬁnes ten diﬀerent change opera-
tions, these correspond to the events in the transition sys-
tem. moreover, the artiﬁcial start and end are added.
hence e={start, op 1, op2, . . ., op 10, end}is the set of
events. the application of a change operation to some
process schema, i.e., a state in figure 8, results in a
new state. since in this particular example all process
schemas happen to be sequential, we can denote them
by a simple sequence as shown in figure 8. for exam-
ple,s1 = /an}bracketle{teo, ip, pp, ep, dr /an}bracketri}htis the original process
schema before applying any changes. when in the ﬁrst
change log instance op1 is applied to s1the resulting
state is s2 =/an}bracketle{teo, ip, pp, ep, lt, dr /an}bracketri}ht(i.e., the process
schema with the lab test added). when in the same change
log instance op2 is applied to s2the resulting state is
s3 =/an}bracketle{teo, pp, ip, ep, lt, dr /an}bracketri}ht(i.e., the process schema
where inform patient is moved). this can be repeated for
all nine instances, resulting in ﬁfteen states plus the two
artiﬁcial states, i.e., s={s0, s1, . . ., s 15, se}. using the
approach deﬁned in deﬁnitions 9 and 10, the transition
system shown in figure 8 is obtained.
after constructing the transition system, the theory of
regions can be used to construct a process model. fig-
ure 9 shows the petri net constructed using this approach.
note that using a combination of prom and petrify the
log is coverted to the transition system of figure 8 which
is then folded into the petri net depicted in figure 9. in
this case the petri net is more or less identical to the tran-
sition system. one can use petrify with diﬀerent settings.
this way it is possible to construct a more compact petri
net, however, this process model is less readable. at ﬁrst
sight, it may be disappointing to see the petri net shown in
figure 9. however, one should note that the change log de-
picted in figure 4 only has nine change log instances, i.e.,
compared to the number of change operations, the number
of instances is rather low. it seems that only a few of the
possible interleavings are present in figure 4. as a result,
the transition system in figure 9 seems to be the result of
a number of particular examples rather than a description
of the full behavior. figures 6 and 7 show that using the
theory of regions it is possible to dramatically reduce the
size of the model if more interleavings are present.5.7 comparing both approaches
we have introduced two new process mining approaches
based on the characteristics of change logs. the ﬁrst ap-
proach is based on the multi-phase algorithm (dongen and
aalst, 2004). however, the original algorithm has been
enhanced to exploit information about commutativity of
change operations. if there are independent changes (i.e.,
changes that operate on diﬀerent parts of the schema), it
is not necessary to see all permutations to conclude that
they are in parallel. the second approach is based on
the observation that given an original schema and a se-
quence of change operations, it is possible to reconstruct
the resulting process schema. this can be used to derive a
transition system where the states are represented by pos-
sible (intermediate) process schemas. using regions such a
transition model can be translated into an equivalent petri
net describing the change process.
in this section, we applied the two approaches to an ex-
ample log. this allows us to compare both. the petri net
in figure 9 is very diﬀerent from the one in figure 5. this
illustrates that both approaches produce diﬀerent results ,
i.e.,they provide two fundamentally diﬀerent ways of look-
ing at change processes . it seems that in this particular ex-
ample, the ﬁrst approach performs better than the second.
this seems to be a direct consequence of the small amount
of change log instances (just nine) in comparison with the
possible number of change operations. when there is an
abundance of change log instances, the second approach
performs better because it more precisely captures the ob-
served sequences of changes. moreover, the second step
could be enhanced by generalization operations at the tran-
sition system level, e.g., using commutativity.
5.8 towards learning about the context of
change
understanding how process change information can be rep-
resented in logs and how these logs can be mined to de-
liver valuable insights into the scope of change delivers in -
sights of howprocesses deviate from predeﬁned routines.
this is a signiﬁcant move towards understanding whysuch
changes occur, viz., the drivers for change). these drivers
can be found in the context of a process (rosemann et al.,
2006).
in general terms, the context of a business process is
made up by all the relevant information that is available
at some stage during the execution of a business process,
and that could potentially have inﬂuenced decisions in this
process. it can be seen as the set of process data and infor-
mation that is relevant to the process execution but typi-
cally not deﬁned in the process deﬁnition itself, which, fol -
lowing existing classiﬁcation schemes (jablonski and bus-
sler, 1996), would at least include the control ﬂow logic,
involved informational data, and organizational resource s.
context information can be retrieved from a wide range of
potential data sources. enactment logs, for instance, ofte n
include information about time and value of a data mod-
14s0
s1op3start
s4
op4
s2
s9s5 s12op8op5op1
op2
s6
s7
s8op6
op2
op1
seendends13
s14op8
endop9s3op2
op1
s11op7
endends10s15end
op10
op7
endendendactivity names:
eo = enter order
ip = inform patient
pp= prepare patient
ep = examine patient
dr = deliver report
lt = lab test
xr = x-raystates:
s0 = initial state
se = final state
s1 = <eo,ip,pp,ep,dr>
s2 = <eo,ip,pp,ep,lt,dr>
s3 = <eo,pp,ip,ep,lt,dr>
s4 = <eo,ip,xr,pp,ep,dr>
s5 = <eo,pp,ep,dr>
s6 = <eo,pp,ep,ip,dr>
s7 = <eo,pp,ip,ep,dr>
s8 = <eo,pp,ip,ep,lt,dr>
s9 = <eo,pp,ip,ep,dr>
s10 = <eo,ip,pp,ep,lt>
s11 = <eo,pp,ip,ep,lt>
s12 = <eo,ip,pp,ep,xr,dr>
s13 = <eo,pp,ip,ep,xr,dr>
s14 = <eo,pp,ip,ep,xr,lt,dr>
s15 = <eo,ip,pp,ep,xr,lt,dr>
figure 8: transition system based on the change log shown in f igure 4
figure 9: screenshot of prom showing the petri net obtained f or the change log depicted in figure 4
iﬁcation. as context information is obviously most useful
when timed, a promising means of storage would be to en-
hance change logs with context data. this would allow to
structure the context history in suitable chunks, i.e., the
structural states of a process between change operations.technically, this can be accomplished by examining each
change event, acquiring timed context information for the
time of its occurrence, and then enriching it with elicited
context information.
assuming access to context information, changes in a
15process could be investigated together with the reasons for
the change decisions taken along the execution of a process.
this can be achieved by looking at change process models
and the decision points contained within. however, while
these change process models themselves are already helpful
in developing an understanding of the drivers for change,
they can not be used to actually learn from the change.
learning can be interpreting as deriving information from
an adaptive pms. the fundamental premise is that cases
in which a certain change has been applied will exhibit dis-
tinctpatterns in their context information. as the set of
potential context information can be very large, identifyi ng
the pivotal data elements, or patterns thereof, which are
unique for a speciﬁc change, somehow resembles looking
for a needle in a haystack. fortunately, existing machine
learning (ml) (mitchell, 1997) techniques can solve this
problem. classiﬁcation algorithms , for instance, take for
input a classiﬁed set of examples, the so-called training set .
once this set has been analyzed, the algorithm is capable
of classifying previously unknown examples. training a de-
cision tree algorithm (rozinat and aalst, 2006b) with such
a classiﬁed set may then provide decision trees that visual-
ize how decisions about process change were being made.
other classiﬁcation algorithms from ml can generate a set
of classiﬁcation rules (mitchell, 1997).
these classiﬁcation algorithms by deﬁnition focus on
speciﬁc decisions, i.e., one branching point in the process ,
and are thus dependent on the mining of a change process
model in the ﬁrst place. an alternative to this approach
is the mining of association rules (agrawal et al., 1993).
here, every case is regarded as a set of facts, where a fact
can both be the occurrence of a change operation as well as
a context attribute having a speciﬁc value. after identify-
ing frequent item sets, the algorithm can derive associatio n
rules. these rules describe, for instance, that for a large
fraction of cases where an additional x-ray was inserted,
the patient was older than 65 years and the doctor was
female, an additional blood screening was inserted. asso-
ciation rules are derived in a global manner, viz., the order
in which change operations occur is not taken into account.
this can be beneﬁcial especially when there are hardly any
causal relations between change operations. association
rules may discover tacit relationships between change op-
erations and context data that could not be captured by
classiﬁcation.
in summation, the application of ml techniques appears
promising for the identiﬁcation of the drivers for change
from the context of a process, and for relating them to
one another. we believe that this structured approach
can deliver precise results while still remaining feasible in
practical settings, and can thus a be foundation for the
future design of self-adapting pmss.
5.9 implementation and tool support
we have implemented a complete toolkit which allows for
creating and experimenting with change logs. process
schemas can be designed, executed, and changed in theadept demonstrator prototype (reichert et al., 2005).
the resulting change and enactment logs can then be ex-
tracted with a custom plug-in for prom import (g¨ unther
and aalst, 2006). prom import is an open source frame-
work greatly facilitating the implementation of log con-
versions to mxml for various systems, and can be down-
loaded from http://promimport.sf.net/ . change logs
extracted from adept, or any other adaptive system for
that matter, can then be loaded into prom, an open source
framework for process mining techniques, which is avail-
able athttp://prom.sourceforge.net/ . our change
mining approaches, described in sections 5.5 and 5.6, have
both been implemented as plug-ins for prom. figure 10
shows the plug-in implementing the approach based on
commutativity, introduced in section 5.5. it displays the
example process introduced in figure 4 in terms of a pro-
cess graph.
process mining algorithms have shown to scale well with
the amount of input data. the majority of these algo-
rithms, including the two approaches presented in this pa-
per, work in two distinct phases. the ﬁrst phase scales lin-
early with the number of events contained in the log. the
second phase is of polynomial complexity, where the num-
ber of activities in the process corresponds to the problem
size. these scalability characteristics make process mini ng
applicable to most real-life problems.
6 related work
although process mining techniques have been intensively
studied in recent years (aalst et al., 2004; agrawal et al.,
1998; cook and wolf, 1998; dongen and aalst, 2004), no
systematic research on analyzing process change logs has
been conducted so far. existing approaches mainly deal
with the discovery of process schemas from execution logs,
conformance testing, and log-based veriﬁcation (cf. sec-
tion 2.1). the theory of regions (cortadella et al., 1997,
1998) has also been exploited to mine process schemas from
execution logs (kindler et al., 2006), e.g. from logs descri b-
ing software development processes. however, execution
logs in traditional pmss only reﬂect what has been mod-
eled before, but do not capture information about pro-
cess changes. while earlier work on process mining has
mainly focused on issues related to control ﬂow mining,
recent work additionally uses event-based data for mining
model perspectives other than control ﬂow (e.g., social net -
works (aalst et al., 2005), actor assignments, and decision
mining (rozinat and aalst, 2006b)).
in recent years, several approaches for adaptive process
management have emerged (rinderle et al., 2004), most
of them supporting changes of certain process aspects and
changes at diﬀerent levels. examples of adaptive pmss
include adept (reichert et al., 2005), cbrﬂow (weber
et al., 2004), and wasa (weske, 2001). though these
pmss provide more meaningful process logs when com-
pared to traditional workﬂow systems, so far, only little
work has been done on fundamental questions like what
16figure 10: change mining plug-in within prom.
we can learn from this additional log information, how we
can utilize change logs, and how we can derive optimized
process schemas from them.
cbrflow (weber et al., 2004) has focused on the ques-
tion how to facilitate exception handling in adaptive pmss.
more precisely, it applies conversational case-based rea-
soning (ccbr) in order to assist users in deﬁning ad-
hoc changes and in capturing contextual knowledge about
them. this, in turn, increases the quality of change logs
and change case bases respectively, and therefore provides
new perspectives. cbrflow, for example, supports the
reuse of previous ad-hoc changes when deﬁning new ones
(weber et al., 2004). the retrieval of similar changes is
based on ccbr techniques. ccbr itself is an extension of
the original case-based reasoning (cbr) paradigm, which
actively involves users in the inference process (aha and
munoz-avila, 2001). a ccbr system can be characterized
as an interactive system that, via a mixed-initiative dia-
logue, guides users through a question-answering sequence
in a case retrieval context. later, weber et al. (2006)
further improved the support for change reuse by addi-
tionally discovering dependencies between diﬀerent ad-ho c
changes. in (rinderle et al., 2005; weber et al., 2005)
the cbrflow approach has been extended to a framework
for integrated process life cycle support. in particular,
knowledge from the change case base is applied to con-
tinuously derive improved process schemas. this is similarto our goal for discovering optimized process schemas from
change log. however, we have provided more advanced and
more general mining techniques in this context, whereas
rinderle et al. (2005) particularly make use of semanticall y
enriched log-ﬁles (e.g., information about the frequency o f
a particular change, user ratings, etc.). we will consider
respective semantical and statistical information in our f u-
ture work as well.
7 summary and outlook
this paper gave an overview of how comprehensive support
for true process ﬂexibility can be provided by combining
adaptive pmss with advanced process mining techniques.
the integration of process mining with adaptive pms en-
ables the exploitation of knowledge about process changes
from change logs.
we have developed two mining techniques and imple-
mented them as plug-ins for the prom framework, taking
adept change logs in the mapped mxml format as in-
put. based on this we have sketched how to discover a
(minimal) change process which captures all modiﬁcations
applied to a particular process. this discovery is based on
the analysis of (temporal) dependencies between change
operations that have been applied to a process instance.
meaningful, compact representations of the change pro-
17cess can be derived by either making use of the concept of
commutativity, or by application of the theory of regions,
as has been shown. altogether, the presented approaches
can be very helpful for process engineers to get an over-
view about which instance changes have been applied at
the system level and what we can learn from them. cor-
responding knowledge is indispensable to make the right
decisions with respect to the introduction of changes at
the process type level (e.g., to reduce the need for ad-hoc
changes at the instance level in future).
in our future work we want to further improve user sup-
port by augmenting change processes with additional con-
textual information (e.g., about the reason why changes
have been applied or the originator of the change). from
this we expect better comprehensibility of change decision s
and higher reusability of change knowledge (in similar sit-
uations). the detection of this more context-based infor-
mation will be accomplished by applying advanced min-
ing techniques (e.g., decision mining (rozinat and aalst,
2006b)) to change log information. in a related stream of
work we continue our research on the identiﬁcation and
description of contextual information. we envision that
based on an appropriate way of conceptualizing and identi-
fying context, support can be developed to monitor, mine
and control contextual variables in the environment of a
process, which would in eﬀect allow for true process agility ,
decreased reaction-time, and overall more ﬂexible support
in process design and execution.
acknowledgment
this research has been supported by eit, nwo, su-
per, and the technology foundation stw, applied sci-
ence division of nwo and the technology program of the
dutch ministry of economic aﬀairs. the contributions of
jan recker and wil van der aalst were partly supported
by the australian research council with the arc discov-
ery grant ”next generation reference process models”
(dp0665480).
references
aalst, w., g¨ unther, c., recker, j., and reichert, m.
(2006). using process mining to analyze and improve
process flexibility (position paper). in latour, t. and
petit, m., editors, the 18th international conference on
advanced information systems engineering. proceedings
of workshops and doctoral consortium , pages 168–177.
namur university press.
aalst, w., reijers, h., and song, m. (2005). discovering
social networks from event logs. computer supported
cooperative work , 14(6):549–593.
aalst, w., weijters, a., and maruster, l. (2004). workﬂow
mining: discovering process models from event logs.ieee transactions on knowledge and data engineer-
ing, 16(9):1128–1142.
agrawal, r., gunopulos, d., and leymann, f. (1998).
mining process models from workﬂow logs. in sixth
international conference on extending database tech-
nology , pages 469–483.
agrawal, r., imielinski, t., and swami, a. (1993). min-
ing association rules between sets of items in large
databases. sigmod rec. , 22(2):207–216.
aha, d. and munoz-avila, h. (2001). introduction: inter-
active case-based reasoning. applied intelligence , 14(7-
8).
bider, i. (2005). masking ﬂexibility behind rigidity: note s
on how much ﬂexibility people are willing to cope with.
in castro, j. and teniente, e., editors, caise’05 work-
shops, pages 7–18, porto, portugal. feup.
bider, i., johannesson, p., and perjons, e. (2002). goal-
oriented patterns for business processes. in proceedings
of the hci workshop on goal-oriented business process
modeling (gbmp’02) , volume 109 of ceur workshop
proceedings , pages 1–5. ceur-ws.org.
casati, f., ceri, s., pernici, b., and pozzi, g. (1998).
workﬂow evolution. data and knowledge engineering ,
24(3):211–238.
cook, j. and wolf, a. (1998). discovering models of
software processes from event-based data. acm
transactions on software engineering and methodology ,
7(3):215–249.
cortadella, j., kishinevsky, m., kondratyev, a., lavagno,
l., and yakovlev, a. (1997). petrify: a tool for manip-
ulating concurrent speciﬁcations and synthesis of asyn-
chronous controllers. ieice transactions on informa-
tion and systems , e80-d(3):315–325.
cortadella, j., kishinevsky, m., lavagno, l., and
yakovlev, a. (1998). deriving petri nets from finite
transition systems. ieee transactions on computers ,
47(8):859–882.
desel, j., reisig, w., and rozenberg, g., editors (2004).
lectures on concurrency and petri nets , volume 3098
oflecture notes in computer science . springer-verlag,
berlin.
dongen, b. and aalst, w. (2004). multi-phase process
mining: building instance graphs. in atzeni, p., chu,
w., lu, h., zhou, s., and ling, t., editors, international
conference on conceptual modeling (er 2004) , volume
3288 of lecture notes in computer science , pages 362–
376. springer-verlag, berlin.
dongen, b., medeiros, a., verbeek, h., weijters, a., and
aalst, w. (2005). the prom framework: a new era in
18process mining tool support. in ciardo, g. and daron-
deau, p., editors, proceedings of the 26th international
conference on applications and theory of petri nets
(icatpn 2005) , volume 3536 of lecture notes in com-
puter science , pages 444–454. springer-verlag, berlin.
dumas, m., aalst, w., and hofstede, a. (2005). process-
aware information systems: bridging people and soft-
ware through process technology . wiley & sons.
ehrenfeucht, a. and rozenberg, g. (1989). partial (set)
2-structures - part 1 and part 2. acta informatica ,
27(4):315–368.
ellis, c., keddara, k., and rozenberg, g. (1995). dy-
namic change within workﬂow systems. in comstock,
n., ellis, c., kling, r., mylopoulos, j., and kaplan, s.,
editors, proceedings of the conference on organizational
computing systems , pages 10 – 21, milpitas, california.
acm sigois, acm press, new york.
glabbeek, r. and weijland, w. (1996). branching time
and abstraction in bisimulation semantics. journal of
the acm , 43(3):555–600.
g¨ unther, c. and aalst, w. (2006). a generic import frame-
work for process event logs. in eder, j. and dustdar,
s., editors, business process management workshops,
workshop on business process intelligence (bpi 2006) ,
volume 4103, pages 81–92. springer verlag, berlin.
jablonski, s. and bussler, c. (1996). workﬂow manage-
ment. modeling concepts, architecture, and implemen-
tation . thomson computer press, london, uk.
kiepuszewski, b. (2002). expressiveness and suit-
ability of languages for control flow modelling
in workﬂows . phd thesis, queensland uni-
versity of technology, brisbane. (available via
http://www.workﬂowpatterns.com/) .
kindler, e., rubin, v., and sch¨ afer, w. (2006). process
mining and petri net synthesis. in eder, j. and dust-
dar, s., editors, business process management work-
shops, volume 4103 of lecture notes in computer sci-
ence, pages 105–116. springer verlag, vienna, austria.
mitchell, t. m. (1997). machine learning . mcgraw-hill.
quinn, j. b. (1992). intelligent enterprise: a knowledge
and service based paradigm for industry . free press,
new york, ny.
regev, g. and wegmann, a. (2005). a regulation-based
view on business process and supporting system ﬂexibil-
ity. in castro, j. and teniente, e., editors, proceedings
of the caise’05 workshops. vol. 1 , pages 91–98. feup,
porto, portugal.
reichert, m. and dadam, p. (1998). adeptﬂex - sup-
porting dynamic changes of workﬂows without loos-
ing control. journal of intelligent information systems ,
10(2):93–129.reichert, m., rinderle, s., and dadam, p. (2003). on the
common support of workﬂow type and instance changes
under correctness constraints. in proc. int’l conf. on
cooperative information systems (coopis’03) , lncs
2888, pages 407–425, catania, italy.
reichert, m., rinderle, s., kreher, u., and dadam,
p. (2005). adaptive process management with
adept2. in proc. 21st int’l conf. on data engineering
(icde’05) , pages 1113–1114, tokyo.
rinderle, s., reichert, m., and dadam, p. (2004). cor-
rectness criteria for dynamic changes in workﬂow sys-
tems – a survey. data and knowledge engineering,
special issue on advances in business process manage-
ment, 50(1):9–34.
rinderle, s., reichert, m., jurisch, m., and kreher, u.
(2006). on representing, purging, and utilizing change
logs in process management systems. in proc. int’l
conf. on business process management (bpm’06) , vi-
enna.
rinderle, s., weber, b., reichert, m., and wild, w.
(2005). integrating process learning and process evo-
lution - a semantics based approach. in proc. 3rd
int. conf. on business process management (bpm’05) ,
pages 252–267, nancy.
rosemann, m., recker, j., ansell, p., and flender, c.
(2006). context-awareness in business process design.
in koronios, a. and fitzgerald, e., editors, australasian
conference on information systems , adelaide, aus-
tralia. australasian chapter of the association for in-
formation systems.
rozinat, a. and aalst, w. (2006a). conformance test-
ing: measuring the fit and appropriateness of event
logs and process models. in bussler et al., c., editor,
bpm 2005 workshops (workshop on business process
intelligence) , volume 3812 of lecture notes in computer
science , pages 163–176. springer-verlag, berlin.
rozinat, a. and aalst, w. (2006b). decision mining in
prom. in dustdar, s., faideiro, j., and sheth, a.,
editors, international conference on business process
management (bpm 2006) , volume 4102 of lecture notes
in computer science , pages 420–425. springer-verlag,
berlin.
soﬀer, p. (2005). on the notion of flexibility in busi-
ness processes. in castro, j. and teniente, e., editors,
proceedings of the caise’05 workshops. vol. 1 , pages
35–42. feup, porto, portugal.
soﬀer, p. and wand, y. (2004). goal-driven analysis
of process model validity. in persson, a. and stirna,
j., editors, advanced information systems engineering,
proceedings of the 16th international conference on ad-
vanced information systems engineering (caise’04) ,
volume 3084 of lecture notes in computer science ,
pages 521–535. springer-verlag, berlin.
19strong, d. and miller, s. (1995). exceptions and exception
handling in computerized information processes. acm
transactions on information systems , 13(2):206–233.
waimer, m. (2006). integration of adaptive process man-
agement technology and process mining. (in german).
weber, b., rinderle, s., wild, w., and reichert, m.
(2005). ccbr-driven business process evolution. in
proc. int. conf. on cased based reasoning (iccbr’05) ,
chicago.
weber, b., wild, w., and breu, r. (2004). cbrflow: en-
abling adaptive workﬂow management through conver-
sational case-based reasoning. in proc. eurpean conf.
on case–based reasoning (eccbr’04) , pages 434–448,
madrid.
weber, b., wild, w., lauer, m., and reichert, m. (2006).
improving exception handling by discovering change
dependencies in adaptive process management sys-
tems. in proc. 2nd int’l workshop on business process
intelligence (bpi’06) , pages 93 – 104, vienna.
weske, m. (2001). formal foundation and conceptual de-
sign of dynamic adaptations in a workﬂow management
system. in proc. hawaii international conference on
system sciences (hicss-34) .
20