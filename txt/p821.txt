change your history:
learning from event logs to improve processes
wil m.p. van der aalstywei zhe lowymoe t. wynnyarthur h.m. ter hofstedey
technische universiteit eindhoven (tu/e),
eindhoven, the netherlands
email: w.m.p.v.d.aalst@tue.nlyqueensland university of technology (qut),
brisbane, queensland, australia
e-mail: w4.lowjm.wynnja.terhofstede@qut.edu.au
abstract —the abundance of event data enables new forms
of analysis that facilitate process improvement. process mining
provides a novel set of tools to discover the real process, to
detect deviations from some normative process, and to analyze
bottlenecks and waste. the lion’s share of process mining focuses
on the “as-is” situation rather than the “to-be” situation. clearly,
analysis should aim at actionable insights and concrete sugges-
tions for improvement. however, state-of-the-art techniques do
not allow for this. techniques like simulation can be used to
do “what-if” analysis but are not driven by event data, and
as a result, improvements can be very unrealistic. techniques
for predictive analytics and combinatorial optimization are data-
driven but mostly focus on well-structured decision problems.
operational processes within complex organizations cannot be
mapped onto a simulation model or simple decision problem. this
paper provides a novel approach based on event logs as used by
process mining techniques. instead of trying to create or modify
process models, this approach works directly on the event log
itself. it aims to “improve history” rather than speculate about
a highly uncertain future. by showing concrete improvements
in terms of partly modiﬁed event logs, the stakeholders can
learn from earlier mistakes and inefﬁciencies. this is similar to
analyzing a soccer match to improve a team’s performance in
the next game. this paper introduces the idea using event logs
in conjunction with ﬂexible “compatibility” and “utility” notions.
an initial prototype –serving as a proof-of-concept– was realized
as a prom plug-in and tested on real-life event logs.
i. i ntroduction
in 2014, the german national soccer team won the world
cup championship. the german team and sap developed
and used the tool “match insights” to obtain a competitive
advantage. the tool was used to analyze former soccer matches
in detail. the idea of analyzing soccer matches to improve
performance based on facts rather than misguided beliefs is not
new. already in 1950, charles reep created a toolkit to analyze
soccer games. reep developed a notational analysis system
of soccer in an attempt to provide empirical evidence for
superior playing strategies. today, lots of detailed soccer data
are collected and, recently, various innovative visualizations
have been developed, for example the wave visualization
tool developed in a collaboration between tu/e and infos-
trada sports. the tool visualizes low-level spatio-temporal
soccer data thus providing novel insights at different levels
of granularity [1]. figure 1 shows a high-level overview of a
match, but it is also possible to zoom-in on particular players,
situations, etc. the potential of analyzing games to learn from
mistakes can also be seen in other sports. in baseball, the term“sabermetrics” refers to the collection of statistics to search
for objective knowledge about baseball. in “moneyball” [2]
michael lewis reports on the successes of oakland athletics
due to their superior understanding of statistics to outperform
better-resourced competitors.
performing operational processes in organizations is in
many ways comparable to playing soccer matches. one orga-
nization is competing with other organizations, just as teams
are competing. within an organization, people need to feel
part of the same team to be most effective. an improvement
in one department may cause problems in other departments.
analyzing operational processes based on historic event data
is as useful as analyzing a match after the fact. this explains
the growing interest in analytics and data science for process
improvement.
fig. 1. visualization of the remarkable soccer match spain versus netherlands
on june 13th 2014 (1-5) [1].
the term process mining refers to techniques that extract
knowledge from event logs [3]. process mining techniques
form a family of a-posteriori analysis techniques exploiting the
information recorded in audit trails, transaction logs, databases,
etc. process mining includes (automated) process discovery
(i.e., learning process models from raw event data), confor-
mance checking (i.e., monitoring deviations by comparing
model and log [5]), social network/organizational mining,
automated construction of simulation models, model extension,
model repair, case prediction, and history-based recommenda-
tions. most of the current process mining techniques aim to
provide insights and do not (yet) support the automation of
process improvements (apart from initial work on operational
support [3]).
process mining complements traditional model-driven ap-
proaches like business process simulation [4]. simulation can
be used for “what-if” analysis. however, simulation models are
often at a higher abstraction-level and not directly connectedto the low-level event data. hence, recommendations based on
simulation may be na ¨ıve or overly optimistic.
data-driven approaches like predictive analytics [6] and
combinatorial optimization [7] tend to focus on speciﬁc de-
cision problems. predictive analytics approaches use machine
learning or data mining to make predictions about future
events. the context may be fuzzy and answers may be incon-
clusive, but the goal is to analyze a speciﬁc variable, e.g., will
a customer buy a product or not. combinatorial optimization
assumes a more reliable problem setting and within this setting
provides some guarantees (e.g., lowest costs).
the approach presented in this paper differs from the above
approaches in the sense that we stay close to the original event
data and do not reduce things to a process model, stochastic
model, decision tree, or regression formula.
starting point is an event log as shown in table i. activities
are executed for cases , i.e., process instances . in table i each
row corresponds to an activity instance . here it is assumed
that each activity has a start time and a completion time and
is executed by a resource . (in section ii we will provide
a more general deﬁnition.) xes (extensible event stream)
[8] and related standards such as mxml provide a tool-
and process-independent way to store event data as event
logs. process mining tools such as prom and disco can
handle such event logs and automatically discover process
models or check conformance. instead of discovering a process
model highlighting performance or conformance problems, we
propose a more detailed analysis of the event log also showing
improvements at the instance level. this can be compared to
analyzing a soccer match based on concrete game situations,
e.g., missed scoring opportunities or defensive errors. this is
done by changing the event log, e.g., activities are reordered
or resource allocations are changed to improve the process in
terms of ﬂow time or costs.
modifying event logs to better understand process improve-
ments can be operationalized using the following two notions:
compatibility andutility . event log l1iscompatible withl2
(notation: l1cl2) ifl1is a possible alternative for l2.
most of the event log must remain invariant and only selected
parts that could actually be inﬂuenced can be modiﬁed, e.g.,
activities can only be transferred to people having the same
role and activities cannot start before all inputs are available.
moreover, a utility function needs to be deﬁned. utilg(l)is the
utility of an event log. positive changes lead to a higher utility.
negative changes (e.g., higher costs, longer ﬂow times, more
rejects, etc.) lead to a lower utility. l1potentially improves
l2if and only if l1cl2andutilg(l1)utilg(l2).l1is
anoptimal improvement ofl2if no better improvement can
be found when considering all compatible alternatives. after
ﬁnding potential or optimal improvements, the differences are
visualized for stakeholders (managers, analysts and end-users).
improvements can be shown at the process level (e.g., the
number of transfers between two resources or the reduced
waiting time for a bottleneck activity) and at the instance level
(e.g., visualizing time shifts within individual cases).
we feel that any redesign effort at the process level should
be preceded by attempts to “change histories” in event logs.
by showing alternative scenarios based on real historic cases,
a reality check is possible and stakeholders are stimulatedto think about process improvements. this is comparable to
a soccer player learning from video recordings of his own
mistakes.
the remainder of this paper is organized as follows.
section ii provides a detailed introduction to the core concepts
in event logs. section iii brieﬂy introduces the basic types
of process mining: process discovery, conformance checking,
and performance analysis. the approach to change event
logs in a controlled manner is described in section iv. an
example of the approach is given in section v. a prototype
implementation is described in section vi followed by related
work (section vii) and a conclusion (section viii).
ii. e vent logs
the “change your history” approach proposed in this paper
heavily relies on detailed event logs as depicted in table i. in
this section, we formalize the key notions used in such logs.
in the remainder, we assume several universes. uet =
fstart;complete ;schedule ;suspend ;resume ; : : :gis the uni-
verse of event types (providing transactional information). a
start event signals the start of an activity instance and a cor-
responding complete event signals its completion. utsis the
universe of timestamps . one can measure a duration by taking
the difference between two timestamps. uresis the universe of
resources , i.e., people, machines, teams, organizational units,
etc.?2u resrepresents a “dummy resource” and is used for
automated events that do not require a real resource. uattr
is the universe of attribute names .uvalis the universe of
attribute values . cases, activity instances and events may have
any number of attributes represented by name-value pairs, e.g.,
(age;49).
deﬁnition 1 (event log): an event log l= (e;an;
ai; c;act;type;time;res;case;name ;attr;)is a tuple
such that:
eis the set of events ,
an is the set of activity names ,
aiis the set of activity instances ,
cis the set of cases (i.e., process instances),
act2e!aiis a surjective function mapping events
onto activity instances ,
type2e!u etis a function mapping events onto
event types ,
time2e!u tsis a function mapping events onto
timestamps ,
res2e!u resis a function mapping events onto
resources ,
case2ai!cis a surjective function mapping
activity instances onto cases ,
name2ai!an is a surjective function mapping
activity instances onto activity names ,
attr2(e[ai[c)!(uattr6!u val)maps events,
activity instances, and cases onto a partial function
assigning values to some attributes,1
1f2x6!yis a partial function with domain dom (f)x.table i. a fragment of some simplified event log :each line corresponds to an activity instance .
case id activity resource start time completion time ...
order1 accept order pete 29-01-2015:11.02 29-01-2015:15.12 ...
order1 send invoice mary 30-01-2015:09.07 30-01-2015:09.13 ...
order2 accept order pete 30-01-2015:09.08 30-01-2015:14.32 ...
order1 handle payment mary 30-01-2015:09.14 30-01-2015:10.00 ...
order2 send invoice mary 30-01-2015:10.08 30-01-2015:11.17 ...
: : : : : : : : : : : : : : : : : :
 relationeedeﬁnes a partial order on events,2
and
 the timestamps respect the partial order: e1e2
implies time (e1)time (e2)for any pair of events
e1ande2.
ulis the universe of all possible event logs.
as deﬁnition 1 shows, an event log consists of events ,
activities , and cases . as usual, we distinguish between activity
names (sometimes called tasks) and activity instances (i.e.,
the execution of a task for a particular case). multiple events
can be associated with an activity instance. for example,
in table i every activity instance has a start event and a
complete event. deﬁnition 1 is more general as it allows for
additional event types (e.g., suspend) and does not require a
particular number of events per activity instance. each activity
instance belongs to a case. note that, transitively, an event also
belongs to a case (i.e., case (act(e))). events have a timestamp
and refer to a resource , e.g., the person triggering the event.
ifres(e) =?, then no real resource is involved ( eis an
automated event). events are partially ordered. note that the
timestamps also induce an ordering and this ordering should
respect:time (e1)time (e2)ife1e2. partial order
can be used to express causal dependencies, e.g., maybe
e1e2, because e2uses data produced by e1. cases, activity
instances, and events can have additional attributes, but these
are not in the focus of this paper.
our approach assumes that part of the event log is ﬁxed
and part of the event log can be modiﬁed, e.g., functions
time andres can be changed, but the rest of event log
l= (e;an;ai; c;act;type;time;res;case;name ;attr;
)may not be changed. this will be formalized using the
compatibility notion. in addition, the utility of an event log
will deﬁned. however, before doing so we brieﬂy introduce
three basic types of process mining.
iii. p rocess mining
process mining starts from event data as speciﬁed in
deﬁnition 1. note that not all attributes are needed for all types
of process mining, e.g., explicit timestamps are only needed
for performance analysis and resources are typically not used
during control-ﬂow discovery.
a. process discovery
the ﬁrst type of process mining is discovery . a discovery
technique takes an event log and produces a process model
(e.g., petri net or bpmn model) without using any a priori
2a partial order is a binary relation that is (1) reﬂexive, i.e. eefor any
event e, (2) antisymmetric , i.e. if e1e2ande2e1thene1=e2, and
(3) transitive, i.e. e1e2ande2e3implies e1e3.information. process discovery is the most prominent process-
mining technique. for many organizations it is often surprising
to see that existing techniques are indeed able to discover real
processes merely based on example behaviors stored in event
logs.
b. conformance checking
the second type of process mining is conformance . here,
an existing process model is compared with an event log of
the same process. conformance checking can be used to check
if reality, as recorded in the log, conforms to the model and
vice versa.
c. performance analysis
state-of-the-art conformance checking techniques create
so-called alignments between the observed event data and the
process model. in an alignment each case is mapped onto the
closest path in the model, also in case of deviations and non-
determinism. as a result, event logs can always be replayed on
process models. this holds for both discovered processes and
hand-made models. next to showing deviations, alignments
can also be used to reveal bottlenecks using timestamps of
events. hence, process mining provides novel forms of perfor-
mance analyses that combine event data with process-centric
visualizations.
fig. 2. a process model automatically discovered from event data. replaying
the event log reveals the bottleneck.
figure 2 shows a process model discovered based on an
event log. prom’s visual inductive miner [9] was used to
discover a block structured model that can be mapped onto
petri nets and bpmn. the model was automatically simpliﬁed
to show only the most frequent activities. the event log is
replayed on the discovered model to show bottlenecks.
the growing number of commercial process mining tools
(disco, perceptive process mining, celonis process mining,
qpr processanalyzer, software ag/aris ppm, fujitsu in-
terstage automated process discovery, etc.) and the numerous
successful applications of process mining illustrate the rising
interest in process mining. see for example the twenty case
studies on the webpage of the ieee task force on process
mining [10]. however, the state-of-the-art in process min-
ing revolves around identifying performance- or compliance-
related problems rather than solving them. therefore, the nextsection returns to the event log itself as a starting point for
analysis.
iv. c hange your history
an event log l= (e;an;ai; c;act;type;time;res;
case;name ;attr;)(deﬁnition 1) provides a uniﬁed repre-
sentation of the history of a process. rather than proposing an
improved process model, we aim to create an improved history.
to do this we need to specify which parts of the event log can
be modiﬁed and how we would like to evaluate the changed
history. therefore, we introduce the notions of compatibility
andutility .
a. compatibility
it is undesirable to be able to change the event log com-
pletely. for example, it is unrealistic to assume that resources
can perform all activities and that all activities can be skipped.
therefore, we carefully need to consider which parts of the
event log are invariant and which parts are changeable .
deﬁnition 2 (compatible): cululis acompatibility
relation. l1cl2if and only if event logs l1andl2are
compatible with respect to constraints c.
ifl1cl2, then history l2can be replaced by a new,
hopefully improved, history l1. the compatibility relation de-
ﬁnes what should remain invariant while exploring alternatives.
the relation does not need to be symmetric. section v provides
a concrete compatibility relation. when deﬁning compatibility
one needs to think about the things that can be realistically
inﬂuenced and avoid changes that lead to unrealistic scenarios.
b. utility
performance measurement is a topic in itself. one can
deﬁne key performance indicators (kpis) with respect to time,
costs, and quality. consider for example kpis related to time.
one can measure ﬂow times, waiting times, service times,
service levels, etc. costs and quality can also be quantiﬁed
in different ways. process improvement is clearly a multi-
criteria decision making problem. hence, one may want to
look for parato optimal decisions, i.e., alternatives that are not
dominated by alternatives that are better (or at least as good)
in all dimensions.
here we take a simpliﬁed approach and assume that
performance can be captured in a single value: utility (inverse
of a cost).
deﬁnition 3 (utility): utilg2ul!ris a utility func-
tion. utilg(l)is the utility of event log lgiven goal g.
given an event log it is easy to compute a utility function
based on time. for example, utilg(l)can be deﬁned as
the average ﬂow time of cases in l. to incorporate costs
or quality, additional information is needed. for example,
costing approaches such as activity based costing (abc) and
resource consumption accounting (rca) need to assign costs
to activities in some way [11]. in [12] a framework for cost-
aware process mining is proposed.c. creating an optimization problem
based on a compatibility relation and a utility function,
one can reason about improved andoptimal event logs . the
compatibility relation limits the space of alternative event logs.
the utility function helps to select the interesting candidates.
deﬁnition 4 (improved and optimal event logs): let
l1; l22ulbe two event logs, culula compatibility
relation, and utilg2ul!ra utility function.
l1potentially improves l2with respect to constraints
cand goal g(notation: l1dc;gl2) if and only if
l1cl2andutilg(l1)utilg(l2),
l1is an optimal improvement ofl2(notation: l14c;g
l2) with respect to constraints cand goal gifl1c
l2and for all l2ul:lcl2implies utilg(l1)
utilg(l).
deﬁnitions 2, 3 and 4 are very generic. combined with
the precise deﬁnition of event logs, they form a framework for
systematically discussing process improvements at the instance
level.
v. e xample : twotypes of shifts
compatibility and utility are generic, but also rather ab-
stract, notions. to illustrate the “change your history” approach
we now deﬁne a concrete compatibility relation cand utility
function utilg.
first, we deﬁne a compatibility relation that keeps every-
thing invariant except the timing of events and the allocation
of events to resources.
deﬁnition 5 (example compatibility relation):
letl1; l22 u lbe two event logs with li=
(ei;ani;aii; ci;acti;typei;time i;resi;case i;name i;attri;
i).l1cl2if and only if the following properties hold:
e=e1=e2,an =an 1=an 2,ai=ai1=
ai2,c=c1=c2,act =act1=act2,type =
type1=type2,case =case 1=case 2,name =
name 1=name 2,attr =attr 1=attr 1,=1=2,
 for all e1; e22ewithai(e1) =ai(e2):time 1(e1) 
time 1(e2) =time 2(e1) time 2(e2)(i.e., time differ-
ences within an activity remain unchanged),
ec=fe2ejcase (act(e)) =cgdenotes the set of
events corresponding to case c2c,
er
i=fe2ejresi(e) =rgdenotes the set of events
performed by resource r2uresinli,
 for all c2 c:min e2ectime 1(e)
min e2ectime 2(e)(i.e., cases do not start earlier),
 for all r2 u res:f(name (act(e));type (e))je2
er
1gf (name (act(e));type (e))je2rr
2g(i.e., a
resource cannot perform activities it did not perform
before), and
 there cannot be four different events es
1; ec
1; es
2; ec
22e
such that res1(es
1) =res1(ec
1) =res1(es
2) =res1(ec
2),
type (es
1) =type (es
2) =start ,type (ec
1) =type (ec
2) =
complete ,time 1(es
2)<time 1(ec
1)andtime 1(es
1)<time 1(ec
2)(i.e., the same resource cannot work on
multiple activities at the same time).
note that the example compatibility relation explicitly
considers activity instances with a start andcomplete event.
all log elements are invariant except the resource allocation
and the times at which events occur. note that:
 the time differences between events in the same
activity instance cannot change. this implies that
durations (time difference between start event and
complete event) do not change.
 cases cannot start earlier, i.e., the ﬁrst event of a case
cannot be moved to an earlier time (only a later time
is allowed).
 resources cannot perform activities they did not per-
form before (taking into account event types). for
example, if resource rnever completed an activity a
in the original event log, then rcannot complete ain
the modiﬁed log. also note the role of ?2u reshere,
i.e., things that always required a resource in the old
log, also require a resource in the new log.
 in the modiﬁed event log, the same resource can
only perform one activity at a time. here start and
completion events are used to demarcate the activity
instances.
an example of a utility function is the average ﬂow time.
deﬁnition 6 (example utility function): letl= (e;
an;ai; c;act;type;time;res;case;name ;attr;)be an
event log. utilg(l) =p
c2c(max e2ectime 1(e) 
min e2ectime 2(e))=jcjforl2ul.
the start time of a case is assumed to be the timestamp
of the ﬁrst event of the case in the original event log (i.e.,
min e2ectime 2(e)). the completion time of a case is the
timestamp of the last event of the case in the modiﬁed event log
(assuming activity instances having just a start andcomplete
event).
deﬁnitions 2, 3 and 4 provide a generic framework that can
be instantiated as just described. however, many alternatives
are possible [13]. moreover, it is important to visualize the
key differences between the original event log l2and the
improved or optimal event log l1. improvements can be shown
at the process (i.e., type) level and at the instance level. this
is illustrated in the next section.
vi. p rototype implementation
multiple prom plug-ins were developed to illustrate the
proposed approach. bearing in mind the goal of cost reduction,
a hybrid genetic algorithm approach was developed and used
together with a utility function that takes into account trade-
offs between time, cost and resource utilization to generate an
improved event log which is compatible with a given event log
[13]. everything in the improved event log is kept invariant
except the timing of events and the allocation of events to
resources. various visualizations have been created to highlight
key differences between two compatible logs in order to gain
insights into potential improvement scenarios.the change in the average start times of events for all
activities in the two logs at the process level is visualized in
figure 3. each bar in a row represents an activity, and its
average difference in start times across all cases that contain
an instance of that activity. a green bar that extends towards
the left shows that, on average, instances of the activity tend
to start earlier. a red bar that extends towards the right shows
activity instances starting later. the conﬁguration panel on the
left enables the user to ﬁlter the cases and activities of interest
and to sort the activities. the statistics panel on the right
provides detailed information about the timing differences.
figure 3 shows that instances of the activities apt andcwr
on average could have started a lot earlier.
figure 4 visualizes the time differences in activities within
each case and compares these differences at the instance level.
each twin-row represents the “before” and “after” behavior
of a case in terms of execution times. the activity instances
that were executed within the case are portrayed by bars, and
are distinguishable by their colors. by observing figure 4, it is
clear that the throughput time of case 144 can be signiﬁcantly
shortened by minimizing idle times between activity instances
in that case. this is made possible due to under-utilized and
free resources being reallocated to undertake these activity
instances in the improved log.
fig. 3. an example visualization that aggregates the changes in average start
times for activities between two event logs.
fig. 4. an example visualization that outlines the timing differences of cases
between two event logs.
in order to examine the changes in resources executing
various activities between two compatible logs, figure 5 vi-
sualizes the resources as nodes and the transfer of activitiesbetween resources as directed arcs between these nodes. for
the resource that a node represents, the size of the node shows
the total number of activity instances that did not have their
resource reallocated, and the colored segments group the activ-
ity instances into their respective activities. the conﬁguration
panel on the left allows the user to customize the visualization
by ﬁltering the activities or by adjusting the details displayed
on the graph. in figure 5, it can be observed that a number of
activity instances were shifted from is2tois1and from sc1 to
sc2. it is also possible to observe the stability of a resource
by comparing the activities executed by the resource in the
original log with those retained by the same resource in the
improved log. the visualization provides us with insights into
possible improvements in workload allocation. these insights
can be used to better utilize the available resources in an
organization.
fig. 5. an example visualization that highlights resource shifts between two
event logs.
through these prom plug-ins, we explored techniques to
generate improved event logs in order to provide evidence at
the instance level of how processes could be improved by
shifting start times of activities and by allocating a different
resource to work on an activity. in order to better understand
the key differences between the two logs, we developed
multiple visualizations that highlight the shifts in time and
changes in resource allocations between two compatible event
logs. these insights can then be used to facilitate discussions
around possible process improvements within the organization.
vii. r elated work
see [3] for an introduction to process mining. the xes
standard is described in [8]. the extraction of event data is
discussed in chapter 4 of [3] and in [14].
as mentioned, our approach complements process mining
[3], simulation [4], predictive analytics [6], and combinatorial
optimization [7]. it is also related to comparative process
mining . for example, the notion of “process cubes” can be
used to systematically compare subsets of event data [15].
some initial work has been done based on the notions
discussed in this paper [16], [13], [17]. for example, [13]
describes a hybrid genetic algorithm that explores alternatives
in a smart manner thus allowing for larger search spaces. in
[17] different visualizations are described (cf. section vi).viii. c onclusion
this paper presented a generic framework for reengineering
event logs in a controlled manner. by exploring different
alternatives at the instance level, stakeholders are able to reﬂect
and learn. this is similar to soccer players analyzing historic
matches and practicing particular game situations.
future work aims at providing a wide range of com-
patibility relations ( c) and utility functions ( utilg), and
corresponding change visualizations. moreover, we aim to
efﬁciently prune the search space using monotonicity results
for processes. this is needed to make the approach feasible in
large-scale real-life settings.
references
[1] m. grootjans, “visualization of spatio-temporal soccer data”, master
thesis, eindhoven, 2014.
[2] m. lewis, moneyball: the art of winning an unfair game . w. w.
norton & company, 2003.
[3] w. van der aalst, process mining: discovery, conformance and en-
hancement of business processes . springer-verlag, berlin, 2011.
[4] ——, “business process simulation survival guide,” in handbook
on business process management , j. brocke and m. rosemann, eds.
springer-verlag, berlin, 2015, pp. 337–370.
[5] w. van der aalst, a. adriansyah, and b. van dongen, “replaying
history on process models for conformance checking and performance
analysis,” data mining and knowledge discovery , vol. 2, no. 2, pp.
182–192, 2012.
[6] e. siegel, predictive analytics: the power to predict who will click,
buy, lie, or die . wiley, 2013.
[7] g. nemhauser and l. wolsey, integer and combinatorial optimization .
wiley, 1988.
[8] ieee task force on process mining, “xes standard deﬁnition,”
www.xes-standard.org, 2013.
[9] s. leemans, d. fahland, and w. van der aalst, “discovering block-
structured process models from event logs containing infrequent
behaviour,” in international workshop on business process intelligence
(bpi 2013) , lnbip, vol. 171. springer-verlag, berlin, 2014, pp. 66–78.
[10] ieee task force on process mining, “process mining case
studies,” http://www.win.tue.nl/ieeetfpm/doku.php?id=shared:process
mining case studies, 2013.
[11] b. clinton and a. van der merwe, “management accounting: ap-
proaches, techniques, and management processes,” cost management ,
vol. 20, no. 3, pp. 14–22, 2006.
[12] m. wynn, w. low, a. ter hofstede, and w. nauta, “a framework for
cost-aware process management: cost reporting and cost prediction,”
journal of universal computer science , vol. 20, no. 3, pp. 406–430,
2014.
[13] w. low, j. de weerdt, m. wynn, a. ter hofstede, w. van der aalst,
and s. broucke, “perturbing event logs to identify cost reduction op-
portunities: a genetic algorithm-based approach,” in ieee congress
on evolutionary computation (cec 2014) . ieee computer society,
2014, pp. 2428–2435.
[14] w. van der aalst, “extracting event data from databases to unleash
process mining,” in bpm: driving innovation in a digital world , j. vom
brocke and t. schmiedel, eds. springer-verlag, 2015, pp. 105–128.
[15] ——, “process cubes: slicing, dicing, rolling up and drilling down
event data for process mining,” in asia paciﬁc conference on business
process management (ap-bpm 2013) , ser. lecture notes in business
information processing, m. song, m. wynn, and j. liu, eds., vol. 159.
springer-verlag, berlin, 2013, pp. 1–22.
[16] ——, “log-based cost analysis and improvement,” technical note,
january 29, 2013.
[17] w. low, m. wynn, a. ter hofstede, j. de weerdt, and w. van der
aalst, “change visualisations: analysing the resource and timing
differences between two event logs,” technical note, january 15,
2015.