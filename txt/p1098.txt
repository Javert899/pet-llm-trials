a generic approach for process performance
analysis using bipartite graph matching
chiao-yun li1, sebastiaan j. van zelst1;2, and wil m. p. van der aalst1;2
1fraunhofer institute for applied information technology (fit), germany
fchiao-yun.li,sebastiaan.van.zelst,wil.van.der.aalst g@fit.fraunhofer.de
2chair of process and data science, rwth aachen university, germany
fs.j.v.zelst,wvdaalst g@pads.rwth-aachen.de
abstract. the eld of process mining focuses on the analysis of event
data, generated and captured during the execution of processes within
companies. the majority of existing process mining techniques focuses on
process discovery, i.e., automated (data-driven) discovery of a descriptive
process model of the process, and conformance and/or compliance check-
ing. however, to eectively improve processes, a detailed understanding
in dierences of the actual performance of a process, as well as the un-
derlying causing factors, is needed. surprisingly, few research focuses on
generic techniques for process-aware data-driven performance measure-
ment, analysis and prediction. therefore, in this paper, we present a
generic approach, which allows us to compute the average performance
between arbitrary groups of activities active in a process. in particular,
the technique requires no a priori knowledge of the process, and thus does
not suer from representational bias induced by any underlying process
representation. our experiments show that our approach is scalable to
large cases and especially robust to recurrent activities in a case.
keywords: process miningprocess performance analysis bipartite
graph matching integer linear programming
1 introduction
the eld of process mining has gained its signicance as a technology to objec-
tively obtain insights into business processes by exploiting event logs , i.e., records
of events executed in the context of a business process. to further understand
the execution of business processes, process performance analysis aims to mea-
sure and analyze the performance of business processes, e.g., throughput time,
by extracting information from event logs [19].
the techniques for process performance analysis [2, 5, 12] can be classied into
two approaches: model-based and log-based approaches [19]. the rst one typi-
cally projects the event log on a predened or discovered process model [2, 12, 13].
the advantage is that the performance analysis results can be interpreted in the
context of a process model. however, this assumes that there exists a suitable
model with high conformance.2 chiao-yun li et al.
fig. 1: process model of repairing telephones in a company [15]. a telephone can
be xed by either the team for simple defects or the other team for complex
defects whereas some defects can be handled by either team.
the other approach is purely based on an event log [5, 11, 19]. the techniques
based on such approach are not limited to the constraints of the model-based
techniques and more exible to users' need. however, current work fails to pro-
vide robust performance metrics in the presence of repeated activities in a case,
i.e., a run of a business process.
in this paper, we present a novel approach for business process performance
analysis. figure 1 serves as a motivating example of a process of repairing tele-
phones in a company [15]. the process starts with a registration of a telephone
sent by a customer (a). the telephone is then analyzed (b) and the problem is
reported to the customer (c). afterwards, one of the two teams in the repair
(r) department repairs the defect; one for simple defect (d) and the other for
complex defect (e) while some defects can be handled by either team. then,
the quality assurance (qa) department tests if the defect is repaired (f) and
decides whether to restart another repair (g) or to archive the case (h).
suppose we are interested in the performance of r and qa department,
i.e., the average duration between doretogorh. given a case in which the
activities are executed in the order of ha;b;c;d;f;g;e;f;g;e;f;h i, figure 2 shows
the events on a timeline for an overview of the duration of interest.
intuitively, the average duration would be1+60+602
3= 60:33 minutes. we
propose a novel approach which supports the intuition and the exibility of anal-
ysis while being robust to recurrent activities, e.g., all d,e,gandhare included
for analysis. our approach applies bipartite graph matching to pair the events
for computation. moreover, by allowing multiple selection of activities, our ap-
proach can be applied to analysis at a higher abstraction level, e.g., performance
of department randqa, without building another model in advance.
fig. 2: a case of the process in figure 1. the events are plotted on a timeline
with the duration of interest shown, i.e., duration between doretogorh.a generic approach for process performance analysis 3
it is common that real processes do not conform with a pre-dened structured
process model. interchangeability and concurrency among activities impose chal-
lenges on the existing methods for process performance analysis. these methods
either need to exclude the non-conforming cases [2], or explicitly specify the re-
lationships between events [5]. for instance, considering processes in a hospital,
suppose we are interested in the duration between an injection and a medical ex-
amination for the reaction after the injection. it is impossible to pre-dene what
and how many injections that a patient would need in advance. by specifying
two sets of activities, our approach allows for a certain degree of uncertainty
among the activities in the event log, and further provides the exibility when
measuring the performance of complex processes.
to assess our approach, we conduct a quantitative evaluation of its scalability
and a qualitative evaluation by means of comparing our approach with analysis
obtained from commercial tools. the rst experiment shows that our approach
is scalable to large cases while the comparative evaluation shows its robustness
against recurrent activities in a case.
the remainder of this paper is organized as follows. section 2 compares our
approach with existing work in academia and with the typical functionalities
provided by commercial tools. section 3 introduces the denitions and nota-
tions used in the paper. we present our approach in section 4, followed by the
evaluation and discussion in section 5. finally, section 6 concludes the paper.
2 related work
existing work on process performance analysis provides metrics at dierent lev-
els. most of them focus on the level of cases, e.g., throughput time, and/or the
level of individual activities, e.g., waiting time. despite various metrics, most
techniques can be classied into model-based and log-based approaches [19].
model-based performance analysis accounts for most techniques proposed
[2, 3, 13, 14, 16, 17]. these techniques attempt to map an event log on a given
process model. regardless of the amount of work [4, 6, 20], relatively few meth-
ods provide solutions on performance analysis for cases deviating from the model.
hornix provides the option to include the deviated cases when computing per-
formance using token-based replay technique [12]. however, the results can be
misleading when there are activities with the same label or articial activities
in a model. adriansyah measures the performance of activities from events with
transaction type attributes, e.g., start, complete, and suspend [2]. nevertheless,
there is no generic rule to determine the timestamps of the missing events in
the work. generally speaking, model-based approach confronts the challenges of
(1) the reliability of the prescribed model, (2) the need for recalculation if the
model changes, (3) complex and exible business processes which result in low
conformance of the model, and (4) the exibility of the analysis, e.g, the metrics
provided are dependent on the model.
alternatively, one can analyze process performance based on an event log
only [5, 11, 19]. this approach provides the exibility and static results due to4 chiao-yun li et al.
table 1: comparison of works on process performance analysis.
algorithm/methodmodel
independenttwo arbitrary
activitiestwo sets of
activities
[2] alignments      
[3] robust performance analysis      
[5] first/last to first/last events + +  
[9] analysis on segmented journey model + +  
[10] disco      
[11] context-aware kpi +    
[12] log reply on petri nets      
[13] hierarchical performance analysis      
[14] analysis with advanced constructs      
[16] alignments with stochastic petri nets      
[17] log replay on petri nets   + 
[18] queue enabling cspns (qcspn) +    
[19] dotted chart +    
this paper: bipartite graph matching + + +
the independence of a model. in this paper, we proposed a novel performance
measurement technique which is scalable to large event logs. we apply bipartite
graph matching for pairing as many events for measuring as possible. by the
design of the algorithm, users can analyze the performance between two arbitrary
groups of activities. compared to the existing log-based techniques, our approach
is more exible to the need of analysis and, supported by the evaluation, more
robust to recurrent activities. table 1 lists some representative work on process
performance analysis. we compare if a method is dependent to a model, i.e.,
suers from the reliability and limitations, and exible to the analysis, i.e., the
selection of activities.
3 preliminaries
in this section, we introduce the related concepts and notations used in this
paper, including process mining and bipartite graph matching.
as a preliminary, we rst dene the required mathematical notations for a
sequence . we introduce a function: :f1;2;:::ng!xfor a nite sequence of
lengthnover an arbitrary set x. the function assigns every element x2xto
an indexi2f1;2;:::;ng. we write =hx1;x2;;:::;xni2x, wherex1=(1),
x2=(2), ...,xn=(n) andxdenotes the set of all possible sequences over
xof arbitrary length. given a sequence 2xand an element x2x, letjj
denotes the length of the sequence, we overload the notation and write x2if
and only if91ijj 
(i) =x
.a generic approach for process performance analysis 5
3.1 event logs
anevent log is a collection of sequences of events , i.e., traces . each event de-
scribes the execution of an activity , i.e., a well-dened step in a process [1].
during the execution of processes, i.e., cases , additional information, i.e., at-
tributes , are associated to the events and/or cases. in the following part of this
section, we explain the relationships among event ,activity ,traces , and event log .
for simplicity, in the remainder of the paper, edenotes the universe of events
andcdenotes the universe of cases.
denition 1. (event, event attributes) letabe the universe of activities
andtbe the universe of timestamps. we dene the projection functions:
act:e!a, whichact(e)represents the activity of the event e2e,
ts:e!t, whichts(e)represents the occurring time of the event e2e.
denition 2. (trace) we dene a projection function tra:c!efor a
trace which describes a nite sequence of events in a case such that
 81i<jjj 
ts((i))ts((j))
 81i<jjj 
(i)6=(j)
we dene an event index as the order of the event in a trace.
denition 3. (event log) given a collection of cases lc, an event log
lis a collection of traces, i.e., l=f2ej9c2l 
=tra(c)
ges.t.
8;02l 
9e2e(e2^e20)=0)
.
for the sake of performance analysis, we additionally dene the notation of
measurements between events in the context of a trace.
denition 4. (measurement) letmdenote all the measurable entities, e.g.,
duration, cost. given a measurable entity m2mand a trace , we dene the
function:m:eee!rfor which8e;e02.
in this paper, we assume that any measurable entities for performance anal-
ysis are always available given an event log.
3.2 bipartite graph matching
a matching in a bipartite graph is to select the edges, i.e., pairs of nodes, such
that no edges share the same nodes. this section formally denes a (weighted)
bipartite graph and the corresponding matching problem as follows.
denition 5. ((weighted) bipartite graph) letg= (v;e;w )be a weighted
graph where vis a set of nodes, eis a set of edges and wis a weight func-
tionw:e!r. given a weighted graph g, it is bipartite if and only if
9v1;v2v 
v1[v2=v^v1\v2= 
s.t.@(v;v0)2e 
v;v02v1_v;v02v2
.
we denote a weighted bipartite graph as g= (v1[v2;e;w ).6 chiao-yun li et al.
fig. 3: an example of maximum weighted bipartite matching. the edges ( p1;j1)
and (p2;j2) are selected due to maximum weights.
denition 6. (maximum weighted bipartite matching) given a weighted
bipartite graph g= (v1[v2;e;w ), a bipartite graph matching is the selection
ofe0es.t.8(v;v0)2e0 
9(v;v00)2e0)v0=v00^9(v00;v0)2e0)v00=v
.
letemdenotes all possible matching. a maximum weighted bipartite match-
ing is a matching e02emsuch that @e002em p
e2e00w(e)>p
e2e0w(e)
.
an example is shown in figure 3 as a bipartite graph which jiis a set of jobs
andpjis the sets of applicants. an edge indicates that an applicant applies for
the job with the qualication score implied as its weight. a maximum weighted
bipartite matching is the optimal assignments of the applicants to the jobs such
that the total qualication score is maximum, i.e., ( p1;j1) and (p2;j2).
in this paper, integer linear programming (ilp) should be applied to nd
the maximum weighted bipartite matching. ilp is a mathematical optimization
method that, given a set of variables, assigns an integral value to every variable to
achieve the best result, e.g., minimum cost, maximum benets, with the objective
and the constraints formulated in linear relationships [7].
4 generic process performance analysis using bipartite
graph matching
our approach aims for measuring the performance between two arbitrary groups
of activities. by projecting the events of interests into a bipartite graph for each
trace, we nd the maximum weighted bipartite matching indicating the pairs of
events from which the performance metric of a case is derived. figure 4 depicts
a global overview of our approach and we illustrate each step in more detail in
the sections specied on the arcs.
4.1 bipartite graphs generation
given an event log, a user species two groups of activities of interest for ana-
lyzing the performance from one to the other. we construct a weighted bipartite
graph for each case by taking the events of interests as nodes and connecting
them according to the direction specied. the weights of the edges are computed
using a monotonic function of the event index of the nodes. figure 5 shows an
example of a bipartite graph for the trace which we only show the events of
interest. the projection of a trace to a bipartite graph is formalize as follows.a generic approach for process performance analysis 7
fig. 4: an overview of the proposed approach. we analyze the performance of a
case by nding a maximum weighted bipartite graph matching using ilp.
denition 7. (trace projection) letabe the universe of activities. given
two sets of activities as;ataand an event log le, we dene a trace
projection function ()which generates a weighted bipartite graph g= (s[
t;e;w )from2lsuch that
s=fe2jact(e)2asg,
t=fe2jact(e)2atg,
e=f(s;t)2stj91i<jjj 
(i) =s^(j) =t
g, and
given (s;t)2eand let 1i < j jjs.t.(i) =sand(j) =t,
w(s;t) =1
j i.
given a graph (),()edenotes the edges of the graph.
fig. 5: an example of the bipartite graph given a trace
4.2 maximum weighted bipartite graph matching formulation
given a bipartite graph built as described in denition 7, we select pairs of
events for measurements by nding a maximum weighted bipartite matching
using ilp. the ilp model is formulated as below.
denition 8. (ilp formulation) given a weighted bipartite graph g= (s[
t;e;w ), we assign a variable x(s;t)to every edge (s;t)2eand limit each8 chiao-yun li et al.
variable to 0or1, indicating whether the edge is selected provided the integral
solutions. we formulate the constraints and the objective as follows to nd the
maximum weighted bipartite matching (denition 6).
maximize z=x
(s;t)2ew(s;t)x(s;t)
subject tox
s2sx(s;t)1;8t2t
x
t2tx(s;t)1;8s2s
x(s;t)2f0;1g
we denote the value for every variable x(s;t)asx
(s;t)such thatzis maximum.
in principle, the problem above should be solved by ilp. however, we alter-
natively relax the integral constraints by applying linear programming (lp),
i.e.,x(s;t)2[0;1], and compare their performance in section 5.1. we found that
lp always selects as much fraction of an edge as possible, i.e., 1, due to the
constraints on the nodes. thus, given the integral solutions provided by lp, we
use lp in our implementation for better performance.
4.3 aggregation
for each case, we average the desired measurements, e.g., duration between
two events, given the pairs of events selected as described in section 4.2. the
performance metrics in terms of case and event log is computed as follows.
denition 9. (case performance) letmdenote all the measurable entities
of a trace. given a trace =tra(c)for whichc2c, refer to denition 8, we
compute the case performance in terms of m2mas:
m() =p
(s;t)2()em(;s;t )x
(s;t)
p
(s;t)2()ex
(s;t):
suppose all the cases in an event log are independent to each other, then we
compute the log performance as dened below.
denition 10. (log performance) letmdenote all the measurable entities
of a trace. given an event log l, for every trace 2l,m()denotes the case
performance in terms of m2m. we select traces t=f2ljj()ej1jand
compute the log performance regarding m2mas:
m(l) =p
2tm()
jtj
by transforming a trace into a bipartite graph, our approach is capable
of measuring the performance between two arbitrary groups of activities. the
grouping can also be applied to analyze the performance at a higher level of
abstraction without constructing another model at the desired granularity.a generic approach for process performance analysis 9
fig. 6: number of nodes and edges of the synthetic dataset.
5 evaluation
in this section, we evaluate the scalability using both ilp and lp in section 5.1,
followed by a comparative evaluation in section 5.2.
5.1 scalability with lp and ilp
we evaluate the performance and scalability of our approach by measuring the
runtime of solving lp and ilp. since the complexity of the problem is reected
by the number of variables (edges) and the number of constraints (nodes), we
generate a synthetic event log with dierent number of nodes and edges. the
event log simulates the results after ltering out events not of interest. each event
is randomly assigned as either an event in the start or target activity group and
an event index between 1 and 1000, indicating the maximum length of a trace
before ltering. the length of the trace is limited to 2 to 200 representing the
log after the ltering. for each length, 15 traces are generated. figure 6 shows
the number of nodes and the corresponding number of edges.
figure 7 shows the runtime using lp and ilp in terms of the number of edges
and nodes. as expected, the runtime increases with complexity of the graph, i.e.,
the number of variables (edges) as shown in figure 7b and constraints (nodes)
as shown in figure 7a. however, the edges selected by using lp and ilp are
dierent. nevertheless, compared to using ilp, the optional solutions from lp
provide the same number of edges given integral solutions. given the better
performance and scalability of lp, we apply lp instead of ilp for our approach.
(a) runtime[ms] versus number of nodes
 (b) runtime[ms] versus number of edges
fig. 7: performance of the approach using lp and ilp. the performance using
lp is better than ilp and highly scalable.10 chiao-yun li et al.
(a) four congurations.
 (b) conguration selected.
 (c) analysis result.
fig. 8: performance analysis using celonis [5]
5.2 comparative evaluation
we compare our approach with other techniques with the dataset from the bpi
challenge 2019 [8]. the methods from celonis [5] and disco [10] are used for
comparison as the representatives of log-based and model-based techniques, re-
spectively. in the experiment, we evaluate the performance between vendor cre-
ates invoice and record invoice receipt . the two activities are chosen due to
the limitation of analyzing with disco [10], i.e., only selection of two adjacent
activities in the model is allowed. to emphasize the dierence of analysis result
in the presence of recurrent activities, we further select the cases in which each
activity is executed at least twice. after the ltering, we obtain 4915 cases with
14498 vendor creates invoice and 17210 record invoice receipt in total.
table 2 shows the performance statistics in terms of the frequency and du-
ration from dierent approaches. the case frequency shows that the number of
cases considered while the absolute frequency shows the number of measurements
used for calculation. these two frequencies are the same using celonis due to
only one measurement out of four possible congurations is selected. figure 8a
depicts the four possible congurations: rst to rst ( c1), rst to last ( c2), last
to rst (c3), last to last ( c4). each refers to the duration between the rst/last
event of one activity to the rst/last event of the other activity in a trace. for
each trace, only one conguration is chosen as the performance metrics. thus, it
produces skewed results depending on the conguration, e.g., the measurement
betweenc2 andc3 can dier much. figure 8c shows the analysis from one of
the conguration as in figure 8b. from the frequency information in table 2,
it shows that some cases are ignored if the events in the cases do not have the
congured order, e.g., the last execution of vendor creates invoice is after the
rst execution of record invoice receipt .
figure 9 shows the mean duration and absolute frequency between activities
from disco [10]. the cases that do not comply to the model are ignored, i.e., only
2684 out of 4915 cases are considered. in addition, the resulting metrics tends
to be smaller since it only considers the measurement if record invoice receipt
directly follows vendor creates invoice without other activities in between.
the results show that our approach is robust for that it covers as many
measurements as possible given two activities. moreover, table 2 shows that
even a simple question as the time between two activities is not as simple as it
seems. besides, our approach allows for measuring the performance between two
groups of activities.a generic approach for process performance analysis 11
table 2: comparative evaluation results. our approach computes the perfor-
mance based on the most measurements, i.e., absolute frequency.
celonisdisco our approachf!f f!l l!f l!l
case freq. 4881 4915 2613 4889 2684 4915
absolute freq. 4881 4915 2613 4889 3797 14441dur(l) min. 5h 19h 5h 84m 84m 8h
max. 70y 70y 159d 447d 15.7w 35y
median. 14d 41d 12d 21d 3.7d 18d
mean. 61d 105d 17d 33d 10.2d 43.7d
f: timestamp of the earliest occurrence of vendor creates invoice in a case
l: timestamp of the latest occurrence of record invoice receipt in a case
dur(l): duration between two activities of the event log l
6 conclusion
fig. 9: analysis using disco [10]process performance can be analyzed based on
a model or an event log only. most techniques
are model-based and are, thus, limited to the
representational bias of the underlying models
and not exible to the need of analysis, e.g.,
measuring the performance between two mile-
stones. existing techniques that are based on
an event log face the challenge of providing a
robust result in the presence of recurrent activ-
ities. this paper introduces a novel and generic
process-aware log-based technique which is ro-
bust to recurrent activities and can be further
extended to analysis of two groups of activi-
ties. by applying bipartite graph matching, we
pair as many events as possible and measure
them accordingly. our experiments show that
the proposed approach is scalable to huge event
logs and outperforms the existing methods by
providing a robust metrics given recurrent ac-
tivities.
to better locate and diagnose the perfor-
mance of a process, we aim to extend our ap-
proach by incorporating the control-ow con-
structs into the bipartite graph and clustering
the cases based on the measured performance.
furthermore, more investigation on dierent business context or rules can be
applied to determine complementary performance indicators and the weights of
the bipartite graph. meanwhile, we also aim to automate the selection of the
activities to facilitate the application of our approach.12 chiao-yun li et al.
references
1. van der aalst, w.m.p.: data science in action. in: process mining, pp. 3{23.
springer (2016)
2. adriansyah, a.: aligning observed and modeled behavior (2014)
3. adriansyah, a., van dongen, b., piessens, d., wynn, m., adams, m.: robust
performance analysis on yawl process models with advanced constructs. journal of
information technology theory and application (jitta) 12(3), 5{26 (2012)
4. castellanos, m., casati, f., shan, m.c., dayal, u.: ibom: a platform for intel-
ligent business operation management. in: 21st international conference on data
engineering (icde'05). pp. 1084{1095. ieee (2005)
5. celonis se: academic cloud. https://academiccloud.celonis.com (2019), [online;
accessed 26-april-2019]
6. costello, c., molloy, o.: building a process performance model for business activity
monitoring. in: information systems development, pp. 237{248. springer (2009)
7. dantzig, g.: linear programming and extensions. princeton university press (2016)
8. van dongen, b.f.: dataset bpi challenge 2019. 4tu.centre for research data.
https://doi.org/10.4121/uuid:d06a4b-79f0-45e6-8ec8-e19730c248f1 (2019), [on-
line; accessed 10-april-2019]
9. gal, a., mandelbaum, a., schnitzler, f., senderovich, a., weidlich, m.: traveling
time prediction in scheduled transportation with journey segments. information
systems 64, 266{280 (2017)
10. g unther, c.w., rozinat, a.: disco: discover your processes. in: bpm (2012)
11. hompes, b.f., buijs, j.c., van der aalst, w.m.p.: a generic framework for context-
aware process performance analysis. in: otm confederated international confer-
ences" on the move to meaningful internet systems". pp. 300{317. springer (2016)
12. hornix, p.t.: performance analysis of business processes through process mining.
master's thesis, eindhoven university of technology (2007)
13. leemans, m., van der aalst, w.m.p., van den brand, m.g.: hierarchical per-
formance analysis for process mining. in: proceedings of the 2018 international
conference on software and system process. pp. 96{105. acm (2018)
14. piessens, d., wynn, m.t., adams, m.j., van dongen, b.: performance analysis of
business process models with advanced constructs (2010)
15. prom: running example - process to repair telephones in a company.
http://www.promtools.org/prom6/downloads/example-logs.zip (2019), [online;
accessed 16-may-2019]
16. rogge-solti, a., van der aalst, w.m.p., weske, m.: discovering stochastic petri
nets with arbitrary delay distributions from event logs. in: international conference
on business process management. pp. 15{27. springer (2013)
17. rozinat, a.: process mining: conformance and extension (2010)
18. senderovich, a., rogge-solti, a., gal, a., mendling, j., mandelbaum, a., kadish,
s., bunnell, c.a.: data-driven performance analysis of scheduled processes. in:
international conference on business process management. pp. 35{52. springer
(2016)
19. song, m., van der aalst, w.m.p.: supporting process mining by showing events at a
glance. in: proceedings of the 17th annual workshop on information technologies
and systems (wits). pp. 139{145 (2007)
20. wetzstein, b., leitner, p., rosenberg, f., brandic, i., dustdar, s., leymann, f.:
monitoring and analyzing inuential factors of business process performance. in:
2009 ieee international enterprise distributed object computing conference.
pp. 141{150. ieee (2009)