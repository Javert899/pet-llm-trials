challenges in business process analysis
wil m.p. van der aalst
department of mathematics and computer science, eindhoven university of
technology, p.o. box 513, 5600 mb, eindhoven, the netherlands,
w.m.p.v.d.aalst@tue.nl ,
www home page: http://www.processmining.org
abstract. business process analysis ranges from model veriﬁcation at
design-time to the monitoring of processes at run-time. much progress
has been achieved in process veriﬁcation. today we are able to verify the
entire reference model of sap without any problems. moreover, more
and more processes leave their “trail” in the form of event logs. this
makes it interesting to apply process mining to these logs. interestingly,
practical applications of process mining reveal that reality is often quite
diﬀerent from the idealized models, also referred to as “powerpoint real-
ity”. future process-aware information systems will need to provide full
support of the entire life-cycle of business processes. recent results in
business process analysis show that this is indeed possible, e.g., the pos-
sibilities oﬀered by process mining tools such as prom are breathtaking
both from a scientiﬁc and practical perspective.
key words: business process management, process mining, petri nets,
veriﬁcation, simulation, workﬂow management
1 introduction: the role of models
models play an important role in information systems and it is clear that the
importance of models will increase. models can be used to specify systems and
processes and can be used for their analysis. some of today’s information sys-
tems are even driven by models (cf. workﬂow management systems). although
the general vision of a “model driven architecture” (mda) is appealing, it is
not yet realistic/practical for many applications. only in speciﬁc niches such as
workﬂow technology, mda is already a reality and has proven to be valuable. in
the context of enterprise resource planning (erp) systems, i.e., the world of
sap, peoplesoft, oracle, etc., models play a less prominent role. these systems
oﬀer a workﬂow component, but most of their functionality is still hard-coded.
the well-know reference model of sap [16] contains 604 event-driven process
chains (epcs) modeling the diﬀerent business processes supported by the r/3
system. however, these epc models are not used for enactment and serve more
as background information. it seems vital that erp systems like sap start us-
ing models as a starting point, rather than just as a means to document things
afterwards. it seems particularly interesting to use conﬁgurable process models2 wil m.p. van der aalst
[4] as a starting point. for example, one can make epcs conﬁgurable as shown in
[31, 23] and use models to conﬁgure the system to ﬁt a certain business context.
although models are highly relevant for the enactment of systems, this pa-
per will not focus on this aspect of modeling. the interested reader may consult
workﬂow literature to learn more about this [6, 1, 24, 20] and play with an
open-source workﬂow management system like yawl [7]. instead we focus on
theanalysis of business processes and try to provide an overview of recent de-
velopments in this area. we will focus on two types of analysis: (1) analysis
atdesign-time and (2) analysis at run-time . at design time, the only basis for
analysis is a model, e.g., a workﬂow (re)design [28]. at run-time, one can also
observe the actual behavior and use this as input for analysis.
models
analyzes
discoveryrecords 
events, e.g., 
messages, 
transactions, 
etc.specifies
configures
implements
analyzessupports/
controls
extensionconformancepeople machines
organizat ionscomponentsbusiness processes
verification
performance 
analysisperformance 
analysis
recommendation
design-time 
analysisrun-time 
analysis
fig. 1. the relationships between reality, systems, logs, and models and the diﬀerent
types of design-time and run-time analysis.
figure 1 shows an overview of the diﬀerent types of analysis discussed in
this paper. to explain the diagram let us ﬁrst consider the top part showing
the interaction between the “world” and some (software) system. any informa-
tion system ultimately interacts with some physical environment; otherwise it
serves no purpose. the system may support or control all kinds of processes
taking place in the real world. moreover, most systems also record events taking
place inside and outside the system as indicated by the arrow connecting the
“world” to event logs via the (software) system. today’s information systems
log enormous amounts of events. classical workﬂow management systems (e.g.
staﬀware), erp systems (e.g. sap), case handling systems (e.g. flower), pdm
systems (e.g. windchill), crm systems (e.g. microsoft dynamics crm), middle-challenges in business process analysis 3
ware (e.g., ibm’s websphere), hospital information systems (e.g., chipsoft), etc.
provide very detailed information about the activities that have been executed.
even embedded systems are connected to the internet today, thus allowing for
unprecedented streams of data. on the other hand, models play a prominent role
as indicated in figure 1. examples of models are process models such as bpmn
diagrams, epcs, petri nets, bpel speciﬁcations, uml activity diagrams, but
also other types of models such as social networks, organizational charts, data
models, etc. these models can be used to model the “world”. however, they can
also be used to model the system. in this context it is important to note that
most information systems have a model of reality, i.e., a software system that
has no “mental image” of the organizational context and the processes it should
support is of limited use. it is often remarkable to see the resemblance between
simulation models and workﬂow models. this supports the earlier observation
that information systems need to have a model of reality. in an mda or work-
ﬂow setting, models are used to conﬁgure the information system as shown in
figure 1. however, in this paper we focus on the analysis aspect and not on
enactment .
figure 1 clearly shows the two types of analysis: (1) analysis at design-time
and (2) analysis at run-time . in the remainder, we will elaborate on the diﬀerent
types of analysis. on the one hand, this provides a comprehensive overview of
business process analysis. on the other hand, we will use this to express our
views on the interesting research questions in this area. in particular, we would
like to make the following statements:
–veriﬁcation of real-life processes has become a reality! it is possible to verify
large sets of complicated models and these eﬀorts pay oﬀ because often many
errors are found. for example, the 604 epcs of the sap reference models can
be easily analyzed and many design errors are uncovered by doing so [26, 27].
–the abundance of event logs allows for new and exciting forms of process
analysis. process mining can use this information in various ways. it may be
used to discover the way that people really work, it may be used to ﬁnd out
where there are deviations, it may be used to support people in performing
their duties, and ultimately it can be used for all kinds of process improvement.
– using the slogan “the world is not a petri net” we would like to emphasize
that reality is often very diﬀerent from what is modeled or what people think.
whatever representation is used (petri nets or any other modeling language),
the model is an abstraction (i.e., things are left out) and may not reﬂect reality.
the ﬁrst observation (abstraction) is unavoidable and should be accepted
as a fact of life. however, the second observation is more problematic and
should be addressed urgently. as long as managers and system designer take
a “powerpoint” reality as starting point, information systems will remain to
have serious alignment problems.
– related to the previous point is the observation that there should be more
attention for the quality of models . simple questions like how similar two mod-
els are or how well models describe reality cannot be answered. practitioners
use informal models that have no semantics while computer scientists like to4 wil m.p. van der aalst
focus on true/false answers (cf. notions like bisimulation, trace equivalence,
etc.). concepts such as abstraction level, non-ﬁtting, over-approximating,
over-ﬁtting, and under-approximating are not well-understood.
– there is a need for the academic community to share software and to build
mature business process analysis tools . with the prom framework we try to
do so. prom provides an open-source environment where people can plug-in
their own analysis tools. currently, prom has more than 190 plug-ins covering
the whole spectrum of process analysis, but with a clear emphasis on process
mining and model translations.
in the remainder of this paper, these statements are explained and put into
context. note that this paper is an invited paper based on a keynote talk at
iceis 2007, extending [2] with some discussion on the quality of models.
2 analysis at design-time
this section elaborates on model-based analysis at design time. note that we
focus on process models but do not limit ourselves to the control-ﬂow perspective.
2.1 diﬀerent types of analysis
the correctness, eﬀectiveness, and eﬃciency of the business processes supported
by the information system are vital to the organization. a process deﬁnition
which contains errors may lead to angry customers, back-log, damage claims,
and loss of goodwill. flaws in the design of a process deﬁnition may also lead to
high throughput times, low service levels, and a need for excess capacity. this
is why it is important to analyze a process before it is put into production. as
shown in figure 1, there are three types of analysis:
–validation , i.e., testing whether the process behaves as expected,
–veriﬁcation , i.e., establishing the correctness of a process deﬁnition, and
–performance analysis , i.e., evaluating the ability to meet requirements with
respect to throughput times, service levels, and resource utilization.
validation can be done by interactive simulation: a number of ﬁctitious cases are
fed to the system to see whether they are handled well. for veriﬁcation and per-
formance analysis more advanced analysis techniques are needed. fortunately,
many powerful analysis techniques have been developed and some of the cor-
responding tools have become mature in recent years. as an example, consider
the petri-net-based techniques and tools available for the modeling and analysis
of workﬂows [6, 1, 37]. linear algebraic techniques can be used to verify many
properties, e.g., place invariants, transition invariants, and (non-)reachability.
coverability graph analysis, model checking, and reduction techniques can be
used to analyze the dynamic behavior of a petri net. simulation and markov-
chain analysis can be used for performance evaluation.challenges in business process analysis 5
2.2 veriﬁcation techniques have become mature!
a complete overview of the diﬀerent types of design-time analysis is outside the
scope of this paper. however, we would like to emphasize that already today
there are mature tools and techniques to verify large collections of non-trivial
models. tools such as woﬂan [37] have played a pioneering role in this domain.1
using woﬂan it is possible to extract models from all kinds of systems and check
these models for deadlocks, etc. to illustrate the maturity of process veriﬁcation
we brieﬂy describe the analysis of the entire sap reference model [16] described
in [26, 27].
the sap reference model contains more than 600 non-trivial process models
expressed in terms of event-driven process chains (epcs). we have automat-
ically translated these epcs into yawl models [7] and analyzed these models
using wofyawl, a veriﬁcation tool based on petri nets extending woﬂan [37].
the translation from epcs to yawl is trivial because epcs can be considered
a subset of the much more expressive yawl language [7]. the yawl mod-
els are then translated to petri nets and these petri nets are analyzed using the
well-known petri-net invariants. this approach does not ﬁnd all errors. however,
all errors found are real errors, i.e., the approach is sound but not necessarily
complete. nevertheless, we discovered that at least 34 of these epcs contain
errors (i.e., at least 5.6% is ﬂawed). we analyzed which parts of the sap ref-
erence model contain most errors. moreover, based on 15 characteristics (e.g.,
the size of the model), we used logistic regression to ﬁnd possible predictors for
these errors showing that complexity of epcs has a signiﬁcant impact on error
probability. this systematic analysis of the sap reference model illustrates the
maturity of process veriﬁcation.
the interested reader is referred to [26, 27] for details and pointers to the
analysis of similar datasets covering thousands of epcs. moreover, using im-
proved techniques we are even able to ﬁnd much more errors. in this work we
also predict the occurrence of errors based on features such as size, complex-
ity, modeling constructs used, etc. as indicated above, logistic regression can be
used to develop useful error predictors. this is related to the complexity metrics
presented in [14]. the hypothesis is that people are more likely to make errors
if they use particular techniques and/or constructs.
3 analysis at run-time
after discussing techniques to be used at design-time, we now focus on run-time
analysis (cf. figure 1). as indicated in the introduction, today’s systems provide
detailed event logs. process mining has emerged as a way to analyze systems
and their actual use based on the event logs they produce [11, 12, 10, 13, 17, 19,
22, 32, 38]. note that, unlike classical data mining, the focus of process mining is
on concurrent processes and not on static or mainly sequential structures. also
1a substantial part of the functionality of woﬂan in embedded in prom [3].6 wil m.p. van der aalst
note that commercial “business intelligence” (bi) tools are not doing any process
mining. they typically look at aggregate data seen from an external perspective
(frequencies, averages, utilization, service levels, etc.). unlike bi tools, process
mining looks “inside the process” (what are the causal dependencies?, where is
the bottleneck?, etc.) and at a very reﬁned level. in the context of a hospital, bi
tools focus on performance indicators such as the number of knee operations, the
length of waiting lists, and the success rate of surgery. process mining is more
concerned with the paths followed by individual patients and whether certain
procedures are followed or not.
the omnipresence of event logs is an important enabler of process mining,
i.e., analysis of run-time behavior is only possible if events are recorded. as
indicated earlier all kinds of information systems provide such logs, e.g., clas-
sical workﬂow management systems (e.g. staﬀware), erp systems (e.g. sap),
case handling systems (e.g. flower), pdm systems (e.g. windchill), crm sys-
tems (e.g. microsoft dynamics crm), middleware (e.g., ibm’s websphere),
hospital information systems (e.g., chipsoft), etc. these systems provide very
detailed information about the activities that have been executed. however, also
all kinds of embedded systems increasingly log events. an embedded system is
a special-purpose system in which the computer is completely encapsulated by
or dedicated to the device or system it controls. examples are medical systems
(e.g., x-ray machines), mobile phones, car entertainment systems, production
systems (e.g., wafer steppers), copiers, sensor networks, etc. software plays an
increasingly important role in such systems and, already today, many of these
systems record events. an example is the “customercare remote services
network” of philips medical systems (pms). this is a worldwide internet-based
private network that links pms equipment to remote service centers. an event
that occurs within an x-ray machine (e.g., moving the table, setting the deﬂec-
tor, etc.) is recorded and analyzed. the logging capabilities of the machines of
pms illustrate the way in which embedded systems produce event logs.
the goal of process mining is to extract information (e.g., process models)
from these logs, i.e., process mining describes a family of a-posteriori analysis
techniques exploiting the information recorded in the event logs. typically, these
approaches assume that it is possible to sequentially record events such that each
event refers to an activity (i.e., a well-deﬁned step in the process) and is related to
a particular case (i.e., a process instance). furthermore, some mining techniques
use additional information such as the performer or originator of the event (i.e.,
the person / resource executing or initiating the activity), the timestamp of the
event, or data elements recorded with the event (e.g., the size of an order).
3.1 process discovery
traditionally, process mining has been focusing on discovery (cf. figure 1), i.e.,
deriving information about the original process model, the organizational con-
text, and execution properties from enactment logs. an example of a technique
addressing the control ﬂow perspective is the α-algorithm, which constructs achallenges in business process analysis 7
fig. 2. a petri net discovered by prom using the α-algorithm.
petri net model [18, 30] describing the behavior observed in the event log. how-
ever, process mining is not limited to process models (i.e., control ﬂow) and
recent process mining techniques are more and more focusing on other perspec-
tives, e.g., the organizational perspective or the data perspective. for example,
there are approaches to extract social networks from event logs and analyze
them using social network analysis [9]. this allows organizations to monitor how
people, groups, or software/system components are working together.
there are many diﬀerent types of discovery. however, to understand the basic
idea let us consider the problem of constructing a petri net from an event log.
letabe a set of activity names. for every process instance (often referred
to as case), a sequence of activities is recorded. such a sequence of activities is
called as a trace .a∗is the set of all possible traces given a set of activities a.
anevent log is a set of process instances. since only the corresponding traces
are of interest here, an event log lis described by a bag (i.e., a multi-set) of
traces. in other words: l∈a∗→i n, i.e., for any possible σ∈a∗,l(σ) denotes
the number of process instances having a sequence of activities σ.
as an example consider the process of handling customer orders. an exam-
ple of a trace would be (register, ship, send bill, payment, accounting, approved,
close) . this trace represents a sequence of 7 activities. to represent the log
we use more convenient (i.e., shorter) names: r=register ,s=ship ,sb=send bill,
p=payment ,ac=accounting ,ap=approved ,c=close . moreover, there are addi-
tional activities such as em=express mail,rj=rejected , and rs=resolve . using
this shorter notation we now consider a log lwhere each of the following traces
occurs once ( r, s, sb, p, ac, ap, c ), (r, sb, em, p, ac, ap, c ), (r, sb, p, em, ac, rj, rs, c ),
(r, em, sb, p, ac, ap, c ), (r, sb, s, p, ac, rj, rs, c ), (r, sb, p, s, ac, ap, c ), and ( r, sb, p,
em, ac, ap, c ). it is easy to imagine that such traces could be extracted from the
logs of some information system (e.g., a sap r/3 system). it should be noted
that all traces start with r(register order) and end with c(close order). more-
over, some of the other activities also appear in all traces, e.g., sb(send bill), p
(payment), and ac(accounting). in all traces either s(ship) or em(express mail)
occurs. if ap(approved) occurs in this small set of traces, then rj(rejected) and
rs(resolve) do not occur (and vice versa). note that for the human eye it is dif-
ﬁcult to make these conclusions and construct a process model that corresponds
to the behavior recorded in event log l. therefore, many process discovery al-
gorithms have been proposed to automatically construct process models (e.g.,8 wil m.p. van der aalst
a petri net) [11, 12, 13, 17, 19, 22, 38]. figure 2 shows a petri net discovered
using the α-algorithm [12], i.e., based on the event log lautomatically a model
is constructed. in section 6, when we discuss tool support for process analysis,
we will provide some more examples.
3.2 conformance checking
the second type of analysis based on event logs is conformance checking (cf.
figure 1). unlike process discovery, it is assumed that there is an a-priori model.
this model is used to check if reality conforms to the model. for example,
there may be a process model indicating that purchase orders of more than one
million euro require two checks. another example is the checking of the four-eyes
principle. conformance checking may be used to detect deviations, to locate and
explain these deviations, and to measure the severity of these deviations.
in [32] it is shown how a process model (e.g., a petri net) can be evaluated
in the context of a log using metrics such as “ﬁtness” (is the observed behavior
possible according to the model?) and “appropriateness” (is the model “typical”
for the observed behavior?). however, it is also possible to check conformance
based on organizational models, predeﬁned business rules, temporal formulas,
quality of service (qos) deﬁnitions, etc.
note that conformance checking seems particularly interesting in the context
of web services [5, 15].
3.3 extension
the third type of process mining assumes again both a log and a model (cf.
figure 1). however, the model is not checked for correctness, instead it is used
as a basis, i.e., the model is extended with a new aspect or perspective. there are
diﬀerent ways to extend a given process model with additional perspectives based
on event logs, e.g., decision mining, performance analysis, and user proﬁling.
decision mining, also referred to as decision point analysis, aims at the detection
of data dependencies that aﬀect the routing of a case [33]. starting from a process
model, one can analyze how data attributes inﬂuence the choices made in the
process based on past process executions. classical data mining techniques such
as decision trees can be leveraged for this purpose. similarly, the process model
can be extended with timing information (e.g., bottleneck analysis).
3.4 process mining and simulation
simulation is typically used at design-time. however, given the abundance of
data about the actual process, it is interesting to combine process mining and
simulation. in our research we envision at least two interesting approaches to
link both topics:
–simulation model discovery [35]. process mining is not limited to the control-
ﬂow perspective. using discovery and extension it is possible to build processchallenges in business process analysis 9
models adequately describing multiple perspectives (control-ﬂow, data, re-
sources, timing, etc.). this model can directly be used for simulation purposes
as demonstrated in [35]. the possibility to extract simulation model from event
logs opens-up all kinds of application possibilities and signiﬁcantly lowers the
threshold for using simulation. moreover, most simulation tools are able to
generate event logs. therefore, it is also possible to use process mining tools
to analyze simulation results. therefore, it is possible to make a very tight
connection between process mining and simulation.
–short-term simulation [29]. one can think of short-term simulation as a quick
look in the near future, i.e., a kind of “fast forward” button. by pushing this
button, it is possible to see what happens if the current situation is extrap-
olated. it is also possible to see the eﬀect of certain decisions (e.g. hiring
additional employees or renounce new orders) in the near future. in this way,
short-term simulation becomes a powerful tool for management control and
operation control. in order to apply this idea three ingredients are essential:
(1) a parameterized process model that can be simulated, (2) historic data
to estimate parameters, (3) the current state of the workﬂows (i.e., the states
of all cases in the pipeline). in the context of a workﬂow management sys-
tem all this information is available as shown in [29]. process mining can be
used to extract the required information from historic data, parameterize the
simulation model, and to analyze the simulation results.
3.5 recommendation
process mining is not limited to analyzing processes. the results can also be
used to act. one of the ideas we are working on is the development of so-called
recommendation services . the idea is as follows. using process mining one can
analyze which strategies are successful and which are not, i.e., every case (process
instance) that was executed can be rated in terms of ﬂow time, costs, quality, etc.
therefore, it is possible to build a model predicting the performance of a case
with respect to the selected metric. this can be used to recommend particular
executions, i.e., given a partial execution of a case (the sequence of steps executed
so far), the recommendation service suggests the next step. diﬀerent variants are
possible and implemented in prom.
4 the world is not a petri net!
the title of this section “the world is not a petri net!” is intended to provoke
designers, manager, and academics that actually think that real-life processes
behave as modeled in some process model. note that this applies to any process
model having some kind of semantics, i.e., not just petri nets but also bpmn
models, epcs, bpel speciﬁcations, uml activity diagrams, process algebraic
speciﬁcations, etc.2this is not a notational problem, i.e., it is not caused by
2models without any semantics are “safe” in this respect but provide no information.10 wil m.p. van der aalst
the modeling language but by the idealized views people have when describing
processes. real-life processes turn out to be less structured than people tend
to believe. unfortunately, traditional process mining approaches have problems
dealing with unstructured processes. the discovered models are often “spaghetti-
like” showing all details without distinguishing what is important and what is
not.
fig. 3. a process model based on the ﬂow of 874 patients having heart surgery.
to illustrate this consider figure 3 showing a process model obtained using
the process mining technique described in [38] which is supported by the heuris-
tics miner of prom (see section 6). the model is based on an event log with
10478 events. these event were recorded by the information system of a dutch
hospital for a group of 874 patients. this was a relatively homogeneous group of
patients: each patient had a heart surgery. there are 181 diﬀerent events, i.e.,challenges in business process analysis 11
event types corresponding to possible activities in the context of heart surgery.
as can be seen, the model is “spaghetti-like”. one may think that figure 3 sug-
gest a poor performance of the process mining technique. however, this is not
the case, figure 3 reﬂects reality and reality is often “spaghetti-like” and not as
structured as people want to believe.
over the last couple of years we obtained much experience in applying the
tried-and-tested set of mining algorithms to real-life processes. existing algo-
rithms tend to perform well on structured processes but often fail to provide
insightful models for less structured processes, cf. figure 3. the problem is not
that existing techniques produce incorrect results. in fact, some of the more ro-
bust process mining techniques guarantee that the resulting model is “correct”
in the sense that reality ﬁts into the model. the problem is that the resulting
model shows all details without providing a suitable abstraction. this is compa-
rable to looking at the map of a country where all cities and town are represented
by identical nodes and all roads are depicted in the same manner. the resulting
map is correct but not very suitable. therefore, the concept of a roadmap can
used as a metaphor to visualize the resulting models. based on an analysis of
the log the importance of activities and relations among activities are taken into
account. activities and their relations can be clustered or removed depending
on their role in the process. moreover, certain aspects can be emphasized graph-
ically just like a roadmap emphasizes highways and large cities over dirt roads
and small towns. the fuzzy miner in prom [21] is using the roadmap metaphor
to present more meaningful process models.
5 quality of models
the complexity of real life processes, triggers questions about the quality of
models. diﬀerent kinds of people ranging from end-users and managers to sys-
tem analysts and programmers make models of processes. often there is little
attention to the quality of these models.
first of all, there is the question of abstraction level : what is the right level
of abstraction? often this is a rather implicit choice while this should be driven
by the questions that the model should answer!
=?=?
does the model reflect rea lity? are models the similar?
fig. 4. questions.12 wil m.p. van der aalst
even if the right level of abstraction is chosen fundamental questions such as
the two shown in figure 4 remain: (1) does the model reﬂect reality? and (2)
when are two models similar?
let us ﬁrst focus on the second question. in various application domains
there is a desire to compare process models, e.g., to relate an organization-
speciﬁc process model to a reference model, to ﬁnd a web service matching some
desired service description, or to compare some normative process model with
a process model discovered using process mining techniques. although many
researchers have worked on diﬀerent notions of equivalence (e.g., trace equiva-
lence, bisimulation, branching bisimulation, etc.), most of the existing notions
are not very useful in this context. first of all, most equivalence notions re-
sult in a binary answer (i.e., two processes are equivalent or not). this is not
very helpful, because, in real-life applications, one needs to diﬀerentiate between
slightly diﬀerent models and completely diﬀerent models. second, not all parts
of a process model are equally important. there may be parts of the process
model that are rarely activated while other parts are executed for most process
instances. clearly, these should be considered diﬀerently. to address these prob-
lems, a completely new way of comparing process models is proposed in [8].
rather than directly comparing two models, the process models are compared
with respect to some typical behavior. this way it is possible to avoid some of
the problems mentioned above. nevertheless, it remains a challenge to compare
models without aiming at a true/false answer.
fig. 5. comparing models with reality.
the ﬁrst question shown in figure 4, relates to the notion of conformance
mentioned earlier. as figure 5 shows four types of problems can be identiﬁed:
non-ﬁtting, over-approximating, over-ﬁtting, and under-approximating (assum-challenges in business process analysis 13
ing the models are at the right abstraction level). the cloud-shaped symbols
refer to reality while the square-shaped symbols refer to models. the model is
non-ﬁtting if behavior observed in reality is not possible according to the model
and behavior possible according to the model is not observed in reality. the
model is over-approximating if it allows for much more behavior than observed
in reality. the model is under-approximating if it allows for much less behavior
than observed in reality. however, an exact ﬁt between observed behavior and
behavior possible according to the model may also not be desirable. as figure 5
shows the behavior observed may shift over time. in many cases, one only sees
a fraction of all possible behaviors. hence, one should not resort to over-ﬁtting .
the goal is to ﬁnd a balance, however, as figure 5 illustrates this is not easy.
to illustrate the relevance of having good models we refer to a case study
reported in [34]. in this case study, we show that for the main test process of
a manufacturer of wafer scanners the reference process (i.e., the process used
to instruct the test engineers) has a ﬁtness of only 37 percent, i.e., only 37
percent of the activities occurs as planned. having better models will assist
these test engineers in doing their work. moreover, only a good understanding
of the process can lead to better it support.
in this section, we did not address the “soft” aspects of model quality like
readability and understandability. clearly, there are also relevant as discussed
in [14, 25, 36].
6 towards comprehensive tool support
in this paper, we already referred to analysis tools such as woﬂan [37] and prom
[3].
the focus on woﬂan is on design-time analysis and in particular on veriﬁca-
tion. woﬂan was designed to address the problem that today’s workﬂow products
have no support for workﬂow veriﬁcation. errors made at design-time are not
detected and result in very costly failures at run-time. woﬂan analyzes workﬂow
process deﬁnitions downloaded from commercial workﬂow products using state-
of-the-art petri-net-based analysis techniques. recently, part of the functionality
of woﬂan was embedded into prom.
initially the focus of prom was on run-time analysis and in particular on
process mining. however, over the last couple of years the scope of prom has
been extended to all kinds of process analysis as shown in figure 1. for example,
prom oﬀers several ways to verify models and can export to all kinds of tools,
e.g., tools for simulation or performance analysis. it also allows for all kinds
of model transformations, e.g., an epc discovered via process mining can be
converted into a petri net or yawl model. prom also oﬀers a recommendation
service and allows for diﬀerent types of conformance checking. currently, prom
contains 190 plug-ins and it is impossible to give a complete overview here.
therefore, we only elaborate a bit on the plug-ins related to process discovery.
prom implements about 20 diﬀerent process discovery algorithms. since a
complete review of the diﬀerent algorithms is outside the scope of this paper, we14 wil m.p. van der aalst
fig. 6. two process models discovered using the multi-phase miner (left) and the
heuristics miner (right).
just show three examples. in section 3.1 we already showed a petri net discovered
using the α-algorithm [12]. figure 2 shows a process model generated by prom
based on the event log ldescribed in section 3.1. it is easy to see that the
traces in the log can indeed be reproduced by this petri net. note that the α-
algorithm “discovers” choices and concurrency. although the example does not
contain any loops, the α-algorithm can also discover iterations. the α-algorithm
is rather sensitive to noise and exceptional behavior and has problems handling
more advanced control-ﬂow patterns. figure 6 shows two alternative techniques
that are more robust. the multi-phase miner always produces a model that can
replay the log [19]. it uses event-driven process chains (epcs) as a default
representation as shown on the left-hand-side of figure 6. however, the epcs
can be converted in other formats such as various types of petri nets, yawl
models, bpel speciﬁcations, etc. the drawback of the technique used by the
multi-phase miner is that it has a tendency to over-generalize, i.e., sometimes the
model allows for too much behavior. the model shown on the right-hand-side of
figure 6 is produced by the heuristics miner [38]. the heuristics miner represents
processes in a notation dedicated to process mining. however, its results can be
converted to other notations. the heuristics miner specializes in dealing with
noise and exceptional situations, e.g., situations such as depicted in figure 3.challenges in business process analysis 15
it is not necessary to understand the three discovered models shown in ﬁg-
ures 2 and 6. however, it is important to note that there are various process
mining algorithms that perform well on structured processes. prom oﬀers a wide
variety of process discovery techniques. using prom the discovered models can
be converted to the desired format (petri nets, epcs, yawl, etc.).
prom is an open-source framework that can be downloaded from www.
processmining.org .
7 conclusion
in this paper, we provided a, rather personalized, overview of interesting trends
in business process analysis. this overview is far from complete and the main
purpose of this paper is to make a number of speciﬁc statements related to
business process analysis. first of all, we argued that the practical veriﬁcation
of real-life processes has become a reality. the veriﬁcation of the entire sap
reference model is a nice illustration of this [26, 27]. second, we motivated that
the abundance of event logs allows for new and exciting forms of process analysis.
we provided an overview of the diﬀerent types of analysis oﬀered by process
mining techniques. third, we showed, using the slogan “the world is not
a petri net” , that reality is often very diﬀerent from what is modeled or what
people think. figure 3 shows a model describing the ﬂow of patients having heart
surgery. it shows a “spaghetti-like” model and for many other real-life processes
similar-looking models are obtained. this does not imply a poor performance
of the corresponding process mining techniques. it merely reﬂects that reality is
often “spaghetti-like” and not as structured as people want to believe, i.e., reality
does not ﬁt onto a powerpoint slide. finally, we showed some of the analysis
tools developed at eindhoven university of technology. we focused on the prom
framework. prom provides an extensive set of analysis techniques which can be
applied to real-life logs while supporting many parts of the spectrum depicted in
figure 1. we encourage people developing and/or using business process analysis
tools to join this initiative and download the toolset from www.processmining.
org.
acknowledgements
this research is supported by eit, nwo-ew, the technology foundation stw,
and the super project (fp6). moreover, we would like to thank the many
people involved in the development of prom.
references
1. w.m.p. van der aalst. business process management demystiﬁed: a tutorial on
models, systems and standards for workﬂow management. in j. desel, w. reisig,16 wil m.p. van der aalst
and g. rozenberg, editors, lectures on concurrency and petri nets , volume 3098
oflecture notes in computer science , pages 1–65. springer-verlag, berlin, 2004.
2. w.m.p. van der aalst. trends in business process analysis: from veriﬁcation to
process mining. in j. cardoso, j. cordeiro, and j. filipe, editors, proceedings of
the 9th international conference on enterprise information systems (iceis 2007) ,
pages 12–22. institute for systems and technologies of information, control and
communication, insticc, medeira, portugal, 2007.
3. w.m.p. van der aalst, b.f. van dongen, c.w. g¨ unther, r.s. mans, a.k. alves
de medeiros, a. rozinat, v. rubin, m. song, h.m.w. verbeek, and a.j.m.m.
weijters. prom 4.0: comprehensive support for real process analysis. in j. kleijn
and a. yakovlev, editors, application and theory of petri nets and other models of
concurrency (icatpn 2007) , volume 4546 of lecture notes in computer science ,
pages 484–494. springer-verlag, berlin, 2007.
4. w.m.p. van der aalst, a. dreiling, f. gottschalk, m. rosemann, and m.h. jansen-
vullers. conﬁgurable process models as a basis for reference modeling. in c. bus-
sler et al., editor, bpm 2005 workshops (workshop on business process refer-
ence models) , volume 3812 of lecture notes in computer science , pages 512–518.
springer-verlag, berlin, 2006.
5. w.m.p. van der aalst, m. dumas, c. ouyang, a. rozinat, and h.m.w. verbeek.
choreography mining and conformance checking. in f. leymann, w. reisig,
s.r. thatte, and w.m.p. van der aalst, editors, the role of business processes in
service oriented architectures , number 6291 in dagstuhl seminar proceedings. in-
ternationales begegnungs- und forschungszentrum fuer informatik (ibfi), schloss
dagstuhl, germany, july 2006.
6. w.m.p. van der aalst and k.m. van hee. workﬂow management: models, methods,
and systems . mit press, cambridge, ma, 2004.
7. w.m.p. van der aalst and a.h.m. ter hofstede. yawl: yet another workﬂow
language. information systems , 30(4):245–275, 2005.
8. w.m.p. van der aalst, a.k. alves de medeiros, and a.j.m.m. weijters. process
equivalence: comparing two process models based on observed behavior. in
s. dustdar, j.l. faideiro, and a. sheth, editors, international conference on busi-
ness process management (bpm 2006) , volume 4102 of lecture notes in computer
science , pages 129–144. springer-verlag, berlin, 2006.
9. w.m.p. van der aalst, h.a. reijers, and m. song. discovering social networks
from event logs. computer supported cooperative work , 14(6):549–593, 2005.
10. w.m.p. van der aalst, h.a. reijers, a.j.m.m. weijters, b.f. van dongen, a.k.
alves de medeiros, m. song, and h.m.w. verbeek. business process mining: an
industrial application. information systems , 32(5):713–732, 2007.
11. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
12. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128–1142, 2004.
13. r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
ﬂow logs. in sixth international conference on extending database technology ,
pages 469–483, 1998.
14. j. cardoso. process control-ﬂow complexity metric: an empirical validation. in
ieee international conference on services computing (scc 2006) , pages 167–
173. ieee computer society, 2006.challenges in business process analysis 17
15. j. cardoso, a.p. sheth, j.a. miller, j. arnold, and k. kochut. quality of service
for workﬂows and web service processes. journal of web semantics , 1(3):281–308,
2004.
16. t. curran and g. keller. sap r/3 business blueprint: understanding the busi-
ness process reference model . upper saddle river, 1997.
17. a. datta. automating the discovery of as-is business process models: proba-
bilistic and algorithmic approaches. information systems research , 9(3):275–301,
1998.
18. j. desel and j. esparza. free choice petri nets , volume 40 of cambridge tracts
in theoretical computer science . cambridge university press, cambridge, uk,
1995.
19. b.f. van dongen and w.m.p. van der aalst. multi-phase process mining: building
instance graphs. in p. atzeni, w. chu, h. lu, s. zhou, and t.w. ling, editors, in-
ternational conference on conceptual modeling (er 2004) , volume 3288 of lecture
notes in computer science , pages 362–376. springer-verlag, berlin, 2004.
20. d. georgakopoulos, m. hornick, and a. sheth. an overview of workﬂow manage-
ment: from process modeling to workﬂow automation infrastructure. distributed
and parallel databases , 3:119–153, 1995.
21. c.w. g¨ unther and w.m.p. van der aalst. fuzzy mining: adaptive process sim-
pliﬁcation based on multi-perspective metrics. in g. alonso, p. dadam, and
m. rosemann, editors, international conference on business process management
(bpm 2007) , volume 4714 of lecture notes in computer science , pages 328–343.
springer-verlag, berlin, 2007.
22. j. herbst. a machine learning approach to workﬂow management. in proceedings
11th european conference on machine learning , volume 1810 of lecture notes in
computer science , pages 183–194. springer-verlag, berlin, 2000.
23. m.h. jansen-vullers, w.m.p. van der aalst, and m. rosemann. mining con-
ﬁgurable enterprise information systems. data and knowledge engineering ,
56(3):195–244, 2006.
24. f. leymann and d. roller. production workﬂow: concepts and techniques .
prentice-hall ptr, upper saddle river, new jersey, usa, 1999.
25. j. mendling. detection and prediction of errors in epc business process models .
phd thesis, vienna university of economics and business administration, vienna,
austria, 2007.
26. j. mendling, w. van der aalst, b. van dongen, and e. verbeek. errors in the sap
reference model. bptrends , 4(6):1–5, june 2006.
27. j. mendling, m. moser, g. neumann, h.m.w. verbeek, b.f. van dongen, and
w.m.p. van der aalst. faulty epcs in the sap reference model. in s. dustdar,
j.l. faideiro, and a. sheth, editors, international conference on business process
management (bpm 2006) , volume 4102 of lecture notes in computer science ,
pages 451–457. springer-verlag, berlin, 2006.
28. m. netjes, i. vanderfeesten, and h.a. reijers. “intelligent” tools for workﬂow
process redesign: a research agenda. in c. bussler and a. haller, editors, busi-
ness process management workshops (bpm 2005) , volume 3812 of lecture notes
in computer science , pages 444–453. springer-verlag, berlin, 2006.
29. h.a. reijers and w.m.p. van der aalst. short-term simulation: bridging the gap
between operational control and strategic decision making. in m.h. hamza,
editor, proceedings of the iasted international conference on modelling and
simulation , pages 417–421. iasted/acta press, anaheim, usa, 1999.
30. w. reisig and g. rozenberg, editors. lectures on petri nets i: basic models ,
volume 1491 of lecture notes in computer science . springer-verlag, berlin, 1998.18 wil m.p. van der aalst
31. m. rosemann and w.m.p. van der aalst. a conﬁgurable reference modelling
language. information systems , 32(1):1–23, 2007.
32. a. rozinat and w.m.p. van der aalst. conformance testing: measuring the fit
and appropriateness of event logs and process models. in c. bussler et al., editor,
bpm 2005 workshops (workshop on business process intelligence) , volume 3812
oflecture notes in computer science , pages 163–176. springer-verlag, berlin,
2006.
33. a. rozinat and w.m.p. van der aalst. decision mining in prom. in s. dustdar,
j.l. faideiro, and a. sheth, editors, international conference on business process
management (bpm 2006) , volume 4102 of lecture notes in computer science ,
pages 420–425. springer-verlag, berlin, 2006.
34. a. rozinat, i.s.m. de jong, c.w. g¨ unther, and w.m.p. van der aalst. process
mining of test processes: a case study. beta working paper series, wp 220,
eindhoven university of technology, eindhoven, 2007.
35. a. rozinat, r.s. mans, and w.m.p. van der aalst. mining cpn models: discover-
ing process models with data from event logs. in k. jensen, editor, proceedings
of the seventh workshop on the practical use of coloured petri nets and cpn
tools (cpn 2006) , volume 579 of daimi , pages 57–76, aarhus, denmark, october
2006. university of aarhus.
36. i. vanderfeesten, j. cardoso, j. mendling, h.a. reijers, and w.m.p. van der aalst.
quality metrics for business process models. in l. fischer, editor, bpm and
workﬂow handbook 2007 , pages 179–190. future strategies inc., lighthouse point,
florida, usa, 2007.
37. h.m.w. verbeek, t. basten, and w.m.p. van der aalst. diagnosing workﬂow
processes using woﬂan. the computer journal , 44(4):246–279, 2001.
38. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models
from event-based data using little thumb. integrated computer-aided engi-
neering , 10(2):151–162, 2003.