log-based evaluation of label splits for process models
tax, n.; sidorova, n.; haakma, r.; van der aalst, w.m.p.
published in:
procedia computer science
doi:
10.1016/j.procs.2016.08.096
published: 01/01/2016
document version
publisher’s pdf, also known as version of record (includes final page, issue and volume numbers)
please check the document version of this publication:
• a submitted manuscript is the author's version of the article upon submission and before peer-review. there can be important differences
between the submitted version and the official published version of record. people interested in the research are advised to contact the
author for the final version of the publication, or visit the doi to the publisher's website.
• the final author version and the galley proof are versions of the publication after peer review.
• the final published version features the final layout of the paper including the volume, issue and page numbers.
link to publication
citation for published version (apa):
tax, n., sidorova, n., haakma, r., & van der aalst, w. (2016). log-based evaluation of label splits for process
models. procedia computer science, 96, 63-72. doi: 10.1016/j.procs.2016.08.096
general rights
copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners
and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.
            • users may download and print one copy of any publication from the public portal for the purpose of private study or research.
            • you may not further distribute the material or use it for any profit-making activity or commercial gain
            • you may freely distribute the url identifying the publication in the public portal ?
take down policy
if you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately
and investigate your claim.
download date: 14. jan. 2018 procedia computer science   96  ( 2016 )  63 – 72 available online at www.sciencedirect.com
1877-0509 © 2016 the authors. published by elsevier b.v . this is an open access article under the cc by-nc-nd license 
(http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
peer-review under responsibility of kes internationaldoi: 10.1016/j.procs.2016.08.096 sciencedirect
20th international conference on knowledge based and intelligent information and engineering
systems
log-ba sed evaluation of label splits for process models
niek taxa,b,∗, natalia sidorovaa, reinder haakmab, wil m. p. van der aalsta
aeindhoven university of technology, p .o. box 513, eindhoven, the netherlands
bphilips resear ch, prof. holstlaan 4, 5665 aa eindhoven, the netherlands
abstract
process mining techniques aim to extract insights in processes from event logs. one of the challenges in process mining is
identifying interesting and meaningful event labels that contribute to a better understanding of the process. our application area is
mining data from smart homes for elderly , where the ultimate goal is to signal deviations from usual behavior and provide timely
recommendations in order to extend the period of independent living. extracting individual process models showing user behavior is
an important instrument in achieving this goal. however, the interpretation of sensor data at an appropriate abstraction level is not
straightforward. for example, a motion sensor in a bedroom can be triggered by tossing and turning in bed or by getting up. we try
to derive the actual activity depending on the context (time, previous events, etc.). in this paper we introduce the notion of label
reﬁnements, which links more abstract event descriptions with their more reﬁned counterparts. we present a statistical evaluation
method to determine the usefulness of a label reﬁnement for a given event log from a process perspective. based on data from smart
homes, we show how our statistical evaluation method for label reﬁnements can be used in practice. our method was able to select
two label reﬁnements out of a set of candidate label reﬁnements that both had a positive e ﬀecton model precision.
c/circlecopyrt2016 the authors. published by elsevier b.v .
peer-revie w under responsibility of kes international.
keywords: label reﬁnement; process mining; sensor networks
1. introduction
process mining is a fast growing discipline that brings together knowledge and techniques from computational
intelligence, data mining, process modeling and proces s analysis15. the process mining task is the automatic or
semi-automatic analysis of events that are logged during process execution, where event records contain information on
what was done, by whom, for whom, where, when, etc. events are grouped into cases (process instances), e.g. per
patient for a hospital log, or per insurance claim for an insurance company. an important task within process mining is
process discovery , which focuses on extracting interpretable models of processes from event logs. one of the attributes
of the events is usually used as its label. these event labels are then used as transition /activity labels in the process
models created by process discovery algorithms.
∗corresponding author . tel.:+31-63-408-5760;
e-mail address: n.tax@tue.nl© 2016 the authors. published by elsevier b.v . this is an open access article under the cc by-nc-nd license 
(http://creativecommons.org/licenses/by-nc-nd/4.0/ ).
peer-review under responsibility of kes international64   niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
p1t ossing
&turning
in bed
t1getting
out of
bed
t2p2living
room
motion
t3p3kitchen
motion
t4p4
open
close
f ridget5p6p5
boil
watert6p7
living
room
motion
t7p8
fig.1: a petri net derived from the event log in table 1
table 1: the corresponding smart home sensor event log with reﬁned labels
id timestamp address sensor heart rate activity
1 03/11/2015 02:45 mountain rd. 7 bedroom motion 74 tossing & turning
2 03/11/2015 03:23 mountain rd. 7 bedroom motion 72 tossing & turning
3 03/11/2015 04:59 mountain rd. 7 bedroom motion 71 tossing & turning
4 03/11/2015 06:04 mountain rd. 7 bedroom motion 73 tossing & turning
5 03/11/2015 08:45 mountain rd. 7 bedroom motion 85 getting up
6 03/11/2015 09:10 mountain rd. 7 living room motion 79 living room motion
... 03/11/2015 ... mountain rd. 7 ... ... ...
7 03/12/2015 01:01 mountain rd. 7 bedroom motion 73 tossing & turning
8 03/12/2015 03:13 mountain rd. 7 bedroom motion 75 tossing & turning
9 03/12/2015 07:24 mountain rd. 7 bedroom motion 74 tossing & turning
10 03/12/2015 08:34 mountain rd. 7 bedroom motion 79 getting up
11 03/12/2015 09:12 mountain rd. 7 living room motion 76 living room motion
... 03/12/2015 ... mountain rd. 7 ... ... ...
12 03/13/2015 00:45 mountain rd. 7 bedroom motion 75 tossing & turning
13 03/13/2015 02:29 mountain rd. 7 bedroom motion 75 tossing & turning
14 03/13/2015 05:19 mountain rd. 7 bedroom motion 74 tossing & turning
15 03/13/2015 05:34 mountain rd. 7 bedroom motion 79 tossing & turning
16 03/13/2015 05:39 mountain rd. 7 bedroom motion 77 tossing & turning
17 03/13/2015 08:37 mountain rd. 7 bedroom motion 79 getting up
18 03/13/2015 08:52 mountain rd. 7 living room motion 78 living room motion
... 03/13/2015 ... mountain rd. 7 ... ... ...
19 03/14/2015 03:41 mountain rd. 7 bedroom motion 75 tossing & turning
20 03/14/2015 05:00 mountain rd. 7 bedroom motion 74 tossing & turning
21 03/14/2015 08:52 mountain rd. 7 bedroom motion 75 getting up
22 03/14/2015 09:30 mountain rd. 7 living room motion 74 living room motion
... 03/14/2015 ... mountain rd. 7 ... ... ...
23 03/15/2015 02:11 mountain rd. 7 bedroom motion 77 tossing & turning
24 03/15/2015 02:34 mountain rd. 7 bedroom motion 76 tossing & turning
25 03/15/2015 08:35 mountain rd. 7 bedroom motion 79 getting up
26 03/15/2015 08:57 mountain rd. 7 living room motion 77 living room motion
... 03/15/2015 ... mountain rd. 7 ... ... ...process mining tak es its roots in the ﬁeld of busi-
ness process management, where the deﬁnition of
labels for events is considered to be rather straight-
forward. in recent years, the application domain of
process mining has broadened. a wide variety of
event types can be used as input and analysis may be
challenging. one of the most challenging application
areas islifelo gging , which focuses on acquisition
and analysis of personal daily life data. lifelogs
amongst others combine data collected through mo-
bile phones, wearable devices, and/or smart home
sensors. the emergence of lifelogging tools and the
resulting increase in availability of activity data en-
able a process-centric analysis of human behavior14.
the aim of process mining analysis on lifelogging
data is to ﬁnd frequent activity patterns and represent
them in a human interpretable process model. such
a process model could then also be used to detect de-
viations from one’ s regular behavior. process mining
in the human behavior application domain closely
relates to the ﬁeld of activity recognition, which aims to detect human activities from sensors and ﬁnding patterns
between human activities2. process mining, however, aims to produce interpretable models that can provide insights
by visually inspecting them. in contrast, most activity recognition techniques produce non-interpretable models.
imagine an elderly person of whom we want to discover a process model describing his /her daily behavior . events
are generated by sensors, either periodically (e.g. by a temperature sensor or heart rate monitor), or triggered by some
activity (e.g. motion). table 1 shows an example log obtained by fusing data from such sensors. the dots indicate that
only a fraction of the logged events are shown. assigning meaningful labels to these events is not straightforward. a
bedroom motion event can be caused by di ﬀerent human activities, e.g. bytossing&turning or by getting up. in some
cases it is necessary to distinguish between tossing&turning and getting up, for example when we aim to generate
a timely reminder to take medication that needs to be taken before breakfast. based on contextual information (e.g. a
speciﬁc increase in heart rate, a time stamp, etc.), the distinction between the two types of activities might be identiﬁed,
and each event with label bedroom motion canbe reﬁned into either tossing&turning orgetting up. the last column
in table 1 shows the desired event labels. figure 1 shows a process model that can be deduced from such a log using
existing process discovery techniques, like the ones from17,21.
many relabelings of bedroom motion events are possible. expert knowledge, data mining or machine learning tech-
niques can be used to generate ideas for potential labeling functions. the goal of this labeling function is to give “similar”
events the same label. however, similarity is a relative notion, so the initially chosen labeling function can be too
abstract or too ﬁne-grained to generate an informative process model . once a process discovery algorithm has been ap-
plied and a process model is obtained, one can assess whether the labeling function used on the original event log allowed
the process disco very algorithm to discover an informative process model. however, it is computationally costly to apply
process mining algorithms to multiple event logs generated from a single original event log using di ﬀerent event labeling
functions with varying levels of abstraction. therefore, we provide a statistical approach to evaluate label reﬁnement use-
fulness in the context of process discovery that is based on signiﬁcance testing of di ﬀerences in event ordering relations.65  niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
thefodina20and theα∗7process disco very algorithms assume that there is one column in the event log that indicates
the activity and reﬁne this label based on a threshold of di ﬀerentness on the event labels occurring directly before and
after. in this paper we assume that the information what activity is performed is spread over multiple columns. we
choose one column as primary activity column and reﬁne the activity labels based on the other columns and temporal in-
formation. we validate whether a reﬁnement makes sense from a process perspective by taking into account all temporal
event information in the event log, using statistical testing and information gain. evaluating splits based on informationgain is a well-known approach in the area of decision tree learning
11, where ground truth labels are available in contrast
to the label reﬁnement setting. label reﬁnements draw similarities with automatic learning of ontologies8in the sense
that both are concerned with inferring multiple levels of semantic interpretations from data. ontology quality evaluation
techniques1canbe used to evaluate (automatically inferred) ontologies, however these techniques are not process-
centric, i.e., the y do not take into account ordering relations between elements of the ontology in execution sequences.
section 2 gives formal deﬁnitions of label reﬁnements, process models, and related concepts. in section 3, we
discuss when a label reﬁnement is useful from a process mining perspective. a statistical method to evaluate the
usefulness of a label reﬁnement is described in section 4. in section 5 we discuss the results of the proposed method
on a real life smart home data set. we draw conclusions in section 6.
2. label reﬁnements & process models
in this section we introduce the notions related to event logs and relabeling functions for traces and then deﬁne the
notions of reﬁnements and abstractions. we also introduce the petri net process model notation.
we use the usual sequence deﬁnition, and denote a sequence by listing its elements, e.g. we write /angbracketlefta1,a2,..., an/angbracketrightfor
a (ﬁnite) sequence s:{1,..., n}→ aof elements from some alphabet a, where s(i)=aiforany i∈{1,..., n}. the
length of a sequence s:{1,..., n}→ ais|s|=n;s1s2denotes the concatenation of sequences s1and s2.a langua gel
over an alphabet ais a set of sequences over a.lpis the preﬁx closure of a language l(with l⊆lp).
an event is the most elementary element of an event log. let ibe a set of event identiﬁers, tbe a set of timestamps,
anda1×···×a nbe an attribute domain consisting of nattributes (e.g. resource, activity name, cost, etc.), each of a
certain type. an event is a tuple e=(i,t,a1,..., an), with i∈i,t∈t, and ( a1,..., an)∈a 1×···×a n. the event label
of an event is the attribute set ( a1..., an);ei,etand earespecti vely denote the identiﬁer, the timestamp and label of event
e.e=i×t×a 1×···×a nis a universe of events over a1,...,an. the lines of table 1, where we do not consider
theactivity column for now, are events from an event universe over the event attributes sensor ,address , and heart rate.
events are often considered in the context of other events. we call e⊆eanevent set ,i fedoes not contain any events
with the same event identiﬁer. the events in table 1 together form an event set. a traceσis a ﬁnite sequence formed
by the events from an event set e⊆ethat respects the time ordering of events, i.e. for all k,m∈n,1≤k<m≤|e|,
we have:σ(k)t≤σ(m)t. we deﬁne the univer se of traces over event universe e, denotedς(e), as the set of all possible
traces overe. we omiteinς(e) and use the shorter notation σwhen the event universe is clear from the context.
often it is useful to partition an event set into smaller sets in which events belong together according to some
criterion. we might for example be interested in discovering the typical behavior of households over the course of a
day. in order to do so, we can e.g. group together events with the same address and the same day-part of the timestamp ,
as indicated by the horizontal lines in table 1. for each of these event sets, we can construct a trace; time stamps deﬁne
the ordering of events within the trace. for events of a trace having the same time stamps, an arbitrary ordering can be
chosen within a trace.
anevent partitioning function is a function ep:e→ tidthat deﬁnes the partitioning of an arbitrary set of events
e⊆efrom a given event universe eintoevent sets e1,..., ej,...where each ejis the maximal subset of esuch that
forany e1,e2∈ej,ep(e1)=ep(e2); the value of epshared by all the elements of ejdeﬁnes the value of the trace
attribute tid. note that complex, multidimensional trace attributes are also possible, i.e. a combination of the name of
the person performing the event activity and the date of the event, so that every trace contains activities of one person
during one day . the event sets obtained by applying an event partitioning can be transformed into traces (respecting the
time ordering of events).
an event log lis a ﬁnite set of traces l⊆σ(e).al⊆a 1×···×a ndenotes the alphabet of event labels that occur
in log l. the traces of a log are often transformed before doing further analysis: very detailed but not necessarily
informati ve event descriptions are transformed into some informative and repeatable labels. for the labels of the log in66   niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
table 1, the heart rate values can be abstracted to low, normal , and high or the label can be redeﬁned to a subset of the
event attributes. next to that, if the event partitioning function maps each event from table 1 to its address and the
day-part of the timestamp, these attributes (indicated in gray) become the trace attribute and can safely be removed
from individual events. the new label is then deﬁned as a combination of the sensor and abstracted heart rate values.
after this relabeling step, some traces of the log can become identically labeled (the event id’s would still be
diﬀerent). the information about the number of occurrences of a sequence of labels in an event log is highly relevant
for process mining, since it allows diﬀerentiating between the main stream behavior of a process (frequently occurring
behavioral patterns) and exceptional behavior.
letς(e) andς/prime(e/prime) be two universes of traces deﬁned over event universes e,e/prime. a function l:ς→σ/primeis a trace
relabeling function if for all tracesσ,γ∈σsuch that ifσis a preﬁx ofγ,l(σ) is a preﬁx of or equal to l(γ). we lift lto
event logs: for l⊆σ, the relabeling l(l) is deﬁned as{l(σ)|σ∈l}.
often, relabeling functions are deﬁned using a more narrow approach: ﬁrst deﬁning an event relabeling function and
then lifting that function to traces. in the context of business processes, event relabeling functions are mostly mere pro-
jections of events on the values of a single attribute, such as activity name . we consider a more general deﬁnition to allow
for history-dependent interpretation of events, which is necessary in the context of lifelogging. preﬁx preservation
requirement is necessary to allow for logging, compliance checking and other forms of analysis performed at run time.
letς,σ1, andς2be trace universes over e,e1,e2respecti vely withe,e1,e2being pairwise diﬀerent. let
l1:σ→σ1and l2:σ→σ2be trace relabeling functions. relabeling function l1is a reﬁnement of relabeling function
l2, denoted by l1/precedesequall2,iﬀ∀σ1,σ2∈σ:l1(σ1)=l1(σ2)=⇒ l2(σ1)=l2(σ2);l2is then called an abstraction ofl1. we call
a reﬁnement l1ofl2astrict reﬁnement, denoted byl1≺l2, when∃σ1,σ2∈σ:l1(σ1)/nequall1(σ2)∧l2(σ1)=l2(σ2). we call
reﬁnement l1ofl2anequal length reﬁnement, denoted byl1/precedesequal=l2,when∀σ∈σ:|l1(σ)|=|l2(σ)|.
letς,σ1be trace universes over e,e1respecti vely, l:ς→σ1a trace relabeling function, and l1be a language
l1⊆σ1overe1.trace concretization l−1:σ1→2σis a function deﬁned as l−1(σ1)={σ∈σ|l(σ)=σ1}, for each
σ1∈σ1.langua ge concretization ofl1is language l−1(l1)=∪σ1∈l1l−1(σ/prime).
the goal of process discovery is to discover a process model that represents the behavior seen in an event log. a
frequently used process modeling notation in the process mining ﬁeld is the petri net12. petri nets are directed bipartite
graphs consisting of transitions and places, connected by arcs. transitions represent activities, while places represent
the enabling conditions of transitions. labels are assigned to transitions to indicate the type of activity that they model.
a special labelτis used to represent invisible transitions, which are only used for routing purposes and not recorded in
theexecution log.
alabeled petri net n=/angbracketleftp,t,f,am,/lscript/angbracketrightis a tuple where pis a ﬁnite set of places, tis a ﬁnite set of transitions such
that p∩t=∅,f⊆(p×t)∪(t×p) is a set of directed arcs, called the ﬂow relation, amis an alphabet of labels
representing activities, with τ/nelementambeing a label representing invisible events, and /lscript:t→am∪{τ}is a labeling
function that assigns a label to each transition. for a node n∈(p∪t)w eu s e•nand n•to denote the set of input and
output nodes ofn, deﬁned as•n={n/prime|(n/prime,n)∈f}and n•={n|(n,n/prime)∈f}. an example of a petri net can be seen in
figure 1, where circles represent places and squares represent transitions.
a state of a petri net is deﬁned by its marking m∈npbeing a multiset of places. a marking is graphically
denoted by putting m(p) tokens on each place p∈p. a pair ( n,m) is called a marked petri net. state changes
occur through transition ﬁrings. a transition tis enabled (can ﬁre) in a given marking mif each input place
p∈•tcontains at least one token. once a transition ﬁres, one token is removed from each input place of tand
one tok en is added to each output place of t, leading to a new marking m/primedeﬁned asm/prime=m−•t+t•.a
ﬁring of a transition tleading from marking mto marking m/primeis denoted as m/lscript(t)−→ m/prime.m1/lscript(σ)−→ m2indicates
that m2canbe reached from m1through a ﬁring sequence σ/prime∈am∗. many process modeling notations have
formal executional semantics and deﬁne a langua ge of accepting traces l. for petri net n2in figure 2, l(n2)=
{/angbracketleftbedroom motion,livingroom motion /angbracketright,/angbracketleftbedroom motion,bedroom motion,livingroom motion /angbracketright,/angbracketleftbedroom motion,
..., bedroom motion,livingroom motion /angbracketright}.
3. on the quality of label reﬁnements for process mining
process discovery algorithms disco ver a process model based on an event log, where event labels are obtained by
applying an event relabeling function to an original log. the main quality metrics discovered process models are ﬁtness,67  niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
p1t ossing
&turning
in bed
t1getting
out of
bed
t2p2living
room
motion
t3p3
(a) petri net n1p1bedroom
motion
t1living
room
motion
t2p2
(b) petri net n2
fig.2: petri nets discovered from two event logs obtained from the same event set with di ﬀerent relabeling functions.
precision, generalization and simplicity15.fitness represents the share of the behavior seen in the log that is allowed by
the process model. precision aims at narrowing the set of traces that belong to the language of the discovered process
model, but was not observed in the event log. generalization aims at preventing overﬁtting, and simplicity measures
the “understandability” and “well-structuredness” of models.
event set e
event log ltrace attribute
event log l1=l1(l)relabeling function l1
event log l2=l2(l)relabeling function l2
l1/precedesequall2
process model n1process disco very
process model n2process disco very
language l1generates
language l2generates
language l−1
1(l1)language
concretizationfitness
language l−1
2(l2)language
concretization
⊇fitness
fig.3: comparing two event relabeling functionsintuiti vely, an event relabeling function is better than another one
if it improves the quality of the discovered model along these quality
dimensions. however, the quality metrics are currently deﬁned in
such a way that only results of discovery algorithms applied to
thevery same log can be compared, while two di ﬀerent relabeling
functions produce logs with diﬀerent event labels. the petri net n1
in figure 2 has perfect precision and ﬁtness for the event log with
labels as shown in the reﬁned label column of table 1. at the same
time, petri net n2has perfect ﬁtness and precision for the event log
with labels as in the sensor column of table 1. however, petri net
n1is useful for the purpose of sending a reminder message to take
medicines after getting up, while petri net n2is not. this suggests
that petri net n1is more precise than n2, but only with respect to
the original log. thus we have to make the comparison in the context of the original log. suppose we have a set
of events e, which is part of some universe of events e. we choose a case identiﬁer and build an event log lfrom
e. then we choose relabeling functions l1and l2with l1≺l2and obtain l1=l1(l) and l2=l2(l) (see figure 3).
applying process disco very to l1and l2results in two process models, which respectively accept languages l1andl2.
these languages cannot be compared directly, since they contain traces consisting of di ﬀerent event labels. precision
metrics look at “redundant” traces in the mined models with respect to the log used as input for the discovery algorithm
(see e.g.10,13). using the inverse functions l−1
1,l−1
2, every trace of l1andl2canbe mapped to a set of traces built
from the events frome. taking the union of the sets obtained with l−1
1,l−1
2over the traces of the languages, we obtain
comparable languages and can conclude whether the relabeling function results in a model that is more precise with
respect to the original log.
fitness and simplicity of the models depend mostly on the performance of the process discovery algorithm, and
noton the choice of the relabeling function. precision deﬁned in terms of events of the original universe eof events
is however highly dependent on the appropriateness of the relabeling function: choosing a more reﬁned relabeling
function can increase the precision by eliminating the behavior that would be allowed in the model discovered with a
more abstract relabeling function. generalization can potentially suﬀer as the result of a higher precision.
3.1. label reﬁnement quality
the comparison of the languages generated by models is not feasible due to its complexity; for many classes of
process models, including petri nets, the problem of language inclusion is just not decidable. therefore, we need a
diﬀerent, practical approach to deciding on the usefulness of a relabeling function reﬁnement. we start with discussing
the usefulness by comparing the discovered models.
consider event log l, relabeling functions l1,l2,l3such that l2≺l1∧l3≺l1, and event logs l1=l1(l),l2=
l2(l),l3=l3(l). let the n1,n2,n3in figure 4 be the petri nets obtained by applying process discovery to l1,l2,l3
respecti vely. the square inside the transition between places p3and p4indicates that it is a subprocess.
we can see that reﬁnement l2does not lead to a meaningful interpretation of basb1and b2, since the behavior of the
model is not related to the choice between b1and b2: transitions labeled with b1and b2have the same input and output
places. reﬁnement l2does not provide new insight and unnecessarily harms the understandability of the petri net by cre-68   niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
p1n1
a p2b p3/square
p4d
ep5p1n2
a p2b1
b2p3/square
p4d
ep5p1n3
a p2b1
b2p3/square
p4d
ep5p6
p7
fig.4:n2is a non-useful reﬁnement and n3is a useful reﬁnement of n1.
table 2: log-based ordering relations and their use by process discovery algorithms
ordering relation miners using the relation
direct successor aminer17,a++miner22, multi-phase miner18, heuristics miner21
length-tw o loop a++miner22, multi-phase miner18, heuristics miner21
direct/indirect successor a++miner22, heuristics miner21table 3: a log statistic in contingency table form
a1 a2 a
+#+
l2,s(a1,b)#+
l2,s(a2,b)#+
l1,s(a,b)
−#−
l2,s(a1,b)#−
l2,s(a2,b)#−
l1,s(a,b)
ating more transitions then needed. on the other hand, l3results in gain of precision, as l(n3), does not contain/angbracketlefta,b1,e/angbracketright
and/angbracketlefta,b2,d/angbracketright, while n1does not distinguish between b1and b2, which suggests that both types of traces are possible.
4. evaluation method for label reﬁnements for process models
in the previous section we showed that we can compare the usefulness of a label reﬁnement by inspecting the petri
net obtained with process disco very. a naive way to evaluate label reﬁnement would be to apply process discovery
to all possible label reﬁnements. the number of possible label reﬁnements to consider can however be large and
process disco very is a computationally expensive task. therefore, this naive approach quickly becomes computationally
infeasible. we now present a way to estimate the usefulness of a label reﬁnement based on statistics and log relations.
algorithm 1 shows the steps of the label reﬁnements evaluation method. the evaluation method consists of an
entropy-based component that measures whether a label reﬁnement makes the log statistics more unbalanced, and a
statistical test that tests whether there is a label statistic that tests whether the label reﬁnement makes a statistically
signiﬁcant diﬀerence to at least one of the log statistics. in the following two sections we described the entropy-based
measure and the statistical testing respecti vely.
4.1. log statistics
event ordering patterns are crucial to most process discovery algorithms. table 2 provides an overview of well-
known log-based ordering relations described in process discovery literature17,18,22,21and provides examples. let lbe
an event log. let b,c∈al. formal deﬁnitions of these log-based ordering statistics are as follows:
•#+
l,>(b,c) is the number of occurrences of bin the traces of lthat are directly followed byc, i.e. in some
σ∈l,i∈{1,...,|σ|}we have [σ(i)]a=band [σ(i+1)] a=c(direct successor ), #−
l,>(b,c) is the number of
occurrences ofbwhich are not directly followed byc;
•#+
l,>>(b,c) and #−
l,>>(b,c) is the number of occurrences of bthat are, respecti vely, are not, followed by c: for a
traceσ∈land i∈{1,...,|σ|}, and [σ(i)]a=[σ(i+2)] a=band [σ(i+1)] a=cand b/nequalc(length-tw o loops);
•#+
l,>>>(b,c) and #−
l,>>>(b,c) is the number of occurrences of bthat are , respectively are not, eventually followed
byc: for a traceσ∈l,i,j∈nwith i<j,[σ(i)]a=band [σ(j)]a=c(direct or indirect successor).
in the general sense, let #+
l,s(b,c) and #−
l,s(b,c) be the count of the number of b’s that do, respectively do not, satisfy
relation sin log lwith respect toc.
let lbe an event log. let l1and l2be two relabeling functions that are to be compared, such that l2≺=l1. let
l1=l1(l) and l2=l2(l). let l1and l2have the property{a1,a2∈al2)|∃σ1,σ2∈l:l1(σ1)=λa∧l1(σ2)=λ/primea∧l2(σ1)=
ζa1∧l2(σ2)=ζ/primea2}/nequal∅, that is, l2reﬁnes activity ainto distinct activities a1and a2. the diﬀerence in control ﬂow
between a1and a2canbe expressed as the dissimilarity in log-based ordering statistics between event label a1and
b∈al2\{a1,a2}on the one hand, and a2and bon the other hand. each log-based ordering statistics of a1and a2with
regard to any other activity bcanbe formulated in the form of a contingency table, as shown in table 3.69  niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
table 4: contingency tables for comparing the behavior of the two reﬁned labels
directly follo ws
tossing
&
turn-inggetting
upbed-
roommotion
+→ 00 0
−→ 16 5 21directly precedes
tossing
&
turn-inggetting
upbed-
roommotion
+→ 05 5
−→ 16 0 16eventually follows
tossing
&
turn-inggetting
upbed-
roommotion
+→ 00 0
−→ 16 5 21eventually precedes
tossing
&
turn-inggetting
upbed-
roommotion
+→ 16 5 21
−→ 00 0
4.2. information gain
the binary entrop y function, hb(p)=−plog2p−(1−p)log2(1−p), where 0 log20=0, is a measure of uncertainty.
applied on a log statistic, the binary entropy function represents a degree of nondeterminism. nondeterministic,
unbalanced, log statistics are a helpful to process discovery algorithms that operate of log statistics, as it provides low
uncertainty to the mining algorithm. low entropy in the log statistics indicate high predictability of the process, making
it easier for process discovery algorithms to return a sensible process model.
consider the contingenc y tables in table 4, based on log statistics obtained from table 1 between the events labeled
tossing &turning and getting upand the events labeled living room motion . on the right hand side of the table,
separated by the bar, are the log statistics of the before-split label in the before-split log. all ﬁve events with label
getting updirectly precede an event with label living room motion , while all sixteen events with label tossing &
turning arenotdirectly preceded byliving room motion . furthermore, all events with reﬁned labels do notdirectly or
eventually follow an event with label living room motion , and all events with reﬁned labels do eventually precede an
event with label living room motion .
log statistics with a high degree of non-determinism, like the directly precedes statistic of the bedroom motion events
before the split, might confuse a mining algorithm as there is no clear structure here: the bedroom motion event might
directly precede livingroom motion , but most of the time it does not. after the split we see a completely deterministic
directly precedes statistic, where tossing&turning never and getting upalways directly precedes livingroom motion .
this increased determinism is reﬂected by the entropy of the directly precedes statistic before and after the split. before
the split we have−5
5+16log25
5+16−16
5+16log216
5+16=0.7919 bit of entropy in the directly precedes statistic, compared to
−0
0+16log20
0+16−16
0+16log216
0+16=0 bit of entropy for tossing&turning and−0
0+5log20
0+5−5
0+5log25
0+5=0 bit of
entrop y for getting up. the conditional entropy of the log statistic after the split is the weighted average of the entropy
of the labels created in the split, which is −16
210×5
210=0. the information gain of this label split with regard to the
directly precedes livingroom motion statistic is equal to the total entropy of the log statistic prior to the split, minus
the conditional entrop y after the split, this 0 .7919−0=0.7919. relati ve information gain6is a metric that provides
insight in the ratio of bits of entropy reduced by a reﬁnement, and can be calculated by dividing the information gain by
the before-split entrop y. the relative information gain of the directly precedes livingroom motion statistic is0.7919
0.7919=1.
figure 2 shows the eﬀectof this label reﬁnement on the resulting petri net obtained by process discovery.
so far we have calculated the relative information gain for a single log statistic. a label reﬁnement however can
have impact on multiple log statistics at once. we need a measure that integrates the information gain values of all log
statistics to express the quality of a label reﬁnement with respect to the determinism of the log statistics. we therefore
sum over the entropy of all log statistics before the label split to obtain the total before-split entropy. we sum over the
conditional entropies of all log statistics after the label split to obtain the total after-split entropy. information gain
and relati ve information gain are calculated as before. we let relative in f ormation gain(l1,l2) be the function that
returns the relati ve information gain based on the pre-split log l1and post-split log l2, where the set of reﬁned label
pairs inl2from which the log statistics are used corresponds to{a1,a2∈al2|∃σ1,σ2∈l:l1(σ1)=λa∧l1(σ2)=λ/primea∧,
with the athe corresponding label inl1.
4.3. statistical testing
relati ve information gain can be high by chance for a reﬁnement when the generated reﬁned labels are infrequent.
statistical testing of log statistic diﬀerences in addition to calculating relative information gain enables us to distinguish70   niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
algorithm 1 algorithm of the label reﬁnement statistical evaluation method
input: event log l, relabeling functions l1and l2such that l2≺=l1,
output: the relative information gain of l1w.r.t l2,
parameters: set of log-based ordering statistics s,
significance level α.
allsignificant different = true; l1=l1(l);l2=l2(l);
split set ={a1,a2∈a(l2)|∃σ1,σ2∈l:l1(σ1)=λa∧l1(σ2)=λ/primea∧l2(σ1)=ζa1∧l2(σ2)=ζ/primea2};
for each a1,a2∈split set:
pair signi f icant di f f erent = false;
for each{b∈a(l2)\{a1,a2}}:
for each s∈s:
p= f isher test(#+
l2,s(a1,b),#−
l2,s(a1,b),#+
l2,s(a2,b),#−
l2,s(a2,b));
if( p<α) pair significant different = true;
if(! pair signi f icant di f f erent )
allsigni f icant di f f erent = false;
if( allsigni f icant di f f erent )
return relative in f ormation gain(l1,l2);
else return 0.0;
between information gain obtained by chance and actual information gain. fisher’s exact test5is a statistical signiﬁcance
test for the analysis of contingency tables. when applied to the table above, it calculates a p-value for the null hypothesis
that a1and a2events are equally likely to hold log relation swith regard to label b. fisher’s exact test assumes individual
observations to be independent and row and column totals to be ﬁxed. independence of individual observations might
be aﬀected by the grouping of events in traces. in this paper we consider individual observations independence to be
working assumption. the test was designed for experiments where both the row and column totals where conditioned.
in our setting, the column totals are conditioned by the relabeling function, as the number of events of each label
depends on the relabeling. the row totals however, are not conditioned and are an observation. fisher’s exact test is not
strictly speaking exact when one or both of the row or column totals are unconditioned, but will instead be slightly
conservati ve9, meaning that the probability of the p-value being less than or equal to the signiﬁcance level when the
nullhypothesis is true is less than the signiﬁcance level. fisher’s exact test is computationally expensive for large
numbers of observations. for large sample sizes, either the χ2testof independence or the g-test of independence can
be used, which are both found to be inaccurate for small sample sizes. a popular guideline is to not use the χ2testof
independence or the g-test for samples sizes less than one thousand9. the computational complexity of the evaluation
procedure iso(|s|×| a(l)|×| split set|). many process discovery algorithms are exponential in the number of labels16.
based on this we can conclude that statistical evaluation of label reﬁnements is computationally less expensive than
checking label reﬁnement usefulness through process disco very.
4.4. correcting for multiple testing
the computational complexity indicates the number of hypothesis tests performed. when a large set of potential
label reﬁnements is evaluated, the evaluation method described is susceptible to the repeated testing problem. the
larger the set of hypotheses tested, the higher the probability of incorrectly rejecting the null hypothesis in at least
oneof the hypothesis tests. applying a bonferroni correction3,4to the hypothesis tests performed in the statistical
evaluation method of label reﬁnements keeps the familywise error rate constant.
4.5. example case
consider the event log in table 1 and imagine a scenario where a home care worker knows from experience that
the elderly always sets his alarm clock at 8:30 am. based on such expert knowledge we are able to deﬁne a label
reﬁnement such that all bedroom movements after 8:30 am are considered as getting upevents, while all other
bedroom movements are considered to be tossing&turning events. the rightmost column shows the reﬁned labels
obtained through this expert relabeling function. to evaluate the usefulness of this label reﬁnement from a process
model point of view, we apply the statistical evaluation method described in section 4. as parameters we set the
signiﬁcance level threshold to the frequently used value of 0 .01.71  niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
table 5: results of the statisti-
cal tests for the evaluation of
label reﬁnement usefulness
log statistic p-value
directly follows 1
directly precedes 4.91×10−5
eventually follows 1
eventually precedes 1table 5 shows the outcome of the statistical tests performed as part of the label reﬁne-
ment usefulness evaluation. four hypothesis tests have been performed, after bonferroni
correction each hypothesis test is tested at signiﬁcance level0.01
4=0.0025. the direct
following statistic of tossing&turning and getting up with living room motion is sta-
tistically signiﬁcantly given this signiﬁcance level. the label reﬁnement constructed with
expert knowledge is found to be a useful label reﬁnement through statistical evaluation.
5. real life evaluation
we apply our label reﬁnement evaluation method to a set of candidate label reﬁnements on the van kasteren smart
home environment data set19in order to illustrate the e ﬀects of label splits in the context of process mining of real
life processes. the van kasteren data set consists of 1285 events divided over fourteen di ﬀerent sensors. events are
segmented in days from midnight to midnight, to deﬁne cases in the event log. the candidate set of label reﬁnements
consists of splitting each of the fourteen event types tinto two event types based on the their time in the day, such that t
events where the time since the start of the day is smaller than the median for tare separated from tevents where it is
equal to or larger than the median. figure 5 shows the dependency graph obtained with the heuristics miner21.a
dependency graph depicts causal relations between activities that meet a certainty threshold. a dependency graph can
be directly converted into a petri net21, however, for the sake of readability we included the dependency graphs instead
of the petri nets. the precision10of the petri net corresponding to figure 5 is 0.56 on a scale from 0 to 1.
out of the fourteen candidate label reﬁnements, two label reﬁnements are selected by our approach. the ﬁrst label
reﬁnement found is the split of hall-bathroom door into hall-bathroom door 1and hall-bathroom door 2, with a times-
tamp below, respectively above or equal to the median time in the day of hall-bathroom door events. the resulting labels
of this reﬁnement are statistically signiﬁcantly di ﬀerent in terms of their eventually follows relation with front door
(p-value: 3.06×10−26) and their eventually follows relation with plates cupboard (p-value: 3.66×10−23) and microwave
1.85×1024. the relative information gain on the whole event log caused by this label reﬁnement is 3.47%. figure 6
shows a heuristics net mined with the heuristics miner21on the van kasteren log with the reﬁned hall-bathroom door
label. the model discovered on the log with this label reﬁnement (figure 6) has a precision of 0.69, up from 0.53 without
the reﬁnement. the increased precision shows that the label reﬁnement helps restricting the share of behavior allowed
fig. 5: heuristics net showing original van kasteren data set
fig. 6: heuristics net showing the label reﬁnement on hall-bathroom door on the van kasteren data set
fig. 7: heuristics net showing the label reﬁnement on cups cupboard on the van kasteren data set72   niek tax et al.  /  procedia computer science   96  ( 2016 )  63 – 72 
by the model that is not covered by the event log. the second label reﬁnement found is the split of cups cupboard into
cups cupboard 1and cups cupboard 2. the resulting labels of this reﬁnement are statistically signiﬁcantly di ﬀerent in
terms of their eventually precedes relation with groceries cupboard (p-value: 2.53×10−34) and their eventually follows
relation with fridge (p-value: 2.2×10−22). the relative information gain on the whole event log caused by this label
reﬁnement is 0.53%. figure 7 shows a heuristics net mined with the heuristics miner on the van kasteren log with
the reﬁned cups cupboard label, of which the precision is 0.61, up to 0.53 without the reﬁnement. the label reﬁnement
with higher information gain also results in a higher improvement in terms of precision, which is in agreement with
the intuition that more deterministic log statistics help the miner in mining structured, non-ﬂower-like, models.
6. conclusion & future work
we have provided a theoretical and conceptual notion of when label reﬁnements and abstractions are useful from a
process disco very point of view. based on this notion of usefulness, we have shown a framework based on statistics
and information theory to evaluate the usefulness of a label reﬁnement or abstraction. in addition, we have shown
the applicability of this statistical framework through a real life smart home case, where our method selected two
label reﬁnements out of a larger candidate set that increased the precision of the resulting process model. methods
for automatic inference of useful label reﬁnements from event attributes are still to be explored. such methods may
generate a set of candidate label reﬁnements, after which the statistical evaluation method described in this paper can
be used to select the most promising label reﬁnement from a set of candidate label reﬁnements.
references
1.j. brank, m. grobelnik, and d. mladenic. a survey of ontology evaluation techniques. in proceedings of the conference on data mining and
data warehouses , pages 166–170, 2005.
2.l. chen, j. hoey, c. nugent, d. cook, and z. yu. sensor-based activity recognition. ieee transactions on systems, man and cybernetics
part c: applications and reviews , 42(6):790–808, 2012.
3. o. j. dunn. estimation of the medians for dependent variables. the annals of mathematical statistics , 30(1):192–197, 1959.
4. o. j. dunn. multiple comparisons among means. journal of the american statistical association , 56(293):52–64, 1961.
5. r. a. fisher. statistical methods for research workers . number 5. genesis publishing pvt ltd, 1934.
6. s. kullback and r. a. leibler. on information and su ﬃcienc y.the annals of mathematical statistics , 22(1):79–86, 1951.
7.j. li, d. liu, and b. yang. process mining: extending α-algorithm to mine duplicate tasks in process logs. in advances in web and network
technologies, and information management , volume 4537 of lncs , pages 396–407. springer berlin heidelberg, 2007.
8. a. maedche. ontolo gy learning for the semantic web , volume 665. springer science & business media, 2012.
9. j. h. mcdonald. handbook of biological statistics , volume 2. sparky house publishing baltimore, md, 2009.
10. j. mu ˜noz gama and j. carmona. a fresh look at precision in process conformance. in business process management , volume 6336 of lncs ,
pages 211–226. springer berlin heidelber g, 2010.
11. j. r. quinlan. c4. 5: programs for machine learning . elsevier, 2014.
12.w. reisig and g. rozenberg. lectur es on petri nets i: basic models: advances in petri nets , volume 1491. springer science & business
media, 1998.
13.a. rozinat and w. m. p. van der aalst. conformance checking of processes based on monitoring real behavior. information systems ,
33(1):64–95, 2008.
14. t. sztyler, j. v ¨olker, j. carmona, o. meier, and h. stuckenschmidt. discovery of personal processes from labeled sensor data–an application
of process mining to personalized health care. in proceedings of the international workshop on algorithms &theories for the analysis of
event data, ataed , pages 22–23, 2015.
15. w. m. p. van der aalst. process mining: discovery, conformance and enhancement of business processes . springer science & business media,
2011.
16.w. m. p. van der aalst. distributed process discovery and conformance checking. in fundamental approaches to software engineering ,
lncs, pages 1–25. springer , 2012.
17.w. m. p. van der aalst, a. j. m. m. weijters, and l. maruster. workﬂow mining: discovering process models from event logs. ieee
transactions on knowledge and data engineering , 16(9):1128–1142, 2004.
18.b. f. van dongen and w. m. p. van der aalst. multi-phase process mining: building instance graphs. in conceptual modeling–er 2004 ,
volume 3288 of lncs , pages 362–376. springer, 2004.
19.t. van kasteren, a. noulas, g. englebienne, and b. kr ¨ose. accurate activity recognition in a home setting. in proceedings of the 10th
international conference on ubiquitous computing , pages 1–9. acm, 2008.
20. s. k. vanden broucke. advanced in process mining: artiﬁcial negative events and other techniques . phd thesis, ku leuven, 2014.
21.a. j. m. m. weijters and j. t. s. ribeiro. flexible heuristics miner (fhm). in proceedings of the 2011 ieee symposium on computational
intelligence and data mining , pages 310–317. ieee, 2011.
22. l. wen, j. wang, and j. sun. detecting implicit dependencies between tasks from event logs. frontiers of www research and development-
apw eb 2006 , pages 591–603, 2006.