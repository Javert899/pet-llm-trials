preprint data & knowledge engineering 134 (2021) 101908
group-based
privacy preservation techniques for process mining
majid rafiei∗,wil m.p. van der aalst
chair of process and data science, rwth aachen university, aachen, germany
a
r t i c l e i n f o
keywords:
responsible
process mining
privacy preservation
result utility
data utility
event dataa b s t r a c t
process
mining techniques help to improve processes using event data. such data are widely
available in information systems. however, they often contain highly sensitive information.
for example, healthcare information systems record event data that can be utilized by process
mining techniques to improve the treatment process, reduce patient’s waiting times, improve
resource productivity, etc. however, the recorded event data include highly sensitive informa-
tion related to treatment activities. responsible process mining should provide insights about
the underlying processes, yet, at the same time, it should not reveal sensitive information. in
this paper, we discuss the challenges regarding directly applying existing well-known group-
based privacy preservation techniques, e.g., 𝑘-anonymity, 𝑙-diversity, etc, to event data. we
provide formal definitions of attack models and introduce an effective group-based privacy
preservation technique for process mining. our technique covers the main perspectives of process
mining including control-flow, time, case, and organizational perspectives. the proposed technique
provides interpretable and adjustable parameters to handle different privacy aspects. we employ
real-life event data and evaluate both data utility and result utility to show the effectiveness
of the privacy preservation technique. we also compare this approach with other group-based
approaches for privacy-preserving event data publishing.
1.
introduction
process mining employs event data to discover, analyze, and improve the real processes [1]. indeed, it provides fact-based insights
into the actual processes using event logs. there are many algorithms and techniques in the field of process mining. however, the
three basic types of process mining are (1) process discovery , where the goal is to learn real process models from event logs, (2)
conformance checking, where the aim is to find commonalities and discordances between a process model and an event log, and (3)
process re-engineering (enhancement ), where the aim is to extend or improve a process model using different aspects of the available
data.
an event log is a collection of events where each event is described by its attributes [1]. the typical attributes required for the
main process mining algorithms are case identifier, activity, timestamp, and resource. the case identifier refers to the entity that the
event belongs to, the activity refers to the activity associated with the event, the timestamp is the time that the event occurred, and
theresource is the activity performer. in the human-centered processes, case identifiers refer to persons. for example, in a patient
treatment process, the case identifiers refer to the patients whose data are recorded. moreover, the resource attribute often refers to
the persons performing activities, e.g., in the healthcare context, the resources refer to the doctors or nurses performing activities
for the patients. the event attributes are not limited to the above-mentioned ones, and an event may also carry other case-related
attributes, so-called case attributes, e.g., age,salary, disease, etc, which could be considered as sensitive person-specific information.
table 1 shows a sample event log.
∗corresponding
author.
e-mail address: majid.rafiei@pads.rwth-aachen.de (m. rafiei).
https://doi.org/10.1016/j.datak.2021.101908
received 30 november 2020; received in revised form 1 april 2021; accepted 25 may 2021
available online 7 june 2021
0169-023x/© 2021 the author(s). published by elsevier b.v. this is an open access article under the cc by license
(http://creativecommons.org/licenses/by/4.0/).m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 1. the general overview of privacy-related activities in process mining. privacy preservation techniques are applied to event logs to mitigate disclosure
risks. the data and result utility analyses are used to evaluate the effectiveness of the techniques where the goal is to balance utility loss and privacy gain.
orthogonal to the three mentioned types of process mining, different perspectives are also defined including control-flow ,
organizational ,case, and timeperspective [1]. the control-flow perspective focuses on activities and their order, which are often utilized
byprocess discovery and conformance checking techniques. the organizational perspective focuses on resources and their relations,
which are exploited by social network discovery techniques. the case perspective is focused on case-related attributes, and the time
perspective is concerned with the time-related information, which can be used for performance and bottleneck analyses .
with respect to the main attributes of events, two different perspectives for privacy in process mining can be considered in
the human-centered processes; resource perspective and case perspective . the resource perspective focuses on the privacy rights of the
individuals performing activities, and the case perspective concerns the privacy rights of the individuals whose data are recorded and
analyzed. depending on the context, the relative importance of these perspectives may differ. however, often the case perspective is
more critical for privacy than the resource perspective . for example, in the healthcare context, activity performers could be publicly
available. however, what happens for a specific patient and her/his personal information should be kept private. in this paper, we
are focused on the case perspective . in principle, when event logs explicitly or implicitly include personal data, privacy concerns appear
which should be taken into account according to regulations such as the european general data protection regulation (gdpr) [2].
in this paper, we describe disclosure risks andlinkage attacks against event logs. the attack models are formally defined based on
the available event attributes. we discuss the challenges regarding directly applying group-based privacy preservation techniques,
e.g.,𝑘-anonymity [3], 𝑙-diversity [4], etc, to event logs. we extend the work described in [5], where the 𝑇𝐿𝐾𝐶 -privacy is introduced
as an effective group-based privacy preservation technique for process mining. the 𝑇𝐿𝐾𝐶 -privacy exploits some restrictions
regarding the availability of background knowledge in the real world to deal with process mining-specific challenges. this technique
is focused on control-flow ,time, and caseperspectives. 𝑇𝐿𝐾𝐶 -privacy generalizes several traditional privacy preservation techniques,
such as𝑘-anonymity, confidence bounding [6], ( 𝛼,𝑘)-anonymity [7], and 𝑙-diversity.
the extended privacy preservation technique covers all the main perspectives of process mining including control-flow ,time,case,
andorganizational perspectives. it empowers the adjustability of the proposed technique by adding new parameters to adjust privacy
guarantees and the loss of accuracy. moreover, a new utility measure is defined to tackle the drawbacks of the current approach. to
evaluate the extended technique, we employ real-life event logs and evaluate both data utility andresult utility . we also compare the
extended𝑇𝐿𝐾𝐶 -privacy with the main algorithm and other group-based approaches for privacy-preserving event data publishing.
our experiments show that the proposed approach maintains high data and result utility, assuming realistic types of background
knowledge. fig. 1 shows a general overview of privacy-related activities in process mining which are discussed in this paper.
the rest of the paper is organized as follows. in section 2, we explain the motivation and challenges. section 3 provides
preliminaries on event logs and different types of background knowledge. in section 4, we provide formal models of the attacks.
privacy preservation techniques are discussed in section 5. in section 6, the experiments are presented. section 7 outlines related
work, and section 8 concludes the paper.
2m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 1
sample event log (each row represents an event).
case id activity timestamp resource age disease
1 registration (re) 01.01.2019-08:30:00 employee 4 (e4) 22 flu
1 visit (vi) 01.01.2019-08:45:00 doctor 3 (d3) 22 flu
2 registration (re) 01.01.2019-08:46:00 employee 1 (e1) 30 infection
3 registration (re) 01.01.2019-08:50:00 employee 1 (e1) 32 infection
4 registration (re) 01.01.2019-08:55:00 employee 4 (e4) 29 poisoning
1 release (rl) 01.01.2019-08:58:00 employee 6 (e6) 22 flu
5 registration (re) 01.01.2019-09:00:00 employee 1 (e1) 35 cancer
2 hospitalization (ho) 01.01.2019-09:01:00 employee 3 (e3) 30 infection
6 registration (re) 01.01.2019-09:05:00 employee 4 (e4) 35 corona
4 visit (vi) 01.01.2019-09:10:00 doctor 2 (d2) 29 poisoning
5 visit (vi) 01.01.2019-09:20:00 doctor 2 (d2) 35 cancer
4 infusion (in) 01.01.2019-09:30:00 nurse 2 (n2) 29 poisoning
5 hospitalization (ho) 01.01.2019-09:55:00 employee 6 (e6) 35 cancer
3 hospitalization (ho) 01.01.2019-10:00:00 employee 3 (e3) 32 infection
2 blood test (bt) 01.01.2019-10:02:00 nurse 1 (n1) 30 infection
5 blood test (bt) 01.01.2019-10:10:00 nurse 2 (n2) 35 cancer
3 blood test (bt) 01.01.2019-10:15:00 nurse 1 (n1) 32 infection
6 visit (vi) 01.01.2019-10:20:00 doctor 3 (d3) 35 corona
4 release (rl) 01.01.2019-10:30:00 employee 6 (e6) 29 poisoning
6 release (rl) 01.01.2019-14:20:00 employee 6 (e6) 35 corona
2 blood test (bt) 01.02.2019-08:00:00 nurse 1 (n1) 30 infection
2 visit (vi) 01.02.2019-09:30:00 doctor 1 (d1) 30 infection
3 visit (vi) 01.02.2019-13:55:00 doctor 1 (d1) 32 infection
2 release (rl) 01.02.2019-14:00:00 employee 2 (e2) 30 infection
3 release (rl) 01.02.2019-14:15:00 employee 2 (e2) 32 infection
5 release (rl) 01.02.2019-16:00:00 employee 2 (e2) 35 cancer
2. motivation and challenges
to motivate the necessity to deal with privacy issues in process mining, we describe the disclosure risks using an example in the
health-care context. consider table 1 as part of an event log recorded by an information system in a hospital. note that each case
has a sequence of events that are ordered based on the timestamps. this sequence of events is called a trace which is a mandatory
attribute for a case [1]. for example, case 1, which could be interpreted as patient 1, is first registered by employee 4, then visited
by doctor 3, and at the end released from the hospital by employee 6.
suppose that an adversary knows that a victim patient’s data are in the event log (as a case), with little information about some
event attributes that belongs to the patient, the adversary is able to connect the patient to the corresponding case id , so-called case
disclosure [8]. consequently, two types of sensitive person-specific information are revealed: (1) the complete sequence of events
belonging to the case, and (2) sensitive case attributes. (1) and (2) are generally called attribute disclosure . (1) is also called trace
disclosure that is a specific type of attribute disclosure [8]. for example, if the adversary knows that two blood tests were performed for
the victim patient, the only matching case is the case with id 2. this attack is called case linkage attack. after the case re-identification,
the sensitive case attributes are disclosed, e.g., the disease of patient 2 is infection . this is called attribute linkage attack. moreover, the
complete sequence of events performed for patient 2 is disclosed which contains private information, e.g., the complete sequence of
activities performed for the case, the resources who performed the activities for the case, or the exact timestamp of doing a specific
activity for the case. we call this attack trace linkage which is a specific type of attribute linkage attack.
note that the attribute linkage attack does not necessarily need to be launched after the case linkage , i.e., if more than one case
corresponds to the adversaries knowledge while all the matching cases have the same value for the sensitive case attribute(s) or
the same sequence of event attributes (e.g., the same sequence of activities), the attribute linkage /trace linkage could happen without
a successful case linkage attack. for example, if the adversary knows that the activity visit has been performed by the resource
doctor 3 for a victim patient, case 1 and case 6 match this background knowledge. however, they both have the same sequence
of activities and resources ( ⟨(𝑅𝐸,𝐸 4),(𝑉𝐼,𝐷 3),(𝑅𝐿,𝐸 6)⟩). consequently, the adversary realizes the complete sequence of activities
and the resources who performed the activities.
several group-based privacy preservation techniques, such as 𝑘-anonymity [3], 𝑙-diversity [4], and 𝑡-closeness [9], have been
introduced to deal with similar attacks in the context of relational databases. in such techniques, the data attributes are classified into
four main categories including; explicit identifiers ,quasi-identifiers ,sensitive attributes , and non-sensitive attributes . the explicit identifiers
are the attributes that can be used to uniquely identify the data owner, e.g., national id. the quasi-identifiers are a set of attributes
that could be exploited to uniquely identify the data owner, e.g., {𝑎𝑔𝑒,𝑔𝑒𝑛𝑑𝑒𝑟,𝑧𝑖𝑝𝑐𝑜𝑑𝑒 }. the sensitive attributes consist of sensitive
person-specific information, e.g., disease or salary, and the non-sensitive attributes contain all the attributes that do not fall into the
previous three categories [10]. assuming that explicit identifiers suppressed or replaced with dummy identifiers, the group-based
privacy preservation techniques aim to perturb potential linkages by generalizing the records into equivalence classes, i.e., groups
of records, having the same values on the quasi-identifier . these techniques are effective for anonymizing relational data. however,
they are not easily applicable to event data due to some specific properties of event data.
in process mining, the explicit identifiers (i.e., actual case identifiers) do not need to be stored and processed, and case identifiers
are often dummy identifiers, e.g., incremental ids. as described in the above-mentioned examples, a trace can be considered as a
3m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
quasi-identifier and, at the same time, as a sensitive attribute . in other words, a complete sequence of events belonging to a case, is
sensitive person-specific information, at the same time, part of a trace, i.e., only some of the event attributes, can be exploited as a
quasi-identifier to launch case linkage and/or attribute linkage attacks.
thequasi-identifier role of traces in process mining causes significant challenges for group-based privacy preservation techniques
because of two specific properties of event data: the high variability of traces and the typical pareto distribution of traces . considering
only activity as the main event attribute in a trace, the variability of traces in an event log is high because of the following reasons:
(1) there could be tens of different activities which could happen in any order, (2) one activity or a bunch of activities could happen
repetitively, and (3) traces could contain any non-zero number of activities, i.e., various lengths. note that this variability becomes
even higher when events contain more attributes, e.g., resources. in an event log, trace variants are often distributed similarly to
the pareto distribution, i.e., few trace variants are frequent and many trace variants are unique. enforcing group-based privacy-
preserving approaches on little-overlapping and high-dimensional space is a significant challenge, and often valuable data needs to
be suppressed in order to achieve desired privacy requirements [11].
3. preliminaries
in this section, we provide formal definitions for event logs and background knowledge. these formal models will be used in
the remainder for describing the attack scenarios and the approach.
3.1. event log
we first introduce some basic notations. for a given set 𝐴,𝐴∗is the set of all finite sequences over 𝐴, and (𝐴)is the set of all
multisets over the set 𝐴. for𝐴1,𝐴2∈(𝐴),𝐴1⊆𝐴2if for all𝑎∈𝐴,𝐴1(𝑎)≤𝐴2(𝑎). a finite sequence over 𝐴of length𝑛is a mapping
𝜎∈ {1,…,𝑛}→𝐴, represented as 𝜎=⟨𝑎1,𝑎2,…,𝑎𝑛⟩where𝑎𝑖=𝜎(𝑖)for any 1≤𝑖≤𝑛.|𝜎|denotes the length of the sequence. for
𝜎1,𝜎2∈𝐴∗,𝜎1⊑𝜎2if𝜎1is a subsequence of 𝜎2, e.g.,⟨𝑎,𝑏,𝑐,𝑥⟩⊑⟨𝑧,𝑥,𝑎,𝑏,𝑏,𝑐,𝑎,𝑏,𝑐,𝑥 ⟩. for𝜎∈𝐴∗,{𝑎∈𝜎}is the set of elements
in𝜎, and [𝑎∈𝜎]is the multiset of elements in 𝜎, e.g., [𝑎∈⟨𝑥,𝑦,𝑧,𝑥,𝑦 ⟩] = [𝑥2,𝑦2,𝑧]. for𝑥= (𝑎1,𝑎2,…,𝑎𝑛) ∈𝐴1×𝐴2×⋯×𝐴𝑛,
𝜋𝐴𝑖(𝑥) =𝑎𝑖is the projection of the tuple 𝑥on the element from the domain 𝐴𝑖,1≤𝑖≤𝑛.
definition 1 (process instance, trace ).we define =×∗×as the universe of all process instances. is the universe of case
identifiers. =××is the universe of main event attributes for process mining where is the universe of activities, is the
universe of resources, and is the universe of timestamps. ⊆1∪⋯∪𝑚is the universe of sensitive case attributes where 1,
.. .,𝑚are the universes of different case attributes, e.g., disease, salary, age, etc. given a process instance 𝑝= (𝑐,𝜎,𝑠 ) ∈,𝜎∈∗
is called the trace attribute of the case 𝑐.
definition 2 (event log ).let=×∗×be the universe of process instances. an event log is 𝐸𝐿⊆ such that if (𝑐1,𝜎1,𝑠1) ∈𝐸𝐿,
(𝑐2,𝜎2,𝑠2) ∈𝐸𝐿, and𝑐1=𝑐2, then𝜎1=𝜎2and𝑠1=𝑠2, i.e., all the case identifiers are unique. moreover, if 𝑝= (𝑐,𝜎,𝑠 ) ∈𝐸𝐿, then
𝜎≠⟨⟩.
definition 3 (perspective, projection ).let=×∗×be the universe of process instances. 𝑝𝑠∈ {,,×,×,×,××}
is a perspective which can be used to project traces of an event log 𝐸𝐿⊆ . for𝜎=⟨(𝑎1,𝑟1,𝑡1),…,(𝑎𝑛,𝑟𝑛,𝑡𝑛)⟩∈∗, such that there
exists (𝑐,𝜎,𝑠 ) ∈𝐸𝐿,𝜋𝑝𝑠(𝜎)is the projection of the trace on the given perspective, e.g., for 𝑝𝑠=×,𝜋𝑝𝑠(𝜎) =⟨(𝑎1,𝑟1),…,(𝑎𝑛,𝑟𝑛)⟩
is the projection of the trace on the activities and resources. we denote = {,,×,×,×,××}as the universe
of perspectives.
definition 4 (set of activities/resources in an event log ).let=×∗×be the universe of process instances, and 𝐸𝐿⊆ be
an event log. 𝐴𝐸𝐿= {𝑎∈∣ ∃(𝑐,𝜎,𝑠)∈𝐸𝐿𝑎∈𝜋(𝜎)}is the set of activities in the event log, and 𝑅𝐸𝐿= {𝑟∈∣ ∃(𝑐,𝜎,𝑠)∈𝐸𝐿𝑎∈𝜋(𝜎)}
is the set of resources in the event log.
definition 5 (set of traces/variants in an event log ).let=×∗×be the universe of process instances, 𝐸𝐿⊆ be an event log,
and𝑝𝑠∈be a perspective. 𝐸𝐿𝑝𝑠= [𝜋𝑝𝑠(𝜎) ∣ (𝑐,𝜎,𝑠 ) ∈𝐸𝐿]is the multiset of traces in the event log w.r.t. the given perspective.
̃𝐸𝐿𝑝𝑠= {𝜋𝑝𝑠(𝜎) ∣ (𝑐,𝜎,𝑠 ) ∈𝐸𝐿}is the set of variants, i.e., unique traces, w.r.t. the given perspective, e.g., ̃𝐸𝐿is the set of unique
traces w.r.t. the activities.
definition 6 (directly follows relations ).let𝐸𝐿⊆be an event log, 𝑝𝑠∈{,}be a perspective, ̃𝐸𝐿𝑝𝑠be the set of variants and
𝐸𝐿𝑝𝑠be the multiset of traces in the event log 𝐸𝐿w.r.t. the given perspective 𝑝𝑠.𝐷𝐹𝐸𝐿
𝑝𝑠={(𝑥,𝑦) ∈𝑝𝑠×𝑝𝑠∣𝑥 >𝐸𝐿
𝑝𝑠𝑦}is the set
of directly follows relations w.r.t. the given perspective. 𝑥 >𝐸𝐿
𝑝𝑠𝑦iff there exists a trace 𝜎∈̃𝐸𝐿𝑝𝑠and 1≤𝑖<|𝜎|, s.t.,𝜎(𝑖) =𝑥and
𝜎(𝑖+1) =𝑦.|𝑥>𝐸𝐿
𝑝𝑠𝑦|=∑
𝜎∈̃𝐸𝐿𝑝𝑠𝐸𝐿𝑝𝑠(𝜎)×|{1≤𝑖<|𝜎|∣𝜎(𝑖)=𝑥∧𝜎(𝑖+1)=𝑦}|is the number of times 𝑥is followed by 𝑦in𝐸𝐿.
definition 7 (variant frequency ).let=×∗×be the universe of process instances, and 𝐸𝐿 ⊆ be an event log. given a
perspective 𝑝𝑠∈,𝑓𝑟𝑒𝑞𝐸𝐿
𝑝𝑠∶̃𝐸𝐿𝑝𝑠→[0,1]is a function that retrieves the relative frequency of the variants in the event log w.r.t.
the given perspective. 𝑓𝑟𝑒𝑞𝐸𝐿
𝑝𝑠(𝜎) =𝐸𝐿𝑝𝑠(𝜎)∕|𝐸𝐿𝑝𝑠|and∑
𝜎∈̃𝐸𝐿𝑝𝑠𝑓𝑟𝑒𝑞𝐸𝐿
𝑝𝑠(𝜎) = 1.
table 2 shows the process instance representation of the event log shown in table 1, where timestamps are represented as
‘‘day-hour:minute". in this event log, disease is the attribute which is considered as the sensitive one.
4m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 2
the process instance representation of the event log table 1 (each row is a process instance
where timestamps are represented as ‘‘day-hour:minute’’).
case id simple trace disease
1 <(re,e4,01-08:30),(vi,d3,01-08:45),(rl,e6,01-08:58) > flu
2 <(re,e1,01-08:46),(ho,e3,01-09:01),(bt,n1,01-10:02),
(bt,n1,02-08:00),(vi,d1,02-09:30),(rl,e2,02-14:00) >hiv
3 <(re,e1,01-08:50),(ho,e3,01-10:00),(bt,n1,01-10:15),
(vi,d1,02-13:55),(rl,e2,02-14:15) >infection
4 <(re,e4,01-08:55),(vi,d2,01-09:10),(in,n2,01-09:30),
(rl,e6,01-10:30) >poisoning
5 <(re,e1,01-09:00),(vi,d2,01-09:20),(ho,e6,01-09:55),
(bt,n2,01-10:10),(rl,e2,02-16:00) >cancer
6 <(re,e4,01-09:05),(vi,d3,01-10:20),(rl,e6,01-14:20) > corona
fig. 2. categorizing background knowledge based on the type and event attributes as well as the corresponding perspectives, e.g., if 𝑡𝑦𝑝𝑒 =𝑟𝑒𝑙and𝑎𝑡𝑡=𝑎𝑟, the
corresponding perspective is 𝑝𝑠=××.
3.2. background knowledge
regarding the quasi-identifier role of traces, we consider four main types of background knowledge including set,multiset (mult),
sequence (seq), and relative time difference (rel). using setas the type of background knowledge, we assume that an adversary knows
a subset of some event attributes contained in the trace attribute of a victim case. in the multiset type of background knowledge, the
assumption is that an adversary knows a subset of some event attributes included in the trace attribute of a victim case as well as
the frequency of the elements. in the sequence type of background knowledge, we suppose that an adversary knows a subsequence
of some event attributes included in the trace attribute of a victim case.
the exact timestamps of events in an event log impose a high risk regarding the linkage attacks such that little time-related
knowledge may easily single out specific events, and consequently the case re-identification. for performance analysis in process
mining, we need to have the time-related information. however, the timestamps do not necessarily need to be the actual ones.
therefore, we make all the timestamps relative as defined in definition 8.
definition 8 (relative timestamps ).let𝜎=⟨(𝑎1,𝑡1),(𝑎2,𝑡2),…,(𝑎𝑛,𝑡𝑛)⟩be a trace including the time attribute, and 𝑡0be an initial
timestamp. 𝑟𝑒𝑙𝑎𝑡𝑖𝑣𝑒 (𝜎) =⟨(𝑎1,𝑡′
1),(𝑎2,𝑡′
2),…,(𝑎𝑛,𝑡′
𝑛)⟩is the trace with relative timestamps such that 𝑡′
1=𝑡0and for each 1< 𝑖≤𝑛,
𝑡′
𝑖=𝑡𝑖−𝑡1+𝑡0.
using relative timestamps does not eliminate time-based attacks, since the time differences are real and can be exploited by
an adversary. relative time difference type of background knowledge is an extension for the sequence type, where the assumption
is that an adversary knows a subsequence of some event attributes as well as the relative time differences between the elements.
fig. 2 shows the classification of background knowledge based on the types and event attributes. in the following, we provide
formal definitions for different categories of background knowledge based on the main event attributes, i.e., activity ,resource , and
timestamp . moreover, one can see that there is a relation between type,attribute , and perspective , i.e., a combination of type and
attribute can be mapped to a perspective. for example, if 𝑡𝑦𝑝𝑒 =𝑟𝑒𝑙and𝑎𝑡𝑡=𝑎𝑟, the corresponding perspective is 𝑝𝑠=××,
or if𝑡𝑦𝑝𝑒 ∈ {𝑠𝑒𝑡,𝑚𝑢𝑙𝑡,𝑠𝑒𝑞 }and𝑎𝑡𝑡=𝑟𝑒, the corresponding perspective is 𝑝𝑠=.
5m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 3. data collection and data publishing scenario.
definition 9 (background knowledge based on activities ).let𝐸𝐿be an event log, and 𝐴𝐸𝐿be the set of activities in the event log.
𝑏𝑘𝑠𝑒𝑡,𝑎𝑐(𝐸𝐿) = 2𝐴𝐸𝐿,𝑏𝑘𝑚𝑢𝑙𝑡,𝑎𝑐 (𝐸𝐿) =(𝐴𝐸𝐿), and𝑏𝑘𝑠𝑒𝑞,𝑎𝑐 (𝐸𝐿) =𝐴∗
𝐸𝐿are the sets of candidates of background knowledge based on the
activity attribute of the events for the set,multiset , and sequence types of background knowledge. for example, {𝑎,𝑏,𝑐 } ∈𝑏𝑘𝑠𝑒𝑡,𝑎𝑐(𝐸𝐿),
[𝑎2,𝑏] ∈𝑏𝑘𝑚𝑢𝑙𝑡,𝑎𝑐 (𝐸𝐿), and⟨𝑎,𝑏,𝑐⟩∈𝑏𝑘𝑠𝑒𝑞,𝑎𝑐 (𝐸𝐿).
definition 10 (background knowledge based on resources ).let𝐸𝐿be an event log, and 𝑅𝐸𝐿be the set of activities in the event
log.𝑏𝑘𝑠𝑒𝑡,𝑟𝑒(𝐸𝐿) = 2𝑅𝐸𝐿,𝑏𝑘𝑚𝑢𝑙𝑡,𝑟𝑒 (𝐸𝐿) =(𝑅𝐸𝐿), and𝑏𝑘𝑠𝑒𝑞,𝑟𝑒(𝐸𝐿) =𝑅∗
𝐸𝐿are the sets of candidates of background knowledge based
on the resource attribute of the events for the different types of background knowledge.
definition 11 (background knowledge based on activities&resources ).let𝐸𝐿be an event log, 𝐴𝐸𝐿be the set of activities in
the event log, and 𝑅𝐸𝐿be the set of resources in the event log. 𝑏𝑘𝑠𝑒𝑡,𝑎𝑟(𝐸𝐿) = 2𝐴𝐸𝐿×𝑅𝐸𝐿,𝑏𝑘𝑚𝑢𝑙𝑡,𝑎𝑟 (𝐸𝐿) =(𝐴𝐸𝐿×𝑅𝐸𝐿), and
𝑏𝑘𝑠𝑒𝑞,𝑎𝑟(𝐸𝐿) = (𝐴𝐸𝐿×𝑅𝐸𝐿)∗are the sets of candidates of background knowledge based on the activity and resource attribute of
the events for the various types of background knowledge.
definition 12 (background knowledge based on time differences between relative timestamps ).let𝐸𝐿be an event log, 𝐴𝐸𝐿be the
set of activities in the event log, 𝑅𝐸𝐿be the set of resources in the event log, and be the universe of (relative) timestamps.
𝑏𝑘𝑟𝑒𝑙,𝑎𝑐(𝐸𝐿) = (𝐴𝐸𝐿×)∗,𝑏𝑘𝑟𝑒𝑙,𝑟𝑒(𝐸𝐿) = (𝑅𝐸𝐿×)∗, and𝑏𝑘𝑟𝑒𝑙,𝑎𝑟(𝐸𝐿) = (𝐴𝐸𝐿×𝑅𝐸𝐿×)∗are the sets of candidates of background
knowledge based on the relative time differences.
note that in definition 12, other attributes are also present. however, our focus is on time differences between relative
timestamps. therefore, we refer to this category of background knowledge as time-based.
4. attack models
fig. 3 shows our simple scenario of data collection and data publishing. with respect to the types of data holder’s models,
introduced in [12], we consider a trusted model . in the trusted data holder models, the data holder is trustworthy, and on the data
holder’s side, only simple anonymization techniques need to be applied, e.g., suppressing real identifiers. however, the data recipient ,
i.e., a process miner, is not trustworthy and may attempt to identify sensitive information about record owners, i.e., cases. given a
process instance 𝑝= (𝑐,𝜎,𝑠 ) ∈, both𝜎and𝑠are considered as sensitive person-specific information, and part of the trace 𝜎can
be exploited as the quasi-identifier to re-identify the owner of the process instance, i.e., 𝑐, and/or to learn the sensitive information
which belongs to the data owner, i.e., 𝜎and/or𝑠.
in the following, we provide formal definitions and examples for the attack scenarios based on the main event attributes,
i.e.,activity ,resource , and timestamp . note that the examples are based on the event log shown in table 2.
4.1. activity-based attacks
in the activity-based scenarios, we assume that the adversary’s knowledge is about the activities performed for a victim case. in
the following, we provide formal models based on the introduced types of background knowledge.
–based on a set of activities (a1): in this scenario, we assume that the adversary knows a subset of activities performed for a
case, and this information can lead to the case linkage and/or attribute linkage attacks. given 𝐸𝐿as an event log, we formalize
this scenario by a function 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑡,𝑎𝑐∶ 2𝐴𝐸𝐿→2𝐸𝐿. for𝐴∈𝑏𝑘𝑠𝑒𝑡,𝑎𝑐(𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑡,𝑎𝑐(𝐴) = {(𝑐,𝜎,𝑠 ) ∈𝐸𝐿∣𝐴⊆ {𝑎∈𝜋(𝜎)}}.
for example, if the adversary knows that {𝑉𝐼,𝐼𝑁 }is a subset of activities performed for a case, the only matching case is
case 4. therefore, both the sequence of events and the sensitive attribute are disclosed.
–based on a multiset of activities (a2): in this scenario, we assume that the adversary knows a sub-multiset of activities
performed for a case, and this information can result in the linkage attacks. given 𝐸𝐿as an event log, we formalize this
scenario as follows. 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑚𝑢𝑙𝑡,𝑎𝑐∶(𝐴𝐸𝐿)→2𝐸𝐿. for𝐵∈𝑏𝑘𝑚𝑢𝑙𝑡,𝑎𝑐 (𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑚𝑢𝑙𝑡,𝑎𝑐(𝐵) = {(𝑐,𝜎,𝑠 ) ∈𝐸𝐿∣𝐵 ⊆ [𝑎∈𝜋(𝜎)]}.
for example, if the adversary knows that [𝐻𝑂1,𝐵𝑇2]is a multiset of activities performed for a case, the only matching case
is case 2. consequently, the complete sequence of events and the disease are disclosed.
6m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
–based on a sequence of activities (a3): in this scenario, we assume that the adversary knows a subsequence of activities
performed for a case, and this information can lead to the linkage attacks. given 𝐸𝐿as an event log, we formalize this scenario
by a function 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑞,𝑎𝑐∶𝐴∗
𝐸𝐿→2𝐸𝐿. for𝜎∈𝑏𝑘𝑠𝑒𝑞,𝑎𝑐 (𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑞,𝑎𝑐(𝜎) = {(𝑐,𝜎′,𝑠) ∈𝐸𝐿∣𝜎 ⊑𝜋(𝜎′)}. for example, if the
adversary knows that ⟨𝑅𝐸,𝑉𝐼,𝐻𝑂 ⟩is a subsequence of activities performed for a case, case 5 is the only matching case.
4.2. resource-based attacks
in the resource-based scenarios, we assume that the adversary’s knowledge is about the resources who perform activities for a
victim case. in the following, we provide formal models based on the main types of background knowledge.
–based on a set of resources (r1): in this scenario, we assume that the adversary knows a subset of resources involved in
performing activities for a victim case, and this information can lead to the case linkage and/or attribute linkage attacks. given
𝐸𝐿as an event log, we formalize this scenario as follows. 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑡,𝑟𝑒∶ 2𝑅𝐸𝐿→2𝐸𝐿. for𝑅∈𝑏𝑘𝑠𝑒𝑡,𝑟𝑒(𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑡,𝑟𝑒(𝑅) =
{(𝑐,𝜎,𝑠 ) ∈𝐸𝐿∣𝑅 ⊆ {𝑟∈𝜋(𝜎)}}. for example, if the adversary knows that {𝐸1,𝐷2}is a subset of resources involved in
handling a victim case, case 5 is the only matching case. therefore, both the sequence of events and the sensitive attribute
are disclosed.
–based on a multiset of resources (r2): in this scenario, we assume that the adversary knows a sub-multiset of resources
involved in performing activities for a victim case, and this information can lead to the linkage attacks. given 𝐸𝐿as an event
log, we formalize this scenario as follows. 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑚𝑢𝑙𝑡,𝑟𝑒∶(𝑅𝐸𝐿)→2𝐸𝐿. for𝑆∈𝑏𝑘𝑚𝑢𝑙𝑡,𝑟𝑒 (𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑚𝑢𝑙𝑡,𝑟𝑒(𝑆) = {(𝑐,𝜎,𝑠 ) ∈
𝐸𝐿∣𝑆 ⊆ [𝑟∈𝜋(𝜎)]}. for example, if the adversary knows that [𝑁12,𝐸3]is a multiset of resources performed activities for
a victim case, the only matching case is case 2.
–based on a sequence of resources (r3): in this scenario, we assume that the adversary knows a subsequence of resources
who performed activities for a victim case, and this information can result in the linkage attacks. given 𝐸𝐿as an event log,
we formalize this scenario by a function 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑞,𝑟𝑒∶𝑅∗
𝐸𝐿→2𝐸𝐿. for𝜎∈𝑏𝑘𝑠𝑒𝑞,𝑟𝑒(𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑞,𝑟𝑒(𝜎) = {(𝑐,𝜎′,𝑠) ∈𝐸𝐿∣𝜎 ⊑
𝜋(𝜎′)}. for example, if the adversary knows that ⟨𝐸4,𝐷2⟩is a subsequence of resources who performed activities for a victim
case, the only matching case is case 4.
4.3. activity & resource-based attacks
in the activity & resource-based scenarios, we assume that the adversary’s knowledge is about activities and the corresponding
resources who perform activities for a victim case. in the following, we provide formal models based on the main types of background
knowledge.
–based on a set of (activity,resource) pairs (ar1): in this scenario, we assume that the adversary knows a subset of
(activity,resource) pairs included in the trace attribute of a victim case, and this information can result in the case linkage
and/or attribute linkage attacks. given 𝐸𝐿as an event log, we formalize this scenario as follows. 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑡,𝑎𝑟∶ 2𝐴𝐸𝐿×𝑅𝐸𝐿→2𝐸𝐿.
for𝐴𝑅∈𝑏𝑘𝑠𝑒𝑡,𝑎𝑟(𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑡,𝑎𝑟(𝐴𝑅) = {(𝑐,𝜎,𝑠 ) ∈𝐸𝐿∣𝐴𝑅 ⊆ {(𝑎,𝑟) ∈𝜋×(𝜎)}}. for example, if the adversary knows that
{(𝐻𝑂,𝐸 6)}is a subset of (activity,resource) pairs contained in the trace attribute of a victim case, case 5 is the only matching
case, which result is the whole sequence and sensitive attribute disclosure.
–based on a multiset of (activity,resource) pairs (ar2): in this scenario, we assume that the adversary knows a sub-multiset
of (activity,resource) pairs included in the trace attribute of a victim case. given 𝐸𝐿as an event log, the scenario can be
formalized as follows. 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑚𝑢𝑙𝑡,𝑎𝑟∶(𝐴𝐸𝐿×𝑅𝐸𝐿)→2𝐸𝐿. for𝐵𝑆∈𝑏𝑘𝑚𝑢𝑙𝑡,𝑎𝑟 (𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑚𝑢𝑙𝑡,𝑎𝑟(𝐵𝑆) = {(𝑐,𝜎,𝑠 ) ∈𝐸𝐿∣𝐵𝑆 ⊆
[(𝑎,𝑟) ∈𝜋×(𝜎)]}. for example, if the adversary knows that [(𝐵𝑇,𝑁 1)2]is a multiset of (activity,resource) pairs included in
the trace attribute of a victim case, the only matching case is case 2.
–based on a sequence of (activity,resource) pairs (ar3): in this scenario, we assume that the adversary knows a subsequence
of (activity,resource) pairs included in the trace attribute of a victim case, and this information can lead to the linkage attacks.
given𝐸𝐿as an event log, we formalize this scenario by a function 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑞,𝑎𝑟∶ (𝐴𝐸𝐿×𝐸𝐸𝐿)∗→2𝐸𝐿. for𝜎∈𝑏𝑘𝑠𝑒𝑞,𝑎𝑟(𝐸𝐿),
𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑠𝑒𝑞,𝑎𝑟(𝜎) = {(𝑐,𝜎′,𝑠) ∈𝐸𝐿 ∣𝜎 ⊑ 𝜋×(𝜎′)}. for example, if the adversary knows that ⟨(𝑅𝐸,𝐸 4),(𝑉𝐼,𝐷 2)⟩is a
(activity,resource) pairs included in the trace attribute of a victim case, case 4 is the only matching case.
4.4. time-based attacks
as we discussed in section 3.2, after making the timestamps relative, the time differences are still real and can be exploited by
an adversary. in the following, we extend the attacks of the type sequence , i.e., a3, r3, ar3, with the time-related information.
–based on relative time differences between activities (at): in this scenario, we assume that the adversary knows a
subsequence of activities and also the time difference between the activities. given 𝐸𝐿as an event log, the scenario is
formalized as follows. 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑟𝑒𝑙,𝑎𝑐∶ (𝐴𝐸𝐿×)∗→2𝐸𝐿. for𝜎∈𝑏𝑘𝑟𝑒𝑙,𝑎𝑐(𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑟𝑒𝑙,𝑎𝑐(𝜎) = {(𝑐,𝜎′,𝑠) ∈𝐸𝐿 ∣𝜎 ⊑
𝑟𝑒𝑙𝑎𝑡𝑖𝑣𝑒 (𝜋×(𝜎′))}. for example, if an adversary’s knowledge is ⟨𝐻𝑂,𝑉𝐼 ⟩, both case 2 and case 3 get matched. however,
if the adversary further knows that for a victim case, visitperformed in the morning of the next day, the only matching case
is case 2.
7m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 3
a simple event log where time difference between relative timestamps are
represented by integer values.
case id trace disease
1 <(re,e4,1),(ho,e3,4),(vi,d1,5),(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > infection
3 <(ho,e3,4),(vi,d1,5),(bt,n1,7),(rl,e2,9) > corona
4 <(re,e4,1),(vi,d1,6),(vi,d1,8),(rl,e2,9) > infection
5 <(ho,4),(vi,d1,8),(rl,e2,9) > corona
6 <(vi,d1,6),(bt,n1,7),(rl,e2,9) > flu
7 <(re,e4,1),(bt,n1,7),(vi,d1,8),(rl,e2,9) > flu
8 <(re,e4,1),(vi,d1,6),(bt,n1,7),(vi,d1,8) > cancer
table 4
the event log after applying 2-anonymity to table 3 using baseline -2.
case id trace disease
1 <(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > infection
3 <(bt,n1,7),(rl,e2,9) > corona
4 <(vi,d1,8),(rl,e2,9) > infection
5 <(vi,d1,8),(rl,e2,9) > corona
6 <(bt,n1,7),(rl,e2,9) > flu
7 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > flu
8 <(bt,n1,7),(vi,d1,8) > cancer
–based on relative time differences between resources who performed activities (rt): according to this scenario, the
adversary knows a subsequence of resources and the time difference between the resources involved in handling a case.
given𝐸𝐿as an event log, we formalize this scenario by a function 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑟𝑒𝑙,𝑟𝑒∶ (𝑅𝐸𝐿×)∗→2𝐸𝐿. for𝜎∈𝑏𝑘𝑟𝑒𝑙,𝑟𝑒(𝐸𝐿),
𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑟𝑒𝑙,𝑟𝑒(𝜎) = {(𝑐,𝜎′,𝑠) ∈𝐸𝐿∣𝜎 ⊑ 𝑟𝑒𝑙𝑎𝑡𝑖𝑣𝑒 (𝜋×(𝜎′))}. for example, if an adversary’s knowledge is ⟨𝐸1,𝐸3⟩, both case 2
and case 3 get matched. however, if the adversary further knows that for the victim case, employee 3 performed hospitalization
more than one hour after registration , case 3 is the only matching case.
–based on relative time differences between (activity,resource) pairs (art): in this scenario, the assumption is that the
adversary knows a subsequence of (activity,resource) pairs and the time difference between these pairs. given 𝐸𝐿as an event
log, we formalize this scenario as follows. 𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑟𝑒𝑙,𝑎𝑟∶ (𝐴𝐸𝐿×𝑅𝐸𝐿)∗→2𝐸𝐿. for𝜎∈𝑏𝑘𝑟𝑒𝑙,𝑎𝑟(𝐸𝐿),𝑚𝑎𝑡𝑐ℎ𝐸𝐿
𝑟𝑒𝑙,𝑎𝑟(𝜎) = {(𝑐,𝜎′,𝑠) ∈
𝐸𝐿∣𝜎 ⊑ 𝑟𝑒𝑙𝑎𝑡𝑖𝑣𝑒 (𝜎′)}. for example, case 1 and case 6 have the same sequence of (activity,resource) pairs. however, if the
adversary knows that for a victim case, it took almost four hours to get released by employee 6 after visiting by a doctor, the
corresponding possible cases narrow down to only one case, which is case 6.
5. privacy preservation techniques
traditional 𝑘-anonymity and its extended privacy preservation techniques assume that an adversary could use all of the quasi-
identifier attributes as background knowledge to launch linkage attacks. according to the types of background knowledge introduced
in section 3, this assumption means that the background knowledge of an adversary is 𝑏𝑘𝑟𝑒𝑙,𝑎𝑟 which covers all the information
contained in a trace. in the following, we show the results of applying two baseline methods with respect to the aforementioned
assumption.
5.1. baseline methods
in this subsection, we introduce two baseline methods to apply 𝑘-anonymity on event logs: baseline -1 and baseline -2.baseline -1
is a naïve𝑘-anonymity approach where we remove all the trace variants occurring less than 𝑘times. baseline -2 maps each violating
trace variant, i.e., the variant that does not fulfill the desired 𝑘-anonymity requirement, to the most similar non-violating subtrace
by removing events. in baseline -2, if there exists no non-violating subtrace, the whole trace variant is removed.
suppose that table 3 is part of an event log recorded by an information system in a hospital that needs to be published after
applying𝑘-anonymity. note that for the sake of simplicity, the time differences between relative timestamps are represented by
integers. since all the traces in this event log are unique if we apply 𝑘-anonymity with any value greater than 1, using baseline -1,
all the traces are removed. if we apply baseline -2 where𝑘= 2then the result is the event log shown in table 4. one can see that for
such a weak privacy requirement 12 events are removed. now, if we use 𝑘= 4, table 5 is the result where 18 events are removed
which is more than half of the events.
in [13], the 𝑃𝑅𝐸𝑇𝑆𝐴 method is introduced as a group-based privacy preservation technique for process mining where the
authors apply 𝑘-anonymity and 𝑡-closeness on event data for privacy-aware process discovery. however, 𝑃𝑅𝐸𝑇𝑆𝐴 focuses on the
8m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
resource perspective of privacy while we focus on the case perspective . the𝑃𝑅𝐸𝑇𝑆𝐴 method assumes a prefix of activity sequences
as the background knowledge, and each violating trace is mapped to the most similar non-violating trace. in [5], 𝑃𝑅𝐸𝑇𝑆𝐴𝑐𝑎𝑠𝑒is
introduced as a variant of 𝑃𝑅𝐸𝑇𝑆𝐴 method where only the 𝑘-anonymity part is considered, and the focus is on the privacy of cases
rather than resources . therefore, 𝑃𝑅𝐸𝑇𝑆𝐴𝑐𝑎𝑠𝑒is a specific type of baseline -2 where the background knowledge is a specific type of
𝑏𝑘𝑠𝑒𝑞,𝑎𝑐, i.e., a prefix of activity sequences rather than any subsequence.
5.2.𝑇𝐿𝐾𝐶 -privacy (extended)
as discussed in [5], it is almost impossible for an adversary to acquire all the information of a target victim, and it requires
non-trivial effort to gather each piece of background knowledge. the 𝑇𝐿𝐾𝐶 -privacy exploits this limitation and assumes that the
adversary’s background knowledge is bounded by at most 𝐿values of the quasi-identifier, i.e., the size or power of background
knowledge. based on the types of background knowledge illustrated in fig. 2, the 𝑇𝐿𝐾𝐶 -privacy considers all the types, i.e., set,
multiset ,sequence , and relative . however, it focuses on the activity attribute (ac) and timestamps which are included in the relative
type. in this paper, the technique is extended with the resource attribute, i.e., merely resource (re) and activity along with resource
(ar) are also considered. in the following, we bound the power of the different types of background knowledge (definition 9–12)
with𝐿as the maximal size of candidates.
definition 13 (bounded background knowledge ).let𝐸𝐿be an event log, 𝑡𝑦𝑝𝑒 ∈ {𝑠𝑒𝑡,𝑚𝑢𝑙𝑡,𝑠𝑒𝑞,𝑟𝑒𝑙 }be the type of background
knowledge, 𝑎𝑡𝑡∈ {𝑎𝑐,𝑟𝑒,𝑎𝑟 }be the event attribute of background knowledge, and l be the size of background knowledge.
𝑏𝑘𝐿
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝐸𝐿) = {𝑐𝑎𝑛𝑑 ∈𝑏𝑘𝑡𝑦𝑝𝑒,𝑎𝑡𝑡 (𝐸𝐿) ∣|𝑐𝑎𝑛𝑑|≤𝐿}are the candidates of the background knowledge whose sizes are bounded
by𝐿.
in the𝑇𝐿𝐾𝐶 -privacy,𝑇∈ {𝑠𝑒𝑐𝑜𝑛𝑑𝑠,𝑚𝑖𝑛𝑢𝑡𝑒𝑠,ℎ𝑜𝑢𝑟𝑠,𝑑𝑎𝑦𝑠 }refers to the accuracy of timestamps, e.g., 𝑇=𝑚𝑖𝑛𝑢𝑡𝑒𝑠 shows that
the accuracy of timestamps is limited at minutes level,𝐿refers to the power of background knowledge, 𝐾refers to the 𝑘in the
𝑘-anonymity definition, and 𝐶refers to the bound of confidence regarding the sensitive attribute values in a matching set. we
denote𝐸𝐿(𝑇)as the event log with the accuracy of timestamps at the level 𝑇. the general idea of 𝑇𝐿𝐾𝐶 -privacy is to ensure that
the background knowledge of size 𝐿in𝐸𝐿(𝑇)is shared by at least 𝐾cases, and the confidence of inferring the sensitive value in
𝑆is not greater than 𝐶.
definition 14 (𝑇𝐿𝐾𝐶 -privacy ).let𝐸𝐿 ⊆ be an event log, 𝐿be the maximal size of background knowledge, 𝑇∈
{𝑠𝑒𝑐𝑜𝑛𝑑𝑠,𝑚𝑖𝑛𝑢𝑡𝑒𝑠,ℎ𝑜𝑢𝑟𝑠,𝑑𝑎𝑦𝑠 }be the accuracy of timestamps, 𝑡𝑦𝑝𝑒 ∈ {𝑠𝑒𝑡,𝑚𝑢𝑙𝑡,𝑠𝑒𝑞,𝑟𝑒𝑙 }, and𝑎𝑡𝑡∈ {𝑎𝑐,𝑟𝑒,𝑎𝑟 }.𝐸𝐿(𝑇)satisfies
𝑇𝐿𝐾𝐶 -privacy if and only if for any 𝑐𝑎𝑛𝑑 ∈𝑏𝑘𝐿
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝐸𝐿(𝑇))such that𝑚𝑎𝑡𝑐ℎ𝐸𝐿(𝑇)
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝑐𝑎𝑛𝑑 )≠∅:
–|𝑚𝑎𝑡𝑐ℎ𝐸𝐿(𝑇)
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝑐𝑎𝑛𝑑 )|≥𝐾, where𝐾∈n>0, and
–𝑃𝑟(𝑠|𝑐𝑎𝑛𝑑 ) =|{𝑝∈𝑚𝑎𝑡𝑐ℎ𝐸𝐿(𝑇)
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝑐𝑎𝑛𝑑 )∣𝜋(𝑝)=𝑠}|
|𝑚𝑎𝑡𝑐ℎ𝐸𝐿(𝑇)
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝑐𝑎𝑛𝑑 )|≤𝐶for any𝑠∈𝑆, where 0<𝐶≤1is a real number as the confidence threshold, and
𝜋(𝑝)is the projection of the process instance on the sensitive attribute value.
the𝑇𝐿𝐾𝐶 -privacy provides a major relaxation from traditional 𝑘-anonymity based on a reasonable assumption that the
adversary has restricted knowledge. it generalizes several privacy preservation techniques including 𝑘-anonymity, confidence
bounding, (𝛼,𝑘)-anonymity, and 𝑙-diversity. it also provides interpretable parameters. note that the type and attribute of background
knowledge implicitly show the perspective (fig. 2).
5.2.1. privacy measure
in the subsection, we define (minimal) violating traces w.r.t. the privacy requirements of the 𝑇𝐿𝐾𝐶 -privacy.
definition 15 (violating trace ).let𝐸𝐿 ⊆ be an event log, 𝐿be the maximal size of background knowledge, 𝑇∈
{𝑠𝑒𝑐𝑜𝑛𝑑𝑠,𝑚𝑖𝑛𝑢𝑡𝑒𝑠,ℎ𝑜𝑢𝑟𝑠,𝑑𝑎𝑦𝑠 }be the accuracy of timestamps, 𝑡𝑦𝑝𝑒 ∈ {𝑠𝑒𝑡,𝑚𝑢𝑙𝑡,𝑠𝑒𝑞,𝑟𝑒𝑙 },𝑎𝑡𝑡∈ {𝑎𝑐,𝑟𝑒,𝑎𝑟 },𝑝𝑠∈be the
corresponding perspective w.r.t. the given 𝑡𝑦𝑝𝑒and𝑎𝑡𝑡, and𝜎 ⊑ 𝜋𝑝𝑠(𝜎′)such that (𝑐,𝜎′,𝑠) ∈𝐸𝐿(𝑇).𝜎is a violating (sub)trace
with respect to the 𝑇𝐿𝐾𝐶 -privacy requirements if there exists a 𝑐𝑎𝑛𝑑 ∈𝑏𝑘𝐿
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝐸𝐿(𝑇)):
–𝑐𝑎𝑛𝑑 ⊑𝜎 ∨𝑐𝑎𝑛𝑑 ⊆ {𝑒∈𝜎} ∨𝑐𝑎𝑛𝑑 ⊆ [𝑒∈𝜎], and
–|𝑚𝑎𝑡𝑐ℎ𝐸𝐿(𝑇)
𝑡𝑦𝑝𝑒,𝑎𝑡𝑡(𝑐𝑎𝑛𝑑 )|<𝐾or𝑃𝑟(𝑠|𝑐𝑎𝑛𝑑 )>𝐶for some𝑠∈𝑆.
an event log satisfies 𝑇𝐿𝐾𝐶 -privacy, if all violating traces w.r.t. the given privacy requirement are removed. a naïve approach
is to determine all violating traces and remove them. however, this approach is inefficient due to the numerous number of violating
traces, even for a weak privacy requirement. moreover, as demonstrated in [5], 𝑇𝐿𝐾𝐶 -privacy is not monotonic w.r.t. 𝐿. in fact,
the anonymity threshold 𝐾is monotonic w.r.t. 𝐿, i.e., if𝐿′≤𝐿and𝐶= 100% , an event log 𝐸𝐿which satisfies 𝑇𝐿𝐾𝐶 -privacy must
satisfy𝑇𝐿′𝐾𝐶-privacy. however, confidence threshold 𝐶is not monotonic w.r.t. 𝐿, i.e., if𝜎is non-violating trace, its subtrace may
or may not be non-violating. therefore, we have to make sure that the conditions should hold for any 𝐿′≤𝐿. to this end, in the
following, we define the extended version of minimal violating traces w.r.t. the different perspectives.
9m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
algorithm 1: 𝑇𝐿𝐾𝐶 -privacy - extended w.r.t. the different perspectives.
input : original event log 𝐸𝐿
input :𝑇,𝐿,𝐾,𝐶, and𝛩(frequency threshold)
input : background knowledge type and attribute ( 𝑏𝑘𝑡𝑦𝑝𝑒,𝑎𝑡𝑡 ), sensitive attributes 
output : anonymized event log 𝐸𝐿′which satisfies the desired 𝑇𝐿𝐾𝐶 -privacy requirements
1generate𝑀𝐹𝑇𝐸𝐿
𝑝𝑠and𝑀𝑉𝑇𝐸𝐿
𝑝𝑠;
2generate𝑀𝐹𝑇𝑡𝑟𝑒𝑒
𝑝𝑠and𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠as the prefix trees for 𝑀𝐹𝑇𝐸𝐿
𝑝𝑠and𝑀𝑉𝑇𝐸𝐿
𝑝𝑠;
3while there is node (event) in 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠do
4 select an event (node) 𝑒𝑤that has the highest score to suppress based on 𝑠𝑜𝑐𝑟𝑒 (𝑒)𝐸𝐿
𝑝𝑠;
5 delete all the mvts and mfts containing the event 𝑒𝑤from𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠and𝑀𝐹𝑇𝑡𝑟𝑒𝑒
𝑝𝑠;
6 update𝑠𝑜𝑐𝑟𝑒 (𝑒)𝐸𝐿
𝑝𝑠for all the remaining events (nodes) in 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠;
7 add𝑒𝑤to the suppression set 𝑆𝑢𝑝𝐸𝐿;
8end
9foreach𝑒∈𝑆𝑢𝑝𝐸𝐿do
10 suppress all instances of 𝑒from𝐸𝐿;
11end
12return suppressed 𝐸𝐿as𝐸𝐿′;
definition 16 (minimal violating trace ).let𝐸𝐿⊆ be an event log, 𝐿be the maximal size of background knowledge, 𝑇∈
{𝑠𝑒𝑐𝑜𝑛𝑑𝑠,𝑚𝑖𝑛𝑢𝑡𝑒𝑠,ℎ𝑜𝑢𝑟𝑠,𝑑𝑎𝑦𝑠 }be the accuracy of timestamps, 𝑡𝑦𝑝𝑒 ∈ {𝑠𝑒𝑡,𝑚𝑢𝑙𝑡,𝑠𝑒𝑞,𝑟𝑒𝑙 },𝑎𝑡𝑡∈ {𝑎𝑐,𝑟𝑒,𝑎𝑟 },𝑝𝑠∈be the
corresponding perspective w.r.t. the given 𝑡𝑦𝑝𝑒and𝑎𝑡𝑡, and𝜎 ⊑ 𝜋𝑝𝑠(𝜎′)such that (𝑐,𝜎′,𝑠) ∈𝐸𝐿(𝑇).𝜎is a minimal violating trace
if𝜎is a violating trace (definition 15) in the 𝐸𝐿, and every proper subtrace of 𝜎is not violating. we denote 𝑀𝑉𝑇𝐸𝐿
𝑝𝑠as the set of
minimal violating traces in the event log 𝐸𝐿w.r.t. the perspective 𝑝𝑠.
every violating trace in an event log is either a minimal violating trace or it contains a minimal violating trace. therefore, if an
event log contains no minimal violating trace, then it contains no violating trace. note that the set of minimal violating traces in an
event log is much smaller than the set of violating traces in the event log which results in better efficiency for removing violating
traces.
5.2.2. utility measure
in the𝑇𝐿𝐾𝐶 -privacy, the maximal frequent traces are defined as a measure for considering data utility, where traces contain
activity and timestamp attributes. since we extend the 𝑇𝐿𝐾𝐶 -privacy preservation technique to cover all the main perspectives of
process mining, the utility measure also needs to be extended. in the following, we provide an extended version of the utility measure
considering the perspectives.
definition 17 (maximal frequent trace ).let𝐸𝐿be an event log, and 𝑝𝑠∈be a perspective. for a given minimum support
threshold𝛩, a non-empty trace 𝜎⊑𝜋𝑝𝑠(𝜎′)such that (𝑐,𝜎′,𝑠) ∈𝐸𝐿ismaximal frequent in the𝐸𝐿if𝜎is frequent, i.e., the frequency
of𝜎is greater than or equal to 𝛩, and no supertrace of 𝜎is frequent in the 𝐸𝐿. we denote 𝑀𝐹𝑇𝐸𝐿
𝑝𝑠as the set of maximal frequent
traces in the event log 𝐸𝐿w.r.t. the perspective 𝑝𝑠.
the goal of data utility is to preserve as many mft as possible w.r.t. the given perspective. for example, in the control-flow
perspective, i.e., 𝑝𝑠=, the goal in to preserve the maximal frequent traces w.r.t. the activities. note that in an event log, the set of
maximal frequent traces is much smaller than the set of frequent traces. moreover, any subtrace of a maximal frequent trace is also
a frequent trace, and once all the mfts are discovered, the support counts of any frequent subtrace can be computed by scanning
the data once.
5.2.3. balancing privacy and utility
as discussed in the privacy measure section, to provide the desired privacy requirements, all the minimal violating traces need
to be removed. however, this should be done w.r.t. the utility measure. according to definition 16, every proper subtrace of a
minimal violating trace is not violating. therefore, a minimal violating trace can be removed after removing one event of the trace.
this event needs to be chosen w.r.t. both utility and privacy measures. to this end, a greedy function is defined to choose an event
to remove from the minimal violating traces such that it maximizes the number of removed minimal violating traces, i.e., privacy
gain, yet, at the same time, minimizes the number of removed maximal frequent traces, i.e., utility loss.
definition 18 (score, privacy gain, utility loss ).let𝐸𝐿be an event log, 𝑝𝑠∈be a perspective, and 𝑒𝑣𝑒𝑛𝑡𝑠𝑝𝑠(𝐸𝐿) = {𝑒∈𝜋𝑝𝑠(𝜎) ∣
(𝑐,𝜎,𝑠 ) ∈𝐸𝐿}be the set of events in the event log w.r.t. the given perspective. 𝑠𝑐𝑜𝑟𝑒𝐸𝐿
𝑝𝑠∶↛r>0is a function which retrieves
the score of the events in the event log w.r.t. the perspective. for 𝑒∈𝑒𝑣𝑒𝑛𝑡𝑠𝑝𝑠(𝐸𝐿),𝑠𝑐𝑜𝑟𝑒𝐸𝐿
𝑝𝑠(𝑒) =𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒)∕𝑈𝐿𝐸𝐿
𝑝𝑠(𝑒)+1.𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒)is the
number of mvts containing the event 𝑒, i.e.,𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒) =|{𝑥∈𝑀𝑉𝑇𝐸𝐿
𝑝𝑠∣𝑒∈𝑥}|and𝑈𝐿𝐸𝐿
𝑝𝑠(𝑒)is the number of mfts containing the
event𝑒, i.e.,𝑈𝐿𝐸𝐿
𝑝𝑠(𝑒) =|{𝑥∈𝑀𝐹𝑇𝐸𝐿
𝑝𝑠∣𝑒∈𝑥}|.
note that in the score (definition 18), 1 is added to the denominator to avoid diving by zero (when 𝑒does not belong to any mft).
the event𝑒with the highest score is called the 𝑤𝑖𝑛𝑛𝑒𝑟 event, denoted by 𝑒𝑤. algorithm 1 summarizes all the steps of 𝑇𝐿𝐾𝐶 -privacy.
in the following, we show how the algorithm works on the event log table 3.
10m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 4. the𝑀𝐹𝑇𝑡𝑟𝑒𝑒
𝑝𝑠and𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠generated for the event log table 3 with 𝑇=ℎ𝑜𝑢𝑟𝑠 ,𝐿= 2,𝐾= 2,𝐶= 50% ,𝛩= 25% ,=𝐷𝑖𝑠𝑒𝑎𝑠𝑒 , and𝑏𝑘𝐸𝐿
𝑟𝑒𝑙,𝑎𝑟.
table 5
the event log after applying 4-anonymity to table 3 using baseline -2.
case id trace disease
1 <(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8) > infection
3 <(rl,e2,9)> corona
4 <(rl,e2,9)> infection
5 <(rl,e2,9)> corona
6 <(rl,e2,9)> flu
7 <(bt,n1,7),(vi,d1,8) > flu
8 <(bt,n1,7),(vi,d1,8) > cancer
suppose that table 3 shows a simple event log 𝐸𝐿where timestamps are represented by integer values as hours. the first line
in algorithm 1 generates the set of maximal frequent traces ( 𝑀𝐹𝑇𝐸𝐿
𝑝𝑠) and the set of minimal violating traces ( 𝑀𝑉𝑇𝐸𝐿
𝑝𝑠) from the
event log𝐸𝐿with𝑇=ℎ𝑜𝑢𝑟𝑠 ,𝐿= 2,𝐾= 2,𝐶= 50% ,𝛩= 25% ,disease as the sensitive attribute , and𝑏𝑘𝐸𝐿
𝑟𝑒𝑙,𝑎𝑟as the background
knowledge, i.e., 𝑝𝑠=××. fig. 4 shows the 𝑀𝐹𝑇𝑡𝑟𝑒𝑒
𝑝𝑠and𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠generated by line 2 in algorithm 1, where each root-to-leaf
path represents one trace, and each node represents an event in a trace with the frequency of occurrence. table 6 shows the initial
score of every event (node) in the 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠(𝑠𝑐𝑜𝑟𝑒𝐸𝐿
𝑝𝑠(𝑒)). line 4 determines the winner event 𝑒𝑤which is (𝑉𝐼,𝐷 1,5). line 5 deletes
all the mvts and mfts containing the winner event 𝑒𝑤, i.e., subtree 2 and the path ⟨(𝑅𝐸,𝐸 4,1),(𝑉𝐼,𝐷 1,5)⟩of subtree 1 in the
𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠, and the path ⟨(𝐻𝑂,𝐸 3,4),(𝑉𝐼,𝐷 1,5),(𝐵𝑇,𝑁 1,7)⟩of subtree 4 in the 𝑀𝐹𝑇𝑡𝑟𝑒𝑒
𝑝𝑠are removed and frequencies get updated.
line 6 updates the scores based on the new frequencies of events. table 7 shows the remaining events in 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠with the updated
scores. line 7 adds the winner event to a suppression set 𝑆𝑢𝑝𝐸𝐿. lines 4–7 is repeated until there is no node in 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠. according
to table 7 the next winner event is (𝑅𝐸,𝐸 4,1), and after deleting all the mvts and mfts containing this event, 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠is empty.
therefore, at the end of the while loop, the suppression set 𝑆𝑢𝑝𝐸𝐿= {(𝑉𝐼,𝐷 1,5),(𝑅𝐸,𝐸 4,1)}. the foreach loop suppresses all
the instances of the events, i.e., global suppression , in the𝑆𝑢𝑝𝐸𝐿from the𝐸𝐿, and the last line returns the suppressed 𝐸𝐿as the
anonymized event log 𝐸𝐿′which is shown in table 8.
compared to tables 4 and 5 which are the results of applying traditional 𝑘-anonymity using baseline -2, table 8 shows that
𝑇𝐿𝐾𝐶 -privacy removes less events (only 6), for the stronger privacy requirements.
5.2.4. new utility measure and new score
in this subsection, we first describe the shortcomings of the utility measure and the score introduced in [5] (extended in
definitions 17 and 18), then we introduce a new utility measure and a new score to overcome the drawbacks. according to
definition 18, the score is calculated based on the existence of events in the set of minimal violating traces and the set of maximal
11m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 6
the initial scores for the events in fig. 4(b).
(𝑅𝐸,𝐸 4,1) (𝐻𝑂,𝐸 3,4) (𝑉𝐼,𝐷 1,5) (𝐵𝑇,𝑁 1,7) (𝑉𝐼,𝐷 1,8) (𝑅𝐿,𝐸 2,9)
𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒) 3 1 3 1 1 1
𝑈𝐿𝐸𝐿
𝑝𝑠(𝑒) + 1 4 4 2 5 6 5
𝑠𝑐𝑜𝑟𝑒𝐸𝐿
𝑝𝑠(𝑒) 0.75 0.25 1.50 0.20 0.16 0.20
table 7
the first updated scores.
(𝑅𝐸,𝐸 4,1) ( 𝐻𝑂,𝐸 3,4) ( 𝐵𝑇,𝑁 1,7)
𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒) 2 1 1
𝑈𝐿𝐸𝐿
𝑝𝑠(𝑒) + 1 4 3 4
𝑠𝑐𝑜𝑟𝑒𝐸𝐿
𝑝𝑠(𝑒) 0.5 0.33 0.25
frequent traces. however, the sizes of these sets, and consequently the included events, highly depends on the corresponding
parameters. the set of mvts is obtained based on 𝑇,𝐿,𝐾,𝐶, and𝑏𝑘𝑡𝑦𝑝𝑒,𝑎𝑡𝑡 , while the set of mfts is discovered based on 𝛩and the
given perspective. therefore, some of the events included in the set of minimal violating traces may not be included in the set of
maximal frequent traces. consequently, the score of the corresponding events is merely calculated based on the effect on the privacy
gain. when two or more events have the same score based on the privacy gain , the algorithm assumes an equal effect for the data
utility aspect and randomly choose one of the events, which is not a valid assumption.
another problem with the current score is that even when there are maximal frequent traces where the event is included, the
score does not differentiate the corresponding mfts based on their frequencies in the event log. for example, suppose that for two
events𝑒1and𝑒2in the minimal violating traces there are two maximal frequent traces 𝑀𝐹𝑇1and𝑀𝐹𝑇2such that𝑒1is only included
in𝑀𝐹𝑇1, i.e.,𝑈𝐿(𝑒1) = 1, and𝑒2is only included in 𝑀𝐹𝑇2, i.e.,𝑈𝐿(𝑒2) = 1. hence, both events get the same score for the utility
aspect. however, the corresponding mfts may have completely different frequencies in the event log which leads to a different
impact on the utility. particularly, this issue is highlighted when the frequency threshold ( 𝛩) is rather low. for example, if 𝛩= 50% ,
then frequency of 𝑀𝐹𝑇1and𝑀𝐹𝑇2in the event log could differ up to 50%. furthermore, the current score is not normalized, and
it is not possible for the user to adjust the effect of each aspect on the score. for example, one may want to consider more effect
for the data utility aspect compared to the privacy gain aspect.
to overcome the above-mentioned shortcomings, we define a new utility measure that is able to show the impact of every single
event on the data utility. we also define a new score based on the new utility measure which provides normalized scores, and the
effect of each aspect is adjustable for users. in the new utility measure (definition 19), we consider the relative frequency of the
variants, where the given perspective of the event is included, as the basis of the utility.
definition 19 (new utility measure ).let𝐸𝐿be an event log, 𝑝𝑠∈be a perspective, and 𝑒𝑣𝑒𝑛𝑡𝑠𝑝𝑠(𝐸𝐿) = {𝑒∈𝜋𝑝𝑠(𝜎) ∣ (𝑐,𝜎,𝑠 ) ∈
𝐸𝐿}be the set of events in the event log w.r.t. the given perspective. for 𝑒∈𝑒𝑣𝑒𝑛𝑡𝑠𝑝𝑠(𝐸𝐿),𝑛𝑈𝐿𝐸𝐿
𝑝𝑠(𝑒) = 1−∑
{𝜎∈̃𝐸𝐿∣𝑒∈𝜋𝑝𝑠(𝜎)}𝑓𝑟𝑒𝑞𝐸𝐿(𝜎).
definition 20 (new score ).let𝐸𝐿be an event log, 𝑝𝑠∈be a perspective, 𝑒𝑣𝑒𝑛𝑡𝑠𝑝𝑠(𝐸𝐿) = {𝑒∈𝜋𝑝𝑠(𝜎) ∣ (𝑐,𝜎,𝑠 ) ∈𝐸𝐿}be the set
of events in the event log w.r.t. the given perspective, 𝛼be the coefficient of privacy gain (0≤𝛼≤1),𝛽be the coefficient of utility
loss(0≤𝛽≤1), and𝛼+𝛽= 1.𝑛-𝑠𝑐𝑜𝑟𝑒𝐸𝐿
𝑝𝑠∶↛r>0is a function which retrieves the score of the events in the event log w.r.t. the
perspective. for 𝑒∈𝑒𝑣𝑒𝑛𝑡𝑠𝑝𝑠(𝐸𝐿),𝑛-𝑠𝑐𝑜𝑟𝑒𝐸𝐿
𝑝𝑠(𝑒) =𝛼⋅𝑟𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒) +𝛽⋅𝑛𝑈𝐿𝐸𝐿
𝑝𝑠(𝑒), where𝑟𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒)is the relative value of the privacy
gain, i.e.,𝑟𝑃𝐺𝐸𝐿
𝑝𝑠(𝑒) =|{𝑥∈𝑀𝑉𝑇𝐸𝐿
𝑝𝑠∣𝑒∈𝑥}|∕|𝑀𝑉𝑇𝐸𝐿
𝑝𝑠|.
algorithm 2 shows the new algorithm based on the new utility measure and new score, where maximal frequent traces are not
used anymore, and the score of events included in the minimal violating traces is calculated based on the new score. note that in
both algorithm 1 and algorithm 2 the perspective is derived from the background knowledge type and attribute (fig. 2).
6. experiments
in this section, we evaluate the extended 𝑇𝐿𝐾𝐶 -privacy by applying it to real-life event logs. we explore the effect of applying
the technique on both data utility andresult utility . the results are also compared with the baseline methods. the result utility analysis
evaluates the similarity of the specific results obtained from the privacy-aware event log with the same type of results obtained from
the original event log, while the data utility analysis compares the privacy-aware event log with the original event log. as discussed
in [8], the result utility analysis is highly dependent on the underlying algorithm generating specific results, and the data utility
analysis provides a more general evaluation. we perform the evaluation for the three main perspectives including control-flow ,
organizational , and timeperspectives. for the result utility analysis, in each perspective, we focus on a specific type of results. for
the control-flow perspective, we focus on process discovery , for the organizational perspective, we perform social network discovery ,
and for the time perspective, we perform bottleneck analysis . the implementation as a python program is available on github.1
1https://github.com/m4jidrafiei/tlkc-privacy-ext.
12m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
algorithm 2: 𝑇𝐿𝐾𝐶 -privacy - extended w.r.t. the different perspectives, new score, and new utility measure.
input : original event log 𝐸𝐿
input :𝑇,𝐿,𝐾,𝐶
input : background knowledge type and attribute ( 𝑏𝑘𝑡𝑦𝑝𝑒,𝑎𝑡𝑡 ), sensitive attributes 
output : anonymized event log 𝐸𝐿′which satisfies the desired 𝑇𝐿𝐾𝐶 -privacy requirements
1generate𝑀𝑉𝑇𝐸𝐿
𝑝𝑠and𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠;
2while there is node (event) in 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠do
3 select an event (node) 𝑒𝑤that has the highest score to suppress based on 𝑛-𝑠𝑜𝑐𝑟𝑒 (𝑒)𝐸𝐿
𝑝𝑠;
4 delete all the mvts containing the event 𝑒𝑤from𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠;
5 update𝑛-𝑠𝑜𝑐𝑟𝑒 (𝑒)𝐸𝐿
𝑝𝑠for all the remaining events (nodes) in 𝑀𝑉𝑇𝑡𝑟𝑒𝑒
𝑝𝑠;
6 add𝑒𝑤to the suppression set 𝑆𝑢𝑝𝐸𝐿;
7end
8foreach𝑒∈𝑆𝑢𝑝𝐸𝐿do
9 suppress all instances of 𝑒from𝐸𝐿;
10end
11return suppressed 𝐸𝐿as𝐸𝐿′;
table 8
the anonymized event log for table 3 with 𝑇=hours,𝐿= 2,𝐾= 2,𝐶= 50% ,
𝛩= 25% ,=disease, and 𝑏𝑘𝐸𝐿
𝑟𝑒𝑙,𝑎𝑟.
case id trace disease
1 <(ho,e3,4),(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > infection
3 <(ho,e3,4),(bt,n1,7),(rl,e2,9) > corona
4 <(vi,d1,6),(vi,d1,8),(rl,e2,9) > infection
5 <(ho,e3,4),(vi,d1,8),(rl,e2,9) > corona
6 <(vi,d1,6),(bt,n1,7),(rl,e2,9) > flu
7 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > flu
8 <(vi,d1,6),(bt,n1,7),(vi,d1,8) > cancer
table 9
the general statistics of the event logs used in the experiments.
event log #cases #events #unique
activity#unique
resource#unique
(activity, resource)
sepsis-cases [14] 1050 15,214 16 – –
bpic-2012-app [15] 13,087 60,849 10 61 301
bpic-2017-app [17] 31,509 2,39,595 10 144 927
table 10
some statistics regarding the variants of the event logs used in the experiments w.r.t. the different
perspectives.
event log #variants activity
perspective#variants resource
perspective#variants (activity,
resource) perspective
sepsis-cases [14] 846 – –
bpic-2012-app [15] 17 2974 3872
bpic-2017-app [17] 102 24,230 24,471
6.1. experimental setup
for the experiments, we employ two human-centered event logs, where the case identifiers refer to individuals: sepsis-cases,
bpic-2012-app, and bpic-2017-app. sepsis-cases [14] is a real-life event log containing events of sepsis cases from a hospital.
bpic-2012-app [15] is also a real-life event log about a loan application process taken from a dutch financial institute. bpic-2017-
app also pertains to a loan application process of a dutch financial institute. table 9 shows the general statistics of these event
logs. the sepsis-cases event log was included in the experiments because it has some challenging features for privacy preservation
techniques, namely, 80% of traces are unique based on the activity perspective which imposes significant challenges for privacy-
preserving process discovery algorithms [5,13,16]. bpic-2017-app has similar properties w.r.t. the resource perspective, i.e., 76%
of traces are unique w.r.t. the resource perspective. note that sepsis-cases does not contain resource information and cannot be
used for the organizational perspective analysis. we employ bpic-2012-app and bpic-2017-app for the organizational perspective.
table 10 shows some statistics about the variants with respect to different perspectives. for example, as mentioned, in sepsis-cases,
80% of traces are unique from the activity perspective, or in bpic-2017-app, 76% of traces are unique from the resource perspective.
overall, we performed more than 1000 experiments for the four different types of background knowledge and different
perspectives. 200 different settings are used based on the following values for the main parameters: 𝐿∈ {2,3,4,5,6},𝐾∈
{20,30,40,50,60},𝐶∈ {0.2,0.3,0.4,0.5}, and𝑇∈ {ℎ𝑜𝑢𝑟𝑠,𝑚𝑖𝑛𝑢𝑡𝑒𝑠 }. we consider equal weights for the privacy gain and utility loss
13m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 5. the quality measures comparison between the four variants of 𝑇𝐿𝐾𝐶 and𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 , the original results, and the baseline methods for sepsis-cases.
aspects of the score, i.e., 𝛼= 0.5and𝛽= 0.5. in sepsis-cases, ‘‘diagnose" and ‘‘age" are considered as the sensitive case attribute.
the numerical attributes are converted to categorical attributes using boxplots such that all the values greater than the upper quartile
are categorized as high, the values less than the lower quartile are categorized as low, and the values in between are categorized as
middle . note that the confidence value 𝐶should not be greater than 0.5, i.e., there are at least two different sensitive values for a
victim case. to show and interpret the results of experiments, we focus on specific strong and weak settings. we use 𝑇=𝑚𝑖𝑛𝑢𝑡𝑒𝑠 ,
𝐿= 2,𝐾= 20, and𝐶= 0.5as the weak setting, and 𝑇=𝑚𝑖𝑛𝑢𝑡𝑒𝑠 ,𝐿= 6,𝐾= 60, and𝐶= 0.2as the strong setting. note that
in the experiments, 𝑇𝐿𝐾𝐶 refers to the algorithm presented in [5] which has been extended here w.r.t. the different perspectives,
i.e., algorithm 1, and 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 refers to algorithm 2.
6.2. control-flow perspective
in this subsection, we evaluate the effect of applying the extended 𝑇𝐿𝐾𝐶 -privacy on the result utility anddata utility with respect
to the control-flow perspective. we perform the control-flow perspective analysis for both event logs.
6.2.1. result utility
as mentioned, for the result utility analysis of the control-flow perspective, we focus on process discovery . the main goal is to
find out how accurately the discovered process model from a privacy-aware event log capture the behavior of the original event log . to this
end, we first discover a process model 𝑀′from the privacy-aware event log 𝐸𝐿′. then, for 𝑀′, we calculate fitness ,precision , and
f1-score , as some model quality measures, w.r.t. the original event log 𝐸𝐿.
fitness quantifies the extent to which the discovered model can reproduce the traces recorded in the event log [18]. precision
quantifies the fraction of the traces allowed by the model which is not seen in the event log [19], and f1-score combines the fitness
and precision 𝑓1-𝑠𝑐𝑜𝑟𝑒 =2×𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 ×𝑓𝑖𝑡𝑛𝑒𝑠𝑠 ∕𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 +𝑓𝑖𝑡𝑛𝑒𝑠𝑠 . for process discovery, we use the inductive miner infrequent algorithm [20]
with the default parameters (noise threshold 0.2). fig. 5 shows the results of experiments for the quality measures. we consider
four variants of our privacy preservation technique based on the introduced types of background knowledge where the attribute
isactivity , i.e.,𝑏𝑘𝑠𝑒𝑡,𝑎𝑡,𝑏𝑘𝑚𝑢𝑙𝑡,𝑎𝑡 ,𝑏𝑘𝑠𝑒𝑞,𝑎𝑡, and𝑏𝑘𝑟𝑒𝑙,𝑎𝑡. note that applying privacy preservation techniques may improve some quality
measures. however, the aim is to provide as similar results as possible to the original ones and not to improve the quality of
discovered models. therefore, we include the results from the original event log to compare the proximity of the values.
figs. 5(a) and 5(b) show how the mentioned quality measures are affected by applying our method with the weak and strong
settings (for 𝑇𝐿𝐾𝐶 , we set𝛩= 0.5). we compare the measures with the results from the original process model and the introduced
baseline methods. if we only consider the quality measures, baseline -2 should be marked as the best one, since it results in better
f1-score values. however, the baseline methods remove more events from the original event log. consequently, the corresponding
privacy-aware event logs contain significantly less behavior compared to the original event log, and the resulting models have high
precision and f1-score . the result utility analyses show that the extended version of the 𝑇𝐿𝐾𝐶 -privacy leads to the more similar
results to the original ones, specifically for the setandmultiset types of background knowledge. however, the results obtained based
on the relative type of background knowledge have a worse fitness value which is not surprising regarding the assumed background
knowledge which is considerably strong, at the same time, difficult to achieve in reality. note that the baseline methods do not
protect event data against the attribute linkage attack and provide weaker privacy guarantees.
6.2.2. data utility
for the data utility analysis, we utilize the earth mover’s distance , as proposed in [8]. the earth mover’s distance describes the
distance between two distributions [21]. in an analogy, given two piles of earth, it describes the effort required to transform one
pile into the other. assuming 𝐸𝐿as the original event log, 𝐸𝐿′as a privacy-aware event log, and 𝑝𝑠∈as the perspective of
analysis. the data utility is calculated as follows: 𝑑𝑢(𝐸𝐿,𝐸𝐿′) = 1−min𝑟∈𝑢𝑙(𝑟,𝐸𝐿𝑝𝑠,𝐸𝐿′𝑝𝑠)where𝑢𝑙(𝑟,𝐸𝐿𝑝𝑠,𝐸𝐿′𝑝𝑠)is the distance
between the traces of two event logs projected on the given perspective. note that 𝑟∈is used as a reallocation function, and
normalized edit distance (levenshtein) [22] is used to calculate the distance between variants. it should also be noted that for the
control-flow 𝑝𝑠=.
14m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 6. the data utility comparison between 𝑇𝐿𝐾𝐶 and𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 which provide the same privacy guarantees for the sepsis-cases event log.
fig. 7. the data and result utility analyses for bpic-2012-app considering the strong setting.
fig. 6 shows the results of data utility analysis where we compare 𝑇𝐿𝐾𝐶 and𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 which provide the same privacy
guarantees. as can be seen, for the weak privacy setting, the data utility results are similar, and 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 performs slightly
better for the stronger types of background knowledge. for the strong privacy setting, 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 performs considerably better
for the multiset and sequence types of background knowledge. comparing the data utility analysis with the result utility analysis
shows that the model quality measures alone cannot precisely evaluate the effectiveness of the privacy preservation techniques.
for example, in the result utility analysis, for both weak and strong setting, 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 results in an acceptable f1-score value.
however, the data utility analysis shows that the utility loss is indeed high for this type of background knowledge.
as already mentioned, the sepsis-cases event log is a significantly challenging dataset for the privacy preservation techniques
due to the high uniqueness of variants. to show the effectiveness of our privacy preservation technique on other event logs, we
perform the same type of analyses for bpic-2012-app considering only the strong setting. fig. 7 shows that both data and result
utility are high even for the strong types of background knowledge.
6.3. organizational perspective
in this subsection, we evaluate the effect of applying the extended 𝑇𝐿𝐾𝐶 -privacy on the result and data utility of the
organizational perspective. the experiments of this perspective are done on bpic-2012-app which includes resource information.
6.3.1. result utility
for the result utility analysis of organizational perspective, we focus on the social network discovery techniques. there are different
methods for discovering social networks from event logs such as causality-based ,joint activities ,joint cases , etc [23]. here, we focus
on the handover technique which is causality-based. this technique monitors for individual cases how work moves from resource to
resource, i.e., there is a handover relation from individual 𝑟1to individual 𝑟2, if there are two subsequent activities where the first
is performed by 𝑟1and the second is performed by 𝑟2.
fig. 8 shows the handover networks discovered from the original event log and a privacy-aware event log when the relation
threshold is 0, i.e., all the handovers. the privacy-aware event log was obtained using the 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 privacy preservation
technique with the strong setting and setas the type of background knowledge. as expected, the density of the network discovered
from the privacy-aware event log is less than the original handover network. however, by focusing on some specific nodes, one can
15m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 8. the handover networks discovered from the original event log and a privacy-aware event log for bpic-2012-app. the privacy-aware event log was
obtained using 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 with the strong setting and setas the type of background knowledge.
see that basic concepts are preserved. for example, node 11339 in the original handover network has the following set of input links
{11302,11003,11300,11121,11122,11180,10932,10861} and no output link (excluding the self-loop), and in the network discovered
from the privacy-aware event log, only the input link from node 11121 is removed.
to quantify the similarity of social networks resulting from an original and a privacy-aware event log, we use a set of
measures similar to the quality measure of process models, i.e., fitness ,precision , and f1-score . consider 𝑆𝑁 = (𝑅𝐸𝐿,𝐷𝐹𝐸𝐿
)and
𝑆𝑁′= (𝑅𝐸𝐿′,𝐷𝐹𝐸𝐿′
)as the handover social networks obtained from an original event log and its corresponding privacy-aware
event log, respectively. since both 𝑇𝐿𝐾𝐶 and𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 provide privacy guarantees by removing events, the vertices of 𝑆𝑁′is a
subset of vertices in 𝑆𝑁, i.e.,𝑅𝐸𝐿⊆𝑅𝐸𝐿′. however, the set of edges in 𝑆𝑁′is not necessarily a subset of edges in 𝑆𝑁, i.e.,𝑆𝑁′is
not necessarily a subgraph of 𝑆𝑁. the following equations are used to compute the fitness (𝐹𝑠𝑛) and the precision (𝑃𝑠𝑛) for handover
networks. the f1-score for handover networks ( 𝐹1𝑠𝑛) is the harmonic mean of 𝐹𝑠𝑛and𝑃𝑠𝑛.
𝐹𝑠𝑛=∑
(𝑥,𝑦)∈𝐷𝐹𝐸𝐿
∩𝐷𝐹𝐸𝐿′
|𝑥>𝐸𝐿′
𝑦|
∑
(𝑥,𝑦)∈𝐷𝐹𝐸𝐿
|𝑥>𝐸𝐿
𝑦|
𝑃𝑠𝑛=|(𝑅𝐸𝐿×𝑅𝐸𝐿)⧵𝐷𝐹𝐸𝐿
∩ (𝑅𝐸𝐿×𝑅𝐸𝐿)⧵𝐷𝐹𝐸𝐿′
|
|(𝑅𝐸𝐿×𝑅𝐸𝐿)⧵𝐷𝐹𝐸𝐿
|
16m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 9. the social network comparison based on fitness (𝐹𝑠𝑛),precision (𝑃𝑠𝑛), and f1-score (𝐹1𝑠𝑛). the privacy preservation technique is 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 with the
strong setting.
fig. 10. the data utility analysis of organizational perspective for bpic-2012-app with the strong and weak settings considering different types of background
knowledge, and using 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 as the privacy preservation technique.
fig. 9 shows the similarity of handover social networks after applying the 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 privacy model with the strong setting
to bpic-2012-app and bpic-2017-app. the precision is high for all the types of background knowledge, i.e., the handover social
networks obtained from the privacy-aware event logs often do not contain edges that do not exist in the original network. the
fitness decreases when the background knowledge becomes stronger, i.e., the 𝑆𝑁′s obtained based on stronger assumptions for the
background knowledge have fewer edges in common with the 𝑆𝑁.
6.3.2. data utility
for the data utility analysis of the organizational perspective, we utilize the earth mover’s distance, similar to the data utility
analysis of the control-flow perspective. here, the perspective is resource, i.e., 𝑝𝑠=. fig. 10 shows the results for the data utility
analysis for bpic-2012-app considering different types of background knowledge using 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 as the privacy preservation
technique. as can be seen, the data utility reservation is above 0.5 even for the strong types of background knowledge.
6.4. time perspective
we evaluate the effect on performance analyses by analyzing the bottlenecks w.r.t. the mean duration of cases between activities.
since the privacy preservation techniques may remove some activities, we cannot compare the bottlenecks in the original process
model with the bottlenecks in a process model discovered from a privacy-aware event log. therefore, we first project the original
event log on the activities existing in the privacy-aware event log. then, we discover a performance-annotated directly follows
graph𝐷𝐹𝐺 from the projected event log and compare it with the performance-annotated directly follows graph 𝐷𝐹𝐺′from the
privacy-aware event log. a dfg is a graph where the nodes represent activities and the arcs represent causalities. two activities 𝑎1
and𝑎2are connected by an arrow when 𝑎1is frequently followed by 𝑎2[24].
fig. 11 ( setand multiset as the types of background knowledge) and fig. 12 ( sequence and relative as the types of background
knowledge) show the results for sepsis-cases using 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 with the strong setting.2as can be seen, the bottlenecks in 𝐷𝐹𝐺
and𝐷𝐹𝐺′are the same for all the variants, except for dfgs discovered using 𝑏𝑘𝑟𝑒𝑙,𝑎𝑐, where the assumed background knowledge
2the results provided by disco (https://fluxicon.com/disco/) with the sliders set to the maximal number of activities and the minimal paths.
17m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 11. the performance-annotated dfgs from the projected event log ( 𝐷𝐹𝐺 ) and an anonymized event log ( 𝐷𝐹𝐺′) for sepsis-cases using 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 with
the strong setting and the specified types of background knowledge.
fig. 12. the performance-annotated dfgs from the projected event log ( 𝐷𝐹𝐺 ) and an anonymized event log ( 𝐷𝐹𝐺′) for sepsis-cases using 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 with
the strong setting and the specified types of background knowledge.
isrelative which is significantly strong and our data utility analysis in section 6.2 demonstrated a low data utility preservation
for sepsis-cases. note that the mean duration of the cases are different in 𝐷𝐹𝐺 and𝐷𝐹𝐺′due to the relative timestamps in the
privacy-aware event logs.
we also evaluate the similarity of the directly follows graphs (dfgs) resulting from an original event log and its corresponding
privacy-aware event log. let 𝐷𝐹𝐺 =(𝐴𝐸𝐿,𝐷𝐹𝐸𝐿
)and𝐷𝐹𝐺′=(𝐴𝐸𝐿′,𝐷𝐹𝐸𝐿′
)be the directly follows graphs obtained from an original
and its corresponding privacy-aware event logs, respectively. to compare these graphs, we follow the same approach taken for
quantifying the similarity of social networks. the fitness (𝐹𝑑𝑓𝑔) and precision (𝑃𝑑𝑓𝑔) for dfgs are calculated as follows:
𝐹𝑑𝑓𝑔=∑
(𝑥,𝑦)∈𝐷𝐹𝐸𝐿
∩𝐷𝐹𝐸𝐿′
|𝑥>𝐸𝐿′
𝑦|
∑
(𝑥,𝑦)∈𝐷𝐹𝐸𝐿
|𝑥>𝐸𝐿
𝑦|
𝑃𝑑𝑓𝑔=|(𝐴𝐸𝐿×𝐴𝐸𝐿)⧵𝐷𝐹𝐸𝐿
∩ (𝐴𝐸𝐿×𝐴𝐸𝐿)⧵𝐷𝐹𝐸𝐿′
|
|(𝐴𝐸𝐿×𝐴𝐸𝐿)⧵𝐷𝐹𝐸𝐿
|
the f1-score for dfgs (𝐹1𝑑𝑓𝑔) is the harmonic mean of 𝐹𝑑𝑓𝑔and𝑃𝑑𝑓𝑔. fig. 13 shows the similarity of dfgs after applying the
𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 privacy model with the strong setting for sepsis-cases, bpic-2012-app, and bpic-2017-app. the precision is always
high, i.e., the dfgs obtained from the privacy-aware event logs often do not contain directly follows relations that do not exist in the
18m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 13. the dfg comparison based on fitness (𝐹𝑑𝑓𝑔),precision (𝑃𝑑𝑓𝑔), and f1-score (𝐹1𝑑𝑓𝑔). the privacy preservation technique is 𝑇𝐿𝐾𝐶 -𝐸𝑋𝑇 with the strong
setting.
original dfg. for the sepsis-cases event log, the fitness decreases when the background knowledge becomes stronger, i.e., the 𝐷𝐹𝐺′s
obtained based on stronger assumptions for the background knowledge preserve fewer directly follows relations of the original dfg.
the fitness for the bpic event logs only drops for the relative type of background knowledge which is considerably strong.
7. related work
in process mining, the research field of confidentiality and privacy is recently receiving more attention. in this section, we list the
work that has been done in this research field which is rapidly growing. in [25], responsible process mining (rpm) is introduced as
the sub-discipline which focuses on possible negative side-effects of applying process mining where fairness ,accuracy ,confidentiality ,
andtransparency (fact) are considered as the concerns. in [26], the authors provide an overview of privacy challenges in process
mining in human-centered industrial environments. in [27], a method to secure event logs for performing process discovery by the
alpha algorithm is proposed. in [28], the aim is to propose a solution which allows the outsourcing of process mining while ensuring
confidentiality. in [29], the goal is to propose a privacy-preserving system design for process mining, where a user-centered view
is considered to track personal data. in [30,31], a framework is proposed which provides a generic scheme for confidentiality in
process mining. in [32], the authors introduce a privacy-preserving method for discovering roles from event logs. in [33], the authors
consider a cross-organizational process discovery context and share public process model fragments as safe intermediates. in [13],
the authors apply 𝑘-anonymity and 𝑡-closeness on event logs to preserve the privacy of resources . in [16,34], the notion of differential
privacy is employed to preserve the privacy of event logs. in [5], the 𝑇𝐿𝐾𝐶 -privacy is introduced to cope with high variability issues
in event logs for applying group-based anonymization techniques. in [35], a uniformization-based approach is proposed to preserve
individuals’ privacy in process mining. in [36], a secure multi-party computation solution is introduces for preserving privacy in
an inter-organizational setting for process discovery . in [37], the data privacy and utility requirements for healthcare event data are
analyzed. in [38], the authors propose a privacy extension for the xes standard3to manage privacy metadata. in [39], the authors
propose a measure to evaluate the re-identification risk of event logs. also, in [8], a general privacy quantification framework, and
some measures are introduced to evaluate the effectiveness of privacy preservation techniques. some tools are also provided for
applying the state-of-the-art privacy preservation techniques in the field of process mining such as ppdp-pm [40], elpaas [41], and
shareprom [42].
3https://xes-standard.org/.
19m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
8. conclusion
in this paper, we discussed the challenges regarding directly applying traditional group-based privacy preservation techniques
to event logs. we discussed the linkage attacks and provided formal models of the possible attacks based on the different types of
background knowledge. we extended the 𝑇𝐿𝐾𝐶 -privacy for process mining to cover all the main perspectives of process mining.
the data utility preservation aspect of the 𝑇𝐿𝐾𝐶 -privacy was improved by introducing a new utility measure. moreover, a new score
equation was proposed to generate normalized scores for the events that need to be removed. the new equation for the score also
provides privacy gain andutility loss coefficients that can be adjusted by users. obviously, the extended version of the 𝑇𝐿𝐾𝐶 -privacy
inherits all the characteristics of the main approach. namely, it counteracts both the case linkage and the attribute linkage attacks. it
generalizes several privacy preservation techniques including 𝑘-anonymity, confidence bounding, ( 𝛼,𝑘)-anonymity, and 𝑙-diversity.
it also provides interpretable and tunable parameters.
similar to the main approach, we implemented four variants of the extended version with respect to the four different types of
background knowledge and considering all the main perspectives. the effectiveness of different variants in different perspectives
was evaluated based on real-life event logs. both data and result utility were analyzed to evaluate the effectiveness. overall more
than 1000 experiments were performed for different types of background knowledge considering different perspectives, and the
results were given for a weak and a strong setting. our experiments showed that the extended 𝑇𝐿𝐾𝐶 -privacy performs better than
the previous version considering the data utility preservation aspect. however, in the event logs with the high ratio of unique traces,
when the assumed type of background knowledge is very specific, e.g., relative , the group-based privacy preservation techniques
may not be able to preserve the general data utility, and this negative effect cannot be observed by only result utility analyses.
credit authorship contribution statement
majid rafiei: conceptualization, methodology, software, validation, formal analysis, investigation, resources, data curation,
writing - original draft, writing - review & editing, visualization. wil m.p. van der aalst: conceptualization, methodology,
validation, formal analysis, resources, data curation, writing - review & editing, visualization, supervision, project administration.
declaration of competing interest
the authors declare that they have no known competing financial interests or personal relationships that could have appeared
to influence the work reported in this paper.
acknowledgment
funded under the excellence strategy of the federal government and the länder, germany. we also thank the alexander von
humboldt (avh) stiftung for supporting our research.
references
[1] w.m.p. van der aalst, process mining - data science in action, second ed., springer, 2016, http://dx.doi.org/10.1007/978-3-662-49851-4.
[2] w.g. voss, european union data privacy law reform: general data protection regulation, privacy shield, and the right to delisting, bus. lawyer 72 (1)
(2016).
[3] l. sweeney, k-anonymity: a model for protecting privacy, int. j. uncertain. fuzziness knowl.-based syst. 10 (05) (2002) 557–570.
[4] a. machanavajjhala, j. gehrke, d. kifer, m. venkitasubramaniam, l-diversity: privacy beyond k-anonymity, in: 22nd international conference on data
engineering, icde’06, ieee, 2006, p. 24.
[5] m. rafiei, m. wagner, w.m.p. van der aalst, tlkc-privacy model for process mining, in: f. dalpiaz, j. zdravkovic, p. loucopoulos (eds.), research
challenges in information science - 14th international conference, rcis 2020, limassol, cyprus, september 23–25, 2020, proceedings, in: lecture notes
in business information processing, vol. 385, springer, 2020, pp. 398–416, http://dx.doi.org/10.1007/978-3-030-50316-1_24.
[6] k. wang, b.c.m. fung, p.s. yu, handicapping attacker’s confidence: an alternative to k-anonymization, knowl. inf. syst. 11 (3) (2007) 345–368,
http://dx.doi.org/10.1007/s10115-006-0035-5.
[7] r.c. wong, j. li, a.w. fu, k. wang, (alpha, k)-anonymity: an enhanced k-anonymity model for privacy preserving data publishing, in: t. eliassi-rad, l.h.
ungar, m. craven, d. gunopulos (eds.), proceedings of the twelfth acm sigkdd international conference on knowledge discovery and data mining,
philadelphia, pa, usa, august 20–23, 2006, acm, 2006, pp. 754–759, http://dx.doi.org/10.1145/1150402.1150499.
[8] m. rafiei, w.m.p. van der aalst, towards quantifying privacy in process mining, in: international conference on process mining - icpm 2020 international
workshops, padua, italy, october 4–9, 2020, 2020.
[9] n. li, t. li, s. venkatasubramanian, t-closeness: privacy beyond k-anonymity and l-diversity, in: r. chirkova, a. dogac, m.t. özsu, t.k. sellis (eds.),
proceedings of the 23rd international conference on data engineering, icde 2007, the marmara hotel, istanbul, turkey, april 15–20, 2007, ieee computer
society, 2007, pp. 106–115, http://dx.doi.org/10.1109/icde.2007.367856.
[10] c.c. aggarwal, s.y. philip, privacy-preserving data mining: models and algorithms, springer science & business media, 2008.
[11] c.c. aggarwal, on k-anonymity and the curse of dimensionality, in: k. böhm, c.s. jensen, l.m. haas, m.l. kersten, p. larson, b.c. ooi (eds.), proceedings
of the 31st international conference on very large data bases, trondheim, norway, august 30 - september 2, 2005, acm, 2005, pp. 901–909.
[12] j. gehrke, models and methods for privacy-preserving data analysis and publishing, in: l. liu, a. reuter, k. whang, j. zhang (eds.), proceedings
of the 22nd international conference on data engineering, icde 2006, 3–8 april 2006, atlanta, ga, usa, ieee computer society, 2006, p. 105,
http://dx.doi.org/10.1109/icde.2006.100.
[13] s.a. fahrenkrog-petersen, h. van der aa, m. weidlich, pretsa: event log sanitization for privacy-aware process discovery, in: international conference
on process mining, icpm 2019, aachen, germany, june 24–26, 2019, ieee, 2019, pp. 1–8, http://dx.doi.org/10.1109/icpm.2019.00012.
[14] f. mannhardt, sepsis cases-event log. eindhoven university of technology, 2016, https://doi.org/10.4121/uuid:915d2bfb-7e84-49ad-a286-dc35f063a460.
[15] b.f. van dongen, bpic 2012. eindhoven university of technology, 2012, http://dx.doi.org/10.4121/uuid:3926db30-f712-4394-aebc-75976070e91f.
20m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
[16] f. mannhardt, a. koschmider, n. baracaldo, m. weidlich, j. michael, privacy-preserving process mining - differential privacy for event logs, bus. inf. syst.
eng. 61 (5) (2019) 595–614, http://dx.doi.org/10.1007/s12599-019-00613-3.
[17] b.f. van dongen, bpic 2017. eindhoven university of technology, 2017, https://doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b.
[18] a. adriansyah, b.f. van dongen, w.m.p. van der aalst, conformance checking using cost-based fitness analysis, in: proceedings of the 15th ieee international
enterprise distributed object computing conference, edoc, 2011, pp. 55–64.
[19] a. adriansyah, j. munoz-gama, j. carmona, b.f. van dongen, w.m.p. van der aalst, measuring precision of modeled behavior, inf. syst. e-business
management 13 (1) (2015) 37–67.
[20] s.j.j. leemans, d. fahland, w.m.p. van der aalst, discovering block-structured process models from event logs containing infrequent behaviour, in: business
process management workshops - bpm international workshops, 2013, pp. 66–78.
[21] l. rüschendorf, the wasserstein distance and approximation theorems, probab. theory related fields 70 (1) (1985) 117–129.
[22] v.i. levenshtein, binary codes capable of correcting deletions, insertions, and reversals, in: soviet physics doklady, vol. 10, 1966, pp. 707–710.
[23] w.m.p. van der aalst, h.a. reijers, m. song, discovering social networks from event logs, comput. support. coop. work (cscw) 14 (6) (2005) 549–593.
[24] s.j. leemans, d. fahland, w.m.p. aalstvan der aalst, scalable process discovery and conformance checking, softw. syst. model. 17 (2) (2018) 599–631.
[25] w.m.p. van der aalst, responsible data science: using event data in a ‘‘people friendly’’ manner, in: s. hammoudi, l.a. maciaszek, m. missikoff, o. camp,
j. cordeiro (eds.), enterprise information systems - 18th international conference, iceis 2016, rome, italy, april 25–28, 2016, revised selected papers,
in: lecture notes in business information processing, vol .291, springer, 2016, pp. 3–28, http://dx.doi.org/10.1007/978-3-319-62386-3_1.
[26] f. mannhardt, s.a. petersen, m.f. oliveira, privacy challenges for process mining in human-centered industrial environments, in: 14th international
conference on intelligent environments, ie 2018, roma, italy, june 25–28, 2018, ieee, 2018, pp. 64–71, http://dx.doi.org/10.1109/ie.2018.00017.
[27] g. tillem, z. erkin, r.l. lagendijk, privacy-preserving alpha algorithm for software analysis, in: 37th wic symposium on information theory in the
benelux/6th wic/ieee sp, 2016.
[28] a. burattin, m. conti, d. turato, toward an anonymous process mining, in: future internet of things and cloud (ficloud), 2015 3rd international
conference on, ieee, 2015, pp. 58–63.
[29] j. michael, a. koschmider, f. mannhardt, n. baracaldo, b. rumpe, user-centered and privacy-driven process mining system design for iot, in: c. cappiello,
m. ruiz (eds.), information systems engineering in responsible information systems - caise forum 2019, rome, italy, june 3–7, 2019, proceedings, in:
lecture notes in business information processing, vol. 350, springer, 2019, pp. 194–206, http://dx.doi.org/10.1007/978-3-030-21297-1_17.
[30] m. rafiei, l. von waldthausen, w.m.p. van der aalst, ensuring confidentiality in process mining, in: p. ceravolo, m.t.g. lópez, m. van keulen (eds.),
proceedings of the 8th international symposium on data-driven process discovery and analysis (simpda 2018), seville, spain, december 13–14, 2018,
in: ceur workshop proceedings, vol. 2270, ceur-ws.org, 2018, pp. 3–17.
[31] m. rafiei, l. von waldthausen, w.m.p. van der aalst, supporting confidentiality in process mining using abstraction and encryption, in: p. ceravolo, m.
van keulen, m.t.g. lópez (eds.), data-driven process discovery and analysis - 8th ifip wg 2.6 international symposium, simpda 2018, seville, spain,
december 13–14, 2018, and 9th international symposium, simpda 2019, bled, slovenia, september 8, 2019, revised selected papers, in: lecture notes
in business information processing, vol. 379, springer, 2019, pp. 101–123, http://dx.doi.org/10.1007/978-3-030-46633-6_6.
[32] m. rafiei, w.m.p. van der aalst, mining roles from event logs while preserving privacy, in: c.d. francescomarino, r.m. dijkman, u. zdun (eds.), business
process management workshops - bpm 2019 international workshops, vienna, austria, september 1–6, 2019, revised selected papers, in: lecture notes
in business information processing, vol. 362, springer, 2019, pp. 676–689, http://dx.doi.org/10.1007/978-3-030-37453-2_54.
[33] c. liu, h. duan, q. zeng, m. zhou, f. lu, j. cheng, towards comprehensive support for privacy preservation cross-organization business process mining,
ieee trans. serv. comput. 12 (4) (2019) 639–653, http://dx.doi.org/10.1109/tsc.2016.2617331.
[34] s.a. fahrenkrog-petersen, h. van der aa, m. weidlich, pripel: privacy-preserving event log publishing including contextual information, in: d. fahland,
c. ghidini, j. becker, m. dumas (eds.), business process management - 18th international conference, bpm 2020, seville, spain, september 13–18, 2020,
proceedings, in: lecture notes in computer science, vol. 12168, springer, 2020, pp. 111–128, http://dx.doi.org/10.1007/978-3-030-58666-9_7.
[35] e. batista, a. solanas, a uniformization-based approach to preserve individuals’ privacy during process mining analyses, peer-to-peer netw. appl. (2021)
1–20.
[36] g. elkoumy, s.a. fahrenkrog-petersen, m. dumas, p. laud, a. pankova, m. weidlich, secure multi-party computation for inter-organizational process
mining, in: s. nurcan, i. reinhartz-berger, p. soffer, j. zdravkovic (eds.), enterprise, business-process and information systems modeling - 21st international
conference, bpmds 2020, 25th international conference, emmsad 2020, held at caise 2020, grenoble, france, june 8–9, 2020, proceedings, in: lecture
notes in business information processing, vol. 387, springer, 2020, pp. 166–181, http://dx.doi.org/10.1007/978-3-030-49418-6_11.
[37] a. pika, m.t. wynn, s. budiono, a.h.m. ter hofstede, w.m.p. van der aalst, h.a. reijers, towards privacy-preserving process mining in healthcare,
in: c.d. francescomarino, r.m. dijkman, u. zdun (eds.), business process management workshops - bpm 2019 international workshops, vienna,
austria, september 1–6, 2019, revised selected papers, in: lecture notes in business information processing, vol. 362, springer, 2019, pp. 483–495,
http://dx.doi.org/10.1007/978-3-030-37453-2_39.
[38] m. rafiei, w.m.p. van der aalst, privacy-preserving data publishing in process mining, 2021, corr abs/2101.02627, https://arxiv.org/abs/2101.02627.
[39] s.n. von voigt, s.a. fahrenkrog-petersen, d. janssen, a. koschmider, f. tschorsch, f. mannhardt, o. landsiedel, m. weidlich, quantifying the
re-identification risk of event logs for process mining - empiricial evaluation paper, in: advanced information systems engineering, caise, 2020.
[40] m. rafiei, w.m.p. van der aalst, practical aspect of privacy-preserving data publishing in process mining, 2020, corr abs/2009.11542, https://arxiv.org/
abs/2009.11542.
[41] m. bauer, s.a. fahrenkrog-petersen, a. koschmider, f. mannhardt, h. van der aa, m. weidlich, elpaas: event log privacy as a service, in: proceedings
of the dissertation award, doctoral consortium, and demonstration track at bpm 2019, 2019.
[42] g. elkoumy, s.a. fahrenkrog-petersen, m. dumas, p. laud, a. pankova, m. weidlich, shareprom: a tool for privacy-preserving inter-organizational process
mining, in: proceedings of the best dissertation award, doctoral consortium, and demonstration & resources track at bpm 2020 co-located with the
18th international conference on business process management (bpm 2020), sevilla, spain, september 13–18, 2020, in: ceur workshop proceedings, vol.
2673, ceur-ws.org, 2020, pp. 72–76.
majid rafiei is a scientific assistant (ph.d. candidate) at the chair of process and data science (pads) - rwth aachen university. he is graduated as master of
engineering in electronic commerce from amirkabir university of technology, tehran. currently he is working on process mining and specifically on responsible
process mining (rpm), where the aim is to use process mining with respect to fairness, accuracy, confidentiality, and transparency (fact).
prof.dr.ir. wil van der aalst is a full professor at rwth aachen university leading the process and data science (pads) group. he is also part-time affiliated
with the technische universiteit eindhoven (tu/e). until december 2017, he was the scientific director of the data science center eindhoven (dsc/e) and led
the architecture of information systems group at tu/e. since 2003, he holds a parttime position at queensland university of technology (qut). currently, he
is also a distinguished fellow at fondazione bruno kessler (fbk) in trento and a member of the board of governors of tilburg university.
21