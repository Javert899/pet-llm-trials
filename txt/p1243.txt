preprint data & knowledge engineering 134 (2021) 101908
group-based
privacy preservation techniques for process mining
majid rafieiâˆ—,wil m.p. van der aalst
chair of process and data science, rwth aachen university, aachen, germany
a
r t i c l e i n f o
keywords:
responsible
process mining
privacy preservation
result utility
data utility
event dataa b s t r a c t
process
mining techniques help to improve processes using event data. such data are widely
available in information systems. however, they often contain highly sensitive information.
for example, healthcare information systems record event data that can be utilized by process
mining techniques to improve the treatment process, reduce patientâ€™s waiting times, improve
resource productivity, etc. however, the recorded event data include highly sensitive informa-
tion related to treatment activities. responsible process mining should provide insights about
the underlying processes, yet, at the same time, it should not reveal sensitive information. in
this paper, we discuss the challenges regarding directly applying existing well-known group-
based privacy preservation techniques, e.g., ğ‘˜-anonymity, ğ‘™-diversity, etc, to event data. we
provide formal definitions of attack models and introduce an effective group-based privacy
preservation technique for process mining. our technique covers the main perspectives of process
mining including control-flow, time, case, and organizational perspectives. the proposed technique
provides interpretable and adjustable parameters to handle different privacy aspects. we employ
real-life event data and evaluate both data utility and result utility to show the effectiveness
of the privacy preservation technique. we also compare this approach with other group-based
approaches for privacy-preserving event data publishing.
1.
introduction
process mining employs event data to discover, analyze, and improve the real processes [1]. indeed, it provides fact-based insights
into the actual processes using event logs. there are many algorithms and techniques in the field of process mining. however, the
three basic types of process mining are (1) process discovery , where the goal is to learn real process models from event logs, (2)
conformance checking, where the aim is to find commonalities and discordances between a process model and an event log, and (3)
process re-engineering (enhancement ), where the aim is to extend or improve a process model using different aspects of the available
data.
an event log is a collection of events where each event is described by its attributes [1]. the typical attributes required for the
main process mining algorithms are case identifier, activity, timestamp, and resource. the case identifier refers to the entity that the
event belongs to, the activity refers to the activity associated with the event, the timestamp is the time that the event occurred, and
theresource is the activity performer. in the human-centered processes, case identifiers refer to persons. for example, in a patient
treatment process, the case identifiers refer to the patients whose data are recorded. moreover, the resource attribute often refers to
the persons performing activities, e.g., in the healthcare context, the resources refer to the doctors or nurses performing activities
for the patients. the event attributes are not limited to the above-mentioned ones, and an event may also carry other case-related
attributes, so-called case attributes, e.g., age,salary, disease, etc, which could be considered as sensitive person-specific information.
table 1 shows a sample event log.
âˆ—corresponding
author.
e-mail address: majid.rafiei@pads.rwth-aachen.de (m. rafiei).
https://doi.org/10.1016/j.datak.2021.101908
received 30 november 2020; received in revised form 1 april 2021; accepted 25 may 2021
available online 7 june 2021
0169-023x/Â© 2021 the author(s). published by elsevier b.v. this is an open access article under the cc by license
(http://creativecommons.org/licenses/by/4.0/).m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 1. the general overview of privacy-related activities in process mining. privacy preservation techniques are applied to event logs to mitigate disclosure
risks. the data and result utility analyses are used to evaluate the effectiveness of the techniques where the goal is to balance utility loss and privacy gain.
orthogonal to the three mentioned types of process mining, different perspectives are also defined including control-flow ,
organizational ,case, and timeperspective [1]. the control-flow perspective focuses on activities and their order, which are often utilized
byprocess discovery and conformance checking techniques. the organizational perspective focuses on resources and their relations,
which are exploited by social network discovery techniques. the case perspective is focused on case-related attributes, and the time
perspective is concerned with the time-related information, which can be used for performance and bottleneck analyses .
with respect to the main attributes of events, two different perspectives for privacy in process mining can be considered in
the human-centered processes; resource perspective and case perspective . the resource perspective focuses on the privacy rights of the
individuals performing activities, and the case perspective concerns the privacy rights of the individuals whose data are recorded and
analyzed. depending on the context, the relative importance of these perspectives may differ. however, often the case perspective is
more critical for privacy than the resource perspective . for example, in the healthcare context, activity performers could be publicly
available. however, what happens for a specific patient and her/his personal information should be kept private. in this paper, we
are focused on the case perspective . in principle, when event logs explicitly or implicitly include personal data, privacy concerns appear
which should be taken into account according to regulations such as the european general data protection regulation (gdpr) [2].
in this paper, we describe disclosure risks andlinkage attacks against event logs. the attack models are formally defined based on
the available event attributes. we discuss the challenges regarding directly applying group-based privacy preservation techniques,
e.g.,ğ‘˜-anonymity [3], ğ‘™-diversity [4], etc, to event logs. we extend the work described in [5], where the ğ‘‡ğ¿ğ¾ğ¶ -privacy is introduced
as an effective group-based privacy preservation technique for process mining. the ğ‘‡ğ¿ğ¾ğ¶ -privacy exploits some restrictions
regarding the availability of background knowledge in the real world to deal with process mining-specific challenges. this technique
is focused on control-flow ,time, and caseperspectives. ğ‘‡ğ¿ğ¾ğ¶ -privacy generalizes several traditional privacy preservation techniques,
such asğ‘˜-anonymity, confidence bounding [6], ( ğ›¼,ğ‘˜)-anonymity [7], and ğ‘™-diversity.
the extended privacy preservation technique covers all the main perspectives of process mining including control-flow ,time,case,
andorganizational perspectives. it empowers the adjustability of the proposed technique by adding new parameters to adjust privacy
guarantees and the loss of accuracy. moreover, a new utility measure is defined to tackle the drawbacks of the current approach. to
evaluate the extended technique, we employ real-life event logs and evaluate both data utility andresult utility . we also compare the
extendedğ‘‡ğ¿ğ¾ğ¶ -privacy with the main algorithm and other group-based approaches for privacy-preserving event data publishing.
our experiments show that the proposed approach maintains high data and result utility, assuming realistic types of background
knowledge. fig. 1 shows a general overview of privacy-related activities in process mining which are discussed in this paper.
the rest of the paper is organized as follows. in section 2, we explain the motivation and challenges. section 3 provides
preliminaries on event logs and different types of background knowledge. in section 4, we provide formal models of the attacks.
privacy preservation techniques are discussed in section 5. in section 6, the experiments are presented. section 7 outlines related
work, and section 8 concludes the paper.
2m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 1
sample event log (each row represents an event).
case id activity timestamp resource age disease
1 registration (re) 01.01.2019-08:30:00 employee 4 (e4) 22 flu
1 visit (vi) 01.01.2019-08:45:00 doctor 3 (d3) 22 flu
2 registration (re) 01.01.2019-08:46:00 employee 1 (e1) 30 infection
3 registration (re) 01.01.2019-08:50:00 employee 1 (e1) 32 infection
4 registration (re) 01.01.2019-08:55:00 employee 4 (e4) 29 poisoning
1 release (rl) 01.01.2019-08:58:00 employee 6 (e6) 22 flu
5 registration (re) 01.01.2019-09:00:00 employee 1 (e1) 35 cancer
2 hospitalization (ho) 01.01.2019-09:01:00 employee 3 (e3) 30 infection
6 registration (re) 01.01.2019-09:05:00 employee 4 (e4) 35 corona
4 visit (vi) 01.01.2019-09:10:00 doctor 2 (d2) 29 poisoning
5 visit (vi) 01.01.2019-09:20:00 doctor 2 (d2) 35 cancer
4 infusion (in) 01.01.2019-09:30:00 nurse 2 (n2) 29 poisoning
5 hospitalization (ho) 01.01.2019-09:55:00 employee 6 (e6) 35 cancer
3 hospitalization (ho) 01.01.2019-10:00:00 employee 3 (e3) 32 infection
2 blood test (bt) 01.01.2019-10:02:00 nurse 1 (n1) 30 infection
5 blood test (bt) 01.01.2019-10:10:00 nurse 2 (n2) 35 cancer
3 blood test (bt) 01.01.2019-10:15:00 nurse 1 (n1) 32 infection
6 visit (vi) 01.01.2019-10:20:00 doctor 3 (d3) 35 corona
4 release (rl) 01.01.2019-10:30:00 employee 6 (e6) 29 poisoning
6 release (rl) 01.01.2019-14:20:00 employee 6 (e6) 35 corona
2 blood test (bt) 01.02.2019-08:00:00 nurse 1 (n1) 30 infection
2 visit (vi) 01.02.2019-09:30:00 doctor 1 (d1) 30 infection
3 visit (vi) 01.02.2019-13:55:00 doctor 1 (d1) 32 infection
2 release (rl) 01.02.2019-14:00:00 employee 2 (e2) 30 infection
3 release (rl) 01.02.2019-14:15:00 employee 2 (e2) 32 infection
5 release (rl) 01.02.2019-16:00:00 employee 2 (e2) 35 cancer
2. motivation and challenges
to motivate the necessity to deal with privacy issues in process mining, we describe the disclosure risks using an example in the
health-care context. consider table 1 as part of an event log recorded by an information system in a hospital. note that each case
has a sequence of events that are ordered based on the timestamps. this sequence of events is called a trace which is a mandatory
attribute for a case [1]. for example, case 1, which could be interpreted as patient 1, is first registered by employee 4, then visited
by doctor 3, and at the end released from the hospital by employee 6.
suppose that an adversary knows that a victim patientâ€™s data are in the event log (as a case), with little information about some
event attributes that belongs to the patient, the adversary is able to connect the patient to the corresponding case id , so-called case
disclosure [8]. consequently, two types of sensitive person-specific information are revealed: (1) the complete sequence of events
belonging to the case, and (2) sensitive case attributes. (1) and (2) are generally called attribute disclosure . (1) is also called trace
disclosure that is a specific type of attribute disclosure [8]. for example, if the adversary knows that two blood tests were performed for
the victim patient, the only matching case is the case with id 2. this attack is called case linkage attack. after the case re-identification,
the sensitive case attributes are disclosed, e.g., the disease of patient 2 is infection . this is called attribute linkage attack. moreover, the
complete sequence of events performed for patient 2 is disclosed which contains private information, e.g., the complete sequence of
activities performed for the case, the resources who performed the activities for the case, or the exact timestamp of doing a specific
activity for the case. we call this attack trace linkage which is a specific type of attribute linkage attack.
note that the attribute linkage attack does not necessarily need to be launched after the case linkage , i.e., if more than one case
corresponds to the adversaries knowledge while all the matching cases have the same value for the sensitive case attribute(s) or
the same sequence of event attributes (e.g., the same sequence of activities), the attribute linkage /trace linkage could happen without
a successful case linkage attack. for example, if the adversary knows that the activity visit has been performed by the resource
doctor 3 for a victim patient, case 1 and case 6 match this background knowledge. however, they both have the same sequence
of activities and resources ( âŸ¨(ğ‘…ğ¸,ğ¸ 4),(ğ‘‰ğ¼,ğ· 3),(ğ‘…ğ¿,ğ¸ 6)âŸ©). consequently, the adversary realizes the complete sequence of activities
and the resources who performed the activities.
several group-based privacy preservation techniques, such as ğ‘˜-anonymity [3], ğ‘™-diversity [4], and ğ‘¡-closeness [9], have been
introduced to deal with similar attacks in the context of relational databases. in such techniques, the data attributes are classified into
four main categories including; explicit identifiers ,quasi-identifiers ,sensitive attributes , and non-sensitive attributes . the explicit identifiers
are the attributes that can be used to uniquely identify the data owner, e.g., national id. the quasi-identifiers are a set of attributes
that could be exploited to uniquely identify the data owner, e.g., {ğ‘ğ‘”ğ‘’,ğ‘”ğ‘’ğ‘›ğ‘‘ğ‘’ğ‘Ÿ,ğ‘§ğ‘–ğ‘ğ‘ğ‘œğ‘‘ğ‘’ }. the sensitive attributes consist of sensitive
person-specific information, e.g., disease or salary, and the non-sensitive attributes contain all the attributes that do not fall into the
previous three categories [10]. assuming that explicit identifiers suppressed or replaced with dummy identifiers, the group-based
privacy preservation techniques aim to perturb potential linkages by generalizing the records into equivalence classes, i.e., groups
of records, having the same values on the quasi-identifier . these techniques are effective for anonymizing relational data. however,
they are not easily applicable to event data due to some specific properties of event data.
in process mining, the explicit identifiers (i.e., actual case identifiers) do not need to be stored and processed, and case identifiers
are often dummy identifiers, e.g., incremental ids. as described in the above-mentioned examples, a trace can be considered as a
3m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
quasi-identifier and, at the same time, as a sensitive attribute . in other words, a complete sequence of events belonging to a case, is
sensitive person-specific information, at the same time, part of a trace, i.e., only some of the event attributes, can be exploited as a
quasi-identifier to launch case linkage and/or attribute linkage attacks.
thequasi-identifier role of traces in process mining causes significant challenges for group-based privacy preservation techniques
because of two specific properties of event data: the high variability of traces and the typical pareto distribution of traces . considering
only activity as the main event attribute in a trace, the variability of traces in an event log is high because of the following reasons:
(1) there could be tens of different activities which could happen in any order, (2) one activity or a bunch of activities could happen
repetitively, and (3) traces could contain any non-zero number of activities, i.e., various lengths. note that this variability becomes
even higher when events contain more attributes, e.g., resources. in an event log, trace variants are often distributed similarly to
the pareto distribution, i.e., few trace variants are frequent and many trace variants are unique. enforcing group-based privacy-
preserving approaches on little-overlapping and high-dimensional space is a significant challenge, and often valuable data needs to
be suppressed in order to achieve desired privacy requirements [11].
3. preliminaries
in this section, we provide formal definitions for event logs and background knowledge. these formal models will be used in
the remainder for describing the attack scenarios and the approach.
3.1. event log
we first introduce some basic notations. for a given set ğ´,ğ´âˆ—is the set of all finite sequences over ğ´, and îˆ®(ğ´)is the set of all
multisets over the set ğ´. forğ´1,ğ´2âˆˆîˆ®(ğ´),ğ´1âŠ†ğ´2if for allğ‘âˆˆğ´,ğ´1(ğ‘)â‰¤ğ´2(ğ‘). a finite sequence over ğ´of lengthğ‘›is a mapping
ğœâˆˆ {1,â€¦,ğ‘›}â†’ğ´, represented as ğœ=âŸ¨ğ‘1,ğ‘2,â€¦,ğ‘ğ‘›âŸ©whereğ‘ğ‘–=ğœ(ğ‘–)for any 1â‰¤ğ‘–â‰¤ğ‘›.|ğœ|denotes the length of the sequence. for
ğœ1,ğœ2âˆˆğ´âˆ—,ğœ1âŠ‘ğœ2ifğœ1is a subsequence of ğœ2, e.g.,âŸ¨ğ‘,ğ‘,ğ‘,ğ‘¥âŸ©âŠ‘âŸ¨ğ‘§,ğ‘¥,ğ‘,ğ‘,ğ‘,ğ‘,ğ‘,ğ‘,ğ‘,ğ‘¥ âŸ©. forğœâˆˆğ´âˆ—,{ğ‘âˆˆğœ}is the set of elements
inğœ, and [ğ‘âˆˆğœ]is the multiset of elements in ğœ, e.g., [ğ‘âˆˆâŸ¨ğ‘¥,ğ‘¦,ğ‘§,ğ‘¥,ğ‘¦ âŸ©] = [ğ‘¥2,ğ‘¦2,ğ‘§]. forğ‘¥= (ğ‘1,ğ‘2,â€¦,ğ‘ğ‘›) âˆˆğ´1Ã—ğ´2Ã—â‹¯Ã—ğ´ğ‘›,
ğœ‹ğ´ğ‘–(ğ‘¥) =ğ‘ğ‘–is the projection of the tuple ğ‘¥on the element from the domain ğ´ğ‘–,1â‰¤ğ‘–â‰¤ğ‘›.
definition 1 (process instance, trace ).we define îˆ¼=îˆ¯Ã—îˆ±âˆ—Ã—îˆ¿as the universe of all process instances. îˆ¯is the universe of case
identifiers. îˆ±=îˆ­Ã—îˆ¾Ã—î‰€is the universe of main event attributes for process mining where îˆ­is the universe of activities, îˆ¾is the
universe of resources, and î‰€is the universe of timestamps. îˆ¿âŠ†îˆ°1âˆªâ‹¯âˆªîˆ°ğ‘šis the universe of sensitive case attributes where îˆ°1,
.. .,îˆ°ğ‘šare the universes of different case attributes, e.g., disease, salary, age, etc. given a process instance ğ‘= (ğ‘,ğœ,ğ‘  ) âˆˆîˆ¼,ğœâˆˆîˆ±âˆ—
is called the trace attribute of the case ğ‘.
definition 2 (event log ).letîˆ¼=îˆ¯Ã—îˆ±âˆ—Ã—îˆ¿be the universe of process instances. an event log is ğ¸ğ¿âŠ† îˆ¼such that if (ğ‘1,ğœ1,ğ‘ 1) âˆˆğ¸ğ¿,
(ğ‘2,ğœ2,ğ‘ 2) âˆˆğ¸ğ¿, andğ‘1=ğ‘2, thenğœ1=ğœ2andğ‘ 1=ğ‘ 2, i.e., all the case identifiers are unique. moreover, if ğ‘= (ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿, then
ğœâ‰ âŸ¨âŸ©.
definition 3 (perspective, projection ).letîˆ¼=îˆ¯Ã—îˆ±âˆ—Ã—îˆ¿be the universe of process instances. ğ‘ğ‘ âˆˆ {îˆ­,îˆ¾,îˆ­Ã—îˆ¾,îˆ­Ã—î‰€,îˆ¾Ã—î‰€,îˆ­Ã—îˆ¾Ã—î‰€}
is a perspective which can be used to project traces of an event log ğ¸ğ¿âŠ† îˆ¼. forğœ=âŸ¨(ğ‘1,ğ‘Ÿ1,ğ‘¡1),â€¦,(ğ‘ğ‘›,ğ‘Ÿğ‘›,ğ‘¡ğ‘›)âŸ©âˆˆîˆ±âˆ—, such that there
exists (ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿,ğœ‹ğ‘ğ‘ (ğœ)is the projection of the trace on the given perspective, e.g., for ğ‘ğ‘ =îˆ­Ã—îˆ¾,ğœ‹ğ‘ğ‘ (ğœ) =âŸ¨(ğ‘1,ğ‘Ÿ1),â€¦,(ğ‘ğ‘›,ğ‘Ÿğ‘›)âŸ©
is the projection of the trace on the activities and resources. we denote îˆ¼îˆ¿= {îˆ­,îˆ¾,îˆ­Ã—îˆ¾,îˆ­Ã—î‰€,îˆ¾Ã—î‰€,îˆ­Ã—îˆ¾Ã—î‰€}as the universe
of perspectives.
definition 4 (set of activities/resources in an event log ).letîˆ¼=îˆ¯Ã—îˆ±âˆ—Ã—îˆ¿be the universe of process instances, and ğ¸ğ¿âŠ† îˆ¼be
an event log. ğ´ğ¸ğ¿= {ğ‘âˆˆîˆ­âˆ£ âˆƒ(ğ‘,ğœ,ğ‘ )âˆˆğ¸ğ¿ğ‘âˆˆğœ‹îˆ­(ğœ)}is the set of activities in the event log, and ğ‘…ğ¸ğ¿= {ğ‘Ÿâˆˆîˆ¾âˆ£ âˆƒ(ğ‘,ğœ,ğ‘ )âˆˆğ¸ğ¿ğ‘âˆˆğœ‹îˆ¾(ğœ)}
is the set of resources in the event log.
definition 5 (set of traces/variants in an event log ).letîˆ¼=îˆ¯Ã—îˆ±âˆ—Ã—îˆ¿be the universe of process instances, ğ¸ğ¿âŠ† îˆ¼be an event log,
andğ‘ğ‘ âˆˆîˆ¼îˆ¿be a perspective. ğ¸ğ¿ğ‘ğ‘ = [ğœ‹ğ‘ğ‘ (ğœ) âˆ£ (ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿]is the multiset of traces in the event log w.r.t. the given perspective.
Ìƒğ¸ğ¿ğ‘ğ‘ = {ğœ‹ğ‘ğ‘ (ğœ) âˆ£ (ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿}is the set of variants, i.e., unique traces, w.r.t. the given perspective, e.g., Ìƒğ¸ğ¿îˆ­is the set of unique
traces w.r.t. the activities.
definition 6 (directly follows relations ).letğ¸ğ¿âŠ†îˆ¼be an event log, ğ‘ğ‘ âˆˆ{îˆ¾,îˆ­}be a perspective, Ìƒğ¸ğ¿ğ‘ğ‘ be the set of variants and
ğ¸ğ¿ğ‘ğ‘ be the multiset of traces in the event log ğ¸ğ¿w.r.t. the given perspective ğ‘ğ‘ .ğ·ğ¹ğ¸ğ¿
ğ‘ğ‘ ={(ğ‘¥,ğ‘¦) âˆˆğ‘ğ‘ Ã—ğ‘ğ‘ âˆ£ğ‘¥ >ğ¸ğ¿
ğ‘ğ‘ ğ‘¦}is the set
of directly follows relations w.r.t. the given perspective. ğ‘¥ >ğ¸ğ¿
ğ‘ğ‘ ğ‘¦iff there exists a trace ğœâˆˆÌƒğ¸ğ¿ğ‘ğ‘ and 1â‰¤ğ‘–<|ğœ|, s.t.,ğœ(ğ‘–) =ğ‘¥and
ğœ(ğ‘–+1) =ğ‘¦.|ğ‘¥>ğ¸ğ¿
ğ‘ğ‘ ğ‘¦|=âˆ‘
ğœâˆˆÌƒğ¸ğ¿ğ‘ğ‘ ğ¸ğ¿ğ‘ğ‘ (ğœ)Ã—|{1â‰¤ğ‘–<|ğœ|âˆ£ğœ(ğ‘–)=ğ‘¥âˆ§ğœ(ğ‘–+1)=ğ‘¦}|is the number of times ğ‘¥is followed by ğ‘¦inğ¸ğ¿.
definition 7 (variant frequency ).letîˆ¼=îˆ¯Ã—îˆ±âˆ—Ã—îˆ¿be the universe of process instances, and ğ¸ğ¿ âŠ† îˆ¼be an event log. given a
perspective ğ‘ğ‘ âˆˆîˆ¼îˆ¿,ğ‘“ğ‘Ÿğ‘’ğ‘ğ¸ğ¿
ğ‘ğ‘ âˆ¶Ìƒğ¸ğ¿ğ‘ğ‘ â†’[0,1]is a function that retrieves the relative frequency of the variants in the event log w.r.t.
the given perspective. ğ‘“ğ‘Ÿğ‘’ğ‘ğ¸ğ¿
ğ‘ğ‘ (ğœ) =ğ¸ğ¿ğ‘ğ‘ (ğœ)âˆ•|ğ¸ğ¿ğ‘ğ‘ |andâˆ‘
ğœâˆˆÌƒğ¸ğ¿ğ‘ğ‘ ğ‘“ğ‘Ÿğ‘’ğ‘ğ¸ğ¿
ğ‘ğ‘ (ğœ) = 1.
table 2 shows the process instance representation of the event log shown in table 1, where timestamps are represented as
â€˜â€˜day-hour:minute". in this event log, disease is the attribute which is considered as the sensitive one.
4m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 2
the process instance representation of the event log table 1 (each row is a process instance
where timestamps are represented as â€˜â€˜day-hour:minuteâ€™â€™).
case id simple trace disease
1 <(re,e4,01-08:30),(vi,d3,01-08:45),(rl,e6,01-08:58) > flu
2 <(re,e1,01-08:46),(ho,e3,01-09:01),(bt,n1,01-10:02),
(bt,n1,02-08:00),(vi,d1,02-09:30),(rl,e2,02-14:00) >hiv
3 <(re,e1,01-08:50),(ho,e3,01-10:00),(bt,n1,01-10:15),
(vi,d1,02-13:55),(rl,e2,02-14:15) >infection
4 <(re,e4,01-08:55),(vi,d2,01-09:10),(in,n2,01-09:30),
(rl,e6,01-10:30) >poisoning
5 <(re,e1,01-09:00),(vi,d2,01-09:20),(ho,e6,01-09:55),
(bt,n2,01-10:10),(rl,e2,02-16:00) >cancer
6 <(re,e4,01-09:05),(vi,d3,01-10:20),(rl,e6,01-14:20) > corona
fig. 2. categorizing background knowledge based on the type and event attributes as well as the corresponding perspectives, e.g., if ğ‘¡ğ‘¦ğ‘ğ‘’ =ğ‘Ÿğ‘’ğ‘™andğ‘ğ‘¡ğ‘¡=ğ‘ğ‘Ÿ, the
corresponding perspective is ğ‘ğ‘ =îˆ­Ã—îˆ¾Ã—î‰€.
3.2. background knowledge
regarding the quasi-identifier role of traces, we consider four main types of background knowledge including set,multiset (mult),
sequence (seq), and relative time difference (rel). using setas the type of background knowledge, we assume that an adversary knows
a subset of some event attributes contained in the trace attribute of a victim case. in the multiset type of background knowledge, the
assumption is that an adversary knows a subset of some event attributes included in the trace attribute of a victim case as well as
the frequency of the elements. in the sequence type of background knowledge, we suppose that an adversary knows a subsequence
of some event attributes included in the trace attribute of a victim case.
the exact timestamps of events in an event log impose a high risk regarding the linkage attacks such that little time-related
knowledge may easily single out specific events, and consequently the case re-identification. for performance analysis in process
mining, we need to have the time-related information. however, the timestamps do not necessarily need to be the actual ones.
therefore, we make all the timestamps relative as defined in definition 8.
definition 8 (relative timestamps ).letğœ=âŸ¨(ğ‘1,ğ‘¡1),(ğ‘2,ğ‘¡2),â€¦,(ğ‘ğ‘›,ğ‘¡ğ‘›)âŸ©be a trace including the time attribute, and ğ‘¡0be an initial
timestamp. ğ‘Ÿğ‘’ğ‘™ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ (ğœ) =âŸ¨(ğ‘1,ğ‘¡â€²
1),(ğ‘2,ğ‘¡â€²
2),â€¦,(ğ‘ğ‘›,ğ‘¡â€²
ğ‘›)âŸ©is the trace with relative timestamps such that ğ‘¡â€²
1=ğ‘¡0and for each 1< ğ‘–â‰¤ğ‘›,
ğ‘¡â€²
ğ‘–=ğ‘¡ğ‘–âˆ’ğ‘¡1+ğ‘¡0.
using relative timestamps does not eliminate time-based attacks, since the time differences are real and can be exploited by
an adversary. relative time difference type of background knowledge is an extension for the sequence type, where the assumption
is that an adversary knows a subsequence of some event attributes as well as the relative time differences between the elements.
fig. 2 shows the classification of background knowledge based on the types and event attributes. in the following, we provide
formal definitions for different categories of background knowledge based on the main event attributes, i.e., activity ,resource , and
timestamp . moreover, one can see that there is a relation between type,attribute , and perspective , i.e., a combination of type and
attribute can be mapped to a perspective. for example, if ğ‘¡ğ‘¦ğ‘ğ‘’ =ğ‘Ÿğ‘’ğ‘™andğ‘ğ‘¡ğ‘¡=ğ‘ğ‘Ÿ, the corresponding perspective is ğ‘ğ‘ =îˆ­Ã—îˆ¾Ã—î‰€,
or ifğ‘¡ğ‘¦ğ‘ğ‘’ âˆˆ {ğ‘ ğ‘’ğ‘¡,ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ ğ‘’ğ‘ }andğ‘ğ‘¡ğ‘¡=ğ‘Ÿğ‘’, the corresponding perspective is ğ‘ğ‘ =îˆ¾.
5m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 3. data collection and data publishing scenario.
definition 9 (background knowledge based on activities ).letğ¸ğ¿be an event log, and ğ´ğ¸ğ¿be the set of activities in the event log.
ğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘(ğ¸ğ¿) = 2ğ´ğ¸ğ¿,ğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘ (ğ¸ğ¿) =îˆ®(ğ´ğ¸ğ¿), andğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘ğ‘ (ğ¸ğ¿) =ğ´âˆ—
ğ¸ğ¿are the sets of candidates of background knowledge based on the
activity attribute of the events for the set,multiset , and sequence types of background knowledge. for example, {ğ‘,ğ‘,ğ‘ } âˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘(ğ¸ğ¿),
[ğ‘2,ğ‘] âˆˆğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘ (ğ¸ğ¿), andâŸ¨ğ‘,ğ‘,ğ‘âŸ©âˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘ğ‘ (ğ¸ğ¿).
definition 10 (background knowledge based on resources ).letğ¸ğ¿be an event log, and ğ‘…ğ¸ğ¿be the set of activities in the event
log.ğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘Ÿğ‘’(ğ¸ğ¿) = 2ğ‘…ğ¸ğ¿,ğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘Ÿğ‘’ (ğ¸ğ¿) =îˆ®(ğ‘…ğ¸ğ¿), andğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’(ğ¸ğ¿) =ğ‘…âˆ—
ğ¸ğ¿are the sets of candidates of background knowledge based
on the resource attribute of the events for the different types of background knowledge.
definition 11 (background knowledge based on activities&resources ).letğ¸ğ¿be an event log, ğ´ğ¸ğ¿be the set of activities in
the event log, and ğ‘…ğ¸ğ¿be the set of resources in the event log. ğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘Ÿ(ğ¸ğ¿) = 2ğ´ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿,ğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘Ÿ (ğ¸ğ¿) =îˆ®(ğ´ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿), and
ğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘ğ‘Ÿ(ğ¸ğ¿) = (ğ´ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿)âˆ—are the sets of candidates of background knowledge based on the activity and resource attribute of
the events for the various types of background knowledge.
definition 12 (background knowledge based on time differences between relative timestamps ).letğ¸ğ¿be an event log, ğ´ğ¸ğ¿be the
set of activities in the event log, ğ‘…ğ¸ğ¿be the set of resources in the event log, and î‰€be the universe of (relative) timestamps.
ğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘(ğ¸ğ¿) = (ğ´ğ¸ğ¿Ã—î‰€)âˆ—,ğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘Ÿğ‘’(ğ¸ğ¿) = (ğ‘…ğ¸ğ¿Ã—î‰€)âˆ—, andğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿ(ğ¸ğ¿) = (ğ´ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿Ã—î‰€)âˆ—are the sets of candidates of background
knowledge based on the relative time differences.
note that in definition 12, other attributes are also present. however, our focus is on time differences between relative
timestamps. therefore, we refer to this category of background knowledge as time-based.
4. attack models
fig. 3 shows our simple scenario of data collection and data publishing. with respect to the types of data holderâ€™s models,
introduced in [12], we consider a trusted model . in the trusted data holder models, the data holder is trustworthy, and on the data
holderâ€™s side, only simple anonymization techniques need to be applied, e.g., suppressing real identifiers. however, the data recipient ,
i.e., a process miner, is not trustworthy and may attempt to identify sensitive information about record owners, i.e., cases. given a
process instance ğ‘= (ğ‘,ğœ,ğ‘  ) âˆˆîˆ¼, bothğœandğ‘ are considered as sensitive person-specific information, and part of the trace ğœcan
be exploited as the quasi-identifier to re-identify the owner of the process instance, i.e., ğ‘, and/or to learn the sensitive information
which belongs to the data owner, i.e., ğœand/orğ‘ .
in the following, we provide formal definitions and examples for the attack scenarios based on the main event attributes,
i.e.,activity ,resource , and timestamp . note that the examples are based on the event log shown in table 2.
4.1. activity-based attacks
in the activity-based scenarios, we assume that the adversaryâ€™s knowledge is about the activities performed for a victim case. in
the following, we provide formal models based on the introduced types of background knowledge.
â€“based on a set of activities (a1): in this scenario, we assume that the adversary knows a subset of activities performed for a
case, and this information can lead to the case linkage and/or attribute linkage attacks. given ğ¸ğ¿as an event log, we formalize
this scenario by a function ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘âˆ¶ 2ğ´ğ¸ğ¿â†’2ğ¸ğ¿. forğ´âˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘(ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘(ğ´) = {(ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿âˆ£ğ´âŠ† {ğ‘âˆˆğœ‹îˆ­(ğœ)}}.
for example, if the adversary knows that {ğ‘‰ğ¼,ğ¼ğ‘ }is a subset of activities performed for a case, the only matching case is
case 4. therefore, both the sequence of events and the sensitive attribute are disclosed.
â€“based on a multiset of activities (a2): in this scenario, we assume that the adversary knows a sub-multiset of activities
performed for a case, and this information can result in the linkage attacks. given ğ¸ğ¿as an event log, we formalize this
scenario as follows. ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘âˆ¶îˆ®(ğ´ğ¸ğ¿)â†’2ğ¸ğ¿. forğµâˆˆğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘ (ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘(ğµ) = {(ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿âˆ£ğµ âŠ† [ğ‘âˆˆğœ‹îˆ­(ğœ)]}.
for example, if the adversary knows that [ğ»ğ‘‚1,ğµğ‘‡2]is a multiset of activities performed for a case, the only matching case
is case 2. consequently, the complete sequence of events and the disease are disclosed.
6m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
â€“based on a sequence of activities (a3): in this scenario, we assume that the adversary knows a subsequence of activities
performed for a case, and this information can lead to the linkage attacks. given ğ¸ğ¿as an event log, we formalize this scenario
by a function ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘,ğ‘ğ‘âˆ¶ğ´âˆ—
ğ¸ğ¿â†’2ğ¸ğ¿. forğœâˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘ğ‘ (ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘,ğ‘ğ‘(ğœ) = {(ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿âˆ£ğœ âŠ‘ğœ‹îˆ­(ğœâ€²)}. for example, if the
adversary knows that âŸ¨ğ‘…ğ¸,ğ‘‰ğ¼,ğ»ğ‘‚ âŸ©is a subsequence of activities performed for a case, case 5 is the only matching case.
4.2. resource-based attacks
in the resource-based scenarios, we assume that the adversaryâ€™s knowledge is about the resources who perform activities for a
victim case. in the following, we provide formal models based on the main types of background knowledge.
â€“based on a set of resources (r1): in this scenario, we assume that the adversary knows a subset of resources involved in
performing activities for a victim case, and this information can lead to the case linkage and/or attribute linkage attacks. given
ğ¸ğ¿as an event log, we formalize this scenario as follows. ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘¡,ğ‘Ÿğ‘’âˆ¶ 2ğ‘…ğ¸ğ¿â†’2ğ¸ğ¿. forğ‘…âˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘Ÿğ‘’(ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘¡,ğ‘Ÿğ‘’(ğ‘…) =
{(ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿âˆ£ğ‘… âŠ† {ğ‘Ÿâˆˆğœ‹îˆ¾(ğœ)}}. for example, if the adversary knows that {ğ¸1,ğ·2}is a subset of resources involved in
handling a victim case, case 5 is the only matching case. therefore, both the sequence of events and the sensitive attribute
are disclosed.
â€“based on a multiset of resources (r2): in this scenario, we assume that the adversary knows a sub-multiset of resources
involved in performing activities for a victim case, and this information can lead to the linkage attacks. given ğ¸ğ¿as an event
log, we formalize this scenario as follows. ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘Ÿğ‘’âˆ¶îˆ®(ğ‘…ğ¸ğ¿)â†’2ğ¸ğ¿. forğ‘†âˆˆğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘Ÿğ‘’ (ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘Ÿğ‘’(ğ‘†) = {(ğ‘,ğœ,ğ‘  ) âˆˆ
ğ¸ğ¿âˆ£ğ‘† âŠ† [ğ‘Ÿâˆˆğœ‹îˆ¾(ğœ)]}. for example, if the adversary knows that [ğ‘12,ğ¸3]is a multiset of resources performed activities for
a victim case, the only matching case is case 2.
â€“based on a sequence of resources (r3): in this scenario, we assume that the adversary knows a subsequence of resources
who performed activities for a victim case, and this information can result in the linkage attacks. given ğ¸ğ¿as an event log,
we formalize this scenario by a function ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’âˆ¶ğ‘…âˆ—
ğ¸ğ¿â†’2ğ¸ğ¿. forğœâˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’(ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’(ğœ) = {(ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿âˆ£ğœ âŠ‘
ğœ‹îˆ¾(ğœâ€²)}. for example, if the adversary knows that âŸ¨ğ¸4,ğ·2âŸ©is a subsequence of resources who performed activities for a victim
case, the only matching case is case 4.
4.3. activity & resource-based attacks
in the activity & resource-based scenarios, we assume that the adversaryâ€™s knowledge is about activities and the corresponding
resources who perform activities for a victim case. in the following, we provide formal models based on the main types of background
knowledge.
â€“based on a set of (activity,resource) pairs (ar1): in this scenario, we assume that the adversary knows a subset of
(activity,resource) pairs included in the trace attribute of a victim case, and this information can result in the case linkage
and/or attribute linkage attacks. given ğ¸ğ¿as an event log, we formalize this scenario as follows. ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘Ÿâˆ¶ 2ğ´ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿â†’2ğ¸ğ¿.
forğ´ğ‘…âˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘Ÿ(ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘Ÿ(ğ´ğ‘…) = {(ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿âˆ£ğ´ğ‘… âŠ† {(ğ‘,ğ‘Ÿ) âˆˆğœ‹îˆ­Ã—îˆ¾(ğœ)}}. for example, if the adversary knows that
{(ğ»ğ‘‚,ğ¸ 6)}is a subset of (activity,resource) pairs contained in the trace attribute of a victim case, case 5 is the only matching
case, which result is the whole sequence and sensitive attribute disclosure.
â€“based on a multiset of (activity,resource) pairs (ar2): in this scenario, we assume that the adversary knows a sub-multiset
of (activity,resource) pairs included in the trace attribute of a victim case. given ğ¸ğ¿as an event log, the scenario can be
formalized as follows. ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘Ÿâˆ¶îˆ®(ğ´ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿)â†’2ğ¸ğ¿. forğµğ‘†âˆˆğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘Ÿ (ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘Ÿ(ğµğ‘†) = {(ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿âˆ£ğµğ‘† âŠ†
[(ğ‘,ğ‘Ÿ) âˆˆğœ‹îˆ­Ã—îˆ¾(ğœ)]}. for example, if the adversary knows that [(ğµğ‘‡,ğ‘ 1)2]is a multiset of (activity,resource) pairs included in
the trace attribute of a victim case, the only matching case is case 2.
â€“based on a sequence of (activity,resource) pairs (ar3): in this scenario, we assume that the adversary knows a subsequence
of (activity,resource) pairs included in the trace attribute of a victim case, and this information can lead to the linkage attacks.
givenğ¸ğ¿as an event log, we formalize this scenario by a function ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘,ğ‘ğ‘Ÿâˆ¶ (ğ´ğ¸ğ¿Ã—ğ¸ğ¸ğ¿)âˆ—â†’2ğ¸ğ¿. forğœâˆˆğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘ğ‘Ÿ(ğ¸ğ¿),
ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘ ğ‘’ğ‘,ğ‘ğ‘Ÿ(ğœ) = {(ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿ âˆ£ğœ âŠ‘ ğœ‹îˆ­Ã—îˆ¾(ğœâ€²)}. for example, if the adversary knows that âŸ¨(ğ‘…ğ¸,ğ¸ 4),(ğ‘‰ğ¼,ğ· 2)âŸ©is a
(activity,resource) pairs included in the trace attribute of a victim case, case 4 is the only matching case.
4.4. time-based attacks
as we discussed in section 3.2, after making the timestamps relative, the time differences are still real and can be exploited by
an adversary. in the following, we extend the attacks of the type sequence , i.e., a3, r3, ar3, with the time-related information.
â€“based on relative time differences between activities (at): in this scenario, we assume that the adversary knows a
subsequence of activities and also the time difference between the activities. given ğ¸ğ¿as an event log, the scenario is
formalized as follows. ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘âˆ¶ (ğ´ğ¸ğ¿Ã—î‰€)âˆ—â†’2ğ¸ğ¿. forğœâˆˆğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘(ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘(ğœ) = {(ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿ âˆ£ğœ âŠ‘
ğ‘Ÿğ‘’ğ‘™ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ (ğœ‹îˆ­Ã—î‰€(ğœâ€²))}. for example, if an adversaryâ€™s knowledge is âŸ¨ğ»ğ‘‚,ğ‘‰ğ¼ âŸ©, both case 2 and case 3 get matched. however,
if the adversary further knows that for a victim case, visitperformed in the morning of the next day, the only matching case
is case 2.
7m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 3
a simple event log where time difference between relative timestamps are
represented by integer values.
case id trace disease
1 <(re,e4,1),(ho,e3,4),(vi,d1,5),(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > infection
3 <(ho,e3,4),(vi,d1,5),(bt,n1,7),(rl,e2,9) > corona
4 <(re,e4,1),(vi,d1,6),(vi,d1,8),(rl,e2,9) > infection
5 <(ho,4),(vi,d1,8),(rl,e2,9) > corona
6 <(vi,d1,6),(bt,n1,7),(rl,e2,9) > flu
7 <(re,e4,1),(bt,n1,7),(vi,d1,8),(rl,e2,9) > flu
8 <(re,e4,1),(vi,d1,6),(bt,n1,7),(vi,d1,8) > cancer
table 4
the event log after applying 2-anonymity to table 3 using baseline -2.
case id trace disease
1 <(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > infection
3 <(bt,n1,7),(rl,e2,9) > corona
4 <(vi,d1,8),(rl,e2,9) > infection
5 <(vi,d1,8),(rl,e2,9) > corona
6 <(bt,n1,7),(rl,e2,9) > flu
7 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > flu
8 <(bt,n1,7),(vi,d1,8) > cancer
â€“based on relative time differences between resources who performed activities (rt): according to this scenario, the
adversary knows a subsequence of resources and the time difference between the resources involved in handling a case.
givenğ¸ğ¿as an event log, we formalize this scenario by a function ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘Ÿğ‘’âˆ¶ (ğ‘…ğ¸ğ¿Ã—î‰€)âˆ—â†’2ğ¸ğ¿. forğœâˆˆğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘Ÿğ‘’(ğ¸ğ¿),
ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘Ÿğ‘’(ğœ) = {(ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿âˆ£ğœ âŠ‘ ğ‘Ÿğ‘’ğ‘™ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ (ğœ‹îˆ¾Ã—î‰€(ğœâ€²))}. for example, if an adversaryâ€™s knowledge is âŸ¨ğ¸1,ğ¸3âŸ©, both case 2
and case 3 get matched. however, if the adversary further knows that for the victim case, employee 3 performed hospitalization
more than one hour after registration , case 3 is the only matching case.
â€“based on relative time differences between (activity,resource) pairs (art): in this scenario, the assumption is that the
adversary knows a subsequence of (activity,resource) pairs and the time difference between these pairs. given ğ¸ğ¿as an event
log, we formalize this scenario as follows. ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿâˆ¶ (ğ´ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿)âˆ—â†’2ğ¸ğ¿. forğœâˆˆğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿ(ğ¸ğ¿),ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿ(ğœ) = {(ğ‘,ğœâ€²,ğ‘ ) âˆˆ
ğ¸ğ¿âˆ£ğœ âŠ‘ ğ‘Ÿğ‘’ğ‘™ğ‘ğ‘¡ğ‘–ğ‘£ğ‘’ (ğœâ€²)}. for example, case 1 and case 6 have the same sequence of (activity,resource) pairs. however, if the
adversary knows that for a victim case, it took almost four hours to get released by employee 6 after visiting by a doctor, the
corresponding possible cases narrow down to only one case, which is case 6.
5. privacy preservation techniques
traditional ğ‘˜-anonymity and its extended privacy preservation techniques assume that an adversary could use all of the quasi-
identifier attributes as background knowledge to launch linkage attacks. according to the types of background knowledge introduced
in section 3, this assumption means that the background knowledge of an adversary is ğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿ which covers all the information
contained in a trace. in the following, we show the results of applying two baseline methods with respect to the aforementioned
assumption.
5.1. baseline methods
in this subsection, we introduce two baseline methods to apply ğ‘˜-anonymity on event logs: baseline -1 and baseline -2.baseline -1
is a naÃ¯veğ‘˜-anonymity approach where we remove all the trace variants occurring less than ğ‘˜times. baseline -2 maps each violating
trace variant, i.e., the variant that does not fulfill the desired ğ‘˜-anonymity requirement, to the most similar non-violating subtrace
by removing events. in baseline -2, if there exists no non-violating subtrace, the whole trace variant is removed.
suppose that table 3 is part of an event log recorded by an information system in a hospital that needs to be published after
applyingğ‘˜-anonymity. note that for the sake of simplicity, the time differences between relative timestamps are represented by
integers. since all the traces in this event log are unique if we apply ğ‘˜-anonymity with any value greater than 1, using baseline -1,
all the traces are removed. if we apply baseline -2 whereğ‘˜= 2then the result is the event log shown in table 4. one can see that for
such a weak privacy requirement 12 events are removed. now, if we use ğ‘˜= 4, table 5 is the result where 18 events are removed
which is more than half of the events.
in [13], the ğ‘ƒğ‘…ğ¸ğ‘‡ğ‘†ğ´ method is introduced as a group-based privacy preservation technique for process mining where the
authors apply ğ‘˜-anonymity and ğ‘¡-closeness on event data for privacy-aware process discovery. however, ğ‘ƒğ‘…ğ¸ğ‘‡ğ‘†ğ´ focuses on the
8m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
resource perspective of privacy while we focus on the case perspective . theğ‘ƒğ‘…ğ¸ğ‘‡ğ‘†ğ´ method assumes a prefix of activity sequences
as the background knowledge, and each violating trace is mapped to the most similar non-violating trace. in [5], ğ‘ƒğ‘…ğ¸ğ‘‡ğ‘†ğ´ğ‘ğ‘ğ‘ ğ‘’is
introduced as a variant of ğ‘ƒğ‘…ğ¸ğ‘‡ğ‘†ğ´ method where only the ğ‘˜-anonymity part is considered, and the focus is on the privacy of cases
rather than resources . therefore, ğ‘ƒğ‘…ğ¸ğ‘‡ğ‘†ğ´ğ‘ğ‘ğ‘ ğ‘’is a specific type of baseline -2 where the background knowledge is a specific type of
ğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘ğ‘, i.e., a prefix of activity sequences rather than any subsequence.
5.2.ğ‘‡ğ¿ğ¾ğ¶ -privacy (extended)
as discussed in [5], it is almost impossible for an adversary to acquire all the information of a target victim, and it requires
non-trivial effort to gather each piece of background knowledge. the ğ‘‡ğ¿ğ¾ğ¶ -privacy exploits this limitation and assumes that the
adversaryâ€™s background knowledge is bounded by at most ğ¿values of the quasi-identifier, i.e., the size or power of background
knowledge. based on the types of background knowledge illustrated in fig. 2, the ğ‘‡ğ¿ğ¾ğ¶ -privacy considers all the types, i.e., set,
multiset ,sequence , and relative . however, it focuses on the activity attribute (ac) and timestamps which are included in the relative
type. in this paper, the technique is extended with the resource attribute, i.e., merely resource (re) and activity along with resource
(ar) are also considered. in the following, we bound the power of the different types of background knowledge (definition 9â€“12)
withğ¿as the maximal size of candidates.
definition 13 (bounded background knowledge ).letğ¸ğ¿be an event log, ğ‘¡ğ‘¦ğ‘ğ‘’ âˆˆ {ğ‘ ğ‘’ğ‘¡,ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’ğ‘™ }be the type of background
knowledge, ğ‘ğ‘¡ğ‘¡âˆˆ {ğ‘ğ‘,ğ‘Ÿğ‘’,ğ‘ğ‘Ÿ }be the event attribute of background knowledge, and l be the size of background knowledge.
ğ‘ğ‘˜ğ¿
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ¸ğ¿) = {ğ‘ğ‘ğ‘›ğ‘‘ âˆˆğ‘ğ‘˜ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡ (ğ¸ğ¿) âˆ£|ğ‘ğ‘ğ‘›ğ‘‘|â‰¤ğ¿}are the candidates of the background knowledge whose sizes are bounded
byğ¿.
in theğ‘‡ğ¿ğ¾ğ¶ -privacy,ğ‘‡âˆˆ {ğ‘ ğ‘’ğ‘ğ‘œğ‘›ğ‘‘ğ‘ ,ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘ ,â„ğ‘œğ‘¢ğ‘Ÿğ‘ ,ğ‘‘ğ‘ğ‘¦ğ‘  }refers to the accuracy of timestamps, e.g., ğ‘‡=ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘  shows that
the accuracy of timestamps is limited at minutes level,ğ¿refers to the power of background knowledge, ğ¾refers to the ğ‘˜in the
ğ‘˜-anonymity definition, and ğ¶refers to the bound of confidence regarding the sensitive attribute values in a matching set. we
denoteğ¸ğ¿(ğ‘‡)as the event log with the accuracy of timestamps at the level ğ‘‡. the general idea of ğ‘‡ğ¿ğ¾ğ¶ -privacy is to ensure that
the background knowledge of size ğ¿inğ¸ğ¿(ğ‘‡)is shared by at least ğ¾cases, and the confidence of inferring the sensitive value in
ğ‘†is not greater than ğ¶.
definition 14 (ğ‘‡ğ¿ğ¾ğ¶ -privacy ).letğ¸ğ¿ âŠ† îˆ¼be an event log, ğ¿be the maximal size of background knowledge, ğ‘‡âˆˆ
{ğ‘ ğ‘’ğ‘ğ‘œğ‘›ğ‘‘ğ‘ ,ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘ ,â„ğ‘œğ‘¢ğ‘Ÿğ‘ ,ğ‘‘ğ‘ğ‘¦ğ‘  }be the accuracy of timestamps, ğ‘¡ğ‘¦ğ‘ğ‘’ âˆˆ {ğ‘ ğ‘’ğ‘¡,ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’ğ‘™ }, andğ‘ğ‘¡ğ‘¡âˆˆ {ğ‘ğ‘,ğ‘Ÿğ‘’,ğ‘ğ‘Ÿ }.ğ¸ğ¿(ğ‘‡)satisfies
ğ‘‡ğ¿ğ¾ğ¶ -privacy if and only if for any ğ‘ğ‘ğ‘›ğ‘‘ âˆˆğ‘ğ‘˜ğ¿
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ¸ğ¿(ğ‘‡))such thatğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿(ğ‘‡)
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ‘ğ‘ğ‘›ğ‘‘ )â‰ âˆ…:
â€“|ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿(ğ‘‡)
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ‘ğ‘ğ‘›ğ‘‘ )|â‰¥ğ¾, whereğ¾âˆˆn>0, and
â€“ğ‘ƒğ‘Ÿ(ğ‘ |ğ‘ğ‘ğ‘›ğ‘‘ ) =|{ğ‘âˆˆğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿(ğ‘‡)
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ‘ğ‘ğ‘›ğ‘‘ )âˆ£ğœ‹îˆ¿(ğ‘)=ğ‘ }|
|ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿(ğ‘‡)
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ‘ğ‘ğ‘›ğ‘‘ )|â‰¤ğ¶for anyğ‘ âˆˆğ‘†, where 0<ğ¶â‰¤1is a real number as the confidence threshold, and
ğœ‹îˆ¿(ğ‘)is the projection of the process instance on the sensitive attribute value.
theğ‘‡ğ¿ğ¾ğ¶ -privacy provides a major relaxation from traditional ğ‘˜-anonymity based on a reasonable assumption that the
adversary has restricted knowledge. it generalizes several privacy preservation techniques including ğ‘˜-anonymity, confidence
bounding, (ğ›¼,ğ‘˜)-anonymity, and ğ‘™-diversity. it also provides interpretable parameters. note that the type and attribute of background
knowledge implicitly show the perspective (fig. 2).
5.2.1. privacy measure
in the subsection, we define (minimal) violating traces w.r.t. the privacy requirements of the ğ‘‡ğ¿ğ¾ğ¶ -privacy.
definition 15 (violating trace ).letğ¸ğ¿ âŠ† îˆ¼be an event log, ğ¿be the maximal size of background knowledge, ğ‘‡âˆˆ
{ğ‘ ğ‘’ğ‘ğ‘œğ‘›ğ‘‘ğ‘ ,ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘ ,â„ğ‘œğ‘¢ğ‘Ÿğ‘ ,ğ‘‘ğ‘ğ‘¦ğ‘  }be the accuracy of timestamps, ğ‘¡ğ‘¦ğ‘ğ‘’ âˆˆ {ğ‘ ğ‘’ğ‘¡,ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’ğ‘™ },ğ‘ğ‘¡ğ‘¡âˆˆ {ğ‘ğ‘,ğ‘Ÿğ‘’,ğ‘ğ‘Ÿ },ğ‘ğ‘ âˆˆîˆ¼îˆ¿be the
corresponding perspective w.r.t. the given ğ‘¡ğ‘¦ğ‘ğ‘’andğ‘ğ‘¡ğ‘¡, andğœ âŠ‘ ğœ‹ğ‘ğ‘ (ğœâ€²)such that (ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿(ğ‘‡).ğœis a violating (sub)trace
with respect to the ğ‘‡ğ¿ğ¾ğ¶ -privacy requirements if there exists a ğ‘ğ‘ğ‘›ğ‘‘ âˆˆğ‘ğ‘˜ğ¿
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ¸ğ¿(ğ‘‡)):
â€“ğ‘ğ‘ğ‘›ğ‘‘ âŠ‘ğœ âˆ¨ğ‘ğ‘ğ‘›ğ‘‘ âŠ† {ğ‘’âˆˆğœ} âˆ¨ğ‘ğ‘ğ‘›ğ‘‘ âŠ† [ğ‘’âˆˆğœ], and
â€“|ğ‘šğ‘ğ‘¡ğ‘â„ğ¸ğ¿(ğ‘‡)
ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡(ğ‘ğ‘ğ‘›ğ‘‘ )|<ğ¾orğ‘ƒğ‘Ÿ(ğ‘ |ğ‘ğ‘ğ‘›ğ‘‘ )>ğ¶for someğ‘ âˆˆğ‘†.
an event log satisfies ğ‘‡ğ¿ğ¾ğ¶ -privacy, if all violating traces w.r.t. the given privacy requirement are removed. a naÃ¯ve approach
is to determine all violating traces and remove them. however, this approach is inefficient due to the numerous number of violating
traces, even for a weak privacy requirement. moreover, as demonstrated in [5], ğ‘‡ğ¿ğ¾ğ¶ -privacy is not monotonic w.r.t. ğ¿. in fact,
the anonymity threshold ğ¾is monotonic w.r.t. ğ¿, i.e., ifğ¿â€²â‰¤ğ¿andğ¶= 100% , an event log ğ¸ğ¿which satisfies ğ‘‡ğ¿ğ¾ğ¶ -privacy must
satisfyğ‘‡ğ¿â€²ğ¾ğ¶-privacy. however, confidence threshold ğ¶is not monotonic w.r.t. ğ¿, i.e., ifğœis non-violating trace, its subtrace may
or may not be non-violating. therefore, we have to make sure that the conditions should hold for any ğ¿â€²â‰¤ğ¿. to this end, in the
following, we define the extended version of minimal violating traces w.r.t. the different perspectives.
9m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
algorithm 1: ğ‘‡ğ¿ğ¾ğ¶ -privacy - extended w.r.t. the different perspectives.
input : original event log ğ¸ğ¿
input :ğ‘‡,ğ¿,ğ¾,ğ¶, andğ›©(frequency threshold)
input : background knowledge type and attribute ( ğ‘ğ‘˜ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡ ), sensitive attributes îˆ¿
output : anonymized event log ğ¸ğ¿â€²which satisfies the desired ğ‘‡ğ¿ğ¾ğ¶ -privacy requirements
1generateğ‘€ğ¹ğ‘‡ğ¸ğ¿
ğ‘ğ‘ andğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ ;
2generateğ‘€ğ¹ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ andğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ as the prefix trees for ğ‘€ğ¹ğ‘‡ğ¸ğ¿
ğ‘ğ‘ andğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ ;
3while there is node (event) in ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ do
4 select an event (node) ğ‘’ğ‘¤that has the highest score to suppress based on ğ‘ ğ‘œğ‘ğ‘Ÿğ‘’ (ğ‘’)ğ¸ğ¿
ğ‘ğ‘ ;
5 delete all the mvts and mfts containing the event ğ‘’ğ‘¤fromğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ andğ‘€ğ¹ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ ;
6 updateğ‘ ğ‘œğ‘ğ‘Ÿğ‘’ (ğ‘’)ğ¸ğ¿
ğ‘ğ‘ for all the remaining events (nodes) in ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ ;
7 addğ‘’ğ‘¤to the suppression set ğ‘†ğ‘¢ğ‘ğ¸ğ¿;
8end
9foreachğ‘’âˆˆğ‘†ğ‘¢ğ‘ğ¸ğ¿do
10 suppress all instances of ğ‘’fromğ¸ğ¿;
11end
12return suppressed ğ¸ğ¿asğ¸ğ¿â€²;
definition 16 (minimal violating trace ).letğ¸ğ¿âŠ† îˆ¼be an event log, ğ¿be the maximal size of background knowledge, ğ‘‡âˆˆ
{ğ‘ ğ‘’ğ‘ğ‘œğ‘›ğ‘‘ğ‘ ,ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘ ,â„ğ‘œğ‘¢ğ‘Ÿğ‘ ,ğ‘‘ğ‘ğ‘¦ğ‘  }be the accuracy of timestamps, ğ‘¡ğ‘¦ğ‘ğ‘’ âˆˆ {ğ‘ ğ‘’ğ‘¡,ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ ğ‘’ğ‘,ğ‘Ÿğ‘’ğ‘™ },ğ‘ğ‘¡ğ‘¡âˆˆ {ğ‘ğ‘,ğ‘Ÿğ‘’,ğ‘ğ‘Ÿ },ğ‘ğ‘ âˆˆîˆ¼îˆ¿be the
corresponding perspective w.r.t. the given ğ‘¡ğ‘¦ğ‘ğ‘’andğ‘ğ‘¡ğ‘¡, andğœ âŠ‘ ğœ‹ğ‘ğ‘ (ğœâ€²)such that (ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿(ğ‘‡).ğœis a minimal violating trace
ifğœis a violating trace (definition 15) in the ğ¸ğ¿, and every proper subtrace of ğœis not violating. we denote ğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ as the set of
minimal violating traces in the event log ğ¸ğ¿w.r.t. the perspective ğ‘ğ‘ .
every violating trace in an event log is either a minimal violating trace or it contains a minimal violating trace. therefore, if an
event log contains no minimal violating trace, then it contains no violating trace. note that the set of minimal violating traces in an
event log is much smaller than the set of violating traces in the event log which results in better efficiency for removing violating
traces.
5.2.2. utility measure
in theğ‘‡ğ¿ğ¾ğ¶ -privacy, the maximal frequent traces are defined as a measure for considering data utility, where traces contain
activity and timestamp attributes. since we extend the ğ‘‡ğ¿ğ¾ğ¶ -privacy preservation technique to cover all the main perspectives of
process mining, the utility measure also needs to be extended. in the following, we provide an extended version of the utility measure
considering the perspectives.
definition 17 (maximal frequent trace ).letğ¸ğ¿be an event log, and ğ‘ğ‘ âˆˆîˆ¼îˆ¿be a perspective. for a given minimum support
thresholdğ›©, a non-empty trace ğœâŠ‘ğœ‹ğ‘ğ‘ (ğœâ€²)such that (ğ‘,ğœâ€²,ğ‘ ) âˆˆğ¸ğ¿ismaximal frequent in theğ¸ğ¿ifğœis frequent, i.e., the frequency
ofğœis greater than or equal to ğ›©, and no supertrace of ğœis frequent in the ğ¸ğ¿. we denote ğ‘€ğ¹ğ‘‡ğ¸ğ¿
ğ‘ğ‘ as the set of maximal frequent
traces in the event log ğ¸ğ¿w.r.t. the perspective ğ‘ğ‘ .
the goal of data utility is to preserve as many mft as possible w.r.t. the given perspective. for example, in the control-flow
perspective, i.e., ğ‘ğ‘ =îˆ­, the goal in to preserve the maximal frequent traces w.r.t. the activities. note that in an event log, the set of
maximal frequent traces is much smaller than the set of frequent traces. moreover, any subtrace of a maximal frequent trace is also
a frequent trace, and once all the mfts are discovered, the support counts of any frequent subtrace can be computed by scanning
the data once.
5.2.3. balancing privacy and utility
as discussed in the privacy measure section, to provide the desired privacy requirements, all the minimal violating traces need
to be removed. however, this should be done w.r.t. the utility measure. according to definition 16, every proper subtrace of a
minimal violating trace is not violating. therefore, a minimal violating trace can be removed after removing one event of the trace.
this event needs to be chosen w.r.t. both utility and privacy measures. to this end, a greedy function is defined to choose an event
to remove from the minimal violating traces such that it maximizes the number of removed minimal violating traces, i.e., privacy
gain, yet, at the same time, minimizes the number of removed maximal frequent traces, i.e., utility loss.
definition 18 (score, privacy gain, utility loss ).letğ¸ğ¿be an event log, ğ‘ğ‘ âˆˆîˆ¼îˆ¿be a perspective, and ğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ğ‘ ğ‘ğ‘ (ğ¸ğ¿) = {ğ‘’âˆˆğœ‹ğ‘ğ‘ (ğœ) âˆ£
(ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿}be the set of events in the event log w.r.t. the given perspective. ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ¸ğ¿
ğ‘ğ‘ âˆ¶îˆ±â†›r>0is a function which retrieves
the score of the events in the event log w.r.t. the perspective. for ğ‘’âˆˆğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ğ‘ ğ‘ğ‘ (ğ¸ğ¿),ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) =ğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’)âˆ•ğ‘ˆğ¿ğ¸ğ¿
ğ‘ğ‘ (ğ‘’)+1.ğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’)is the
number of mvts containing the event ğ‘’, i.e.,ğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’) =|{ğ‘¥âˆˆğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ âˆ£ğ‘’âˆˆğ‘¥}|andğ‘ˆğ¿ğ¸ğ¿
ğ‘ğ‘ (ğ‘’)is the number of mfts containing the
eventğ‘’, i.e.,ğ‘ˆğ¿ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) =|{ğ‘¥âˆˆğ‘€ğ¹ğ‘‡ğ¸ğ¿
ğ‘ğ‘ âˆ£ğ‘’âˆˆğ‘¥}|.
note that in the score (definition 18), 1 is added to the denominator to avoid diving by zero (when ğ‘’does not belong to any mft).
the eventğ‘’with the highest score is called the ğ‘¤ğ‘–ğ‘›ğ‘›ğ‘’ğ‘Ÿ event, denoted by ğ‘’ğ‘¤. algorithm 1 summarizes all the steps of ğ‘‡ğ¿ğ¾ğ¶ -privacy.
in the following, we show how the algorithm works on the event log table 3.
10m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 4. theğ‘€ğ¹ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ andğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ generated for the event log table 3 with ğ‘‡=â„ğ‘œğ‘¢ğ‘Ÿğ‘  ,ğ¿= 2,ğ¾= 2,ğ¶= 50% ,ğ›©= 25% ,îˆ¿=ğ·ğ‘–ğ‘ ğ‘’ğ‘ğ‘ ğ‘’ , andğ‘ğ‘˜ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿ.
table 5
the event log after applying 4-anonymity to table 3 using baseline -2.
case id trace disease
1 <(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8) > infection
3 <(rl,e2,9)> corona
4 <(rl,e2,9)> infection
5 <(rl,e2,9)> corona
6 <(rl,e2,9)> flu
7 <(bt,n1,7),(vi,d1,8) > flu
8 <(bt,n1,7),(vi,d1,8) > cancer
suppose that table 3 shows a simple event log ğ¸ğ¿where timestamps are represented by integer values as hours. the first line
in algorithm 1 generates the set of maximal frequent traces ( ğ‘€ğ¹ğ‘‡ğ¸ğ¿
ğ‘ğ‘ ) and the set of minimal violating traces ( ğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ ) from the
event logğ¸ğ¿withğ‘‡=â„ğ‘œğ‘¢ğ‘Ÿğ‘  ,ğ¿= 2,ğ¾= 2,ğ¶= 50% ,ğ›©= 25% ,disease as the sensitive attribute îˆ¿, andğ‘ğ‘˜ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿas the background
knowledge, i.e., ğ‘ğ‘ =îˆ­Ã—îˆ¾Ã—î‰€. fig. 4 shows the ğ‘€ğ¹ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ andğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ generated by line 2 in algorithm 1, where each root-to-leaf
path represents one trace, and each node represents an event in a trace with the frequency of occurrence. table 6 shows the initial
score of every event (node) in the ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ (ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ¸ğ¿
ğ‘ğ‘ (ğ‘’)). line 4 determines the winner event ğ‘’ğ‘¤which is (ğ‘‰ğ¼,ğ· 1,5). line 5 deletes
all the mvts and mfts containing the winner event ğ‘’ğ‘¤, i.e., subtree 2 and the path âŸ¨(ğ‘…ğ¸,ğ¸ 4,1),(ğ‘‰ğ¼,ğ· 1,5)âŸ©of subtree 1 in the
ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ , and the path âŸ¨(ğ»ğ‘‚,ğ¸ 3,4),(ğ‘‰ğ¼,ğ· 1,5),(ğµğ‘‡,ğ‘ 1,7)âŸ©of subtree 4 in the ğ‘€ğ¹ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ are removed and frequencies get updated.
line 6 updates the scores based on the new frequencies of events. table 7 shows the remaining events in ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ with the updated
scores. line 7 adds the winner event to a suppression set ğ‘†ğ‘¢ğ‘ğ¸ğ¿. lines 4â€“7 is repeated until there is no node in ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ . according
to table 7 the next winner event is (ğ‘…ğ¸,ğ¸ 4,1), and after deleting all the mvts and mfts containing this event, ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ is empty.
therefore, at the end of the while loop, the suppression set ğ‘†ğ‘¢ğ‘ğ¸ğ¿= {(ğ‘‰ğ¼,ğ· 1,5),(ğ‘…ğ¸,ğ¸ 4,1)}. the foreach loop suppresses all
the instances of the events, i.e., global suppression , in theğ‘†ğ‘¢ğ‘ğ¸ğ¿from theğ¸ğ¿, and the last line returns the suppressed ğ¸ğ¿as the
anonymized event log ğ¸ğ¿â€²which is shown in table 8.
compared to tables 4 and 5 which are the results of applying traditional ğ‘˜-anonymity using baseline -2, table 8 shows that
ğ‘‡ğ¿ğ¾ğ¶ -privacy removes less events (only 6), for the stronger privacy requirements.
5.2.4. new utility measure and new score
in this subsection, we first describe the shortcomings of the utility measure and the score introduced in [5] (extended in
definitions 17 and 18), then we introduce a new utility measure and a new score to overcome the drawbacks. according to
definition 18, the score is calculated based on the existence of events in the set of minimal violating traces and the set of maximal
11m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
table 6
the initial scores for the events in fig. 4(b).
(ğ‘…ğ¸,ğ¸ 4,1) (ğ»ğ‘‚,ğ¸ 3,4) (ğ‘‰ğ¼,ğ· 1,5) (ğµğ‘‡,ğ‘ 1,7) (ğ‘‰ğ¼,ğ· 1,8) (ğ‘…ğ¿,ğ¸ 2,9)
ğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’) 3 1 3 1 1 1
ğ‘ˆğ¿ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) + 1 4 4 2 5 6 5
ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) 0.75 0.25 1.50 0.20 0.16 0.20
table 7
the first updated scores.
(ğ‘…ğ¸,ğ¸ 4,1) ( ğ»ğ‘‚,ğ¸ 3,4) ( ğµğ‘‡,ğ‘ 1,7)
ğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’) 2 1 1
ğ‘ˆğ¿ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) + 1 4 3 4
ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) 0.5 0.33 0.25
frequent traces. however, the sizes of these sets, and consequently the included events, highly depends on the corresponding
parameters. the set of mvts is obtained based on ğ‘‡,ğ¿,ğ¾,ğ¶, andğ‘ğ‘˜ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡ , while the set of mfts is discovered based on ğ›©and the
given perspective. therefore, some of the events included in the set of minimal violating traces may not be included in the set of
maximal frequent traces. consequently, the score of the corresponding events is merely calculated based on the effect on the privacy
gain. when two or more events have the same score based on the privacy gain , the algorithm assumes an equal effect for the data
utility aspect and randomly choose one of the events, which is not a valid assumption.
another problem with the current score is that even when there are maximal frequent traces where the event is included, the
score does not differentiate the corresponding mfts based on their frequencies in the event log. for example, suppose that for two
eventsğ‘’1andğ‘’2in the minimal violating traces there are two maximal frequent traces ğ‘€ğ¹ğ‘‡1andğ‘€ğ¹ğ‘‡2such thatğ‘’1is only included
inğ‘€ğ¹ğ‘‡1, i.e.,ğ‘ˆğ¿(ğ‘’1) = 1, andğ‘’2is only included in ğ‘€ğ¹ğ‘‡2, i.e.,ğ‘ˆğ¿(ğ‘’2) = 1. hence, both events get the same score for the utility
aspect. however, the corresponding mfts may have completely different frequencies in the event log which leads to a different
impact on the utility. particularly, this issue is highlighted when the frequency threshold ( ğ›©) is rather low. for example, if ğ›©= 50% ,
then frequency of ğ‘€ğ¹ğ‘‡1andğ‘€ğ¹ğ‘‡2in the event log could differ up to 50%. furthermore, the current score is not normalized, and
it is not possible for the user to adjust the effect of each aspect on the score. for example, one may want to consider more effect
for the data utility aspect compared to the privacy gain aspect.
to overcome the above-mentioned shortcomings, we define a new utility measure that is able to show the impact of every single
event on the data utility. we also define a new score based on the new utility measure which provides normalized scores, and the
effect of each aspect is adjustable for users. in the new utility measure (definition 19), we consider the relative frequency of the
variants, where the given perspective of the event is included, as the basis of the utility.
definition 19 (new utility measure ).letğ¸ğ¿be an event log, ğ‘ğ‘ âˆˆîˆ¼îˆ¿be a perspective, and ğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ğ‘ ğ‘ğ‘ (ğ¸ğ¿) = {ğ‘’âˆˆğœ‹ğ‘ğ‘ (ğœ) âˆ£ (ğ‘,ğœ,ğ‘  ) âˆˆ
ğ¸ğ¿}be the set of events in the event log w.r.t. the given perspective. for ğ‘’âˆˆğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ğ‘ ğ‘ğ‘ (ğ¸ğ¿),ğ‘›ğ‘ˆğ¿ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) = 1âˆ’âˆ‘
{ğœâˆˆÌƒğ¸ğ¿âˆ£ğ‘’âˆˆğœ‹ğ‘ğ‘ (ğœ)}ğ‘“ğ‘Ÿğ‘’ğ‘ğ¸ğ¿(ğœ).
definition 20 (new score ).letğ¸ğ¿be an event log, ğ‘ğ‘ âˆˆîˆ¼îˆ¿be a perspective, ğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ğ‘ ğ‘ğ‘ (ğ¸ğ¿) = {ğ‘’âˆˆğœ‹ğ‘ğ‘ (ğœ) âˆ£ (ğ‘,ğœ,ğ‘  ) âˆˆğ¸ğ¿}be the set
of events in the event log w.r.t. the given perspective, ğ›¼be the coefficient of privacy gain (0â‰¤ğ›¼â‰¤1),ğ›½be the coefficient of utility
loss(0â‰¤ğ›½â‰¤1), andğ›¼+ğ›½= 1.ğ‘›-ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ¸ğ¿
ğ‘ğ‘ âˆ¶îˆ±â†›r>0is a function which retrieves the score of the events in the event log w.r.t. the
perspective. for ğ‘’âˆˆğ‘’ğ‘£ğ‘’ğ‘›ğ‘¡ğ‘ ğ‘ğ‘ (ğ¸ğ¿),ğ‘›-ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ğ¸ğ¿
ğ‘ğ‘ (ğ‘’) =ğ›¼â‹…ğ‘Ÿğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’) +ğ›½â‹…ğ‘›ğ‘ˆğ¿ğ¸ğ¿
ğ‘ğ‘ (ğ‘’), whereğ‘Ÿğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’)is the relative value of the privacy
gain, i.e.,ğ‘Ÿğ‘ƒğºğ¸ğ¿
ğ‘ğ‘ (ğ‘’) =|{ğ‘¥âˆˆğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ âˆ£ğ‘’âˆˆğ‘¥}|âˆ•|ğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ |.
algorithm 2 shows the new algorithm based on the new utility measure and new score, where maximal frequent traces are not
used anymore, and the score of events included in the minimal violating traces is calculated based on the new score. note that in
both algorithm 1 and algorithm 2 the perspective is derived from the background knowledge type and attribute (fig. 2).
6. experiments
in this section, we evaluate the extended ğ‘‡ğ¿ğ¾ğ¶ -privacy by applying it to real-life event logs. we explore the effect of applying
the technique on both data utility andresult utility . the results are also compared with the baseline methods. the result utility analysis
evaluates the similarity of the specific results obtained from the privacy-aware event log with the same type of results obtained from
the original event log, while the data utility analysis compares the privacy-aware event log with the original event log. as discussed
in [8], the result utility analysis is highly dependent on the underlying algorithm generating specific results, and the data utility
analysis provides a more general evaluation. we perform the evaluation for the three main perspectives including control-flow ,
organizational , and timeperspectives. for the result utility analysis, in each perspective, we focus on a specific type of results. for
the control-flow perspective, we focus on process discovery , for the organizational perspective, we perform social network discovery ,
and for the time perspective, we perform bottleneck analysis . the implementation as a python program is available on github.1
1https://github.com/m4jidrafiei/tlkc-privacy-ext.
12m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
algorithm 2: ğ‘‡ğ¿ğ¾ğ¶ -privacy - extended w.r.t. the different perspectives, new score, and new utility measure.
input : original event log ğ¸ğ¿
input :ğ‘‡,ğ¿,ğ¾,ğ¶
input : background knowledge type and attribute ( ğ‘ğ‘˜ğ‘¡ğ‘¦ğ‘ğ‘’,ğ‘ğ‘¡ğ‘¡ ), sensitive attributes îˆ¿
output : anonymized event log ğ¸ğ¿â€²which satisfies the desired ğ‘‡ğ¿ğ¾ğ¶ -privacy requirements
1generateğ‘€ğ‘‰ğ‘‡ğ¸ğ¿
ğ‘ğ‘ andğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ ;
2while there is node (event) in ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ do
3 select an event (node) ğ‘’ğ‘¤that has the highest score to suppress based on ğ‘›-ğ‘ ğ‘œğ‘ğ‘Ÿğ‘’ (ğ‘’)ğ¸ğ¿
ğ‘ğ‘ ;
4 delete all the mvts containing the event ğ‘’ğ‘¤fromğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ ;
5 updateğ‘›-ğ‘ ğ‘œğ‘ğ‘Ÿğ‘’ (ğ‘’)ğ¸ğ¿
ğ‘ğ‘ for all the remaining events (nodes) in ğ‘€ğ‘‰ğ‘‡ğ‘¡ğ‘Ÿğ‘’ğ‘’
ğ‘ğ‘ ;
6 addğ‘’ğ‘¤to the suppression set ğ‘†ğ‘¢ğ‘ğ¸ğ¿;
7end
8foreachğ‘’âˆˆğ‘†ğ‘¢ğ‘ğ¸ğ¿do
9 suppress all instances of ğ‘’fromğ¸ğ¿;
10end
11return suppressed ğ¸ğ¿asğ¸ğ¿â€²;
table 8
the anonymized event log for table 3 with ğ‘‡=hours,ğ¿= 2,ğ¾= 2,ğ¶= 50% ,
ğ›©= 25% ,îˆ¿=disease, and ğ‘ğ‘˜ğ¸ğ¿
ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘Ÿ.
case id trace disease
1 <(ho,e3,4),(bt,n1,7),(vi,d1,8) > cancer
2 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > infection
3 <(ho,e3,4),(bt,n1,7),(rl,e2,9) > corona
4 <(vi,d1,6),(vi,d1,8),(rl,e2,9) > infection
5 <(ho,e3,4),(vi,d1,8),(rl,e2,9) > corona
6 <(vi,d1,6),(bt,n1,7),(rl,e2,9) > flu
7 <(bt,n1,7),(vi,d1,8),(rl,e2,9) > flu
8 <(vi,d1,6),(bt,n1,7),(vi,d1,8) > cancer
table 9
the general statistics of the event logs used in the experiments.
event log #cases #events #unique
activity#unique
resource#unique
(activity, resource)
sepsis-cases [14] 1050 15,214 16 â€“ â€“
bpic-2012-app [15] 13,087 60,849 10 61 301
bpic-2017-app [17] 31,509 2,39,595 10 144 927
table 10
some statistics regarding the variants of the event logs used in the experiments w.r.t. the different
perspectives.
event log #variants activity
perspective#variants resource
perspective#variants (activity,
resource) perspective
sepsis-cases [14] 846 â€“ â€“
bpic-2012-app [15] 17 2974 3872
bpic-2017-app [17] 102 24,230 24,471
6.1. experimental setup
for the experiments, we employ two human-centered event logs, where the case identifiers refer to individuals: sepsis-cases,
bpic-2012-app, and bpic-2017-app. sepsis-cases [14] is a real-life event log containing events of sepsis cases from a hospital.
bpic-2012-app [15] is also a real-life event log about a loan application process taken from a dutch financial institute. bpic-2017-
app also pertains to a loan application process of a dutch financial institute. table 9 shows the general statistics of these event
logs. the sepsis-cases event log was included in the experiments because it has some challenging features for privacy preservation
techniques, namely, 80% of traces are unique based on the activity perspective which imposes significant challenges for privacy-
preserving process discovery algorithms [5,13,16]. bpic-2017-app has similar properties w.r.t. the resource perspective, i.e., 76%
of traces are unique w.r.t. the resource perspective. note that sepsis-cases does not contain resource information and cannot be
used for the organizational perspective analysis. we employ bpic-2012-app and bpic-2017-app for the organizational perspective.
table 10 shows some statistics about the variants with respect to different perspectives. for example, as mentioned, in sepsis-cases,
80% of traces are unique from the activity perspective, or in bpic-2017-app, 76% of traces are unique from the resource perspective.
overall, we performed more than 1000 experiments for the four different types of background knowledge and different
perspectives. 200 different settings are used based on the following values for the main parameters: ğ¿âˆˆ {2,3,4,5,6},ğ¾âˆˆ
{20,30,40,50,60},ğ¶âˆˆ {0.2,0.3,0.4,0.5}, andğ‘‡âˆˆ {â„ğ‘œğ‘¢ğ‘Ÿğ‘ ,ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘  }. we consider equal weights for the privacy gain and utility loss
13m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 5. the quality measures comparison between the four variants of ğ‘‡ğ¿ğ¾ğ¶ andğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ , the original results, and the baseline methods for sepsis-cases.
aspects of the score, i.e., ğ›¼= 0.5andğ›½= 0.5. in sepsis-cases, â€˜â€˜diagnose" and â€˜â€˜age" are considered as the sensitive case attribute.
the numerical attributes are converted to categorical attributes using boxplots such that all the values greater than the upper quartile
are categorized as high, the values less than the lower quartile are categorized as low, and the values in between are categorized as
middle . note that the confidence value ğ¶should not be greater than 0.5, i.e., there are at least two different sensitive values for a
victim case. to show and interpret the results of experiments, we focus on specific strong and weak settings. we use ğ‘‡=ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘  ,
ğ¿= 2,ğ¾= 20, andğ¶= 0.5as the weak setting, and ğ‘‡=ğ‘šğ‘–ğ‘›ğ‘¢ğ‘¡ğ‘’ğ‘  ,ğ¿= 6,ğ¾= 60, andğ¶= 0.2as the strong setting. note that
in the experiments, ğ‘‡ğ¿ğ¾ğ¶ refers to the algorithm presented in [5] which has been extended here w.r.t. the different perspectives,
i.e., algorithm 1, and ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ refers to algorithm 2.
6.2. control-flow perspective
in this subsection, we evaluate the effect of applying the extended ğ‘‡ğ¿ğ¾ğ¶ -privacy on the result utility anddata utility with respect
to the control-flow perspective. we perform the control-flow perspective analysis for both event logs.
6.2.1. result utility
as mentioned, for the result utility analysis of the control-flow perspective, we focus on process discovery . the main goal is to
find out how accurately the discovered process model from a privacy-aware event log capture the behavior of the original event log . to this
end, we first discover a process model ğ‘€â€²from the privacy-aware event log ğ¸ğ¿â€². then, for ğ‘€â€², we calculate fitness ,precision , and
f1-score , as some model quality measures, w.r.t. the original event log ğ¸ğ¿.
fitness quantifies the extent to which the discovered model can reproduce the traces recorded in the event log [18]. precision
quantifies the fraction of the traces allowed by the model which is not seen in the event log [19], and f1-score combines the fitness
and precision ğ‘“1-ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ =2Ã—ğ‘ğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› Ã—ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘  âˆ•ğ‘ğ‘Ÿğ‘’ğ‘ğ‘–ğ‘ ğ‘–ğ‘œğ‘› +ğ‘“ğ‘–ğ‘¡ğ‘›ğ‘’ğ‘ ğ‘  . for process discovery, we use the inductive miner infrequent algorithm [20]
with the default parameters (noise threshold 0.2). fig. 5 shows the results of experiments for the quality measures. we consider
four variants of our privacy preservation technique based on the introduced types of background knowledge where the attribute
isactivity , i.e.,ğ‘ğ‘˜ğ‘ ğ‘’ğ‘¡,ğ‘ğ‘¡,ğ‘ğ‘˜ğ‘šğ‘¢ğ‘™ğ‘¡,ğ‘ğ‘¡ ,ğ‘ğ‘˜ğ‘ ğ‘’ğ‘,ğ‘ğ‘¡, andğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘¡. note that applying privacy preservation techniques may improve some quality
measures. however, the aim is to provide as similar results as possible to the original ones and not to improve the quality of
discovered models. therefore, we include the results from the original event log to compare the proximity of the values.
figs. 5(a) and 5(b) show how the mentioned quality measures are affected by applying our method with the weak and strong
settings (for ğ‘‡ğ¿ğ¾ğ¶ , we setğ›©= 0.5). we compare the measures with the results from the original process model and the introduced
baseline methods. if we only consider the quality measures, baseline -2 should be marked as the best one, since it results in better
f1-score values. however, the baseline methods remove more events from the original event log. consequently, the corresponding
privacy-aware event logs contain significantly less behavior compared to the original event log, and the resulting models have high
precision and f1-score . the result utility analyses show that the extended version of the ğ‘‡ğ¿ğ¾ğ¶ -privacy leads to the more similar
results to the original ones, specifically for the setandmultiset types of background knowledge. however, the results obtained based
on the relative type of background knowledge have a worse fitness value which is not surprising regarding the assumed background
knowledge which is considerably strong, at the same time, difficult to achieve in reality. note that the baseline methods do not
protect event data against the attribute linkage attack and provide weaker privacy guarantees.
6.2.2. data utility
for the data utility analysis, we utilize the earth moverâ€™s distance , as proposed in [8]. the earth moverâ€™s distance describes the
distance between two distributions [21]. in an analogy, given two piles of earth, it describes the effort required to transform one
pile into the other. assuming ğ¸ğ¿as the original event log, ğ¸ğ¿â€²as a privacy-aware event log, and ğ‘ğ‘ âˆˆîˆ¼îˆ¿as the perspective of
analysis. the data utility is calculated as follows: ğ‘‘ğ‘¢(ğ¸ğ¿,ğ¸ğ¿â€²) = 1âˆ’minğ‘Ÿâˆˆîˆ¾îˆ­ğ‘¢ğ‘™(ğ‘Ÿ,ğ¸ğ¿ğ‘ğ‘ ,ğ¸ğ¿â€²ğ‘ğ‘ )whereğ‘¢ğ‘™(ğ‘Ÿ,ğ¸ğ¿ğ‘ğ‘ ,ğ¸ğ¿â€²ğ‘ğ‘ )is the distance
between the traces of two event logs projected on the given perspective. note that ğ‘Ÿâˆˆîˆ¾îˆ­is used as a reallocation function, and
normalized edit distance (levenshtein) [22] is used to calculate the distance between variants. it should also be noted that for the
control-flow ğ‘ğ‘ =îˆ­.
14m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 6. the data utility comparison between ğ‘‡ğ¿ğ¾ğ¶ andğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ which provide the same privacy guarantees for the sepsis-cases event log.
fig. 7. the data and result utility analyses for bpic-2012-app considering the strong setting.
fig. 6 shows the results of data utility analysis where we compare ğ‘‡ğ¿ğ¾ğ¶ andğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ which provide the same privacy
guarantees. as can be seen, for the weak privacy setting, the data utility results are similar, and ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ performs slightly
better for the stronger types of background knowledge. for the strong privacy setting, ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ performs considerably better
for the multiset and sequence types of background knowledge. comparing the data utility analysis with the result utility analysis
shows that the model quality measures alone cannot precisely evaluate the effectiveness of the privacy preservation techniques.
for example, in the result utility analysis, for both weak and strong setting, ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ results in an acceptable f1-score value.
however, the data utility analysis shows that the utility loss is indeed high for this type of background knowledge.
as already mentioned, the sepsis-cases event log is a significantly challenging dataset for the privacy preservation techniques
due to the high uniqueness of variants. to show the effectiveness of our privacy preservation technique on other event logs, we
perform the same type of analyses for bpic-2012-app considering only the strong setting. fig. 7 shows that both data and result
utility are high even for the strong types of background knowledge.
6.3. organizational perspective
in this subsection, we evaluate the effect of applying the extended ğ‘‡ğ¿ğ¾ğ¶ -privacy on the result and data utility of the
organizational perspective. the experiments of this perspective are done on bpic-2012-app which includes resource information.
6.3.1. result utility
for the result utility analysis of organizational perspective, we focus on the social network discovery techniques. there are different
methods for discovering social networks from event logs such as causality-based ,joint activities ,joint cases , etc [23]. here, we focus
on the handover technique which is causality-based. this technique monitors for individual cases how work moves from resource to
resource, i.e., there is a handover relation from individual ğ‘Ÿ1to individual ğ‘Ÿ2, if there are two subsequent activities where the first
is performed by ğ‘Ÿ1and the second is performed by ğ‘Ÿ2.
fig. 8 shows the handover networks discovered from the original event log and a privacy-aware event log when the relation
threshold is 0, i.e., all the handovers. the privacy-aware event log was obtained using the ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ privacy preservation
technique with the strong setting and setas the type of background knowledge. as expected, the density of the network discovered
from the privacy-aware event log is less than the original handover network. however, by focusing on some specific nodes, one can
15m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 8. the handover networks discovered from the original event log and a privacy-aware event log for bpic-2012-app. the privacy-aware event log was
obtained using ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ with the strong setting and setas the type of background knowledge.
see that basic concepts are preserved. for example, node 11339 in the original handover network has the following set of input links
{11302,11003,11300,11121,11122,11180,10932,10861} and no output link (excluding the self-loop), and in the network discovered
from the privacy-aware event log, only the input link from node 11121 is removed.
to quantify the similarity of social networks resulting from an original and a privacy-aware event log, we use a set of
measures similar to the quality measure of process models, i.e., fitness ,precision , and f1-score . consider ğ‘†ğ‘ = (ğ‘…ğ¸ğ¿,ğ·ğ¹ğ¸ğ¿
îˆ¾)and
ğ‘†ğ‘â€²= (ğ‘…ğ¸ğ¿â€²,ğ·ğ¹ğ¸ğ¿â€²
îˆ¾)as the handover social networks obtained from an original event log and its corresponding privacy-aware
event log, respectively. since both ğ‘‡ğ¿ğ¾ğ¶ andğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ provide privacy guarantees by removing events, the vertices of ğ‘†ğ‘â€²is a
subset of vertices in ğ‘†ğ‘, i.e.,ğ‘…ğ¸ğ¿âŠ†ğ‘…ğ¸ğ¿â€². however, the set of edges in ğ‘†ğ‘â€²is not necessarily a subset of edges in ğ‘†ğ‘, i.e.,ğ‘†ğ‘â€²is
not necessarily a subgraph of ğ‘†ğ‘. the following equations are used to compute the fitness (ğ¹ğ‘ ğ‘›) and the precision (ğ‘ƒğ‘ ğ‘›) for handover
networks. the f1-score for handover networks ( ğ¹1ğ‘ ğ‘›) is the harmonic mean of ğ¹ğ‘ ğ‘›andğ‘ƒğ‘ ğ‘›.
ğ¹ğ‘ ğ‘›=âˆ‘
(ğ‘¥,ğ‘¦)âˆˆğ·ğ¹ğ¸ğ¿
îˆ¾âˆ©ğ·ğ¹ğ¸ğ¿â€²
îˆ¾|ğ‘¥>ğ¸ğ¿â€²
îˆ¾ğ‘¦|
âˆ‘
(ğ‘¥,ğ‘¦)âˆˆğ·ğ¹ğ¸ğ¿
îˆ¾|ğ‘¥>ğ¸ğ¿
îˆ¾ğ‘¦|
ğ‘ƒğ‘ ğ‘›=|(ğ‘…ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿)â§µğ·ğ¹ğ¸ğ¿
îˆ¾âˆ© (ğ‘…ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿)â§µğ·ğ¹ğ¸ğ¿â€²
îˆ¾|
|(ğ‘…ğ¸ğ¿Ã—ğ‘…ğ¸ğ¿)â§µğ·ğ¹ğ¸ğ¿
îˆ¾|
16m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 9. the social network comparison based on fitness (ğ¹ğ‘ ğ‘›),precision (ğ‘ƒğ‘ ğ‘›), and f1-score (ğ¹1ğ‘ ğ‘›). the privacy preservation technique is ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ with the
strong setting.
fig. 10. the data utility analysis of organizational perspective for bpic-2012-app with the strong and weak settings considering different types of background
knowledge, and using ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ as the privacy preservation technique.
fig. 9 shows the similarity of handover social networks after applying the ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ privacy model with the strong setting
to bpic-2012-app and bpic-2017-app. the precision is high for all the types of background knowledge, i.e., the handover social
networks obtained from the privacy-aware event logs often do not contain edges that do not exist in the original network. the
fitness decreases when the background knowledge becomes stronger, i.e., the ğ‘†ğ‘â€²s obtained based on stronger assumptions for the
background knowledge have fewer edges in common with the ğ‘†ğ‘.
6.3.2. data utility
for the data utility analysis of the organizational perspective, we utilize the earth moverâ€™s distance, similar to the data utility
analysis of the control-flow perspective. here, the perspective is resource, i.e., ğ‘ğ‘ =îˆ¾. fig. 10 shows the results for the data utility
analysis for bpic-2012-app considering different types of background knowledge using ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ as the privacy preservation
technique. as can be seen, the data utility reservation is above 0.5 even for the strong types of background knowledge.
6.4. time perspective
we evaluate the effect on performance analyses by analyzing the bottlenecks w.r.t. the mean duration of cases between activities.
since the privacy preservation techniques may remove some activities, we cannot compare the bottlenecks in the original process
model with the bottlenecks in a process model discovered from a privacy-aware event log. therefore, we first project the original
event log on the activities existing in the privacy-aware event log. then, we discover a performance-annotated directly follows
graphğ·ğ¹ğº from the projected event log and compare it with the performance-annotated directly follows graph ğ·ğ¹ğºâ€²from the
privacy-aware event log. a dfg is a graph where the nodes represent activities and the arcs represent causalities. two activities ğ‘1
andğ‘2are connected by an arrow when ğ‘1is frequently followed by ğ‘2[24].
fig. 11 ( setand multiset as the types of background knowledge) and fig. 12 ( sequence and relative as the types of background
knowledge) show the results for sepsis-cases using ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ with the strong setting.2as can be seen, the bottlenecks in ğ·ğ¹ğº
andğ·ğ¹ğºâ€²are the same for all the variants, except for dfgs discovered using ğ‘ğ‘˜ğ‘Ÿğ‘’ğ‘™,ğ‘ğ‘, where the assumed background knowledge
2the results provided by disco (https://fluxicon.com/disco/) with the sliders set to the maximal number of activities and the minimal paths.
17m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 11. the performance-annotated dfgs from the projected event log ( ğ·ğ¹ğº ) and an anonymized event log ( ğ·ğ¹ğºâ€²) for sepsis-cases using ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ with
the strong setting and the specified types of background knowledge.
fig. 12. the performance-annotated dfgs from the projected event log ( ğ·ğ¹ğº ) and an anonymized event log ( ğ·ğ¹ğºâ€²) for sepsis-cases using ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ with
the strong setting and the specified types of background knowledge.
isrelative which is significantly strong and our data utility analysis in section 6.2 demonstrated a low data utility preservation
for sepsis-cases. note that the mean duration of the cases are different in ğ·ğ¹ğº andğ·ğ¹ğºâ€²due to the relative timestamps in the
privacy-aware event logs.
we also evaluate the similarity of the directly follows graphs (dfgs) resulting from an original event log and its corresponding
privacy-aware event log. let ğ·ğ¹ğº =(ğ´ğ¸ğ¿,ğ·ğ¹ğ¸ğ¿
îˆ­)andğ·ğ¹ğºâ€²=(ğ´ğ¸ğ¿â€²,ğ·ğ¹ğ¸ğ¿â€²
îˆ­)be the directly follows graphs obtained from an original
and its corresponding privacy-aware event logs, respectively. to compare these graphs, we follow the same approach taken for
quantifying the similarity of social networks. the fitness (ğ¹ğ‘‘ğ‘“ğ‘”) and precision (ğ‘ƒğ‘‘ğ‘“ğ‘”) for dfgs are calculated as follows:
ğ¹ğ‘‘ğ‘“ğ‘”=âˆ‘
(ğ‘¥,ğ‘¦)âˆˆğ·ğ¹ğ¸ğ¿
îˆ­âˆ©ğ·ğ¹ğ¸ğ¿â€²
îˆ­|ğ‘¥>ğ¸ğ¿â€²
îˆ­ğ‘¦|
âˆ‘
(ğ‘¥,ğ‘¦)âˆˆğ·ğ¹ğ¸ğ¿
îˆ­|ğ‘¥>ğ¸ğ¿
îˆ­ğ‘¦|
ğ‘ƒğ‘‘ğ‘“ğ‘”=|(ğ´ğ¸ğ¿Ã—ğ´ğ¸ğ¿)â§µğ·ğ¹ğ¸ğ¿
îˆ­âˆ© (ğ´ğ¸ğ¿Ã—ğ´ğ¸ğ¿)â§µğ·ğ¹ğ¸ğ¿â€²
îˆ­|
|(ğ´ğ¸ğ¿Ã—ğ´ğ¸ğ¿)â§µğ·ğ¹ğ¸ğ¿
îˆ­|
the f1-score for dfgs (ğ¹1ğ‘‘ğ‘“ğ‘”) is the harmonic mean of ğ¹ğ‘‘ğ‘“ğ‘”andğ‘ƒğ‘‘ğ‘“ğ‘”. fig. 13 shows the similarity of dfgs after applying the
ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ privacy model with the strong setting for sepsis-cases, bpic-2012-app, and bpic-2017-app. the precision is always
high, i.e., the dfgs obtained from the privacy-aware event logs often do not contain directly follows relations that do not exist in the
18m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
fig. 13. the dfg comparison based on fitness (ğ¹ğ‘‘ğ‘“ğ‘”),precision (ğ‘ƒğ‘‘ğ‘“ğ‘”), and f1-score (ğ¹1ğ‘‘ğ‘“ğ‘”). the privacy preservation technique is ğ‘‡ğ¿ğ¾ğ¶ -ğ¸ğ‘‹ğ‘‡ with the strong
setting.
original dfg. for the sepsis-cases event log, the fitness decreases when the background knowledge becomes stronger, i.e., the ğ·ğ¹ğºâ€²s
obtained based on stronger assumptions for the background knowledge preserve fewer directly follows relations of the original dfg.
the fitness for the bpic event logs only drops for the relative type of background knowledge which is considerably strong.
7. related work
in process mining, the research field of confidentiality and privacy is recently receiving more attention. in this section, we list the
work that has been done in this research field which is rapidly growing. in [25], responsible process mining (rpm) is introduced as
the sub-discipline which focuses on possible negative side-effects of applying process mining where fairness ,accuracy ,confidentiality ,
andtransparency (fact) are considered as the concerns. in [26], the authors provide an overview of privacy challenges in process
mining in human-centered industrial environments. in [27], a method to secure event logs for performing process discovery by the
alpha algorithm is proposed. in [28], the aim is to propose a solution which allows the outsourcing of process mining while ensuring
confidentiality. in [29], the goal is to propose a privacy-preserving system design for process mining, where a user-centered view
is considered to track personal data. in [30,31], a framework is proposed which provides a generic scheme for confidentiality in
process mining. in [32], the authors introduce a privacy-preserving method for discovering roles from event logs. in [33], the authors
consider a cross-organizational process discovery context and share public process model fragments as safe intermediates. in [13],
the authors apply ğ‘˜-anonymity and ğ‘¡-closeness on event logs to preserve the privacy of resources . in [16,34], the notion of differential
privacy is employed to preserve the privacy of event logs. in [5], the ğ‘‡ğ¿ğ¾ğ¶ -privacy is introduced to cope with high variability issues
in event logs for applying group-based anonymization techniques. in [35], a uniformization-based approach is proposed to preserve
individualsâ€™ privacy in process mining. in [36], a secure multi-party computation solution is introduces for preserving privacy in
an inter-organizational setting for process discovery . in [37], the data privacy and utility requirements for healthcare event data are
analyzed. in [38], the authors propose a privacy extension for the xes standard3to manage privacy metadata. in [39], the authors
propose a measure to evaluate the re-identification risk of event logs. also, in [8], a general privacy quantification framework, and
some measures are introduced to evaluate the effectiveness of privacy preservation techniques. some tools are also provided for
applying the state-of-the-art privacy preservation techniques in the field of process mining such as ppdp-pm [40], elpaas [41], and
shareprom [42].
3https://xes-standard.org/.
19m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
8. conclusion
in this paper, we discussed the challenges regarding directly applying traditional group-based privacy preservation techniques
to event logs. we discussed the linkage attacks and provided formal models of the possible attacks based on the different types of
background knowledge. we extended the ğ‘‡ğ¿ğ¾ğ¶ -privacy for process mining to cover all the main perspectives of process mining.
the data utility preservation aspect of the ğ‘‡ğ¿ğ¾ğ¶ -privacy was improved by introducing a new utility measure. moreover, a new score
equation was proposed to generate normalized scores for the events that need to be removed. the new equation for the score also
provides privacy gain andutility loss coefficients that can be adjusted by users. obviously, the extended version of the ğ‘‡ğ¿ğ¾ğ¶ -privacy
inherits all the characteristics of the main approach. namely, it counteracts both the case linkage and the attribute linkage attacks. it
generalizes several privacy preservation techniques including ğ‘˜-anonymity, confidence bounding, ( ğ›¼,ğ‘˜)-anonymity, and ğ‘™-diversity.
it also provides interpretable and tunable parameters.
similar to the main approach, we implemented four variants of the extended version with respect to the four different types of
background knowledge and considering all the main perspectives. the effectiveness of different variants in different perspectives
was evaluated based on real-life event logs. both data and result utility were analyzed to evaluate the effectiveness. overall more
than 1000 experiments were performed for different types of background knowledge considering different perspectives, and the
results were given for a weak and a strong setting. our experiments showed that the extended ğ‘‡ğ¿ğ¾ğ¶ -privacy performs better than
the previous version considering the data utility preservation aspect. however, in the event logs with the high ratio of unique traces,
when the assumed type of background knowledge is very specific, e.g., relative , the group-based privacy preservation techniques
may not be able to preserve the general data utility, and this negative effect cannot be observed by only result utility analyses.
credit authorship contribution statement
majid rafiei: conceptualization, methodology, software, validation, formal analysis, investigation, resources, data curation,
writing - original draft, writing - review & editing, visualization. wil m.p. van der aalst: conceptualization, methodology,
validation, formal analysis, resources, data curation, writing - review & editing, visualization, supervision, project administration.
declaration of competing interest
the authors declare that they have no known competing financial interests or personal relationships that could have appeared
to influence the work reported in this paper.
acknowledgment
funded under the excellence strategy of the federal government and the lÃ¤nder, germany. we also thank the alexander von
humboldt (avh) stiftung for supporting our research.
references
[1] w.m.p. van der aalst, process mining - data science in action, second ed., springer, 2016, http://dx.doi.org/10.1007/978-3-662-49851-4.
[2] w.g. voss, european union data privacy law reform: general data protection regulation, privacy shield, and the right to delisting, bus. lawyer 72 (1)
(2016).
[3] l. sweeney, k-anonymity: a model for protecting privacy, int. j. uncertain. fuzziness knowl.-based syst. 10 (05) (2002) 557â€“570.
[4] a. machanavajjhala, j. gehrke, d. kifer, m. venkitasubramaniam, l-diversity: privacy beyond k-anonymity, in: 22nd international conference on data
engineering, icdeâ€™06, ieee, 2006, p. 24.
[5] m. rafiei, m. wagner, w.m.p. van der aalst, tlkc-privacy model for process mining, in: f. dalpiaz, j. zdravkovic, p. loucopoulos (eds.), research
challenges in information science - 14th international conference, rcis 2020, limassol, cyprus, september 23â€“25, 2020, proceedings, in: lecture notes
in business information processing, vol. 385, springer, 2020, pp. 398â€“416, http://dx.doi.org/10.1007/978-3-030-50316-1_24.
[6] k. wang, b.c.m. fung, p.s. yu, handicapping attackerâ€™s confidence: an alternative to k-anonymization, knowl. inf. syst. 11 (3) (2007) 345â€“368,
http://dx.doi.org/10.1007/s10115-006-0035-5.
[7] r.c. wong, j. li, a.w. fu, k. wang, (alpha, k)-anonymity: an enhanced k-anonymity model for privacy preserving data publishing, in: t. eliassi-rad, l.h.
ungar, m. craven, d. gunopulos (eds.), proceedings of the twelfth acm sigkdd international conference on knowledge discovery and data mining,
philadelphia, pa, usa, august 20â€“23, 2006, acm, 2006, pp. 754â€“759, http://dx.doi.org/10.1145/1150402.1150499.
[8] m. rafiei, w.m.p. van der aalst, towards quantifying privacy in process mining, in: international conference on process mining - icpm 2020 international
workshops, padua, italy, october 4â€“9, 2020, 2020.
[9] n. li, t. li, s. venkatasubramanian, t-closeness: privacy beyond k-anonymity and l-diversity, in: r. chirkova, a. dogac, m.t. Ã¶zsu, t.k. sellis (eds.),
proceedings of the 23rd international conference on data engineering, icde 2007, the marmara hotel, istanbul, turkey, april 15â€“20, 2007, ieee computer
society, 2007, pp. 106â€“115, http://dx.doi.org/10.1109/icde.2007.367856.
[10] c.c. aggarwal, s.y. philip, privacy-preserving data mining: models and algorithms, springer science & business media, 2008.
[11] c.c. aggarwal, on k-anonymity and the curse of dimensionality, in: k. bÃ¶hm, c.s. jensen, l.m. haas, m.l. kersten, p. larson, b.c. ooi (eds.), proceedings
of the 31st international conference on very large data bases, trondheim, norway, august 30 - september 2, 2005, acm, 2005, pp. 901â€“909.
[12] j. gehrke, models and methods for privacy-preserving data analysis and publishing, in: l. liu, a. reuter, k. whang, j. zhang (eds.), proceedings
of the 22nd international conference on data engineering, icde 2006, 3â€“8 april 2006, atlanta, ga, usa, ieee computer society, 2006, p. 105,
http://dx.doi.org/10.1109/icde.2006.100.
[13] s.a. fahrenkrog-petersen, h. van der aa, m. weidlich, pretsa: event log sanitization for privacy-aware process discovery, in: international conference
on process mining, icpm 2019, aachen, germany, june 24â€“26, 2019, ieee, 2019, pp. 1â€“8, http://dx.doi.org/10.1109/icpm.2019.00012.
[14] f. mannhardt, sepsis cases-event log. eindhoven university of technology, 2016, https://doi.org/10.4121/uuid:915d2bfb-7e84-49ad-a286-dc35f063a460.
[15] b.f. van dongen, bpic 2012. eindhoven university of technology, 2012, http://dx.doi.org/10.4121/uuid:3926db30-f712-4394-aebc-75976070e91f.
20m. rafiei and w.m.p. van der aalst data & knowledge engineering 134 (2021) 101908
[16] f. mannhardt, a. koschmider, n. baracaldo, m. weidlich, j. michael, privacy-preserving process mining - differential privacy for event logs, bus. inf. syst.
eng. 61 (5) (2019) 595â€“614, http://dx.doi.org/10.1007/s12599-019-00613-3.
[17] b.f. van dongen, bpic 2017. eindhoven university of technology, 2017, https://doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b.
[18] a. adriansyah, b.f. van dongen, w.m.p. van der aalst, conformance checking using cost-based fitness analysis, in: proceedings of the 15th ieee international
enterprise distributed object computing conference, edoc, 2011, pp. 55â€“64.
[19] a. adriansyah, j. munoz-gama, j. carmona, b.f. van dongen, w.m.p. van der aalst, measuring precision of modeled behavior, inf. syst. e-business
management 13 (1) (2015) 37â€“67.
[20] s.j.j. leemans, d. fahland, w.m.p. van der aalst, discovering block-structured process models from event logs containing infrequent behaviour, in: business
process management workshops - bpm international workshops, 2013, pp. 66â€“78.
[21] l. rÃ¼schendorf, the wasserstein distance and approximation theorems, probab. theory related fields 70 (1) (1985) 117â€“129.
[22] v.i. levenshtein, binary codes capable of correcting deletions, insertions, and reversals, in: soviet physics doklady, vol. 10, 1966, pp. 707â€“710.
[23] w.m.p. van der aalst, h.a. reijers, m. song, discovering social networks from event logs, comput. support. coop. work (cscw) 14 (6) (2005) 549â€“593.
[24] s.j. leemans, d. fahland, w.m.p. aalstvan der aalst, scalable process discovery and conformance checking, softw. syst. model. 17 (2) (2018) 599â€“631.
[25] w.m.p. van der aalst, responsible data science: using event data in a â€˜â€˜people friendlyâ€™â€™ manner, in: s. hammoudi, l.a. maciaszek, m. missikoff, o. camp,
j. cordeiro (eds.), enterprise information systems - 18th international conference, iceis 2016, rome, italy, april 25â€“28, 2016, revised selected papers,
in: lecture notes in business information processing, vol .291, springer, 2016, pp. 3â€“28, http://dx.doi.org/10.1007/978-3-319-62386-3_1.
[26] f. mannhardt, s.a. petersen, m.f. oliveira, privacy challenges for process mining in human-centered industrial environments, in: 14th international
conference on intelligent environments, ie 2018, roma, italy, june 25â€“28, 2018, ieee, 2018, pp. 64â€“71, http://dx.doi.org/10.1109/ie.2018.00017.
[27] g. tillem, z. erkin, r.l. lagendijk, privacy-preserving alpha algorithm for software analysis, in: 37th wic symposium on information theory in the
benelux/6th wic/ieee sp, 2016.
[28] a. burattin, m. conti, d. turato, toward an anonymous process mining, in: future internet of things and cloud (ficloud), 2015 3rd international
conference on, ieee, 2015, pp. 58â€“63.
[29] j. michael, a. koschmider, f. mannhardt, n. baracaldo, b. rumpe, user-centered and privacy-driven process mining system design for iot, in: c. cappiello,
m. ruiz (eds.), information systems engineering in responsible information systems - caise forum 2019, rome, italy, june 3â€“7, 2019, proceedings, in:
lecture notes in business information processing, vol. 350, springer, 2019, pp. 194â€“206, http://dx.doi.org/10.1007/978-3-030-21297-1_17.
[30] m. rafiei, l. von waldthausen, w.m.p. van der aalst, ensuring confidentiality in process mining, in: p. ceravolo, m.t.g. lÃ³pez, m. van keulen (eds.),
proceedings of the 8th international symposium on data-driven process discovery and analysis (simpda 2018), seville, spain, december 13â€“14, 2018,
in: ceur workshop proceedings, vol. 2270, ceur-ws.org, 2018, pp. 3â€“17.
[31] m. rafiei, l. von waldthausen, w.m.p. van der aalst, supporting confidentiality in process mining using abstraction and encryption, in: p. ceravolo, m.
van keulen, m.t.g. lÃ³pez (eds.), data-driven process discovery and analysis - 8th ifip wg 2.6 international symposium, simpda 2018, seville, spain,
december 13â€“14, 2018, and 9th international symposium, simpda 2019, bled, slovenia, september 8, 2019, revised selected papers, in: lecture notes
in business information processing, vol. 379, springer, 2019, pp. 101â€“123, http://dx.doi.org/10.1007/978-3-030-46633-6_6.
[32] m. rafiei, w.m.p. van der aalst, mining roles from event logs while preserving privacy, in: c.d. francescomarino, r.m. dijkman, u. zdun (eds.), business
process management workshops - bpm 2019 international workshops, vienna, austria, september 1â€“6, 2019, revised selected papers, in: lecture notes
in business information processing, vol. 362, springer, 2019, pp. 676â€“689, http://dx.doi.org/10.1007/978-3-030-37453-2_54.
[33] c. liu, h. duan, q. zeng, m. zhou, f. lu, j. cheng, towards comprehensive support for privacy preservation cross-organization business process mining,
ieee trans. serv. comput. 12 (4) (2019) 639â€“653, http://dx.doi.org/10.1109/tsc.2016.2617331.
[34] s.a. fahrenkrog-petersen, h. van der aa, m. weidlich, pripel: privacy-preserving event log publishing including contextual information, in: d. fahland,
c. ghidini, j. becker, m. dumas (eds.), business process management - 18th international conference, bpm 2020, seville, spain, september 13â€“18, 2020,
proceedings, in: lecture notes in computer science, vol. 12168, springer, 2020, pp. 111â€“128, http://dx.doi.org/10.1007/978-3-030-58666-9_7.
[35] e. batista, a. solanas, a uniformization-based approach to preserve individualsâ€™ privacy during process mining analyses, peer-to-peer netw. appl. (2021)
1â€“20.
[36] g. elkoumy, s.a. fahrenkrog-petersen, m. dumas, p. laud, a. pankova, m. weidlich, secure multi-party computation for inter-organizational process
mining, in: s. nurcan, i. reinhartz-berger, p. soffer, j. zdravkovic (eds.), enterprise, business-process and information systems modeling - 21st international
conference, bpmds 2020, 25th international conference, emmsad 2020, held at caise 2020, grenoble, france, june 8â€“9, 2020, proceedings, in: lecture
notes in business information processing, vol. 387, springer, 2020, pp. 166â€“181, http://dx.doi.org/10.1007/978-3-030-49418-6_11.
[37] a. pika, m.t. wynn, s. budiono, a.h.m. ter hofstede, w.m.p. van der aalst, h.a. reijers, towards privacy-preserving process mining in healthcare,
in: c.d. francescomarino, r.m. dijkman, u. zdun (eds.), business process management workshops - bpm 2019 international workshops, vienna,
austria, september 1â€“6, 2019, revised selected papers, in: lecture notes in business information processing, vol. 362, springer, 2019, pp. 483â€“495,
http://dx.doi.org/10.1007/978-3-030-37453-2_39.
[38] m. rafiei, w.m.p. van der aalst, privacy-preserving data publishing in process mining, 2021, corr abs/2101.02627, https://arxiv.org/abs/2101.02627.
[39] s.n. von voigt, s.a. fahrenkrog-petersen, d. janssen, a. koschmider, f. tschorsch, f. mannhardt, o. landsiedel, m. weidlich, quantifying the
re-identification risk of event logs for process mining - empiricial evaluation paper, in: advanced information systems engineering, caise, 2020.
[40] m. rafiei, w.m.p. van der aalst, practical aspect of privacy-preserving data publishing in process mining, 2020, corr abs/2009.11542, https://arxiv.org/
abs/2009.11542.
[41] m. bauer, s.a. fahrenkrog-petersen, a. koschmider, f. mannhardt, h. van der aa, m. weidlich, elpaas: event log privacy as a service, in: proceedings
of the dissertation award, doctoral consortium, and demonstration track at bpm 2019, 2019.
[42] g. elkoumy, s.a. fahrenkrog-petersen, m. dumas, p. laud, a. pankova, m. weidlich, shareprom: a tool for privacy-preserving inter-organizational process
mining, in: proceedings of the best dissertation award, doctoral consortium, and demonstration & resources track at bpm 2020 co-located with the
18th international conference on business process management (bpm 2020), sevilla, spain, september 13â€“18, 2020, in: ceur workshop proceedings, vol.
2673, ceur-ws.org, 2020, pp. 72â€“76.
majid rafiei is a scientific assistant (ph.d. candidate) at the chair of process and data science (pads) - rwth aachen university. he is graduated as master of
engineering in electronic commerce from amirkabir university of technology, tehran. currently he is working on process mining and specifically on responsible
process mining (rpm), where the aim is to use process mining with respect to fairness, accuracy, confidentiality, and transparency (fact).
prof.dr.ir. wil van der aalst is a full professor at rwth aachen university leading the process and data science (pads) group. he is also part-time affiliated
with the technische universiteit eindhoven (tu/e). until december 2017, he was the scientific director of the data science center eindhoven (dsc/e) and led
the architecture of information systems group at tu/e. since 2003, he holds a parttime position at queensland university of technology (qut). currently, he
is also a distinguished fellow at fondazione bruno kessler (fbk) in trento and a member of the board of governors of tilburg university.
21