123
business & information systems
engineering
the international journal of
wirtschaftsinformatik
 
issn 2363-7005
volume 58
number 6
 
bus inf syst eng (2016) 58:375-379
doi 10.1007/s12599-016-0454-0open research in business and
information systems engineering
wil van der aalst, martin bichler &
armin heinzl
123
your article is protected by copyright and
all rights are held exclusively by springer
fachmedien wiesbaden. this e-offprint is
for personal use only and shall not be self-
archived in electronic repositories. if you wish
to self-archive your article, please use the
accepted manuscript version for posting on
your own website. you may further deposit
the accepted manuscript version in any
repository, provided it is only made publicly
available 12 months after official publication
or later and provided acknowledgement is
given to the original source of publication
and a link is inserted to the published article
on springer's website. the link must be
accompanied by the following text: "the final
publication is available at link.springer.com”.editorial
open research in business and information systems engineering
wil van der aalst •martin bichler •
armin heinzl
published online: 14 october 2016
/c211springer fachmedien wiesbaden 2016
1 towards open research
we can all witness rapid changes in the way people con-
duct research, publish results, and share artifacts. this is
affecting the way journals and conferences operate. it
seems that we are gradually moving towards truly ‘‘open
research’’, sometimes also referred to as ‘‘open science’’.
open science is the movement towards making scientiﬁc
research and related artifacts (data, software, etc.) acces-
sible to all levels of inquisition. although digitization and
the internet have dramatically changed, globalized, and
accelerated communication in general, the way that
research results are communicated through journals
remains fairly traditional (groen 2007 ). bise is no
exception. the reviewing process is double-blind, but
reviews are not publically available. a small fraction of
papers are available through springer’s open access
(springer 2016 ), but the majority of bise papers still
require a subscription. accepted papers may use or present
data and software, but these are not required to be public(thus making it difﬁcult to verify results and compare
approaches). of course there are all kinds of practical
reasons why journals like bise do not enforce ‘‘open
research’’ (yet). however, it is good to deliberate on the
topic and seek feedback from the bise community
(fig. 1).
why are we discussing the topic of ‘‘open research’’
now? it seems that the way we publish and disseminate
results is about to change: governments are discussing the
topic, and elements of open research are becoming
mandatory for government-funded research. for example,
the european commission is actively pushing ‘‘open sci-
ence’’ (european commission 2016 ). the amsterdam call
for action on open science (netherlands eu presidency
2016 ) was written based on an open science meeting in
april 2016 that was organized by the dutch presidency of
the european union. nwo, the dutch science foundation,
recently stated that ‘‘research results paid for by public
funds should be freely accessible worldwide’’ (nwo
2016 ). open research concerns both scientiﬁc publications
and other forms of scientiﬁc output. there is a lot more to
open research than just open access (i.e., publications that
are freely accessible to all). for example, open access
journals do not necessarily enforce the sharing of artifacts
such as data sets and software. in fact, the last part of this
editorial focuses on the sharing of these artifacts as they are
vital for many of the results reported in bise.
2 open publication
in 1665, henry oldenburg became the editor of philo-
sophical transactions of the royal society. this was the
ﬁrst academic journal devoted to science, and this devel-
opment coincided with the formation of scientiﬁcprof. dr. ir. w. van der aalst ( &)
department of mathematics and computer science (mf 7.103),
eindhoven university of technology, po box 513,
5600 mb eindhoven, the netherlands
e-mail: w.m.p.v.d.aalst@tue.nl
prof. dr. m. bichler
department of informatics, decision sciences and systems,
technical university of munich (tum), boltzmannstr 3,
85748 munich, germany
e-mail: bichler@in.tum.de
prof. dr. a. heinzl
general management and information systems, university of
mannheim, 68161 mannheim, germany
e-mail: heinzl@uni-mannheim.de
123bus inf syst eng 58(6):375–379 (2016)
doi 10.1007/s12599-016-0454-0
author's personal copyacademies (david 2004 ). for example, in 1660 the royal
society was established in england and in 1666 the french
academy of sciences was founded (nielsen 2011 ). before
the establishment of prestigious journals, there were often
long discussions of the ownership of new inventions. sci-
entists would hide results, afraid that competitors wouldclaim priority. results were even encrypted to control
distribution. obviously, concealing results because com-
petitors can claim priority does not help to advance sci-ence. journals helped to resolve such conﬂicts and aided
the dissemination of results. since the creation of the ﬁrst
journals in the 17th century, the number of journals hasbeen steadily growing. by now there are tens of thousands
of journals, bise being one of them.
as long as journals existed only in paper form, it was
obvious that readers would need to pay for the print and
distribution of published papers. however, today,
researchers mostly access the electronic versions of jour-nals. this triggers the question why publishers should still
receive substantial amounts of money for the distribution
of work done by the scientiﬁc community (writing andreviewing). in a way, citizens are paying twice for the same
research. taxes are used to fund scientiﬁc research, but still
subscription fees need to be paid (by academic institutionsand citizens alike) to access the results of this government-
funded research. moreover, researchers from developing
countries do not have access to the publications in expen-sive journals. therefore, discussions to enforce the free
availability of scientiﬁc publications (‘‘open access’’) take
place at different levels. for example, nwo is enforcingan open publication policy: projects funded by this orga-
nization need to be publically available (nwo 2016 ). at
the eu level one can observe similar developments. pres-sure by governments and the academic community has led
to the creation of new business models where research
organizations pay a publication fee to enable open access.consider for example springer’s open access policy
(springer 2016 ). it is good to see that funding organizations
have started to realize that managing a journal (editing
papers, handling review processes, etc.) and making mil-
lions of papers accessible electronically is something thatrequires substantial resources and a professional organi-
zation. most attempts to create fully open journals without
involving publishers have failed. there are a fewnotable exceptions, e.g., the plos (public library ofscience) initiative aiming at a library of open access
journals and other scientiﬁc literature under an open con-
tent license (public library of science 2016 ). despite these
exceptions, most open journals have problems in terms of
reputation and sustainability. when a journal ‘‘fails’’, there
are no guarantees that the corresponding publicationsremain available indeﬁnitely. aspects such as stability,
reputation, infrastructure, accessibility, etc. need to be
considered when talking about open access.
3 open reviewing
profound reviewing is essential for ensuring the quality of
scientiﬁc research. new ideas are often generated based oncritical feedback. incorrect or unclear results should be
scrutinized by experts before they are widely distributed.
the ‘‘publish or perish’’ culture has unfortunately created asituation where young researchers are stimulated to ‘‘write
rather than read’’. part of the problem is the wide range of
scientiﬁc outlets; the uptake of the internet has triggered atsunami of journals not bounded by the physical limitations
of classical paper journals. everyone can start a new
journal at any time, and for researchers it is time-con-suming to manage the information overload. there is also a
mismatch between the people that review and the people
that submit, e.g., experienced researchers from somecountries are expected to review the work of inexperienced
researchers from other countries where researchers are
forced to submit to journals early in their career. thereshould be a healthy balance between reviewing and sub-
mitting papers at the level of individuals as well as at the
level of groups or even countries. the reviewing systembreaks down if one group is massively submitting papers,
whereas another group needs to take care of the quality
control.
on the one hand, as mentioned, the number of journals
is growing. on the other hand, in most established disci-
plines there is a fairly stable set of top-tier journals or
conferences, and the competition of authors for papers in
these outlets has increased signiﬁcantly (attema et al.2014 ).
regrettably, review work is hardly visible and not
rewarded sufﬁciently in the current academic climate. anauthor’s curriculum vitae will never reveal that the personopen 
publica/g415on open 
reviewing open data open 
so/g332ware open 
research 
fig. 1 open research and some of its ingredients
123376 w. van der aalst et al.: open research in business and information systems engineering, bus inf syst eng 58(6):375–379 (2016)
author's personal copyavoids peer review work or delivers superﬁcial reviews.
bise uses a double-blind reviewing process. this is good
in the sense that reviewers can give unbiased and inde-
pendent feedback, but also renders the review processclosed and invisible for the outside world. a fully open
review process can set incentives for various types of
strategies such as retaliation or publication cartels similarto what has been observed in online reputation systems (ye
et al. 2014 ). hence, there is not a simple solution. how-
ever, it is important to think of new ways of reviewing,
acknowledging the importance of true scientiﬁc interaction
and improving transparency at the same time. outstandingreviewer awards, that were introduced recently, can only be
a starting point. becoming an editorial board member can
be an incentive, but more needs to be done, considering thetime spent to evaluate each paper.
4 open data
we live in a world ﬂooded by data (big and small). data
are collected about anything, at any time, and at any place.
consider for example the ‘‘internet of events’’ (ioe)
composed of the internet of content (ioc), the internet ofpeople (iop), the internet of things (iot), and the internet
of locations (iol) (van der aalst 2016 ). people, devices,
organizations, software systems, phones, etc. all record‘‘events’’, i.e., things that happen in the real world. this is
changing the way people conduct research. there is a shift
from purely model-driven research and mostly conceptualresearch to research based on real-life data (van der aalst
2016 ). for example, we are able to monitor how people
interact with software and the intelligent devices aroundthem. as researchers we have an obligation to use this.
bise papers increasingly depend on data. as research
data used in publications become more detailed and theirvolume increases, it becomes more difﬁcult to judge a
paper without having access to the corresponding data. the
progress of science depends on the ability to reproducescientiﬁc results. unfortunately, as a recent study in nature
shows (baker 2016 ), most of the results described in lit-
erature cannot be reproduced. based on a survey involving
1576 researchers, the nature article (baker 2016 ) reveals
that 70 % of researchers have tried and failed to reproduce
another scientist’s experiments, and more than half havefailed to reproduce their own experiments. factors
explaining this include the pressure to publish and selective
reporting.
in information systems, there is no established tradition
to share data and reproduce existing results. many papers
aim at originality rather than at reproducing and analyzingalready published results. there are a few exceptions in
more data-driven branches of information systems researchand beyond (vlaeminck and herrmann 2015 ). consider for
example the ﬁeld of process mining. most process mining
papers use or provide public data in xes format. there are
competitions like the business process intelligence chal-lenge (bpic) (van dongen 2016 ) which provide real life
data, and it has become impossible to publish papers on a
new process discovery or conformance checking techniquewithout showing results for publically available data. for
most other branches of bise research this is not (yet) the
case and perhaps also more difﬁcult. there may be a range
of practical limitations when sharing data. for example,
data may be conﬁdential or in a format that cannot beinterpreted easily by others. however, the bise commu-
nity should pose itself questions like:
•should all data used in bise papers be publically
available?
•how can we ensure the reproducibility of results?
•how to create a culture of sharing data and reproducing
scientiﬁc results?
•how to ensure the availability of data over a longer
period?
note that it is far from trivial to make data accessible for
a longer period. published papers typically remain avail-able ‘‘forever’’ (assuming a reputable publisher). however,
the data used in such papers may only exist on the laptop of
a phd student or on the website of the research group.when projects end or researchers retire, the corresponding
data sets often disappear. initiatives like the 4tu center
for research data ( 2016 ) aim to ensure the long-term
availability of data. data sets hosted by this center have a
digital object identiﬁer (doi) and are guaranteed to be
available indeﬁnitely. researchers can click on such a doilink in a paper and immediately obtain access to the cor-
responding data. the editors of bise are aiming for a data
availability policy for the journal in the near future.
5 open software
software is vital for most of the research published in
bise. in many cases novel software is developed in order
to carry out the research. consider for example a process
mining paper presenting a new algorithm that is evaluatedby using several data sets. the paper could not exist
without the software and the data (but both can exist
without the paper!). however, the paper may be acceptedwithout providing access to the data and/or software. the
authors may have made a programming error or con-
sciously (or unconsciously) manipulated the results. theonly way to verify this is by using the software and
repeating the experiments. we must keep in mind that the
‘‘science is wrong’’ if the software is wrong.
123w. van der aalst et al.: open research in business and information systems engineering, bus inf syst eng 58(6):375–379 (2016) 377
author's personal copypurely analytical research can be evaluated and repli-
cated based on the paper only. however, more and more
academic work is based on an implemented system that
cannot be fully described in an academic paper.
some papers report on software systems that have only
existed on the phd student’s computer. authors may
describe the architecture of a complex system that onlypartly existed. functionality suggested in the paper may not
have been implemented. unfortunately, such practices
seem widespread (just take a random sample of papers
presenting complex it artifacts and ask the authors to
provide the software). for an external party, results arealmost impossible to evaluate without access to the code.
the reviewer needs to make guesses based on the reputa-
tion of the authors. this is undesirable, because ensuringthe reliability and reproducibility of scientiﬁc results is one
of our main contributions to society.
fortunately, more and more research projects develop
open source software as an important by-product of
research. people can inspect reported software artifacts and
even modify and improve them. open research adoptsideas and the mindset originating from the open source
community. note that ‘‘open source’’ software is by deﬁ-
nition ‘‘open software’’. however, ‘‘open software’’doesn’t need to be ‘‘open source’’. for example, people can
share an executable program without sharing the source
code.
it is important to create a ‘‘level playing ﬁeld’’ in
research. for example, there may be two competing
research groups. assume group a provides open sourcesoftware and group b only uses/develops proprietary
software. group b can use ideas from group a and write
papers comparing the performance of its software with thesoftware of the other group. this doesn’t hold in the other
direction. even when group a is sure that the results of
group b are ﬂawed, it cannot demonstrate this easily.
there are also a few questions to put to the bise
community related to software:
•should software reported in bise papers be publically
available?
•when is the use of proprietary software acceptable?
•should authors with an industrial background be treated
differently?
•how can the availability of software be ensured over a
longer period?
•how long should software be available?
providing open software is easier said than done. rapid
technological advances make it difﬁcult to maintain soft-
ware just for the purpose of reproducibility. some journalshave introduced new policies and they publish repro-
ducibility articles (wolke et al. 2016 ). such articles include
a validation by reviewers; they also provide access to thesource code in a repository and possibly a virtual machine.
this makes it possible for readers to reproduce the results
of a system-oriented paper with the respective experiments
at relatively low cost.
6 final remarks
this editorial aims to trigger a discussion on ‘‘open
research’’ in the bise community. open research relates to
open access of publications and novel ways of reviewing. it
also refers to opening up the artifacts (data and software)publications build upon. scientiﬁc journals exist since the
17th century. however, due to the digitization of science,
the ‘‘rules of the game’’ are changing rapidly. for example,reproducibility is a key concern and new possibilities in our
digital society should be exploited to facilitate this. we
should reward authors who share data and software. it isprobably too early to make this mandatory for all bise
papers, but a trend towards more ‘‘openness’’ is
inevitable and also highly desirable. sharing artifacts andproviding transparency will help us to advance science
faster.
we hope that our thoughts will facilitate the further
development of bise and trigger discussions within the
community regarding open research.
references
attema ae, brouwer wbf, van exel j (2014) your right arm for a
publication in aer? econ inq 52(1):495–502
baker m (2016) 1,500 scientists lift the lid on reproducibility. nat
533:452–454
david p (2004) understanding the emergence of ‘‘open science’’
institutions: functionalist economics in historical context. ind
corp chang 13(4):571–589
european commission (2016) open innovation, open science, open to
the world: a vision for europe. https://ec.europa.eu/digital-
single-market/en/news/open-innovation-open-science-open-world-vision-europe . accessed 15 sept 2016
groen fk (2007) access to medical knowledge: libraries, digitiza-
tion, and the public good. scarecrow, lanham
nielsen m (2011) reinventing discovery: the new era of networked
science. princeton university press, princeton
nwo (2016) open access at nwo. http://www.nwo.nl/en/policies/
open?science/open ?access ?publishing . accessed 15 sept 2016
netherlands eu presidency (2016) amsterdam call for action on open
science. https://english.eu2016.nl/documents/reports/2016/04/
04/amsterdam-call-for-action-on-open-science . accessed 15
sept 2016
public library of science (2016) public library of science (plos):
open for discovery. http://www.plos.org . accessed 18 sept 2016
springer (2016) springeropen. http://www.springeropen.com .
accessed 15 sept 2016
4tu center for research data (2016) data collections. http://data.
4tu.nl/ . accessed 15 sept 2016
123378 w. van der aalst et al.: open research in business and information systems engineering, bus inf syst eng 58(6):375–379 (2016)
author's personal copyvan der aalst w (2016) chapter 1 data science in action. process
mining: data science in action. springer, berlin
van dongen b (2016) business process intelligence challenge
(bpic). http://www.win.tue.nl/bpi/doku.php?id=2016:challenge .
accessed 15 sept 2016
vlaeminck s, herrmann l-k (2015) data policies and data archives:
a new paradigm for academic publishing in economic sciences?new avenues for electronic publishing in the age of inﬁnite
collections and citizen science: scale, openness and trust.proceedings of the 19th international conference on electronic
publishing, pp 145–155. http://hdl.handle.net/10419/121278 .
accessed 15 sept 2016
wolke a, bichler m, chirigati f, steeves v (2016) reproducible
experiments on dynamic resource allocation in cloud data
centers. inf syst 59:98–101
ye s, gao g, viswanathan s (2014) strategic behavior in online
reputation systems: evidence from revoking on ebay. mis q
38(4):1033–1056
123w. van der aalst et al.: open research in business and information systems engineering, bus inf syst eng 58(6):375–379 (2016) 379
author's personal copy