mining cpn models
discovering process models with data from event logs
a. rozinat, r.s. mans, and w.m.p. van der aalst
department of technology management, eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands
{a.rozinat,r.s.mans,w.m.p.v.d.aalst }@tm.tue.nl
abstract. process-aware information systems typically log events (e.g., in trans-
action logs or audit trails) related to the actual execution of business processes.
proper analysis of these execution logs can yield important knowledge that can
help organizations to improve the quality of their services. starting from a pro-
cess model, which can be discovered by conventional process mining algorithms,
we analyze how data attributes inﬂuence the choices made in the process based
on past process executions using decision mining, or decision point analysis. in
this paper we describe how the resulting model (including the discovered data
dependencies) can be represented as a colored petri net (cpn), and how fur-
ther perspectives, such as the performance and organizational perspective, can
be incorporated. we also present a cpn tools export implemented within the
prom framework. using this plug-in simulation models in prom obtained via
a combination of various process mining techniques can be exported to cpn
tools. we believe that the combination of automatic discovery of process models
using prom and the simulation capabilities of cpn tools oﬀers an innovative
way to improve business processes. the initially discovered process model de-
scribes reality better than most hand-crafted simulation models. moreover, the
simulation models are constructed in such a way that it is easy to explore various
redesigns.
1 introduction
process mining techniques have proven to be a valuable tool in order to gain insight
into how business processes are handled within organizations. taking a set of real
process executions (the so-called “event logs”) as the starting point, these techniques
can be used for process discovery andconformance checking . process discovery [4, 6]
can be used to automatically construct a process model reﬂecting the behavior that
has been observed and recorded in the event log. conformance checking [1, 10] can
be used to compare the recorded behavior with some already existing process model
to detect possible deviations. both may serve as input for designing and improving
business processes, e.g., conformance checking can be used to ﬁnd problems in existing
processes, and process discovery can be used as a starting point for process analysis
and system conﬁguration. while there are several process mining algorithms that deal
with the control ﬂow perspective of a business process [4] less attention has been paid
to how the value of a data attribute may aﬀect the routing of a case .most information systems (cf. wfm, erp, crm, scm, and b2b systems) provide
some kind of event log (also referred to as transaction log or audit trail) [4] where an
event refers to a case (i.e., process instance) and an activity, and, in most systems, also
a timestamp, a performer, and some additional data. nevertheless, many process min-
ing techniques only make use of the ﬁrst two attributes in order to construct a process
model which reﬂects the causal relations that have been observed among the activities.
in this paper we start from a discovered process model (i.e., a model discovered by con-
ventional process mining algorithms), and we try to enhance the model by integrating
patterns that can be observed from data modiﬁcations, i.e., a decision point analysis [?]
will be carried out in order to ﬁnd out which properties of a case might lead to taking
certain paths in the process. colored petri nets (cpns) [ ?] are then a suitable rep-
resentation for the enhanced model because of their expressiveness and the good tool
support provided through cpn tools [ ?] (which, for example, has strong simulation
capabilities). furthermore, the hierarchy concept allows for the composition of cpn
model in a modular way. the time concept and the availability of many probability
distributions in cpn tools allow for the modeling of performance aspects. moreover,
by introducing resource tokens also organizational and work distribution aspects can
be modeled.
fig. 1. the approach pursued in this paper
figure 1 illustrates the overall approach. first of all, some process mining algorithm
is used to discover a process model in terms of a petri net (e.g., the α-algorithm
[6]). note that conventional process miners (e.g., based on the α-algorithm) only use
the ﬁrst two columns depicted in figure 1. however, the event log may contain also
2information about the people executing activities (cf. originator column), the timing
of these activities (cf. timestamp column), and the data involved (cf. data column). in
the next step we make use of the additional information, the data column to be precise.
the decision miner uses this information to discover rules for taking alternative paths
based on values of the data attributes present in the process. finally, the process
model including the data perspective is exported as a cpn simulation model. the
cpn simulation model may be extended with additional information about time and
resources. this information may be manually included or is extracted from the log
based on the originator column and timestamp column.
to directly support the generation of a cpn simulation model for business pro-
cesses we have implemented a cpn tools export plug-in in the context of the prom
framework1, which oﬀers a wide range of tools related to process mining and process
analysis.
the paper is organized as follows. first, section 2 introduces a simple example pro-
cess that is used throughout the paper. then, the decision mining approach is explained
brieﬂy in section 3. subsequently, we describe how a business process (including mul-
tiple perspectives) can be represented as a cpn in section 4. section 5 presents the
cpn tools export plug-in of the prom framework. finally, related work is discussed
in section 6, and the paper concludes by pointing out future research directions.
2 running example
as pointed out in figure 1 the ﬁrst step in the decision mining process is to obtain
a process model without data through some classical process miner , e.g., a petri net
discovered using the α-algorithm. figure 2(a) shows an event log in a schematic way,
i.e., as a set of event traces. note that this information can be extracted from the
ﬁrst two columns of the event log shown in figure 1. based on this information the
α-algorithm automatically constructs the process model shown in figure 2(b).
fig. 2. process mining phase
1both documentation and software (including the source code) can be downloaded from
www.processmining.org .
3the example process used throughout the paper sketches the processing of a li-
ability claim within an insurance company: ﬁrst, some data related to the claim is
registered ( a), and then either a full check or a policy-only check is performed ( bor
c). afterwards, the claim will be evaluated ( d), and then it is either rejected ( f) or
approved ( eandg). finally, the case is archived and closed ( h).
now we have discovered the control ﬂow perspective of the process. but the pro-
cess execution log contains much more valuable information. in order to generate a
simulation model that reﬂects as close as possible the process that has been observed,
case data attributes, timestamps, and originator information can be analyzed to reveal
characteristics related to the data,performance , and organizational perspectives. fig-
ure 3 depicts a screenshot of the event log in mxml2format, and in the following we
will have a closer look at it considering these perspectives.
fig. 3. fragment of the example log in mxml format viewed using xml spy
(a)data perspective . here a data item within an audit trail entry is interpreted
as a case attribute that has been created, or modiﬁed. in figure 3 one can observe
that only activities register claim and evaluate claim have data items associated.
during the execution of activity register claim information about the amount of money
2both the corresponding schema deﬁnition and the promimport framework, which converts
logs from existing (commercial) process-aware information systems to the xml format used
by prom, can be downloaded from www.processmining.org .
4involved ( amount ), the corresponding customer ( customerid ), and the type of policy
(policytype ) are provided, while after handling the activity evaluate claim the outcome
of the evaluation is recorded ( status ). semantically, amount is a numerical attribute,
customerid is an attribute which is unique for each customer, and both policytype
andstatus are enumeration types (being either “normal” or “premium”, or either
“approved” or “rejected”, respectively).
(b)performance perspective . in the example, for simplicity, activities are considered
as being atomic and carry no time information. however, information systems deal-
ing with processes typically log events on a more ﬁne-grained level, e.g., they record
schedule ,start, and complete events (including timestamps) for each activity that has
been ﬁrst activated and then executed. thus, time information can be used to infer,
e.g., activity durations, or the arrival rate of newly started cases. furthermore, the
frequency of alternative paths represents quantitative information that is implicitly
contained in the event log. for example, the event log shown in figure 3 contains 10
process instances, of which 7 executed activity check policy only and only 3 performed
the full check procedure check all .
(c)organizational perspective . in figure 3 one can observe that each event carries
information about the resource that executed the activity. in the insurance handling
example process 7 diﬀerent persons have worked together: howard, fred, mona, vin-
cent, robert, linda, and john.
as illustrated in figure 1, the discovered process model and the detailed log are
the starting point for the decision miner , which analyzes the data perspective of the
process in order to discover data dependencies that inﬂuence the routing of a case.
the idea of decision mining is brieﬂy explained in the next section (see [ ?] for further
details). the decision miner constructs a simulation model incorporating the data
perspective and passes this on to the cpn export plug-in. however, in addition to
the control-ﬂow and data perspective the simulation model may also contain informa-
tion about resources, probabilities, and time (i.e., the performance and organizational
perspectives).3the representation of all these perspectives in terms of a cpn model
and the conﬁguration possibilities of the cpn tools export in prom are described in
section 4 and section 5.
3 decision mining
in order to analyze the choices in a business process we ﬁrst need to identify those
parts of the model where the process splits into alternative branches, also called decision
points . based on data attributes associated to the cases in the event log we subsequently
want to ﬁnd rules for following one route or the other.
in terms of a petri net, a decision point corresponds to a place with multiple out-
going arcs. since a token can only be consumed by one of the transitions connected to
3these perspectives can be added by hand or through additional process mining techniques.
we are currently working on integrating the information from various plug-ins, focusing on
integrating the performance and organizational perspectives with the information from the
decision miner.
5these arcs, alternative paths may be taken during the execution of a process instance.
the process model in figure 2(b) exhibits three such decision points: p0(if there is
a token, either borccan be performed), p2(if there is a token, either eorfcan
be executed) and p3(if there is a token, either forgmay be carried out). in order
to analyze the choices that were made in past process executions, we need to ﬁnd out
which alternative branch was taken by a certain process instance. therefore, the set of
possible decisions must be described with respect to the event log. starting from the
identiﬁcation of a choice construct in the process model a decision can be detected if
the execution of an activity in the respective alternative branch of the model has been
observed, which requires a mapping from that activity to its “occurrence footprint” in
the event log. so, if a process instance contains the given “footprint”, this means that
there was a decision for the associated alternative path in the process. for simplicity
we examine the occurrence of the ﬁrst activity per alternative branch in order to clas-
sify the possible decisions. however, in order to make decision mining operational for
real-life business processes several challenges posed by, for example, invisible activities ,
duplicate activities , and loops need to be met. we refer the interested reader to our
technical report [ ?], where these issues are addressed in detail.
after identifying a decision point in a business process and classifying the decisions
of the process instances in the log, the next step is to determine whether this decision
might be inﬂuenced by case data, i.e., whether cases with certain properties typically
follow a speciﬁc route. the idea is to convert every decision point into a classiﬁca-
tion problem [?,?,?], where the classes are the diﬀerent decisions that can be made.
as training examples we use the process instances in the log (for which it is already
known which alternative path they followed with respect to the decision point). the
attributes to be analyzed are the case attributes contained in the log, and we assume
that all attributes that have been written before the choice construct under consid-
eration are relevant for the routing of a case at that point4. in order to solve such
a classiﬁcation problem, various algorithms are available [ ?,?]. we decided to use an
algorithm based on decision trees (i.e., the c4.5 algorithm [ ?]). decision trees are a
popular tool for inductive inference and the corresponding algorithms have been ex-
tended in various ways to improve practical applicability. for example, they are able
to deal with continuous-valued attributes, missing attribute values, and they include
eﬀective methods to avoid over-ﬁtting the data (i.e., that the tree is too much tailored
towards the particular training examples).
using decision point analysis we can extract knowledge about decision rules as
shown in figure 4. each of the three discovered decision points corresponds to one of the
choices in the running example. with respect to decision point p0the extensive check
(activity b) is only performed if the amount is greater than 500 and the policytype
is “normal”, whereas a simpler coverage check (activity c) is suﬃcient if the amount
is smaller than or equal to 500, or the policytype is “premium” (which may be due
to certain guarantees given by “premium” member corporations). the two choices at
decision point p2andp3are both guided by the status attribute, which is the outcome
of the evaluation activity (activity d).
4we also allow the user to set other scoping rules, e.g., only the data set in a directly
preceding activity, or all case data including the data that is set later.
6fig. 4. enhanced process model
now that we have discovered a model of the control-ﬂow and data perspective of the
example process, we describe how this information (and information about the perfor-
mance and organizational perspective) can be represented in a cpn model (section 4),
and show how such a cpn simulation model can be generated in prom (section 5).
4 cpn simulation models
since we want to make use of the simulation facilities of cpn tools, we provide the
actual process model together with a simulation environment. the top-level page in
the hierarchical cpn model is shown in figure 5. for each process model this page will
look identical; the environment generates cases and puts them into the start place, and
removes those that have ﬁnally reached the end place. we assume that the discovered
process represented by the sub-page process is sound, i.e., any case that enters the
sub-page via place start leaves the sub-page via place end.
environment
environment
process
processstart
case_idend
case_id
fig. 5. overview page
figure 6 depicts the simulation environment in more detail. one can observe that
the case id is an integer which is simply incremented for each generated process
instance. for the data perspective, a separate token containing the case id and a
record of case attributes (deﬁned via the data color set) is created and initialized.
7the place case data is modeled as a fusion place as activities may need to inspect or
modify attribute values on a diﬀerent page in the hierarchical model. furthermore, the
resources fusion place contains the available resources for the process, and therefore
determines the environment from an organizational perspective. finally, each time a
token is put back in the next case id place a time delay5is added to it, which is used
to steer the generation of new cases. in figure 6 a constant time delay of 3 implements
that every 3 time units a new case arrives. note that the inter-arrival times may also
be sampled from some probability distribution discovered by prom.
(c,data)
(c, {amount = 0,
policytype = normal,status = rejected})
cc c+1 @+round(3.0)
cclean_up init
resources
resources["howard","fred","mona",
"vincent","robert","linda","john"]
resourcecase data
case datacase_idxdatanext
case id1
case_id
end
incase_idstart
outcase_idout incase data
resources
fig. 6. environment page
figure 7 shows the sub-page containing the actual process model, which looks ex-
actly like the original, low-level petri net. note that the tokens routed from the start
to the end place are of type case id, so that tokens belonging to diﬀerent instances
are not mixed up.
send
rejection
letter
send rejection letter
send
approval
letter
send approval letterissue
payment
issue payment
evaluate
claim
evaluate claim
check 
policy only
check  policy onlycheck all
check all
register
claim
register claimp5p4
p3p2
p1 p0 end
outstart
inin out
register claimcheck all
check  policy onlyevaluate claimissue payment
send approval lettersend rejection letterarchive
claim
archive claimarchive claim case_id case_id
case_idcase_id case_id
case_idcase_id case_id
fig. 7. process page
every activity on the process page has its own sub-page containing the actual simu-
lation information. depending on the simulation conﬁguration these activity sub-pages
5note that in our simulation model the time delay is always attached to an arc (depending
on the token that should be delayed) rather than using the time delay of a transition in
order to reduce side eﬀects on other tokens that should actually not be delayed (such as
thecase data token).
8may look very diﬀerent. in the following sub sections we will present how simulation
information from several dimensions can be represented in terms of a cpn sub-page.
4.1 data
taking the enhanced model from figure 4 as the starting point, we now want to
incorporate the discovered data dependencies in the simulation model. the discovered
decision rules are based on attributes provided by activity register claim andevaluate
claim respectively. since the attribute customerid is not involved in the discovered
rules, we discard it from the process model and deﬁne process-speciﬁc data types for
each of the remaining attributes (i.e., amount, policytype, and status).
fig. 8. writing data items using random values
figure 8 shows how the provision of case data can be modeled using random values.
while a random value for a nominal attribute can be generated by applying the ran()
function directly to the color set6a dedicated random function is needed for numeric
attributes. in the action part of transition register claim function policytype.ran()
is used to select the policy type (“normal” or “premium”) and a dedicated function
randomamount() is used to set the amount. in this case, the amount is sampled from
a uniform distribution generating a value between the lowest and the highest attribute
value observed in the event log. however, many other settings are possible.
figure 9 shows how the discovered data dependencies can then be modeled with the
help of transition guards. if the transition is enabled from a control-ﬂow perspective,
it additionally needs to satisfy the given guard condition in order to be ﬁred.
4.2 time
although there is no time information in the example event log, we want to include the
time dimension in our simulation model. we can, for example, say that—in contrast to
the policy-only check, which takes between 3 and 8 time units—the full check procedure
needs between 9 and 17 time units to complete. furthermore, the time between the
6note that the ran() function can only be used for enumerated color sets with less than 100
elements.
9fig. 9. modeling data dependencies using transition guards
point where the activity could have been started (i.e., all required previous activities
were completed) and the point where someone actually starts working on it may vary
from 3 to 5 time units. whereas the sub-page shown in figure 9(a) models the activity
check all in an atomic way, one can distinguish between schedule ,start, and complete
transitions in order to incorporate the waiting time andexecution time of this activity.
figure 10 shows three ways to model this for activity check all .
in figure 10(a) only the execution time of the activity is modeled. when transition
check all start is ﬁred, a token is produced with the indicated time delay. similar to the
case generation scheme in figure 6, the token will remain between 9 and 17 time units
in the place e(i.e., the activity is in the state executing ) before transition check all
complete may ﬁre.
in figure 10(b) both the execution time and the waiting time are explicitly modeled.
analogously to the execution time, the waiting time is realized by a time delay that
forces the token to reside in place w(i.e., the activity is in the state waiting ) between
3 and 5 time units before transition check all start may ﬁre.
in figure 10(c) the sum of the waiting time and the execution time is modeled.
this may be useful if no information is available about the actual start of an activity
(i.e., only the time when it becomes enabled and when it is ﬁnished is known).
10fig. 10. diﬀerent variants of modeling time on sub-page check all depending on the event
types (i.e., schedule, start, and complete) present in the log
4.3 resources
in order to gain insight into the organizational perspective we analyze the event log
shown in figure 3 with the social network miner of prom. figure 11 shows a social
network generated based on the metric similar work [3], i.e., two people are linked in
the social network if they execute similar activities. the more similar their execution
proﬁles are the stronger their relationship. in the social network depicted one can
observe that vincent and howard execute a set of activities which is disjoint from those
executed by all other employees. more precisely, they only execute the activity issue
payment and, therefore, might work, e.g., in the finance department of the insurance
company. furthermore, the work of fred and linda seems to be more similar to each
other than to the work of the other three people. having a closer look at the event
log again reveals that they are the only people performing the evaluate claim activity,
although they also execute other activities, (such as send rejection letter andarchive
claim ). this may be due to the fact that the activity evaluate claim requires some
manager role, whereas all the remaining activities can be performed by people having
aclerk role.
fig. 11. social network based on the metric “similar work” [3]
11a simple way to incorporate this knowledge in our simulation model is to create
three groups of resources (finance = {howard, vincent }, manager = {fred, linda },
clerk = {fred, linda, john, robert, mona }) and to specify for each activity which
kind of resource is required (if no particular group has been speciﬁed for an activity,
it can be performed by any resource). figure 12 depicts how the fact that activity
evaluate claim requires the role manger is modeled in the corresponding cpn model.
the role is modeled as a separate color set manager, which contains only “lisa” and
“fred”. because the variable g1is of type manager, only the resource token “lisa”
or “fred” can be consumed by transition evaluate claim start . as soon as transition
evaluate claim start is ﬁred, the corresponding resource token resides in the place e,
i.e., it is not available for concurrent executions of further activities, until transition
evaluate claim complete ﬁres and puts the token back.
fig. 12. sub-page evaluate claim including resource modeling
4.4 probabilities and frequencies
in addition to the modeling of data, time and resource information, one may also be
interested in stochastic aspects. hence, these aspects also need to be incorporated in
the cpn model. figure 13 shows how often each arc in the model has been used,
determined through the log replay analysis carried out by the conformance checker in
prom7. looking at the ﬁrst choice it becomes clear that activity check policy only has
been executed 7 (out of 10) times and activity check all was performed only 3 times.
similarly, activity send rejection letter happened for 4 (out of 10) cases, while in 6
cases both activity send approval letter and activity issue payment were executed.
in order to incorporate frequencies of alternative paths in the simulation model we
use two diﬀerent approaches, depending on the nature of the choice.
simple choice the ﬁrst choice construct in the example model is considered to be a
so-called simple choice as it is only represented by one single place. we can model
7note that the place names and the markup of the choices have been added to the diagnostic
picture obtained from prom for explanation purposes.
12fig. 13. frequencies of alternative paths in the example model
such a simple choice using a probability token that is shared among all the activities
involved in this choice via a fusion place.
figure 14 shows this solution for the choice at place p0. both sub-pages check all
andcheck policy only contain a fusion place p0probability that initially contains
a token with the value 0, but after each ﬁring of either transition check all start or
transition check policy only start a random value between 0 and 100 is generated.
because of the guard condition, the decision at the place p0is then determined for
each case according to the current value of the token in place p0probability . for
example, the transition check all start needs to bind the variable prob to a value
greater than or equal to 70 in order to be enabled, which will only happen in 30%
of the cases.
fig. 14. using a probability token for simple choices
dependent choices the second choice construct in the example model actually con-
sists of two dependent choices8(i.e., the choices represented by places p2andp3)
8similar to the decision miner we consider each place as a choice (or decision point) if it
contains more than one outgoing arc (cf. figure 4).
13that need to be coordinated in order to either approve or reject a claim. it is clear
that two dependent choices cannot be steered properly by two independently gen-
erated probability tokens, because the process model will deadlock as soon as the
values of the probability tokens indicate contrasting decisions (e.g., the probability
token in p2indicates a reject while the other probability token in p3suggests to
approve the claim).
figure 15 shows a solution for modeling the dependent choices at place p2andp3.
the idea is to increase the likelihood of choosing a certain activity through activity
duplication (because during simulation any enabled transition will be ﬁred with
an equal probability). this way, the observed relative frequency9of the transitions
involved in the dependent choices can be incorporated in the simulation model.
figure 15(a) shows an intermediate sub-page for activity issue payment , where
three substitution transitions issue payment point to diﬀerent instances of the
same sub-page issue payment (i.e., the actual sub-page is only modeled once).
figures 15(b) and (c) show similar intermediate sub-pages for the activities send
approval letter (also duplicated three times) and send rejection letter (duplicated
twice).
fig. 15. modeling dependent choices via activity duplication
4.5 logging and monitoring simulation runs
the cpn models described in this section deal with time, resources, and data. when
running a simulation in cpn tools we are interested in statistics (e.g. average, variance,
minimum, and maximum) related to the utilization of resources and the throughput
times of cases during the simulation run.
9in order to obtain the relative frequency, the absolute frequency is divided by the greatest
common divisor (i.e., 6 /2 = 3 and 4 /2 = 2).
14in the case that resources have been deﬁned for the process all the available resources
are contained in a resources fusion place, which is located on the environment page
and on every activity sub-page. for obtaining statistics about the resource utilization
during the simulation we can simply deﬁne a marking size monitor for this resources
fusion place, which records the number of available resources plus the current time
(and step) as soon as a resource becomes (un-)available.
furthermore, when the timing perspective is enabled, tokens are created with a
timestamp. in order to calculate the throughput time for each case, we record the
timestamp of its creation together with the case id token that is routed through the
process. this way, the current run time of a case can be easily determined at each stage
in the process via some custom monitor. for the throughput time monitor, a data col-
lector monitor has been deﬁned for the clean up transition on the environment page
(cf. figure 6), which simply calculates the diﬀerence between the current model time
and the start time of a case10, and records the throughput time, the end time and end
step for each case.
moreover, we want to generate process execution logs for the business process in
the cpn simulation model. this can be very useful for, e.g., the creation of artiﬁcial
logs that are needed to evaluate the performance of process mining algorithms.
for each ﬁring of a transition on an activity sub-page an event is logged, which
includes case id, the type of transition (i.e., schedule ,start, or complete ), current
timestamp, originator, and additional data (each if available). for generating these
process execution logs we use the logging functions that have been described in [ ?].
however, in contrast to [ ?]—where the input/output/action inscriptions of transitions
have to be modiﬁed to invoke these logging functions—we decided to use user deﬁned
monitors in order to clearly separate the logging from the rest of the simulation model.
figure 16 shows the monitor that has been deﬁned for the complete transition
ofevaluate claim . while ﬁring this transition a random value is generated for the
status attribute and it may only be performed by people having the manager role
(cf. ﬁgures 8(b) and 12). each time evaluate claim complete ﬁres, the monitor does
the following. the predicate function checks whether all variables that belong to the
transition are bounded. then the observer function is executed. this function extracts
information from the net that can be passed to the action function. here, we extract the
case id (variable c), the originator (variable g1) and the data that has been modiﬁed
(variable modiﬁeddata ), which will be passed to the action function (the original
data (variable data) is also extracted but does not need to be passed to the action
function). in the action function the passed values are used to create the corresponding
audit trail entry that needs to be written to the log ﬁle of the case. for this we
use the function addate that has been described in [ ?]. in figure 16 the addate
function writes an audit trail entry to the log ﬁle of the case id that is represented
by variable f. for the audit trail entry itself, the name of the transition is recorded,
10because the type of the current model time is inﬁnite integer and in order to not lose
precision when calculating the diﬀerence between the current model time and the start time
of a case, the model time is mapped onto a string value, i.e., color set start time is
of type string and is used to encode inﬁnite integers.
15fig. 16. user deﬁned monitor for evaluate claim complete
the corresponding event type , the timestamp at which the transition has been executed,
which manager completed the activity, and ﬁnally the case attribute that has been
changed.
note that the initand the stop functions are not used because it is not necessary
to initialize or terminate the monitor. however, before it is even possible to write to
a log ﬁle, we ﬁrst need to open a log ﬁle for each case. this is ensured by deﬁning a
monitor for the inittransition on the environment page that initializes every case. in
theaction function of that monitor the function createcasefile is called, which opens
a log ﬁle for every case.
5 exporting cpn models from prom
we are able to generate cpn simulation models as presented in the previous section
using the cpn tools 2.0 export plug-in in the prom framework11. it either accepts
a simulation model that has been provided by another plug-in in the framework, or a
simple, low-level petri net (in which case an empty simulation model is created and
ﬁlled with default values). before the actual export takes place, it allows for the manip-
ulation of the simulation information in the model. as illustrated in figure 1, we have
discovered a process model including the data perspective (provided by the decision
miner ), and we can now manually integrate information about further dimensions,
such as the performance and organizational dimension.
figure 17(a) shows the global conﬁguration settings, where the user can choose
which dimensions should be included in the generated simulation model. in fact, al-
though the relevant simulation information may be provided, it will be ignored if the
corresponding conﬁguration option was not chosen. note that, since the waiting time
of an activity typically results from the unavailability of resources, explicit modeling of
a resource scheme such as in figure 12 is in conﬂict with modeling the time dimension
11note that the layout of the generated models was slightly adjusted in order to improve the
readability.
16fig. 17. cpn tools export settings
including waiting time (cf. ﬁgures 10(b) and (c)). therefore, only the execution time
option is available if the resource dimension is selected.
figure 17(b) depicts the attributes settings of the process. new data attributes can
be provided by specifying their name, type (nominal or numeric), possible values (a list
of string values for a nominal attribute, and some distribution for a numeric one), and
initial value. however, the available data attributes for the example process were al-
ready discovered by the decision miner. we might only want to delete the customerid
attribute, since it is not involved in any of the discovered data dependencies.
in figure 17(c), a screenshot of the activity settings for activity register claim is
displayed. in this view, the provided data attributes, the execution time, waiting time,
17sojourn time, and the required resource group may be speciﬁed for each of the activi-
ties in the process. the data attributes were already provided by the decision miner,
but we can assign some execution time to each activity (the probability distributions
currently supported by the cpn export plug-in are the constant, uniform, and nor-
mal distribution), and choose the suitable group of resources from the list of groups
available in the process.
figure 17(d) shows the choice conﬁguration view, where the user can determine for
each decision point in the process whether it should be based on either probabilities or
frequencies (cf. section 4.4), or on data attributes, or whether it should not be guided
by the simulation model (one of the alternative paths is then randomly chosen by cpn
tools). in figure 17(d) the probability settings are displayed. for every alternative
branch a probability may be provided between 0.0 and 1.0. before the actual export
takes place, each value is normalized by the sum of all speciﬁed values, and if the values
sum up to 0.0, default values (i.e., equal probabilities for each alternative branch) are
used. as discussed in section 4.4, for dependent choices one should specify a relative
frequency value instead. finally, we can provide a dependency value based on data
attributes (in the case of our example process the discovered dependency has already
been ﬁlled in by the decision miner). in the current version of the export plug-in
this dependency value is simply a string containing the condition to be placed in the
transition guard of the corresponding transition.
in figure 17(e) the resources settings are depicted. here, one can add groups and
resources, and assign resources to groups. this way the cpn tools 2.0 export plug-in
also supports the export of information about resources. this information is then used
to create the sub-pages shown earlier.
6 related work
the work reported in this paper is related to earlier work on process mining, i.e.,
discovering a process model based on some event log. the idea of applying process
mining in the context of workﬂow management was ﬁrst introduced in [7]. cook and
wolf have investigated similar issues in the context of software engineering processes
using diﬀerent approaches [8]. herbst and karagiannis also address the issue of process
mining in the context of workﬂow management using an inductive approach [9]. they
use stochastic task graphs as an intermediate representation and generate a workﬂow
model described in the adonis modeling language. then there are several variants of
theαalgorithm [6, 11]. in [6] it is shown that this algorithm can be proven to be correct
for a large class of processes. in [11] a heuristic approach using rather simple metrics is
used to construct so-called “dependency/frequency tables” and “dependency/frequency
graphs”. this is used as input for the αalgorithm. as a result it is possible to tackle
the problem of noise. for more information on process mining we refer to a special
issue of computers in industry on process mining [5] and a survey paper [4]. however,
as far as we know, this is the ﬁrst attempt to mine process models including other
dimensions, such as data.
in [?] the authors present a translation of protos simulation models to cpn tools.
in addition, three types of data collector monitors (measuring the total ﬂow time per
18case, the waiting time per task, and the resource availability/utilization per resource
type), and conﬁguration features enabling the dynamic elimination of unnecessary parts
of the process model are generated. besides the work in [ ?], we are not aware of further
attempts to export business process models to cpn tools. the work reported in this
paper has a diﬀerent starting point as it is not limited by the simulation information
present in a protos model, but aims at discovering the process characteristics to be
simulated from the event logs of real process executions.
7 future work
future work includes the reﬁnement of the generated cpn models and the further
exploitation of the features already present in cpn tools. for example, a more realis-
tic resource modeling scheme may allow for the speciﬁcation of a working scheme per
resource (e.g., whether the person works half-time or full-time) and include diﬀerent
allocation mechanisms, and we plan to support all random distributions that are avail-
able in cpn tools in the near future. moreover, the discovery of further perspectives
of a business process will be integrated in the mined process models. currently, we
are able to discover data dependencies via the decision miner in prom. but existing
plug-ins in prom will deliver also time-related characteristics of a process (such as the
case arrival scheme, and execution and waiting times) and frequencies of alternative
paths, or organizational characteristics (such as the roles of the employees involved in
the process). all these diﬀerent pieces of aggregate information (discovered from the
event log) need then to be combined in one holistic simulation model, which may be
exported to cpn tools, or, e.g., translated to an executable yawl model [2]. note
that a yawl model can be used to enact a business process using the yawl workﬂow
engine. for enactment all perspectives play a role and need to be taken into account.
hence, successfully exporting to yawl is another interesting test case for the mining
of process models with data and resource information.
acknowledgements
this research is supported by eit and the iop program of the dutch ministry of eco-
nomic aﬀairs. the authors would also like to thank ton weijters, boudewijn van don-
gen, ana karla alves de medeiros, minseok song, laura maruster, christian g¨ unther,
eric verbeek, monique jansen-vullers, hajo reijers, michael rosemann, huub de beer,
peter van den brand, et al. for their on-going work on process mining techniques. we
would also like to thank lisa wells and kurt jensen for their support in using cpn
tools.
references
1. w.m.p. van der aalst. business alignment: using process mining as a tool for delta
analysis. in j. grundspenkis and m. kirikova, editors, proceedings of the 5th workshop on
business process modeling, development and support (bpmds’04) , volume 2 of caise’04
workshops , pages 138–145. riga technical university, latvia, 2004.
192. w.m.p. van der aalst and a.h.m. ter hofstede. yawl: yet another workﬂow language.
information systems , 30(4):245–275, 2005.
3. w.m.p. van der aalst, h.a. reijers, and m. song. discovering social networks from
event logs. computer supported cooperative work , 14(6):549–593, 2005.
4. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data and
knowledge engineering , 47(2):237–267, 2003.
5. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining , special issue of
computers in industry, volume 53, number 3. elsevier science publishers, amsterdam,
2004.
6. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining: dis-
covering process models from event logs. ieee transactions on knowledge and data
engineering , 16(9):1128–1142, 2004.
7. r. agrawal, d. gunopulos, and f. leymann. mining process models from workﬂow
logs. in sixth international conference on extending database technology , pages 469–
483, 1998.
8. j.e. cook and a.l. wolf. discovering models of software processes from event-based
data. acm transactions on software engineering and methodology , 7(3):215–249, 1998.
9. a.k. alves de medeiros and c.w. guenther. process mining: using cpn tools to create
test logs for mining algorithms. in kurt jensen, editor, proceedings of the sixth work-
shop and tutorial on practical use of coloured petri nets and the cpn tools , pages
177–190, 2005.
10. f. gottschalk, w.m.p. van der aalst, m.h. jansen-vullers, and h.m.w. verbeek. pro-
tos2cpn: using colored petri nets for conﬁguring and testing business processes. in
submitted to the seventh workshop and tutorial on practical use of coloured petri nets
and the cpn tools , 2006.
11. j. herbst. a machine learning approach to workﬂow management. in proceedings 11th
european conference on machine learning , volume 1810 of lecture notes in computer
science , pages 183–194. springer-verlag, berlin, 2000.
12. k. jensen. coloured petri nets. basic concepts, analysis methods and practical use .
springer-verlag, 1997.
13. t. m. mitchell. machine learning . mcgraw-hill, 1997.
14. j. r. quinlan. c4.5: programs for machine learning . morgan kaufmann, 1993.
15. a. rozinat and w.m.p. van der aalst. conformance testing: measuring the fit and
appropriateness of event logs and process models. in c. bussler et al., editor, business
process management 2005 workshops , volume 3812 of lecture notes in computer science ,
pages 163–176. springer-verlag, berlin, 2006.
16. a. rozinat and w.m.p. van der aalst. decision mining in business processes. bpm
center report bpm-06-10, bpmcenter.org, 2006.
17. a. vinter ratzer, l. wells, h. m. lassen, m. laursen, j. f. qvortrup, m. s. stissing,
m. westergaard, s. christensen, and k. jensen. cpn tools for editing, simulating, and
analysing coloured petri nets. in w.m.p. van der aalst and e. best, editors, applications
and theory of petri nets 2003: 24th international conference, icatpn 2003 , volume
2679 of lecture notes in computer science , pages 450–462. springer verlag, 2003.
18. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models
from event-based data using little thumb. integrated computer-aided engineering ,
10(2):151–162, 2003.
19. i. h. witten and e. frank. data mining: practical machine learning tools and tech-
niques, 2nd edition . morgan kaufmann, 2005.
20