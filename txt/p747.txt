"mine your own business": using process mining 
to turn big data into real value 
van der aalst, wil, eindhoven university of technology, p.o. box 513, nl-5600 mb, 
eindhoven, the ne
therlands, w.m.p.v.d.aalst@tue.nl 
abstract  
like most it-related phenomena, also the growth of event data complies with moore’ s law. similar to 
the number of transistors on chips, the capacity of hard disks, and the computing power of computer s, 
the digital universe is growing exponentially and roughly doubling every 2 years. although this is not 
a new phenomenon, suddenly many organizations realize that increasing amounts of “big data” (in 
the broadest sense of the word) need to be used intelligently in order to compete with other 
organizations in terms of efficiency, speed and service. however, the goal is not to collect as much 
data as possible. the real challenge is to turn event data into valuable insights. only process mining 
techniques directly relate event data to end- to-end business processes. existing business process 
modeling approaches generating piles of process models are typically disconnected from the real 
processes and information systems. data-oriented analysis techniques (e.g., data mining and 
machines learning) typically focus on simple classification, clustering, regression, or rule-learning 
problems. this keynote paper provides pointers to recent developments in process mining thereby 
clearly showing that process mining provides a natural link between processes and data on the one 
hand and performance and compliance on the other hand. 
keywords: process mining, process discovery , conformance checking, business process 
management. 
 
proceedings of the 21st european conference on information systems
11 big data as the fuel for mining your own business  
recently, process mining emerged as a new scientific discipline on the interface between process 
models and event data (van der aalst, 2011). on the one hand, conventional business process 
management (bpm) and workflow management (wfm) approaches and tools are mostly model-
driven with little consideration for event data. on the other hand, data mining (dm), business 
intelligence (bi), and machine learning (ml) focus on data without considering end- to-end process 
models, cf. (mitchell, 1997) and (hand, mannila, and smyth, 2001). process mining aims to bridge the 
gap between bpm and wfm on the one hand and dm, bi, and ml on the other hand. here, the 
challenge is to turn torrents of event data ("big data") into valuable insights related to performance 
and compliance. fortunately, process mining results can be used to identify and understand 
bottlenecks, inefficiencies, deviations, and risks. process mining helps organizations to "mine their 
own business", i.e., they are enabled to discover, monitor and improve real processes by extracting 
knowledge from event logs.  
 
process 
mining
data-oriented analysis   
(data mining, machine learning, business intelligence)process model analysis  
(simulation, verification, optimization, gaming, etc.)
performance-
oriented 
questions, 
problems and 
solutionscompliance-
oriented 
questions, 
problems and 
solutions
 
figure 1. process mining can be positioned as the missing link between process model analysis 
and data-oriented analysis. process mining is not limited to automated process 
discovery based on event data: it can be used to answer a wide variety of performance 
and compliance questions in a unified and integrated manner. 
 
as shown by hilbert and lopez (2011), our increasing capabilities to process and store data are 
undeniable. this will change the way operational processes can be analyzed and improved. this can 
be illustrated as follows. consider a typical 1 tb hard disk purchased in 2010. the disk can store 1012 
bytes (i.e., one terabyte). according to idc, the entire “digital universe ” was 1.2  zettabyte (1.2 x 
1021 bytes) at that time. this estimate ta ken from idc's annual report “ the digital universe decade: 
are you ready?” published in may 2010. hence, the 1 tb disk needs to grow 230.16 = 1.2 x 1021 / 1012 
times. based on the average growth rate of hard disks over the last decades and an extrapolation of 
moore's law, we assume that hard disks indeed double every 1.56 years (like in the past 40 years). 
this implies that in 30.16 x 1.56 = 47.05 years a standard hard disk may contain the whole “digital 
universe”  of 2010. this includes the entire internet, all computer files, transaction logs, movies, 
photos, music, books, databases, a scientific data, etc. this simple calculation exemplifies the 
increasing relevance of data for process analysis by simply assuming a continuing growth of event 
data in the next decennia. it is obvious to see that business processes will generate more and more 
proceedings of the 21st european conference on information systems
2event data that can be used for analysis. detailed transaction data and sensor data (cf. rfid tags) will 
enable new process mining applications replacing traditional analysis based on hand-made models 
(van der aalst, 2011). 
since the mckinsey report “big data: the next frontier for innovation, competition, and 
productivity” (manyika, chui, brown, bughin, dobbs, roxburgh, and byers , 2011), the term "big 
data" appeared on the radar of all larger organizations. consultants, software suppliers, and it 
specialists have high-jacked the term and all define "big data" in a different manner. in scientific 
computing, large scale experiments like the discovery of the higgs- particle by cern’s large hadron 
collider (lhc) are considered as primary examples of big data. the four detectors of the lhc-
particle collider produce in the order of fifteen petabytes (15 x 1015 bytes) per year, i.e., the equivalent 
of three mill ion dvd’s. however, facebook, google, and youtube are managing even larger data sets. 
the desire to manage huge datasets has resulted in key technologies such as the hadoop programming 
framework (inspired by google’s mapreduce). data is the fuel for new an alysis techniques an d 
people like to brag about the volume of data being stored and analyzed. in fact, sometimes people lose 
track of the original objectives. if data is the "fuel" of analysis, it cannot be the goal to consume as 
much data as possible. instead, the focus should be on the efficient and effective use of data (mileage 
and speed).  
 
2 elephant  trails  in big data  
the starting point for process mining is not just any data, but event  data (ieee task force on process 
mining, 2012). data should refer to discrete events that happened in reality. a collection of related 
events is referred to as an event log . each event in such a log refers to an activity  (i.e., a well-defined 
step in some process) and is related to a particular case (i.e., a process instance). the events belonging 
to a case are ordered  and can be seen as one “run” of the process. it is important to note that an event 
log contains only example behavior , i.e., we cannot assume that all possible runs have been observed. 
in fact, an event log often contains only a fraction of the possible behavior (van der aalst, 2011). 
often event logs store additional information about events and these additional data attributes may be 
used during analysis. for example, many process mining techniques use extra information such as the 
resource  (i.e., person or device) executing or initiating the activity, the timestamp  of the event, or data 
elements  recorded with the event (e.g., the size of an order). 
event logs can be viewed as “olifantenpaadjes”. this is  the dutch word for “elephant trails” 
commonly known as desire lines . desire lines refer to tracks worn across grassy spaces - where people 
naturally walk - regardless of formal pathways. a desire line emerges through erosion caused by 
footsteps of humans (or animals) and the width and degree of erosion of the path indicates how 
frequently the path is used. typically, the desire line follows the shortest or most convenient path 
between two points. moreover, as the path emerges more people are encouraged to use it, thus 
stimulating further erosion. dwight eisenhower is often mentioned as one of the persons using this 
emerging group behavior. before becoming the 34th president of the united states, he was the 
president of columbia university. when he was asked how the university should arrange the 
sidewalks to best interconnect the campus buildings, he suggested letting the grass grow between 
buildings and delay the creation of sidewalks. after some time the desire lines revealed themselves. 
the places where the grass was most worn by people's footsteps were turned into sidewalks. 
the digital desire lines  recorded in event logs may be very different from formal procedures or 
expected behavior (i.e., the "sidewalks" in processes). as more events are recorded, it becomes 
possible to determine desire lines in organizations, systems, and products. besides visualizing such 
desire lines, we can also investigate how these desire lines change over time, characterize the people 
following a particular desire line, etc. desire lines may reveal behaviors that are "undesirable" (unsafe, 
inefficient, unfair, etc.) and used for auditing and compliance purposes (van der aalst, van hee, van 
proceedings of the 21st european conference on information systems
3der werf, and verdonk, 2010). uncovering such phenomena is a prerequisite for process and product 
improvement. process mining can be used to redesign procedures and systems ("reconstructing the 
formal pathways"), to recommend people taking the right path ("adding signposts were needed"), or to 
build in safeguards ("building fences to avoid dangerous situations"). 
modeled (normative or 
descriptive) behaviordeviating behavior may be squeezed into model for analysis 
(e.g., performance analysis, prediction, and decision mining) 
deviating behavior can identified 
and subsequently used for 
conformance checking 
 
figure 2. process mining aligns observed and modeled behavior: "moves" seen in reality are 
related to "moves" in the model (if possible).   
one of the key contributions of process mining is its ability to relate observed and modeled behavior 
at the event level , i.e., traces observed in reality (process instances in event log) are aligned with traces 
allowed by the model (complete runs of the model). as shown in figure 2 it is useful to align both 
even when model and reality disagree. first of all, it is useful to highlight where and why there are 
discrepancies between observed and modeled behavior. second, deviating traces need to be 
"squeezed" into the model for subsequent analysis, e.g., performance analysis or predicting remaining 
flow times. the latter is essential in case of non-conformance (van der aalst, adriansyah, and van 
dongen 2012). without aligning model and event log, subsequent analysis is impossible or biased 
towards conforming cases. 
proceedings of the 21st european conference on information systems
4(b) zooming in on the center of moscow (a) map of moscow
(c) satellite view of center (d) subway map of moscow
(e) photos projected on map (f) traffic jams projected on map 
figure 3. process models should be viewed as maps (like in google maps). typically, there are 
multiple useful maps showing the same physical reality. moreover, it should be 
possible to seamlessly zoom-in and project information (e.g., traffic congestion) onto 
maps. 
the desire line metaphor suggests that we can view process models as maps . often modelers aim to 
create one "perfect process model " that needs to serve all possible purposes. however, a process 
model is merely a view on the real process. depending on the questions that need to be answered, 
proceedings of the 21st european conference on information systems
5different views may be needed. there may be highway maps, subway maps, city maps, bicycle maps, 
boating maps, and hiking maps covering (parts of) the same area. some elements may not be shown 
while other elements are emphasized. some maps may show a larger area with less detail (cf. fig. 3a) 
whereas other maps show a smaller area with more details (cf. fig. 3b). when using the subway 
another map is desired (cf. fig. 3d). it is also possible to map current or historic information on maps. 
for example, fig. 3f shows the traffic jams in the center of moscow on a monday morning in april 
2013. these examples illustrate that depending on the intended purpose (discussion, bottleneck 
analy
sis, auditing, simulation, etc.), different process models are needed.  
 
3 use cases related to process mining  
to conclude this keynote paper, we discuss the main bpm use cases related to process mining. in 
(van der aalst, 2013) twenty use cases  are used to structure the bpm discipline and to show "how, 
where, and when" bpm techniques can be used. these are summarized in fig. 4. models  are depicted 
as pentagons marked with the letter m. a model may be descriptive ( d), normative ( n), and/or 
executable ( e). a " d|n|e " tag inside a pentagon means that the corresponding model is descriptive, 
normative, or executable. configurable models  are depicted as pentagons marked with cm. event 
data (e.g., an event log) are denoted by a disk symbol (cylinder shape) marked with the letter e. 
information systems  used to support processes at runtime are depicted as squares with rounded corners 
and marked with the letter s. diagnostic information  is denoted by a star shape marked with the letter 
d. we distinguish between conformance-related diagnostics  (star shape marked with cd) and 
performance-related diagnostics  (star shape marked with  pd). the twenty atomic use cases can be 
chained together in so-called composite  use cases. these composite cases can be used to describe 
realistic bpm scenarios. 
in (van der aalst, 2013), bpm literature is analyzed to see trends in terms of the twenty use cases, 
e.g., topics that are getting more and more attention. here we only mention the use cases most related 
to process mining.  
 use case log event data  (loged) refers to the recording of event data, often referred to as 
event logs. such event logs are used as input for various process mining techniques. xes 
(extensible event stream), the successor of mxml (mining xml format), is a standard format 
for storing event logs (www.xes-standard.org). 
 use case discover model from event data  (discm) refers to the automated generation of a 
process model using process mining techniques. examples of discovery techniques are the 
alpha algorithm (van der aalst, weijters, and maruster, 2004), language-based regions (werf, 
van dongen, hurkens, and serebrenik, 2010), and state-based regions (carmona, cortadella, 
and kishinevsky, 2008). note that classical synthesis approaches (darondeau, 2004) need to 
be adapt
ed since the event log only contains examples. 
 use case check conformance using event data  (confed) refers to all kinds of analysis 
aiming at uncovering discrepancies between modeled and observed behavior. conformance 
checking may be done for auditing purposes, e.g., to uncover fraud or malpractices. token-
based (rozinat and van der aalst, 2008) and alignment-based (van der aalst, adriansyah, 
and van dongen, 2012) techniques replay the event log to identify non-conformance (weerdt, 
de backer, vanthienen, and baesens, 2011).  
 use c ase analyze performance using event data  (perfed) refers to the combined use of 
models and timed event data. by replaying an event log with timestamps on a model, one can 
measure delays, e.g., the time in-between two subsequent activities. the results of timed 
replay can be used to highlight bottlenecks. moreover, the gathered timing information can be 
used for simulation or prediction techniques (rozinat, mans, song, and van der aalst, 2009). 
proceedings of the 21st european conference on information systems
6m
d|n|edesign model
em
d|ediscover model from 
event data
m
d|n|eselect model from 
collectionmmm
d|n|e(desm)
(discm)
(selm)
m
d|n|emerge modelsmmm
d|n|e
m
d|n|ecompose model m
d|n|em
d|n|e
m
d|n|e(merm)
(compm)
cm
d|n|emerge models into 
configurable modelmmm
d|n|ecm
d|n|edesign configurable 
model
m
d|n|econfigure configurable 
model
cm
d|n|e(descm)
(mercm)
(concm)analyze performance 
based on model
m
epd
verify model
m
ecd(perfm)
(verm)
check conformance 
using event data
m
ecde
analyze performance 
using event data
m
eepd(confed)
(perfed)
repair model
m
d|n|ecd m
d|n|e
extend model
m
eem
e
improve model
m
d|n|em
d|n|epd(repm)
(extm)
(impm)slog event data
es
monitor
s d(loged)
mon
adapt while running
m
e(adawr) s m
e
enact model
m
esrefine model
m
d|nm
e(refm)
(enm) 
figure 4. twenty bpm use cases (van der aalst, 2013). use cases log event data (loged), 
discover model from event data (discm), check conformance using event data 
(confed), analyze performance using event data (perfed), repair model (repm) , 
extend model (extm), improve model (impm) are most related to process mining. 
 
 use case repair model  (repm) uses the diagnostics provided by use case confed to adapt 
the model such that it better matches reality. on the one hand, a process model should 
correspond to the observed behavior. on the other hand, there may be other forces influencing 
the desired target model, e.g., a reference model, desired normative behavior, and domain 
knowledge. 
 event logs refer to activities being executed and events may be annotated with additional 
information such as the person/resource executing or initiating the activity, the timestamp of 
proceedings of the 21st european conference on information systems
7the event, or data elements recorded with the event. use case extend model  (extm) refers to 
the use of such additional information to enrich the process model. for example, timestamps 
of events may be used to add delay distributions to the model. data elements may be used to 
infer decision rules that can be added to the model. resource information can be used to attach 
roles to activities in the model (rozinat, wynn, van der aalst, ter hofstede, fidge, 2009). 
 use case improve model  (impm) uses the performance related diagnostics obtained through 
use case perfed. impm is used to generate alternative process models aiming at process 
improvements, e.g., to reduce costs or response times. these models can be used to do ``what-
if'' analysis. note that unlike repm the focus impm is on improving the process itself. 
 
4 min(d) your own business  
the phrase "mind your own business" is a common english saying suggesting people to focus on their 
own affairs rather than prying into the lives of others. in this keynote paper, the phrase is used to 
encourage the reader to apply process mining techniques to the event data that can be found for any 
operational process. the torrents of event data available in most organizations enable evidence-based 
business process management  (ebbpm). we predict that there will be a remarkable shift from pure 
model-driven or questionnaire-driven approaches to data-driven process analysis as we are able to 
monitor and reconstruct the real business processes using event data. see (van der aalst, 2011) for 
techniques supporting this shift. note that the current version of prom holds over 550 plug-ins. each 
plug-in provides some analysis capability, e.g., discovering a petri net from event data or animating 
historic data on a fuzzy model.  
 
references  
carmona, j., cortadella, j., and kishinevsky, m. (2008). a region-based algorithm for discovering 
petri nets from event logs. in business process management (bpm2008). 358-373. 
darondeau, p. (2004). unbounded petri net synthesis. in lectures on concurrency and petri nets, j. 
desel, w. reisig, and g. rozenberg, eds. lecture notes in computer science series, vol. 3098. 
springer-verlag, berlin, 413-438. 
grigori, d., casati, f., castellanos, m., dayal, u., sayal, m., and shan, m. (2004). business process 
intelligence. computers in industry  53,  3, 321-343. 
hand, d., mannila, h., and smyth, p. (2001). principles of data mining. mit press, cambridge, ma. 
hilbert, m. and lopez, p. (2011) the world's technological capacity to store, communicate, and 
compute information. science, 332(6025), 60-65. 
ieee task force on process mining (2012). process mining manifesto. in f. daniel, k. barkaoui, 
and s. dustdar, editors, business process management workshops, volume 99 of lecture notes in 
business information processing, pages 169-194. springer-verlag, berlin. 
manyika, j., chui, m., brown, b., bughin, j., dobbs, r., roxburgh, c., and byers, a. (2011). big 
data: the next frontier for innovation, competition, and productivity. mckinsey global institute. 
mitchell, t. (1997). machine learning. mcgraw-hill, new york. 
rozinat, a. and van der aalst, w.m.p. (2008). conformance checking of processes based on 
monitoring real behavior. information systems, 33(1), 64-95. 
rozinat, a., wynn, m., van der aalst, w.m.p., ter hofstede, a., fidge, c. (2009). workflow 
simulation for operational decision support. data and knowledge engineering, 68(9), 834-850. 
rozinat, a., mans, r., song, m., and van der aalst, w.m.p. (2009). discovering simulation models. 
information systems, 34(3), 305-327. 
weer
dt, j., m. de backer, vanthienen, j., and baesens, b. (2011). a robust f-measure for evaluating 
discovered process models. in ieee symposium on computational intelligence and data mining 
(cidm 2011), n. chawla, i. king, and a. sperduti, eds. ieee, paris, france, 148-155. 
proceedings of the 21st european conference on information systems
8van der aalst, w.m.p. (2011). process mining: discovery, conformance and enhancement of 
business processes. springer-verlag, berlin. 
van der aalst, w.m.p. (2013). business process management: a comprehensive survey. isrn 
software engineering, doi:10.1155/2013/507984, 1-37. 
van der aalst, w.m.p. , adriansyah, a., and van dongen, b. (2012). replaying history on process 
models for conformance checking and performance analysis. wires data mining and 
knowledge discovery, 2(2), 182-192. 
van der aalst, w.m.p., van hee, k.m., van der werf, j.m. and verdonk, m. (2010). auditing 2.0: 
using process mining to support tomorrow's auditor. ieee computer, 43(3):90-93. 
van der aalst, w., weijters, a., and maruster, l. (2004). workflow mining: discovering process 
models from event logs. ieee transactions on knowledge and data engineering   16(9), 1128-
1142. 
werf, j., van dongen, b., hurkens, c., and serebrenik, a. (2010). process discovery using integer 
linear programming. fundamenta informaticae 94, 387-412. 
 
proceedings of the 21st european conference on information systems
9