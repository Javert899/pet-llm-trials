supporting the full bpm life-cycle using
process mining and intelligent redesign
wil m.p. van der aalst, mariska netjes, and hajo a. reijers
eindhoven university of technology, department of technology management,
po box 513, nl-5600 mb eindhoven, the netherlands
w.m.p.v.d.aalst,m.netjes,h.a.reijers@tm.tue.nl
abstract. business process management (bpm) systems provide a broad
range of facilities to enact and manage operational business processes.
ideally, these systems should provide support for the complete bpm
life-cycle: (re)design, con¯guration, execution, control, and diagnosis of
processes. however, based on an extensive evaluation of the filenet p8
bpm suite, we show that existing bpm tools are unable to support the
full life-cycle. there are clearly gaps between the various phases (i.e.,
users need to transfer or interpret information without any support) and
some of the phases (e.g., the redesign and diagnosis phases) are not sup-
ported satisfactorily. we selected the filenet p8 bpm suite because it
is consistently ranked as one of the leading commercial bpm systems
and representative for the current generation of bpm products. based
on this evaluation, we show what is needed to close the bpm life-cycle
and seamlessly support all phases. we will argue that techniques for pro-
cess mining and intelligent redesign are needed to support the (re)design
and diagnosis phases and thus close the bpm life-cycle. we also brie°y
report on the work done in the context of the prom tool which is used
as framework to experiment with such techniques.
keywords : business process management, work°ow technology, process mining,
business process simulation, business process intelligence, filenet.
1 introduction
business process management (bpm) systems can be seen as successors of work-
°ow management (wfm) systems, which became popular in the mid-nineties.
however, already in the seventies people were working on o±ce automation sys-
tems which are comparable with today's wfm systems. consider, for example,
the o±cetalk system developed by ellis et al. at xerox that was already able to
support administrative processes based on petri-net-based speci¯cations of pro-
cedures (ellis, 1979). today, many wfm systems are available (aalst & hee,
2004a; jablonski & bussler, 1996; lawrence, 1997; mä uhlen, 2004). the core func-
tionality of these systems can be described as the ability to support an operational
business process based on an explicit process model , i.e., automating the \°ow of
work" without necessarily automating individual activities.recently, wfm vendors started to position their systems as bpm systems.
we de¯ne bpm as follows: supporting business processes using methods, tech-
niques, and software to design, enact, control, and analyze operational processes
involving humans, organizations, applications, documents and other sources of
information (aalst, hofstede, & weske, 2003). this de¯nition restricts bpm
to operational processes, i.e., processes at the strategic level and processes that
cannot be made explicit are excluded. it also follows that systems supporting
bpm need to be \process aware". after all, without information about the op-
erational processes at hand little support is possible. when comparing classical
de¯nitions of wfm (lawrence, 1997) with the above de¯nition of bpm, one
could conclude that the main goal of bpm systems is to o®er a broader set of
functionalities and support of the whole process life-cycle. this is also the \sales
pitch" that many vendors use to market their products. however, analysis of
existing bpm systems shows that the functionality of these systems leaves much
to be desired. in the ¯rst part of this paper we analyze the limitations of today's
bpm systems. based on this analysis problems are identi¯ed and in the second
part of this paper, we show how to address these problems.
1.1 step 1: evaluation of the filenet p8 bpm suite
the ¯rst goal of this paper is to analyze whether today's bpm systems actually
support the bpm life-cycle. to do this we use the bpm life-cycle as depicted in
figure 1. this life-cycle identi¯es ¯ve phases ( design ,con¯guration ,execution ,
control , and diagnosis ), which will be described later. the depicted life-cycle is
an extension of the life-cycle presented in (aalst, hofstede, & weske, 2003). we
will discuss the desired functionality in each of the phases. to make things more
concrete, we have evaluated one particular system in detail: filenet p8 bpm
suite (version 3.5). we have selected this system because it is considered as one
of the leading commercial bpm systems (gartner, 2003, 2004, 2005). moreover,
the system is explicitly positioned by the vendor as a tool to support the whole
bpm life-cycle.
design configuration 
execution
control diagnosis 
fig. 1. the bpm life-cycle.we analyze the support of the filenet p8 bpm suite in each of the ¯ve
phases shown in figure 1. for our evaluation we performed a full pass through
these phases using ¯ve realistic work°ow scenarios, each including a concrete
work°ow process and life-cycle context. we have used ¯ve work°ows to be able
to obtain additional insights when necessary. as starting point for our evaluation,
we will assume that each work°ow has already made one pass through the bpm
cycle. the name and the related literature for each of the work°ows is provided
in table 1. these particular work°ows have been selected because the papers
describing them provide a diagnosis of the improvement points and one or more
alternative designs. also, the original work°ows and the alternatives have already
been tested and the underlying data were available to us.
table 1. the work°ows used in our analysis.
work°ow name reference
intake admin (reijers, 2003)
credit application (reijers, 2003)
intake meetings (jansen-vullers & reijers, 2005; reijers,
2003)
bank account (netjes, aalst, & reijers, 2005)
mortgage request (aalst, 2001; netjes, vanderfeesten, & rei-
jers, 2006)
1.2 step 2: an approach based on process mining and intelligent
redesign
based on the evaluation of the filenet p8 bpm suite using the ¯ve work°ows
mentioned in table 1, we noted that there was little support for the diagnosis and
design phases in the bpm life-cycle. moreover, the transfer of information from
the run-time environment to the design-time environment is hardly supported.
when looking at other bpm products we see the same limitations. therefore,
the second part of this paper is concerned with a more detailed analysis of these
problems and a proposal for a solution addressing them. figure 2 sketches the
link between step 1 (evaluation of systems like the filenet p8 bpm suite) and
step 2 (our proposal to address some of the problems identi¯ed). on the left-
hand side of figure 2, we highlight the part of the bpm life-cycle we consider to
be most problematic and typically poorly supported by bpm systems. the right-
hand side of figure 2 shows a diagram analyzing the problem and proposing an
approach based on process mining and intelligent redesign. we will elaborate on
this diagram later in the paper.
our approach is based on the observation that in current bpm systems there
are two core problems:information
systemoperational
process
modelsevent
logsmodels
discovery
log-based
analysisrecords
configuressupports/
controls
design
extension
answers to
questionsmodel&log-
based analysismodel-based
analysisintelligent
redesignconformanceredesign
redesign
rules
problem area
addressed by
the approach
proposed in
this paperfig. 2. problems in the bpm life-cycle related to the approach presented in this paper.
{problem 1: the actual execution of the process supported by the bpm sys-
tem is completely disconnected from the (re)design of the process. to close
the bpm life-cycle it is necessary to automatically interpret information
stored in event logs and use this to discover, check, and enhance models
describing what is really going on in the business process. to address this
problem we propose to use process mining techniques (aalst, weijters, &
maruster, 2004; aalst, reijers, & song, 2005; agrawal, gunopulos, & ley-
mann, 1998; cook & wolf, 1998; datta, 1998; weijters & aalst, 2003).
{problem 2: bpm systems o®er graphical editors and sometimes also simple
analysis facilities to analyze the design.1several bpm systems (including
the filenet p8 bpm suite) o®er basic simulation facilities. however, these
facilities are typically considering a very abstract situation (with many as-
sumptions about reality that do not hold) and provide only \what-if" anal-
ysis. this means that it is di±cult to use these systems and the designer
has to come up with ideas for redesigns. the goal of intelligent redesign is
twofold. first of all, we want to use the information about the real process
obtained through process mining. second, we want to move beyond \what-if"
analysis, i.e., the system should automatically suggest and evaluate di®erent
redesign possibilities.
in the context of the prom framework (dongen, medeiros, verbeek, weijters,
& aalst, 2005) we are developing automated support for process mining and
intelligent redesign in an e®ort to address the two problems mentioned above.
the goal of this paper is not to provide detailed solutions but to show the
potential of truly closing the bpm life-cycle.
1in this context we are not referring to the veri¯cation of models, i.e., the goal is
not to assess the internal consistency (e.g., absence of deadlocks) but to improve the
process from a business perspective.the remainder of this paper is organized as follows. section 2 discusses related
work. then, in section 3, we evaluate the filenet p8 bpm suite based on a
generic approach which can also be applied to other bpm systems. based on
this evaluation we identify the main problems and propose in section 4 an ap-
proach involving techniques for process mining and intelligent redesign. section 5
concludes the paper.
2 related work
since the early nineties, work°ow technology has matured (georgakopoulos, hor-
nick, & sheth, 1995) and several textbooks have been published, e.g., (aalst &
hee, 2004a; dumas, aalst, & hofstede, 2005; jablonski & bussler, 1996; ley-
mann & roller, 1999; marinescu, 2002; mä uhlen, 2004). most of the available
systems use some proprietary process modeling language and, even if systems
claim to support some \standard", there are often all kinds of system-speci¯c
extensions and limitations. petri nets have often been used as an abstraction
of these languages: both for the purpose of modeling the control-°ow aspects
work°ows as for the analysis of work°ows and di®erent work°ow languages and
systems (aalst & hee, 2004a; aalst, hofstede, kiepuszewski, & barros, 2003;
dumas et al., 2005). the evaluation of work°ow and bpm systems has been the
domain of consultancy ¯rms such as gartner (gartner, 2003, 2004, 2005) and
many others. these evaluations are typically not very rigorous and lack objec-
tive criteria with respect to the functionality of systems. the work°ow patterns
initiative, cf. www.work°owpatterns.com, has been one of the few attempts to
evaluate systems and languages in a systematic manner (aalst, hofstede, kie-
puszewski, & barros, 2003). this paper does not use the work°ow patterns to
evaluate the filenet p8 bpm suite because we want to look at the support of
the whole bpm life-cycle. note that the work°ow patterns focus on speci¯c as-
pects of the system such as the control-°ow perspective, the data perspective, or
the resource perspective. therefore, we used an approach were we selected ¯ve
processes (table 1) and for each of these processes we went through the whole
bpm life-cycle.
it is impossible to give a complete overview of process mining here. therefore,
we refer to a special issue of computers in industry on process mining (aalst
& weijters, 2004) and a survey paper (aalst, dongen, et al., 2003) for more
references. we will show that process mining techniques can be split into three
categories: (1) discovery, (2) conformance, and (3) extension. techniques for
discovery try to generate a model based on the event logs. this may be a process
model (aalst et al., 2004; agrawal et al., 1998; cook & wolf, 1998; datta, 1998;
weijters & aalst, 2003), but also other models focusing on di®erent perspectives
(e.g., a social network (aalst, reijers, & song, 2005)) can be discovered using
process mining. techniques for conformance checking (rozinat & aalst, 2006a)
aim at exposing the di®erence between some a-priori model (e.g., a petri net
describing the control-°ow) and the real process observed via the event log.process mining techniques for model extension take some a-priori model (e.g., a
control-°ow model) and project other information on it derived from the log, e.g.,
a petri net can be extended by providing a decision tree for each choice in the
system (rozinat & aalst, 2006b). this way data and performance aspects can
be projected on some a-priori process model obtained directly from the system
or discovered through process mining.
process mining can be seen in the broader context of business (process) in-
telligence (bpi) and business activity monitoring (bam). in (grigori et al.,
2004; grigori, casati, dayal, & shan, 2001; sayal, casati, dayal, & shan, 2002)
a bpi toolset on top of hp's process manager is described. the bpi toolset
includes a so-called \bpi process mining engine". in (mä uhlen & rosemann,
2000) the authors describe the pisa tool which can be used to extract per-
formance metrics from work°ow logs. similar diagnostics are provided by the
aris process performance manager (ppm) (ids scheer, 2002). the latter tool
is commercially available and a customized version of ppm is the sta®ware pro-
cess monitor (spm) (tibco, 2005) which is tailored towards mining sta®ware
logs.
literature on \intelligent" redesign is limited (netjes, vanderfeesten, & rei-
jers, 2006). clearly there are many techniques originating from operations man-
agement (e.g., simulation, queueing networks , etc.) that can be applied to work-
°ow processes (buzacott, 1996). however, these typically only support \what-if"
analysis and do not provide suggestions for improvement.
several researchers have focused on the problem of not meeting certain dead-
lines in a process. for example, in (panagos & rabinovich, 1997) an approach
to dynamically adjust deadlines based on costs, expected execution times, and
available slack time is described. in (panagos & rabinovich, 1998) this approach
is re¯ned and supported by simulation experiments. in (eder, panagos, & ra-
binovich, 1999; eder, panagos, pezewaunig, & rabinovich, 1999) the topic of
capturing time constraints in work°ow de¯nitions is considered, and a pert-
like technique for the analysis of the temporal behavior of a work°ow is pro-
posed. this technique is similar to the one employed by the \prediction engine"
of sta®ware (sta®ware, 2003). there also several papers that address timing
(e.g., determining performance indicators based on simulation or some analyti-
cal method) without considering what to do in case deadlines are not met, cf.
(reijers, 2003) for an overview. for example, in (zhao & stohr, 1999) di®erent
task prioritization policies are compared with respect to turnaround times.
few of the simulation techniques and systems described in literature use
historic data. even fewer use the current state of a work°ow in their analysis.
a notable exception is (reijers & aalst, 1999) which proposes the concept of a
so-called short-term simulation, i.e., a \fast forward" into the near future based
on historic and current data.
most related to the type of intelligent redesign discussed in this paper are
the redesign rules de¯ned in (reijers, 2003). one example of such a rule is
the \knock-out rule" which describes how to reorder activities in a sequential or
parallel \checking process" consisting of multiple tests (aalst, 2001). also relatedare the \process recombinator" tool developed in the context of the mit process
handbook (bernstein, klein, & malone, 1999) and the koper tool described
in (nissen, 1998). the process recombinator tool (bernstein et al., 1999) uses
the notions of (i) process specialization and (ii) coordination mechanisms to
generate new designs on the basis of a list of core activities. from these process
designs the user can select the most promising ones. the koper tool (nissen,
1998) attempts to automate three activities required for process redesign: process
measurement, pathology diagnosis, and transformation matching. the idea is
that a limited set of process measures (e.g. process length, process hando®s, etc.)
can be used to identify process pathologies in a given process (e.g. a problematic
process structure, fragmented process °ows, etc.). these process pathologies can
then be matched to redesign transformations known to e®ectively deal with these
pathologies. note that the koper tool only provides ideas for redesign and does
not generate new designs.
3 evaluation of the filenet p8 bpm suite
as described in the introduction, we start by analyzing the filenet p8 bpm
suite.2the main goal of this evaluation is not to discuss the speci¯cs of this
particular system, but to provide some insights into the functionality of today's
bpm systems. the evaluation approach that we will present is based on the
bpm life-cycle and can also be applied to other systems. we selected the filenet
p8 bpm suite for two reasons. first of all, it is consistently ranked as one of
the leading commercial bpm systems (gartner, 2003, 2004, 2005). second, it
is representative for the current generation of bpm products. in fact, when it
comes to supporting the full bpm life-cycle we expect most systems to o®er less
functionality (gartner, 2003, 2004, 2005).
3.1 evaluation approach based on the bpm life-cycle
first, we present our system-independent approach to evaluate bpm systems.
pivotal to our evaluation approach is the bpm life-cycle depicted in figure 1.
clearly, we want to evaluate the degree to which each phase is facilitated by
a bpm system. moreover, we want to asses the interoperability among phases,
i.e., can information obtained or created in one phase be used in another phase?
for example, a bpm system may incorporate a simulation tool, but it may
be the case that the simulation model and the model used for execution are
incompatible, forcing the user to re-create models or to set parameters twice.
first, we focus on the design phase . in case of an already existing process
the goal of this phase is to create an alternative for the current process. this
alternative should remedy the diagnosed weaknesses of the process according to
the identi¯ed improvement possibilities. as indicated in figure 1, this phase is
in-between the diagnosis phase and the con¯guration phase, i.e., input from the
2this section is based on (netjes, reijers, & aalst, 2006b).diagnosis phase is used to identify improvement opportunities (e.g., bottlenecks
or other weaknesses) and the output is transferred towards the con¯guration
part of the bpm system. the resulting process de¯nition consists of the following
elements (aalst & hee, 2004a):
{the process structure,
{the resource structure,
{the allocation logic, and
{the interfaces.
we would like to emphasize that a graphical editor by itself does not o®er full
support for the design phase. in the design phase the designer wants to exper-
iment with designs, evaluate designs, and use input from the diagnosis phase.
some systems o®er a simulation tool to support the design phase. unfortunately,
such a tool is often disconnected from the diagnosis phase, i.e., it is impossible to
directly use historic data (e.g., to estimate service time distributions or routing
probabilities). moreover, simulation tools typically o®er only what-if analysis,
i.e., the designer has to come up with ideas for alternative designs and needs
to analyze each alternative separately without su±cient tool support (netjes,
vanderfeesten, & reijers, 2006).
thecon¯guration phase focuses on the detailed speci¯cation of the selected
design. note that in the design phase the emphasis is on the performance of the
process, while in the con¯guration phase the emphasis shifts to the realization
of the corresponding system. in principle, the design and con¯guration phase
could use a common graphical editor, i.e., the con¯guration phase details the
process de¯nition created in the design phase. however, it is important (a) that
the user is not forced to bypass the editor to code parts of the process and (b)
that technical details do not need to be addressed in the design phase. if both
phases use di®erent tools or concepts, interoperability issues may frustrate a
smooth transition from design to con¯guration.
in the execution phase the con¯gured work°ow becomes operational by trans-
ferring the process de¯nition to the work°ow engine. for the work°ow execution
not only the process de¯nition data is required, but also context data about
the environment with which the bpm system interacts. relevant environmental
aspects are:
{information on arriving cases,
{availability and behavior of internal/external resources and services.
the execution part of the bpm system captures the context data and relates it
to speci¯c instances of the work°ow.
the execution of the operational business process is monitored in the control
phase . the control part of the bpm system monitors on the one hand individ-
ual cases to be able to give feedback about their status and on the other hand,
aggregates execution data to be able to obtain the current performance of the
work°ow. the monitoring of speci¯c cases is done with the data from individual
process executions without any form of aggregation, while obtaining the perfor-
mance indicators requires aggregation of these data. information about runningcases can be used as input for the diagnosis phase. however, it can also be used
to make changes in the process. for example, temporary bottlenecks do not re-
quire a redesign of the process, but require the addition of resources or other
direct measures (e.g., not accepting new cases). hence, the control phase also
provides input for the execution phase.
in the diagnosis phase information collected in the control phase is used to
reveal weaknesses in the process. in this phase the focus is usually on aggregated
performance data and not on individual cases. this is the domain of process
mining (aalst, dongen, et al., 2003), business process intelligence (grigori et al.,
2004), data warehousing, and classical data mining techniques. this diagnosis
information is providing ideas for redesign (e.g., bottleneck identi¯cation) and
input for the analysis of redesigns (e.g., historic data) in the design phase.
as indicated, it is not su±cient to support each of the ¯ve phases in isola-
tion: interoperability among phases is vital for the usability of a bpm system.
consider for example the role of simulation. in a worst case scenario, a bpm
system could o®er a simulation tool that, on the one hand, cannot directly read
the current work°ow design used for execution (or relevant information is lost
in some translation) and, on the other hand, cannot use any historic data to ex-
tract information about service times, routing probabilities, workloads, resource
availability. such a simulation tool probably o®ers little support for the bpm
life-cycle (reijers & aalst, 1999).
3.2 applying the evaluation approach to filenet
we will evaluate the available bpm support by conducting a full pass through
the bpm cycle with the aid of several tools from the filenet p8 bpm suite. we
have evaluated the filenet p8 bpm suite, version 3.5. the system has been
used with microsoft windows 2000 as operating system, a microsoft sql server
as database, bea weblogic as j2ee application server and microsoft internet
explorer as browser. the p8 bpm suite consists of six parts: work°ow manage-
ment, process design, process simulation, process tracking, process analysis and
document review & approval (www.filenet.com). the evaluation of filenet's
bpm abilities focuses on the tools supporting the ¯rst ¯ve parts. document
review & approval is not relevant for the evaluation; it only facilitates process
management. in the remainder of this section, we consider filenet's capabilities
for each of the ¯ve bpm phases (design, con¯guration, execution, control, and
diagnosis). a detailed illustration of the bpm support o®ered by filenet can be
found in (netjes, reijers, & aalst, 2006a) where we present the full pass through
the bpm life-cycle for one of the ¯ve work°ow scenarios.
design we start our evaluation with the design phase. for each of the ¯ve
work°ow scenarios mentioned in table 1 we would like to create an alternative
work°ow with help from the filenet p8 bpm suite. we assume these work°ows
have already made one pass through the bpm cycle, meaning that the original
work°ow model and data from execution are present in the filenet system.a work°ow model for which an alternative should be made can be loaded in
the filenet process designer , which, however, does not support the creation of
one or more alternatives. the redesign of the original model to obtain a better
performing alternative should be done manually. for each of the work°ows we
take the alternatives described in the related paper and use the process designer
to change the original model to the alternative model. one of the alternative
designs made with the process designer is shown in figure 3. the depicted
design presents a medical process in which a mental patient is registered and
assigned to medical employees (intakers), and for which intake meetings are
planned. a detailed description of the process is available in (reijers, 2003).
more information on the modeling of work°ows with the filenet process designer
can be found in (netjes, reijers, & aalst, 2006a).
fig. 3. work°ow model in the process designer .
the performance of each of the created alternatives should be evaluated to
¯nd the best alternative. for this we use the filenet process simulator . for
each alternative we create a simulation scenario for which we import the process
steps, their order and the allocation logic de¯ned with the process designer . the
imported data can not be changed in the process simulator , but a replacement
can be imported from the process designer without the loss of settings. other
process de¯nition data should be added to the simulation scenario manually.
jobs are connected to the process steps and assigned to resources which areallocated according to shifts . the notion of shifts allows for the scheduling of
resources over the available working hours. relating these jobs,resources and
shifts to each other is rather complicated, because only one de¯nition window
can be open at the time and relations should also be indicated when de¯ning a
job,resource orshift.
in addition to the de¯nition data there is context data required to perform
a simulation. historic data is present in the system, but it can only be used in
a limited way. historic information on arriving cases can be transferred to the
process simulator , but all other data, like processing times and routing proba-
bilities, should be derived from the execution data and included manually. it is
only possible to provide constant values for the simulation parameters, so the
simulation results will only provide a rough indication for the performance of
a scenario. simulation results are generated fast and with no additional e®ort.
the use of the filenet process simulator is in detail explained in (netjes, rei-
jers, & aalst, 2006a). a simulation scenario with simulation results is depicted
in figure 4. for each of the ¯ve work°ows we choose the best alternative which
we specify in detail in the con¯guration phase.
con¯guration the filenet process designer is also used for the con¯guration
of the chosen alternative work°ows and o®ers interoperability between the de-
sign and the con¯guration phase. in the design phase we already speci¯ed the
process structure and the mapping of resources to tasks for each work°ow with
theprocess designer . the more complicated parts of the process structure are
detailed out in the con¯guration phase. each work°ow model contains one or
more complex constructs, but besides one construct, we have been able to con-
¯gure them all with the process designer . the resource structure, the allocation
rules and the interfaces are de¯ned outside the process designer . de¯ning out-
side the process designer allows for sharing with other processes, making the
resource structure and the allocation rules reusable for other process de¯nitions.
all ¯ve work°ows use the same allocation rules and some work°ows have the
same resource structure. the complete con¯guration of the ¯ve work°ows, both
inside and outside the process designer has been done in two working days. the
con¯guration phase is strongly supported by the filenet p8 bpm suite.
as closure of the con¯guration phase, the work°ow model is checked for com-
pleteness by the system and a work°ow instance could be launched to pretest
the execution of the work°ow. another possible check would have been a check
on the correctness of the model, conform the veri¯cation of work°ow processes
provided by the wo°an tool (verbeek, basten, & aalst, 2001), but such a veri¯-
cation is not supported by the filenet system. the con¯guration of the work°ows
is necessary for their execution.
execution the execution phase is started with the transfer of the work°ow
con¯gurations to the filenet process engine . all process de¯nition data are
transferred to the process engine providing interoperability between the con¯g-
uration and the execution phase. resources work on the processes in operationvia an inbox. the filenet p8 bpm suite o®ers integration with external ap-
plications, document management, integration with content management, and
interaction between inter-related processes. the filenet system supports the ex-
ecution phase in an excellent way. we expected mature support for execution,
because this support has traditionally been the heart of a wfm system and
many systems provide extended support for the execution phase. in the execu-
tion phase context data is related to each speci¯c instance of a work°ow and this
combination of de¯nition and context data is used for the control of a work°ow.
control in the control phase, the operational business process is monitored to
follow individual cases and to obtain the performance of a work°ow. the ¯rst
way of monitoring is supported by the filenet process administrator and the
second by the analysis engine , providing a strong support for the control phase.
the execution data for individual cases and other work°ow events are logged
by the process engine . the history of a certain work°ow, step or work item can be
tracked in the log through the filenet process administrator . for the work°ows
with conditional routing this gives the opportunity to determine which steps
were executed for a speci¯c case. with the process administrator it can also be
determined how certain decisions were made during execution allowing us to see
at which point and why a certain case was rejected.
the performance of a work°ow is read from aggregated execution data. the
execution data present in the process engine is aggregated and parsed to the
filenet analysis engine . interoperability exists between the execution and the
control phase, because all execution data necessary for control are available either
through the process engine or the analysis engine . the aggregated performance
data resides on a separate engine to not a®ect the performance of the process
engine . reporting and analysis of the aggregated data is facilitated by twenty
out-of-the-box reports; each graphically presenting the data related to one per-
formance indicator. it is possible to specify custom reports, but this requires
advanced excel skills. the representation of the data can be manipulated by
adjusting the detail level or by ¯ltering the data.
an analysis of the work present in the queues gives insight in the existence of
temporary bottlenecks in the process. this information is used as feedback for the
execution phase. the feedback, however, is obtained from human interpretation
of the analysis results and does not contain suggestions for the removal of the
bottleneck. more permanent weaknesses in the process could also be revealed
based on the analysis of performance data and this is done in the diagnosis
phase.
diagnosis in the diagnosis phase, problems and improvement possibilities are
identi¯ed through analysis of the operational process. the analysis engine fa-
cilitates the control and the diagnosis phase, creating interoperability between
the two phases. analysis reports present an aggregated view on the performance
data and weaknesses in the process are derived from this. the derivation, how-
ever, is not supported by the filenet p8 bpm suite and is based on humanfig. 4. simulation results from the process simulator .
insights. a system not capable of identifying process weaknesses is certainly un-
able to provide improvement suggestions for these weaknesses. the filenet p8
bpm suite provides limited support for the diagnosis phase and the creation of
ideas for process improvement should be done manually.
the ideas for redesign generated in the diagnosis phase could result in another
pass through the bpm cycle starting with a new design phase. when we started
our pass in the design phase it became clear that historic performance data is
necessary to obtain the performance of the created redesigns with simulation.
we already mentioned that only historic arrival data could be used, making
the interoperability between the diagnosis and the design phase limited. we did
not mention yet that data generated with simulation can also be transferred
to the analysis engine and presented in the performance reports. this provides
a comprehensive view on the simulation results. nevertheless, presenting the
correct data becomes problematic when multiple scenarios of the same simulation
model have been simulated over the same simulation time. it is not possible to
select the data of only one of the scenarios, while the aggregation of all simulation
data leads to unusable results. the only solution for this is clearing the analysis
engine before each new simulation run, which does not only lead to unworkable
situations, but will also remove the historic execution data from the analysis
engine .
3.3 analysis of the evaluation results
the conclusions from the evaluation just described are summarized in table 2.
in table 2 we present the support required for each phase in the bpm life-cycle
and the support provided by the filenet p8 bpm suite. from our evaluationwe conclude that filenet provides strong support for the con¯guration, the ex-
ecution and the control phase. in particular,
{the con¯guration phase is well supported by the process designer .
{the execution of the work°ow is strongly supported by the process engine .
{the control phase is supported by the process administrator and the analysis
engine .
less explicit support is available for the diagnosis and (re)design phase. some
support in the diagnosis phase is provided by the process analyzer , which gives
an aggregate view on the data. however, the search for weaknesses in the pro-
cess is not supported and certainly no improvement suggestions are generated.
moreover, the information provided by the process analyzer is limited to simple
performance indicators such as °ow time and utilization. there is no analysis
aiming at identifying structures or patterns in the processes and the organiza-
tion (e.g., social networks or deviations from the normal execution paths). fur-
thermore, in the design phase the creation of the alternatives is not supported.
limited support is available through the representation of the alternatives as
facilitated by the process designer and the selection of the best alternative by
theprocess simulator .
the conclusion for our interoperability evaluation is that the interoperability
of the filenet process tools is notably supported in the transitions between the
design, the con¯guration, the execution, the control and the diagnosis phase. at
the same time, the interoperability between the diagnosis and the design phase
is limited to the use of historic arrival data (present in the analysis engine ) for
the simulation. all other performance data present in the analysis engine can
not be passed to the process simulator and should be copied manually. although
interoperability exists between the execution and control phase, the loop back
from control to execution is not supported. in the control phase temporary bot-
tlenecks can be identi¯ed, but human intervention is required to interpret the
¯ndings and tune the operational process.
these insights are in line with the support that could be expected from
a wfm system, as these systems are well-known for their emphasis on the
con¯guration, execution and control phase. nonetheless, it is also clear that
opportunities exist to improve the support that so-called bpm systems o®er to
execute the entire bpm life-cycle. we consider the filenet p8 bpm suite as a
relevant benchmark for many of the other available systems, because of its broad
range of features and market dominance. yet the system is far from supporting
the whole bpm life-cycle. therefore, in the remainder, we focus on the main
problems identi¯ed, i.e., limited support for the diagnosis and (re)design phase
and the problematic integration of components in this part of the bpm life-cycle .
in the next section we will argue that an approach based on state-of-the-art
techniques for process mining andintelligent redesign is needed to address these
problems.table 2. summary of the evaluation.
phase required support filenet support
design make redesign -
model designs process designer
evaluate designs process simulator
compare designs -
input from diagnosis phase available - (only arrival data)
output for con¯guration phase available through process designer
con¯guration model detailed designs process designer
input from design phase available through process designer
output for execution phase available transfer of process de¯nition
execution work°ow engine process engine
capture context data process engine
input from con¯guration phase available transfer to process engine
output for control phase available transfer from process engine
control monitor speci¯c cases process administrator
aggregation of execution data analysis engine
monitor performance process analyzer
input from execution phase available transfer to analysis engine
output for diagnosis phase available through analysis engine
output for execution phase available -
diagnosis reveal weaknesses process analyzer
identify improvement points -
input from control phase available through analysis engine
output for design phase available - (only arrival data)
- : not supported by filenet, should be done manually.4 an approach based on process mining and intelligent
redesign
based on the evaluation and analysis presented in the previous section, we now
zoom in onto the two problems mentioned in the introduction. first, we describe
the two problems in more detail. based on this we present our ideas with respect
to using process mining and intelligent redesign. finally, we brie°y discuss the
prom framework as a platform for addressing the two problems.
4.1 linking design and reality
to clarify the two problems mentioned in the introduction and to link our pro-
posal to the evaluation presented in the previous section, we use figure 5.
information
systemoperational
process
modelsevent
logsmodelsrecords
configuressupports/
controls
design
redesignthis is the business
process that is (to
be) supported  by
the bpm system.
the process
definition models
the process
structure, resource
structure, allocation,
etc. and is modeled
by some designer.
problem 2 : the
redesign of processes
is not well supported.
at best there is some
simulation facility to
do what-if analysis.based on the
process definition,
the bpm system is
configured.most information
systems log all events,
e.g., the start and end
of an activity.in this paper, we
assume that the
information system
is based on some
bpm product.
however, our
approach also
applies to other
information systems
supporting
processes.
problem 1 : the actual
execution of the operational
process is completely
disconnected from the
(re)design of the process.
therefore, the bpm life-cycle
is not closed.
fig. 5. two problems not addressed by contemporary bpm systems: (1) event logs are
not used to feed the (re)design of processes and (2) the redesign is at best supported
by \what-if" analysis (e.g., simulation).
figure 5 shows the operational process (e.g., the °ow of patients in a hos-
pital, the handling of insurance claims, the procurement process of a multina-
tional, etc.) that is interacting with some information system (e.g., an erp,
crm, pdm, bpm, or wfm system). clearly the information system and theoperational process exchange information, e.g., the system may support and/or
control the processes at hand. related to the information system and processes
it supports are models and event logs. many systems log events related to the
processes they support (cf. the arrow labeled records in figure 5). the role of
models is more involved. clearly, process models can be used to model the op-
erational process for a variety of reasons. process models can be used to analyze
and optimize processes but can also be used for guidelines, training, discussions,
etc. (cf. the arrow labeled models in figure 5). however, increasingly information
systems are con¯gured on the basis of models (cf. the arrow labeled con¯gures
in figure 5). for example, consider process-aware systems (dumas et al., 2005)
ranging from work°ow and bpm systems such as filenet, sta®ware and cosa
to erp systems like sap r/3 and peoplesoft. models can be prescriptive or
descriptive. if they are used for con¯guration, they tend to be prescriptive. if
they are used for other purposes, they are often descriptive. in the ¯rst part of
the paper, we were focusing on prescriptive models (i.e., the process de¯nition
used by filenet). however, it is important to note that also descriptive models
play an important role when it comes to process support and improvement.
using figure 5 we can further detail the two problems mentioned in sec-
tion 1.2:
{problem 1: as figure 5 shows, the actual execution of the process supported
by the bpm system is completely disconnected from the (re)design of the
process. in bpm systems such as filenet the event logs are not related to
the initial process design. moreover, there is no support to extract knowledge
from these logs to aid the redesign.
{problem 2: redesign activities are typically only supported by a graphical
editor which allows the designer to modify the existing process. this im-
plies that the designer has to come up with ideas for process improvement.
these are not suggested by the system. moreover, at best there is a simple
simulation facility that is completely disconnected from the real operational
process, i.e., no information extracted from the real process is automatically
used in the analysis of di®erent redesign alternatives.
we would like to argue that the only way to address these problems is by linking
design andreality , i.e., as long as information about the real process (event logs)
is not used by the design tool it is not possible to close the bpm life-cycle.
therefore, we propose to use recent results achieved in the domain of process
mining (aalst & weijters, 2004; aalst, dongen, et al., 2003).
4.2 process mining
figure 6 shows that there are three classes of process mining techniques. this
classi¯cation is based on whether there is an a-priori model and, if so, how it is
used.
{discovery : there is no a-priori model, i.e., based on an event log some model
is constructed. for example, using the alpha algorithm (aalst et al., 2004)a process model can be discovered based on low-level events. there exist
many techniques to automatically construct process models (e.g., in terms
of a petri net) based some event log (aalst et al., 2004; agrawal et al.,
1998; cook & wolf, 1998; datta, 1998; weijters & aalst, 2003). recently,
process mining research also started to target the other perspectives (e.g.,
data, resources, time, etc.). for example, the technique described in (aalst,
reijers, & song, 2005) can be used to construct a social network.
{conformance : there is an a-priori model. this model is compared with the
event log and discrepancies between the log and the model are analyzed.
for example, there may be a process model indicating that purchase orders
of more than 1 million euro require two checks. another example is the
checking of the so-called \four-eyes" principle. conformance checking may
be used to detect deviations, to locate and explain these deviations, and
to measure the severity of these deviations. an example is the conformance
checker described in (rozinat & aalst, 2006a) which compares the event log
with some a-priori process model expressed in terms of a petri net.
{extension : there is an a-priori model. this model is extended with a new
aspect or perspective, i.e., the goal is not to check conformance but to enrich
the model. an example is the extension of a process model with performance
data, i.e., some a-priori process model is used to project the bottlenecks
on. another example is the decision miner described in (rozinat & aalst,
2006b) which takes an a-priori process model and analyzes every choice in
the process model. for each choice the event log is consulted to see which
information is typically available the moment the choice is made. then clas-
sical data mining techniques are used to see which data elements in°uence
the choice. as a result, a decision tree is generated for each choice in the
process.
note that the filenet p8 bpm suite does not support any form of process min-
ing. this illustrates the missing link between the various models used in the
context of a bpm system (e.g., process de¯nitions, organizational models, simu-
lation models, etc.) and the real processes as observed by the information system
through its event logs. clearly all three classes of process mining techniques are
valuable in a setting where bpm systems are used. discovery techniques look
at the process under a speci¯c angle and reveal what is really going on. for ex-
ample, by creating a social network one can see how people work together. the
construction of a process model (e.g., a petri net) may be helpful if the process is
not enforced by the information system or if one is collecting information about
a process that is not yet supported by the bpm system (e.g., to generate an
initial design). conformance checking is useful to detect deviations. this infor-
mation can be used to redesign the process where it does not ¯t or to improve
the control of the system to make sure that reality follows the desired process.
finally, model extension based on event logs can be very valuable because it
combines a-priori knowledge with real observations. this can be used to \up-
grade" process models with information relevant for simulation purposes (e.g.,information
systemoperational
process
modelsevent
logsmodels
discoveryrecords
configuressupports/
controls
extensionconformance
three classes of  process mining  techniques
are considered: (1)  discovery , i.e., constructing
a model based on information in the log without
a-priori information, (2)  conformance , i.e.,
comparing some a-priori model with observed
reality, and (3)  extension , i.e., using information
in the log to extend some a-priori model (e.g.,
project performance data).different types of
models are considered
ranging from simple
control-flow models
(petri nets, epcs, etc.),
social networks,
organizational models,
decision trees, and
stochastic models to
complex workflow
definitions and detailed
simulation models.
each event in the event
log can be linked to
both a particular
process instance (case)
and a workflow model
element (task/activity,
subprocess).fig. 6. process mining as a means to link models and event logs.
routing probabilities, service times, inter-arrival times, etc.) or decision support
(e.g., decision analysis).
4.3 intelligent redesign
although process mining is useful by itself, we believe that it is particularly
powerful if it is combined with intelligent redesign . to illustrate this, consider
figure 7 where intelligent redesign is linked to process mining. the goal of in-
telligent redesign is to come up with suggestions for redesigns based on the
evaluation of all kinds of redesign possibilities. the starting point for intelligent
redesign is a set of redesign rules (in the sense of (reijers, 2003)). each rule
speci¯es:
{aprecondition describing under which circumstances the rule is applicable.
for example, a redesign rule intended to make a sequential process more
parallel has as a precondition that there should be a sequence of tasks where
the tasks are potentially executed by di®erent people (otherwise it makes
no sense to put things in parallel). one can think of this precondition as a
kind of pattern matching: potentially suboptimal structures in the process
de¯nition (in the broadest sense, i.e., also interaction with other parties and
organizational structures are considered) are identi¯ed using a repository
of redesign rules. note that the patterns do not have to be of a strictlystructural nature, i.e., they may also refer to performance indicators as work-
in-progress, °ow time, utilization, service levels, etc.
{atransformation describing how the design should be changed. for example,
the redesign rule intended to make a sequential process more parallel should
specify how to transform a sequential process fragment into a parallel one.
the transformation is typically a replacement of the pattern described in
precondition.
{a set of intended e®ects , i.e., the redesign rule aims at improving some aspect
of the process. the di®erent aspects are captured in so-called performance
indicators. the goal of the rule may be to improve the °ow time, to reduce
resource utilization, to improve quality, etc. note that redesign rules often
provide a tradeo®, e.g., parallel processing may lead to a reduction in °ow
time but at the same time increase overhead.
information
systemoperational
process
modelsevent
logsmodels
discovery
log-based
analysisrecords
configuressupports/
controls
design
extension
answers to
questionsmodel&log-
based analysismodel-based
analysisintelligent
redesignconformanceredesignintelligent redesign
uses both the initial
design and the results
of all kinds of analysis
techniques that may
be based on just the
model (e.g.,
simulation), just the
log (e.g., performance
analysis based on
historical data), or
both (e.g., prediction
based on simulation
combined with real/
historical data).
analysis techniques
not using the event
log, e.g., classical
forms of simulation.analysis techniques not
using or constructing
explicit models, e.g.,
simple calculations to
determine the key
performance indicators
of a process.
advanced forms of
analysis combining
model-based analysis
with real data.intelligent redesign
suggests
improvements rather
than just supporting
“what-if” analysis.
redesign
rules
each redesign rule is
specified by: (1) a
precondition, (2) a
transformation, and
(3) intended effects.
fig. 7. intelligent redesign linked to process mining.
as an example consider the knock-out rule de¯ned in (aalst, 2001). the knock-
out rule applies to so-called \knock-out processes". the goal of a knock-out
process is to decide whether the case should be accepted or rejected. to make
this decision, a sequence of tasks needs to be executed. each task has two possible
results: ok or nok (i.e., not ok). if for a speci¯c case (i.e., process instance)a task results in nok, the case is rejected immediately. only if all tasks have a
positive result, the case is accepted. many business processes have parts that can
be viewed as knock-out processes. handling an insurance claim, a request for a
loan, a job application, and the reviewing of paper for publication in a journal
are typical examples of processes with a knock-out structure. many knock-out
processes are characterized by the fact that the degree of freedom with respect
to the order in which tasks can be executed is quite high. most tasks correspond
to checks which can be executed in any order. a task is selective if the reject
probability is high. a task is expensive if the average processing time is high.
clearly, it is wise to start with selective tasks that are not expensive and postpone
the expensive tasks which are not selective as long as possible. this rule of thumb
is captured in the following redesign rule: tasks sharing the same resource class
should be ordered in descending order using the ratio rp(t)=pt(t)to obtain an
optimal process with respect to resource utilization and maximal throughput.3it
is fairly straightforward to de¯ne the knock-out rule in terms of a precondition,
a transformation, and its intended e®ects. the precondition is the presence of a
sequential process fragment consisting of di®erent tests executed by potentially
the di®erent sets of people (preferably di®erent roles, departments, etc.). the
transformation is a reordering of activities based on the ratio rp(t)=pt(t). the
intended e®ects are a reduction of °ow time and a lower resource utilization.
driven by a set of redesign rules, the following procedure is followed to sup-
port intelligent redesign:
{step 1: determine applicable redesign rules. in this ¯rst step the precondi-
tions of all redesign rules are checked in the context of the concrete process
at hand. note that the preconditions may also refer to the process as it is
being executed, i.e., the pattern matching is not limited to the process design
and extends to e.g. the detection of bottle-necks, etc.
{step 2: select applicable redesign rules based on intended e®ects. based on
the opportunities identi¯ed in the ¯rst step a ¯rst selection is made. this
selection is based on the expected e®ects of the application of the rule and
what the perceived problem is. note that the same redesign rule may be
applicable at multiple places in the process. for each possible application
of the rule, a selection decision needs to be made. the selection of applica-
ble redesign rules is an interactive process, i.e., the designer can guide the
selection process.
{step 3: create redesigns. after selecting the applicable redesign rules, di®er-
ent redesigns are created. typically, each selected redesign rule results in a
redesign, i.e., the rules are applied incrementally (cf. step 5). to do this the
transformation part of the redesign rule is used.
{step 4: evaluate redesigns. after applying the redesign rules, each of the
resulting redesigns is evaluated using simulation. using simulation the e®ects
of applying the redesign rule in this particular context are predicted. note
that the performance indicators used to describe the intended e®ects of a
3in this ratio, trefers to a task, rp(t) the rejection probability (i.e., the percentage of
cases for which tresults in a nok), and pt(t) the average processing time of task t.redesign are of particular interest for this step, because now the predicted
e®ect can be measured.
{step 5: select the redesigned processes . for each redesign evaluated through
simulation, two decisions need to be made: (1) will the redesign be used
for further investigation? and/or (2) will the redesign be presented to the
designer? in this step the most promising redesigns are selected. for each
redesign selected for further investigation steps 1-5 are repeated. moreover,
all redesigns selected for presentation are collected as input for step 6.
{step 6: present the selected redesigns and their expected e®ects . in the ¯nal
step the results are presented to the designer. it is the designer that selects
the redesign to be used (if any). moreover, the designer may re¯ne a selected
redesign or restart the procedure with di®erent input.
it is important to note that both in step 1 and in step 4 the event logs play an
important role, i.e., the pattern matching in step 1 may be partially based on
performance indicators derived from the real process (e.g., a redesign rule only
applies if there is some sort of problem) and the simulation in step 4 should be
based on data derived from the actual process (e.g., the arrival patterns of new
cases). this is illustrated by the lower half of figure 7. as shown, intelligent
redesign is driven by the existing process design, the redesign rules, and answers
to various questions. these questions relate to just the models (e.g., the pro-
cess de¯nition or the organizational model), just the event logs (e.g., °ow times,
frequencies, etc.), or both (e.g., the process de¯nition embedded in a real-life
context). figure 7 refers to answering these questions as model-based analysis ,
log-based analysis , and model&log-based analysis . an example of model-based
analysis is the classical form of simulation, i.e., based on some model completely
disconnected from the run-time environment performance indicators are esti-
mated. log-based analysis typically uses simple queries or calculations one some
database with run-time/historic information. this is the area commonly referred
to as data-warehousing, business activity monitoring, or business intelligence.
model&log-based analysis tries to combine some a-priori model with relevant
run-time/historic information, e.g., a simulation model using run-time/historic
information as described in (reijers & aalst, 1999). it should be noted that
model&log-based analysis is closely related to model extension (the third form
of process mining). note that the same information, e.g., inter-arrival times of
cases, may be used to extend the model (¯t some stochastic distribution and add
this to the simulation model) or to directly answer a question without extending
the model (directly feed a log with historic inter-arrival times to the simulation
engine as supported by the filenet simulator).
existing bpm systems provide limited support for the lower half of figure 7.
at best they o®er basic model-based analysis (e.g., simple simulation engine) and
log-based analysis (e.g., basic information on the key performance indicators).
there is typically no support for process mining and model&log-based analysis.
as shown in section 3, leading bpm systems such as the filenet p8 bpm
suite only provide a basic process designer and a process simulator . historic
information on arriving cases can be transferred to the process simulator , butall other data, like processing times and routing probabilities, should be derived
from the execution data and included manually. it is only possible to provide
constant values for the simulation parameters, so the simulation results will only
provide a very rough indication for the performance of a scenario. moreover,
there is no form of intelligent redesign, i.e., it is impossible to use redesign rules
in a systematic way. the user needs to come up with redesigns and and is not
supported in any way.
4.4 the prom framework
the primary goal of this paper is not to provide detailed solutions but to sketch
how process mining and intelligent redesign could be used to close the bpm
life-cycle and to enhance systems like the filenet p8 bpm suite. we have been
developing process mining techniques in the context of the prom framework for
several years now (dongen et al., 2005) and recently started adding functionality
to support intelligent redesign to prom. therefore, we brie°y describe the prom
framework and some of its plug-ins.
starting point for prom are event logs in mxml format. the mxml format
is system-independent and using promimport it is possible to extract logs from
a wide variety of systems, i.e., systems based on products such as sap, people-
soft, sta®ware, flower, websphere, yawl, adept, aris ppm, caramba,
inconcert, oracle bpel, outlook, etc. and tailor-made systems. it is also possi-
ble to load and/or save a variety of models, e.g., epcs (i.e., event-driven process
chains in di®erent formats, e.g., aris, aris ppm, epml, and visio), bpel
(e.g., oracle bpel, websphere), yawl, petri nets (using di®erent formats, e.g.,
pnml, tpn, etc.), cpns (i.e., colored petri nets as supported by cpn tools),
and protos. currently, there are no interfaces with the filenet p8 bpm suite
but it would be fairly easy to make this connection (both at the model level
and the event log level) since it is similar to many of the other systems already
supported.
the prom framework is open-source and plug-able, i.e., people can plug-in
new pieces of functionality. some of the plug-ins are related to model transforma-
tions and various forms of model analysis (e.g., veri¯cation of soundness, analysis
of deadlocks, invariants, reductions, etc.). most of the plug-ins, however, focus
on a particular process mining technique. currently, there are more than 100
plug-ins of which about half are mining and analysis plug-ins. in this paper, we
distinguished three types of process mining techniques: discovery, conformance,
and extension. below we brie°y mention some of the plug-ins present in prom
to support these three types of process mining.
prom supports many discovery algorithms. prom currently o®ers eight plug-
ins for discovering processes. these plug-ins use di®erent \target formats", i.e.,
di®erent languages to represent the result of the discovery algorithm (e.g., petri
nets, epcs, heuristics nets). figure 8 shows four process models obtained us-
ing various plug-ins for control-°ow discovery present in prom. the models are
based on a event log with about 20000 events relating to about 1000 patients.fig. 8. based on an analysis of an event log with data on 1000 patients, various mining
plug-ins are able to discover the underlying process.it is important to note that the process models have been generated automat-
ically without any a-priori information. figure 8(a) shows the result obtained
by applying the ®algorithm (aalst et al., 2004) to the log with the full trans-
actional information, i.e., each activity characterized by three events in the log:
o®er,start, and complete . hence, in the resulting petri-net each activity is rep-
resented by three transitions. figure 8(b) is also generated by the ®algorithm
but now by only considering the complete events. figure 8(c) shows the result
of applying the multi-phase miner. this approach ¯rst builds a model for every
instance and then starts aggregating these instance models. the native format
of the multi-phase miner is the epc language. however, the multi-phase miner
can also display its results as petri nets. in fact, in prom any petri net can
be converted into an epc, yawl model, or heuristics net and vice versa. fig-
ure 8(d) shows a heuristics net discovered by the heuristics miner (weijters &
aalst, 2003). the format is also used by the genetic miner and both are able to
cope with noise. discovery in prom is not limited to the control-°ow perspective.
it is also possible to discover social networks (aalst, reijers, & song, 2005) or
sta® assignment rules. however, a complete overview of all discovery techniques
supported by prom is outside the scope of this paper.
prom also has two plug-ins for conformance: the conformance checker (roz-
inat & aalst, 2006a) and the ltl checker (aalst, beer, & dongen, 2005). both
are able to discover deviations between some model and the real behavior cap-
tured in the event log.
the decision miner described in (rozinat & aalst, 2006b) is an example of
a plug-in that takes a process model without data and extends it with data and
information about decisions. more precisely, it takes an a-priori process model
and analyzes every choice in the process model. for each choice the event log is
consulted to see which information is typically available the moment the choice is
made. then classical data mining techniques are used to see which data elements
in°uence the choice. as a result, a decision tree is generated for each choice in
the process.
in the context of intelligent redesign it is relevant to note that it is possible
to export process models in prom to cpn tools (cpn group, university of
aarhus, denmark, n.d.). the control-°ow, data-°ow, performance and organi-
zational perspectives can be incorporated in a single colored petri net (cpn)
model (jensen, 1996) that can be exported to cpn tools. cpn tools allows for
various types of analysis including state-space analysis and simulation. using the
monitoring facilities of cpn tools it is easy to detect bottlenecks and collect
all kinds of performance indicators. we believe that the combination of auto-
matic discovery of process models using prom and the simulation capabilities of
cpn tools o®ers an innovative way to improve business processes. the initially
discovered process model describes reality better than most hand-crafted simu-
lation models. moreover, if there is an a-priori model it can be veri¯ed whether
reality ¯ts the model (conformance checker) and the model can also be extended
to incorporate historic information (e.g., arrival processes and service times).the simulation models are constructed in such a way that it is easy to explore
various redesigns.
prom is available as open source (under the common public license, cpl)
and can be downloaded from www.processmining.org. it has been applied to
various real-life processes, ranging from administrative processes and health-
care processes to the logs of complex machines and service processes. while the
process mining capabilities of prom are very mature, the support of intelligent
redesign is still in its infancy. currently, we are adding redesign rules to prom
to support intelligent redesign.
5 conclusion
in this paper we focused to supporting the whole bpm life-cycle consisting of
the following phases: (re)design ,con¯guration ,execution ,control , and diagnosis .
the contribution of this paper is twofold.
first of all, we analyzed the limitations of today's bpm systems using the
filenet p8 bpm suite as a representative example. we presented a generic ap-
proach to analyze the capabilities of a bpm product with respect to its support
of the bpm life-cycle. we discovered several problems. it was observed that sys-
tems such as the filenet p8 bpm suite provide limited support for the diagnosis
and (re)design phase and that the integration of the di®erent components in this
part of the bpm life-cycle is problematic (i.e., results obtained in one compo-
nent are not used in other components and users need to rekey and reinterpret
results).
second, based on these observations, we zoomed in onto the problematic
part of the bpm life-cycle and discussed techniques that can alleviate the prob-
lems. we identi¯ed two key problems: (1) the complete disconnect between the
(re)designs and reality as observed by the system through its event logs and (2)
the lack of support when it comes to automatically generating redesigns based
on an analysis of the current situation (i.e., current design and event logs) and
evaluating these results. to address these problems we argued that techniques
for process mining and intelligent redesign are needed to support the (re)design
and diagnosis phases and thus close the bpm life-cycle.
we brie°y presented prom framework and some of its plug-ins. currently,
prom already provides mature support for a wide variety of process mining
techniques (aiming at discovery, conformance, and extension). future work aims
at strengthening the support of intelligent redesign by adding redesign plug-ins
and a repository of redesign rules.
acknowledgements
we would like to thank the consultancy and it support sta® from filenet for
their kind assistance in carrying out this study. we also thank the people in-
volved in the development of the prom framework: ton weijters, boudewijn
van dongen, ana karla alves de medeiros, anne rozinat, christian gä unter,minseok song, laura maruster, eric verbeek, monique jansen-vullers, huub de
beer, ronny mans, peter van den brand, andriy nikolov, irene vanderfeesten,
et al. this research is supported by eit and the technology foundation stw,
applied science division of nwo and the technology program of the dutch min-
istry of economic a®airs.
references
aalst, w. van der (2001). reengineering knock-out processes. decision support
systems ,30(4), 451{468.
aalst, w. van der, beer, h., & dongen, b. van (2005). process mining and
veri¯cation of properties: an approach based on temporal logic. in
r. meersman & z. t. et al. (eds.), on the move to meaningful internet
systems 2005: coopis, doa, and odbase: otm confederated inter-
national conferences, coopis, doa, and odbase 2005 (vol. 3760, pp.
130{147). springer-verlag, berlin.
aalst, w. van der, dongen, b. van, herbst, j., maruster, l., schimm, g., &
weijters, a. (2003). work°ow mining: a survey of issues and approaches.
data and knowledge engineering ,47(2), 237{267.
aalst, w. van der, & hee, k. van (2004a). work°ow management: models,
methods, and systems . mit press, cambridge, ma.
aalst, w. van der, hofstede, a. ter, kiepuszewski, b., & barros, a. (2003).
work°ow patterns. distributed and parallel databases ,14(1), 5{51.
aalst, w. van der, hofstede, a. ter, & weske, m. (2003). business process
management: a survey. in w. aalst, a. hofstede, & m. weske (eds.),
international conference on business process management (bpm 2003)
(vol. 2678, pp. 1{12). springer-verlag, berlin.
aalst, w. van der, reijers, h., & song, m. (2005). discovering social networks
from event logs. computer supported cooperative work ,14(6), 549{593.
aalst, w. van der, & weijters, a. (eds.). (2004). process mining. elsevier
science publishers, amsterdam.
aalst, w. van der, weijters, a., & maruster, l. (2004). work°ow mining: discov-
ering process models from event logs. ieee transactions on knowledge
and data engineering ,16(9), 1128{1142.
agrawal, r., gunopulos, d., & leymann, f. (1998). mining process models from
work°ow logs. in sixth international conference on extending database
technology (pp. 469{483).
bernstein, a., klein, m., & malone, t. (1999). the process recombinator: a
tool for generating new business process ideas. in icis(p. 178-192).
buzacott, j. (1996). commonalities in reengineerd business processes: models
and issues. management science ,42(5), 768{782.
cook, j., & wolf, a. (1998). discovering models of software processes
from event-based data. acm transactions on software engineering and
methodology ,7(3), 215{249.cpn group, university of aarhus, denmark. (n.d.). cpn tools home page.
(http://wiki.daimi.au.dk/cpntools/)
datta, a. (1998). automating the discovery of as-is business process models:
probabilistic and algorithmic approaches. information systems research ,
9(3), 275{301.
dongen, b. van, medeiros, a., verbeek, h., weijters, a., & aalst, w. van der
(2005). the prom framework: a new era in process mining tool support.
in g. ciardo & p. darondeau (eds.), application and theory of petri nets
2005 (vol. 3536, pp. 444{454). springer-verlag, berlin.
dumas, m., aalst, w. van der, & hofstede, a. ter (2005). process-aware infor-
mation systems: bridging people and software through process technology .
wiley & sons.
eder, j., panagos, e., pezewaunig, h., & rabinovich, m. (1999). time man-
agement in work°ow systems. in w. abramowicz & m. orlowska (eds.),
third international conference on business information systems (bis'99)
(pp. 265{280). poznan, polen: springer-verlag, berlin.
eder, j., panagos, e., & rabinovich, m. (1999). time constraints in work-
°ow systems. in m. jarke & a. oberweis (eds.), proceedings of the 11th
international conference on advanced information systems engineering
(caise '99) (vol. 1626, pp. 286{300). springer-verlag, berlin.
ellis, c. (1979). information control nets: a mathematical model of o±ce
information flow. in proceedings of the conference on simulation, mea-
surement and modeling of computer systems (pp. 225{240). boulder,
colorado: acm press.
gartner. (2003). gartner's magic quadrant for pure-play bpm.
(http://www.gartner.com)
gartner. (2004). gartner's magic quadrant for pure-play bpm.
(http://www.gartner.com)
gartner. (2005). gartner's magic quadrant for pure-play bpm.
(http://www.gartner.com)
georgakopoulos, d., hornick, m., & sheth, a. (1995). an overview of work°ow
management: from process modeling to work°ow automation infrastruc-
ture. distributed and parallel databases ,3, 119{153.
grigori, d., casati, f., castellanos, m., dayal, u., sayal, m., & shan, m. (2004).
business process intelligence. computers in industry ,53(3), 321{343.
grigori, d., casati, f., dayal, u., & shan, m. (2001). improving business pro-
cess quality through exception understanding, prediction, and preven-
tion. in p. apers, p. atzeni, s. ceri, s. paraboschi, k. ramamohanarao,
& r. snodgrass (eds.), proceedings of 27th international conference on
very large data bases (vldb'01) (pp. 159{168). morgan kaufmann.
ids scheer. (2002). aris process performance manager (aris ppm): mea-
sure, analyze and optimize your business process performance (whitepa-
per). (ids scheer, saarbruecken, gemany, http://www.ids-scheer.com)
jablonski, s., & bussler, c. (1996). work°ow management: modeling con-
cepts, architecture, and implementation . international thomson com-puter press, london, uk.
jansen-vullers, m., & reijers, h. (2005). business process redesign at a mental
healthcare institute: a coloured petri net approach. in k. jensen (ed.),
proceedings of the sixth workshop on the practical use of coloured petri
nets and cpn tools (cpn 2005) (vol. 576, pp. 21{38). aarhus, denmark:
university of aarhus.
jensen, k. (1996). coloured petri nets. basic concepts, analysis methods and
practical use . springer-verlag, berlin.
lawrence, p. (ed.). (1997). work°ow handbook 1997, work°ow management
coalition . john wiley and sons, new york.
leymann, f., & roller, d. (1999). production work°ow: concepts and tech-
niques . prentice-hall ptr, upper saddle river, new jersey, usa.
marinescu, d. (2002). internet-based work°ow management: towards a se-
mantic web (vol. 40). wiley-interscience, new york.
mä uhlen, m. (2004). work°ow-based process controlling: foundation, design
and application of work°ow-driven process information systems . logos,
berlin.
mä uhlen, m., & rosemann, m. (2000). work°ow-based process monitoring and
controlling - technical and organizational issues. in r. sprague (ed.),
proceedings of the 33rd hawaii international conference on system science
(hicss-33) (pp. 1{10). ieee computer society press, los alamitos,
california.
netjes, m., aalst, w. van der, & reijers, h. (2005, october). analysis of
resource-constrained processes with colored petri nets. in k. jensen
(ed.), proceedings of the sixth workshop on the practical use of coloured
petri nets and cpn tools (cpn 2005) (vol. 576, pp. 251{266). aarhus,
denmark: university of aarhus.
netjes, m., reijers, h., & aalst, w. van der (2006a). filenet's bpm life-cycle
support. bpm center report bpm-06-07. bpmcenter.org.
netjes, m., reijers, h., & aalst, w. van der (2006b). supporting the bpm
lifecycle with filenet. in t. latour & m. petit (eds.), proceedings of the
emmsad workshop at the 18th international conference on advanced
information systems engineering (caise'06) (pp. 497{508). namur uni-
versity press.
netjes, m., vanderfeesten, i., & reijers, h. (2006). \intelligent" tools for
work°ow process redesign: a research agenda. in c. bussler & a. haller
(eds.), business process management workshops (bpm 2005) (vol. 3812,
pp. 444{453). springer-verlag, berlin.
nissen, m. (1998). redesigning reengineering through measurement-driven
inference. mis quarterly ,22(4), 509{534.
panagos, e., & rabinovich, m. (1997). escalations in work°ow management
systems. in proceedings of the workshop on databases: active and real time
(dart-96) (pp. 25{28). acm press.
panagos, e., & rabinovich, m. (1998). reducing escalation-related costs in
wfmss. in work°ow management systems and interoperability (pp. 107{127). springer-verlag, berlin.
reijers, h. (2003). design and control of work°ow processes: business process
management for the service industry (vol. 2617). springer-verlag, berlin.
reijers, h., & aalst, w. van der (1999). short-term simulation: bridging
the gap between operational control and strategic decision making. in
m. hamza (ed.), proceedings of the iasted international conference on mod-
elling and simulation (pp. 417{421). iasted/acta press, anaheim, usa.
rozinat, a., & aalst, w. van der (2006a). conformance testing: measuring the
fit and appropriateness of event logs and process models. in c. bus-
sler et al. (ed.), bpm 2005 workshops (workshop on business process
intelligence) (vol. 3812, pp. 163{176). springer-verlag, berlin.
rozinat, a., & aalst, w. van der (2006b). decision mining in prom. in s. dust-
dar, j. faideiro, & a. sheth (eds.), international conference on business
process management (bpm 2006) (vol. 4102, pp. 420{425). springer-
verlag, berlin.
sayal, m., casati, f., dayal, u., & shan, m. (2002). business process cockpit.
inproceedings of 28th international conference on very large data bases
(vldb'02) (pp. 880{883). morgan kaufmann.
sta®ware. (2003). sta®ware process suite version 2 { white paper. maiden-
head, uk.
tibco. (2005). tibco sta®ware process monitor (spm).
(http://www.tibco.com)
verbeek, h., basten, t., & aalst, w. van der (2001). diagnosing work°ow
processes using wo°an. the computer journal ,44(4), 246{279.
weijters, a., & aalst, w. van der (2003). rediscovering work°ow models
from event-based data using little thumb. integrated computer-aided
engineering ,10(2), 151{162.
zhao, j., & stohr, e. (1999). temporal work°ow management in a claim
handling system. in proceedings of the international joint conference on
work activities coordination and collaboration (wacc'99) (p. 187-195).
acm.