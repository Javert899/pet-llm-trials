complexity metrics for workow nets
kristian bisgaard lassena,, wil m.p. van der aalstb
adepartment of computer science, university of aarhus, it-parken, aabogade 34,
dk-8200 aarhus n, denmark.
beindhoven university of technology, p.o. box 513, nl-5600 mb, eindhoven, the
netherlands
abstract
process modeling languages such as epcs, bpmn, ow charts, uml activity
diagrams, petri nets, etc. are used to model business processes and to congure
process-aware information systems. it is known that users have problems un-
derstanding these diagrams. in fact, even process engineers and system analysts
have diculties grasping the dynamics implied by a process model. recent em-
pirical studies show that people make numerous errors when modeling complex
business processes, e.g., about 20 percent of the epcs in the sap reference
model have design aws resulting in potential deadlocks, livelocks, etc. [29]. it
seems obvious that the complexity of the model contributes to design errors and
a lack of understanding. it is not easy to measure complexity, however. this
paper presents three complexity metrics that have been implemented in the
process analysis tool prom. the metrics are dened for a subclass of petri nets
named workow nets, but the results can easily be applied to other languages.
to demonstrate the applicability of these metrics, we have applied our approach
and tool to 262 relatively complex protos models made in the context of various
student projects. this allows us to validate and compare the dierent metrics.
it turns out that our new metric focusing on the structuredness outperforms
existing metrics.
key words: metrics, petri nets, understandability
1. introduction
no silver bullet exists for building readable process models no matter what
process language is used. often the complexity of a process model is a true
reection of the nature of the problem that needs to be solved. however, the
model may also be unnecessarily complex. for example, the same behavior
can be represented in dierent ways. therefore, it is important to stimulate
designers to keep their models as simple as possible. moreover, if the model is
corresponding author
preprint submitted to elsevier august 5, 2008too complex to be understood by end users, then one may choose to decompose
or split the model.
overly complex models cause all kinds of problems. if end-users cannot
check the models, this may lead to the implementation of systems that do not
adequately support them. moreover, complex models also lead to all kinds of
design aws. a nice illustration is the empirical work presented in [27, 29, 28].
using a collection of 2003 event-driven process chain (epc) [1, 33] models it
is shown that at least 10 percent of these models are awed [27, 29]. 604 of
these 2003 models originate from the well-known sap reference model [20]. in
[28] it was shown that with a rather basic petri-net-based analysis technique
(invariants) already 5.6 percent of these models can be proven to be incorrect
(deadlocks, livelocks, dead activities, etc.). using a more rened technique it
was shown that more than 20 percent of the epcs in the reference model have
errors such as deadlocks, livelocks, etc. [29]. moreover, as shown in [27, 28], it
is possible to adequately predict errors based on the complexity. therefore, we
think it is safe to assume that the complexity of the model directly impacts the
readability and quality of the model. therefore, this paper focuses on measuring
the complexity of process models .
in this paper, we dene three metrics. the rst two metrics are extensions
of existing metrics and the third metric is new. all metrics are dened on a
subclass of petri nets named workflow nets (wf-nets) [2, 3, 4]. wf-nets are
an abstraction of real-life workow languages suitable for analysis. however, as
we will demonstrate, the results are also directly applicable to other languages
such as epcs, bpmn diagrams, ow charts, and uml activity diagrams.
the rst metric extends the metric dened by cardoso [13] and is purely
based on the presence of certain splits and joins in the syntactical process de-
nition. the second metric extends the so-called cyclomatic metric of mccabe
[26]. this metric is based on the state-space. the third metric is a new metric
that better tries to capture the complexity of the model as it is perceived by hu-
mans . it iteratively analyzes the structure of the model and assigns penalties
to undesirable constructs from a complexity point of view.
the three complexity metrics are dened dierently and are good repre-
sentatives of the various types of complexity metrics found in the literature.
they each try to measure how dicult a process denition is to understand and
communicate to others. the scores of the dierent metrics cannot be compared
directly, but by looking at how dierent processes score with respect to the same
metric, it is possible to see if one process is more complicated than the other.
all three metrics have been implemented in the prom framework [7]. since
prom supports the mapping of dierent types of models onto wf-nets, we can
apply our results to a wide range of models. to validate our approach and to
compare the dierent metrics, we have applied our approach and tool to 262
relatively complex protos models. these protos models have been translated to
wf-nets and analyzed using prom. this case study shows that the new metric
based on structuredness provides a major improvement over existing metrics.
the paper is structured as follows. in section 2 we familiarize the reader
with petri nets and other basic concepts used in this paper. section 3 presents
2the three metrics. a short introduction to the implementation of the metrics is
given in section 4. section 5 describes a case study where the three metrics are
compared and there dierences are discussed. section 6 presents related work
and section 7 concludes the paper.
2. preliminaries
in this section we would like to familiarize the reader with some key concepts
that are important for the understanding of the remainder of this paper.
2.1. petri nets
this section introduces the basic petri net terminology and notations. read-
ers familiar with petri nets can skip this section.
the classical petri net is a directed bipartite graph with two node types
called places and transitions . the nodes are connected via directed arcs. con-
nections between two nodes of the same type are not allowed. places are repre-
sented by circles and transitions by rectangles.
denition 1 (petri net). apetri net is a triple ( p;t;f ):
-pis a nite set of places ,
-tis a nite set of transitions (p\t=;),
-f(pt)[(tp) is a set of arcs (ow relation)
note that we do not consider multiple arcs from one node to another. in the
context of workow procedures it makes no sense to have other weights, because
places correspond to conditions.
elements of p[tare called nodes . a nodexis an input node of another
nodeyi there is a directed arc from xtoy(i.e., (x;y)2f). nodexis an
output node ofyi (y;x)2f. for anyx2p[t,nx=fyj(y;x)2fg
andxn=fyj(x;y)2fg; the superscript nmay be omitted if clear from the
context.
the projection and union of a petri net are dened as follows.
denition 2 (projection and union). letpn= (p;t;f ) and pn0= (p0;t0;f0)
be petri nets and xp[ta set of nodes. pnjx= (p\x;t\x;f\(xx))
is the projection of pnontox.pn[pn0= (p[p0;t[t0;f[f0) is the
union of pnand pn0.
at any time a place contains zero or more tokens , drawn as black dots. the
state, often referred to as marking , is the distribution of tokens over places, i.e.,
m2p!i n. we will represent a state as follows: 1 p1+ 2p2+ 1p3+ 0p4is the
state with one token in place p1, two tokens in p2, one token in p3and no tokens
inp4. we can also represent this state as follows: p1+ 2p2+p3. to compare
states we dene a partial ordering. for any two states m1andm2,m1m2
i for allp2p:m1(p)m2(p).
3the number of tokens may change during the execution of the net. transi-
tions are the active components in a petri net: they change the state of the net
according to the following ring rule :
(1) a transition tis said to be enabled i each input place poftcontains at
least one token.
(2) an enabled transition may re. if transition tres, thentconsumes one
token from each input place poftandproduces one token for each output
placepoft.
given a petri net ( p;t;f ) and a state m1, we have the following notations:
-m1t!m2: transition tis enabled in state m1and ringtinm1results
in statem2
-m1!m2: there is a transition tsuch thatm1t!m2
-m1!mn: the ring sequence =t1t2t3:::tn 1leads from state m1to
statemnvia a (possibly empty) set of intermediate states m2;:::mn 1,
i.e.,m1t1!m2t2!:::tn 1!mn
a statemnis called reachable fromm1(notationm1!mn) i there is a ring
sequenceso thatm1!mn. note that the empty ring sequence is also
allowed, i.e., m1!m1.
we use ( pn;m) to denote a petri net pnwith an initial state m. a state
m0is areachable state of (pn;m) im!m0.
let us dene some standard properties for petri nets. first, we dene prop-
erties related to the dynamics of a petri net, then we give some structural
properties.
denition 3 (live). a petri net ( pn;m) islivei, for every reachable state
m0and every transition t2t, there is a state m00reachable from m0which
enablest.
a petri net is structurally live if there exists an initial state such that the net is
live.
denition 4 (bounded, safe). a petri net ( pn;m) isbounded i for each
placep2pthere is a natural number nso that for every reachable state the
number of tokens in pis less than n. the net is safe i for each place the
maximum number of tokens does not exceed 1.
a petri net is structurally bounded if the net is bounded for any initial state.
forpn= (p;t;f ) we also dene some standard structural properties.
denition 5 (strongly connected). a petri net is strongly connected i, for
every pair of nodes (i.e., places and transitions) xandy, there is a path leading
fromxtoy.
4denition 6 (free-choice). a petri net is a free-choice petri net i, for every
two transitions t12tandt22t,t1\t26=;impliest1=t2.
denition 7 (state machine). a petri net is state machine i each transi-
tion has at most one input place and at most one output place, i.e., for all t2t:
jtj1 andjtj 1.
denition 8 (marked graph). a petri net is marked graph i each place
has at most one input transition and at most one output transition, i.e., for all
p2p:jpj1 andjpj 1.
see [16, 35] for a more elaborate introduction to these standard notions.
2.2. wf-nets
a petri net which models the control-ow dimension of a workow, is called a
workflow net (wf-net, [2]). in wf-net the transitions correspond to activities.
some of the transitions represent \real activities" while others are added for
routing purposes (i.e., similar to the structured activities in bpel). places
correspond to pre- and post-conditions of these activities. it should be noted
that a wf-net species the dynamic behavior of a single case (i.e., process
instance in bpel terms) in isolation.
denition 9 (wf-net). a petri net pn= (p;t;f ) is a wf-net (workow
net) if and only if:
(i) there is one source place i2psuch thati=;.
(ii) there is one sink place o2psuch thato=;.
(iii) every node x2p[tis on a path from itoo.
a wf-net has one input place ( i) and one output place ( o) because any case
handled by the procedure represented by the wf-net is created when it enters
the wfm system and is deleted once it is completely handled by the system,
i.e., the wf-net species the life-cycle of a case. the third requirement in
denition 9 has been added to avoid \dangling activities and/or conditions",
i.e., activities and conditions which do not contribute to the processing of cases.
given the denition of a wf-net it is easy to derive the following properties
[4].
proposition 1 (properties of wf-nets). let pn = (p;t;f )be petri net.
if pn is a wf-net with source place i, then for any place p2p:p6=;
orp=i, i.e.,iis the only source place.
if pn is a wf-net with sink place o, then for any place p2p:p6=;or
p=o, i.e.,ois the only sink place.
5if pn is a wf-net and we add a transition tto pn which connects
sink placeowith source place i(i.e.,t=fogandt=fig), then the
resulting petri net is strongly connected.
if pn has a source place iand a sink place oand adding a transition t
which connects sink place owith source place iyields a strongly connected
net, then every node x2p[tis on a path from itooin pn and pn is
a wf-net.
2.3. soundness
in this section we summarize some of the basic results for wf-nets presented
in [2, 3, 4].
the three requirements stated in denition 9 can be veried statically, i.e.,
they only relate to the structure of the petri net. however, there is another
requirement which should be satised:
for any case, the procedure will terminate eventually and the mo-
ment the procedure terminates there is a token in place o and all the
other places are empty.
moreover, there should be no dead activities, i.e., it should be possible to execute
an arbitrary transition by following the appropriate route through the wf-
net. these two additional requirements correspond to the so-called soundness
property [3].
denition 10 (sound). a procedure modeled by a wf-net pn= (p;t;f )
is sound if and only if:
(i) for every state mreachable from state i, there exists a ring sequence
leading from state mto stateo. formally:1
8m(i!m))(m!o)
(ii) stateois the only state reachable from state iwith at least one token in
placeo. formally:
8m(i!m^mo))(m=o)
(iii) there are no dead transitions in ( pn;i). formally:
8t2t9m;m0i!mt!m0
1note that there is an overloading of notation: the symbol iis used to denote both the
place i and the state with only one token in place i(see section 2.1).
6note that the soundness property relates to the dynamics of a wf-net. the
rst requirement in denition 10 states that starting from the initial state (state
i), it is always possible to reach the state with one token in place o(state o).
if we assume a strong notion of fairness, then the rst requirement implies
that eventually state ois reached. strong fairness means that in every innite
ring sequence, each transition res innitely often. the fairness assumption is
reasonable in the context of wfm: all choices are made (implicitly or explicitly)
by applications, humans or external actors. clearly, they should not introduce
an innite loop. note that the traditional notions of fairness (i.e., weaker forms
of fairness with just local conditions, e.g., if a transition is enabled innitely
often, it will re eventually) are not sucient. see [3, 23] for more details. the
second requirement states that the moment a token is put in place o, all the
other places should be empty. the last requirement states that there are no
dead transitions (activities) in the initial state i.
given a wf-net pn= (p;t;f ), we want to decide whether pnis sound.
in [2] we have shown that soundness corresponds to liveness and boundedness.
to link soundness to liveness and boundedness, we dene an extended net pn=
(p;t;f).pnis the petri net obtained by adding an extra transition twhich
connectsoandi. the extended petri net pn= (p;t;f) is dened as follows:
p=p,t=t[ftg, andf=f[f(o;t);(t;i)g. in the remainder we will
call such an extended net the short-circuited net of pn. the short-circuited net
allows for the formulation of the following theorem.
theorem 1. a wf-net pn is sound if and only if (pn;i)is live and bounded.
proof. see [2]. 
this theorem shows that standard petri-net-based analysis techniques can be
used to verify soundness.
sometimes we require a wf-net to be safe, i.e., no marking reachable from
(pn;i) marks a place twice (cf. denition 4). although safeness is dened with
respect to some initial marking, we extend it to wf-nets and simply state that
a wf-net is safe or not.
in literature there exist many variants of the \classical" notion of soundness
used here. juliane dehnert uses the notion of relaxed soundness where proper
termination is possible but not guaranteed [15, 17]. the main idea is that the
scheduler of the workow system should avoid problems like deadlocks etc. in
[24] ekkart kindler et al. dene variants of soundness tailored towards interor-
ganizational workows. kees van hee et al. [19] dene a notion of soundness
where multiple tokens in the source place are considered. a wf-net is k-sound
if it \behaves well" when there are ktokens in place i, i.e., no deadlocks and
in the end there are ktokens in place o. robert van der toorn uses the same
concept in [36]. in [12, 6] stronger notions of soundness are used and places
have to be safe. another notion of soundness is used in [21, 22] where there
is not a single sink place but potentially multiple sink transitions. see [36]
for the relation between these variants of the same concept. other references
7using (variants of) the soundness property include [18, 25]. for simplicity we
restrict ourselves to the classical notion of soundness described in denition 10.
however, the reader is referred to [8] for a denition of the various soundness
notions, their relations, and their decidability.
3. three complexity metrics
in this section we will introduce three metrics for determining the readability
of a wf-net. the rst two metrics are extensions of existing metrics while the
third one is a completely new metric. the new metric attempts to capture the
real complexity as perceived by the modeler or user. the two extensions are
triggered by the translation of the original metrics to wf-nets. the remainder
of this section is structured as follows. first of all, we will introduce a version
of the cardoso metric [13], extended to wf-nets (section 3.1). second, we
introduce an extended version of the cyclomatic complexity metric [26] known
from procedural programming (section 3.2). third, we present our new metric
for wf-nets. finally, we compare the three metrics using an example wf-net.
3.1. extended cardoso metric
before we introduce the extended cardoso metric let us rst introduce the
classic cardoso metric. to do this it is necessary to dene the type of process
that cardoso considers, and we do this in denition 11.
denition 11 (cardoso process). we say that p= (n;f;j;s ) is a cardoso
process where
nis a set of nodes.
fnnis a ow relation from between nodes.
j:fn2njn6=;g!f xor;or;andgis the join function.
s:fn2njn6=;g!f xor;or;andgis the split function.
using the above denition we can dene the so-called \cardoso metric" [13].
denition 12 (cardoso metric). letp= (n;f;j;s ) be a cardoso pro-
cess. cfc xor,cfc or, and cfc and are three auxiliary functions of type
dom(s)!ndened as follows. for n2dom(s):
cfc xor(n) =jnj,
cfc or(n) = 2jnj 1,
cfc and(n) = 1.
8using these auxiliary functions the cardoso metric is dened as
cfc (p) =p
n2dom(s):s(n)=xorcfc xor(n)
+p
n2dom(s):s(n)=orcfc or(n)
+p
n2dom(s):s(n)=and cfc and(n)
as denition 12 shows, the metric counts the various splits (xor, or, and
and) in the net and give each of them a certain penalty. the rationale for
each split, is to give a penalty depending on how many dierent substates it
induces when executed. xor-split n2nwill go to exactly one of the states
inn, therefore the penalty is jnj; or-splitn2nmay go to any subset of
the succeeding states in nwith the exception of the empty set, so the penalty
here isjp(n)n;j= 2jnj 1; and nally, and-split n2nalways goes to all
subsequent nodes in n(i.e., one state), so nis given the penalty 1.
the cardoso metric is applicable for languages with xor-, or-, and and-
splits. petri nets have only two types of nodes: places and transition. however,
using places and transition it is possible to model xor-, or-, and and-splits.
in fact, using non-free choice nets even more complex choices are possible.
therefore, we have dened a petri net version of the metric that generalizes
and improves the original metric.
denition 13 (extended cardoso metric). letpn= (p;t;f ) be a wf-
net. ecfc p:p!nis an auxiliary function. for any p2p:
ecfc p(p) =jftjt2pgj.
we dene the extended cardoso metric (ecam) for petri net as
ecam (pn) =x
p2pecfc p(p)
as for the cardoso metric, the ecam metric penalizes each state by how
many direct successor states it induces. ecfcpin denition 13 says that the
penalty for a place p is the number of subsets of places reachable from a place
p. this may not be completely obvious why this is a petri net version of the
cardoso metric, so let us look a some examples of xor-, or-, and and-splits
in a free choice petri net in figure 1.
in figure 1(a) we see an xor-split. corresponding to denition 13 it has
value ecam (pnxor) =p
p2fpi;p1;p2;p3gecfc p=ecfc p(pi)+ecfc p(p1)+
ecfc p(p2)+ecfc p(p3) =jffp1g;fp2g;fp3ggj+j;j+j;j+j;j= 3+0+0+0 = 3.2
note that ecam (pnxor) yields the same as the cardoso metric for a xor-
split n with three succeeding states. likewise we can compute for figure 1(b)
ecam (pnor) =jffp1g;fp2g;fp3g;fp1;p2g;fp1;p3g;fp2;p3g;fp1;p2;p3ggj=
2note that the three petri nets in figure 1 are not wf-nets while the denition of ecam
is intended for wf-nets. one can see these nets as fragments of some larger wf-net and the
metric does not depend on this requirement.
9i
123
123(a)pnxor: xor-split.
i
2343
125
167 (b)pnor: or-split.
i 1
123 (c)pnand: and-split.
figure 1: splits in three dierent petri nets: pnxor,pnor, and pnand.
7, the same as the cardoso metric gives, i.e., 23 1 = 7, and for figure 1(c)
ecam (pnand) =jffp1;p2;p3ggj= 1, again the same as for the cardoso met-
ric.
the examples show that in many situations the cardoso metric and our
extended version coincide. only for non-free choice petri nets there are true
dierences, because this situation is not covered by the original metric, but it is
obvious that our extended version is dened in the same spirit as the cardoso
metric.
the ecam metric uses a local/syntactical view of process complexity. the
metric only looks at the successor nodes for each place. this means that other
behavioral issues resulting from combinations of constructs are not taken into
account.
if we assume that there are nplaces in a net and that there is a number k
bounding the number of successor places for each place, we then know that the
ecam will score between n 1 and (n 1)(2k 1). note that the output place
has no output arcs while all the others have between 1 and koutput arcs. this
explains the bounds. the time complexity of the ecam metric is linear in the
number of nodes in the wf-net (assuming some upperbound k), oro(jp[tj),
and is therefore very ecient.
3.2. extended cyclomatic metric
the cyclomatic metric of mccabe [26] is a very well known metric for mea-
suring the control-ow graph of a procedure of a program. it is dened in
10denition 14.
denition 14 (cyclomatic metric). let g = (v,e) be a control-ow graph.
the cyclomatic metric cm is dened as
cm(g) =jej jvj+p
where p is the number of connected components.
only wf-nets that are state-machine nets behave as a control-ow graph,
because the control-ow graph does not allow for concurrency. therefore, the
cyclomatic metric needs to be extended to address this.
the cyclomatic metric was intended to reveal complicated pieces of imper-
ative code by measuring the control-ow graph of that code. mccabe did not
consider the actual code, only its behavior, and in the same sense we can extend
the cyclomatic metric to wf-nets by not measuring the actual wf-net struc-
ture, but its reachability graph instead. in denition 15 we dene this extended
cyclomatic metric (ecym) for wf-nets.
denition 15 (extended cyclomatic metric). letpn= (p;t;f ) be a
wf-net with source place i.g= (v;e) is the corresponding reachability graph
ofpn, i.e.,v=fmji!mgande=f(m1;m2)2vvjm1!m2g. the
extended cyclomatic metric (ecym) is dened as follows:
ecym (pn) =jej jvj+p
where p is the number of strongly connected components in g.
note that typically we only consider sound wf-nets. for such nets the state
space is nite and the metric can be computed.
the ecym metric clearly attempts to measure one aspect of what we are
interested in: how complicated is the behavior that my model exhibit? it does
so by considering which states can the process be in and what transitions may
occur. as we will see later in section 3.4, having a small reachability graph
and small ecym, does not necessarily mean that the wf-net in itself is simple.
it may be that the wf-net is extremely complicated with various restrictions,
but that the reachability graph is small because its size is reduced by the many
restrictions.
to nd the time complexity of the ecym we need to consider two things.
the time complexity of generating the reachability graph of the wf-net and
calculating the strongly connected components of the graph. typically we only
consider wf-nets that are safe and sound. the time complexity of generating
the reachability graph for such a wf-net pn= (p;t;f ) iso(2jpj). the time
complexity for nding the strongly connected components of the reachability
graphg= (v;e) iso(jvj+jej) if the graph is represented as an adjacency
list [14]. if we assume that the wf-net is safe we know that the maximal size
of the reachability graph will be jvj= 2jpj 1 (all permutations of empty and
11non-empty places, without the case of all empty places), and jej=jvj(jvj 1)
(the reachability graph is strongly connected, with the exception that it is not
possible to leave the state v2vwhere a token is on the sink place and all
other places are empty). this means that the time complexity of the ecym
iso(2jpj+jvj+jej) =o(2jpj+jvj+jvj(jvj 1)) =o(2jpj+jvj2) =
o(2jpj+ (2jpj 1)2) =o(4jpj).
although the time complexity of the ecym might discourage its use, it is,
however, in practice useful since most real-world safe and sound wf-nets have
a reachability graph much smaller than 2jpj 1 nodes. we will demonstrate
this using the case study in section 5.
3.3. structuredness metric
in this section, we propose a new complexity metric. this metric is triggered
by problems related to the existing metrics such as the cardoso metric and
the cyclomatic metric. metrics such as the cardoso metric only focus on the
syntax of the model and ignore the complexity of the behavior. the and-split is
considered to be more simple than the xor-split while the number of possible
states in a concurrent net may be exponential in the number of tasks. this
could be addressed by giving the and-split a higher penalty. however, this
would not solve the problem since the complexity of the behavior results from
the interaction between dierent modeling components. metrics such as the
cyclomatic metric only focus on the resulting behavior and ignore the complexity
of the model itself. there may be two dierent models that have the same state
space where one model is compact and simple while the other one is large
and dicult. the addition of an implicit place (i.e., a place that does not
aect the behavior) may make the net more complex because it becomes bigger.
however, in some cases, such a place can also make the net simpler because of
symmetry reasons. variants of the cardoso metric and cyclomatic metric have
two problems in common: they focus on a single aspect (behavior versus syntax)
and they do not consider the interaction between the dierent elements. a net
consisting of just and-splits and and-joins or just xor-splits and xor-joins
is typically much simpler than a net with all kinds of mixtures of choice and
concurrency. this also applies to parts of the process model, e.g., one long
sequence is much easier to understand than a sequence interrupted by splits
and joins. moreover, certain types of patterns are more tricky than others, e.g.,
constructs involving arbitrary loops, milestones, and synchronizing merges [10]
are perceived as complex.
the idea behind this metric stems from the observation that wf-nets are
often structured in terms of design patterns . parts of the process model may
implement basic patterns such as sequence, choice, iteration, etc. or more ad-
vanced control-ow patterns [10]. these have a varying degree of how well
they are understood and communicated by people. to capture this insight we
have made a metric that recognizes dierent kinds of structures and scores each
structure by giving it some \penalty" value. the sum of these values is used to
dene our structuredness metric (sm).
12to dene this metric, we need to introduce some notations. in denition 16
we dene the notion of a component, which is basically a wf-net with the
exception that the source and/or sink may be transitions.
the idea is that a component corresponds to a behavioral pattern. in our
approach we try to identify atomic patterns. then iteratively these atomic
patterns are replaced by new transitions. this means that the wf-net is reduced
in several steps by identifying and removing patterns. each time a component
is removed the weight, or cost, of this component is calculated and associated
with the new transition that the component is replaced by. the algorithm for
calculating sm is nished when the wf-net is reduced to a trivial wf-net with
just one transition. the complexity score of sm is then weight associated with
the single transition.
denition 16 (component). letpn= (p;t;f ) be a wf-net. cis a com-
ponent of pnif and only if
(i)cp[t,
(ii) there exists dierent source and sink nodes ic;oc2csuch that
-(cnficg)cnfocg,
- (cnfocg)cnficg, and
- (oc;ic)62f.
the denition of a component will be used to iteratively identify patterns. to
dene the dierent patterns (component types), we need the following notations.
denition 17 (component notations). letpn= (p;t;f ) be a wf-net
and letcbe a component of pnwith source icand sinkoc. we introduce the
following notations and terminology:
cis a pp-component if ic2pandoc2p,
cis a tt-component if ic2tandoc2t,
cis a pt-component if ic2pandoc2t,
cis a tp-component if ic2tandoc2p,
c=cnfic;ocg,
pnjjc=
{pnjcific2pandoc2p,
{pnjc[(fp(i;c)g;ficg;f(p(i;c);ic)g)[(fp(o;c)g;focg;f(oc;p(o;c))g)
ific2tandoc2t,3
3note that p(i;c)arep(o;c)are the (fresh) identiers of the places added to make a
transition bordered component place bordered.
13{pnjc[(fp(o;c)g;focg;f(oc;p(o;c))g) ific2pandoc2t,
{pnjc[(fp(i;c)g;ficg;f(p(i;c);ic)g) ific2tandoc2p.
[pn] is the set of non-trivial components of pn, i.e., all components
containing two or more transitions.
this denition introduces pp-, tt-, pt-, tp-components to acknowledge
that components can be place and/or transition bordered. the function pnjjc
maps a component to a wf-net that is place bordered by adding places to pnjc
if needed.
in [11] we prove that pnjjcyields a safe and sound wf-net if pnis a safe
and sound wf-net. this result is very important for the remainder because it
shows that components in a safe and sound wf-net can be seen as \black boxes"
that have a well-dened input-output behavior. this allows us to iteratively
replace components by transitions until we obtain a trivial wf-net consisting
of just one transition.
(a) sequence.
 (b)
choice.
(c)
while.
(d) marked
graph.
(e) state ma-
chine.
(f) well-
structured.
(g) unstruc-
tured.
figure 2: dierent component types.
figure 2 shows some of the components we are interested in. to nd such
components we provide the following denitions.
denition 18 (component types). letpn= (p;t;f ) be a wf-net, c2
[pn] a component in pn, and pnjjc= (pc;tc;fc).
c is a sequence-component if and only if pnjjcis a state machine
and a marked graph.
we say that c is a maximal sequence-component if and only if
8c02[pn], c' a sequence-component: c6=c0)c6c0.
c is a choice-component if and only if pc=fpi;pogandtc=pi=
po.
14c is a while-component if and only if pc=fpg,tc=fti;t;tog, and
fc=f(ti;p);(p;t);(t;p);(p;to)g.
c is a marked-graph component if and only if pnjjcis a marked
graph net.
we say that c is a maximal marked-graph-component if and only
if8c02[pn], c' a marked-graph-component: c6=c0)c6c0.
c is a state-machine-component if and only if pnjjcis a state ma-
chine net.
we say that c is a maximal state-machine-component if and only
if8c02[pn], c' a state-machine-component: c6=c0)c6c0.
c is a well-structured component if and only if 8(p;t)2fc: (jp
j>1)jtj= 1)^(jtj>1)jpj= 1) and8n2pc[tc: (n;n)62f
c
(i.e. no cycles).
we say that c is a maximal well-structured-component if and
only if8c02[pn], c' a well-structured-component: c6=c0)
c6c0.
c is an unstructured-component if none of the above denitions
apply for c.
c is a minimal-unstructured component if and only 8c02[pn]:
c6=c0)c06c.
most of the component types correspond to well-known subclasses of petri
nets (state machines and marked graphs) or basic programming constructs
(while loop). also constructs from the -calculus [32] such as prexing and par-
allism can be expressed (sequences and marked graphs). the only component
type that requires some explanation is the well-structured component.
the rst requirement jpj>1)jtj= 1 is similar to the free-choice prop-
erty. it is slightly more strict, i.e., if a place has multiple outgoing arcs the
corresponding transitions should not synchronize. in other words: choice and
synchronization are separated. the second requirement jtj>1)jpj= 1
can be seen as a dual property of the free-choice property. if a transition needs
to synchronize, it should not be directly preceded by an xor-join. this implies
that for every synchronization transition, the set of transitions that supply to-
kens for such a synchronization is xed. the third requirement states that the
component should not have a cycle. some process modeling languages locally
enforce such requirements to keep the modeling and implementation simple. a
nice example is the ow construct in bpel that corresponds exactly to a well-
structured component [11]. note that alternative component types could be
dened. this would not change the essence of our approach. the unstructured
component type acts as a last resort, i.e., if no nice pattern can be discovered
15this pattern is selected. therefore, we prefer to take the minimal unstructured
component rather than the largest one.
as indicated before, the goal is to identify atomic patterns in the form of
component types and replace them by transitions. by doing this iteratively the
whole wf-net is reduced until the trivial net is reached. the function fold(see
denition 19) takes care of the actual reduction. foldreduces a wf-net with
a component c by removing c and replacing it by a \fresh" transition. this
operation yield a safe and sound wf-net if the original wf-net was safe and
sound (see theorem 3 in [11]). this property is essential as it guarantees that
the behavior in the rest of the net does not change by removing the atomic
pattern identied.
denition 19 (fold). letpn= (p;t;f ) be a wf-net and let cbe a non
trivial component of pn(i.e.,c2[pn]). function foldreplacescinpnby a
single transition tc, i.e., fold(pn;c) = (p0;t0;f0) with:
p0=pnc,
t0= (tnc)[ftcg,
f0= (f\((p0t0)[(t0p0)))[f(p;tc)jp2p0\(ficg[ic)g[
f(tc;p)jp2p0\(focg[oc)g.
before we describe how we calculate the sm score, we extend the notion of
a wf-net by adding an annotation (cf. denition 20). this annotated wf-net
allows us to express that each transition has a weight associated with it. when
the algorithm for calculating sm reduces the wf-net iteratively, we assign a
weight to the transitions corresponding to the collapsed components. the input
wf-net to the sm algorithm is an annotated wf-net with annotation function
to(t) = 1,8t2t. in other words, initially all transitions will have the weight
1.
denition 20 (annotated wf-net). pn= (p;t;f; ) is an annotated wf-
net if and only if:
(p;t;f ) is a wf-net.
:t!r+is a function that assigns a weight to each transition in pn.
next we introduce two functions: a function pnthat denes a priority of
a component type, and a function !pnthat denes the weight, or cost, of a
component depending on its type. these two functions are used to determine the
order in which components are reduced to transitions and the weight associated
to the dierent component types.
denition 21 (component type priority function). letpn= (p;t;f; )
be an annotated wf-net. the component priority function pn: [pn]!nis
16dened as follows. for any c2[pn]:
pn(c) =8
>>>>>>>><
>>>>>>>>:1;ifc is a maximal sequence-component;
2;ifc is a choice-component;
3;ifc is a while-component;
4;ifc is a maximal marked-graph-component;
5;ifc is a maximal state-machine-component;
6;ifc is a maximal well-structured-component;
7;otherwise
as function pnshows we rst try to select a maximal sequence-
component and not a maximal marked-graph, maximal state-
machine, or maximal well-structured-component. the reason is
that any net representing a sequence is also a marked graph, state machine and
well-structured net. therefore, things are sorted from more specic patterns to
more generic patterns. the penalty associated to the dierent component types
is given by function !pn.
denition 22 (component weight function). letpn= (p0;t0;f0;) be
an annotated wf-net. we dene the component weight !pn: [pn]!r+as
follows. for any c2[pn], with source icand sinkoc, andpnjc= (p;t;f ):
!pn(c) =8
>>>>>>>><
>>>>>>>>:p
t2t(t); ifpn(c) = 1;
1:5p
t2t(t); ifpn(c) = 2;p
t2fic;ocg(t) + 2p
t2tnfic;ocg(t); ifpn(c) = 3;
2p
t2t(t)di(t); ifpn(c) = 4;
2p
p2p(t)di(p); ifpn(c) = 5;
2p
t2t(t)di(p)di(t); ifpn(c) = 6;
5(jjfj jp[tjj+ 1)p
t2t(t)di(p)di(t);otherwise
where di : 2p0[t0!nnf0gis dened as di(x) =jjfx2xjjxj>
1gj jfx2xjjxj>1gjj+ 1.
diis a rough measure of how evenly matched split and merge points are in
the component; the more unevenly matched these are the higher value of di.
the above component weight function is based on practical experiences.
however, the actual function remains subjective and may be congured dif-
ferently based on the application domain or tools used. the particular choice
for!pnis motivated in the remainder. sequence-components are consid-
ered simple and their weight is the sum of weights of the transitions involved.
we feel that the transitions involved in the choice-component are harder
to understand than if they were in a sequence-component, so we multiply
the sum of weights by 1.5. the while-component can be seen as a sequence
starting with the source transition and ending with the sink transition and in-
between these two transitions there is a transition that can be executed an
arbitrary number of times. we think that the transition involved in the it-
eration is more dicult to understand than the source and sink transitions
17so we multiply its weight by two and add it to the weight of the other two
transitions. the three remaining types of components (marked-graph,
state-machine, and well-structured) are weighted by multiplying
the sum of the involved transitions weights by two and then multiplying the
dierence in how many splits and joins there exists in the component. the last
factor is to reect that components that have unevenly matched splits and joins
are often harder to understand. unstructured-components are given the
biggest penalty, and this is because we do not know what behavioral pattern
they model. the penalty can be obtained by multiplying three factors: rst
a factor that describes how many arcs versus nodes multiplied by ve { the
more arcs there are than nodes, the more dicult we expect the component is
to understand; second, the sum of weights of the transitions in the component;
and third, the number of joins versus splits in the component. notice that the
unstructured-component penalty is larger than any of the others, so if
we, e.g., score a well-structured-component as an unstructured-
component that would yield a larger penalty:
!pn(c)pn(c)=6= 2p
t2t(t)di(p)di(t)
< 5p
t2t(t)di(p)di(t)
 5(jjfj jp[tjj+ 1)p
t2t(t)di(p)di(t)
pn(c)=7=!pn(c)
similar arguments can be used to show that the unstructured-component
penalty is always larger than any of the other penalties.
note that it is impossible to \prove" that the component weight !pnis the
right one. complexity is perceived in a subjective manner and therefore there
is not a \best" way to assign weights. therefore, we do not present !pnas
\the" component weight function; it is just an example based on experience.
alternative weight functions can be dened as is explained later.
the algorithm that calculates the structuredness metric is given in deni-
tion 23. the intuition behind the algorithm is as follows. first pick a component
with the highest priority (i.e., the lowest pnvalue). after selecting the com-
ponent use the function foldto remove this component from the wf-net. the
weight of the added transition, is the weight (i.e. complexity) of the removed
component.
this matching followed by reduction is repeated until the net contains no
non-trivial components anymore; the weight of the transition in the nal trivial
wf-net is the sm score. note that another implication of the algorithm is
that components embedded in other components are penalized the more deeply
embedded they occur in the wf-net, since we multiply the sum of weights by
a number greater than one for most component types (cf. denition 22). this
is, we believe, a desirable property of our metric, since we feel that components
that are wrapped in other components make the wf-net, as a whole, more
dicult to understand.
18denition 23 (structuredness metric algorithm). letpn= (p;t;f ) be
a wf-net,x: [x]!nbe a component priority function and !x: [x]!r+a
component weight function for an arbitrary wf-net x. the following algorithm
calculates the structuredness metric (sm).
(i)x:= (pn;), where(t) = 1;8t2t
(ii) while [x]6=;(i.e.,x= (pn;) contains a non-trivial component)4
(iii) pickcso thatx(c) =minfx(c0)jc02[x]g
(iv) pn0:=fold(pn;c) wheretcis the added transition
(v)0(tc) =!x(c) and0(t) =(t) for all other t
(vi)x:= (pn0;0)
(vii) output sm(pn) =(t) (t=ftgafter the net is reduced).
note that the algorithm will always reduce the wf-net completely. this
follows from the observation that for each iteration of the while loop in step (ii)
we reduce the net by one component when we use the function fold. since a
component has at least two transitions and it is replaced by a single transition,
each invocation of foldwill yield a smaller wf-net with fewer transitions. it is
always possible to nd a component if the wf-net contains multiple transitions,
because as a last resort we fold a minimal unstructured-component.
therefore, the algorithm given in denition 23 will terminate and yield some
positive value.
the time complexity of calculating the structuredness metric sm(pn) can
be divided into four parts: (1) the time required for nding a component; (2) the
time for recognizing and scoring component; (3) the time needed for executing
function fold; (4) and the number of times the while-loop in the algorithm of
denition 23 needs to be executed.
in the following let n=jp[tj. (1) the algorithm we choose to nd the
components are the following simple one: nd all pairs of nodes in the net and
see for each pair if they are the source and sink in a component, by checking if
all paths from the source end up in the sink node. there may be more clever
ways of nding the components, but we choose this version since it has proven
ecient in practice. the time complexity of the algorithm is o(n3), and the
reason is that for each possible source node n2p[tthere aren 1 possible
sink nodes, so this means that there are n(n 1)2o(n2) possible components
in a net. testing if a pair of source and sink node borders a component, takes
o(n) time, so all in all nding all components takes o(n3) time.
(2) recognizing and scoring a component depends on the component type.
recognizing the component types that we have dened, as well as the evaluating
its weight!in denition 22 both has an upper bound time complexity of o(n).
4note that this is the case as long as xis not reduced to a wf-net with just a single
transition.
19p1registerp2checkavailabilityupdatep3out of stock replenishin stockp6p7ship goods
reminderp9archivep4send billp8receive paymentp10p11out of stock no replenishp5replenishfigure 3: order handling process.
(3)foldalso runs in time o(n). so one iteration of the while-loop has a time
complexity of o(n3). (4) the while-loop removes at least one transition in each
iteration, the number of iterations is o(jtj), oro(n).
hence the time complexity for the whole algorithm o(n4), oro(jp[tj4),
since the body of the while-loop runs in o(n3) and the while-loop iterates o(n)
times.
3.4. comparison of the three metrics
we conclude this section by rst presenting an example wf-net, where we
show how each of the three metrics is calculated, and compare the dierent
scores. the wf-net considered is shown in figure 3. this is a fragment of an
order handling process taken from [5]. even though the example is small it still
uses complicated structures such as the milestone pattern [9, 10] involving place
p9and transition reminder .
the ecam metric can easily be calculated.
ecam (pn) =p
p2pecfcp(p)
=jftjt2p1gj+jftjt2p2gj+:::+jftjt2p11gj
=jffp2;p4ggj+jffp3ggj+:::+j;j
= 1p1+ 1p2+ 3p3+ 1p4+ 1p5+ 1p6+ 1p7+ 2p8+ 2p9+ 1p10+ 0p11
= 14
20(p1)(p2,p4)register(p3,p4)checkavailability(p4,p5)out ofstock noreplenish(p4,p6)out ofstockreplenish(p4,p7)in stock
updatereplenish(p4,p9)shipgoods(p8,p9)remindersendbill(p9,p10)receivepayment(p11)archivefigure 4: reachability graph of the order handling process.
to calculate the ecym metric we rst have to generate the reachability
graph of the order handling process. the resulting graph is shown in figure 4.
ecym can be calculated from as follows:
ecym (pn) =jej jvj+p= 12 10 + 6 = 8
this is because the reachability graph has 12 edges, 10 vertices, and 6
strongly connected components.
the 6 components are: f(p1)g,f(p2;p4);(p3;p4);(p4;p5);(p4;p6)g,f(p4;p7)g,
f(p4;p9);(p8;p9)g,f(p9;p10)g, andf(p11)g.
to calculate the structuredness metric we need to execute the algorithm
presented in this paper. figures 5 through 8 illustrate how the order handling
process is broken down and reduced. this is done in three iterations. this leads
to the following penalty values:
iteration 0 (t) = 1;8t2t
iteration 1 (tc1) = 2;(t) = 1;8t2tnftc1g(c is a maximal sequence-
component and !x(c) = 1)
iteration 2 (tc1) = 2;(tc2) = 2;(t) = 1;8t2tnftc1;tc2g(c is a max-
imal sequence-component and !x(c) = 1)
iteration 3 (tc3) = 168 (c is a minimal unstructured-component
and!x(c) = 168)
hence sm(pn) =(tc3) = 168 for the order handling process.
as expected the three metrics return dierent results for the process model
shown in figure 3. the ecym metric scores the net with 8 (the lowest), then
comes the ecam metric with 14, and nally the sm metric assigns a score of
168 (the highest) to the process. the low ecym metric score can be explained
by the fact that the model has a relatively small state space (only 10 states).
the ecam counts how many successor states can be reached from each place.
21p1registerp2checkavailabilityupdatep3out of stock replenishin stockp6p7ship goods
reminderp9archivep4send billp8receive paymentp10p11out of stock no replenishp5replenishmaximal sequencemaximal sequenceunstructuredfigure 5: calculating the sm for the order handling process. before rst iteration.
p1registerp2checkavailabilityupdatep3in stockp7ship goods
reminderp9archivep4send billp8receive paymentp10p11out of stock no replenishp5
maximal sequenceunstructuredtc1
figure 6: calculating the sm for the order handling process. before second iteration.
22p1registerp2checkavailabilityupdatep3tc2
reminderp9archivep4send billp8receive paymentp10p11out of stock no replenishp5unstructuredtc1figure 7: calculating the sm for the order handling process. before third iteration.
p1tc3p11
figure 8: calculating the sm for the order handling process. after third and nal iteration.
23since there are only a few choices this results in a small number. note that a
purely sequential model would have a value of 10 rather than 14. this shows
that despite its complex structure the wf-net is not rated as complex by this
metric. the score based on the sm metric is the only one that acknowledges
the complexity of this relatively small example process.
note that it is not possible to compare the dierent metrics on the basis
of a single example. this is why we have analyzed and compared 262 real-life
process models. before discussing this case study, we rst describe the tool
support we have developed.
4. implementation
the three metrics presented in this paper have been implemented in the
context of prom [7, 34]. prom is a plugable framework aiming at process
analysis. although most of the functionality is related to process mining, the
tool also allows for various kinds of model-based analysis (e.g., verication).
the prom framework hosts a wide variety of plug-ins:
import plug-ins it is possible to load a wide variety of les into prom. some
of the important formats are: mxml, pnml (standard format for petri
net), aris aml (proprietary format for epcs), epml (standard format
for epcs), bpel, yawl, and protos models. all of these are represented
as rst class objects in the framework. this means that, e.g., importing
a pnml le results in a petri net object which can be used as input for
plug-ins that works on petri nets.
mining plug-ins prom was developed as a framework for process mining.
therefore, there are many plug-ins than can be used to discover mod-
els. for example, based on audit trails or event logs, various plug-ins can
derive petri nets, epcs, social networks, etc.
analysis plug-ins these are plug-ins used for analyzing the various model
objects in prom. for example, there are analysis plug-ins to test soundness
of petri nets or ltl checkers to test properties of an mxml object.
conversion plug-ins these plug-ins are useful for converting between dier-
ent object types. for example, it is possible to convert epcs to petri nets,
petri nets to bpel, petri nets to yawl, and so on.
export plug-ins these plug-ins are used to store objects in prom to les so
that they can be used by other tools, e.g., workow management systems
or simulation tools.
the approach presented in this paper is supported by a new analysis plug-in
in prom. this plug-in is easy to use on any petri net object. first load a petri
net, choose the workow net metrics plug-in from the analysis menu, and the
dialog shown in figure 9 will appear. note that the model may also be the
24figure 9: input dialog for the workow net metrics analysis plug-in.
result of process mining eorts or some model conversion. in fact it is possible
to load an epc or protos model, convert it to a wf-net and then apply the
plug-in. the dialog shown in figure 9 allows the user to congure the order by
which components are matched in the sm algorithm. in other words, the user
may redene the component priority function .
figure 9 also shows that dierent weight functions can be supported. as
indicated before, the approach presented in this paper does not depend on a
particular component priority and weight !functions. therefore, this part is
congurable and can be extended.
after the user is satised with the setup she may either press the proceed
button, or press the batch analysis button. the rst choice will make the analysis
plug-in use the three metrics on a particular net and present the result with
statistics of the calculations (see figure 10). the second choice will lead the user
to a le dialog where she must choose a folder that contains either pnml or tpn
(a proprietary le format for petri nets) les in its subfolders. when selecting
thebatch analysis option, the plug-in uses the three metrics on all the petri nets
in the subfolder. moreover, at the end the plug-in also provides dierent kinds of
comparisons and aggregated results. the ability to automatically analyze large
collections of models in batch mode is very useful for empirically investigating
25figure 10: results from the workow net metrics analysis plug-in when applied to the order
handling process.
complexity in process models. this will be demonstrated in the next section.
figure 11: the tree-structure of the order handling process used when calculating the struc-
turedness metric.
figure 10 shows a summary of the metrics applied to the order handling
process. figure 11 shows the actual derivation of the structuredness metric,
i.e., prom is able to show the iterative process of collapsing components into
transitions until one transition remains.
5. comparison of metrics: a case study
to evaluate the applicability of our approach and to compare and evaluate
the dierent metrics we used 262 process models created using protos. protos
(pallas athena) uses a petri-net-based modeling notation and is a widely used
26business process modeling tool. it is used by more than 1500 organizations in
more than 20 countries. the number of users that use protos for designing
processes is estimated to be 25000. some of the organizations have modeled
more than 1500 processes. the 262 process models used for the evaluation re-
sulted from student projects where students had to model and redesign realistic
business cases using protos. these models were collected in 2005, 2006, and
2007.
protos can be used to model dierent perspectives, i.e., besides the control-
ow also organizational structures, timing information, and data can be mod-
eled. in this study we focused on the control-ow perspective. protos supports
dierent splits and joins. any split or join is of type xor, and, or or. there-
fore, we rst had to translate the protos models into wf-nets. fortunately, it
is quite straightforward to automatically convert protos models into wf-nets
using prom. the resulting 262 wf-nets were then analyzed using the new prom
plug-in described in this paper.
in figure 12(a) we see the number of elements (places, transitions, and arcs)
that each individual net contains. figure 12(b) shows a dierent view that in-
dicates how many nets have a certain number of places, transition, and arcs.
the two gures show that the input nets span a wide range, i.e., from nets
with only 19 elements to nets with 345 elements. on average each net con-
tains 25 places, 28.2 transitions, and 62.26 edges. the correlation coecients5,
place;transition = 0:93,place;arc= 0:94, andtransition;arc= 0:99, indicate
that there is a strong dependency between the number of places, transitions,
and arcs in the input nets6. in a sense, the proportion of places, transitions and
arcs is similar for all of the nets. the distribution of elements in the input nets
is 22% places, 24% transitions, and 54% arcs.
in figure 13 we show how the three metrics scored on the input nets. the
y-axis is logarithmic since the scores generated by ecym and sm cover a wide
range of values. the mean score of the ecam is 30.56, ecym is 169.94, and
sm is 1381.57. the correlation coecients between the dierent scores are
ecam;ecym = 0:16,ecam;sm= 0:32, andecym;sm= 0:02. from this we
can see that ecam;ecym and ecym;smseem to be pairwise independent
since their correlation coecients are rather low. even though ecam;sm= 0:32
is not as low as the two other correlation coecients, we can say that ecam;sm
are not strongly correlated and relatively independent.
the correlation coecients suggest that it may be worthwhile to introduce
two new composed metrics: ( ecam;ecym ) and ( sm;ecym ). for each pair
it is clear that the functions do not linearly depend on each other. in other
words, they seem to be orthogonal, and it could therefore make sense to dene
5in this paper we use the term \correlation coecient" to refer to pearson's product-
moment coecient.
6usually we interpret correlation coecients x;y in the following way. a correlation
coecient between 0 and 0.5 indicates the range from no dependency to a stronger but still
not denite dependency. a correlation coecient between 0.5 and 1 corresponds to the range
from a weak dependency to a strong dependency.
27(a) number of places, transitions and edges per net.
(b) occurence of nets dierent amounts of places, transitions and edges.
figure 12: statistics for the 262 input nets.
28figure 13: scores of the three metrics.
these two metrics. of course, the input nets of our case study, do not reect
all possible process denitions, so we may come across input nets in other case
studies where the metrics are not orthogonal. but we do, however, feel that
our data set provides a good representation of the process denitions that can
be found in real life, so in this perspective it would really make sense to not
use a single metric of the three metrics, but rather the pair ( ecam;ecym ) or
(sm;ecym ).
we will not go into more details on how the dierent metrics scored for
the individual nets. we did, however, make some observations on why each
the metrics scored high for particular nets. ecam scored high in situations
where the input net had a high degree of fan-out from places. this was to
be expected based on the way it was dened. ecym scored high on nets that
had a high degree of parallelism. parallelism in a process typically leads to
large reachability graphs, and since ecym indeed measures the complexity of
the reachability graph, it is no surprise that ecym score high on nets that
has parallelism. finally, sm scored in general high on input nets that had
many layers of components in components, but also on nets where marked-
graph, state-machine, or well-structured components did not
have a matching number of splits and joins.
in addition to the scores of the three metrics, we also looked at what com-
ponents where \matched" while iteratively calculating sm and how they were
scored, not only by sm itself, but also how ecam and ecym scored these.
29figure 14: components matched by the sm-algorithm.
in figure 5 we present the dierent types of components that we discov-
ered and how frequently they were used in the reduction (i.e., the components
replaced using the function fold). all in all we matched and reduced 2769
components, including 234 choice-components, 155 maximal marked-
graph-components, 1932 maximal sequence-components, 187 state
machine-components 175 minimal unstructured-components, 10 max-
imal well-structured-components, and 76 while-components.
we have scored each component that was reduced in the sm algorithm with
each of the three metrics to see how they dier. since a component that is
being reduced may have transitions that are the result of a reduction, it may
be that sm will score that component a lot higher than it would had it not
contained any of such transitions. also, the other metrics do not take such
issues into consideration, so to give a fair comparison we look at each component
as if it does not contain transitions that are a result of a reduced component.
this means that when we calculate sm for each component, we consider all
transitions tto be annotated as (t) = 1.
table 1 shows the correlation coecients for the dierent pairs of metrics.
note that the value \{" in the table is used when no correlation coecient
between the metrics could be calculated for a particular pair of metrics. the
correlation coecients could not be always be calculated because in some cases
one of the metrics gave the same score for each component. this implies e.g.
that it is not possible to calculate ecam;ecym andecam;smfor the choice
30table 1: correlation coecients of component scores.
component type ecam;ecymecam;smecym;sm
choice { { 1
marked-graph 0.57 0.72 0.40
sequence 0.85 0.85 1
state-machine 0.92 0.82 0.74
unstructured 0.34 0.58 0.11
well-structured 0.88 0.15 0.32
while { { {
component.
interestingly, the three pairs of metrics have in general a higher degree of
correlation than they had when we considered scores for the whole nets. this
indicates that they agree more on how to score components rather than whole
wf-nets. especially ecym;smhad almost no correlation, but looking at their
correlation coecients they tend to agree on their scoring of individual compo-
nents. this is in part because smpenalizes embedded component explicitly by
how it is dened, whereas ecym does not consider this aspect at all. a similar
argument applies to the pair ecam and sm.
our survey in this section allows us to conclude that the three metrics are
very dierent. this can seen from the correlation coecient absolute value for
each pair of metrics, were below 0.32, and even as low as 0.02. it is not clear
from the denitions of the three metrics that they would be so dierent, since
it is possible to make small examples where their scores are very similar, as
is backed up by our survey of how the correlation coecient for each pair of
metrics on each component scored in table 1. if we only look at small examples
that have this uniform behavior, we would have ended up by concluding that
the three metrics are, although dened dierently, highly correlated. but when,
we look at complete models, with a high degree of behavioral patterns, the
dierences in the three metrics become evident.
to learn what impact it would have to change the penalties for each of
the component we investigate at what depth the component is matched in the
wf-net. the depth of a component is dened from the hierarchical compo-
nent decomposition of the wf-net. informally, we build the tree by running
the algorithm in denition 23 backwards, so that the top level component in
the decomposition become the last reduced component. the children of each
component c in the decomposition are the components that were folded and
became transitions in c. we dene the depth of the top-level component as 0,
its children as 1, its children's children as 2, and so on. for an example, please
refer to the tree view shown in figure 11 and generated by our prom plug-in.
there the unstructured component has depth 0 and the two sequences has depth
1.
in table 2 we show the match depth of each component type; the percentage
31table 2: match depth of component types.
depth choice marked-graph sequence state-machine
0 0 21 (13.6%) 65 (3.4%) 103 (55.1%)
1 39 (16.7%) 91 (58.7%) 725 (37.5%) 52 (27.8%)
2 113 (48.3%) 24 (15.5%) 640 (33.1%) 26 (13.9%)
3 40 (17.1%) 17 (11.0%) 319 (16.5%) 4 (2.1%)
4 29 (12.4%) 2 (1.3%) 126 (6.5%) 2 (1.1%)
5 12 (5.1%) 0 44 (2.3%) 0
6 1 (0.4%) 0 12 (0.6%) 0
7 0 0 1 (0.05%) 0
depth unstructured well-structured while
0 63 (36.0%) 9 (90.0%) 1 (1.3%)
1 86 (49.1%) 1 (10.0%) 27 (35.5%)
2 21 (12.0%) 0 24 (31.6%)
3 4 (2.3%) 0 20 (26.3%)
4 1 (0.6%) 0 4 (5.3%)
after each number indicates how many times that component was matched at
that depth compared to occurrences of it at other depths. the average match
depth was: choice 2.42; marked-graph 1.28; sequence 1.95; state-
machine 0.66; unstructured 0.82; well-structured 0.10; and,
while 1.99.
from the table we see that complex components such as marked-graph,
state-machine, unstructured and well-structured do not
occur at such a low-level as, e.g., the sequence or choice components.
this makes sense because the later two have a higher priority according to pn.
what table 2 doesn't show is the depth of each component compared to
the maximal depth in the wf-net where it was found. however, the relative
depth is interesting and, therefore, we introduce the depth fraction function in
denition 24 and a new metric in denition 25.
denition 24 (depth fraction function). letpn= (p;t;f; ) be an an-
notated wf-net, depth be a function that calculates the depth of a component
in a decomposition hierarchy, and max depth be a function which calculates
the maximal depth in a decomposition hierarchy. the depth fraction function
pn:dom(pn)![0; 1] is dened as follows. for c2dom(pn):
pn(c) =(
depth (c;pn)
max depth (pn)ifmax depth (pn)>0
0 ifmax depth (pn) = 0
denition 25 (aggregated depth fraction metric). letsbe a set of an-
notated wf-nets, pn2s. the aggregated depth fraction metric  s:rng(pn)!
32[0; 1] maps a component type (according to the 7 classes in denition 21) onto
its average relative depth and is dened as follows. for c2rng(pn):
s(c) =x
pn2s0
@x
c2[pn]:pn(c)=cpn(c)1
a
x
pn2sjfc2[pn]jpn(c) =cgj
intuitively  sscore close to 0 if the components with the component type
cfound insall are found close to the top-level of their respective wf-net
component decomposition hierarchy. conversely, it score close to 1 if they are
found close to the bottom-level.
we applied the  smetric to the 262 nets and the results were: choice
0.63; marked-graph 0.41; sequence 0.64; state-machine 0.23;
unstructured 0.27; well-structured 0.05; and, while 0.59. this
shows that choice-, sequence-, and while-components are more likely
to be found at the bottom of each of the wf-net component decomposition
hierarchy, whereas the rest of the component types are more likely to be found
at the top-level.
if we take this knowledge about the depth where we nd the various com-
ponent types we can more accurately ne-tune the component weight function.
by also observing that the metric penalty score is accumulated at each level of a
component decomposition tree, changing the penalties of component types that
are more likely to be found at the lower levels will have a greater eect on the
total score of smthan changing those more likely to be found at the top-level.
in the survey we saw that nets where ecam scored high, were as expected,
nets with high fan-outs from places, but the nets themselves were not behav-
iorally complex. this leads us to believe that ecam is not suited for scoring
nets that contain many behavioral patterns, and where these are embedded in
each other.
ecym did in many ways, as for ecam , not really reect the complexity
of the actual net. its intent is to measure the behavioral complexity of the
reachability graph, and not the actual net. however, we found that although
ecym actually scored very similar to ecam andsmon small examples and on
the components found in the smalgorithm, the way it scored a net in general
did not truly reect the complexity and eort needed to understand a net.
based on our empirical evaluation, we conclude that ecym does not give us
any insight in how complicated real-world process models are. it does, however,
give us an understanding of how complicated the underlying behavior of the net
is, and this makes ecym a valuable supplement to other metrics such as ecam
and smthat do not take the reachability graph into account.
we, the authors, found that smwas the best metric. nets that had a low
smvalue were easy to understand, and the nets that scored high were very
dicult. we observed that nets that sm gave a higher score, had many levels of
components embedded in each other and/or uneven number of splits and joins.
336. related work
as discussed in the introduction, it is assumed that simpler models are
preferable over more complex models. moreover, if models become too com-
plex, they should be split into simpler models. while this seems obvious, little
evidence can be found in literature. a notable exception is the empirical work
presented in [27, 28]. using a collection of 2003 epc models it is shown that
at least 10 percent of these models is awed. in fact, for certain subsets (e.g.,
the sap reference model consisting of 604 epcs) it is shown that more than
20 percent have errors such as deadlocks, livelocks, etc. [27]. so people make
errors and the complexity of these models is a good predictor. using a simple
regression model it is shown that 7 variables (including coecient of connectiv-
ity, connector mismatch, cyclicity, separability, diameter) can be used to predict
whether a model is awed or not. in 95 percent of the cases such a prediction
is correct. this shows that variables related to the complexity of the model are
indeed predictors for errors. this supports our initial assumption.
the study reported in [27, 28, 29] also shows that none of the existing
complexity metrics is able to adequately capture complexity in two ways: they
dene metrics by looking at local syntactical complexity, with the exception of
the structuredness metric7, and the interpolation of the seven metrics as a single
metric are dicult to understand. we believe that by identifying behavioral
patterns in a process and scoring these according to their type and elements,
we get a metric that is better at scoring complexity. also, our emphasis on
penalizing components that are embedded in others give a more true reection
on the complexity of a process. another benet of only using a single metric
as we would use smis that for the end-user it will be much clearer why a net
scored as it did. with the tool support that we described in section 4 we were
able to achieve this.
the cardoso metric which inspired us to the denition of ecam is described
in [13]. the cardoso metric is in many way simple to understand and argue
why it is sensibly dened, if we look at small examples. but as we showed in our
case study in section 5 for large models with many dierent kinds of behavioral
patterns, it does not come close to truly measuring the complexity of the nets.
vanderfeesten et al. [37] dene the cross-connectivity metric ( cc) as a
measure for the complexity of a process model. their starting point is a process
model with an explicit representation of splits and joins (similar to epcs) of
the types and, or, xor. from there they dene a value for a path which is
calculated from the nodes on that path. now, ccis calculated by summing
values of all possible paths in the process graph and dividing it with the number
7the structuredness metric dened in [27] is a very simplistic version of sm and has
not yet been formally dened. it relates to the essential cyclomatic metric [26], and it
measures how well the process can be decomposed into well-dened components. it does not,
as we do, consider dierent types of components, and score them dierent accordingly. the
structuredness metric is then  n= 1 jn0j
jnj; n is the nodes in the original graph and n' the
nodes in the graph after all possible reductions are applied.
34of possible connections; cc=p
n1;n22nv(n1;n2)
jnj(jnj 1).ccis similar to the cardoso
metric in the sense that it focuses on the syntax of the process, although it is
not as simple in that cctakes entire paths into considerations. although cc
tries to consider a larger portion of the process model when evaluating a model,
it still doesn't consider complete behavioral structures as we do with sm.
much empirical work has been done by mendling et al. [31, 30], to learn
what makes a model understandable. they operationalize understandability by
introducing three categories of factors that they feel are important in under-
standing a model: personal (beyond psychological and intellectual); structural
(model characteristics); and textual (description in the model). besides charac-
terizing understandability they do a web survey to test a number of hypothesis
on the three categories of understandability. among their ndings they saw
that higher knowledge of theory of concurrency and daily work with models
lead to better understanding of models. also, that the larger the score the par-
ticipants of the web survey got wrt. a particular model was positively correlated
with the structuredness and soundness of the model, regardless of their prior
knowledge of the theory of concurrency. their experiments show that there
is a connection between the degree of structuredness in a process model and
the understandability of it, and thereby also to lower complexity of the process
model.
muehlen and recker [38] investigate how many of the bpmn language con-
structs is actually used in real-world models. interestingly they nd that the
most used constructs is from the core set of bpmn. the core set of bpmn has
constructs for sequencing tasks, splitting them in ows or choices. the authors
argue that people often don't extend their usage of constructs besides the core
elements because they are confused of how they should be used. in comparison
to our work we also see that the majority of components we found in all of the
process models were of the predened types and that only 6.1% were actually
unstructured.
7. conclusion
process models play an important role in the analysis of business processes
and their implementation. the correctness and quality of these models are vital
for any organization. a workow management system congured on the basis of
an incorrect model may lead to costly problems. analysis results obtained using
e.g. simulation are only reliable if the models are an adequate reection of the
perceived or intended reality. sadly, both process engineers and end-users, have
problems understanding models. therefore, it is important to carefully assess
and measure the complexity of process models. contemporary metrics have
problems adequately capturing this complexity. therefore, we proposed a new
metric based on the structuredness of process models. highly structured process
models based on simple design patterns are classied as \easy" while spaghetti-
like process models using advanced patterns are classied as \dicult".
35we have implemented dierent complexity metrics using prom. the new
metric based on structuredness is completely congurable and can be ne-tuned
to specic application domains or languages. to test this metric we have evalu-
ated 262 process models and compared the dierent metrics. this study suggests
that the new structuredness outperforms existing ones.
we believe that smis a true alternative to already known metrics and in
many ways supersedes them in the way that smconsider the process as a whole,
and that smis dened in such a way that it is easy to explain to people and
make them understand why a process scores the way it did { an aspect the other
metrics mentioned in the related work in section 6 all struggle with.
although we have tested the metrics on hundreds of models, notions of
complexity are subjective and the actual weights of the dierent constructs
used by smin this paper are just an initial proposal. therefore, we suggest to
a eld study as proposed in other papers [30] where the metrics are compared
with the (subjective) opinions of experts and end-users.
references
[1] w. m. p. van der aalst. formalization and verication of event-driven
process chains. information and software technology , 41(10):639{650,
1999.
[2] w.m.p. van der aalst. verication of workow nets. in p. az ema and
g. balbo, editors, application and theory of petri nets 1997 , volume 1248
oflecture notes in computer science , pages 407{426. springer-verlag,
berlin, 1997.
[3] w.m.p. van der aalst. the application of petri nets to workow man-
agement. the journal of circuits, systems and computers , 8(1):21{66,
1998.
[4] w.m.p. van der aalst. workow verication: finding control-flow errors
using petri-net-based techniques. in w.m.p. van der aalst, j. desel, and
a. oberweis, editors, business process management: models, techniques,
and empirical studies , volume 1806 of lecture notes in computer science ,
pages 161{183. springer-verlag, berlin, 2000.
[5] w.m.p. van der aalst. business process management demystied: a tu-
torial on models, systems and standards for workow management. in
j. desel, w. reisig, and g. rozenberg, editors, lectures on concurrency
and petri nets , volume 3098 of lecture notes in computer science , pages
1{65. springer-verlag, berlin, 2004.
[6] w.m.p. van der aalst and t. basten. inheritance of workows: an ap-
proach to tackling problems related to change. theoretical computer
science , 270(1-2):125{203, 2002.
36[7] w.m.p. van der aalst, b.f. van dongen, c.w. g unther, r.s. mans, a.k.
alves de medeiros, a. rozinat, v. rubin, m. song, h.m.w. verbeek, and
a.j.m.m. weijters. prom 4.0: comprehensive support for real process
analysis. in j. kleijn and a. yakovlev, editors, application and theory of
petri nets and other models of concurrency (icatpn 2007) , volume 4546
oflecture notes in computer science , pages 484{494. springer-verlag,
berlin, 2007.
[8] w.m.p. van der aalst, k.m. van hee, a.h.m. ter hofstede, n. sidorova,
h.m.w. verbeek, m. voorhoeve, and m.t. wynn. soundness of workow
nets: classication, decidability, and analysis. bpm center report bpm-
08-02, bpmcenter.org, 2008.
[9] w.m.p. van der aalst, a.h.m. ter hofstede, b. kie-
puszewski, and a.p. barros. workow patterns home page.
http://www.workowpatterns.com.
[10] w.m.p. van der aalst, a.h.m. ter hofstede, b. kiepuszewski, and a.p.
barros. workow patterns. distributed and parallel databases , 14(1):5{
51, 2003.
[11] w.m.p. van der aalst and k.b. lassen. translating unstructured workow
processes to readable bpel: theory and implementation. information
and software technology , 2006.
[12] w.m.p. van der aalst, k.m. van hee, and r.a. van der toorn. component-
based software architectures: a framework based on inheritance of be-
havior. science of computer programming , 42(2-3):129{171, 2002.
[13] j. cardoso. control-ow complexity measurement of processes and
weyuker's properties. in transactions on enformatika, systems sciences
and engineering , volume 8, pages 213{218. springer verlag, berlin, bu-
dapest, hungary, 6 edition, october 2005.
[14] t.h. cormen, c.e. leiserson, and r.l. rivest. introduction to algorithms .
mit press/mcgraw-hill, 1990.
[15] j. dehnert. a methodology for workow modeling: from business process
modeling towards sound workow specication . phd thesis, tu berlin,
berlin, germany, 2003.
[16] j. desel and j. esparza. free choice petri nets , volume 40 of cambridge
tracts in theoretical computer science . cambridge university press, cam-
bridge, uk, 1995.
[17] r. eshuis and j. dehnert. reactive petri nets for workow modeling.
in w.m.p. van der aalst and e. best, editors, application and theory of
petri nets 2003 , volume 2679 of lecture notes in computer science , pages
295{314. springer-verlag, berlin, 2003.
37[18] r.j. van glabbeek and d.g. stork. query nets: interacting workow mod-
ules that ensure global termination. in w.m.p. van der aalst, a.h.m.
ter hofstede, and m. weske, editors, international conference on busi-
ness process management (bpm 2003) , volume 2678 of lecture notes in
computer science , pages 184{199. springer-verlag, berlin, 2003.
[19] k. van hee, n. sidorova, and m. voorhoeve. soundness and separabil-
ity of workow nets in the stepwise renement approach. in w.m.p.
van der aalst and e. best, editors, application and theory of petri nets
2003, volume 2679 of lecture notes in computer science , pages 335{354.
springer-verlag, berlin, 2003.
[20] g. keller and t. teufel. sap r/3 process oriented implementation .
addison-wesley, reading ma, 1998.
[21] b. kiepuszewski. expressiveness and suitability of languages for con-
trol flow modelling in workows . phd thesis, queensland uni-
versity of technology, brisbane, australia, 2003. available via
http://www.workowpatterns.com.
[22] b. kiepuszewski, a.h.m. ter hofstede, and w.m.p. van der aalst. funda-
mentals of control flow in workows. acta informatica , 39(3):143{209,
2003.
[23] e. kindler and w.m.p. van der aalst. liveness, fairness, and recurrence.
information processing letters , 70(6):269{274, june 1999.
[24] e. kindler, a. martens, and w. reisig. inter-operability of workow
applications: local criteria for global soundness. in w.m.p. van der
aalst, j. desel, and a. oberweis, editors, business process management:
models, techniques, and empirical studies , volume 1806 of lecture notes
in computer science , pages 235{253. springer-verlag, berlin, 2000.
[25] a. martens. on compatibility of web services. petri net newsletter ,
65:12{20, 2003.
[26] t. mccabe. a complexity measure. ieee transactions on software en-
gineering , 2:308{320, 1976.
[27] j. mendling. detection and prediction of errors in epc business pro-
cess models . phd thesis, vienna university of economics and business
administration, vienna, austria, 2007.
[28] j. mendling, m. moser, g. neumann, h.m.w. verbeek, b.f. van dongen,
and w.m.p. van der aalst. faulty epcs in the sap reference model. in
s. dustdar, j.l. faideiro, and a. sheth, editors, international conference
on business process management (bpm 2006) , volume 4102 of lecture
notes in computer science , pages 451{457. springer-verlag, berlin, 2006.
38[29] j. mendling, g. neumann, and w.m.p. van der aalst. understanding the
occurrence of errors in process models based on metrics. in f. curbera,
f. leymann, and m. weske, editors, proceedings of the otm conference
on cooperative information systems (coopis 2007) , volume 4803 of lecture
notes in computer science , pages 113{130. springer-verlag, berlin, 2007.
[30] j. mendling, h.a. reijers, and j.cardoso. what makes process mod-
els understandable? in business process management, 5th international
conference, bpm 2007, brisbane, australia, september 24-28, 2007, pro-
ceedings , volume 4714 of lecture notes in computer science , pages 48{63.
springer-verlag, berlin, 2007.
[31] j. mendling and m. strembeck. inuence factors of understanding busi-
ness process models. in witold abramowicz and dieter fensel, editors,
bis, volume 7 of lecture notes in business information processing , pages
142{153. springer, 2008.
[32] r. milner. communicating and mobile systems: the pi-calculus . cam-
bridge university press, cambridge, uk, 1999.
[33] m. n uttgens. event-driven process chain (epc) / ereignisgesteuerte
prozesskette (epk). http://www.iwi.uni-sb.de/nuettgens/epk/epk.htm.
[34] prom. prom, 2006. http://prom.sourceforge.net .
[35] w. reisig and g. rozenberg, editors. lectures on petri nets i: basic mod-
els, volume 1491 of lecture notes in computer science . springer-verlag,
berlin, 1998.
[36] r. van der toorn. component-based software design with petri nets: an
approach based on inheritance of behavior . phd thesis, eindhoven uni-
versity of technology, eindhoven, the netherlands, 2004.
[37] i.t.p. vanderfeesten, h. reijers, j. mendling, w.m.p. van der aalst, and
j. cardoso. on a quest for good process models: the cross-connectivity
metric. in z. bellahsene and m. l eonard, editors, proceedings of the 20th
international conference on advanced information systems engineering
(caise 2008) , volume 5074 of lecture notes in computer science , pages
480{494. springer-verlag, berlin, 2008.
[38] m. zur muehlen and j. recker. how much language is enough? theo-
retical and practical use of the business process modeling notation. in
z. bellahsene and m. l eonard, editors, proceedings of the 20th interna-
tional conference on advanced information systems engineering (caise
2008) , volume 5074 of lecture notes in computer science , pages 465{479.
springer-verlag, berlin, 2008.
39