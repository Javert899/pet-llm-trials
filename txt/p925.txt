arxiv:1704.08101v1  [cs.db]  25 apr 2017event stream-based process discovery using
abstract representations
s.j. van zelst∗, b.f. van dongen, and w.m.p. van der aalst
department of mathematics and computer science
eindhoven university of technology
p.o. box 513, 5600 mb eindhoven, the netherlands
april 27, 2017
abstract
the aim of process discovery, originating from the area of pr ocess min-
ing, is to discover a process model based on business process execution
data. a majority of process discovery techniques relies on a n event log as
aninput. aneventlogisastatic source ofhistorical dataca pturingtheex-
ecution of a business process. in this paper we focus on proce ss discovery
relying on online streams of business process execution eve nts. learning
process models from event streams poses both challenges and opportuni-
ties, i.e. we need to handle unlimited amounts of data using ﬁ nite memory
and, preferably, constant time. we propose a generic archit ecture that al-
lows for adopting several classes of existing process disco very techniques
in context of eventstreams. moreover, we provide several in stantiations of
the architecture, accompanied by implementations in the pr ocess mining
tool-kit prom1. using these instantiations, we evaluate several dimen-
sions of stream-based process discovery. the evaluation sh ows that the
proposed architecture allows us to lift process discovery t o the streaming
domain.
1 introduction
process mining [2] aims at understanding and improving business processes.
the ﬁeld consists of three main branches, i.e. process discovery ,conformance
checking andprocess enhancement . process discovery aims at discovering a
process model based on event data. conformance checking is con cerned with
assessingwhetheraprocessmodelandeventdataconformtoea chotherinterms
∗corresponding author: s.j.v.zelst@tue.nl
1http://promtools.org
1of possible behaviour. process enhancement is concerned with impr ovement of
processmodelsbasedonknowledgegainedfromeventdata, e.g. ap rocessmodel
is extended with performance diagnostics based on event data.
several process discovery algorithms exist [4,5,24,30,45,48]. t hese algo-
rithms all use an event log as an input. an event log is a static data source
describing sequences of executed business process activities rec orded over a his-
torical time-span. as the number of events recorded for operat ional processes
is growing tremendously every year, so does the average event log size. con-
ventional process discovery techniques are not able to cope with s uch large data
sets, i.e. they fail when the data does not ﬁt main memory. moreove r, events
are being generated at high rates, e.g. consider data originating fr om sensor
networks, mobile devices and e-business applications. since existing process
discovery techniques use static data, they are not able to captur e the dynamics
of such event streams in an adequate manner.
in thispaper, wefocusonprocessdiscoveryusingstreamsofbus inessprocess
events, i.e. event streams , rather than event logs. applying process discovery
on event streams allows us to gain insights in the underlying business p rocess in
a live fashion. it furthermore allows us to deal with situations where :1.)event
logs are too large to ﬁt main memory, 2.)there is no time to access event data
continuously, i.e. real-time constraints and 3.)recent behaviour is more impor-
tant, i.e. concept drift. a large class of existing process discovery algorithms
transforms the event log into an abstract representation , i.e. an abstraction of
the event log, which is subsequently used to discover a process mod el. to adopt
these algorithms in a streaming context, it suﬃces to approximate t he abstract
representation based on the event stream. using abstract repr esentations has
several advantages: 1.) reusability ; wereuseexisting techniques by predom-
inantly focusing on learning abstract representations from event streams. 2.)
extensibility ; once we design and implement a method for approximating a
certain abstract representation, any (future) algorithm using t he same abstract
representation is automatically ported to event streams. 3.) anonymity ; in
some cases, laws and regulations dictate that we are not allowed to s tore all
event data. some abstract representations ignore large parts o f the data, ef-
fectively storing a summary of the actual event data, and theref ore comply to
anonymity regulations.
we present the stream-based abstract representation (s-bar) architecture
that describes this mechanism in a generic way (fig. 1). an event str eams
represents an (in)ﬁnite sequence of events, emitted over time. an eventis
represented by a ( c,a)-pair, stating that activity ais executed in context of
casec. we maintain a data structure ( dt) that represents the past behaviour
emitted onto stream s. each time a new event arrives the data structure is kept
up to date by updating its previous state based on the newly receive d event
(δdt). from the data structure an algorithm-speciﬁc abstract representation
(at) is deduced ( λat
dt). after learning the abstract representation, we reuse
existing translations borrowed from conventional process discov ery algorithms
to return a process model ( γat).
2...,(c,a),...
event streamsδdtdata struct. update function data structure
dt λat
dtabstr. representation mapping
at
abstract representationγat
disc. algorithm process modelm
figure 1: schematic overview of the s-bar architecture .
the s-bar architecture is instantiated by designing a data structu re, a
data structure update mechanism and a data structure translat ion function.
the actual implementation of the data structure and related upda te functions
inﬂuences the behaviour described by the discovered process mod el, e.g. using a
time-decayingdatastructureversusadatastructurethatapp roximatesthemost
frequent cases on the stream. several instantiations of the arc hitecture have
been implemented in the process mining toolkits prom [19] and rapidpro m [3,
10]. using these implementations we conduct empirical experiments w .r.t. the
behaviourof these algorithms in an event stream setting. the expe riments show
that the algorithms are able to capture the behaviour reﬂected by the event
stream. moreover, the experiments show that memory usage and processing
times of the algorithms have non-increasing trends.
the remainder of this paper is organized as follows. in section 2, we p resent
background information regarding business processes and proce ss discovery. in
section 3, wepresenteventstreamsandthenotionofeventstre ambasedprocess
discovery. in section 4, we introduce the s-bar architecture. in section 5, we
provide several instantiations of the architecture. in section 6, we present an
empirical evaluation of several instantiations of the architecture . in section 7,
we present related work. in section 8, we discuss general challeng es in event
stream based process discovery. section 9 concludes the paper.
2 background
in this section we present general notation used throughout the paper and back-
ground concepts regarding business processes and process disc overy.
ndenotes the set of positive integers, n0includes 0. a multiset bover set
xis a function b:x→n0. we write a multiset as [ ek1
1,ek2
2,...,eknn], where
for 1≤i≤nwe have ei∈x,ki∈nandeki
i≡b(ei) =ki. if for element e,
b(e) = 1, we omit its superscript. if for element e,b(e) = 0, we omit efrom
the multiset notation. an empty multiset is denoted as [ ]. element inclu sion
applies to multisets, i.e. if e∈xandb(e)>0 thene∈b.
asequence σof length nrelates positions to elements e∈x, i.e.σ:{1,
2,...,n} →x. an empty sequence is denoted as ǫ. we write every non-empty
sequence as /a\}bracketle{te1,e2,...,en/a\}bracketri}ht. the set of all possible sequences over a set xis
3figure 2: bpmn model of a loan application process (adopted from [21 ]).
denoted as x∗. we write concatenation of sequences σ1andσ2asσ1·σ2.
letx,y,zandz′be sets and let f:x→yandg:y→z. function
composition of fandgis deﬁned as g◦f:x→z, withx/mapsto→g(f(x)) forx∈x.
moreover,given h:z→z′we write h◦g◦fforh◦(g◦f), i.e.h◦g◦f:x→z′,
withx/mapsto→h(g(f(x))) forx∈x.
2.1 business processes, models and event logs
business processes represent the execution of related business activities leading
to a business goal. consider a bank oﬀering loans to its customers. a business
goal of the bank is to accept, reject or cancel a loan application. t he bank’s
employees and its enterprise information system execute activities to achieve
4this goal, e.g. by checking a client’s credit history and assessing the lo an risk.
a business process pdeﬁnes a set of sequences over a set of activities a, i.e.
p ⊆a∗. ifσ∈ pthen the sequence of business activities σleads to a business
goal and belongs to the behaviour ofp. in this paper, we assume the execution
of activities to be atomic and abstract from data attributes such a s resource,
time-stamp etc. hence, we only consider the sequential ordering o f activities
(thecontrol-ﬂow perspective ).updenotes the universe of business processes.
a process model mrepresents a business process and, like a process, deﬁnes
a set of sequences over a set of activities a, i.e.m ⊆a∗.umdenotes the
universe of process models. in this paper, we consider process mo dels that de-
scribe behaviour in a deterministic manner, e.g. petri nets [36], bpmn [38] and
workﬂow nets [1]. consider the bpmn model of a loan application handlin g
process in fig. 2. it describes that after an application is received, the ﬁrst
activity to be executed is “check application completeness” . depending upon
the completeness of the application, the corresponding form is “returned back
to the applicant” , or, the client’s “credit history is checked” and subsequently
a“loan risk assessment” is performed. the two aforementioned activities can
be executed concurrently with the “appraise property” activity. an “eligibility
assessment” of the loan is performed, eventually leading to a rejection,cancel-
lationorapproval of the loan.
today’sinformationsystemstrackthe executionofbusinessproc esseswithin
a company. such systems store the execution of activities in conte xt of acase,
i.e. an instance of the process. the data stored by the information system is
oftenin theformofan event log. considertable1asanexample. theexecution
table 1: fragment of an event log.
case activity resource time-stamp
... ... ... ...
3 approve application (a4) john 2015-05-08 08:45
4 check application completeness (c1) lucy 2015-05-08 09:13
5 check application completeness (c1) john 2015-05-08 09:14
5 return application to applicant (r1) pete 2015-05-08 10:11
5 receive updated application (r2) pete 2015-05-08 10:28
6 check application completeness (c1) lucy 2015-05-08 10:33
4 check credit history (c2) rob 2015-05-08 10:43
5 appraise property (a1) pete 2015-05-08 11:00
4 appraise property (a1) rob 2015-05-08 11:14
4 assess loan risk (a2) rob 2015-05-08 11:35
4 assess eligibility (a3) lucy 2015-05-08 11:55
5 check credit history (c2) john 2015-05-08 11:57
4 prepare acceptance pack (p1) lucy 2015-05-08 12:25
4check insurance quote request present (c3) lucy 2015-05-08 12:23
4 send acceptance pack (s2) lucy 2015-05-08 12:28
5 assess loan risk (a2) john 2015-05-08 12:37
4 verify repayment agreement (v1) lucy 2015-05-09 13:05
4 approve application (a4) john 2015-05-09 14:15
... ... ... ...
5of an activity in context of a case, e.g. approve application executed for case
3, is referred to as an event. a sequence of events, e.g. the sequence of events
related to case 4,/a\}bracketle{tcheck application form completeness, check credit history ,
..., approve application /a\}bracketri}ht, is referred to as a trace(written /a\}bracketle{tc1,c2,...,a4/a\}bracketri}htwhen
using abbreviated activity names).
an event log lis a multiset of sequences over a set of activities a, i.e.
l:a∗→n0, and describes the execution of some p ∈ up.uldenotes the
universe of event logs. an event log is a sampleof the underlying process.
therefore, there might exist process behaviour that is not prese nt in the event
log e.g., caused by parallelism. in such case an event log is incomplete . there
might also exist traces in the event log that are not part of the proc ess, i.e.
noisytraces. noisy traces can be caused by faulty execution of the pro cess,
incomplete speciﬁcations or technical issues such as incorrect logg ing, system
errors and mixed time granularity.
2.2 process discovery
the goal of process discovery is to discover a process model base d on an event
log. several process discovery algorithms exist [4,5,24,30,45,4 8]. these algo-
rithms diﬀer in terms oftheir underlyingcomputationalschemesand data struc-
tures as well as their resultingprocess modeling formalism. we refer to [2,20,44]
for a detailed overview of process discovery algorithms.
aprocessdiscoveryalgorithm γldiscoversaprocessmodelbasedonanevent
log, i.e.γl:ul→ um. the challenge is to design γlin such way that γl(l) is
anappropriate representation of the underlying process p. appropriateness of
γ(l) depends on the aim of the process discovery analysis, e.g. ensurin g that all
behaviour in the event log is present in the model versus ensuring th at the most
frequent behaviour is present. given the diﬀerent aims of process discovery
analyses, several quality measures are deﬁned in order to judge t heir resulting
model’s appropriateness. ideally, pis used as a basis to compute these metrics,
however, as lis the only tangible sample of p, we typically compute the quality
ofγl(l)usingl. thefouressentialprocessminingqualitydimensionsare replay
ﬁtness,precision ,simplicity andgeneralization [2,12]. replay ﬁtness describes
what fractionof the behaviourpresent in lis alsodescribed by γl(l). precision
describes what fraction of the behaviour described by γl(l) is also present
inl. simplicity describes the (perceived) complexity of the process mod el.
since it is unlikely that the event log contains all behaviour (incomplete ness),
generalization describes how well the process model generalizes fo r behaviour
not present in l. due to noise, an algorithm guaranteeingperfect replay ﬁtness,
i.e. all behaviour in the event log is present in the discovered model, ca ptures
behaviour that is not part of the process. in practice this leads to very complex
models that are impossible to be interpreted by a human analyst. hen ce, a
process discovery algorithm needs to strike an adequate balance between the
four essential quality dimensions.
6s1 ∞ (3,a4),(4,c1),(5,c1),(5,r1),(5,r2)(6,c1),(4,c2),(5,a1),···
figure 3: example event stream s1.
3 event stream based process discovery
existing process discovery techniques discover process models in a n a-posteriori
fashion, i.e. they provide a historical view of the data. however, mo st infor-
mation systems allow us to capture the execution of activities at the moment
they occur. discovering and analysing process models from such co ntinuous
streams of events allows us to get a real-time view of the process un der study.
such view paves the way for new types of process mining analysis, i.e. we are
able to answer more advanced questions such as “what is the curre nt status of
the process?” and “what running cases are likely to cause problems ?”. it also
allows us to inspect and visualize recent behaviour and evolution of be haviour
in the process, i.e. concept drift.
there are several other advantages of studying streams of eve nts rather than
event logs. trends such as big data anddata science signify the spectacular
growth and omnipresence of data. typically, real event logs do not ﬁt main
memory. since we assume event streams to be potentially inﬁnite, an alysing
them enables us to handle event data of arbitrary size. in other ca ses we do not
have the time or are not allowed to access event data continuously a nd, hence,
need to analyse events at the moment they occur.
in this section we formalize event streams andevent stream based process
discovery . additionally we quantify high-level requirements for the design of
event stream based process discovery algorithms.
3.1 event streams
an event stream is a continuous stream of events executed in cont ext of an
underlying business process. we represent an event stream as a s equence of
pairs consisting of a case-identiﬁer and anactivity. hence, for each event we
know what activity was performed in context of what process insta nce. when
comparing event streams to event logs, we identify two main diﬀeren ces:1.)
an event stream is potentially inﬁniteand2.)behaviour seen for a case is
incomplete , i.e. in the future new events may be executed in context of a case.
deﬁnition 1 (event stream) letabe a set of activities and let cdenote
the set of all possible case identiﬁers. an event stream sis a sequence over
c×a, i.e.s ∈(c×a)∗.
a pair (c,a)∈c×arepresents an event, i.e. activity awas executed in
context of case c.s(1) denotes the ﬁrst event that we receive, whereas s(i)
denotes the ithevent. consider stream s1in fig. 3 as an example, where, event
(3,a4) is emitted ﬁrst ( s1(1) = (3,a4)), event (4 ,c1) is emitted second and event
(5,a1) is the eight and last event emitted onto the stream up until now . we
7receive multiple events related to the same case at diﬀerent points in time, e.g.
the second and seventh event on s1are related to case 4. hence, handling such
type of data needs new types of data structures and event proc essing techniques
compared to conventional process discovery.
3.2 process discovery
the goal of event stream based process discovery is to discover a process model
using an event stream as an input. a ﬁrst step is to approximate, ba sed ons,
the presence of some σ∈ pand possibly σ’s frequency w.r.t. s. given such
approximation the next step is to deploy a process discovery algorit hm onto the
approximation in order to obtain a process model.
a naive approach is to construct an event log based on the event st ream
by using a data structure that stores case-sequence pairs ( c,σ)∈c×a∗. for
everyevent ( c,a) we receive, we check whether the data structure contains entr y
(c,σ′). if so, we update this entry to ( c,σ′·/a\}bracketle{ta/a\}bracketri}ht). if not, we insert new entry ( c,
/a\}bracketle{ta/a\}bracketri}ht). whenever we want to discover a new process model based on the current
state of the event stream, we transform the data structure int o an event log
and provide it to any conventional process discovery algorithm. ob serve that,
since the stream is potentially inﬁnite, this procedure needs inﬁnite memory .
moreover, the approach includes redundancy , i.e. several (partial) traces that
where already analysed in a previous call to a discovery algorithm, an d are
still in memory at the next call, are analysed twice. hence, we want th e data
structure to either represent, or be easily translatable to, some minimal form of
data needed in order to discover a process model.
an example of an algorithm using a minimal data representation is the
ﬂower-miner . the ﬂower-miner produces a process model that allows for every
possible sequence over the observed activities. reconsider examp le stream s1
(fig. 3) which consists ofactivities labelled a1,a4,c1,c2,r1andr2. in fig. 4 we
depict a ﬂower model, in terms of a petri net [36], that allows for all a ctivities
ons1.
pa1a4
c1
c2 r1r2
figure 4: example “ﬂower”
model.to ensure that the ﬂower miner uses ﬁ-
nite memory, we just need to deploy any
ﬁnite memory based data structure that
keeps track of the activities seen on the
stream. a wide variety of such data struc-
tures exits, e.g. count-based frequent item
data structures [16], reservoirs [6,43] and
time-decay based models [17]. whenever
we receive a new event ( c,a) we just add a
to the data structure. translating the data
structure to a process model is trivial, i.e.
every activity present in the data-structure
is adopted in the ﬂower model.
the ﬂower miner works, yet it has deﬁciencies from a process discov ery
perspective. it generalizes the behaviour represented by the ev ent stream as
8much as possible. the resulting process model very likely allows for much more
behaviour than actually present in the underlying process. hence, we need
techniques that are more precise .
the event log based approach and the ﬂower miner represent two e xtremes.
storing the event stream as an event log requires us to reuse a larg e part of
the data several times. the ﬂower miner on the other hand neglect s a large
quantity of information carried by the event stream and greatly ov er-generalizes
the stream’s behaviour. we therefore need a scheme that is in the m iddle of
both extremes, i.e. it does not store the complete event log, yet it s tores enough
data to provide meaningful output.
4 the s-bar architecture
when analysing conventional process discovery algorithms, we obs erve that a
majority shares a common underlying algorithmic mechanism. the eve nt log
is transformed into an abstract representation , which is subsequently used to
construct a resulting process model. moreover, several algorith ms use the same
abstract representation. in 1 we illustrate the directly follows abstraction , used
by theα-miner[5].
example 1 (the directly follows abstraction & the α-miner) consider
event log l= [/a\}bracketle{ta,b,c,d/a\}bracketri}ht,/a\}bracketle{ta,c,b,d/a\}bracketri}ht]. theα-miner computes a directly follows
abstraction based on the event log. activity ais directly followed by b, written
asa > b, if there exists some sequence σ∈lof the form σ=σ′·/a\}bracketle{ta,b/a\}bracketri}ht·σ′′. in
case of event log lwe deduce a > b,a > c,b > c,b > d,c > b,c > d. using
these relations as a basis, the α-miner constructs a petri net.
as 1 shows, the event log is translated into a directly follows abstraction ,
which is subsequently used to construct a process model. other dis covery al-
gorithms like the inductive miner [30] and the ilp miner [48] use the same
mechanism to discover a process model. to adopt these algorithms to an event
stream context, it suﬃces to determine whether we are able to lear n the corre-
sponding abstract representation from the event stream and, if possible, design
a data structure that supports this.
in the remainder of this section we formalize the notion of abstract represen-
tations. subsequently we introduce the stream-based abstract representation
(s-bar) architecture that captures the notion of event stream based abstract
representation computation in a generic manner.
4.1 abstractrepresentations inconventional processdis-
covery
we reﬁne conventional process discovery by splitting γlinto two steps. in the
ﬁrst step, the event log is translated into the abstraction used by the discovery
algorithm. inthe secondstep, the abstractionistranslatedintoa processmodel.
in the remainder we let tdenote an abstract representation type. atdenotes
9event logl∈ ulλat
l
c1r1··· r2
a1···
c2···
directly follows abstractionγat
process model
figure 5: the α-miner in terms of its abstract representation.
an abstract representation of type tanduatdenotes the universe of abstract
representations of type t.
deﬁnition 2 (abstraction function - event log) lettdenote an abstract
representation type. anabstraction function λat
lis a function mapping an event
log to an abstract representation of type t.
λat
l:ul→ uat (1)
using 2, we deﬁne process discovery in terms of abstract represe ntations.
deﬁnition 3 (process discovery algorithm - abstract repres entation)
lettdenote an abstract representation type. an abstract repres entation based
process discovery algorithm γatmaps an abstract representation of type tto a
process model.
γat:uat→ um (2)
every discovery algorithm that uses an abstract representation internally
can be expressed as a composition of λat
landγat. thus, given event log
l∈ uland abstract representation type t, we obtain γl= (γat◦λat
l)(l).
for example, consider fig. 5 depicting the α-miner in terms of γatandλat
l.
4.2 abstract representations in event stream based pro-
cess discovery
in this section we present the s-bar architecture which captures the use of
abstract representations in an event stream context in a generic manner. in
fig. 6 the s-bar architecture is depicted schematically. the s-bar a rchitec-
ture conceptually splits event-stream-based process discovery into three compo-
nents, highlighted in gray in fig. 6. we explain the purpose of each com ponent,
i.e.δdt,λat
dtandγat, by means of an example.
consider maintaining the directly follows abstraction, introduced in 1 , on
a stream. to do this, we need a data structure that tracks the mo st recent
activity for each case. given such data structure, if we receive ne w event ( c,a),
we check whether we already received an activity a′for casecor whether ais
the ﬁrst activity received for case c. if we already received activity a′for case
c, we deduce a′> a. subsequently we update our data structure such that it
now assigns ato be the last activity received for case c.
10i
s(i)
dt
0
δdt1
(c1,a1)
dt
1
at
1
m12
(c2,a2)
dt
2
λat
dtat
2
m2...
...
...
...
...n
(cn,an)
dt
n
at
n
mn
γat...
...
...
...
...
figure 6: detailed overview of the s-bar architecture.
the ﬁrst component, i.e. δdt, maintains and updates a (collection of) data
structure(s) that together form a suﬃcient representation of the behaviour en-
tailed by the event stream. in context of our example, the ﬁrst co mponent is
mainly concerned with keeping track of pairs of activities that are in a a′> a
relation. the second component, i.e. λat
dt, translates the data structure to an
abstract representation. in context of our example, this consis ts of translating
the pairs of activities that are in a a′> arelation into the directly follows ab-
straction. the third component, i.e. γat, translatesthe abstractrepresentation
to a process model and is inherited from conventional process disc overy.
in the remainder, given an arbitrary data structure type t, we let udt
denote the universe of data structures of type t. a data type tmight refer
to an array or a (collection of) hash table(s), yet it might also refer to some
implementation of a stream-based frequent-item approximation alg orithm such
as lossy counting [33]. we assume any dt∈ udtto use ﬁnite memory.
deﬁnition 4 (data structure update function) letabe a set of activ-
ities and let cdenote the set of all possible case identiﬁers. we deﬁne a dat a
structure update function δdtas:
δdt:udt×c×a→ udt (3)
the data structure update function δdtallows us to update a given data
structure dt∈ udtbased on any newly arrived event. in practice the function
typically consists of two components. one component keeps track of the cases
that were already active before and maps them in some way to a seco nd (col-
lection of) data structure(s). such second component allows us t o construct the
abstract representation. thus, when abstracting this mechanis m, given some
event stream based data structure, we need a mechanism to tran slate the data
structure, i.e. the range of δdt, to an abstract representation.
11deﬁnition 5 (abstraction function - data structure) an abstraction func-
tionλat
dtis a function mapping a data structure of type tto an abstract repre-
sentation of type t.
λat
dt:udt→ uat (4)
ideally, translating the data structure is computationally inexpens ive. however,
in some cases translating the data structure to the intended abst ract represen-
tation might be expensive. this is acceptable, as long as we (re)-com pute the
abstraction in a periodic fashion or at the user’s request.
assume that we have seen i≥0 events on an event stream sand letdt
i∈
udtdenote the data structure that approximates the behaviour in th e event
streamsafter receiving ievents. when new event ( c,a)∈c×aarrives, we are
ableto discovera new processmodel mi+1by applying( γat◦λat
dt◦δdt)(dt
i,c,
a). in practice, δdtis applied continuously and whenever, after receiving a new
ithevent, weareinterestedin ﬁndingaprocessmodelweapply( γat◦λat
dt)(dt
i)
to obtain the process model.
the main challenge in instantiating the framework is designing a data st ruc-
turedt∈ udtthat allows us to approximate an abstract representation to-
gether with accompanying δdtandλat
dtfunctions.
5 instantiating s-bar
in this section, we show the applicability of the s-bar frameworkby p resenting
severalinstantiations for diﬀerent existing processdiscoveryalg orithms. a large
class of algorithms, e.g. the α-miner [5], the heuristics miner [45,47] and the
inductive miner [30], is based on the directly follows abstraction.ther efore, we
ﬁrst present how to compute this abstraction. subsequently we h ighlight, for
eachalgorithmusingthedirectlyfollowsabstractionasabasis, them ainchanges
and/or extensions that need to be applied w.r.t. the basic scheme. t o illustrate
the generality of the architecture, we also show a completely diﬀere nt class of
discoveryapproaches,i.e. region-basedtechniques[4,48]. thes etechniqueswork
fundamentally diﬀerent compared to the aforementioned class of a lgorithms and
use diﬀerent abstract representations.
5.1 directly follows abstraction
thedirectly follows abstraction describes pairs of activities ( a,b), written as
a > b, if there exists some sequence σ∈lof the form σ=σ′· /a\}bracketle{ta,b/a\}bracketri}ht ·σ′′.
to approximate the relation, we let data structure dt∈ udtconsist of two
internal data structures dcandda. within dcwe store (case,activity)-pairs,
i.e. (c,a)∈c×a, that represent the last activity aseen for case c. within da
we store (activity, activity)-pairs ( a,a′)∈a×a, where ( a,a′)∈ da⇔a > a′.
the basic scheme works as follows. when a new event ( c,a) arrives, we check
whether dcalready contains some pair ( c,a′). if so, we add ( a′,a) toda,
remove ( c,a′) fromdcand add ( c,a) todc. if not, we just add ( c,a) todc.
12algorithm 1: dc(space saving)
input : k∈n,s∈(c×a)∗,da
begin
1x←∅;i←0;
2whiletruedo
3 i←i+ 1;
4 (c,a)← s(i);
5 if∃(c′,a′)∈x(c′=c)then
6 vc←vc+ 1;
7da⊎{(a′,a)};
8 x←(x∪{(c,a)})\{(c,a′)};
9 else if|x|< kthen
10 x←x∪{(c,a)};
11 vc←1;
12 else
13 (c′,a′)←argmin
(c′,a′)∈x(vc′);
14 vc←vc′+ 1;
15 x←(x∪{(c,a)})\{(c′,
a′)};algorithm 2: dc(lossy)
input : k∈n,s∈(c×a)∗,da
begin
1i,∆←0;x←∅;
2whiletruedo
3 i←i+ 1;
4 (c,a)← s(i);
5 if∃(c′,a′)∈x(c′=c)then
6 vc←vc+ 1;
7da⊎{(a′,a)};
8 x←(x∪{(c,a)})\{(c,a′)};
9 else
10 x←x∪{(c,a)};
11 vc←∆;
12 if⌊i/k⌋/\e}atio\slash= ∆then
13 foreach (c′,a′)∈xdo
14 ifvc′≤∆then
15 x←x\(c′,a′);
16 ∆←⌊i/k⌋;
darepresents the directly follows abstraction by means of a collection of pairs,
thus, function λat
dtconsists of translating dato the appropriate underlying
data type used by the discovery algorithm of choice.
as an example consider algorithm 1 and algorithm 2 describing a design o f
dcbased on the spacesaving algorithm [35] and lossy counting [33] re spec-
tively. both algorithms have three inputs, i.e. a maximum size k∈n, an event
streams ∈(c×a)∗and a ﬁnite memory data structure implementing da. the
algorithms maintain a set of (case,activity)-pairs x, initialized to ∅(line 1). for
each case cpresent in xan associated counter vcis maintained which is used for
memory management. when a new event ( c,a) appears on the event stream,
the algorithms check whether some pair ( c′,a′) s.t.c=c′is stored in x(line 5).
if this is the case, c’s counter is increased, ( a′,a) is added to data structure da
and (c,a′) is replaced by ( c,a) inx(lines 6-8). the algorithms diﬀer in the way
they process events ( c,a) for which ∄(c′,a′)∈x(c′=c). the space saving based
algorithm (algorithm 1) either adds the element to xif|x|< kor replaces
pair (c′,a′)∈xwith the lowest correspondingcounter ( vc′) value (algorithm 1,
lines 9-15). the lossy counting based algorithm cleans up its x-set after each
block of kconsecutive events and removes all those entries that have a cou nter
value lower than variable ∆ (lines 9-16).
both algorithms insert a new element in data structure dain line 7. con-
ceptually, the algorithms generate a stream of (activity, activity) -pairs. hence,
in algorithm 3 we present a basic design for dabased on the frequent algo-
rithm [18,28] which uses an activity pair stream sa∈(a×a)∗as an input.
thus,da⊎{(a′,a)}in line 7 ofalgorithms 1 and 2 representsadding pair( a,a′)
at the end of stream sa.
the algorithm stores pairs of activities in its internal set x. whenever a
13new pair ( a,a′) arrives, the algorithm checks if it is already present in x, if so,
it updates the corresponding counter v(a,a′). if the pair is not yet present in x,
the size of xis evaluated. if |x|< kthe new pair is added to xand a new
counter is created for the pair. if |x| ≥kthe new pair is not added, moreover,
each counter is decreased by one and if a counter gets value 0 the c orresponding
pair is removed.
algorithm 3: da(frequent)
input : k∈n,sa∈(a×a)∗
begin
1x←∅,i←0;
2whiletruedo
3 i←i+ 1;
4 (a,a′)← sa(i);
5 if(a,a′)∈xthen
6 v(a,a′)←v(a,a′)+ 1;
7 else if|x|< kthen
8 x←x∪{(a,a′)};
9 v(a,a′)←1;
10 else
11 foreach (x,y)∈xdo
12 v(x,y)←v(x,y)−1;
13 ifv(x,y)= 0then
14 x←x\{(x,y)};thegeneralmechanismofalgorithm 3
is very similar to algorithm 1. the
main diﬀerence consists of how to up-
datexwhen|x| ≥k. all three algo-
rithms use a parameter kwhich, in a
way, represents the (maximum) size
ofx. hence, when we write |dc|,
|da|respectively, we implicitly refer
to the value of k. it should be clear
that we are also able to implement
dcbased on the frequent algorithm,
i.e. we just adopt a diﬀerent updat-
ing mechanism for x. likewise we
are also able to design dabased on
the space saving/lossy counting al-
gorithm. moreover, for dcwe are
able to use other types of stream-
aware data structures, i.e. techniques
adopting a diﬀerent scheme to ensure ﬁnite memory. examples of su ch types
of techniques are reservoir sampling [6], and/or decay based sche mes [17].
in the next sections we brieﬂy explain how the α-miner, heuristics miner and
inductive miner use the directly follows abstraction and what chang es to the
base scheme must be applied in order to adopt them in a streaming set ting.
5.1.1 the α-miner
theα-miner [5] transforms the directly follows abstraction into a petri n et.
when adopting the α-miner to an event stream context, we directly adopt the
scheme described in the previous section. however, the algorithm e xplicitly
needs a set of start-andend activities .
approximating the start activities seems rather simple, i.e. wheneve r we
receive a new case, the corresponding activity represents a star t activity. how-
ever,giventhatweatsomepointremove(case,activity)-pairsfro mdc, wemight
designate some activities falsely as start activities, i.e. a new case ma y in fact
refer to a previously removed case. approximating the end activitie s is more
complex, as we areoften not awarewhen a caseterminates. a pote ntial solution
is to apply a warm-up period in which we try to observe cases that seem to be
terminated, e.g. by identifying cases that have long periods of inact ivity or by
assuming that cases that are dropped out of dcare terminated. however, since
we approximate case termination, using this approach may lead to fa lsely select
14certain activities as end activities.
we can also deduce start- and end activities from the directly follows ab-
straction. a start activity is an a∈awith∄a′∈a(a′/\e}atio\slash=a|a′> a) and an end
activity is an a∈awith∄a′∈a(a′/\e}atio\slash=a|a > a′). this works if these activities
are only executed once at the beginning, respectively the end, of t he process. in
case of loops or multiple executions of start/end activities within the process,
we potentially falsely neglect certain activities as being either start a nd/or end
activities. in section 8.2, we discuss this problem in depth.
5.1.2 the heuristics miner
the heuristics miner [45,46,47] is designed to cope with noise in event logs. to
do this, it eﬀectively counts the number of occurrences of activitie s, as well as
the>-relation. based on the directly follows abstraction it computes a de rived
metrica⇒b=|a>b|−|b>a|
|a>b|+|b>a|+1that describes the relative causality between two
tasksaandb(|a > b|denotes the number of occurrences of a > b). the basic
scheme presented in section 5.1 suﬃces for computing a⇒b, as long as da
explicitly tracks,or, approximates,the frequencies ofits element s (in the scheme
this is achieved by the internal counters).
5.1.3 the inductive miner
the inductive miner [30], like the α-miner, uses the directly follows abstraction
and start and end activities. it tries to ﬁnd patterns within the dire ctly fol-
lows abstraction that indicate certain behaviour, e.g. parallelism. us ing these
patterns it splits the event log into several smaller logs and repeats the proce-
dure. due to its iterative nature, the inductive miner guarantees to ﬁndsound
workﬂow nets [1]. the inductive miner has also been extended to handle noise
and/or infrequent behaviour [29]. this requires, like the heuristics miner, to
count the >-relation. in [31], a version of the inductive miner is presented in
which the inductive steps are directly performed on the directly follo ws abstrac-
tion. in context of event streams this is the most adequate versio n to use as we
only need to maintain a (counted) directly follows abstraction.
5.2 region theory
several process discovery algorithms [4,9,15,48,50] are based onregion theory
which solve the petri net synthesis problem [8]. classical region theo ry tech-
niques ensure strict formal properties for the resulting process models. process
discovery algorithms based on region theory relax these propertie s. we iden-
tify two diﬀerent region theory approaches, i.e. language-based andstate-based
region theory, which use diﬀerent forms of abstract representa tions.
5.2.1 language-based approaches
algorithms based on language-based region theory [9,48] rely on a preﬁx-closure
ofthe input event log, i.e. the set ofallpreﬁxes ofall traces. it ist rivial toadapt
15the scheme presented to compute the directly follows abstraction (section 5.1)
to preﬁx-closures. in stead of storing (case,activity)-pairs in dc, we store pairs
(c,σ)∈c×a∗. we additionally use a data structure dpcwhich approximates
the preﬁx-closure. whenever we receive an event ( c,a), we look for a pair ( c,
σ)∈ dc. if such pair exist we subsequently add σ′=σ·/a\}bracketle{ta/a\}bracketri}httodpcand update
(c,σ) to (c,σ′). if there is no such pair ( c,σ), we add ǫand/a\}bracketle{ta/a\}bracketri}httodpcand
(c,/a\}bracketle{ta/a\}bracketri}ht) todc. in case of [48], which uses integer linear programming where
(an abstraction of) the preﬁx-closureforms the constraint bod y, we simply store
the constraints in dpc, rather than the preﬁx-closure.
5.2.2 state-based approaches
within process discovery based on state-based regions [4], a tran sition system
is constructed based on a viewof a trace. examples of a view are the complete
preﬁx of the trace, the multiset projection of the preﬁx, etc. th efuture of a
tracecan be used as well, i.e. given an event within a trace, the future of th e
event are all events happening after the event. however, futur e-based views are
not applicable in an event stream setting, as the future is unknown.
as an example of a transition system based on a simple event log l= [/a\}bracketle{ta,b,
c,d/a\}bracketri}ht,/a\}bracketle{ta,c,b,d/a\}bracketri}ht], consider fig. 7. in fig. 7a states are represented by a multiset
view of the preﬁxes of the traces, i.e. the state is determined by th e multiset
of activities seen before. activities make up the transitions within th e system,
i.e. the ﬁrst activity in both traces is a, thus the empty multiset is connected
to multiset [ a] by means of a transition labelled a. in fig. 7a we do not limit
the maximum size of the multisets. fig. 7b shows a set view of the trac es with
a maximum set size of 1. again the empty set is connected with set {a}by
means of a transition labelled a. for trace /a\}bracketle{ta,b,c,d/a\}bracketri}htfor example, the second
activity is a band thus state {a}has an outgoing transition labelled bto state
{b}. this is the case, i.e. a connection to state {b}rather than {a,b}, due to
the size restriction of size 1.
considerthefollowingscheme,similartotheschemepresentedinsec tion 5.1.
s0: [ ]
s1: [a]
s2: [a,b] s3: [a,c]
s4: [a,b,c]
s5: [a,b,c,d ]a
bc
cb
d
(a) multiset abstraction (unbounded).s0:∅
s1:{a}
s2:{b} s3:{c}
s4:{d}a
bc
cb
d d
(b) set abstraction (max. set size 1).
figure 7: example transition systems based on l= [/a\}bracketle{ta,b,c,d/a\}bracketri}ht,/a\}bracketle{ta,c,b,d/a\}bracketri}ht].
16given a view type v, e.g. a set view, we design dcto maintain pairs ( c,vc), s.t.
vcis the last view constructed for case c. moreover, we maintain a collection of
viewsdv. updating dvis straightforward. given new event ( c,a), based on
vcwe compute some new view v′
c, add it to dvand update ( c,vc) to (c,v′
c) in
dc, e.g. updating the size-1 set view means that the new view based on n ew
event (c,a) is simply the set {a}. however, just maintaining size-1 sets in dv
does not suﬃce as the relations between those sets, i.e. the trans itions in the
transition system, are not present in dv.
the problem is ﬁxed by maintaining the transition system in memory, ra ther
thandv, and updating it directly when we receive new events. given some
latestview vcforcasec, i.e. (c,vc)∈ dc, activity aofnew event( c,a) represents
the transition from vcto the newly derived v′
c. without a limit on the view-
size, translating the transition system into a petri net is rather slo w. hence,
in a streaming setting we limit the maximum size of the views. this, in turn ,
causes some challenges w.r.t. dcand translation function λat
dt. consider the
case where we maintain a multiset/set view of traces with some arbitr ary ﬁnite
capacity k. moreover, given k= 2, assume we receive event ( c,a) and (c,{a′,
a′′})∈ dc. the question is whether the new view for cis{a,a′}or{a,a′′}?
only if we store the last two events observed for c, in order, we are able to
answer this question, i.e. if ( c,/a\}bracketle{ta′,a′′/a\}bracketri}ht)∈ dcwe deduce the new view to be
{a,a′′}. finally note, that when we aim at removing paths from the transition s
system, for example when we remove cases from cfromdc, we need to store the
whole trace for cin order to be able to reduce all states and transitions related
to casec.
6 evaluation
in this section we present an evaluation of several instantiations o f the archi-
tecture. we also consider performance aspects of the implementa tion. all ﬁve
algorithms, i.e. α-miner, heuristics miner, inductive miner, ilp (language
based regions) and transition system miner (state based regions) , have been
implemented using the schemes presented in section 5 in the prom [19] frame-
work (http://www.promtools.org ). prom is the de facto standard academic
tool-kit for process mining algorithms and is additionally used by pract ition-
ers in the ﬁeld. some of the implementations are ported to rapidprom [3]
(http://www.rapidprom.org ), i.e. apluginofrapidminer( http://www.rapidminer.com ),
which allows for designing large-scale repetitive experiments by mean s of sci-
entiﬁc workﬂows [10]. source code of the implementations is available v ia the
stream-related packages within the prom code base, i.e. streamabstractrepre-
sentation ,streamalphaminer ,streamheuristicsminer ,streamilpminer ,strea-
minductiveminer andstreamtransitionsystemsminer (code for a package x
is located at http://svn.win.tue.nl/repos/prom/packages/x ). experiment
results, event streams and generating process models used, are available at
https://github.com/s-j-v-zelst/research/releases/do wnload/kais1/2016_kais1_experiments.tar.g
17figure 8: visual results of applying the inductive miner on a stream.
6.1 structural analysis
as a ﬁrst visual experiment we investigate the steady-state beha viour of the
inductive miner [30]. for both dcanddawe use the lossy counting scheme
(section 5.1). to create an event stream, we created a timed colou red petri
net [26] in cpn-tools [27] which simulates the bpmn model depicted in fig . 2
and emits the corresponding events. the event stream, and all ot her event
streams used for experiments, are free of noise. the model is able to simu-
late multiple cases being executed simultaneously. the prom streamin g frame-
work [49,51] is used to generate an event stream out of the proce ss model.
in fig. 8 we show the behaviour ofthe inductive miner overtime, con ﬁgured
with|dc|= 75,|da|= 75, based on a random simulation of the cpn model.
initially (model 1) the inductive miner only observes a few directly fo llows re-
lations, all executed in sequence. after a while (model 2) the induc tive miner
observes that there is a choice between prepare acceptance pack andreject ap-
plication. in model 3, the ﬁrst signs of parallel behaviour of activities appraise
property,check credit history andassess loan risk become apparent. however,
not enough behaviour is emitted onto the stream to eﬀectively obse rve the par-
allel behaviour yet. in model 4, we identify a large block of activities w ithin a
18choice construct. moreover, an invisible transition loops back into t his block.
the inductive miner tends to show this type of behaviour given an inc omplete
directly follows abstraction. finally, after enough behaviour is emitt ed onto the
stream, model 5 shows a petri net version of example process mod el of fig. 2.
fig. 8 shows that the inductive miner is able to ﬁnd the original model
based on the event stream. we now focus on comparing the induct ive miner
with other algorithms described in the paper. all discovery techniqu es discover
a petri net or some alternative process model that we can convert to a petri net.
the techniques howeverdiﬀer in terms of guaranteesw.r.t. the res ulting process
model. the inductive miner guarantees that the resulting petri ne ts aresound,
whereasthe ilpminer andthe transitionsystem minerdonotneces sarilyyield
sound process models. to perform a proper behavioural compara tive analysis,
the soundness property is often a prerequisite. hence, we perfo rm a structural
analysis of all the algorithms by measuring structural properties o f the resulting
petri nets.
using the oﬀ-line variantofeachalgorithmwe ﬁrstcompute a refere ncepetri
net. wegeneratedaneventlog lwhichcontains enough behaviour suchthat the
discoveredpetrinetsdescribeallbehaviourofthebpmnmodelof fig. 2. based
onthe referencepetrinet wecreatea 15-by-15matrixin whichea chrow/column
correspondsto an activity in the bpmn model. if, in the petri net, t wo labelled
transitions are connected by means of a place, the corresponding cells in the
matrix get value 1. for example, given the ﬁrst petri net of fig. 8, t he labels
startandcheckapplication completeness (in the ﬁgure this is “check appl”)
are connected by means of a place. hence, the distance between t he two labels
is set to 1 in the corresponding matrix. if two transitions are not co nnected,
the corresponding value is set to 0.
using an event stream based on the cpn-model, after each newly re ceived
event, we use each algorithm to discover a petri net. for each pet ri net we
construct the 15-by-15 matrix. we apply the same procedure as a pplied on
the reference model. however, if in a discovered petri net a certa in label is
not present, we set all cells in the corresponding row/column to −1, e.g. in
model 1 of fig. 8 there is no transition labelled end, thus the corresponding row
and column consist of −1 values. given a matrix mbased on the streaming
variant of an algorithm, we compute the distance to the reference matrixmr
as:dm,mr=/radicalbig/summationtext
i,j∈{1,2,...,15}((m(i,j)−mr(i,j))2. for all algorithms, the
internal data structures used where based on lossy counting, w ith size 100.
since the inductive miner and the α-miner are completely based on the
same abstraction, we expect them to behave similar. hence, we plot their
corresponding results together in fig. 9a. interestingly, the dist ance metric
follows the same pattern for both algorithms. initially, there is a ste ep decline
inthedistancemetricafterwhichitbecomeszero. thismeansthatt hereference
matrix equals the matrix based on the discovered petri net. the dis tance shows
some peaks in the area between 400 until 1000 received events. an alyzing
the resulting petri nets at these points in time showed that some ac tivities
where not present in the resulting petri nets at those points. the results for
190 500 1000 1500 2000 25000 5 10 15
eventsdistancealpha
inductive
(a) distances for αand im0 500 1000 1500 2000 25000 5 10 15
eventsdistancets
ilp
heuristics
(b) distances for ts, ilp and hm.
figure 9: distance measurements for the α-miner, inductive miner (im), ilp
miner (ilp), transition systems miner (ts) and heuristics miner.
the transition systems miner (ts), the ilp miner and the heuristics miner
are depicted in fig. 9b. we observe that the algorithms behave similar to the
α- and inductive miner, which intuitively makes sense as the algorithms all
have the same data structure capacity. however, the peeks in th e distance
metric occur at diﬀerent locations. for the heuristics miner this is ex plained
by the fact that it takes frequency into account and thus uses th e directly
follows abstraction diﬀerently. the transition system miner and the ilp miner
use diﬀerent abstract representations, and have a diﬀerent upd ate mechanism
than the directly follows abstraction, i.e. they always update their a bstraction
whereas the directly follows abstraction only updates if, for a given case, we
already received a preceding activity.
6.2 behavioral analysis
although the previous experiments provide interesting insights w.r.t . the func-
tioning of the algorithms in a streaming setting, they only consider st ructural
model quality. a distance value of 0 in fig. 9 indicates that the resultin g model
is very similar to the reference model. it does not guaranteethat t he model is in
fact equal, or, entails the same behaviour as the reference model. hence, in this
section we focus on measuring quantiﬁable similarity in terms of behaviour . we
use the inductive miner asit providesformalguaranteesw.r.t. initia lization and
termination of the resulting process models. this in particular is a req uirement
to measure behavioural similarity in a reliable manner. we adapt the in ductive
miner to a streaming setting by instantiating the s-bar framework, using the
scheme described in section 5.1, combined with the modiﬁcations desc ribed in
section 5.1.3. for ﬁnding start and end activities we traverse the dir ectly fol-
lows abstraction and select activities that have no predecessor, o r, successor,
respectively. we again use lossy counting [33] to implement both dcandda
(algorithm 2, section 5.1).
we assess under what conditions the inductive miner instantiation is able
to discover a process model with the same behaviour as the bpmn mo del in
fig. 2. in the experiment, after each received event, we query th e miner for
200 5000 10000 15000 20000 250000.0 0.4 0.8
eventsreplay fitness
(a)|dc|= 25,|da|= 250 5000 10000 15000 20000 250000.0 0.4 0.8
eventsreplay fitness
(b)|dc|= 75,|da|= 75
0 5000 10000 15000 20000 250000.0 0.4 0.8
eventsprecision
(c)|dc|= 25,|da|= 250 5000 10000 15000 20000 250000.0 0.4 0.8
eventsprecision
(d)|dc|= 75,|da|= 75
figure 10: replay ﬁtness and precision measures based on applying t he stream
inductive miner: increasing memory helps to improve ﬁtness and pr ecision.
its current result and compute replay ﬁtness and precision measur es based on
a complete corresponding event log. in fig. 10 the results are pres ented for
varying capacity sizes of the underlying data structure (lossy co unting).
forthesmallestdatastructuresizes, i.e. fig. 10a, weidentifythat thereplay
ﬁtness does not stabilize. when the data structure size increases , i.e. fig. 10b,
we identify the replay ﬁtness to reach a value of 1 rapidly. the high va riability
in the precision measurements present in fig. 10c suggests that th e algorithm is
not capable of storing the complete directly follows abstraction. as a result, the
inductive miner tends to create ﬂower-like patterns, thus great ly under-ﬁtting
the actual process. the stable pattern present in fig. 10d sugge st that the sizes
used within the experiment are suﬃcient to store the complete direc tly follows
abstraction. given that the generating process model is within the class ofre-
discoverable process models of the inductive miner, both a replay ﬁtness and
a precision value of 1 indicates that the model is completely discovere d by the
algorithm.
in the previous experimental setting, we chose to use the same ca pacity for
bothdcandda. here we study the inﬂuence of the individual sizes of dcand
da. in fig. 11 we depict the results of two diﬀerent experiments in which we
ﬁxed the size of one of the two data structures and varied the size of the other
data structure. fig. 11a depicts the results for a ﬁxed value |dc|= 100 and
varying sizes |da|= 10,20,...,50. fig. 11b depicts the results for a ﬁxed value
|da|= 100 and varying sizes |dc|= 10,20,...,50. as the results show, the lack
of conversionto a replay ﬁtness value of 1 mostly depends on the siz e ofdaand
210 2000 6000 10000−0.2 0.4 0.8
eventsreplay fitness100x10
100x20100x30
100x40100x50
(a)|dc|= 100,|da|= 10,20...,500 2000 6000 100000.0 0.4 0.8
eventsreplay fitness100x10
100x20100x30
100x40100x50
(b)|dc|= 10,20,...,50,|da|= 100
figure 11: replay fitness measures for the stream inductive miner .
is relatively independent of the size of dc. intuitively this makes sense as we
only need one entry ( c,a)∈ dcto deduce a > b, given that the newly received
event is ( c,b). even if case cis dropped at some point in time, and reinserted
later, still informationregardingthe directlyfollowsabstractionca nbe deduced.
however, if not enough space is reserved for the dadata structure, then the
data structure is incapable of storing the complete directly follows a bstraction.
6.3 concept drift
in the previous experiments we focused on a process model that d escribes ob-
servedsteady state behaviour, i.e. the process model from which events are
sampled does not change during the experiments. in this section we assess to
what extend the inductive miner based instantiation of the framew ork is able
to handle concept drift [11,42]. we focus on gradual drift , i.e. the behaviour
of the process model changes at some point in time, though the cha nge is only
applicable for new cases, already active cases follow the old behaviou r. in order
to obtain a gradual drift, we manipulated the cpn simulation model of the pro-
cess model presented in fig. 2. the ﬁrst ﬁve hundred cases that a re simulated
follow the original model. all later cases are routed to a model in which we
swap the parallel and choice structures within the model (fig. 12).
fig. 13 depicts the results of applying the inductive miner on the des cribed
gradual drift. in fig. 13a we depict the results using data structu re sizes|dc|=
100 and |da|= 50 (lossy counting). the blue solid line depicts the replay
ﬁtness w.r.t. an event log containing behaviour priorto the drift, the red
dashed line represents replay ﬁtness w.r.t. an event log containing b ehaviour
afterthe drift. we observethat the algorithmagainneeds sometime tost abilize
in terms of behaviour w.r.t. the pre-drift model. interestingly, at t he moment
that the algorithm seems to be stabilized w.r.t. the pre-drift model, t he replay
ﬁtness w.r.t. the post-drift model ﬂuctuates. this indicates that the algorithm
is not able to fully rediscover the pre-drift model, yet it produces a g eneralizing
model which includes more behaviour, i.e. even behaviour that is part of the
post-drift model. the ﬁrst event in the stream related to the new e xecution
of the process, is the 6 .415thevent. indeed, the blue solid line drops around
22(a) parallel to choice.
 (b) choice to parallel.
figure 12: changes made to the business process model presente d in fig. 2.
0 5000 15000 25000 350000.0 0.4 0.8
eventsreplay fitnessbefore
after
(a)|dc|= 100,|da|= 500 5000 15000 25000 350000.0 0.4 0.8
eventsreplay fitnessbefore
after
(b)|dc|= 100,|da|= 100
figure 13: replay fitness measures for the stream inductive miner , given an
event stream containing concept drift.
this point in fig. 13a. likewise, the red dashed line rapidly increase to v alue
1.0. finally, around event 15 .000 the replay ﬁtness w.r.t. the pre-drift model
stabilizescompletely, indicatingthat the priorknowledgerelatedto t he pre-drift
model is completely erased from the underlying data structure. in fig. 13b we
depict results for the inductive miner using sizes |dc|= 100 and |da|= 100. in
this case we observe more stable behaviour, i.e. both the pre- and p ost-model
behaviour stabilizes quickly. interestingly, due to the use of a bigge rk-value of
the lossy counting algorithm, the drift is reﬂected longer in the rep lay ﬁtness
values. only after roughly the 30 .000thevent the replay ﬁtness w.r.t. the pre-
drift model stabilizes.
6.4 performance analysis
the main goal of the performance evaluation is to assess whether m emory usage
and processing times of the implementations are acceptable. as the implemen-
tations are of a prototypical fashion, we focus on trendsin processing time and
230 5000 10000 15000 20000 250000 60000
eventsnano seconds25x25 50x50 75x75
(a) processing times in nanoseconds.0 5000 10000 15000 20000 250000 40000bytes
events25x25 50x50 75x75
(b) memory usage in bytes.
figure 14: performance measurements based on the stream indu ctive miner.
table 2: aggregate performance measures for the stream induc tive miner.
25x25 50x50 75x75
avg. processing time (ns.): 4.7167,77 3.866,45 3.519,22
stdev. processing time (ns.): 3.245,80 2.588,76 2.690,54
avg. memory usage (byte): 75.391,75 81.013,60 84.695,86
stdev. memory usage (byte): 762,55 1.229,60 1724,98
memoryusage, ratherthan absoluteperformancemeasures. fo rboth processing
time and memory usage, we expect stabilizing behaviour, i.e. over time we ex-
pect to observe some non-increasing asymptote. if the process ing time/memory
usage keeps increasing over time this implies that we are potentially un able to
handle data on the stream or need inﬁnite memory.
within the experiment we measured the processing time and memory u sage
for handling the ﬁrst 25.000 events emitted onto the stream. we ag ain use
the inductive miner with lossy counting and varying window sizes (pa rameter
k):|dc|= 25 and |da|= 25,|dc|= 50 and |da|= 50 and |dc|= 75,
|da|= 75 (represented in the figures as 25x25, 50x50 and 75x75 respe ctively).
we measured the time the algorithm needs to update both dcandda. the
memory measured is the combined size of dcanddain bytes. the results of
the experiments are depicted in fig. 14. both ﬁgures depict the tot al number of
events received on the x-axis. in fig. 14a, the processing time in na noseconds is
shownonthe y-axis, whereasin fig. 14b, the memoryusagein bytes is depicted.
the aggregates of the experiments are depicted in table 2.
as fig. 14a shows, there is no observable increase in processing time s as
more events have been processed. the average processing time s eems to slightly
decrease when the window size of the lossy counting data structu re increases
(see table 2). intuitively this makes sense as a bigger window size of t he lossy
counting algorithm implies less frequent cleanup operations.
like processing time, memory usage of the lossy counting data str uctures
does not show an increasing trend (fig. 14b). in this case however , memory
usage seems to increase when the window size of the lossy counting algorithm
24is bigger. again this makes sense, as less cleanup operations implies mo re active
members within the data structures, and hence, a higher memory u sage.
7 related work
for a detailed overview of process mining we refer to [2]. for an overv iew of
models, techniques and algorithms in stream based mining and analysis , e.g.
frequency approximation algorithms, we refer to [7,23,37]. little w ork has been
done on the topic of stream-based process discovery, and, stre am-based process
mining in general. the notion of streams of events is not new, i.e. several ﬁelds
study aspects related to streams of (discrete) events. compar ed to the ﬁeld of
complex event processing (cep) [22], the s-bar architecture can b e seen as
anevent consumer , i.e. a decoupled entity that processes the events produced
by the underlying system. however, whereas the premise of cep is t owards
thedesignof event based systems and architectures, this work focuses on the
behavioural analysis of such systems. the area of event mining [32], focuses
on gaining knowledge from historical event/log data. although the in put data
is similar, i.e. streams of system events, the assumptions on the dat a source
are diﬀerent. within event mining, data mining techniques such as pattern
mining[32, chpt. 4] are used as opposed to techniques used within this pap er,
i.e. techniques discovering end-to-end process models with associa ted execution
semantics. also, event mining includes methods for system monitorin g, whereas
the s-bar architecture can serve as an enabler for business proc ess monitoring
and prediction.
to the best of the author’s knowledge this paper is the ﬁrst work th at
presents a generic architecture for the purpose of event strea m based process
discovery. as such the work may be regarded as a generalization an d standard-
ization eﬀort of some of the related work mentioned within this sectio n.
in [14] an event stream based variant of the heuristics miner is pres ented.
thealgorithmusesthreeinternaldatastructuresusingbothlos sycounting[33]
and lossy counting with budget [41]. the authors use these struc tures to
approximatea causalgraph based on an event stream. the autho rs additionally
presentaslidingwindowbasedapproach. recentlyanalternativeda tastructure
has been proposed based on preﬁx-trees [25]. in this work the aut hors deduce
the directly follows abstractiondirectly from a preﬁx tree which is ma intained in
memory. the main advantage of using the preﬁx-trees is the reduc ed processing
time and usage of memory. in [40], redlich et al. design an event strea m based
variant of the ccm algorithm [39]. the authors identify the need to co mpute
dynamic footprint information based on the event stream, which ca n be seen as
the abstract representation used by ccm. the dynamic footprint is translated
to a process model using a translation step called footprint interpretation . the
authors additionally apply an ageing factor to the collected trace inf ormation
to fade out the behaviour extracted from older traces. although the authors
deﬁne event streams similarly to this paper the evaluation relies heav ily on the
concept of completed traces . in [13] burattin et al. propose an event stream
25based process discovery algorithm to discover declarative proces s models. the
structure described to maintain events and their relation to cases is comparable
with the one used in [14]. the authors present several declarative c onstraints
that can be updated on the basis of newly arriving events instead of an event
log consisting of full traces.
8 discussion
in this section we discuss interesting phenomena observed during e xperimenta-
tion which should be taken into account when adopting the architect ure pre-
sented in this paper, and, in event stream based process discover y in general.
wediscusslimitationsw.r.t. thecomplexityofabstractrepresentat ioncomputa-
tion anddiscuss the impact ofthe absenceoftraceinitialization andt ermination
information.
8.1 complexity of abstract representation computation
there are limitations w.r.t. the algorithms we are able to adopt using ab stract
representations as basis. this is mainly related to the computation o f the ab-
stract representation within the conventional algorithm.
as an example, consider the α+-algorithm [34] which extends the original α-
miner such that it is able to handle self-loops and length-1-loops. for handling
self-loops, the α+-algorithm traverses the event log and identiﬁes activities that
are within a self-loop. subsequently it removes these from the log an d after
that calculates the directly follows abstraction. for example, if l= [/a\}bracketle{ta,b,c/a\}bracketri}ht,/a\}bracketle{ta,
b,b,c/a\}bracketri}ht], the algorithm will construct l′= [/a\}bracketle{ta,c/a\}bracketri}ht] and compute directly follows
metrics based on l′.
in a streaming setting we are able to handle this as follows. whenever we
observe some activity ato be in a self-loop and want to generate the directly
follows abstraction, then for every ( a′,a)∈ daand (a,a′′)∈ da, s.t.a/\e}atio\slash=a′
anda/\e}atio\slash=a′′, we deduce that ( a′,a′′) is part of the directly follows abstraction
whereas( a,a), (a′,a)and(a,a′′) arenot. although thisprocedureapproximates
the directly follows relation on the event stream, a simple example sho ws that
the relation is not always equal.
a c
ed
(a) event loga c
ed
(b) event stream
figure 15: two abstract representa-
tions.imagine a process p={/a\}bracketle{ta,b,b,
c/a\}bracketri}ht,/a\}bracketle{ta,e,b,d/a\}bracketri}ht}. clearly any noise-free
event log over this process is just
a multi-set over the two traces in
p. in case of the conventional α+-
algorithm, removing the b-activity
leads to the two traces /a\}bracketle{ta,c/a\}bracketri}htand/a\}bracketle{ta,
e,d/a\}bracketri}ht. consider the corresponding di-
rectly follows abstraction, depicted in
fig. 15a. observethat allpossible di-
rectlyfollowspairsthat weareableto
26observe on any stream over pare: (a,b),(a,e),(b,b),(b,c),(b,d),(e,b). apply-
ing the described procedure yields the abstraction depicted in fig. 1 5b. due
to the information that is lost by only maintaining directly follows pairs, we
deduce non-existing relations ( a,d) and (e,c).
in general it is preferable to adopt an abstraction-based algorith m that con-
structs the abstract representation in one pass over the event log.
8.2 initialization and termination
for the deﬁnitions presented in this paper, we abstract from trac e initialization
and/or termination, i.e. we do not assume the existence of explicit st art/end
events. apart from the technical challenges related to ﬁnding the se events, i.e.
as described in section 5.1.1 regarding start/end activity sets used by theα-
miner and inductive miner, this can have a severe impact on computin g the
abstract representation as well.
if we assume the existence and knowledge of unique start and end a ctivities,
adopting any algorithm to cope with this type of knowledge is trivial. we only
consider cases of which we identify a start event and we only remove knowledge
related to cases of which we have seen the end event. the only challe nge is to
cope with the need to remove an unﬁnished case due to memory issue s, i.e. how
to incorporate this deletion into the data structure/abstract re presentation that
is approximated.
if we do not assume and/or know of the existence of start/end ac tivities,
whenever we encounter a case for which our data structure indica tes that we
have not seen it before, this case is identiﬁed as being a “new case”. similarly,
whenever we decide to drop a case from a data structure, we implicit ly assume
that this case has terminated. clearly, when there is a long period of inactivity,
a case might be falsely assumed to be terminated. if the case becom es active
again, it is treated as a new case again. the experiments reported o n in fig. 11
show that in case of the directly follows abstraction, this type of be haviour
has limited impact on the results. however, in a more general sense, e.g. when
approximating a preﬁx-closureon an event stream, this type of be haviour might
be of greater inﬂuence w.r.t. resulting model. the ilp miner likely suﬀe rs from
such errors and as a result produces models of inferior quality.
in fact, for the ilp miner the concept of termination is of particula r im-
portance. to guarantee a single ﬁnal state of a process model, th e ilp miner
needs to be aware of completed traces . this corresponds to explicit knowledge
of when a case is terminated in an event stream setting. like in the ca se of
initialization, the resulting models of the ilp miner are greatly inﬂuenc ed by a
faulty assumption on case termination.
9 conclusion
in this paper, we presented a generic architecture that allows for adopting ex-
isting process discovery algorithms in an event stream setting. the architecture
27is based on the observation that many existing process discovery a lgorithms
translate a given event log into some abstract representation and subsequently
use this representation to discover a process model. thus, in an ev ent stream
based setting, it suﬃces to approximate the abstract represent ation using the
event stream in order to apply existing process discovery algorithm s to streams
of events. the exact behaviour present in the resulting process m odel greatly
depends on the instantiation of the underlying techniques that app roximate the
abstract representation.
several instantiations of the architecture have been implemented in the pro-
cess mining tool-kits prom and rapidprom. we primarily focused on abs tract
representation approximations using algorithms designed for the p urpose of fre-
quent item mining on data streams. we structurally evaluated and co mpared
ﬁve diﬀerent instantiations of the framework. from a behavioural perspective
we focused on the inductive miner as it grantees to produce sound workﬂow
nets. the experiments show that the instantiation is able to captur e process
behaviouroriginatingfrom a steady state-based process. moreo ver, convergence
ofreplayﬁtnesstoastablevaluedependsonparametrizationofth einternaldata
structure. in case of concept drift, the size of the internal dat a structure of use
impacts both model quality and the drift detection point. we addition ally stud-
iedthe performanceofthe inductiveminerinstantiation. the expe rimentsshow
that both processing time of new events and memory usage are non -increasing
as more data is received.
future work within the experiments we chose to limit the use of internal
data structure to the lossy counting based approach. however , more instantia-
tions, i.e. frequent / space saving, are presented and implemented . we plan to
investigate the impact of several diﬀerent designs of the internal data structures
w.r.t. both behaviour and performance.
the architecture presented in this work focuses on approximating abstract
representations and exploiting existing algorithms to discover a pro cess model.
however, bulk of the work might be performed multiple times, i.e. seve ral new
events emitted to the stream might not change the abstract repr esentation. we
thereforeplantoconductastudytowardsacompletelyincrement alinstantiation
of the architecture, i.e. can we immediately identify whether new dat a changes
the abstraction or even the resulting model?
another interesting direction for future work is to go beyond cont rol-ﬂow
discovery, i.e. can we lift conformance checking, performance ana lysis, etc. to
the domain of event streams? moreover, in such cases we might nee d to store
more information, i.e. store all attributes related to events within c ases seen
so far. we plan to investigate the application of lossless/lossy compr ession of
the data seen so far, i.e. using frequency distributions of activities /attributes
to encode sequences in a compact manner.
28references
[1] aalst, w.m.p. van der: the application of petri nets to workﬂow ma nage-
ment. journal of circuits, systems, and computers 8(1), 21–66 (1998).
doi 10.1142/s0218126698000043
[2] aalst, w.m.p. van der: process mining - data science in action, seco nd
edition. springer (2016). doi 10.1007/978-3-662-49851-4
[3] aalst, w.m.p. van der, bolt, a., zelst, s.j. van : rapidprom: mine you r
processes and not just your data. corr abs/1703.03740 (2017)
[4] aalst, w.m.p. van der, rubin, v., verbeek, h.m.w., dongen, b.f. van,
kindler, e., g¨ unther,c.w.: processmining: a two-stepapproachto b al-
ance between underﬁtting and overﬁtting. software and system modeling
9(1), 87–111 (2010). doi 10.1007/s10270-008-0106-z
[5] aalst, w.m.p. van der, weijters, t., maruster, l.: workﬂow mining: dis-
covering process models from event logs. ieee trans. knowl. data eng.
16(9), 1128–1142 (2004). doi 10.1109/tkde.2004.47
[6] aggarwal, c.c.: on biased reservoir sampling in the presence of str eam
evolution. in: proceedings of the 32nd international conferenc e on very
large data bases, vldb ’06, pp. 607–618. vldb endowment (2006 )
[7] aggarwal, c.c. (ed.): data streams, advances in database systems ,
vol. 31. springer us (2007). doi 10.1007/978-0-387-47534-9
[8] badouel, e., bernardinello, l, darondeau,p: petri net synthesis . texts in
theoretical computer science. an eatcs series. springer (2015) . doi
10.1007/978-3-662-47967-4
[9] bergenthum, r., desel, j., lorenz, r., mauser, s.: process mining based
on regions of languages. in: business process management, 5th interna-
tional conference, bpm 2007, brisbane, australia, september 24 -28, 2007,
proceedings, pp. 375–383 (2007). doi 10.1007/978-3-540-751 83-0\27
[10] bolt, a., leoni, m. de, aalst, w.m.p. van der: scientiﬁc workﬂows f or
process mining: building blocks, scenarios, and implementation. int erna-
tional journal on software tools for technology transfer pp. 1– 22 (2015).
doi 10.1007/s10009-015-0399-5
[11] bose, r.p.j.c., aalst, w.m.p. van der, zliobaite, i., pechenizkiy, m.: d eal-
ing withconcept driftsin processmining. ieeetrans.neuralnetw. learn-
ing syst. 25(1), 154–171 (2014). doi 10.1109/tnnls.2013.2278313
[12] buijs, j.c.a.m., dongen, b.f. van, aalst, w.m.p. van der : quality di-
mensions in process discovery: the importance of ﬁtness, precisio n, gener-
alization and simplicity. int. j. cooperative inf. syst. 23(1) (2014). doi
10.1142/s0218843014400012
29[13] burattin, a., cimitile, m., maggi, f.m., sperduti, a.: online discovery
of declarative process models from event streams. ieee trans. s ervices
computing 8(6), 833–846 (2015). doi 10.1109/tsc.2015.2459703
[14] burattin, a., sperduti, a., aalst, w.m.p. van der: control-flow dis cov-
ery from event streams. in: proceedings of the ieee congress o n evo-
lutionary computation, cec 2014, beijing, china, july 6-11, 2014, p p.
2420–2427 (2014)
[15] carmona,j.,cortadella,j.: processdiscoveryalgorithmsusingn umerical
abstract domains. ieee trans. knowl. data eng. 26(12), 3064–3076
(2014). doi 10.1109/tkde.2013.156
[16] cormode, g., hadjieleftheriou, m.: methods for finding frequen t items
in data streams. the vldb journal 19(1), 3–20 (2009). doi 10.1007/
s00778-009-0172-z
[17] cormode, g., shkapenyuk, v., srivastava, d., xu, b.: forward d ecay:
a practical time decay model for streaming systems. in: 2009 iee e
25th international conference on data engineering, pp. 138–14 9 (2009).
doi 10.1109/icde.2009.65
[18] demaine, e.d., l´ opez-ortiz, a., munro, j.i.: frequency estimat ion of
internet packet streams with limited space. in: m¨ ohring, r.h., ra -
man, r. (ed.) algorithms - esa 2002, 10th annual european sympo-
sium, rome, italy, september 17-21, 2002, proceedings, lecture notes
in computer science , vol. 2461, pp. 348–360. springer (2002). doi
10.1007/3-540-45749-6 33
[19] dongen, b.f. van, medeiros, a.k.a. de, verbeek, h.m.w., weijters ,
a.j.m.m., aalst, w.m.p. van der: the prom framework: a new era in
process mining tool support. in: applications and theory of petri nets
2005, 26th international conference, icatpn 2005, miami, usa, june
20-25, 2005, proceedings, pp. 444–454 (2005). doi 10.1007/11 494744\25
[20] dongen, b.f. van, medeiros, a.k.a. de, wen, l.: process mining:
overview and outlook of petri net discovery algorithms. t. petri n ets
and other models of concurrency 2, 225–242 (2009)
[21] dumas, m., rosa, m. la, mendling, j., reijers, h.a.: fundamen-
tals of business process management. springer (2013). doi 10.10 07/
978-3-642-33143-5
[22] etzion, o., niblett, p.: event processing in action. manning publica tions
company (2010)
[23] gama, j.: knowledge discovery from data streams, 1st edn. ch apman &
hall/crc (2010). doi 10.1201/ebk1439826119
30[24] g¨ unther, c.w., aalst, w.m.p. van der: fuzzy mining - adaptive pro cess
simpliﬁcation based on multi-perspective metrics. in: business proc ess
management, 5th international conference, bpm 2007, brisban e, aus-
tralia, september 24-28, 2007, proceedings, pp. 328–343 (2007 ). doi
10.1007/978-3-540-75183-0 \24
[25] hassani, m., siccha, s., richter, f., seidl, t.: eﬃcient process disc overy
from event streams using sequential pattern mining. in: computa tional
intelligence, 2015 ieee symposium series on, pp. 1366–1373(2015 ). doi
10.1109/ssci.2015.195
[26] jensen, k., kristensen, l.m.: coloured petri nets - modelling and valida-
tion of concurrent systems. springer (2009). doi 10.1007/b951 12
[27] jensen, k., kristensen, l.m., wells, l.: coloured petri nets and c pn
tools for modelling and validation of concurrent systems. sttt 9(3-4),
213–254 (2007). doi 10.1007/s10009-007-0038-x
[28] karp, r.m., shenker s., papadimitriou, c.h.: a simple algorithm for
finding frequent elements in streams and bags. acm trans. databa se
syst.28, 51–55 (2003). doi 10.1145/762471.762473
[29] leemans, s.j.j., fahland, d., van der aalst, w.m.p.: discovering bloc k-
structured process models from event logs containing infrequent behaviour.
in: business process management workshops - bpm 2013 interna tional
workshops, beijing, china, august 26, 2013, revised papers, pp. 66–78
(2013). doi 10.1007/978-3-319-06257-0 \6
[30] leemans, s.j.j., fahland, d., aalst, w.m.p. van der: discovering blo ck-
structured process models from event logs - a constructive app roach.
in: application and theory of petri nets and concurrency - 34th i nter-
national conference, petri nets 2013, milan, italy, june 24-28, 2013.
proceedings, pp. 311–329 (2013)
[31] leemans, s.j.j., fahland, d., aalst, w.m.p. van der: scalable proce ssdis-
covery with guarantees. in: enterprise, business-process and information
systems modeling - 16th international conference, bpmds 2015, 20th
international conference, emmsad 2015, held at caise 2015, sto ck-
holm, sweden, june 8-9, 2015, proceedings, pp. 85–101 (2015). doi
10.1007/978-3-319-19237-6 \6
[32] li, t.: event mining: algorithms and applications. chapman and
hall/crc (2015)
[33] manku, g.s., motwani, r.: approximate frequency counts over d ata
streams. in: proceedings of the 28th international conferenc e on very
large data bases, vldb ’02, pp. 346–357. vldb endowment (2002 )
31[34] medeiros, a.k.a. de, dongen, b.f. van, aalst, w.m.p. van der, weij ters,
a.j.m.m.: process mining for ubiquitous mobile systems: an overview
and a concrete algorithm. in: baresi, l., dustdar, s.m gall, h.c., mat-
era, m. (ed.) ubiquitous mobile information and collaboration system s,
lecture notes in computer science , vol. 3272, pp. 151–165.springer berlin
heidelberg (2005)
[35] metwally, a., agrawal, d., abbadi, a.: eﬃcient computation of fre-
quent and top-k elements in data streams. in: eiter, t., libkin, l.
(ed.) proceedingsofthe10thinternationalconferenceondata basetheory,
icdt’05, pp. 398–412. springer-verlag, berlin, heidelberg (2005) . doi
10.1007/978-3-540-30570-5 \27
[36] murata, t.: petri nets: properties, analysis and applications. proceed-
ings of the ieee 77(4), 541–580 (1989)
[37] muthukrishnan, s.: data streams: algorithms and applications. foun-
dations and trends in theoretical computer science 1(2) (2005). doi
10.1561/0400000002
[38] object management group: business process model and nota tion
(bpmn). formal speciﬁcation formal/2011-01-03, object manag ement
group (2011)
[39] redlich, d., molka, t., gilani, w., blair, g., rashid, a.: constructs com -
petition miner: process control-flow discovery of bp-domain const ructs
pp. 134–150 (2014). doi 10.1007/978-3-319-10172-9 \9
[40] redlich, d., molka, t., gilani, w., blair, g., rashid, a.: scalabledynamic
businessprocessdiscoverywith theconstructscompetition miner pp.91–
107 (2014)
[41] san martino, g. da, navarin, n., sperduti, a.: a lossy counting b ased
approach for learning on streams of graphs on a budget. in: ijc ai
2013, proceedings of the 23rd international joint conference o n artiﬁcial
intelligence, beijing, china, august 3-9, 2013 (2013)
[42] schlimmer, j.c., granger, r.h.: beyond incremental processing : tracking
concept drift. in: proceedingsof the 5th national conference o n artiﬁcial
intelligence. philadelphia, pa, august 11-15, 1986. volume 1: scienc e., pp.
502–507 (1986)
[43] vitter, j.s.: randomsamplingwithareservoir. acmtrans.math. softw.
11(1), 37–57 (1985). doi 10.1145/3147.3165
[44] weerdt, j. de, backer, m. de, vanthienen, j., baesens, b.: a m ulti-
dimensional quality assessment of state-of-the-art process dis covery
algorithms using real-life event logs. inf. syst. 37(7), 654–676 (2012).
doi 10.1016/j.is.2012.02.004
32[45] weijters, a.j.m.m., aalst, w.m.p. van der: rediscovering workﬂow m od-
els from event-based data using little thumb. integrated comput er-
aided engineering 10(2), 151–162 (2003)
[46] weijters, a.j.m.m., aalst, w.m.p. van der, medeiros, a.k.a. de: proc ess
mining with the heuristicsminer-algorithm. beta working paper series
wp 166, eindhoven university of technology (2006)
[47] weijters, a.j.m.m., ribeiro, j.t.s.: flexible heuristics miner (fhm). in :
computational intelligence and data mining (cidm), 2011 ieee symp o-
sium on, pp. 310–317 (2011). doi 10.1109/cidm.2011.5949453
[48] werf, j.m.e.m. van der, dongen, b.f. van, hurkens, c.a.j., sereb renik,
a.: processdiscoveryusingintegerlinearprogramming. fundam. inform.
94(3-4), 387–412 (2009)
[49] zelst, s.j. van, burattin, a., dongen, b.f. van, verbeek, h.m.w.: data
streams in prom 6: a single-node architecture. in: proceedings of the
bpm demo sessions 2014 co-located with the 12th international co n-
ference on business process management (bpm 2014), eindhoven , the
netherlands, september 10, 2014., p. 81 (2014)
[50] zelst, s.j. van, dongen, b.f. van, aalst, w.m.p. van der: avoiding over-
fitting in ilp-based process discovery. in: business process man agement
- 13th international conference, bpm 2015, innsbruck, austr ia, august
31 - september 3, 2015, proceedings, pp. 163–171 (2015). doi 1 0.1007/
978-3-319-23063-4 \10
[51] zelst, s.j. van, dongen, b.f. van, aalst, w.m.p. van der: know wh at
you stream: generating event streams from cpn models in prom 6.
in: proceedings of the bpm demo session 2015 co-located with the 1 3th
international conference on business process management (bp m 2015),
innsbruck, austria, september 2, 2015., pp. 85–89 (2015)
33