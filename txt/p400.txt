fuzzy mining – adaptive process simpliﬁcation
based on multi-perspective metrics
christian w. g ¨unther and wil m.p. van der aalst
eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands
fc.w.gunther, w.m.p.v.d.aalst g@tue.nl
abstract. process mining is a technique for extracting process models from ex-
ecution logs. this is particularly useful in situations where people have an ide-
alized view of reality. real-life processes turn out to be less structured than peo-
ple tend to believe. unfortunately, traditional process mining approaches have
problems dealing with unstructured processes. the discovered models are often
“spaghetti-like”, showing all details without distinguishing what is important and
what is not. this paper proposes a new process mining approach to overcome this
problem. the approach is conﬁgurable and allows for different faithfully simpli-
ﬁed views of a particular process. to do this, the concept of a roadmap is used as
a metaphor. just like different roadmaps provide suitable abstractions of reality,
process models should provide meaningful abstractions of operational processes
encountered in domains ranging from healthcare and logistics to web services
and public administration.
1 introduction
business processes, whether deﬁned and prescribed or implicit and ad-hoc, drive and
support most of the functions and services in enterprises and administrative bodies of
today’s world. for describing such processes, modeling them as graphs has proven to
be a useful and intuitive tool. while modeling is well-established in process design, it
is complicated to do for monitoring and documentation purposes. however, especially
for monitoring, process models are valuable artifacts, because they allow us to commu-
nicate complex knowledge in intuitive, compact, and high-level form.
process mining is a line of research which attempts to extract such abstract, compact
representations of processes from their logs, i.e. execution histories [1–3, 5–7, 10, 14].
the-algorithm, for example, can create a petri net process model from an execution
log [2]. in the last years, a number of process mining approaches have been developed,
which address the various perspectives of a process (e.g., control ﬂow, social network),
and use various techniques to generalize from the log (e.g., genetic algorithms, theory
of regions [12, 4]). applied to explicitly designed, well-structured, and rigidly enforced
processes, these techniques are able to deliver an impressive set of information, yet their
purpose is somewhat limited to verifying the compliant execution. however, most pro-
cesses in real life have not been purposefully designed and optimized, but have evolved
over time or are not even explicitly deﬁned. in such situations, the application of pro-
cess mining is far more interesting, as it is not limited to re-discovering what we already
know, but it can be used to unveil previously hidden knowledge .2
over the last couple of years we obtained much experience in applying the tried-
and-tested set of mining algorithms to real-life processes. existing algorithms tend to
perform well on structured processes, but often fail to provide insightful models for less
structured processes. the phrase “spaghetti models” is often used to refer to the results
of such efforts. the problem is not that existing techniques produce incorrect results.
in fact, some of the more robust process mining techniques guarantee that the resulting
model is “correct” in the sense that reality ﬁts into the model. the problem is that the
resulting model shows all details without providing a suitable abstraction. this is com-
parable to looking at the map of a country where all cities and towns are represented by
identical nodes and all roads are depicted in the same manner. the resulting map is cor-
rect, but not very suitable. therefore, the concept of a roadmap is used as a metaphor to
visualize the resulting models. based on an analysis of the log, the importance of activ-
ities and relations among activities are taken into account. activities and their relations
can be clustered or removed depending on their role in the process. moreover, certain
aspects can be emphasized graphically just like a roadmap emphasizes highways and
large cities over dirt roads and small towns. as will be demonstrated in this paper, the
roadmap metaphor allows for meaningful process models.
in this paper we analyze the problems traditional mining algorithms have with less-
structured processes (section 2), and use the metaphor of maps to derive a novel, more
appropriate approach from these lessons (section 3). we abandon the idea of perform-
ing process mining conﬁned to one perspective only, and propose a multi-perspective
set of log-based process metrics (section 4). based on these, we have developed a ﬂexi-
ble approach for fuzzy mining , i.e. adaptively simplifying mined process models (sec-
tion 5).
2 less-structured processes – the infamous spaghetti affair
the fundamental idea of process mining is both simple and persuasive: there is a pro-
cess which is unknown to us, but we can follow the traces of its behavior, i.e. we have
access to enactment logs. feeding those into a process mining technique will yield an
aggregate description of that observed behavior, e.g. in form of a process model.
in the beginning of process mining research, mostly artiﬁcially generated logs were
used to develop and verify mining algorithms. then, also logs from real-life work-
ﬂow management systems, e.g. staffware, could be successfully mined with these tech-
niques. early mining algorithms had high requirements towards the qualities of log ﬁles,
e.g. they were supposed to be complete and limited to events of interest. yet, most of
the resulting problems could be easily remedied with more data, ﬁltering the log and
tuning the algorithm to better cope with problematic data.
while these successes were certainly convincing, most real-life processes are not
executed within rigid, inﬂexible workﬂow management systems and the like, which en-
force correct, predictive behavior. it is the inherent inﬂexibility of these systems which
drove the majority of process owners (i.e., organizations having the need to support
processes) to choose more ﬂexible or ad-hoc solutions. concepts like adaptive work-
ﬂow or case handling either allow users to change the process at runtime, or deﬁne
processes in a somewhat more “loose” manner which does not strictly deﬁne a speciﬁc3
path of execution. yet the most popular solutions for supporting processes do not en-
force any deﬁned behavior at all, but merely offer functionality like sharing data and
passing messages between users and resources. examples for these systems are erp
(enterprise resource planning) and cscw (computer-supported cooperative work)
systems, custom-built solutions, or plain e-mail.
it is obvious that executing a process within such less restrictive environments will
lead to more diverse and less-structured behavior . this abundance of observed behav-
ior, however, unveiled a fundamental weakness in most of the early process mining
algorithms. when these are used to mine logs from less-structured processes, the result
is usually just as unstructured and hard to understand. these “spaghetti” process mod-
els do not provide any meaningful abstraction from the event logs themselves, and are
therefore useless to process analysts. it is important to note that these “spaghetti” mod-
els are not incorrect. the problem is that the processes themselves are really “spaghetti-
like”, i.e., the model is an accurate reﬂection of reality.
pysy(complete)108 0.971 47pywz(complete)316 0.917 39
dsye(complete)69 0.667 3
lewp(complete)2 0 1 0.917 27 0.994 197osyw(complete)181 0.833 41
oscw(complete)94
 0.667 31ywnb(complete)84 0.833 19
dswz(complete)31 0.667 11zezr(complete)1 0.5 1
iwlh(complete)252 0.99 162iwnp(complete)303 0.527 75 0.986 159unyk(complete)35 0.667 18
ceoi(complete)450 0.88 61onix(complete)12 0.8 12
iwol(complete)230 0.968 99iwdb(complete)64 0.588 43
 0.75 60vpmo(complete)4 0.5 2iwow(complete)144
 0.857 24 0.964 61osix(complete)20 0.5 4
onxb(complete)169 0.75 19kzwz(complete)224 0.75 15leyw(complete)115 0.75 14 pysk(complete)83 0.971 38
oswz(complete)78 0.667 14ywna(complete)1651 0.75 26
 0.968 46onwz(complete)34 0.75 7ywzp(complete)23 0.667 10 0.987 125oszy(complete)28 0.8 10ahcw(complete)1 0.5 1
 0.955 52osvo(complete)210
 0.769 29osio(complete)5 0.667 2 0.991 149onyw(complete)55 0.8 25ospd(complete)17 0.5 9
 0.923 17 0.5 5
unhl(complete)91 0.979 74vppq(complete)184
 0.667 11unel(complete)155 0.977 86unle(complete)41 0.545 18
 0.881 36 0.5 16 unen(complete)44neoi(complete)15 0.75 9dnez(complete)6 0.833 6 0.978 50ywhy(complete)44 0.75 27ywwy(complete)94 0.889 32 0.8 29ywly(complete)138  0.886 53
hqoq(complete)6163 0.667 53onow(complete)5 0.5 2
onzy(complete)394 0.992 244
onvl(complete)155 0.756 70onzo(complete)173 0.956 78
 0.955 28dsyn(complete)57 0.921 37dsyv(complete)52 0.939 49dspy(complete)35 0.8 18dslq(complete)30
 0.909 16
 0.667 10 0.917 13osyn(complete)106 0.5 7 0.957 52
osdl(complete)80 0.821 28osat(complete)8 0.75 5
 0.929 19dssv(complete)234 0.966 50
osai(complete)8 0.8 5
oshy(complete)224 0.989 153
ahzi(complete)68 0.878 50 0.983 88
dssn(complete)304 0.854 129osvz(complete)18 0.5 4
appp(complete)9110
 0.794 60 0.8 43 0.9 28
 1 7387
ahhw(complete)197 0.917 76onvy(complete)160
 0.941 53zeds(complete)195  0.828 118
xieo(complete)1038 0.929 366dnlp(complete)264 0.929 117
aivy(complete)552 0.941 178hqql(complete)1153 0.909 379
kzpa(complete)224 0.941 100tutc(complete)23 0.667 23osyr(complete)19 0.5 11
osxz(complete)10  0.5 2
wsii(complete)13  0.5 6yvyw(complete)1 0.5 1aisb(complete)4 0.5 3
xiww(complete)1422 0.996 770ywsm(complete)648 0.923 123aick(complete)56 0.936 49 0.984 165
oshb(complete)231 0.944 65oszo(complete)61 0.8 28
osos(complete)35ossp(complete)358 0.667 17dssa(complete)238 0.98 147 0.969 66vppn(complete)2 0.5 1dsvm(complete)29 0.833 12 0.756 42 0.984 128
svei(complete)302 0.825 38pozi(complete)263
 0.8 20
 0.932 51 0.991 173scei(complete)449 0.944 126osoi(complete)291 0.981 110pola(complete)1255 0.923 169
oslp(complete)75 0.8 5
oncz(complete)11 0.5 2 0.5 5 0.923 89 0.998 871oswl(complete)103 0.877 54aisw(complete)430 0.667 34
onpi(complete)264 0.819 104lely(complete)126 0.667 12
kzol(complete)166 0.8 36spwv(complete)114 0.929 28
onyz(complete)7 0.5 6
ospl(complete)4 0.5 1
 0.667 20
 0.995 281
yhlh(complete)749 0.918 127
 0.994 437ahhj(complete)264 0.972 56 0.942 84
spwb(complete)214  0.938 54ahbl(complete)271 0.981 45aisy(complete)845
 0.917 43dsya(complete)3 0.5 2
 0.99 154
ahca(complete)206 0.978 51 0.888 51
 0.986 114 0.889 58dsna(complete)1159
 0.833 36 0.857 8 0.997 1054dscl(complete)3 0.5 3dsic(complete)20
 0.75 11leoj(complete)7 0.667 5
dsry(complete)2 0.5 2
 0.5 7
 0.667 55 0.986 104oono(complete)28 0.5 6 0.8 5 0.974 71onaz(complete)171 0.909 41onhl(complete)264 0.974 108vpht(complete)118 0.975 42
onyn(complete)142 0.942 88oniz(complete)23 0.75 8
levn(complete)5 0.5 2vpny(complete)10
 0.5 1 0.982 59
vpnh(complete)160 0.854 53
 0.983 75
onlw(complete)100 0.978 46unea(complete)239
 0.941 36
vpne(complete)15 0.667 2 0.957 52 0.75 24 0.909 14 0.985 94neow(complete)60 0.923 34nepl(complete)47 0.885 26 0.909 19 0.667 24 newn(complete)96 0.667 23 0.958 49
 0.985 161kzoo(complete)26 0.8 18ovwz(complete)21 0.5 6
lewo(complete)2 0.5 2 0.941 37xish(complete)866
 0.833 59
osel(complete)1 0.5 1
 0.9 65 0.995 285 0.833 29 0.667 29 0.8 46 0.997 729
aivm(complete)130 0.667 44
ywok(complete)856 0.998 604ywvp(complete)469 0.769 134
ahmk(complete)1 0.5 1 0.991 112
 0.923 46 0.997 407
ywxb(complete)257 0.896 92 0.917 64
 0.984 69
svpz(complete)203 0.98 64osax(complete)6 0.833 5
ahnp(complete)301 0.993 253ahmi(complete)10 0.875 8 0.997 370
 0.8 40hdei(complete)40 0.5 3
tuii(complete)90 0.667 9
 0.995 245 0.667 27 0.999 1471 0.812 101
aisi(complete)842 0.75 27ioii(complete)243 0.872 43
bkzv(complete)4 0.5 1
 0.993 158 0.881 73
 0.9 62 0.976 47ywpz(complete)92 0.944 54 ceso(complete)123
 0.82 45 0.875 85 0.977 55
 0.921 40 0.989 123scpz(complete)154 0.889 28dnwz(complete)22
 0.667 8
 0.994 168hnrn(complete)49 0.944 27
ahze(complete)1 0.5 1vppk(complete)350 0.904 80
 0.986 154
 0.9 38 0.909 72
 0.964 25 0.984 101vpha(complete)102 0.9 43 0.981 173 0.978 44
 0.909 37onoi(complete)703 0.667 54 0.941 104 0.966 56
onhi(complete)78 0.947 60onhb(complete)178 0.952 79onhy(complete)74 0.983 64onny(complete)191 0.938 64 0.988 108
 0.75 77
 0.75 60 0.998 522vphn(complete)279 0.867 140 0.985 136 0.75 97
 0.985 151
 0.75 18 0.985 83lejo(complete)7 0.5 5lejv(complete)2 0.5 1ahlz(complete)5 0.5 1pona(complete)65 0.667 11 0.938 38 0.98 91oniy(complete)117 0.921 70 0.981 70 0.97 43
hqwl(complete)221 0.99 165hqxz(complete)83 0.759 35
 0.75 17
 1 5207
incy(complete)50 0.812 45hqxb(complete)775
 0.909 277 kzzl(complete)1427
 0.917 270hqoh(complete)59 0.848 59aiyw(complete)114 0.941 67
blzi(complete)3 0.5 3
nwya(complete)1 0.5 1 0.968 47
hqoz(complete)601 0.75 13
hqhi(complete)4504 1 4245inky(complete)93 0.963 44inlo(complete)119 0.885 35kzoy(complete)122 0.875 35 0.982 84
leje(complete)50 0.923 41leoo(complete)85 0.914 37
lelz(complete)10 0.75 3 0.917 35
levl(complete)176 0.786 43 0.967 63zepz(complete)141 0.955 121
zelc(complete)304 0.988 128
 0.9 117 0.975 109
kzoi(complete)107
 0.909 42ovna(complete)155 0.909 21 0.929 253
 0.998 629
aiht(complete)87 0.978 53ovle(complete)107 0.875 16
 0.932 53turc(complete)53 0.95 26
bkxt(complete)1 0.5 1 0.929 152 0.909 37 0.977 111
 0.923 15oonv(complete)26 0.667 9
 0.667 14 0.909 11opno(complete)2 0.5 1 0.762 67 0.75 62
 0.99 107aivj(complete)7 0.5 1
hqjw(complete)2 0.5 1
aigp(complete)877
 0.983 85 0.996 445xisv(complete)418 0.917 149
 0.929 32cnnn(complete)60 0.743 46
hdea(complete)243 0.727 18hdwe(complete)43
 0.833 6tugp(complete)73
 0.688 19dscw(complete)20
 0.667 4  0.944 95 0.957 47
 0.917 15 0.994 230aino(complete)270 0.872 47
zenc(complete)806 0.933 101
 0.909 53 0.75 29 0.976 112hqpi(complete)48 0.667 7
 0.8 31 0.909 70inol(complete)53 0.909 34
 0.955 35 0.917 12inom(complete)44 0.861 38 0.96 27
hqel(complete)256 0.8 16
 0.909 385 0.998 390 0.857 50
 0.992 205 0.75 14
 0.893 42 0.97 30
 0.991 187 0.75 32
 0.75 37invw(complete)42 0.727 17 0.929 22 0.667 5 0.976 41 0.963 47ovnz(complete)163 0.828 56 0.983 97 hqle(complete)6010 0.833 66
 0.941 250
 0.934 160 0.996 285osol(complete)28 0.667 6
tuxw(complete)1 0.5 1hqqy(complete)185 0.962 83hqly(complete)80
 0.902 62
hqlk(complete)1 0.5 1 0.896 79 0.909 425 0.998 682
 0.981 56 0.857 30 0.667 10 0.845 96 1 5791
tuwi(complete)43 0.667 27kzey(complete)43 0.667 18
hqxy(complete)12 0.667 4
leor(complete)4 0.5 3
 0.998 651zena(complete)1094 0.795 151 0.939 113 0.999 931 0.941 104
 0.904 78 0.99 115
 0.711 52 0.998 779
kzwn(complete)87 0.964 55 0.516 30
lgzi(complete)6 0.5 1
 0.917 262 0.75 160 0.999 1124tuji(complete)296
 0.889 13
hlpa(complete)122 0.75 21aihn(complete)23
 0.667 3 0.909 98
dspo(complete)3 0.5 1
 0.833 30hdoe(complete)10
 0.5 1
cwnw(complete)782 0.667 15bkzi(complete)8 0.5 1
kzzo(complete)111 0.955 46 0.929 74
 0.998 689ainp(complete)7
 0.5 2
osiz(complete)161 0.917 28aiyb(complete)2
 0.667 2
 0.875 80 0.995 312 0.987 171
pozw(complete)103 0.933 75
 0.8 43 0.933 15 0.933 27
 0.97 72ovbk(complete)84 0.932 53 0.941 29 0.964 22
 0.955 29ywwp(complete)226 0.994 173zein(complete)887 0.923 15cwsw(complete)177 0.971 34
 0.889 59 0.998 743zebz(complete)179 0.917 56
zewz(complete)9 0.5 4hqli(complete)28 0.75 5 0.909 18 0.993 158ioik(complete)76 0.617 67
 0.938 31 0.952 26dsli(complete)7 0.5 3 0.881 51 0.989 121 0.667 18
tumi(complete)409 0.995 310
 0.923 10hdpt(complete)145
 0.833 10
bkmi(complete)195
 0.923 60tumk(complete)40 0.571 16
 0.848 39 0.986 97scni(complete)4 0.5 1
 0.917 20 0.944 73cnat(complete)65 0.95 24cnns(complete)68 0.889 40 0.794 29
cnik(complete)43 0.971 42
 0.941 16 0.923 18 0.938 17turi(complete)53 0.839 34 0.909 15
turk(complete)42 0.825 38 0.9 20
tusc(complete)166 0.833 17 0.967 36spwa(complete)129 0.824 72 0.962 45
spwn(complete)120 0.9 74 0.957 45
spwi(complete)99 0.963 72 0.914 46
 0.909 27 tuzv(complete)308 0.986 119tuzc(complete)390 0.929 148
tujv(complete)92 0.889 28 0.929 14 0.987 101
tuzi(complete)395 0.944 252tuwv(complete)5 0.5 1tutp(complete)24
 0.667 4
 0.944 2 0.98 119tuok(complete)44 0.975 42tupk(complete)66 0.954 65
tuzk(complete)207 0.969 156 0.875 43 0.972 34
tupc(complete)18 0.75 8
bkya(complete)153 0.97 55bkyi(complete)160
 0.892 93
kzal(complete)2 0.5 2 0.952 37bkyv(complete)144 0.884 109tusi(complete)306 0.667 10
lebr(complete)1 0.5 1 0.933 21
blyi(complete)128 0.797 120 0.968 56 0.978 50 0.96 80 0.957 84 0.938 49
bccc(complete)82 0.667 18tuew(complete)154 0.688 35tuiv(complete)1
 0.5 1 0.97 82
 0.8 16hdwp(complete)11 0.5 1tusk(complete)88 0.667 13
 0.667 32 0.989 209 0.923 10 0.941 25
 0.941 66 0.981 46 0.5 7
 0.667 23  0.667 8 0.941 43 0.962 51tujc(complete)121 0.857 22
 0.9 37 0.955 32tuic(complete)24 0.667 7
tujp(complete)203 0.964 99 0.923 86tugv(complete)39 0.8 13 0.923 56 0.986 100
tujk(complete)131 0.852 124
tumc(complete)192 0.8 49lebs(complete)197 0.833 38tuab(complete)12 0.5 2tuyk(complete)1 0.5 1tukw(complete)73
 0.833 12 0.955 45 0.5 1
 0.667 7 0.955 28 0.75 12
 0.981 100hdpr(complete)35 0.594 31
 0.8 8
bccv(complete)55 0.75 22
tugc(complete)79 0.667 20  0.989 134 0.857 19 0.875 21 0.964 36 0.8 18
 0.955 41 0.75 27 0.967 49tugi(complete)152 0.986 119tugk(complete)40
 0.857 21
hlpo(complete)4 0.5 3bcci(complete)177 0.989 139bcck(complete)63 0.923 30 0.993 231 0.917 54
tuti(complete)26 0.667 7
 0.5 8 0.5 4 0.5 1
 0.75 21 0.998 744 0.917 56 0.992 122dsln(complete)30 0.917 13dsll(complete)36 0.759 28dszn(complete)25 0.958 25dslx(complete)48 0.87 20 0.889 26 0.947 20dszv(complete)22 0.957 22dslv(complete)26 0.952 20 0.95 15
hdop(complete)7 0.5 6 0.667 3 0.8 30
tumv(complete)96
 0.75 41 0.938 38 aiwz(complete)116 0.75 14bkma(complete)130 0.8 29 0.944 69
 0.875 53 0.99 129 0.923 44 0.96 80bkmv(complete)143
 0.912 66 0.75 17 0.923 14 0.917 45 0.7 14 0.955 17
 0.923 17 0.929 18bccw(complete)4 0.4 4
 0.75 19
 0.667 28 0.8 28 0.5 3dsiy(complete)14 0.667 4dsit(complete)13 0.727 13  0.875 8  0.533 10 0.5 2
osow(complete)6 0.5 2 0.833 10 0.941 17
 0.5 2 0.667 3
lecl(complete)211 0.75 23 0.991 159
 0.75 37 0.99 135tuip(complete)39 0.75 28
 0.667 20
 0.909 86
sypi(complete)6 0.667 5
 0.976 85hlpn(complete)99 0.8 33 0.8 2 0.98 66tuik(complete)24 0.842 21 0.889 43 0.917 50blom(complete)22 0.522 20blam(complete)63
hlpw(complete)32 0.833 11tuqk(complete)1 0.5 1 0.889 18
 0.857 26 0.833 26 0.977 76blbo(complete)10 0.5 2
 0.75 15 0.929 19tuwp(complete)39 0.944 19 0.5 7
 0.923 20 0.545 17
tuwk(complete)23 0.938 22
 0.667 2 0.667 12
 0.958 64
 0.857 15
 0.75 27hlpi(complete)6 0.667 4 0.667 7
bkza(complete)1 0.5 1tutk(complete)13 0.857 13 0.667 7 0.667 12
 0.5 2
 0.917 31 0.5 2 0.981 111
 0.8 11oshw(complete)4
 0.5 1
osxy(complete)10 0.667 2
 0.667 40 0.933 30ahwz(complete)3 0.5 1 0.5 1
 0.864 24 0.964 21 0.75 23
 0.667 3 0.5 1 0.5 3
 0.938 18 0.909 94 0.989 470
hqwp(complete)1 0.5 1 0.5 1lejc(complete)6 0.667 4 0.75 5nebi(complete)33 0.917 13 0.947 16neoo(complete)16 0.562 14neek(complete)18 0.9 11nelt(complete)11 0.909 11nelo(complete)13 0.909 10 0.667 6 0.5 3
osll(complete)61
 0.75 16 0.941 35oshd(complete)17
 0.667 6
 0.5 10 0.812 30
 0.667 8
 0.667 8 0.933 13
 0.5 2
hlpj(complete)1 0.5 1onwl(complete)21 0.875 7
 0.8 10
 0.625 6 0.667 4
 0.667 5
 0.5 2bkxi(complete)1 0.5 1
bkxa(complete)1 0.5 1 0.5 1 0.875 17
 0.5 1 0.5 2
 0.875 21
 0.5 1 0.4 4
 0.5 1 0.75 3 0.75 4 0.929 14 0.5 3
 0.5 2
 0.667 2 0.75 2
 0.5 1 0 1
 0.667 7
tuav(complete)5 0.5 7 0.25 4tuai(complete)1 0.5 1tuak(complete)2 0.5 1 0.5 2
 0.5 1 0.8 6
 0.96 22  0.5 2 0.5 2
 0.667 2
 0.5 4 0.5 1
ahmy(complete)10 0.889 8
hnwz(complete)15 0.25 2ahmh(complete)9 0.727 9ahmw(complete)8 0.889 8ahmo(complete)8 0.889 8ahmz(complete)8 0.875 8ahmn(complete)8 0.875 8 0.875 6
 0.5 1  0.917 12 0.5 1 0.5 2scna(complete)3 0.5 2
scnk(complete)1 0.5 1
 0.5 1 0.5 1 0.5 1
 0.667 4 0.75 2
 0.5 2 0.5 1 0.5 1 0.5 1 0.5 2
 0.5 1 0.5 7
 0.5 1
 0.5 1 0.5 2tuxk(complete)2 0.5 2 0.5 2 0.5 1 0.5 4
 0.833 8 0.833 5
 0.75 5  0.667 2 0.929 17 0.667 4 0.5 1
 0.5 1
 0.25 2pyyw(complete)1 0 1
 0.5 3 0.5 1 0.5 1 0.5 1
fig. 1. excerpt of a typical “spaghetti” process model (ca. 20% of complete model).
an example of such a “spaghetti” model is given in figure 1. it is noteworthy that
this ﬁgure shows only a small excerpt (ca. 20%) of a highly unstructured process model.
it has been mined from machine test logs using the heuristics miner, one of the tradi-
tional process mining techniques which is most resilient towards noise in logs [14].
although this result is rather useful, certainly in comparison with other early process
mining techniques, it is plain to see that deriving helpful information from it is not easy.
event classes found in the log are interpreted as activity nodes in the process model.
their sheer amount makes it difﬁcult to focus on the interesting parts of the process. the
abundance of arcs in the model, which constitute the actual “spaghetti”, introduce an
even greater challenge for interpretation. separating cause from effect, or the general
direction in which the process is executed, is not possible because virtually every node
is transitively connected to any other node in both directions. this mirrors the crux of
ﬂexibility in process execution – when people are free to execute anything in any given
order they will usually make use of such feature, which renders monitoring business
activities an essentially infeasible task.4
we argue that the fault for these problems lies neither with less-structured pro-
cesses, nor with process mining itself. rather, it is the result of a number of, mostly
implicit, assumptions which process mining has historically made, both with respect
to the event logs under consideration, and regarding the processes which have gener-
ated them. while being perfectly sound in structured, controlled environments, these
assumptions do not hold in less-structured, real-life environments , and thus ultimately
make traditional process mining fail there.
assumption 1: all logs are reliable and trustworthy . any event type found in the
log is assumed to have a corresponding logical activity in the process. however,
activities in real-life processes may raise a random number of seemingly unrelated
events. activities may also go unrecorded, while other events do not correspond to
any activity at all.
the assumption that logs are well-formed and homogeneous is also often not true.
for example, a process found in the log is assumed to correspond to one logical
entity. in less-structured environments, however, there are often a number of “tacit”
process types which are executed, and thus logged, under the same name.
also, the idea that all events are raised on the same level of abstraction, and are
thus equally important, is not true in real-life settings. events on different levels are
“ﬂattened” into the same event log, while there is also a high amount of informa-
tional events (e.g., debug messages from the system) which need to be disregarded.
assumption 2: there exists an exact process which is reﬂected in the logs . this as-
sumption implies that there is the one perfect solution out there, which needs to
be found. consequently, the mining result should model the process completely ,
accurately , and precisely . however, as stated before, spaghetti models are not nec-
essarily incorrect – the models look like spaghetti, because they precisely describe
every detail of the less-structured behavior found in the log. a more high-level so-
lution, which is able to abstract from details, would thus be preferable.
traditional mining algorithms have also been conﬁned to a single perspective (e.g.,
control ﬂow, data), as such isolated view is supposed to yield higher precision.
however, perspectives are interacting in less-structured processes, e.g. the data ﬂow
may complement the control ﬂow, and thus also needs to be taken into account.
in general, the assumption of a perfect solution is not well-suited for real-life appli-
cation. reality often differs signiﬁcantly from theory, in ways that had not been an-
ticipated. consequently, useful tools for practical application must be explorative ,
i.e. support the analyst to tweak results and thus capitalize on their knowledge.
we have conducted process mining case studies in organizations like philips med-
ical systems, uwv , rijkswaterstaat, the catharina hospital eindhoven and the amc
hospital amsterdam, and the dutch municipalities of alkmaar and heusden. our ex-
periences in these case studies have shown the above assumptions to be violated in all
ways imaginable. therefore, to make process mining a useful tool in practical, less-
structured settings, these assumptions need to be discarded. the next section introduces
the main concept of our mining approach, which takes these lessons into account.5
3 an adaptive approach for process simpliﬁcation
process mining techniques which are suitable for less-structured environments need to
be able to provide a high-level view on the process, abstracting from undesired details.
the ﬁeld of cartography has always been faced with a quite similar challenge, namely
to simplify highly complex and unstructured topologies. activities in a process can be
related to locations in a topology (e.g. towns or road crossings) and precedence relations
to trafﬁc connections between them (e.g., railways or motorways).
insigniﬁcant roadsare not shown.parts of the city are merged.focuses on theintended use andlevel of detail.highways are highlighted by size, contrast and color.abstractionaggregationcustomizationemphasis
fig. 2. example of a road map.
when one takes a closer look at maps (such as the example in figure 2), the solution
cartography has come up with to simplify and present complex topologies, one can
derive a number of valuable concepts from them.
aggregation: to limit the number of information items displayed, maps often show
coherent clusters of low-level detail information in an aggregated manner. one ex-
ample are cities in road maps, where particular houses and streets are combined
within the city’s transitive closure (e.g., the city of eindhoven in figure 2).
abstraction: lower-level information which is insigniﬁcant in the chosen context is
simply omitted from the visualization. examples are bicycle paths, which are of no
interest in a motorist’s map.
emphasis: more signiﬁcant information is highlighted by visual means such as color ,
contrast ,saturation , and size. for example, maps emphasize more important roads
by displaying them as thicker, more colorful and contrasting lines (e.g., motorway
“e25” in figure 2).
customization: there is no one single map for the world. maps are specialized on a
deﬁned local context , have a speciﬁc level of detail (city maps vs highway maps),
and a dedicated purpose (interregional travel vs alpine hiking).
these concepts are universal, well-understood, and established. in this paper we ex-
plore how they can be used to simplify and properly visualize complex, less-structured
processes. to do that, we need to develop appropriate decision criteria on which to base
the simpliﬁcation and visualization of process models. we have identiﬁed two funda-
mental metrics which can support such decisions: (1) signiﬁcance and (2) correlation .6
signiﬁcance, which can be determined both for event classes (i.e., activities) and
binary precedence relations over them (i.e., edges), measures the relative importance of
behavior. as such, it speciﬁes the level of interest we have in events, or their occurring
after one another. one example for measuring signiﬁcance is by frequency, i.e. events or
precedence relations which are observed more frequently are deemed more signiﬁcant.
correlation on the other hand is only relevant for precedence relations over events.
it measures how closely related two events following one another are. examples for
measuring correlation include determining the overlap of data attributes associated to
two events following one another, or comparing the similarity of their event names.
more closely correlated events are assumed to share a large amount of their data, or have
their similarity expressed in their recorded names (e.g. “check customer application”
and “approve customer application”).
based on these two metrics, which have been deﬁned specially for this purpose, we
can sketch our approach for process simpliﬁcation as follows.
–highly signiﬁcant behavior is preserved , i.e. contained in the simpliﬁed model.
–less signiﬁcant buthighly correlated behavior is aggregated , i.e. hidden in clusters
within the simpliﬁed model.
–less signiﬁcant andlowly correlated behavior is abstracted from , i.e. removed from
the simpliﬁed model.
this approach can greatly reduce and focus the displayed behavior, by employing
the concepts of aggregation and abstraction. based on such simpliﬁed model, we can
employ the concept of emphasis , by highlighting more signiﬁcant behavior.
fig. 3. excerpt of a simpliﬁed and decorated process model.
figure 3 shows an excerpt from a simpliﬁed process model, which has been cre-
ated using our approach. bright square nodes represent signiﬁcant activities, the darker
octagonal node is an aggregated cluster of three less-signiﬁcant activities. all nodes
are labeled with their respective signiﬁcance, with clusters displaying the mean sig-
niﬁcance of their elements. the brightness of edges between nodes emphasizes their
signiﬁcance, i.e. more signiﬁcant relations are darker. edges are also labeled with their
respective signiﬁcance and correlation values. by either removing or hiding less signif-
icant information, this visualization enables the user to focus on the most interesting
behavior in the process.7
yet, the question of what constitutes “interesting” behavior can have a number of
answers, based on the process, the purpose of analysis, or the desired level of abstrac-
tion. in order to yield the most appropriate result, signiﬁcance and correlation measures
need to be conﬁgurable. we have thus developed a set of metrics, which can each mea-
sure signiﬁcance or correlation based on different perspectives (e.g., control ﬂow or
data) of the process. by inﬂuencing the “mix” of these metrics and the simpliﬁcation
procedure itself, the user can customize the produced results to a large degree.
the following section introduces some of the metrics we have developed for signif-
icance and correlation in more detail.
4 log-based process metrics
signiﬁcance and correlation, as introduced in the previous section, are suitable concepts
for describing the importance of behavior in a process in a compact manner. however,
because they represent very generalized, condensed metrics, it is important to mea-
sure them in an appropriate manner. taking into account the wide variety of processes,
analysis questions and objectives, and levels of abstraction, it is necessary to make this
measurement adaptable to such parameters.
our approach is based on a conﬁgurable and extensible framework for measuring
signiﬁcance and correlation. the design of this framework is introduced in the next
subsection, followed by detailed introductions to the three primary types of metrics:
unary signiﬁcance, binary signiﬁcance, and binary correlation.
4.1 metrics framework
an important property of our measurement framework is that for each of the three pri-
mary types of metrics (unary signiﬁcance, binary signiﬁcance, and binary correlation)
different implementations may be used. a metric may either be measured directly from
the log ( log-based metric) , or it may be based on measurements of other, log-based
metrics ( derivative metric ).
when the log contains a large number of undesired events, which occur in between
desired ones, actual causal dependencies between the desired event classes may go un-
recorded. to counter this, our approach also measures long-term relations , i.e. when the
sequencea;b;c is found in the log, we will not only record the relations a!band
b!c, but also the length-2-relationship a!c. we allow measuring relationships
of arbitrary length, while the measured value will be attenuated , i.e. decreased, with
increasing length of relationship.
4.2 unary signiﬁcance metrics
unary signiﬁcance describes the relative importance of an event class, which will be
represented as a node in the process model. as our approach is based on removing less
signiﬁcant behavior, and as removing a node implies removing all of its connected arcs,
unary signiﬁcance is the primary driver of simpliﬁcation.8
one metric for unary signiﬁcance is frequency signiﬁcance , i.e. the more often a
certain event class was observed in the log, the more signiﬁcant it is. frequency is a log-
based metric, and is in fact the most intuitive of all metrics. traditional process mining
techniques are built solely on the principle of measuring frequency, and it remains an
important foundation of our approach. however, real-life logs often contain a large
number of events which are in fact not very signiﬁcant, e.g. an event which describes
saving the process state after every ﬁve activities. in such situations, frequency plays a
diminished role and can rather distort results.
another, derivate metric for unary signiﬁcance is routing signiﬁcance . the idea
behind routing signiﬁcance is that points, at which the process either forks (i.e., split
nodes) or synchronizes (i.e., join nodes), are interesting in that they substantially deﬁne
the structure of a process. the higher the number and signiﬁcance of predecessors for a
node (i.e., its incoming arcs) differs from the number and signiﬁcance of its successors
(i.e., outgoing arcs), the more important that node is for routing in the process. routing
signiﬁcance is important as ampliﬁer metric , i.e. it helps separating important routing
nodes (whose signiﬁcance it increases) from those less important.
4.3 binary signiﬁcance metrics
binary signiﬁcance describes the relative importance of a precedence relation between
two event classes, i.e. an edge in the process model. its purpose is to amplify and to
isolate the observed behavior which is supposed to be of the greatest interest. in our
simpliﬁcation approach, it primarily inﬂuences the selection of edges which will be
included in the simpliﬁed process model.
like for unary signiﬁcance, the log-based frequency signiﬁcance metric is also
the most important implementation for binary signiﬁcance. the more often two event
classes are observed after one another, the more signiﬁcant their precedence relation.
the distance signiﬁcance metric is a derivative implementation of binary signiﬁ-
cance. the more the signiﬁcance of a relation differs from its source and target nodes’
signiﬁcances, the less its distance signiﬁcance value. the rationale behind this metric is,
that globally important relations are also always the most important relations for their
endpoints. distance signiﬁcance locally ampliﬁes crucial key relations between event
classes, and weakens already insigniﬁcant relations. thereby, it can clarify ambiguous
situations in edge abstraction, where many relations “compete” over being included in
the simpliﬁed process model. especially in very unstructured execution logs, this metric
is an indispensible tool for isolating behavior of interest.
4.4 binary correlation metrics
binary correlation measures the distance of events in a precedence relation, i.e. how
closely related two events following one another are. distance, in the process domain,
can be equated to the magnitude of context change between two activity executions.
subsequently occurring activities which have a more similar context (e.g., which are
executed by the same person or in a short timeframe) are thus evaluated to be higher
correlated. binary correlation is the main driver of the decision between aggregation or
abstraction of less-signiﬁcant behavior.9
proximity correlation evaluates event classes, which occur shortly after one another,
as highly correlated. this is important for identifying clusters of events which corre-
spond to one logical activity, as these are commonly executed within a short timeframe.
another feature of such clusters of events occurring within the realm of one higher-
level activity is, that they are executed by the same person. originator correlation be-
tween event classes is determined from the names of the persons, which have triggered
two subsequent events. the more similar these names, the higher correlated the respec-
tive event classes. in real applications, user names often include job titles or function
identiﬁers (e.g.“sales john” and “sales paul”). therefore, this metric implementation is
a valuable tool also for unveiling implicit correlation between events.
endpoint correlation is quite similar, however, instead of resources it compares the
activity names of subsequent events. more similar names will be interpreted as higher
correlation. this is important for low-level logs including a large amount of less sig-
niﬁcant events which are closely related. most of the time, events which reﬂect similar
tasks also are given similar names (e.g., “open valve13” and “close valve13”), and this
metric can unveil these implicit dependencies.
in most logs, events also include additional attributes, containing snapshots from the
data perspective of the process (e.g., the value of an insurance claim). in such cases,
theselection of attributes logged for each event can be interpreted as its context. thus,
thedata type correlation metric evaluates event classes, where subsequent events share
a large amount of data types (i.e., attribute keys), as highly correlated. data value cor-
relation is more speciﬁc, in that it also takes the values of these common attributes into
account. in that, it uses relative similarity, i.e. small changes of an attribute value will
compromise correlation less than a completely different value.
currently, all implementations for binary correlation in our approach are log-based.
the next section introduces our approach for adaptive simpliﬁcation and visualization
of complex process models, which is based on the aggregated measurements of all
metric implementations which have been introduced in this section.
5 adaptive graph simpliﬁcation
most process mining techniques follow an interpretative approach, i.e. they attempt to
map behavior found in the log to typical process design patterns (e.g., whether a split
node has and- or xor-semantics). our approach, in contrast, focuses on high-level
mapping of behavior found in the log, while not attempting to discover such patterns.
thus, creating the initial (non-simpliﬁed) process model is straightforward: all event
classes found in the log are translated to activity nodes, whose importance is expressed
by unary signiﬁcance. for every observed precedence relation between event classes, a
corresponding directed edge is added to the process model. this edge is described by
the binary signiﬁcance and correlation of the ordering relation it represents.
subsequently, we apply three transformation methods to the process model, which
will successively simplify speciﬁc aspects of it. the ﬁrst two phases, conﬂict reso-
lution andedge ﬁltering , remove edges (i.e., precedence relations) between activity
nodes, while the ﬁnal aggregation and abstraction phase removes and/or clusters less-
signiﬁcant nodes. removing edges from the model ﬁrst is important – due to the less-10
structured nature of real-life processes and our measurement of long-term relationships,
the initial model contains deceptive ordering relations, which do not correspond to valid
behavior and need to be discarded. the following sections provide details about the
three phases of our simpliﬁcation approach, given in the order in which they are applied
to the initial model.
5.1 conﬂict resolution in binary relations
whenever two nodes in the initial process model are connected by edges in both direc-
tions, they are deﬁned to be in conﬂict . depending on their speciﬁc properties, conﬂicts
may represent one of three possible situations in the process:
–length-2-loop: two activities aandbconstitute a loop in the process model,
i.e. after executing aandbin sequence, one may return to aand start over. in
this case, the conﬂicting ordering relations between these activities are explicitly
allowed in the original process, and thus need to be preserved.
–exception: the process orders a!bin sequence, however, during real-life exe-
cution the exceptional case of b!aalso occurs. most of the time, the “normal”
behavior is clearly more signiﬁcant. in such cases, the “weaker” relation needs to
be discarded to focus on the main behavior.
–concurrency: aandbcan be executed in any order (i.e., they are on two distinct,
parallel paths), the log will most likely record both possible cases, i.e. a!b
andb!a, which will create a conﬂict. in this case, both conﬂicting ordering
relations need to be removed from the process model.
conﬂict resolution attempts to classify each conﬂict as one of these three cases, and
then resolves it accordingly. for that, it ﬁrst determines the relative signiﬁcance of both
conﬂicting relations.
aba → bb → aainaoutbinbout
fig. 4. evaluating the relative signiﬁcance of conﬂicting relations.
figure 4 shows an example of two activities aandbin conﬂict. the relative sig-
niﬁcance for an edge a!bcan be determined as follows.
deﬁnition 1 (relative signiﬁcance). letnbe the set of nodes in a process model, and
letsig:nn ! r+
0be a relation that assigns to each pair of nodes a;b2n
the signiﬁcance of a precedence relation over them. rel:nn! r+
0is a relation
which assigns to each pair of nodes a;b2ntherelative importance of their ordering
relation:rel(a;b) =1
2sig(a;b )p
x2nsig(a;x )+1
2sig(a;b )p
x2nsig(x;b )11
every ordering relation a!bhas a set of competing relations comp ab=aout[
bin. this set of competing relations is composed of aout, i.e. all edges starting from a,
and ofbin, i.e. all edges pointing to b(cf. figure 4). note that this set also contains the
reference relation itself, i.e. more speciﬁcally: bin\aout=fa!bg. by dividing the
signiﬁcance of an ordering relation a!bwith the sum of all its competing relations’
signiﬁcances, we get the importance of this relation in its local context .
if the relative signiﬁcance of both conﬂicting relations, rel(a;b)andrel(b;a)
exceeds a speciﬁed preserve threshold value, this signiﬁes that aandbare apparently
forming a length-2-loop , which is their most signiﬁcant behavior in the process. thus,
in this case, both a!bandb!awill be preserved.
in case at least one conﬂicting relation’s relative signiﬁcance is below this threshold,
theoffset between both relations’ relative signiﬁcances is determined, i.e. ofs(a;b) =
jrel(a;b) rel(b;a)j. the larger this offset value, the more the relative signiﬁcances
of both conﬂicting relations differ, i.e. one of them is clearly more important. thus, if
the offset value exceeds a speciﬁed ratio threshold , we assume that the relatively less
signiﬁcant relation is in fact an exception and remove it from the process model.
otherwise, i.e. if at least one of the relations has a relative signiﬁcance below the
preserve threshold and their offset is smaller than the ratio threshold , this signiﬁes that
botha!bandb!aare relations which are of no greater importance for both their
source and target activities. this low, yet balanced relative signiﬁcance of conﬂicting
relations hints at aandbbeing executed concurrently , i.e. in two separate threads of
the process. consequently, both edges are removed from the process model, as they do
not correspond to factual ordering relations.
5.2 edge filtering
although conﬂict resolution removes a number of edges from the process model, the
model still contains a large amount of precedence relations. to infer further structure
from this model, it is necessary to remove most of these remaining edges by edge ﬁl-
tering , which isolates the most important behavior. the obvious solution is to remove
the globally least signiﬁcant edges, leaving only highly signiﬁcant behavior. however,
this approach yields sub-optimal results, as it is prone to create small, disparate clusters
of highly frequent behavior. also, in the subsequent aggregation step, highly corre-
lated relations play an important part in connecting clusters, even if they are not very
signiﬁcant.
therefore, our edge ﬁltering approach evaluates each edge a!bby its utility
util(a;b), a weighed sum of its signiﬁcance and correlation. a conﬁgurable utility
ratiour2[0;1]determines the weight, such that util(a;b) =ursig(a;b) + (1 
ur)cor(a;b). a larger value for urwill preserve more signiﬁcant edges, while a
smaller value will favor highly correlated edges.
figure 5 shows an example for processing the incoming arcs of a node a. using
a utility ratio of 0:5, i.e. taking signiﬁcance and correlation equally into account, the
utility value is calculated, which ranges from 0.4 to 1.0 in this example.
filtering edges is performed on a local basis, i.e. for each node in the process model,
the algorithm preserves its incoming and outgoing edges with the highest utility value.
the decision of which edges get preserved is conﬁgured by the edge cutoff parameter12
a1.0pqrs0.90.70.51.00.20.80.3sign.corr.1.00.550.750.41.00.250.580.0util.normal. util.ur = 0.5co = 0.41.00.58preserveaqspr
fig. 5. filtering the set of incoming edges for a node a.
co2[0;1]. for every node n, the utility values for each incoming edge x!nare
normalized to [0;1], so that the weakest edge is assigned 0and the strongest one 1. all
edges whose normalized utility value exceeds coare added to the preserved set. in the
example in figure 5, only two of the original edges, are preserved, using a edge cutoff
value of 0:4:p!a(with normalized utility of 1.0) and r!a(norm. utility of
0.56). the outgoing edges are processed in the same manner for each node.
theedge cutoff parameter determines the aggressiveness of the algorithm, i.e. the
higher its value, the more likely the algorithm is to remove edges. in very unstructured
processes, where precedence relations are likely to have a balanced signiﬁcance, it is
often useful to use a lower utility ratio, such that correlation will be taken more into
account and resolve such ambiguous situations. on top of that, a high edge cutoff will
act as an ampliﬁer, helping to distinguish the most important edges.
note that our edge ﬁltering approach starts from an empty set of precedence rela-
tions, i.e. all edges are removed by default. only if an edge is selected locally for at least
one node, it will be preserved. this approach keeps the process model connected, while
clarifying ambiguous situations. whether an edge is preserved depends on its utility for
describing the behavior of the activities it connects – and not on global comparisons
with other parts of the model, which it does not even interact with.
topcomplete0.517midtopcomplete0.4060.7950.815
sponsorscomplete0.4730.0490.697
toolbarcomplete0.4080.0820.697
layout_ﬁles/_rootcomplete0.8960.0150.672
bottomcomplete0.4170.0410.638
witcomplete0.6570.0510.660
zwartcomplete0.6100.3640.651
stylescomplete0.7850.0240.676
introductioncomplete0.4300.1570.653subtopcomplete0.4370.3430.768processmining/_rootcomplete1.0000.0400.6970.0380.846
0.0960.6710.2210.6180.0230.5510.1250.7030.0460.7340.0790.6670.0380.3800.4220.6980.8960.8200.0010.395
0.0260.6400.0290.675
0.0081.0000.0320.7190.2270.4940.0590.7490.2060.5980.4790.6790.4720.6370.0680.6690.0370.6510.0660.4840.0310.7660.0200.660
0.4290.6850.0620.4530.9810.6740.0610.5450.1230.6400.1320.5280.0710.7080.0230.6690.0310.5890.0700.4710.0180.509
0.0200.6150.0140.4440.2410.7160.0070.4120.0750.4130.0480.4550.2950.5310.0590.4080.0490.5070.1990.4760.0230.7650.0280.781
0.9820.7260.1010.7070.1210.5170.0020.8530.1030.6200.2220.5920.2200.5560.0400.7300.0290.7640.0480.5860.5920.6120.1990.707
0.0340.5150.0560.5890.1790.4730.0310.6690.0390.9360.6700.7430.4410.4930.0600.5920.1910.6790.0320.5950.5730.6390.5410.623
0.0370.6360.0960.6270.1160.5150.0720.6270.4830.7820.0400.9040.2430.5070.1220.6500.2850.6220.0380.6510.0510.4140.0300.603
0.0160.6770.0160.4330.9840.5740.0380.5300.0730.3720.0600.4570.4920.7070.0980.3920.0120.5720.1850.3770.0370.6870.0180.744
0.1790.6150.9570.6990.0490.4060.4370.6850.0600.5680.0760.6620.1670.5200.0070.6820.0260.7360.0220.3820.0710.8430.1220.834
0.0860.6740.3920.6100.0180.4210.1840.6970.0230.6510.0930.6600.0460.5880.9140.7140.0200.6720.2660.5490.1040.630
0.0230.7020.0250.5000.0070.7940.0230.6691.0000.6140.3060.5580.0060.7180.0320.6130.0620.5650.0080.682
topcomplete0.517midtopcomplete0.4060.7950.815
subtopcomplete0.4370.8960.820
sponsorscomplete0.4730.0081.000zwartcomplete0.6100.4790.679stylescomplete0.7850.4720.637toolbarcomplete0.408bottomcomplete0.4170.9810.674
layout_ﬁles/_rootcomplete0.8960.2410.716processmining/_rootcomplete1.0000.1990.4760.9820.7260.0020.853
witcomplete0.6570.5920.612
0.0390.9360.4410.4930.5730.6390.5410.623
0.0400.9040.9840.5740.4920.707introductioncomplete0.4300.9570.6990.0070.6820.9140.714
1.0000.6140.0080.682
fig. 6. example of a process model before (left) and after (right) edge ﬁltering.
figure 6 shows the effect of edge ﬁltering applied to a small, but very unstructured
process. the number of nodes remains the same, while removing an appropriate subset
of edges clearly brings structure to the previously chaotic process model.
5.3 node aggregation and abstraction
while removing edges brings structure to the process model, the most effective tool for
simpliﬁcation is removing nodes. it enables the analyst to focus on an interesting subset13
of activities. our approach preserves highly correlated groups of less-signiﬁcant nodes
as aggregated clusters, while removing isolated, less-signiﬁcant nodes. removing nodes
is based on the node cutoff parameter. every node whose unary signiﬁcance is below
this threshold becomes a victim , i.e. it will either be aggregated or abstracted from. the
ﬁrst phase of our algorithm builds initial clusters of less-signiﬁcant behavior as follows.
– for each victim, ﬁnd the most highly correlated neighbor (i.e., connected node)
– if this neighbor is a cluster node, add the victim to this cluster.
– otherwise, create a new cluster node, and add the victim as its ﬁrst element.
whenever a node is added to a cluster, the cluster will “inherit” the ordering rela-
tions of that node, i.e. its incoming and outgoing arcs, while the actual node will be
hidden. the second phase is merging the clusters, which is necessary as most clusters
will, at this stage, only consist of one single victim. the following routine is performed
to aggregate larger clusters and decrease their number.
– for each cluster, check whether all predecessors or all successors are also clusters.
– if all predecessor nodes are clusters as well, merge with the most highly correlated
one and move on to the next cluster.
– if all successors are clusters as well, merge with the most highly correlated one.
– otherwise, i.e. if both the cluster’s pre- and postset contain regular nodes, the clus-
ter is left untouched.
xstart0.507cluster b2 primitives~ 0.1270.4470.902cluster c1 primitives~ 0.1560.4470.902ystart0.9270.0000.451cluster a2 primitives~ 0.1690.0000.5640.0010.676
fig. 7. excerpt of a clustered model after the ﬁrst aggregation phase.
it is important that clusters will only be merged, if the “victim” has only clusters in
his pre- or postset. figure 7 shows an example of a process model after the ﬁrst phase
of clustering. cluster acannot merge with cluster b, as they are also both connected
to nodex. otherwise, xwould be connected to the merged cluster in both directions,
making the model less informative. however, clusters bandccan merge, as b’s post-
set consists only of c. this simpliﬁcation of the model does not lessen the amount of
information, and is thus valid.
the last phase, which constitutes the abstraction , removes isolated andsingular
clusters. isolated clusters are detached parts of the process, which are less signiﬁcant
and highly correlated, and which have thus been folded into one single, isolated cluster
node. it is obvious that such detached nodes do not contribute to the process model,
which is why they are simply removed. singular clusters consist only of one, single
activity node. thus, they represent less-signiﬁcant behavior which is not highly corre-
lated to adjacent behavior. singular clusters are undesired, because they do not simplify
the model. therefore, they are removed from the model, while their most signiﬁcant
precedence relations are transitively preserved (i.e., their predecessors are artiﬁcially
connected to their successors, if such edge does not already exist in the model).14
6 implementation and application
we have implemented our approach as the fuzzy miner plugin for the prom framework
[8]. all metrics introduced in section 4 have been implemented, and can be conﬁgured
by the user. figure 8 shows the result view of the fuzzy miner, with the simpliﬁed graph
view on the left, and a conﬁguration pane for simpliﬁcation parameters on the right.
alternative views allow the user to inspect and verify measurements for all metrics,
which helps to tune these metrics to the log.
fig. 8. screenshot of the fuzzy miner, applied to the very large and unstructured log also used
for mining the model in figure 1.
note that this approach is the result of valuable lessons learnt from a great number of
case studies with real-life logs. as such, both the applied metrics and the simpliﬁcation
algorithm have been optimized using large amounts actual, less-structured data. while
it is difﬁcult to validate the approach formally, the fuzzy miner has already become
one of the most useful tools in case study applications.
for example, figure 8 shows the result of applying the fuzzy miner to a large test
log of manufacturing machines (155.296 events in 16 cases, 826 event classes). the
approach has been shown to scale well and is of linear complexity. deriving all metrics
from the mentioned log was performed in less than ten seconds, while simplifying the
resulting model took less than two seconds on a 1.8 ghz dual-core machine. while this
model has been created from the raw logs, figure 1 has been mined with the heuristics
miner, after applying log ﬁlters [14]. it is obvious that the fuzzy miner is able to clean
up a large amount of confusing behavior, and to infer and extract structure from what
is chaotic. we have successfully used the fuzzy miner on various machinery test and
usage logs, development process logs, hospital patient treatment logs, logs from case15
handling systems and web servers, among others. these are notoriously ﬂexible and
unstructured environments, and we hold our approach to be one of the most useful tools
for analyzing them so far.
7 related work
while parting with some characteristics of traditional process mining techniques, such
as absolute precision and describing the complete behavior, it is obvious that the ap-
proach described in this paper is based on previous work in this domain, most specif-
ically control-ﬂow mining algorithms [2, 14, 7]. the mining algorithm most related to
fuzzy mining is the heuristics miner, which also employs heuristics to limit the set of
precedence relations included in the model [14]. our approach also incorporates con-
cepts from log ﬁltering, i.e. removing less signiﬁcant events from the logs [8]. however,
the foundation on multi-perspective metrics, i.e. looking at all aspects of the process at
once, its interactive and explorative nature, and the integrated simpliﬁcation algorithm
clearly distinguishes fuzzy mining from all previous process mining techniques.
the adaptive simpliﬁcation approach presented in section 5 uses concepts from the
domains of data clustering and graph clustering. data clustering attempts to ﬁnd related
subsets of attributes, based on a binary distance metric inferred upon them [11]. graph
clustering algorithms, on the other hand, are based on analyzing structural properties of
graphs, from which they derive partitioning strategies [13, 9]. our approach, however,
is based on a unique combination of analyzing the signiﬁcance andcorrelation of graph
elements, which are based on a wide set of process perspectives. it integrates abstraction
and aggregation, and is also more specialized towards the process domain.
8 discussion and future work
we have described the problems traditional process mining techniques face when ap-
plied to large, less-structured processes, as often found in practice. subsequently, we
have analyzed the causes for these problems, which lie in a mismatch between fun-
damental assumptions of traditional process mining, and the characteristics of real-life
processes. based on this analysis, we have developed an adaptive simpliﬁcation and vi-
sualization technique for process models, which is based on two novel metrics, signiﬁ-
cance andcorrelation . we have described a framework for deriving these metrics from
an enactment log, which can be adjusted to particular situations and analysis questions.
while the ﬁne-grained conﬁgurability of the algorithm and its metrics makes our
approach universally applicable, it is also one of its weaknesses, as ﬁnding the “right”
parameter settings can sometimes be time-consuming. thus, our next steps will concen-
trate on deriving higher-level parameters and sensible default settings, while preserving
the full range of parameters for advanced users. further work will concentrate on ex-
tending the set of metric implementations and improving the simpliﬁcation algorithm.
it is our belief that process mining, in order to become more meaningful, and to
become applicable in a wider array of practical settings, needs to address the problems
it has with unstructured processes. we have shown that the traditional desire to model
thecomplete behavior of a process in a precise manner conﬂicts with the original goal,16
i.e. to provide the user with understandable, high-level information . the success of
process mining will depend on whether it is able to balance these conﬂicting goals
sensibly. fuzzy mining is a ﬁrst step in that direction.
acknowledgements this research is supported by the technology foundation stw,
applied science division of nwo and the technology programme of the dutch ministry
of economic affairs.
references
1. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and a.j.m.m.
weijters. workﬂow mining: a survey of issues and approaches. data and knowledge
engineering , 47(2):237–267, 2003.
2. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining: discovering
process models from event logs. ieee transactions on knowledge and data engineering ,
16(9):1128–1142, 2004.
3. r. agrawal, d. gunopulos, and f. leymann. mining process models from workﬂow logs.
insixth international conference on extending database technology , pages 469–483, 1998.
4. e. badouel, l. bernardinello, and p. darondeau. the synthesis problem for elementary net
systems is np-complete. theoretical computer science , 186(1-2):107–134, 1997.
5. j.e. cook and a.l. wolf. discovering models of software processes from event-based
data. acm transactions on software engineering and methodology , 7(3):215–249, 1998.
6. a. datta. automating the discovery of as-is business process models: probabilistic and
algorithmic approaches. information systems research , 9(3):275–301, 1998.
7. b.f. van dongen and w.m.p. van der aalst. multi-phase process mining: building instance
graphs. in p. atzeni, w. chu, h. lu, s. zhou, and t.w. ling, editors, international con-
ference on conceptual modeling (er 2004) , volume 3288 of lecture notes in computer
science , pages 362–376. springer-verlag, berlin, 2004.
8. b.f. van dongen, a.k. alves de medeiros, h.m.w. verbeek, a.j.m.m. weijters, and w.m.p.
van der aalst. the prom framework: a new era in process mining tool support. in
g. ciardo and p. darondeau, editors, application and theory of petri nets 2005 , volume
3536 of lecture notes in computer science , pages 444–454. springer-verlag, berlin, 2005.
9. s. van dongen. graph clustering by flow simulation . phd thesis, university of utrecht,
2000.
10. j. herbst. a machine learning approach to workﬂow management. in proceedings 11th
european conference on machine learning , volume 1810 of lecture notes in computer
science , pages 183–194. springer-verlag, berlin, 2000.
11. a.k. jain, m.n. murty, and p.j. flynn. data clustering: a review. acm computing surveys ,
31(3):264–323, 1999.
12. a.k.a. de medeiros, a.j.m.m. weijters, and w.m.p. van der aalst. genetic process mining:
a basic approach and its challenges. in c. bussler et al., editor, bpm 2005 workshops
(workshop on business process intelligence) , volume 3812 of lecture notes in computer
science , pages 203–215. springer-verlag, berlin, 2006.
13. a. pothen, h. d. simon, and k. liou. partitioning sparse matrics with eigenvectors of graphs.
siam j. matrix anal. appl. , 11(3):430–452, july 1990.
14. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models from event-
based data using little thumb. integrated computer-aided engineering , 10(2):151–162,
2003.