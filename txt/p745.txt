process cubes: slicing, dicing, rolling up and
drilling down event data for process mining
wil m.p. van der aalst
department of mathematics and computer science, eindhoven university of
technology, eindhoven, the netherlands;
business process management discipline, queensland university of technology,
brisbane, australia; and
international laboratory of process-aware information systems, national research
university higher school of economics, moscow, russia.
w.m.p.v.d.aalst@tue.nl
abstract. recent breakthroughs in process mining research make it
possible to discover, analyze, and improve business processes based on
event data. the growth of event data provides many opportunities but
also imposes new challenges. process mining is typically done for an iso-
lated well-dened process in steady-state. however, the boundaries of a
process may be uid and there is a need to continuously view event data
from dierent angles. this paper proposes the notion of process cubes
where events and process models are organized using dierent dimen-
sions. each cell in the process cube corresponds to a set of events and can
be used to discover a process model, to check conformance with respect
to some process model, or to discover bottlenecks. the idea is related
to the well-known olap (online analytical processing) data cubes and
associated operations such as slice, dice, roll-up, and drill-down. how-
ever, there are also signicant dierences because of the process-related
nature of event data. for example, process discovery based on events is
incomparable to computing the average or sum over a set of numerical
values. moreover, dimensions related to process instances (e.g. cases are
split into gold and silver customers), subprocesses (e.g. acquisition versus
delivery), organizational entities (e.g. backoce versus frontoce), and
time (e.g., 2010, 2011, 2012, and 2013) are semantically dierent and it
is challenging to slice, dice, roll-up, and drill-down process mining results
eciently.
key words: olap, process mining, big data, process discovery, con-
formance checking
1 introduction
like most it-related phenomena, also the growth of event data complies with
moore's law. similar to the number of transistors on chips, the capacity of hard
disks, and the computing power of computers, the digital universe is growing
exponentially and roughly doubling every 2 years [35, 40]. although this is not a2 w.m.p. van der aalst
new phenomenon, suddenly many organizations realize that increasing amounts
of \big data" (in the broadest sense of the word) need to be used intelligently
in order to compete with other organizations in terms of eciency, speed and
service. however, the goal is not to collect as much data as possible. the real
challenge is to turn event data into valuable insights. only process mining tech-
niques directly relate event data to end-to-end business processes [1]. existing
business process modeling approaches generating piles of process models are
typically disconnected from the real processes and information systems. data-
oriented analysis techniques (e.g., data mining and machines learning) typically
focus on simple classication, clustering, regression, or rule-learning problems.
process 
mining
data-oriented analysis  
(data mining, machine learning, business intelligence)process model analysis  
(simulation, verification, optimization, gaming, etc.)
performance-
oriented 
questions, 
problems and 
solutionscompliance-
oriented 
questions, 
problems and 
solutions
fig. 1. process mining provides the missing link between on the one hand process
model analysis and data-oriented analysis and on the other hand performance and
conformance.
process mining aims to discover, monitor and improve real processes by ex-
tracting knowledge from event logs readily available in today's information sys-
tems [1]. starting point for any process mining task is an event log . each event
in such a log refers to an activity (i.e., a well-dened step in some process) and
is related to a particular case (i.e., a process instance ). the events belonging to
a case are ordered and can be seen as one \run" of the process, i.e., an event log
can be viewed as a collection of traces . it is important to note that an event log
contains only example behavior , i.e., we cannot assume that all possible traces
have been observed [1].
the growing interest in process mining is illustrated by the process mining
manifesto [36] recently released by the ieee task force on process mining .
this manifesto is supported by 53 organizations and 77 process mining experts
contributed to it.
the process mining spectrum is quite broad and includes techniques for pro-
cess discovery, conformance checking, model repair, role discovery, bottleneckprocess cubes 3
analysis, predicting the remaining ow time, and recommending next steps. over
the last decade hundreds of process mining techniques have been proposed. a
process discovery technique uses as input an event log consisting of a collection
of traces (i.e., sequences of events) and constructs a process model (petri net,
bpmn model, or similar) that \adequately" describes the observed behavior.
a conformance checking technique uses as input an event log and a process
model, and subsequently diagnoses dierences between the observed behavior
(i.e., traces in the event log) and the modeled behavior (i.e., possible runs of
the model). dierent process model notations can be used, e.g., bpmn models,
bpel specications, uml activity diagrams, statecharts, c-nets, or heuristic
nets. mxml or xes ( www.xes-standard.org ) are two typical formats for stor-
ing event logs ready for process mining.
the incredible growth of event data poses new challenges [53]. as event
logs grow, process mining techniques need to become more ecient and highly
scalable. dozens of process discovery [1, 11, 12, 16, 30, 18, 24, 25, 28, 31, 41,
54, 60, 61] and conformance checking [6, 13, 14, 15, 22, 29, 31, 42, 43, 51, 59]
approaches have been proposed in literature. despite the growing maturity of
these approaches, the quality and eciency of existing techniques leave much
to be desired. state-of-the-art techniques still have problems dealing with large
and/or complex event logs and process models.
whereas traditional process mining techniques focus on the oine analysis
of solitary processes in steady-state, this paper focuses on multiple inter-related
processes that may change over time. processes may change due to seasonal
inuences, working patterns, new laws, weather, and economic development.
moreover, there may be multiple variants of the same process or the process is
composed of subprocesses. existing techniques also cannot handle multiple pro-
cess variants and/or heterogeneous collections of cases. however, in reality the
same process may be used to handle very dierent cases, e.g., in a care process
there may be characteristic groups of patients that need to be distinguished from
one another. moreover, there may be dierent variants of the same process, e.g.,
dierent hospitals execute similar care processes, and it is interesting to com-
pare them. obviously, it is very challenging to discover and compare processes
for dierent hospitals and patient groups. unfortunately, traditional techniques
tend to focus on a single well-dened process. cases can be clustered in groups
and process models can be compared, however, there are no process discovery
techniques that produce overarching models able to relate and analyze dierent
groups and process variants . for example, we have applied process discovery in
over 25 municipalities executing similar processes. however, there are no discov-
ery approaches relating these process variants.
in this paper, we propose the new notion of process cubes where events and
process models are organized using dierent dimensions (e.g., case types, event
classes, and time windows). a process cube may have any number of dimensions
used to distribute process models and event logs over multiple cells. the rst
process cube shown in figure 2(left) has three dimensions: case type ,event class
and time window . in this simple example, there is only one case type and only4 w.m.p. van der aalst
time window
event classcase type 
a
g
bcd
ef1: acdeg
2: bcfg
3: bcfg
4: acedg
5: acfg
6: acedg
7: bcedg
8: bcdeg1: ac
4: ac
5: ac
6: ac1: cdeg
4: cedg
5: cfg
6: cedg
2: bc
3: bc
7: bc
8: bc2: cfg
3: cfg
7: cedg
8: cdega
c
bcg cd
ef
g cd
eftime window
event classcase type 
drill down
gold customer silver customer
20122013
20122013
sales deliveryroll up
fig. 2. two process cubes illustrating the splitting (drilling down) and merging (rolling
up) of process cells using the case type and event class dimensions.
one event class. the cube covers multiple time windows, but only one is shown
(all cases completed in 2012). in this toy example there are only eight cases
(i.e., process instances) and seven distinct activities. the process may be split
by identifying multiple case types and/or multiple event classes. the second
process cube shown on the right-hand side of figure 2 has two case types (gold
customer and silver customer) and two event classes (sales and delivery).
the case type dimension is based on properties of the case the event belongs
to. in figure 2(right), cases 1, 4, 5, and 6 refer to a \gold customer". hence, the
cells in the \gold customer" row include events related to these four cases. the
event class dimension is based on properties of individual events, e.g., the event's
activity name, its associated resource, or the geographic location associated with
the event. in figure 2(right), the event class dimension is based on the activity
of each event. the event class \sales" includes activities a,b, andc. the
event class \delivery" refers to activities c,d,e,f, andg. the time window
dimension uses the timestamps found in the event log. a time window may refer
to a particular day, week, month, or any other period.
each cell in a process cube refers to a collection of events and possibly also
process mining results (e.g., a discovered process model) or other artifacts (e.g.,
a set of business rules). events may be included in multiple cells, e.g., sales
and delivery cells share cevents. each of the three dimensions may have an
associated hierarchy, e.g., years composed of months and months composed of
days.process cubes 5
municipality 1 municipality 2 municipality 2
municipality 3 municipality 3
municipality 4 municipality 4
fig. 3. process models showing how complaints regarding the taxation of real estate
are handled within four dutch municipalities.
figure 3 illustrates the relevance of process cubes using four variants of the
same municipal complaints handling process. the process models in figure 3
show that four of the ten municipalities involved in our coselog project1are
handling complaints related to the taxation of houses very dierently [20]. for
each of the four processes we have event data and normative process models.
the average throughput times of the four process variants are very dierent,
e.g., municipality 1 handles complaints in 22 days whereas municipality 3 uses
227 days. we aim at organizing such event data and process models in a process
cube that allows for easy comparison of processes between municipalities, over
time, and for dierent groups of citizens.
process cubes are related to the well-known olap (online analytical pro-
cessing) cubes [27] and large process model repositories [49]. in an olap cube,
one can drill-down or roll-up data, zoom into a selected slice of the overall data,
or reorder the dimensions. however, olap cubes cannot be used for process-
related data since events are ordered and belong to cases. moreover, cells are
associated to process models and not just event data. conversely, process model
repositories do not store event data. in process cubes, models and event data
are directly related. observed and modeled behavior can be compared, models
can be discovered from event data, and event data can be used the breathe life
into otherwise static process models.
this paper denes olap notions such as \slicing", \dicing", \rolling up" and
\drilling down" for event data. these can be used to compare, merge, and split
process cells at both the log and model level. the process cube notion is closely
related to divide-and-conquer approaches in process mining where huge event
logs are partitioned into smaller sublogs to improve performance and scalability.
in principle, process cubes can also be used to decompose challenging process
mining problems into smaller problems using the techniques described in [3, 5, 4].
these techniques may be used to speed-up olap operations.
1see the coselog (congurable services for local governments) project home page,
www.win.tue.nl/coselog .6 w.m.p. van der aalst
the remainder of this paper is organized as follows. section 2 introduces the
process cube notion and further motivates its relevance. section 3 formalizes the
event base used to create process cubes, i.e., the source information describing
\raw" events and their properties. the so-called process cube structure is dened
in section 4. this structure denes the dimensions of the cube. event base and
process cube structure are linked through the so-called process cube view dened
in section 5. section 6 denes the slice and dice operations on process cubes.
roll-up anddrill-down are formalized in section 7. section 8 concludes the paper
by discussing innovations and challenges.
2 process cubes
as illustrated by figure 4, event data can be used to construct a process cube .
each cellin the process cube corresponds to a set of events selected based on
the corresponding dimension values. in figure 4 there are three dimensions.
however, a process cube can have any number of dimensions n2n. moreover,
dimensions can be based on any event property. in figure 4 events are grouped
in cells based on case type , a particular event class , and a particular time window ,
i.e., one cell refers to the set of all events belonging to case type ct, event class
ec, and time window tw. the case type dimension is based on properties of the
case as a whole and not on the characteristics of individual events. hence, if
eventeis of type ct, then all events of the case to which ebelongs, also have
type ct. case type ctmay be based on the type of customer (gold of silver)
or on the total amount (e.g., <1000 or1000). the event class dimension
is based on properties of the individual events, e.g., the event's activity name,
associated resources, or geographic location. event type ( et) may depend on
the activity name, e.g., there could be three event classes based on overlapping
sets of activity names: fa;bg,fc;dg, andfeg. the time window dimension
uses the timestamps found in the event log. a time window ( tw) may refer to
a particular day, week, month, or any other period, e.g., to all events that took
place in december 2012.
an event may belong to multiple process cells because case types, event
classes, and time windows may be overlapping. process cells may be merged
into larger cells, i.e., event data can be grouped at dierent levels of granularity.
semantically, the merging of cells corresponds to the merging of the correspond-
ing event sets. one may rene or coarsen a dimension.
aprocess cube is composed of a set of process cells as shown in figure 4. per
cell one may have a predened or discovered process model. the process model
may have been discovered from the cell's event data or given upfront. moreover,
other artifacts, e.g., organizational models [56], may be associated to individual
cells.
process cubes will be used to relate dierent processes, e.g., we may be inter-
ested in understanding the dierences between gold and silver customers, large
orders and small orders, december and january, john and ann, etc. moreover,process cubes 7
time window
event classcase type 
process cell
eventnew behaviorprocess cube
cell model
  
   cell sublog
cases
timect
ectwdimension
fig. 4. a process cube relates events to dierent dimensions. each cell in the cube
corresponds to a sublog containing events and may have an associated set of models
or other artifacts (derived or given as input).
we may want to chop a larger cell into many smaller cells for eciency reasons
(e.g., distributing a time-consuming discovery task).
the three dimensions shown in figure 4 only serve as examples and may be
rened further, e.g., there may be multiple dimensions based on various classi-
cations of cases (e.g., customer type, region, size, etc.). moreover, each dimension
may have a natural hierarchical structure (e.g., a year is composed of months
and a country is composed of regions) that can be exploited for the aggregation,
renement, and selection of event data.
process cells (and the associated sublogs and models) can be split and merged
in two ways as is illustrated in figure 5. the horizontal dimension of a cell
refers to model elements (typically activities) rather than cases. the vertical
dimension of a cell refers to cases rather than model elements. consider for8 w.m.p. van der aalst
a
start completeg
bcd
ef1: acdeg
2: bcfg
3: bcfg
4: acedg
5: acfg
6: acedg
7: bcedg
8: bcdeg1: ac
2: bc
3: bc
4: ac
5: ac
6: ac
7: bc
8: bca
g
bcd
ef c1: cdeg
2: cfg
3: cfg
4: cedg
5: cfg
6: cedg
7: cedg
8: cdeg
split 
horizontally
a c f g
b c f gb cd
g
ea cd
g
e1: acdeg
4: acedg
6: acedg
7: bcedg
8: bcdeg
5: acfg
2: bcfg
3: bcfgmerge 
horizontally
split 
verticallymerge 
vertically
fig. 5. illustration of the two types of merging and splitting process cells.
example the event log depicted in the middle of figure 5. the event log consists of
8 cases and 37 events. if the log is split horizontally based on the two overlapping
event classesfa;b;cgandfc;d;e;f;gg, then we obtain two sublogs each
consisting of all 8 cases. the top-left part of figure 5 shows the new process
cell corresponding to event class fa;b;cg. model and event log abstract from
activitiesfd;e;f;gg. the top-right part of figure 5 shows the process cell
corresponding to event class fc;d;e;f;gg. note that the cell's sublog and
model abstract from activities aandb. if the log is split vertically, we could
obtain the four sublogs depicted in the lower half of figure 5. each cell contains
a subset of cases selected according to some criterion, e.g., the type of customer
or the set of activities executed. unlike the horizontal split, no individual events
are removed, i.e., all events belonging to a case are included in the cell (or no
events of the case are included).
the seven process models shown in figure 5 may correspond to discovered or
modeled behaviors. the models in the horizontally split cells are in a \part of"
relationship, i.e., they are fragments of the larger model and cover only subsets
of activities. the models in the vertically split cells are in an \is a" relationship,
i.e., they can be viewed as specializations of original model covering only subsetsprocess cubes 9
of cases. the case type and time window dimensions in figure 4 are often used to
merge or split a log vertically. the event class dimension is often used to merge
or split a log horizontally.
obviously, there are some similarities between a process cube and an olap
(online analytical processing) cube [27]. in an olap cube, one can drill-down
or roll-up data, zoom into a selected slice of the overall data, or reorder the
dimensions. as shown in [46], these ideas can be applied to event data. any
selection of cells in the process cube can be used to materialize an event log and
discover the corresponding process model. however, unlike [46] which focuses
on a multi-dimensional variant of the well-know heuristic miner [60], we aim at
a much more general approach. on the one hand, we allow for any number of
dimensions and any process mining technique (not just discovery). on the other
hand, we take into account the essential properties of event data and processes.
for example, the two types of merging and splitting process cells illustrated by
figure 5 are process-specic and do not correspond to existing olap notions.
techniques for merging and splitting process cells are related to divide-and-
conquer approaches for process mining (e.g., to distribute process discovery or
conformance checking) [3].
based on the ideas shown in figure 4, we have developed an initial prototype
(called procube ) using the process mining framework prom and the palo olap
toolset ( jpalo client and palo molap server) [39]. procube application runs as
a plugin in prom .palo is employed for its olap capabilities. the procube plug-
in creates sublogs per cell on-the-y and visualizes process models discovered
using the fuzzy [34] and heuristics [60] miner, social networks derived using
prom's social network miner [10], and dotted charts [55] computed per cell.
  
   
process cube view (pcv)event base (eb)
case
activity
resource
type
total
time process cube 
dimensions
process cube structure (pcs)materialize
(make sublog) 
apply process 
mining technique  
   
fig. 6. overview of the dierent ingredients needed to dene and use process cubes.
in the remainder, we do not focus on specic process mining techniques or
a specic implementation of the process cube notion. instead, we conceptual-
ize the essential ideas. figure 6 lists the dierent ingredients described next.
the event base (eb) contains information about actually recorded events (sec-
tion 3). these events may have dierent properties, some of which are used as
dimensions in the process cube structure (pcs) described in section 4. a pro-10 w.m.p. van der aalst
case id properties event id properties
type total timestamp activity resource cost
35654423 30-12-2012:11.02 a john 300
1 gold 1600 35654424 30-12-2012:11.06 c ann 400
35654425 30-12-2012:11.12 d pete 100
35654426 30-12-2012:11.18 e pete 400
35654427 30-12-2012:11.19 g pete 400
35655526 30-12-2012:16.10 b john 200
2 silver 900 35655527 30-12-2012:16.14 c ann 450
35655528 30-12-2012:16.26 f sue 150
35655529 30-12-2012:16.36 g sue 100
::: :::::: ::: ::: ::: ::: :::
table 1. a fragment of some event log: each line corresponds to an event.
cess cube view (pcv) uses both eb and pcs to create a concrete view. the
view may be modied using typical olap operations such as slice and dice
(section 6) and roll-up and drill-down (section 7). any process mining tech-
nique can be applied to a cell in the selected view. to do this, the cell's event
data need to be materialized to create a sublog that is used as input by con-
ventional process mining techniques. these techniques may produce (process)
models, charts, etc. the results are stored per cell and the dierent cells can be
compared systematically.
3 event base
normally, event logs serve as the starting point for process mining. these logs
are created having a particular process and a set of questions in mind. an event
log can be viewed as a multiset of traces . each trace describes the life-cycle of
a particular case (i.e., a process instance ) in terms of the activities executed.
often event logs store additional information about events. for example, many
process mining techniques use extra information such as the resource (i.e., person
or device) executing or initiating the activity, the timestamp of the event, or
data elements recorded with the event (e.g., the size of an order). table 1 shows
a small fragment of some larger event log. only two traces are shown. each
event has a unique id and several properties. for example, event 35654423 is an
instance of activity athat occurred on december 30th at 11.02, was executed by
john, and costs 300 euros. the second trace starts with event 35655526 and also
refers to an instance of activity a. note that each trace corresponds to a case,
i.e., a completed process instance. also cases may have properties as is shown
in table 1 where cases have a customer type (gold or silver) and total amount ,
e.g., case 1 was executed for a gold customer and had a total amount of 1600
euro. implicitly, an event inherits the properties of the corresponding case.
for process cubes we consider an event base , i.e., a large collection of events
not tailored towards a particular process or predened set of questions. an eventprocess cubes 11
base can be seen as an all-encompassing event log or the union of a collection of
related event logs.
properties of events have values and the dimensions of a process cube struc-
ture sets of possible property values. throughout the paper we assume the fol-
lowing universes.
denition 1 (universes). uvis the universe of possible attribute values (e.g.,
strings, numbers, etc.). us=p(uv)is the universe of value sets. uh=p(us)
is the universe of value set collections (set of sets).
note thatv2uvis a single value (e.g., v= 300),v2usis a set of values
(e.g.,v=fgold;silverg), andh2 uhis a collection of sets. for example,
h=ffa;b;cg;fc;dg;fd;e;fggorh=ffx2njx <50g;fx2nj50x <
60g;fx2njx60gg.
denition 2 (event base). anevent base eb= (e;p; )denes a set of
eventse, a set of event properties p, and a function 2p!(e6!u v). for
any property p2p,(p)(denotedp) is a partial function mapping events onto
values. ifp(e) =v, then event e2ehas a property p2pand the value of this
property is v2uv. ife62dom(p), then event edoes not have property pand
we writep(e) =?to indicate this.
the seterefers to the individual events. for example event e= 35654423 in
table 1 may be such an event. note that an event identier e2emay be gener-
ated implicitly (it has no meaning). pis the set of properties that events may or
may not have. for example, p=fcase;activity;time;resource;cost;type;totalg
corresponds to the columns in table 1. case(35654423) = 1, activity (35654423) =
a, andresource (35654423) = john are some of the properties of the rst event
in table 1. in the remainder we assume the standard properties case,activity ,
and time to be dened for all events, i.e., dom(case) = dom(activity ) =
dom(time) =e. for example, we do not allow for events not related to a case.
an attribute like resource is optional. note that denes a partial function
per property pand missing values are represented as p(e) =?. for example,
ifresource (e) =?, thene62dom(resource ) implying that edoes not have an
associated resource.
assume thatuais the set of activities appearing in eb= (e;p; ). given
a set of events e0e, we can compute a multiset of traces l2(ua)!n
where each trace 2lcorresponds to a case. for example, case 1 in table 1
can be presented as ha;c;d;e;giand case 2 ashb;c;f;gi. most control-ow
discovery techniques [1, 11, 12, 16, 30, 18, 24, 25, 28, 31, 41, 54, 60, 61] use such a
simple representation as input. this representation ignores concrete timestamps
(only the order matters) and abstracts from properties such as resource ,cost,
type, and total.
note that given an event base, one can derive additional properties. for ex-
ample, we can take dierent event properties together, e.g., ar(e) = (activity (e);
resource (e)). such derived properties may also be based on other events. for ex-
ample,st(e) =minftime(e0)je02e^case(e) =case(e0)gis the start time12 w.m.p. van der aalst
of the case ebelongs to, and sum(e) =sumfcosts(e0)je02e^case(e) =
case(e0)gare the total costs of the case ebelongs to. many useful event at-
tributes can be derived from information inside or outside the initial event base
[9]. for example, one can estimate the \stress level" of a resource working on
eventeby computing the number of queueing activities. in the remainder we
assume an event base eb= (e;p; ) that includes all properties that may serve
as dimensions of the process cube (including derived ones).
4 process cube structure
independent of the event base ebwe dene the structure of the process cube.
the structure is fully characterized by the dimensions of the cube.
denition 3 (process cube structure). aprocess cube structure is a triplet
pcs = (d;type;hier)where:
{dis a set of dimensions,
{ type2d! u sis a function dening the possible set of values for each
dimension, e.g., type (age) =f0;1;2;:::; 120gfor age2d, and
{ hier2d!u hdenes a hierarchy for each dimension such that for any
d2d: type (d) =shier(d). note that a hierarchy is merely a collection of
sets of values.
a dimension d2dhas a type type(d) and a hierarchy hier(d).type(d) is the
set of possible values and typically only a fraction of these values are present in
a concrete instance of the process cube. for example, type(cost) =nallows for
innitely many possible values.
a hierarchy hier(d) is a set of sets. for example hier(time) contains sets such
ast2011,t2012, andt2013each representing all possible timestamps in a partic-
ular year.2these sets do not need to be disjoint. for example, hier(time) may
also contain sets such as tdec 2012(all possible timestamps in december 2012),
ttue 2012(all tuesdays in 2012), and t30 12 2012(december 30th 2012). these
sets may form a hierarchy based on set inclusion, for example t2012dominates
tdec 2012becausetdec 2012t2012. sets may also be partially overlapping,
e.g.,ttue 2012\tdec 20126=;.
in order to relate an event base and a process cube structure both need to be
compatible , i.e., dimensions should correspond to properties and concrete event
property values need to be of the right type.
denition 4 (compatible). a process cube structure pcs = (d;type;hier)
and an event base eb = (e;p; )are compatible if
{dp, i.e., dimensions correspond to properties, and
{ for anyd2dande2e:d(e)2type(d).
2note that the notation txalways refers to a set of timestamps meeting constraint
x, e.g., t30 12 2012are all timestamps on the specied day.process cubes 13
there are dierent ways of dealing with missing values . the above denition
allows for missing values if ? 2 type(d). if? 62 type(d), then compatibility
implies dom(d) =e.
5 process cube view
while applying typical olap operations such as slice, dice, roll-up and drill-
down the event base eb = (e;p; ) and process cube structure pcs =
(d;type;hier) do not change. it is merely a change of the way event data is
viewed. a process cube view denes which dimensions are visible and which
events are selected.
denition 5 (process cube view). let pcs = (d;type;hier)be a process
cube structure. a process cube view is a pair pcv = (dsel;sel)such that:
{dseldare the selected dimensions,
{ sel2d!u his a function selecting the part of the hierarchy considered per
dimension. function sel is such that for any d2d:
{ sel (d)hier(d), and
{ for anyv1;v22sel(d):v1v2impliesv1=v2.
a process cube view denes a cube with k=jdseljdimensions. the maximal
number of dimensions is set by d, i.e., all dimensions dened in the process cube
structure (dseld). function selselects sets of values per dimension (including
dimensions not selected in dsel). for example, when slicing a cube one decision is
removed, but the removed dimension is still used for ltering. given a dimension
d2d,sel(d) denes the elements on the daxis. for example, sel(time) =
ft2011;t2012;t2013gstates that the time dimension has three elements. this
implies that events before 2011 are ltered out. moreover, we do not distinguish
events based on the month, day or time; only the year matters. sel(time) =
ft2011;tjan 2012;tfeb 2012;:::;t dec 2012;t2013gis an alternative view for the
time dimension. now the dierent months of 2012 are distinguished. sel(d)
hier(d) ensures that the elements of the ddimension are consistent with the
process cube structure. the last requirement ( v1v2impliesv1=v2) implies
that the elements of sel(d) are non-dominating. for example, it would not make
sense to have sel(time) =ft2012;tjan 2012gbecausetjan 2012t2012.
as shown in figure 6, the process cube view can be used to create a sublog
per cell in the process cube view based on the event base. these sublogs can
be viewed as conventional event logs and any process mining technique can be
applied to them.
denition 6 (materialized process cube view). let process cube struc-
ture pcs = (d;type;hier)and event base eb = (e;p; )be compatible.
the materialized process cube for some view pcv = (dsel;sel)of pcs is
meb;pcv =f(c;events (c))jc2cellsgwith cells =fc2dsel! u sj
8d2dselc(d)2sel(d)gbeing the cells of the cube and events (c) =fe2ej
8d2dseld(e)2c(d)^ 8d2dd(e)2ssel(d)gthe set of events per cell.14 w.m.p. van der aalst
cells is the collection of cells of the cube. a c2cells is an assignment of each
visible dimension to precisely one element of that dimension, e.g., c(time) =
tjan 2012,c(resource ) =fjohn;peteg, andc(type) =fgoldg.events (c) are all
events corresponding to cell c(rst requirement: 8d2dseld(e)2c(d)) and not
ltered out (second requirement: 8d2dd(e)2ssel(d)).
denition 6 provides the interface to existing process discovery [1, 11, 12, 16,
30, 18, 24, 25, 28, 31, 41, 54, 60, 61] and conformance checking [6, 13, 14, 15, 22,
29, 31, 42, 43, 51, 59] techniques. meb;pcv denes how to compute an event
log (called sublog) per cell. as shown in figure 6, these sublogs can be used to
compute results per cell.
note that the materialized process cube view meb;pcv may be constructed
on-the-y or pre-computed. existing olap tools often materialize views in or-
der to enable interactive analysis. however, for process mining techniques it is
typically not known how to do this eciently.
6 slice and dice
next we consider the classical olap operations in the context of our process
cubes.
the slice operation produces a sliced olap cube by allowing the analyst to
pick specic value for one of the dimensions. for example, for sales data one can
slice the cube for location \eindhoven", i.e., the location dimension is removed
from the cube and only sales of the stores in eindhoven are considered. slicing
the cube for the year \2012" implies removing the time dimension and only
considering sales in 2012. the dice operation produces a subcube by allowing
the analyst to pick specic values for multiple dimensions. for example, one
could dice the sales olap cube for years \2012" and \2013" and locations
\eindhoven" and \amsterdam". no dimensions are removed, but only sales in
2012 and 2013 in stores in eindhoven and amsterdam are considered.
given the earlier formalizations, we can easily dene the slice operation for
process cubes.
denition 7 (slice). let pcs = (d;type;hier)be a process cube structure
and pcv = (dsel;sel)a view of pcs. for any d2dselandv2sel(d):
slice d;v(pcv ) = (d0
sel;sel0)withd0
sel=dselnfdg, sel0(d) =fvg, and
sel0(d0) =sel(d0)ford02dnfdg.
slice d;v(pcv ) produces a new process cube view. note that dis no longer
a visible dimension: d62d0
sel. at the same time dis used to lter events: only
eventsewithd(e)2vare considered in the new view.
denition 8 (dice). let pcs = (d;type;hier)be a process cube structure
and pcv = (dsel;sel)a view of pcs. let res 2dsel6!u hbe a restriction
such for any d2dom(res): res(d)sel(d). dice res(pcv ) = (dsel;sel0)with
sel0(d) =res(d)ford2dom(res)and sel0(d) =sel(d)ford2dndom(res).process cubes 15
dice res(pcv ) produces a process cube view having the original dimensions.
res2dsel6!u hrestricts selected dimensions. for example, if res(time) =
ftjan 2012;tjan 2013g,res(resource ) =ffjohng;fpetegg, and res(type) =
ffgold;silvergg, then dice res(pcv ) restricts the time dimension to two elements
(2012 and 2013), the resource dimension to two elements (john and pete), and
the customer type dimension to one element (both gold and silver customers).
7 roll-up and drill-down
roll-up and drill-down operations do not remove any events but change the
level of granularity of a particular dimension. for example, before drilling
down sel(time) =ft2011;t2012;t2013gand after drilling down sel0(time) =
ft2011;tjan 2012;tfeb 2012;:::;t dec 2012;t2013g. rolling up (sometimes re-
ferred to as drilling up) is the reverse. for example, sel(type) =ffgoldg;fsilvergg
is rolled up into sel0(type) =ffgold;silvergg.
denition 9 (change granularity). let pcs = (d;type;hier)be a process
cube structure and pcv = (dsel;sel)a view of pcs. let d2dselandh2uh
such that:
{hhier(d),
{sh=ssel(d), and
{ for anyv1;v22h:v1v2impliesv1=v2.
chgrd;h(pcv ) = (dsel;sel0)with sel0(d) =h, and sel0(d0) = sel(d0)ford02
dnfdg.
chgrd;h(pcv ) yields a process cube view with the original dimensions dsel.
however, dimension dis reorganized in such a way that the result is indeed a
view (e.g., elements are not dominating and consistent with the process cube
structure) and the set of possible values is unchangedssel0(d) =ssel(d).
8 conclusion
in this paper, we formalized the notion of process cubes. it gives end users
the opportunity to analyze and explore processes interactively on the basis of
a multidimensional view on event data. there is no need to extract event logs
beforehand like in traditional process mining approaches. although an initial
prototype implementation supporting the main ideas in this paper has been
realized [39], many challenges remain. in the remainder, we discuss some of
these challenges.16 w.m.p. van der aalst
8.1 comparing and visualizing dierent cells
first of all, there is the challenge of comparing and visualizing dierent cells.
how to visualize this in an eective manner? unlike the numerical values shown
in traditional olap cubes, we need to visualize models that cannot be reduced
to simple numbers. two models many be similar, but their visualizations may
be unrelated. this is not just a matter of lay-out. two process models that are
similar from a representational point of view may have very dierent behav-
iors and two process models that are dierent from a representational point of
view may have very similar behaviors [1]. here, we can benet from research on
congurable process models . a congurable process model represents a family of
process models, that is, a model that through conguration can be customized
for a particular setting [32, 47, 50, 52]. process models belonging to such a family
need to be related, just like cells in a process cube need to be related to allow
for comparison.
given a process cube, we suggest to visualize the dierent models with re-
spect to a cornerstone model . the dierent cell models are visualized as edit
operations on the cornerstone model. typical edit operations are: add/remove
activity, add/remove edge, hide/insert activity, swap activities, and sequential-
ize/parallelize activities. these edit operations have costs and are minimized
to nd the shortest path from the cornerstone model to a particular cell model.
moreover, the edit operations for the dierent cells are aligned to make the over-
all understanding of the process cube as simple as possible. one may consider
a restricted set of edit operations for block-structured process models [57] to
simplify comparison.
there are dierent approaches to obtain the cornerstone model. the corner-
stone model may be selected by the user or may be the rst or last model in
an array of cells. moreover, the model may be the greatest common divisor
(gcd) or the least common multiple (lcm) of the collection of process mod-
els considered [7]. the gcd captures the common parts of the cell models, i.e.,
all cell models are extensions of the gcd. the lcm embeds all cell models, i.e.,
all models are restrictions of the lcm. these notions are based on the observa-
tion that \hiding" and \blocking" are the essential operators needed for dening
inheritance with respect to behavior [8]. the cornerstone model may also be the
model closest to all cell models (minimal average edit distance) [38].
8.2 computing sublogs and models per cell
second, there is the problem of performance. the olap operations need to be
instantaneous to allow for direct user interaction. to realize this, cell results may
be pre-computed (materialization of event data and process mining results, e.g.,
models). however, this may be infeasible in case of many sparse dimensions.
hence, it may be better to do this on-the-y.
figure 5 already illustrated the notion of splitting/merging cells horizon-
tally/vertically. we want to do this eciently for both logs and models.process cubes 17
when merging cells one can discover the process model from scratch using
the merged event log. as this can be time-consuming, it may be better to merge
the process models. various approaches for merging process models have been
proposed in literature [33, 48]. however, these approaches only merge vertically
(cf. figure 5), whereas we also need to support the horizontal merge. moreover,
existing approaches for model merging are not taking into account the event
log. therefore, we would like to develop hybrid approaches that exploit both the
existing models and the log to create a merged model that is as close as possible
to the original models and the merged event log.
when splitting cells one can discover a process model for each of the smaller
event logs. again this may be time-consuming. moreover, after splitting, the
resulting event logs may be too small to create reliable models. therefore, we
would like to develop hybrid approaches that exploit both the original model
and the smaller event logs to create a model for each new cell. for example, the
original model may be projected using information from the sublog.
when splitting and merging process cells, one may need to preserve existing
relationships between model and event log, e.g., so-called alignments [6, 13] need
to be split and merged without losing any connections.
8.3 concept drift
the time dimension of a process cube has specic properties that can be ex-
ploited. for example, the hierarchy of the time dimension can be shared among
dierent applications. moreover, time introduces particular challenges. for ex-
ample, processes often change while being analyzed. therefore, concept drift is
mentioned as one of the main challenges in the process mining manifesto [36].
concept drift was been investigated in the context of various data mining prob-
lems [62, 37]. in [19] the problem was rst investigated in the context of process
mining. however, many challenges remain [19, 26], e.g., dealing with incremental
drifts and mixtures of periodic drifts.
drift point corresponding to a 
high frequent periodic change
drift point revealing a 
low frequent change
fig. 7. a periodically changing processes with two types of drift at dierent time
scales.
note that the time window dimension in figure 4 is dierent from the case
type and event class dimensions. in case of short-running cases, we can associate
whole cases to time windows. in case of long-running cases, we need to associate
individual events to time windows as the process may change while the instance
is running. using carefully selected feature vectors we can analyze drifts using18 w.m.p. van der aalst
sliding time windows: statistical hypothesis testing will reveal drifts if there are
signicant dierences between two successive windows. a complication is that
dierent types of drifts may be intertwined as illustrated by figure 7. the drift
points are depicted by the bars splitting the double headed arrows: the split
arrows represent two consecutive time windows having signicant dierences.
we would also like to relate process changes to contextual elements captured
by the cube's dimensions. for example, the time of the day, the weather, the
workload, or the type of customer may inuence the way cases are handled.
as an additional complication, classical conformance notions such as tness,
generalization, and precision [1, 6] cannot be applied to processes that change as
one needs to judge the result with respect to a particular time window. concept
drift is also related to on-the-y process discovery [21] where event streams are
not stored.
8.4 distributed process mining
today, there are many types of distributed systems, i.e., systems composed of
multiple autonomous computational entities communicating through a network.
the terms grid computing, multicore cpu systems, manycore gpu systems,
cluster computing, and cloud computing all refer to technologies where dierent
resources are used concurrently to improve performance and scalability. most
data mining techniques can be distributed [23], e.g., there are various techniques
for distributed classication, distributed clustering, and distributed association
rule mining [17]. these techniques cannot be applied to process mining because
events belong to cases and the ordering of events matters. yet, there is an obvious
need for distributed process mining using more ecient and eective discovery
techniques. process mining tasks become challenging when there are hundreds
or even thousands of dierent activities and millions of cases. typically, process
mining algorithms are linear in the number of cases and exponential in the
number of dierent activities.
process cubes partition event data and therefore may enable divide-and-
conquer approaches that decompose the event log based on splitting/merging
cells horizontally/vertically [3]. this was already illustrated using figure 5. we
are particularly interested in splitting logs horizontally. thus far we have devel-
oped horizontal divide-and-conquer approaches based on seses [45, 44], pas-
sages [2, 58], and maximal decompositions [5] as a decomposition strategy. as
demonstrated in [4, 5] these are merely examples of the broad spectrum of pos-
sible techniques to decompose process mining problems. given the incredible
growth of event data, there is an urgent need to explore and investigate the en-
tire spectrum in more detail. hopefully, such techniques can be used to speed-up
olap-like operations on process cubes.
acknowledgements
this work was supported by the basic research program of the national re-
search university higher school of economics (hse). the author would alsoprocess cubes 19
like to thank tatiana mamaliga for her work on realizing procube, a prototype
process cube implementation based on prom and palo (supervised by the author
and joos buijs).
references
1. w.m.p. van der aalst. process mining: discovery, conformance and enhancement
of business processes . springer-verlag, berlin, 2011.
2. w.m.p. van der aalst. decomposing process mining problems using passages. in
s. haddad and l. pomello, editors, applications and theory of petri nets 2012 ,
volume 7347 of lecture notes in computer science , pages 72{91. springer-verlag,
berlin, 2012.
3. w.m.p. van der aalst. distributed process discovery and conformance checking.
in j. de lara and a. zisman, editors, international conference on fundamental
approaches to software engineering (fase 2012) , volume 7212 of lecture notes
in computer science , pages 1{25. springer-verlag, berlin, 2012.
4. w.m.p. van der aalst. a general divide and conquer approach for process min-
ing. in m. ganzha, l. maciaszek, and m. paprzycki, editors, federated conference
on computer science and information systems (fedcsis 2013) , pages 1{10. ieee
computer society, 2013.
5. w.m.p. van der aalst. decomposing petri nets for process mining: a generic
approach. distributed and parallel databases , 31(4):471{507, 2013.
6. w.m.p. van der aalst, a. adriansyah, and b. van dongen. replaying history
on process models for conformance checking and performance analysis. wires
data mining and knowledge discovery , 2(2):182{192, 2012.
7. w.m.p. van der aalst and t. basten. identifying commonalities and dierences
in object life cycles using behavioral inheritance. in j.m. colom and m. koutny,
editors, application and theory of petri nets 2001 , volume 2075 of lecture notes
in computer science , pages 32{52. springer-verlag, berlin, 2001.
8. w.m.p. van der aalst and t. basten. inheritance of workows: an approach
to tackling problems related to change. theoretical computer science , 270(1-
2):125{203, 2002.
9. w.m.p. van der aalst and s. dustdar. process mining put into context. ieee
internet computing , 16(1):82{86, 2012.
10. w.m.p. van der aalst, h.a. reijers, and m. song. discovering social networks
from event logs. computer supported cooperative work , 14(6):549{593, 2005.
11. w.m.p. van der aalst, v. rubin, h.m.w. verbeek, b.f. van dongen, e. kindler,
and c.w. g unther. process mining: a two-step approach to balance between
undertting and overtting. software and systems modeling , 9(1):87{111, 2010.
12. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128{1142, 2004.
13. a. adriansyah, b. van dongen, and w.m.p. van der aalst. conformance checking
using cost-based fitness analysis. in c.h. chi and p. johnson, editors, ieee
international enterprise computing conference (edoc 2011) , pages 55{64. ieee
computer society, 2011.
14. a. adriansyah, b.f. van dongen, and w.m.p. van der aalst. towards robust con-
formance checking. in m. zur muehlen and j. su, editors, bpm 2010 workshops,20 w.m.p. van der aalst
proceedings of the sixth workshop on business process intelligence (bpi2010) ,
volume 66 of lecture notes in business information processing , pages 122{133.
springer-verlag, berlin, 2011.
15. a. adriansyah, n. sidorova, and b.f. van dongen. cost-based fitness in confor-
mance checking. in international conference on application of concurrency to
system design (acsd 2011) , pages 57{66. ieee computer society, 2011.
16. r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
ow logs. in sixth international conference on extending database technology ,
volume 1377 of lecture notes in computer science , pages 469{483. springer-
verlag, berlin, 1998.
17. r. agrawal and j.c. shafer. parallel mining of association rules. ieee trans-
actions on knowledge and data engineering , 8(6):962{969, 1996.
18. r. bergenthum, j. desel, r. lorenz, and s. mauser. process mining based on
regions of languages. in g. alonso, p. dadam, and m. rosemann, editors, inter-
national conference on business process management (bpm 2007) , volume 4714
oflecture notes in computer science , pages 375{383. springer-verlag, berlin,
2007.
19. r.p. jagadeesh chandra bose, w.m.p. van der aalst, i. zliobaite, and m. pech-
enizkiy. handling concept drift in process mining. in h. mouratidis and c. rol-
land, editors, international conference on advanced information systems engi-
neering (caise 2011) , volume 6741 of lecture notes in computer science , pages
391{405. springer-verlag, berlin, 2011.
20. j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst. towards cross-
organizational process mining in collections of process models and their exe-
cutions. in f. daniel, k. barkaoui, and s. dustdar, editors, business process
management workshops, international workshop on process model collections
(pmc 2011) , volume 100 of lecture notes in business information processing ,
pages 2{13. springer-verlag, berlin, 2012.
21. a. burattin, a.sperduti, and w.m.p. van der aalst. heuristics miners for stream-
ing event data. corr , abs/1212.6383, 2012.
22. t. calders, c. guenther, m. pechenizkiy, and a. rozinat. using minimum de-
scription length for process mining. in acm symposium on applied computing
(sac 2009) , pages 1451{1455. acm press, 2009.
23. m. cannataro, a. congiusta, a. pugliese, d. talia, and p. truno. distributed
data mining on grids: services, tools, and applications. ieee transactions on
systems, man, and cybernetics, part b , 34(6):2451{2465, 2004.
24. j. carmona and j. cortadella. process mining meets abstract interpretation. in
j.l. balcazar, editor, ecml/pkdd 210 , volume 6321 of lecture notes in articial
intelligence , pages 184{199. springer-verlag, berlin, 2010.
25. j. carmona, j. cortadella, and m. kishinevsky. a region-based algorithm
for discovering petri nets from event logs. in business process management
(bpm2008) , pages 358{373, 2008.
26. j. carmona and r. gavalda. online techniques for dealing with concept drift in
process mining. in advances in intelligent data analysis xi , volume 172, pages
90{102. springer-verlag, berlin, 2012.
27. s. chaudhuri and u. dayal. an overview of data warehousing and olap tech-
nology. acm sigmod record , 26(1):65{74, 1997.
28. j.e. cook and a.l. wolf. discovering models of software processes from event-
based data. acm transactions on software engineering and methodology ,
7(3):215{249, 1998.process cubes 21
29. j.e. cook and a.l. wolf. software process validation: quantitatively measuring
the correspondence of a process to a model. acm transactions on software
engineering and methodology , 8(2):147{176, 1999.
30. w. gaaloul, k. gaaloul, s. bhiri, a. haller, and m. hauswirth. log-based transac-
tional workow mining. distributed and parallel databases , 25(3):193{240, 2009.
31. s. goedertier, d. martens, j. vanthienen, and b. baesens. robust process dis-
covery with articial negative events. journal of machine learning research ,
10:1305{1340, 2009.
32. f. gottschalk, w.m.p. van der aalst, m.h jansen-vullers, and m. la rosa. con-
gurable workow models. international journal of cooperative information sys-
tems, 17(2):177{221, 2008.
33. f. gottschalk, t. wagemakers, m.h. jansen-vullers, w.m.p. van der aalst, and
m. la rosa. congurable process models: experiences from a municipality case
study. in p. van eck, j. gordijn, and r. wieringa, editors, advanced informa-
tion systems engineering, proceedings of the 21st international conference on
advanced information systems engineering (caise'09) , volume 5565 of lecture
notes in computer science , pages 486{500. springer-verlag, berlin, 2009.
34. c.w. g unther and w.m.p. van der aalst. fuzzy mining: adaptive process sim-
plication based on multi-perspective metrics. in g. alonso, p. dadam, and
m. rosemann, editors, international conference on business process management
(bpm 2007) , volume 4714 of lecture notes in computer science , pages 328{343.
springer-verlag, berlin, 2007.
35. m. hilbert and p. lopez. the world's technological capacity to store, commu-
nicate, and compute information. science , 332(6025):60{65, 2011.
36. ieee task force on process mining. process mining manifesto. in f. daniel,
k. barkaoui, and s. dustdar, editors, business process management workshops ,
volume 99 of lecture notes in business information processing , pages 169{194.
springer-verlag, berlin, 2012.
37. m. van leeuwen and a. siebes. streamkrimp: detecting change in data streams.
inmachine learning and knowledge discovery in databases , volume 5211 of lec-
ture notes in computer science , pages 672{687. springer-verlag, berlin, 2008.
38. c. li, m. reichert, and a. wombacher. the minadept clustering approach
for discovering reference process models out of process variants. international
journal of cooperative information systems , 19(3-4):159{203, 2010.
39. t. mamaliga. realizing a process cube allowing for the comparison of event
data. master's thesis, eindhoven university of technology, eindhoven, 2013.
40. j. manyika, m. chui, b. brown, j. bughin, r. dobbs, c. roxburgh, and a. by-
ers. big data: the next frontier for innovation, competition, and productivity.
mckinsey global institute, 2011.
41. a.k. alves de medeiros, a.j.m.m. weijters, and w.m.p. van der aalst. genetic
process mining: an experimental evaluation. data mining and knowledge dis-
covery , 14(2):245{304, 2007.
42. j. munoz-gama and j. carmona. a fresh look at precision in process confor-
mance. in r. hull, j. mendling, and s. tai, editors, business process management
(bpm 2010) , volume 6336 of lecture notes in computer science , pages 211{226.
springer-verlag, berlin, 2010.
43. j. munoz-gama and j. carmona. enhancing precision in process conformance:
stability, condence and severity. in n. chawla, i. king, and a. sperduti, editors,
ieee symposium on computational intelligence and data mining (cidm 2011) ,
pages 184{191, paris, france, april 2011. ieee.22 w.m.p. van der aalst
44. j. munoz-gama, j. carmona, and w.m.p. van der aalst. conformance checking in
the large: partitioning and topology. in f. daniel, j. wang, and b. weber, editors,
international conference on business process management (bpm 2013) , volume
8094 of lecture notes in computer science , pages 130{145. springer-verlag, berlin,
2013.
45. j. munoz-gama, j. carmona, and w.m.p. van der aalst. hierarchical confor-
mance checking of process models based on event logs. in j.m. colom and
j. desel, editors, applications and theory of petri nets 2013 , volume 7927 of
lecture notes in computer science , pages 291{310. springer-verlag, berlin, 2013.
46. j.t.s. ribeiro and a.j.m.m. weijters. event cube: another perspective on busi-
ness processes. in otm 2011 , volume 7044 of lecture notes in computer science ,
pages 274{283. springer-verlag, berlin, 2011.
47. m. la rosa, m. dumas, a. ter hofstede, and j. mendling. congurable multi-
perspective business process models. information systems , 36(2):313{340, 2011.
48. m. la rosa, m. dumas, r. uba, and r.m. dijkman. business process model
merging: an approach to business process consolidation. acm transactions on
software engineering and methodology , 22(2), 2012.
49. m. la rosa, h.a. reijers, w.m.p. van der aalst, r.m. dijkman, j. mendling,
m. dumas, and l. garcia-banuelos. apromore: an advanced process model
repository. expert systems with applications , 38(6):7029{7040, 2011.
50. m. rosemann and w.m.p. van der aalst. a congurable reference modelling
language. information systems , 32(1):1{23, 2007.
51. a. rozinat and w.m.p. van der aalst. conformance checking of processes based
on monitoring real behavior. information systems , 33(1):64{95, 2008.
52. a. schnieders and f. puhlmann. variability mechanisms in e-business process
families. in w. abramowicz and h.c. mayr, editors, proceedings of the 9th in-
ternational conference on business information systems (bis'06) , volume 85 of
lni, pages 583{601. gi, 2006.
53. a. sheth. a new landscape for distributed and parallel data management. dis-
tributed and parallel databases , 30(2):101{103, 2012.
54. m. sole and j. carmona. process mining from a basis of regions. in j. lilius and
w. penczek, editors, applications and theory of petri nets 2010 , volume 6128 of
lecture notes in computer science , pages 226{245. springer-verlag, berlin, 2010.
55. m. song and w.m.p. van der aalst. supporting process mining by showing events
at a glance. in k. chari and a. kumar, editors, proceedings of 17th annual
workshop on information technologies and systems (wits 2007) , pages 139{145,
montreal, canada, december 2007.
56. m. song and w.m.p. van der aalst. towards comprehensive support for organi-
zational mining. decision support systems , 46(1):300{317, 2008.
57. j. vanhatalo, h. v olzer, and j. koehler. the rened process structure tree. data
and knowledge engineering , 68(9):793{818, 2009.
58. h.m.w. verbeek and w.m.p. van der aalst. decomposing replay problems: a
case study. bpm center report bpm-13-09, bpmcenter.org, 2013.
59. j. de weerdt, m. de backer, j. vanthienen, and b. baesens. a robust f-measure
for evaluating discovered process models. in n. chawla, i. king, and a. sperduti,
editors, ieee symposium on computational intelligence and data mining (cidm
2011) , pages 148{155, paris, france, april 2011. ieee.
60. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workow models
from event-based data using little thumb. integrated computer-aided engi-
neering , 10(2):151{162, 2003.process cubes 23
61. j.m.e.m. van der werf, b.f. van dongen, c.a.j. hurkens, and a. serebrenik.
process discovery using integer linear programming. fundamenta informaticae ,
94:387{412, 2010.
62. g. widmer and m. kubat. learning in the presence of concept drift and hidden
contexts. machine learning , 23:69{101, 1996.