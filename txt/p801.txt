tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
international journal of cooperative information systems
cworld scientic publishing company
quality dimensions in process discovery:
the importance of fitness, precision,
generalization and simplicity
j.c.a.m. buijs and b.f. van dongen and w.m.p. van der aalst
faculty of mathematics and computer science, eindhoven university of technology
den dolech 2, eindhoven, the netherlands
received (day month year)
revised (day month year)
process discovery algorithms typically aim at discovering process models from event
logs that best describe the recorded behavior. often, the quality of a process discovery
algorithm is measured by quantifying to what extent the resulting model can reproduce
the behavior in the log, i.e. replay tness. at the same time, there are other measures
that compare a model with recorded behavior in terms of the precision of the model and
the extent to which the model generalizes the behavior in the log. furthermore, many
measures exist to express the complexity of a model irrespective of the log.
in this paper, we rst discuss several quality dimensions related to process discovery.
we further show that existing process discovery algorithms typically consider at most
two out of the four main quality dimensions: replay tness ,precision ,generalization and
simplicity . moreover, existing approaches cannot steer the discovery process based on
user-dened weights for the four quality dimensions.
this paper presents the etm algorithm which allows the user to seamlessly steer
the discovery process based on preferences with respect to the four quality dimensions.
we show that all dimensions are important for process discovery. however, it only makes
sense to consider precision, generalization and simplicity if the replay tness is accept-
able.
keywords : process mining, process discovery, process model quality
1. introduction
the goal of process mining is to automatically produce process models that accu-
rately describe processes by considering only an organization's records of its op-
erational processes. such records are typically captured in the form of event logs ,
consisting of cases and events related to these cases. using these event logs process
models can be discovered.
over the last decade, many such process discovery techniques have been devel-
oped, producing process models in various forms, such as petri nets, bpmn-models,
epcs, yawl-models etc. furthermore, many authors have compared these tech-
niques by focusing on the properties of the models produced, while at the same
time the applicability of various techniques have been compared in case-studies.
1tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
2
in this paper, we rst present a new high-level view on quality measures for pro-
cess discovery. this is then related to the four commonly known quality dimensions
for process discovery. we then also present the etm algorithm, which is a genetic
algorithm able to optimize the process discovery result towards any of these di-
mensions. by making use of so-called process trees [15] this algorithm ensures that
the resulting model is a sound process model describing the observed log, while,
at the same time, the model can be steered to emphasize dierent quality dimen-
sions. using the etm algorithm, we can easily explore the eects of focusing on
one dimension in isolation and on combinations of these dimensions.
traditionally, when determining the quality of a mined process model, four qual-
ity dimensions are considered, e.g. simplicity, replay tness, precision and general-
ization, where simplicity is a property of the model and the others relate the model
to the event log. in this paper, we reconsider the notion of quality of a process
mining result, by explicitly assuming the notion of a \system" outside the process
model. in previous work the system was not explicitly considered while determin-
ing the quality of a process mining result. nevertheless, the notion of the system is
often implicitly assumed when discussing quality issues. in this work, a system can
be a concrete information system implementation but can also refer to the context
of the process, e.g. the organization, rules, economy, etc. this system may allow for
people involved in the operational processes to deviate from the intended behavior
of the information system, sometimes for good reasons. we show that explicitly
considering the presence of such a \system" leads to new insights into the role of
existing quality dimensions in process mining.
the remainder of this paper is structured as follows. in section 2 we discuss
related work in the area of process model quality assessment. section 3 discusses the
research approach and relates the various contributions of this paper. in section 4
we discuss how the behavior of the system, event log and discovered process model
are related and which measures are of importance during process discovery. in
section 5, we present our etm algorithm. furthermore, we present one measure
for each of the four common quality dimensions and we present process trees as a
convenient means of modeling sound process models. in section 6, we then present
a running example which we use throughout the remainder of the paper. using this
example, we show the quality of various existing process discovery algorithms in
terms of the presented measures in section 7. section 8 then shows the results of
focusing on a subset of the quality dimensions during process discovery. here, we
use our etm algorithm to show that not considering all quality dimensions results
in poor models. subsection 8.4 shows the results when considering all dimensions
and assigning dierent weights them. in section 9 we apply existing techniques and
our etm algorithm on several real life event logs. section 10 then discusses an
extension of the approach that produces a collection of process models. section 11
concludes the paper.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
3
replay fitness
precision generalizationsimplicity‚Äúable to replay event log‚Äù ‚Äúoccam‚Äôs razor‚Äù
‚Äúnot overfitting the log‚Äù ‚Äúnot underfitting the log‚Äùprocess 
discovery
fig. 1: dierent quality dimensions for process model discovery [2]
2. related work
as mentioned in the introduction, the goal of process mining is to automatically
produce process models that accurately describe processes by considering only an
organization's record of its operational processes [2]. over the last decade many of
such process discovery techniques have been developed [6,8,12,20,22,28,29,34,45,
46]. each of these techniques uses a dierent approach to obtain a process model
describing the observed behavior. to measure how well a process model describes
the observed behavior, dierent quality dimensions are used, which are shown in
fig. 1.
the four dierent quality dimensions each cover a dierent aspect of the quality
of a process model [2{4]:
simplicity the simplicity dimension evaluates how simple the process model is to
understand for a human. this dimension is therefore not directly related
to the observed behavior but can consider the process model solitarily.
since there are dierent ways to describe the same behavior using dier-
ent process models, choosing the simplest one is obviously best. this is
also expressed by occam's razor: \one should not increase, beyond what is
necessary, the number of entities required to explain anything". however,
sometimes a complex process model can only be simplied by changing the
behavior, hence inuencing the other quality dimensions. several measures
exist to measure how simple a process model is, for an overview we refer
to [35]. however, research has also shown that size is the main complexity
indicator [36].
replay fitness the quality dimension of replay tness describes the fraction
of the behavior in the event log that can be replayed by the pro-
cess model. several dierent measures exist for this quality dimension
[2, 4, 7, 19, 21, 25{27, 34, 40, 44, 45]. some measures [27, 45] consider traces
of behavior as whole, checking if the whole trace can be replayed by the
process model. other measures consider the more detailed level of events
within a trace and try to get a more ne-grained idea of where the devia-
tions are. another important dierence between existing measures is that
some enforce a process model to be in an accepted end state when thetuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
4
whole trace is replayed. others ignore this and allow the process model to
remain in an active state when the trace ends. the most recent and robust
technique [4,7] uses a cost-based alignment between the traces in the event
log and the most optimal execution of the process model. this allows for
more exibility and distinction between more and less important activities
by changing the costs.
precision the quality dimension of precision estimates the extent of the behavior
allowed by the process model that is not observed in the event log. be-
cause of the possibly unlimited behavior of the process model, in case of
loops, only estimations of precision can be made. several measures for pre-
cision have been suggested [27, 37, 40]. one of the most recent and robust
techniques considers the partial state space constructed while replaying the
event log on the process model [37]. the unused escaping edges from states
that are visited are counted. the higher the fraction of unused edges the
more additional behavior is allowed and the less precise the model is.
generalization replay tness and precision only consider the relationship be-
tween the event log and the process model. however, the event log only
contains a part of all the possible behavior that is allowed by the system.
generalization therefore should indicate if the process model is not \overt-
ting" to the behavior seen in the event log and describes the actual system.
another explanation for generalization is the likelihood that the process
model is able to describe yet unseen behavior of the observed system [2].
to date only few measures for generalization exist. in [40] two mea-
sures for something related to generalization are proposed. however, these
measures don't consider the event log and only measure the number of du-
plicate transitions in the process model. a measure that is more in line
with the notion of generalization is presented in [4] and is based on the
work in [13, 16, 17]. this measure uses how often certain states are visited
and the number of dierent activities observed in each state. if a state is
visited very often and only few activities are observed, it is unlikely that a
new activity will be observed at the next visit. vice versa, if each visit to
a state is followed by a dierent activity, chances are very high that a next
visit will be followed by a new activity.
unlike existing approaches, we provide a process discovery technique that can seam-
lessly integrate the dierent quality dimensions (and possibly new criteria). more-
over, we provide new insights in the trade-o between these dimensions (e.g., by
analyzing the pareto front).
3. research approach
in this paper, we present a process mining algorithm that is exible with respect
to the quality dimensions it focusses on when discovering a process model and, us-
ing this algorithm, we show the relative importance of all four quality dimensions.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
5
fig. 2: research approach and the role of the various sections in this paper
figure 2 shows an overview of the approach followed in this paper. first, we care-
fully analyze the dierent quality dimensions starting from the viewpoint that we
know the \real" process model. our ndings support the importance of the four
classical quality dimensions described before (simplicity, replay tness, precision,
and generalization). then, we present the etm discovery algorithm. this discov-
ery algorithm has two distinctive features compared to traditional approaches: (1)
models are by denition free of deadlocks and other anomalies and (2) it is possible
to seamlessly prioritize the dierent quality dimensions. next to presenting the al-
gorithm it is shown (using a running example) that traditional approaches indeed
suer from the problems the etm discovery algorithm aims to avoid. subsequently,
the etm algorithm is used to analyze the relationships between the dierent qual-
ity dimensions. this analysis shows that all quality dimensions are necessary, but
that an acceptable replay tness is a prerequisite for any form of evaluation. the
ndings are validated using real-life logs from the coselog project involving 10
dutch municipalities. these experiments show that it is dicult to balance the dif-
ferent dimensions. therefore, the etm discovery algorithm does not provide one
model but a collection of complementary models characterizing the pareto front.
this paper follows the `design science' research methodology [30]. process dis-
covery is clearly a \wicked problem" [39], i.e., it involves unstable requirements
and constraints based on ill-dened environmental contexts, complex interactions
among subcomponents of the problem, and a critical dependence upon human cog-
nitive abilities to interpret results. this justies the chosen research methodology.
in table 1 we reect on the well-known seven design-science research guidelines [30].
4. quality dimensions for discovered process models
traditionally, next to simplicity three quality dimensions are considered when re-
lating an event log to a model [2{4]. replay tness quanties the fraction of the log
supported by the model, precision quanties the fraction of the model not observed
in the log and generalization quanties the likelihood that previously unseen behav-tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
6
table 1: the design-science research guidelines by hevner, march, park and ram
[30] can be used to justify the chosen research approach
guideline 1: de-
sign as an arti-
factdesign science research must produce
a viable artifact in the form of a con-
struct, a model, a method, or an in-
stantiation.clearly identiable artifacts are
the etm algorithm and corre-
sponding prom implementation.
guideline 2: pro-
blem relevancethe objective of design science re-
search is to develop technology-based
solutions to important and relevant
business problems.process mining techniques are in-
creasingly being used in industry
and there is a clear need for better
discovery algorithms.
guideline 3: de-
sign evaluationthe utility, quality, and ecacy of
a design artifact must be rigorously
demonstrated via well-executed evalu-
ation methods.dierent quality dimensions de-
scribed in literature are used and
discussed. the corresponding met-
rics are used to empirically evalu-
ate the performance of the etm
algorithm using both syntectic and
real-life data.
guideline 4: re-
search contribu-
tionseective design science research must
provide clear and veriable contribu-
tions in the areas of the design arti-
fact, design foundations, and/or design
methodologiesthe paper demonstrates that the
etm algorithm overcomes limita-
tions of existing approaches using
logical argumentation and experi-
ments.
guideline 5: re-
search rigordesign science research relies upon
the application of rigorous methods in
both the construction and evaluation
of the design artifact.the approach denes clear and un-
ambiguous criteria to evaluate dis-
covered models.
guideline 6: de-
sign as a search
processthe search for an eective artifact
requires utilizing available means to
reach desired ends while satisfying laws
in the problem environment.starting point is a detailed analysis
of the weaknesses of existing pro-
cess discovery approaches. more-
over, various data sets are used for
evaluation.
guideline 7:
communication
of researchdesign science research must be pre-
sented eectively to both technology-
oriented and management-oriented au-
diences.the paper aims to motivate the
need for better discovery algo-
rithms by showing many examples
and discussing the desired outcome
in a non-technical manner.
ior is supported by the model. in other words, the notion of generalization considers
more than just the log and the model. instead, it also uses an implicit notion of a
\system" that is being observed. in this section, we make this notion more explicit
and we consider the eect of doing so on the other quality dimensions.
4.1.a theoretical view
in fig. 3, we explicitly depict the behavior of a process model, the behavior observed
in the event log and the behavior of an observed system. it is shown how the behavior
included in these three entities can overlap, but also where they may be disjoint. in
practice there are many forms in which behavior can be described, such as traces [3],
behavioral proles [44], -relations [6], process algebra's [10], etc. however, for thetuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
7
process
modelevent
log
system1223
4
5
67m
l
s
fig. 3: venn diagram showing how the behavior of the process model (m), event
log (l) and system (s) can be disjoint or overlapping.
discussion in this paper, this is irrelevant.
the venn diagram shown in fig. 3 shows seven areas. we can intuitively describe
the behavior contained in each area as follows:
(1)modeled and observed system behavior ( l\m\s). the central black
area in the venn diagram contains all behavior that is the behavior of the
system which is observed in the event log and possible in the process model.
(2)unmodeled exceptions ( (lnm)ns). all the observed behavior that is
actually non-system behavior is considered an exception. the exceptions that
are not supported by the process model are contained in this area.
(3)modeled and observed exceptions ( (l\m)ns). modeled and observed
exceptions are those exceptions observed in the event log that are described by
the process model.
(4)modeled but unobserved and non-system behavior ( (mns)nl). this
contains all the behavior described by the process model which is non-system
behavior and is also not found in the event log.
(5)modeled but unobserved system behavior ( (m\s)nl). the behavior
described by the process model that is the system's behavior but is not seen in
the event log.
(6)unmodeled and unobserved system behavior ( (snl)nm). all the system
behavior that is neither observed in the event log nor modeled by the process
model.
(7)unmodeled but observed system behavior ( (s\l)nm). the system
behavior that is observed in the event log but not described by the process
model.
it is important to realize that there is generally no way to explicitly describetuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
8
the behavior of the system, rst of all since this behavior is typically innite, but
more so because there is always the possibility of unforeseen behavior in any real-
world system that may even change over time. nonetheless, the traditional goal of
process mining is to nd a process model that describes this system as accurately as
possible, using nothing more than the observed behavior in the log . in the remainder
of section 4.1, we assume that the behavior of the system is known. in section 4.2
we show how to deal with the fact that the behavior of the system is generally not
known.
relating the behavior allowed by the process model and that recorded in the
event log, we can distinguish two measures commonly used in information retrieval.
the precision between the process model and the event log expresses the amount
of behavior not seen in the event log that can be produced by the process model.
this can be expressed as:
model-event log precision =jl\mj
jmj
the recall between the model and the event log relates the behavior of the event
log that can be produced by the process model versus all the observed behavior in
the event log:
model-event log recall =jl\mj
jlj
precision and recall between the process model and the event log follow the
common notions of precision and recall in information retrieval. however, in process
mining the problem setting is a bit dierent. in information retrieval instances
should be classied correctly from a large set of instances. in process mining however
we have observed instances in the event log that the process model should describe.
this event log is created by, or obtained from, a system. so the behavior observed
in the event log can also be related to the behavior of the system. this can be
expressed by precision and recall between the event log and the system:
event log-system precision =jl\sj
jlj
this expresses the fraction of the observed behavior in the event log that is
included in the system.
the amount of overlap between the observed behavior recorded in the event log
and the behavior of the system can be expressed as follows:
event log-system recall =jl\sj
jsj
this expresses the fraction of the behavior of the system and seen in the event
log, with respect to all the behavior of the system.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
9
the behavior allowed by the process model can also be compared to the behavior
of the system. then again, precision can be calculated, but now for the process
model w.r.t. the system. this is expressed as:
model-system precision =js\mj
jmj
this fraction thus expresses the fraction of behavior that is allowed by the
process model, but is not part of the behavior of the system.
finally, recall between the model and the system expresses the fraction of the
behavior expressed by the process model that is also the behavior of the system:
model-system recall =js\mj
jsj
if all these six fractions are one then the three circles of the venn diagram of
fig. 3 coincide and if all fractions are zero, then the three circles are disjoint.
in process mining, we start from a given event log l which comes from a given
system s, i.e. l and s are constant. if we assume that s is known then we could
simply use a genetic algorithm to discover a process model m which maximizes all
of the fractions. however, the behavior of the system is unknown, but can, to some
extent, be estimated from l.
4.2.dealing with an unknown system
when considering the notion of a system, we rephrase the goal of process mining to:
discover a process model m from a given log l taken from an unknown, but constant
system s, which maximizes all fractions listed in section 4.1 .
the notion of model-event log precision directly relates to the existing quality
dimension precision discussed in section 2 and model-event log recall relates to
replay tness discussed there. furthermore, if l and s are constant, then the event
log-system precision and recall are constant, i.e. these fractions become irrelevant
for process discovery. in fact, many papers about process mining use the notion of
noise to describe behavior observed in the log, but not part of the system (i.e. the
noise level corresponds to 1  event log-system precision). furthermore, a certain
level of completeness is often assumed which refers to the completeness of the log
with respect to the system, i.e. event log-system recall.
things become more complex when we consider model-system precision and
model-system recall under the assumption that the system is unknown. basically,
these metrics cannot be computed or estimated without further assumptions. typi-
cally, process discovery algorithms use a hidden assumption that the process model
they discovered from the event log does not include behavior outside of the system,
i.e. they assume that ms, hence model-system precision is one. this leaves the
model-system recall to be estimated.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
10
finally, the model-system recall represents the fraction of the system which is
covered by the model, i.e. if this recall is high then any behavior of the system can
be explained with the model, regardless of whether this is observed or unobserved
behavior. under the assumption that ms, this is what is traditionally referred
to as generalization.
in section 5 of this paper, we present the etm algorithm, which is a process
discovery algorithm that in many aspects makes the same assumptions about the
relations between the log, the system and the model as other algorithms. the im-
portant dierence is that the focus on the quality dimensions can be parameterized.
however, before we introduce this algorithm, we present some requirements on how
the various quality aspects should be measured.
4.3.measure requirements
several measures can be created to indicate the quality of a process model in a cer-
tain dimension. however, there are some important requirements that each measure
should follow.
ecient implementation although in general the quality of a process model
is only measured when it is required by the user, the implementation should
still be ecient. for some measures the most easy way of calculation is also
the most time consuming one. however, the user likely wants an almost instant
answer. furthermore, genetic algorithms, as the one we will present in section 5,
need to call each measure very often. therefore, the performance of a genetic
algorithm mainly depends on the time required by the measures to evaluate the
process models [31, 32]. approximation of the quality can greatly improve the
performance of algorithms depending on the measurement.
intuitive results the main requirement for measures is that the results are in-
tuitive. process models that are extremely good or bad according to a certain
measure should also be considered the best or worst according to the quality
dimension the measure is related to. the same holds for a process model that
according to the measure is slightly better or worse than another process model.
why it is better or worse, and by `how much' should follow the philosophy of the
quality dimension [11]. probably even more important is that the user agrees
with the result, since tness evaluation is mainly an estimation of the user's
preference [31].
clear specication the specication of the measure, e.g. the way it is calcu-
lated, should also be clear. if the specication cannot be understood, it cannot
be veried why a certain process model has a certain value assigned to it. fur-
thermore, the measures should require as few parameters as possible since they
make interpreting the results dicult if the parameter settings are unknown.
furthermore, in certain situations, parameters can change the results of a mea-
sure dramatically. this makes a measure unclear and less authoritative. the
measure should be robust to dierent situations without requiring parameters.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
11
where possible, the measurement should be a proper metric [33], where triangle
inequality is the most important property.
orthogonal dierent measures should be orthogonal to each other. if two mea-
sures both punish or reward certain aspects of a process model then that aspect
is over-emphasized. this should be expressed by aiming at a good score for
one measure that considers this aspect. if two measures overlap, the results be-
come unclear and one of the measures is redundant. furthermore, each measure
should only cover a single quality dimension for the same reason.
an exception to this rule is incorporating additional specic user preferences.
those preferences are rarely independent of functional requirements on the
process model. they should however be incorporated if the user desires to do
so. however, the measurements for the recall and precision between the system,
event log and process model should only be concerned with that aspect.
5. process trees and the etm algorithm
as stated in the introduction, we use the etm algorithm to see the eects of (not)
considering either of the four quality dimensions in process discovery. to this end,
we rst introduce process trees, which we use throughout the paper.
5.1.process trees
traditional languages like bpmn, petri nets, uml activity diagrams may be con-
venient ways of representing process models. however, only a small fraction of all
possible models in these languages is sound [5], i.e. many models contain deadlocks,
livelocks and other anomalies. especially for the results presented in this paper,
where the focus is on measuring the quality of the resulting models, it is essen-
tial that such unsound constructs are avoided. therefore, we choose to use process
trees to describe our models since all possible process trees represent sound process
models.
fig. 4 shows the possible operators of a process tree and their translation to a
petri net. a process tree contains operator nodes and leaf nodes. operator nodes
specify the relation between its children. possible operators are sequence ( !), paral-
lel execution (^), exclusive choice ( ), non-exclusive choice ( _) and loop execution
(	). the order of the children matters for the operators sequence and loop. the
order of the children of a sequence operator specify the order in which they are exe-
cuted (from left to right). for a loop, the left child is the `do' part of the loop. after
the execution of this `do' part the right child, the `redo' part, might be executed.
after this execution the `do' part is again enabled. the loop in fig. 4 for instance
is able to produce the traces hai,ha;b;ai,ha;b;a;b;aiand so on.
although also making use of a tree structure, a slightly dierent approach is
taken by the rened process structure tree (rpst) [43]. the rpst approach
provides \a modular technique of workow graphs parsing to obtain ne-grainedtuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
12
a
b
ba
a
ba
bsequence
exclusive choice
loopparallellism
or choicea b
fig. 4: relation between process trees and block-structured petri nets.
fragments with a single entry and single exit node" [43]. the content of these frag-
ments are graphs themselves and are not necessarily block-structured nor sound.
each operator in a process tree however results in a block structured process part
with a single entry and single exit node. each block in a process tree can only
contain a predened control ow construct, which are shown in fig. 4. therefore,
workow graphs decomposed into an rpst can be more expressive than process
trees but an rpst is not necessarily sound while a process tree always is.
5.2.the representational bias of process trees
as mentioned, the main benet of working with process trees is the inherent sound-
ness of block structured process models. this is an especially important property
when working with genetic algorithms since they evaluate many process models.
because process trees are inherently sound, no additional eort has to be spend
in detecting or xing unsound process models. besides soundness, there are other
aspects that should be considered when determining the representation used by a
process discovery algorithm. as discussed in [1] the internal representation chosen
by a discovery algorithm can imply important limitations on the results it can pro-
duce. the main limitation that process trees have is the inability to express non-local
dependencies without duplicating some of the activities involved. the genetic miner
by alves de medeiros [34] for instance uses a causal matrix to represent petri nets.
this allows them to produce process models that contain non-local dependencies.
however they also often result in unsound process models, as is shown in section 9.
on the other hand, process models containing only local dependencies often pro-
vide a good compromise between expressive power and analyzability. therefore,
by using process trees as our internal representation we ensure soundness while at
the same time maintaining enough expressive power. furthermore, as we discuss in
section 10, our algorithm can easily be extended to return multiple process mod-
els. this allows us to return dierent process models that either ignore non-local
dependencies or that explicitly capture these by duplicating certain activities.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
13
5.3.translation of process trees to other notations
process trees can be quite trivially translated to any of the well-known process
modeling languages such as bpmn, epc, petri-net, etc. because of its inherent
block structure, the translation of process trees to other modeling languages results
in clean process models with a clear structure. one of the most commonly used
process modeling languages in industry is the bpmn notation [38]. all process
trees that we will present as a result of our etm algorithm will therefore also
be shown in the bpmn process modeling notation. the translation is done in a
similar way as the translation to petri nets, as shown in fig. 4. it should be noted
however that process trees can easily be translated to any of the well-known process
modeling languages.
5.4.quality of process trees
to measure the quality of a process tree, we consider one measure for each of the four
quality dimensions discussed in section 4.2. we based these measures on existing
work in each of the four areas and we adapted them for process trees [2, 4, 19, 35{
37,40].
simplicity quanties the complexity of the model. simplicity is measured by com-
paring the size of the tree with the number of activities in the log. this is
based on the observation that the size of a process model is the main factor for
perceived complexity and introduction of errors in process models [36]. further-
more, since we internally use binary trees, the number of leafs of the process
tree corresponds to the number of operator nodes. thus, if each activity is rep-
resented exactly once in the tree, that tree is considered to be as simple as
possible. therefore, simplicity is calculated as follows:
qs= 1 #duplicate activities + #missing activities
#nodes in process tree + #event classes in event log
duplication of activities is measured by counting the number of times the ac-
tivity is repeated in the process model. an activity is missing from the process
model if it is not included in the process model while it is present in the event
log. these numbers are summed up and normalized by the total number of
nodes in the process tree and event classes (or activities) in the event log.
this simplicity metric breaks the orthogonal requirement since leaving out,
or duplicating activities in the process model, can be benecial for the quality
dimensions replay tness and precision. however, this metric is mainly used to
encode user preferences.
replay tness quanties the extent to which the model can reproduce the traces
recorded in the log. we use an alignment-based tness computation dened
in [4] to compute the tness of a process tree. basically, this technique aligns
as many events as possible from the trace with activities in an execution of the
model (this results in a so-called alignment ). if necessary, events are skipped, ortuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
14
activities are inserted without a corresponding event present in the log. penalties
are given for skipping and inserting activities. the nal replay tness score is
calculated as follows:
qrf= 1 cost for aligning model and event log
minimal cost to align event log on model with no synchronous moves
where the denominator is the minimal costs when no match between event log
and process model can take place (e.g. worst case scenario). this is used to
normalize the replay tness to a value between 0 and 1.
calculating the alignments is a complex task and therefore takes relatively
much time. this breaks with the rst measurement requirement of ecient
implementation. however, currently it is the most robust way of relating the
process model with the event log. moreover, the next two quality measures
use the information provided by the alignments without requiring additional
complex computations.
precision indicates how much additional behavior the process model allows that
is not seen in the event log. it therefore compares the state space of the tree
execution while replaying the log. our measure is inspired by [37] and counts
so-called escaping edges, i.e. decisions that are possible in the model, but never
made in the log. if there are no escaping edges, precision is considered to be
perfect. we obtain the part of the state space used from information provided
by the replay tness, where we ignore events that are in the log, but do not
correspond to an activity according to the alignment. in short, we calculate the
precision as follows:
qp= 1 p
visited markings#visits#outgoing edges  #used edges
#outgoing edges
#total marking visits over all markings
generalization estimates how well the process model describes the (unknown)
system, and not only the event log. if all parts of the process model are fre-
quently used, the process model is likely to be generic. however, if some parts
of the process model are rarely used, chances are high that the system actually
allows for more behavior. therefore we base the generalization measure on how
often parts of the process model have been used while replaying the event log.
for this we use the alignment provided by the replay tness. if a node is visited
more often then we are more certain that its behavior is (in)correct. if some
parts of the tree are very infrequently visited, generalization is bad. therefore,
generalization is calculated as follows:
qg= 1 p
nodes(p#executions) 1
#nodes in tree
the square root is taken from the number of executions because the eect of
having 10 executions instead of 1 is considered a more signicant improvement
than from 10 to 100 executions. from each of these values the power of  1 is
taken to normalize it to a value between 0 and 1. then these values are summedtuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
15
and divided by the total number of nodes in the tree to get the average for the
whole tree.
generalization is currently the quality dimension that is most dicult to
express. however, results show that this measure for generalization follows the
intuition for this quality dimension.
the four measures above are computed on a scale from 0 to 1, where 1 is optimal.
replay tness, simplicity and precision can reach 1 as optimal value. generalization
however can only reach 1 in the limit i.e., the more frequent the nodes are visited,
the closer the value gets to 1. the exibility required to nd a process model that
optimizes a weighted sum over the four measures can eciently be implemented
using a genetic algorithm.
5.5.the etm algorithm
as discussed in section 1 we propose the use of a genetic algorithm [14,15] for the
discovery of process models from event logs. evolutionary algorithms have been
applied to process mining discovery before in [34]. our approach follows the same
high-level steps as most evolutionary algorithms [24]. the overall approach is shown
in fig. 5. the main improvements with respect to [34] are the internal representation
and the tness calculations. by using a genetic algorithm for process discovery we
gain exibility: by changing the weights of dierent tness factors we can guide the
process discovery.
by using process trees as our internal representation we only consider sound
process models . this drastically reduces the search space and therefore improves
the performance of the genetic algorithm. furthermore, we can apply standard
tree change operations on the process trees to evolve them further. finally, in our
tness calculation we consider all four quality dimensions for process models: replay
tness, precision, generalization and simplicity. the user can specify the relative
importance of each dimension beforehand . the etm algorithm (which stands for
evolutionary tree miner ) will then favor those candidates that have the correct
mix of the dierent quality dimensions.
in general, our genetic algorithm follows the process as shown in fig. 5. the
input of the algorithm is an event log describing observed behavior. in the initial
result
fig. 5: the dierent phases of the genetic algorithm.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
16
step a population of random process trees is generated where each activity occurs
exactly once in each tree. next the four quality dimensions are calculated for each
candidate in the population. using the weight given to each dimension the overall
tness of the process tree is calculated. in the next step certain stop criteria are
tested such as nding a tree with the desired overall tness. if none of the stop
criteria are satised, the candidates in the population are changed and the tness is
again calculated. this is continued until at least one stop criterion is satised and
the ttest candidate is then returned.
5.5.1. change operations
we apply three dierent change operations to the process trees in the population:
replacement, crossover and mutation. the replacement operation is a rather drastic
one: it replaces the worst process trees in the population with random new ones. the
next change operation, crossover , takes two process trees and swaps two subtrees
between them, resulting in two new process trees. currently the subtrees are selected
randomly. however, crossover in general does not guarantee to improve the overall
quality of a process tree. therefore we only apply it in a few cases to increase the
diversity of the population.
the most important change operation we apply is that of mutation . several
mutation operations have been implemented where we make a distinction between
random mutation and guided mutation. currently, three random mutations have
been implemented: adding a node, removing a node and changing a node. exam-
ples of these mutations are shown in fig. 6. none of these mutations guarantee
improvement in any of the quality dimensions, since the operations are applied ran-
domly. furthermore, since we use binary trees in the current implementation, these
mutation operations need to perform additional actions to maintain this binary
form.
using the information provided by the replay tness measure, mutation can be
applied more eciently. for instance, when the replay tness indicates that a certain
activity is often observed in the event log but cannot be replayed in the process tree,
we can add the activity in that location. vice versa, if the replay tness indicates
that an activity, or even a whole subtree, is often skipped then this can be removed.
!
cba
(a) refer-
ence tree.!
cb^
da
(b) adding d
in parallel to
a!
ca
(c) re-
moving
b^
cba
(d)
change
root to^.
fig. 6: examples of possible edits on a tree (a).tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
17
a combination of these operations is updating an activity to a more appropriate
activity. finally, information is also recorded about the behavior of the control-ow
nodes. for instance, if we observe that an ^operator always rst executes the whole
left hand side tree and then the complete right hand side tree, we can change the
operator type to a !to improve precision. please note that the guided mutation
operations are applied using thresholds. since the importance of dierent quality
dimensions can be changed, it might be benecial to improve precision at the cost
of replay tness for instance. none of the mutation operations guarantee improving
one quality dimension without reducing another but in general improve at least one
quality dimension.
our genetic algorithm has been implemented as a plug-in for the prom frame-
work. we used this implementation for all experiments presented in the remainder.
the algorithm stops as soon as a perfect candidate was found, i.e. with optimal
tness, or after 1 :000 generations. in [15] we have shown that 1 :000 generations
are typically enough to nd the optimal solution, especially for processes with few
activities. all other settings were selected according to the optimal values presented
in [15].
6. running example
throughout the remainder of the paper, we use a running example, describing a
simple loan application process of a nancial institute, providing small consumer
credit through a webpage. when a potential customer lls in a form and submits
the request on the website, the process is started by activity awhich is sending an
e-mail to the applicant to conrm the receipt of the request. next, three activities
are executed in parallel. activity bis a check of the customer's credit history with a
registration agency. activity cis a computation of the customer's loan capacity and
activity dis a check whether the customer is already in the system. this check is
skipped if the customer lled in the application while being logged in to the personal
page, since then it is obsolete. after performing some computations, the customer
is notied whether the loan was accepted (activity e, covering about 20% of the
cases) or rejected (activity f, covering about 80% of the cases). finally, activity g
is performed, notifying the applicant of the outcome.
a petri net of the loan application model is shown in fig. 7 and the log we
obtained through simulation is shown in tab. 2.
7. results of current process discovery algorithms
in order to validate that our small running example provides enough of a challenge
for existing process discovery techniques, we applied several existing techniques,
many of which resulted in unsound process models. we translated the behavior of
each model to a process tree, in order to measure the quality of the result. where
applicable, we stayed as close as possible to the parallel behavior of the original
model. fig. 8 to 14 show the results of the various algorithms.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
18
table 2: the event log
trace # trace #
a b c d e g 6 a d b c f g 1
a b c d f g 38 a d b c e g 1
a b d c e g 12 a d c b f g 4
a b d c f g 26 a c d b f g 2
a b c f g 8 a c b f g 1
a c b e g 1
fig. 7: petri net of a loan application pro-
cess. ( a= send e-mail, b= check credit,
c= calculate capacity, d= check system,
e= accept, f= reject, g= send e-mail)
for all algorithms, unless mentioned otherwise, the publicly available version,
as included in the prom process mining frameworka, version 6:2, has been used.
7.1.thealgorithm
one of the earliest process discovery algorithms is the algorithm [6]. the -
algorithm is one of the most basic process discovery algorithms, and does not take
any parameters. the result of the algorithm is exactly the petri net shown at
the left hand side of fig. 8. this petri net can be easily translated to the process
tree notation without changing the intended behavior. the process tree that is the
result of this translation is shown at the right hand side of fig. 8. please note that
activities eand fin the petri net also function as a silent parallel join. in the
process tree this has been split in a control ow node (as parents of b,candd) and
a choice between activities eandf.
!!
g
fe!^^
dcbaf: 0.992 p: 0.995
s: 1.000 g: 0.889
fig. 8: result of the algorithm [6] (sound)
next to the process tree obtained after conversion is a table that shows the
results of the applied metrics, one for each of the four quality dimensions. the
replay tness of 0 :992, indicated by the `f' character, indicates that the process tree
is able to replay almost all behavior. only skipping activity d, which sometimes
happens in the event log, is not possible in the process models. the precision score
of 0:995, as is indicated by the `p' character, shows that the process model does not
allow for too much additional behavior. this is caused by the fact that the event log
does not include all the possible orders of b,candd. simplicity is perfect (s=1 :000)
athe prom framework can be obtained via www.promtools.orgtuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
19
since all activities are included exactly once. generalization is not bad with a score
of 0:889, especially considering that generalization can only reach 1 :000 in the limit.
7.2.the ilp miner
a process discovery algorithm that ensures perfect replay tness is the ilp
miner [46]. the result of running this algorithm on the running example`s event
log is shown at the left hand side of in fig. 9. this result is obtained by using the
following, mostly default, parameters: `java-ilp and lpsolve' as solvers, `petri net
(empty after completion)' as ilp variant, number of places per causal dependency
and enabled the option of `search for separate initial places'. none of the ilp ex-
tensions were enabled. the ilp miner directly produced the petri net as shown in
fig. 9.
!!
g
fe!^^
dcbaf: 1.000 p: 0.784
s: 0.933 g: 0.830
fig. 9: result of the ilp miner [46] (ensuring empty net after completion, sound)
also this petri net can be directly translated to a process tree, without changing
its behavior. the guarantee of the ilp miner, that it always produces a perfectly
tting process model, is indicated by the perfect score for replay tness. however,
this comes as the cost of precision, as is shown by the precision value of 0 :784. this
is caused by the model allowing for loops of activity dwhile the event log never
contains more than one instance of dper trace. simplicity is not perfect because
atransition has been introduced and because of this generalization is also a bit
worse than for the previous process model.
7.3.language-based region theory
the result of the language-based region theory [12] can be obtained by running the
ilp miner plug-in and set the number of places to `basic representation', disable
the `search for separate initial places' checkbox and check the option to discover an
`elementary net'. this produces the petri net that is shown in fig. 10. it is clear
to see that the resulting model is overly complex and incomprehensible.
the translation to a process tree results in the process tree as is shown in
fig. 10. since there is no option to skip dthe replay tness score is only 0 :992. the
process model also includes activities e,fandgin the parallel part, which results
in a precision of 0 :957 since these are always strictly executed at the end of the
process. simplicity on the process tree is perfect since each activity occurs exactlytuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
20
!^!!
g
fe^
cbda f: 0.992 p: 0.957
s: 1.000 g: 0.889
fig. 10: result of the language-based region theory [12] (the model is overly com-
plex and incomprehensible, but sound)
once. note that the translation from the petri net to the process tree simplied the
model drastically, while maintaining its behavior. finally generalization is at the
best value that can be obtained for this particular event log.
7.4.heuristic miner
the heuristics miner [45] has been developed to be more noise-resistant than most
other process discovery algorithms. when applied to running example the petri net
as shown in the left hand side of fig. 11 is obtained, after converting the heuristics
net to a petri net. all thresholds and other default settings (e.g. `all tasks connected'
enabled and `long distance dependency' disabled) were maintained. other settings
were experimented with but did not result in a process model with a better quality
score. unfortunately, the resulting petri net is not sound. tokens are left in the
petri net for instance before task bwhen the following ring sequence is executed:
ha;c;e;gi.
!
!
g
fe!
^
d^
cb^
cbaf: 1.000 p: 0.986
s: 0.875 g: 0.852
fig. 11: result of the heuristic miner [45] (unsound, tokens are left behind.)
since the petri net is not sound, it is not possible to directly translate it to
a process tree. therefore the process tree as shown in fig. 11 represents a sound
interpretation of the intended behavior of the petri net. most notably is the choice
between two dierent parallel branches, one with dand the other without. this is
as the process model was meant as discovered by the heuristic miner, as is indicated
by the two silent transitions in the beginning of the petri net.
the dierent quality measures of the process tree show that the process tree can
correctly replay all the behavior recorded in the event log. the precision is however
not perfect and a bit worse than the process tree discovered by the algorithm.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
21
simplicity is not perfect because of the duplication of activities band c. finally,
generalization is low considering the other process models.
7.5.multi-phase miner
the result after running the multi-phase miner [22] as included in prom 5 :2, with
the default settings, results in an epc model. converting this epc to a petri net
results in the petri net as shown at the left hand side of hand side of fig. 12. the
process model is relaxed sound but is not easy to understand due to all the silent
transitions before and after activities b,cand d. the process tree relations show
that all these three activities are included in an _construct, and can therefore be
skipped. although this results in a perfect replay tness, it is not very precise since
activities bandcare never skipped in the event log. generalization is as high as it
reasonably can be for this event log and simplicity is perfect.
!!
g
fe!__
dcbaf: 1.000 p: 0.830
s: 1.000 g: 0.889
fig. 12: result of the multi-phase miner [22] (model is guaranteed \relaxed sound"
and the tree reects this.)
7.6.the genetic miner
the genetic miner [34] is run with a population of 20, a target tness of 1 :0 and for
a maximum of 10 ;000 generations. the result is an unsound petri net since tokens
are left behind before task ewhen executing the activities ha;b;c;d;f;gi.
!
g!^
b
!
fec
!
e^
dc^
d!
fca f: 1.000 p: 0.922
s: 0.737 g: 0.790
fig. 13: result of the genetic miner [34] (unsound, tokens left behind.)
when translating the behavior described by this model, for example the fact that
the activities banddare parallel to f, we obtained the process tree as shown at thetuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
22
right hand side in fig. 13. although replay tness is perfect in the translated process
tree, precision is mediocre. simplicity is rather low, caused by the duplication of
several activities. this also inuenced generalization since the process tree contains
several choices between dierent process model parts.
7.7.state-based region theory
applying the state-based region theory [9,18,23,41], by executing the plug-in `mine
transition system' followed by a conversion to petri nets using region theory, results
in the petri net as shown in fig. 14. for the transition system mining the default
settings the maximum set size has been set to unlimited and all activities have been
included.
!!
g
fe!^^
dcbaf: 1.000 p: 0.893
s: 0.933 g: 0.830
fig. 14: result of the state-based region theory
the resulting petri net is sound and includes the option to execute activities
eand fwithout executing dexplicitly by duplicating activities eand f. we have
translated this petri net to a process tree without duplicating activities eand
f, which would have reduced simplicity and generalization. replay tness of the
resulting process tree is perfect. however, precision is rather low because of the
explicit choice to skip d. in this translation simplicity and generalization are rather
high.
7.8.why existing algorithms fail
the results of existing process discovery algorithms, as shown in fig. 8 to 14, clearly
indicate that, even on our small example, only the -algorithm was able to balance
the four quality dimensions well. several algorithms even produce an unsound re-
sult. moreover, the -algorithm was \lucky" for this small example. in general,
this algorithm produces models that are not tting or not precise. therefore, in
section 8, we rst investigate combining various dimensions and show that all of
them have to be considered in order to discover a sound, easy to understand process
model, accurately describing the log under consideration . in subsection 8.4 we show
that assigning dierent weights to the dimensions results in dierent process mod-
els. then, in section 9, we show that only our etm algorithm is able to balance
all quality dimensions for real life event logs.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
23
8. ignoring quality dimensions
the examples shown in gures 8 to 14 show that various existing process mining
techniques perform dierently on all four quality dimensions and they often provide
unsound models. in this section, we use the etm algorithm to discover a process
model on the given log, while varying which of the quality dimensions should be
considered. we show some optimal models that resulted from dierent runs of the
algorithm and discuss their properties. for each result we show the process tree,
the scores for each of the four quality dimensions and the translation of the process
tree to bpmn.
8.1.considering only one quality dimension
fig. 15a shows an example process tree, and the corresponding bpmn model, that
was discovered when focusing solely on the replay tness dimension. although the
process model is able to replay the event log perfectly, the model allows for more
behavior than is seen in the event log. since adding parts to the process tree might
improve replay tness, and removing parts never does, the process tree will keep
growing until perfect replay tness is reached. this is bad for simplicity since activ-
ities will be duplicated (activities banddin fig. 15a) and certain parts of the tree
will never be used (the rightmost band the leftmost dare never used when replaying
the event log). and although the bpmn process model looks very structured, it is
harder to understand than the process model used to describe the running example.
in order to obtain trees that do not allow for behavior that is not observed in the
event log, we considered only the precision dimension in the genetic algorithm. an
example of such a tree is shown in fig. 15b, which has a perfect precision because it
can only generate the trace hc;b;ci. the translation to bpmn shows how simple
the model really is and that it indeed can only produce one trace. a process tree
will have perfect precision if each trace it can generate is used in an alignment.
since the tree of fig. 15b can only generate one trace, each alignment between the
event log and the tree uses this path of execution. however, the low replay tness
score indicates that the process model in fig. 15b has little to do with the behavior
that is recorded in the event log.
when only considering simplicity , we get trees such as the one in fig. 15c,
where each activity is included exactly once. the corresponding bpmn model nicely
demonstrates this. however, the process model does not really describe the observed
process executions in the event log well, which is indicated by the low scores on
replay tness and precision.
fig. 15d shows the process tree and bpmn model that has the best general-
ization score when solely focusing on generalization. as mentioned before, general-
ization cannot reach 1, as this would require all possible behavior to be observed
innitely often. since generalization takes the number of node visits into account,
the score is improved if nodes are visited more often, where the visits are again
measured on the closest matching execution of the model for each trace. by placingtuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
24
^^_
d^
b_
e
dc^^
ab
fgf: 1.000 p: 0.341
s: 0.737 g: 0.681
(a) only replay tness
!
c!
bcf: 0.449 p: 1.000
s: 0.400 g: 0.797
(b) only precision

g^

ead
bcff: 0.504 p: 0.587
s: 1.000 g: 0.661
(c) only simplicity

b
f_
d_
agcf: 0.961 p: 0.394
s: 0.923 g: 0.916
(d) only generalization
fig. 15: process trees discovered when considering each of the quality dimensions
separatelytuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
25
	operators high in the tree, and activities fandbin the `redo' part, the loops and
the nodes in the `do' part are executed more often, hence improving generalization.
8.2.always considering replay fitness
the discussion in the previous section showed that none of the quality dimensions
should be considered in isolation. furthermore, we validated the choice of many
existing process discovery techniques to put emphasis on replay tness, i.e. if the
replay tness is not good enough, the other quality dimensions add little value as
the discovered model does not describe the recorded behavior. on the other hand,
achieving a perfect replay tness is not always necessary or desired.
when focusing on replay tness and precision , the goal is to nd a process
model that describes all traces, and not much more, much like the region-based
algorithms the results of which are depicted in fig. 9, 10 and 14. in general, a
model that contains an initial exclusive choice between all unique traces in the log
has perfect precision and replay tness. each choice is taken at least once and each
trace in the event log is a sequence in the process model. this always results in a
perfect replay tness. for our running example the process tree and bpmn model
as shown in fig. 16a also have both a perfect replay tness and precision. each part
of the process tree is used to replay a trace in the event log and no behavior that
is not present in the event log can be produced by the process tree. however, since
both process models are fairly big, the simplicity score is low and more importantly,
the generalization is not very high either. this implies that, although this model is
very precise, it is not likely that it explains any future, unseen behavior.
next we consider replay tness and simplicity , the result of which is shown in
fig. 16b. when considering only replay tness, we obtained fairly large models,
while simplicity should keep the models compact. the process models discovered
when considering both replay tness and simplicity contain each activity exactly
once and hence has perfect simplicity. at the same time all traces in the event log
can be replayed. however, the process tree contains two ^, one	and three_nodes
that allow for (far) more behavior than is seen in the event log. this is reected in
the low precision score in combination with the high generalization.
the process tree and bpmn model that are found when focusing on the com-
bination of replay tness and generalization is shown in fig. 16c. the process tree
shows many similarities with the process tree found when solely considering gen-
eralization. activity ehas been added to the `do' part of the 	to improve the
replay tness. however, it also reduces the generalization dimension since it is only
executed 20 times. furthermore, the tree is still not very precise.
in contrast to the trees in section 8.1, the various process trees discussed in
this section mainly capture the behavior observed in the event log. however, they
either are overtting (i.e. they are too specic) or they are undertting (i.e. they
are too generic). hence, considering replay tness in conjunction with only one
other dimension still does not yield satisfying results. therefore, in section 8.3, wetuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
26
!!
g
!
f!
cb
!
ef!
bc
!!
fb^
dc!
ef^!
cbdaf: 1.000 p: 1.000
s: 0.560 g: 0.657
(a) replay fitness and precision
^
b^
a
e_
f_
c_
dgf: 1.000 p: 0.387
s: 1.000 g: 0.892
(b) replay fitness and simplicity

_
bf_
e_
d__
agc f: 1.000 p: 0.214
s: 1.000 g: 0.906
(c) replay fitness and generalization
fig. 16: process trees discovered when considering replay tness and one of the
other quality dimensionstuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
27
consider three out of four dimensions, while never ignoring replay tness.
8.3.ignoring one dimension
we just showed that replay tness, in conjunction with one of the other quality
dimensions, is insucient to judge the quality of a process model. however, most
process discovery algorithms steer on just two quality dimensions. hence we consider
three of the four quality dimensions.
fig. 17 shows the three process trees that are discovered when ignoring one of the
quality dimensions, but always including replay tness. fig. 17a shows the process
tree and bpmn model found when ignoring precision. the resulting process tree is
similar to the one in fig. 16c, which was based on replay tness and generalization
only. the only dierence is that the parent of aand ghas changed from _to.
since the_was actually only used as an , this only inuences precision. hence the
other measures have the same values. the bpmn models of fig. 16c and fig. 17a
are also very similar where the latter one only has an additional block.
the process tree which is discovered when ignoring generalization is the same
a when simplicity is ignored and is shown in fig. 17b. this is due to the fact that
both simplicity and generalization are optimal in this tree. in other words, when
weighing all four dimensions equally, this tree is the best possible process tree to

_
bf_
e__
agdcf: 1.000 p: 0.234
s: 1.000 g: 0.906
(a) no precision
!!!
g
fe^
d^
bca
f: 0.992 p: 0.995
s: 1.000 g: 0.889
(b) no generalization or no simplicity
fig. 17: considering 3 of the 4 quality dimensionstuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
28
describe the process.
interestingly, this tree is the same as the result of the -algorithm (fig. 8).
however, as mentioned earlier, the -algorithm is not very robust. this will also be
demonstrated in section 9 using real life event logs.
8.4.weighing dimensions
the process trees shown in fig. 17 have trouble replaying all traces from the event
log while maintaining a high precision. however, since process discovery is mostly
used to gain insights into the behavior recorded in the log, it is generally required
that the produced model represents the log as accurately as possible, i.e. that both
replay tness and precision are high. by giving more weight to replay tness, while
still taking precision into account, our genetic algorithm can accommodate this
importance. fig. 18a shows the process tree and bpmn model resulting from our
algorithm when giving 10 times more weight to replay tness than the other three
quality dimensions. as a result the process tree is able to replay all traces from the
event log while still maintaining a high precision.
let us compare this process with the process tree of fig. 17b. this is also the
process tree or bpmn model produced when all quality dimensions are weighted
equally. it can be seen that the price to pay for improving tness was a reduction
in precision. this can be explained by looking at the change made to the process
model: activity dis now in an_relation with activities band c. replay tness
is hereby improved since the option to skip activity dis introduced. however, the
process tree now also allows for skipping the execution of both bandc. something
which is never observed in the event log.
furthermore, the process tree of fig. 18a performs better than the model we
!!
g!
fe_
d^
cbaf: 1.000 p: 0.923
s: 1.000 g: 0.889
(a) process tree discovered when replay tness is 10 times more important than all other dimen-
sions
!!
g!
fe^
^
bc
da
(b) process tree of the model used for simulation (translated manually from fig. 7)
fig. 18: weighing dimensions and original process model.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
29
originally used for simulating the event log as can be seen in fig. 18b. the original
tree performs equal on replay tness but worse on the other three quality dimen-
sions. precision is worse because the state space of the original model is bigger while
some paths are not used. simplicity is also worse because an additional node is
used in the original tree, hence the tree is two nodes bigger than optimal. further-
more, since the node is only executed ten times, the generalization reduces as well
because the other nodes are executed more than 10 times, thus the average visits
per node decreases.
9. experiments using real life event logs
in the previous sections we discussed the results of various existing process discovery
techniques on our running example. we also demonstrated that all four quality
dimensions should be considered when discovering a process model. in this section
we apply a selection of process discovery techniques, and our etm algorithm, on
three event logs from real information systems. using these event logs, and the
running example, we show that our etm algorithm is more robust than existing
process discovery techniques.
in this section we consider the following event logs:
(1) the event log l0is the event log as presented in tab. 2. l0 contains 100 traces,
590 events and 7 activities.
(2)event log l1 contains 105 traces, 743 events in total, with 6 dierent activi-
ties.
(3)event log l2 contains 444 traces, 3 :269 events in total, with 6 dierent ac-
tivities.
(4)event log l3 contains 274 traces, 1 :582 events in total, with 6 dierent ac-
tivities.
event logs l1, l2 and l3 are extracted from information systems of municipalities
participating in the coselogbproject. since some of the existing process discovery
techniques require a unique start and end activity, all event logs have been ltered
to contain only those traces that start with the most common start activity and
end with the most common end activity. furthermore, activity names have been
renamed to the letters a. . .f.
from the process discovery algorithms discussed in section 7 we selected four
well-known algorithms: the -algorithm [6], the ilp-miner [46], the heuristics
miner [45] and the genetic algorithm by alves de medeiros [34]. because we do
not have enough space to show all process models we show some important charac-
teristics of the resulting petri nets in tab. 3.
the-algorithm and ilp miner produce sound petri nets for each of the four
input logs. in contrast, the genetic miner never produces a sound petri net for the
bsee http://www.win.tue.nl/coselogtuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
30
table 3: petri net properties of discovered models.
legend: s?: whether the model is sound ( x) or unsound ( 7);
#p: number of places; #t: number of transitions; #arcs: number of arcs
l0 l1 l2 l3
s?#p #t#arcs s?#p #t#arcs s?#p #t#arcs s?#p #t#arcs
-algorithmx 97 20x 36 4x 36 4x 66 10
ilp minerx 77 19x 46 9x 26 11x 46 9
heuristics 71212 30x1215 28x1216 32 71011 23
genetic 710 9 21 71320 42 71120 36 71011 25
table 4: quality of process tree translations of several discovery algorithms
(italic results indicate unsound models, the best model is indicated by a gray cell
background)
l0 l1 l2 l3
-algorithmf: 0.992 p: 0.995 f: 1.000 p: 0.510 f: 1.000 p: 0.468 f: 0.976 p: 0.532
s: 1.000 g: 0.889 s: 0.923 g: 0.842 s: 0.923 g: 0.885 s: 0.923 g: 0.866
overall: 0.969 overall: 0.819 overall: 0.819 overall: 0.824
ilp minerf: 1.000 p: 0.748 f: 1.000 p: 0.551 f: 1.000 p: 0.752 f: 1.000 p: 0.479
s: 0.933 g: 0.830 s: 0.857 g: 0.775 s: 0.923 g: 0.885 s: 0.857 g: 0.813
overall: 0.887 overall: 0.796 overall: 0.890 overall: 0.787
heuristicsf: 1.000 p: 0.986 f: 0.966 p: 0.859 f: 0.917 p: 0.974 f: 0.995 p: 1.000
s: 0.875 g: 0.852 s: 0.750 g: 0.746 s: 0.706 g: 0.716 s: 1.000 g: 0.939
overall: 0.928 overall 0.830 overall: 0.828 overall: 0.983
geneticf: 1.000 p: 0.922 f: 0.997 p: 0.808 f: 0.905 p: 0.808 f: 0.987 p: 0.875
s: 0.737 g: 0.790 s: 0.750 g: 0.707 s: 0.706 g: 0.717 s: 0.750 g: 0.591
overall: 0.862 overall: 0.815 overall: 0.784 overall: 0.801
etmf: 0.992 p: 0.995 f: 0.901 p: 0.989 f: 0.863 p: 0.982 f: 0.995 p: 1.000
s: 1.000 g: 0.889 s: 0.923 g: 0.894 s: 0.923 g: 0.947 s: 1.000 g: 0.939
overall: 0.969 overall: 0.927 overall: 0.929 overall: 0.983tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
31
event logs. the heuristics miner produces a sound solution for two out of the four
event logs.
for each of the discovered petri nets we created process tree representations,
describing the same behavior. if a petri net was unsound, we interpreted the sound
behavior as closely as possible. for each of these process trees the evaluation of each
of the four measures, and the overall average tness, is shown in tab. 4.
for event log l1 both the -algorithm and the ilp miner nd process mod-
els that can replay all behavior. but, as is also indicated by the low precision,
these allow for far more behavior than observed in the event log. this is caused by
transitions without input places that can occur an arbitrary number of times. the
heuristics miner is able to nd a reasonably tting process model, although it is
also not very precise since it contains several loops. the genetic algorithm nds a
model similar to that of the heuristics miner, although it is unsound and contains
even more loops. the etm algorithm nds a process tree, of which the bpmn
translation is shown in fig. 19a, that scores high on all dimensions. if we want to
improve replay tness even more we can make it 10 times more important as the
other quality dimensions. this results in the process model shown in fig. 19b. with
an overall (unweighted) tness of 0 :884 it is better than all process models found
by other algorithms while at the same time having a perfect replay tness.
event log l2 shows similar results: the -algorithm and the ilp miner are able
to nd process models that can replay all behavior but allow for far more behavior.
the heuristics miner and genetic miner again found models with several loops.
the etm algorithm was able to nd a process model, shown in fig. 20a, that
scores high on all dimensions but less so on replay tness. if we emphasize replay
tness 10 times more than the other dimensions, we get the process model shown
f: 0.901 p: 0.989
s: 0.923 g: 0.894
(a) all dimensions weight 1
f: 0.996 p: 0.775
s: 0.923 g: 0.843
(b) replay fitness weight 10, rest 1
fig. 19: process trees discovered for l1tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
32
in fig. 20b. although replay tness improved signicantly, the other dimensions,
especially precision and simplicity, are reduced.
for event log l3 the observations for the last two event logs still hold. both
the-algorithm and the ilp miner provide tting process models that allow for
far more behavior. both the heuristics miner and the genetic algorithm result in
unsound models. however, the sound interpretation of the heuristics model is the
same as the sound process model found by the etm algorithm, which is shown
in fig. 21a. replay tness is almost perfect. however, we let the etm algorithm
discover a process model with real perfect replay tness, which is shown in fig. 21b.
this requires making replay tness 1 :000 times more important than the others and
results in a process tree that has perfect replay tness but scores bad on precision.
however, as we have seen before, this is a common trade-o and the process tree
is still more precise than the one found by the ilp miner which also has a perfect
replay tness.
investigating the results shown in tab. 4 we see that on two occasions a pro-
cess model similar to the one found by the etm algorithm was found by another
algorithm. however, the -algorithm was not able to produce sensible models for
any of the three real life event logs. the heuristics miner once produced a process
model of which the sound behavior matched the process tree the etm algorithm
discovered. however, our algorithm always produced sound process models superior
f: 0.863 p: 0.982
s: 0.923 g: 0.947
(a) all dimensions weight 1
f: 0.964 p: 0.415
s: 0.571 g: 0.838
(b) replay tness weight 10, rest weight 1
fig. 20: process trees discovered for l2tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
33
to the others. furthermore, the etm algorithm can be steered to improve certain
dimensions of the process model as desired.
10. building a pareto front
by assigning weights to the dierent dimensions the etm algorithm is able to
produce a process model that balances the dimensions as desired. however, it is
hard to specify the weights required beforehand. consider for instance the process
model of fig. 21b where tness was weighed 1 ;000 times more than the other
dimensions in order to get perfect replay tness. in fig. 19b and fig. 20b however,
tness was weighed 10 times more important than the other dimensions to get a
similar result. it is sometimes hard to know beforehand how to set the weights to
get the desired results.
therefore, we prefer to avoid assigning weights to the dierent dimensions up-
front. by presenting the user with a collection of process models to choose from,
f: 0.995 p: 1.000
s: 1.000 g: 0.939
(a) all dimensions weight 1
f: 1.000 p: 0.502
s: 0.857 g: 0.900
(b) replay tness weight 1000, rest weight 1
fig. 21: process trees discovered for l3tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
34
replay fitnessp
r 
e
c
i 
s
i 
o
n(partly unknown)
pareto frontnon-optimal
process modelstruncated 
members
bcd
efgab c d f a g
fig. 22: example of a pareto front on two dimensions.
the user can pick the process model that has the desired trade-os. this can be
achieved by constructing a pareto front [42] of process models. fig. 22 shows an
example of a pareto front for the dimensions replay tness and precision. each dot
in the graph represents a process model with a certain replay tness and precision
value. the open dots in the lower middle area are non-optimal process models,
e.g. one of the dimensions can be improved without reducing the quality in any
of the other dimensions. the solid black dots represent the current estimation of
the pareto front. currently, for these models there is no model known where one
dimension has a better score without reducing one of the other dimensions. the
ideal or real pareto front, as indicated by the dotted curved line, shows that some
improvements can still be made.
however, the pareto front can grow very large because in general at least 4 di-
mensions are considered which each have innitely many possible values. therefore,
the pareto front can be truncated by removing process models that are similar, i.e.,
representative examples are selected from groups of similar models. the bigger dots
shown in fig. 22 are the most diverse process models in the current front. this is
determined by looking at the distance between the process models in all dimensions.
when the pareto front is truncated process models that are too similar to others
are removed, until the desired pareto front size is obtained.
the pareto front can be easily constructed by the etm algorithm by replacing
the group of elite process trees with the pareto front and updating it during the
generations. since the pareto front size is not xed, and in general will grow over
time, the etm algorithm is slightly adjusted to select a xed number of process
trees from the current pareto front as input for the new mutation cycle. after
applying the dierent mutations, the new trees are considered to be added to the
pareto front and the pareto front is updated.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
35
10.1. pareto front for the running example
if a pareto front is constructed for the running example, using the process models
discovered so far by the etm algorithm, it contains six of the eleven process models
shown in fig. 15 through fig. 18. it will not contain the process model discovered
when only replay tness is taken into account, which is shown in fig. 15a. this pro-
cess tree is dominated by the process tree discovered when considering both replay
tness and precision (fig. 16a) since they both have perfect replay tness but the
precision of the latter model is better. for the reason the process tree found when
considering replay tness and simplicity (fig. 16b) is included since it scores better
on simplicity. another process tree that is in the pareto front is the tree discovered
when ignoring precision (fig. 17a), and the one found when considering only preci-
sion (fig. 15b. the process tree that is discovered when ignoring either simplicity
or generalization, which is the same as the one discovered by the algorithm is also
included in the pareto front.
additionally, the process tree as shown in fig. 23 will be included in the pareto
front since it balances the four quality dimensions very well.
when considering the process models found by the existing process discovery
algorithms, some of them are also in the pareto front. the model discovered by the
-algorithm is on the pareto front: it is the same as the process tree found by the
etm algorithm. however, also the sound interpretation of the model discovered by
the heuristics miner (fig. 11) is included in the pareto front because of the balance
of the dierent quality dimensions.
a pareto front changes over time, i.e. during the execution of the etm algo-
rithm, process models may disappear from it as they are replaced by better ones.
therefore, the pareto front as discussed may be improved if the etm algorithm is
allowed to run longer.
f: 0.980 p: 0.613
s: 0.923 g: 0.898
fig. 23: process tree that was not discovered before but will be in the pareto front.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
36
10.2. using the pareto front to indicate non-local dependencies
another issue that is addressed by returning multiple process models is that of
modeling non-local dependencies using process trees. consider for instance a process
for obtaining a driving license for either a car or a motorbike. first driving classes
for either car or motorbike need to be followed. after this a theoretical exam needs
to be taken, which is the same for both. next the practical test needs to be done,
which is of course dierent for cars and motorbikes. two process models describing
this process are shown in fig. 24, with the activities renamed to atoj. in this
example process activity f(the practical exam for cars) should only be executed if
activity c(driving class for cars) was executed before. similarly, activity g(practical
exam for motorbike) should only be chosen if earlier activity d(driving class for
motorbike) was executed. however, in between always activity e(theoretical exam)
should be executed.
the pareto front constructed by the etm algorithm will include both process
models shown in fig. 24. in the process model of fig. 24a the dependencies between
the activities are not modeled and activity fcould be executed even if activity d
has been performed earlier. this is not possible in the process model of fig. 24b
where activity ehas been duplicated. the process model of fig. 24b has a perfect
precision. the process model of fig. 24a does not have a perfect precision since
this process model can produce traces not observed in the event log. however, this
process model scores better on the dimensions generalization and simplicity.
in general, the process model where the non-local dependency is expressed by
duplicating the activities in between scores better on precision. this process model
restricts certain activity combinations from occurring which are not observed in the
event log, hence increasing precision. this however always comes at the cost of both
generalization and simplicity. therefore the pareto front will always include both
process model variants. this allows the user to make the decision which of the two
process models to prefer.
f: 1.000 p: 0.937
s: 0.952 g: 0.407
(a)
f: 1.000 p: 1.000
s: 0.909 g: 0.361
(b)
fig. 24: two process trees where activities f and g depend on c and d respectively.tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
37
11. conclusion
the quality of process discovery algorithms is generally measured using four dimen-
sions, namely replay tness, precision, generalization and simplicity. many existing
process discovery algorithms focus on only two or three of these dimensions and gen-
erally, they do not allow for any parameters indicating to what extent they should
focus on any of them. furthermore, most process discovery algorithms assume that
the event log is complete in describing the behavior of the system. moreover, they
assume that the event log is noise-free and that the process model is a correct
description of the system.
in this paper we provide an overview of the relationship between the behavior
of the system, the observed behavior in the event log and the possible behavior
of the process model. the existing four quality dimensions are positioned within
this comparison and we present the etm algorithm to discover process trees on
a log which can be congured to optimize for a weighted average over the quality
dimensions, i.e. a model can be discovered that is optimal given the weights to
each parameter. finally, the etm algorithm is guaranteed to produce sound process
models .
we use our etm algorithm to show that all four quality dimensions are nec-
essary when doing process discovery and that none of them should be left out.
however, the replay tness dimension, indicating to what extent the model can
reproduce the traces in the log, is more important than the other dimensions.
using both an illustrative example and three real life event logs we demonstrate
the need to consider all four quality dimensions. moreover, our algorithm is able to
balance all four dimensions is a seamless manner.
to prevent the need to congure the weights assigned to each quality dimension,
a pareto front can be constructed by the etm algorithm. the pareto front contains
a number of process trees, each balancing the quality dimensions in a dierent way.
currently the main challenge is to nd a way to present the pareto front to the
user such that they can understand the dierences between the process models and
make an informed choice which process model to select.
references
1. w.m.p. van der aalst. on the representational bias in process mining. in en-
abling technologies: infrastructure for collaborative enterprises (wetice), 2011
20th ieee international workshops on , pages 2{7. ieee, 2011. pages
2. w.m.p. van der aalst. process mining: discovery, conformance and enhancement of
business processes . springer-verlag, berlin, 2011. pages
3. w.m.p. van der aalst. mediating between modeled and observed behavior: the
quest for the \right" process. in ieee international conference on research chal-
lenges in information science (rcis 2013) , pages 31{43. ieee computing society,
2013. pages
4. w.m.p. van der aalst, a. adriansyah, and b.f. van dongen. replaying history on
process models for conformance checking and performance analysis. wiley interdis-
ciplinary reviews: data mining and knowledge discovery , 2(2):182{192, 2012. pagestuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
38
5. w.m.p. van der aalst, k.m. van hee, a.h.m. ter hofstede, n. sidorova, h.m.w.
verbeek, m. voorhoeve, and m.t. wynn. soundness of workow nets: classication,
decidability, and analysis. formal aspects of computing , 23(3):333{363, 2011. pages
6. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workow mining: dis-
covering process models from event logs. ieee transactions on knowledge and data
engineering , 16(9):1128{1142, 2004. pages
7. a. adriansyah, b. van dongen, and w.m.p. van der aalst. conformance checking
using cost-based fitness analysis. in ieee international enterprise computing con-
ference (edoc 2011) , pages 55{64. ieee computer society, 2011. pages
8. r. agrawal, d. gunopulos, and f. leymann. mining process models from workow
logs. in sixth international conference on extending database technology , volume
1377 of lecture notes in computer science , pages 469{483. springer-verlag, berlin,
1998. pages
9. e. badouel and p. darondeau. theory of regions. in w. reisig and g. rozenberg,
editors, lectures on petri nets i: basic models , volume 1491 of lecture notes in
computer science , pages 529{586. springer-verlag, berlin, 1998. pages
10. j.c.m. baeten and w.p. weijland. process algebra , volume 18 of cambridge tracts in
theoretical computer science . cambridge university press, cambridge, 1990. pages
11. f.d. banzhaf, w.and francone, r.e. keller, and p. nordin. genetic programming: an
introduction: on the automatic evolution of computer programs and its applications .
morgan kaufmann publishers inc., san francisco, ca, usa, 1998. pages
12. r. bergenthum, j. desel, r. lorenz, and s. mauser. process mining based on regions
of languages. in g. alonso, p. dadam, and m. rosemann, editors, international
conference on business process management (bpm 2007) , volume 4714 of lecture
notes in computer science , pages 375{383. springer-verlag, berlin, 2007. pages
13. c. boender and a. rinnooy kan. a bayesian analysis of the number of cells of a
multinomial distribution. the statistician , 32(1-2):240{248, 1983. pages
14. j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst. on the role of fitness,
precision, generalization and simplicity in process discovery. in otm federated con-
ferences, 20th international conference on cooperative information systems (coopis
2012) , volume 7565, pages 305{322, 2012. pages
15. j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst. a genetic algorithm for
discovering process trees. in evolutionary computation (cec), 2012 ieee congress
on, pages 1 {8, june 2012. pages
16. j.a. bunge and m. fitzpatrick. estimating the number of species: a review. journal
of the american statistical association , 88(421):pp. 364{373, 1993. pages
17. k.p. burnham and w.s. overton. robust estimation of population size when cap-
ture probabilities vary among animals. ecology , 60(5):pp. 927{936, 1979. pages
18. m.p. cabasino, a. giua, and c. seatzu. identication of petri nets from knowledge
of their language. discrete event dynamic systems , 17(4):447{474, 2007. pages
19. t. calders, c. w. g unther, m. pechenizkiy, and a. rozinat. using minimum de-
scription length for process mining. in proceedings of the 2009 acm symposium on
applied computing , sac '09, pages 1451{1455, new york, ny, usa, 2009. acm.
pages
20. j.e. cook and a.l. wolf. discovering models of software processes from event-based
data. acm transactions on software engineering and methodology , 7(3):215{249,
1998. pages
21. j.e. cook and a.l. wolf. software process validation: quantitatively measuring the
correspondence of a process to a model. acm transactions on software engineering
and methodology , 8(2):147{176, 1999. pagestuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
39
22. b.f. van dongen and w.m.p. van der aalst. multi-phase mining: aggregating in-
stances graphs into epcs and petri nets. in d. marinescu, editor, proceedings of the
second international workshop on applications of petri nets to coordination, work-
ow and business process management , pages 35{58. florida international university,
miami, florida, usa, 2005. pages
23. a. ehrenfeucht and g. rozenberg. partial (set) 2-structures - part 1 and part 2. acta
informatica , 27(4):315{368, 1989. pages
24. a.e. eiben and j.e. smith. introduction to evolutionary computing . springer verlag,
2003. pages
25. k. gerke, j. cardoso, and a. claus. measuring the compliance of processes with
reference models. in robert meersman, tharam dillon, and pilar herrero, editors,
on the move to meaningful internet systems: otm 2009 , volume 5870 of lecture
notes in computer science , pages 76{93. springer berlin heidelberg, 2009. pages
26. s. goedertier, d. martens, j. vanthienen, and b. baesens. robust process discovery
with articial negative events. journal of machine learning research , 10:1305{1340,
2009. pages
27. g. greco, a. guzzo, l. pontieri, and d. sacc a. discovering expressive process models
by clustering log traces. ieee transaction on knowledge and data engineering ,
18(8):1010{1027, 2006. pages
28. c.w. g unther and w.m.p. van der aalst. fuzzy mining: adaptive process simplica-
tion based on multi-perspective metrics. in g. alonso, p. dadam, and m. rosemann,
editors, international conference on business process management (bpm 2007) , vol-
ume 4714 of lecture notes in computer science , pages 328{343. springer-verlag,
berlin, 2007. pages
29. j. herbst and d. karagiannis. integrating machine learning and workow manage-
ment to support acquisition and adaptation of workow models. international jour-
nal of intelligent systems in accounting, finance and management , 9:67{92, 2000.
pages
30. a.r. hevner, s.t. march, j. park, and s. ram. design science in information systems
research. mis q. , 28(1):75{105, march 2004. pages
31. y. jin. a comprehensive survey of tness approximation in evolutionary computation.
soft computing journal , 9(1):3{12, 2005. pages
32. j.r. koza. genetic programming: on the programming of computers by means of
natural selection . mit press, 1992. pages
33. m. kunze, m. weidlich, and m. weske. behavioral similarity - a proper metric. in
business process management (bpm 2011) , pages 166{181, 2011. pages
34. a.k. alves de medeiros, a.j.m.m. weijters, and w.m.p. van der aalst. genetic pro-
cess mining: an experimental evaluation. data mining and knowledge discovery ,
14(2):245{304, 2007. pages
35. j. mendling, g. neumann, and w.m.p. van der aalst. understanding the occur-
rence of errors in process models based on metrics. in f. curbera, f. leymann, and
m. weske, editors, proceedings of the otm conference on cooperative information
systems (coopis 2007) , volume 4803 of lecture notes in computer science , pages
113{130. springer-verlag, berlin, 2007. pages
36. j. mendling, h.m.w. verbeek, b.f. van dongen, w.m.p. van der aalst, and g. neu-
mann. detection and prediction of errors in epcs of the sap reference model. data
and knowledge engineering , 64(1):312{329, 2008. pages
37. j. munoz-gama and j. carmona. enhancing precision in process conformance: sta-
bility, condence and severity. in n. chawla, i. king, and a. sperduti, editors, ieee
symposium on computational intelligence and data mining (cidm 2011) , paris,tuesday 25thjune, 2013 14:45 wspc/instruction file ijcis
40
france, april 2011. ieee. pages
38. omg. business process model and notation (bpmn). object management group,
dtc/2010-06-05, 2010. pages
39. h. rittel and m. webber. dilemmas in a general theory of planning. policy sciences ,
4(2):155{169, 1973. pages
40. a. rozinat and w.m.p. van der aalst. conformance checking of processes based on
monitoring real behavior. information systems , 33(1):64{95, 2008. pages
41. m. sole and j. carmona. process mining from a basis of regions. in j. lilius and
w. penczek, editors, applications and theory of petri nets 2010 , volume 6128 of
lecture notes in computer science , pages 226{245. springer-verlag, berlin, 2010.
pages
42. d.a. van veldhuizen and g.b. lamont. evolutionary computation and convergence
to a pareto front. in late breaking papers at the genetic programming 1998 con-
ference , pages 221{228, 1998. pages
43. j. vanhatalo, h. v olzer, and j. koehler. the rened process structure tree. data
and knowledge engineering , 68(9):793{818, 2009. pages
44. m. weidlich, a. polyvyanyy, n. desai, and j. mendling. process compliance measure-
ment based on behavioural proles. in advanced information systems engineering ,
pages 499{514. springer, 2010. pages
45. a.j.m.m. weijters, w.m.p. van der aalst, and a.k. alves de medeiros. process min-
ing with the heuristics miner-algorithm. beta working paper series, wp 166, eind-
hoven university of technology, eindhoven, 2006. pages
46. j.m.e.m. van der werf, b.f. van dongen, c.a.j. hurkens, and a. serebrenik. process
discovery using integer linear programming. fundamenta informaticae , 94:387{412,
2010. pages