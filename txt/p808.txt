business process simulation survival guide
wil m.p. van der aalst
abstract simulation provides a Ô¨Çexible approach to analyzing business processes.
through simulation experiments various ‚Äúwhat if‚Äù questions can be answered and
redesign alternatives can be compared with respect to key performance indicators.
this chapter introduces simulation as an analysis tool for business process manage-
ment. after describing the characteristics of business simulation models, the phases
of a simulation project, the generation of random variables, and the analysis of simu-
lation results, we discuss 15 risks, i.e., potential pitfalls jeopardizing the correctness
and value of business process simulation. for example, the behavior of resources is
often modeled in a rather na ¬®ƒ±ve manner resulting in unreliable simulation models.
whereas traditional simulation approaches rely on hand-made models, we advocate
the use of process mining techniques for creating more reliable simulation models
based on real event data. moreover, simulation can be turned into a powerful tool
for operational decision making by using real-time process data.
1 introduction
simulation was one of the Ô¨Årst applications of computers. the term ‚Äúmonte carlo
simulation‚Äù was Ô¨Årst coined in the manhattan project during world war ii, because
of the similarity of statistical simulation to games of chance played in the monte
carlo casino. this illustrates that that already in the 1940s people were using com-
puters to simulate processes (in this case to investigate the effects of nuclear explo-
wil m.p. van der aalst
department of mathematics and computer science, eindhoven university of technology, p.o.
box 513, nl-5600 mb, eindhoven, the netherlands, e-mail: w.m.p.v.d.aalst@tue.nl;
business process management discipline, queensland university of technology, gpo box 2434,
brisbane qld 4001, australia; and
international laboratory of process-aware information systems, national research university
higher school of economics, 33 kirpichnaya str., moscow, russia.
12 wil m.p. van der aalst
sions). later monte carlo methods were used in all kinds of other domains ranging
from Ô¨Ånance and telecommunications to logistics and workÔ¨Çow management. for
example, note that the inÔ¨Çuential and well-known programming language simula
[13], developed in the 1960s, was designed for simulation. simulation has become
one of the standard analysis techniques used in the context of operations research
and operations management. simulation is particularly attractive since it is versatile,
imposes few constraints, and produces results that are relatively easy to interpret.
analytical techniques have other advantages but typically impose additional con-
straints and are not as easy to use [12]. therefore, it is no surprise that in the context
ofbusiness process management (bpm), simulation is one of the most established
analysis techniques supported by a vast array of tools [3].
consider for example a large car rental agency (like hertz or avis) having thou-
sands of ofÔ¨Åces in different countries sharing a centralized information system
where customers can book cars online. one can make simulation models of indi-
vidual ofÔ¨Åces and the centralized information system to answer question such as:
what are the average waiting times of customers when booking a car online?
what is the variability of waiting times when picking up a car at a particular
location?
what is the utilization of staff at a particular location?
will waiting times be reduced substantially if extra staff is deployed?
how many customers are lost due to excessive waiting times?
what is the effect of allocating staff based on the number of bookings?
what is the effect of changing the opening hours at a particular location?
to answer these and many other questions, a simulation model can be used. a proper
simulation model is a simpliÔ¨Åed representation of reality and thus can be used to
simulate that reality using a computer. obvious reasons for using a simulation model
are [7, 6]:
gaining insight in an existing or proposed future situation. by charting a business
process, it becomes apparent what is important and what is not.
a real experiment may be too expensive . simulation is a cost-effective way to
analyze several alternatives. decisions such as hiring extra staff or adding new
servers many too expensive to simply try out in reality. one would like to know
in advance whether a certain measure will have the desired effect.
a real experiment may be too dangerous and may not be repeatable . some ex-
periments cannot be carried out in reality due to legal, ethical, or safety reasons.
moreover, it is often impossible to reliably compare alternatives due to changing
conditions (performance may change due to external factors).
there is an abundance of mathematical models that can be used to analyze abstrac-
tions of business processes. such models are often referred to as analytical models.
these models can be analyzed without simulation. examples are queueing models
[21], queueing networks [9], markov chains, and stochastic petri nets [23, 15]. if a
simple analytical model can do the job, one should not use simulation. in compari-
son to a simulation model, an analytical model is typically less detailed and requires
fewer parameter settings. widely acknowledged advantages of simulation are:business process simulation survival guide 3
simulation is Ô¨Çexible . any situation, no matter how complex, can be investigated
through simulation.
simulation can be used to answer a wide range of questions . it is possible to
assess waiting times, utilization rates and fault percentages using one and the
same model.
simulation stimulates creativity . simulation triggers ‚Äúprocess thinking‚Äù without
restricting the solution space upfront.
simulation is easy to understand . in essence, it is nothing but replaying a mod-
eled situation. in contrast to many analytical models, little specialist knowledge
is necessary to understand the analysis technique used. hence, simulation can be
used to communicate ideas effectively.
unfortunately, simulation also has some disadvantages .
a simulation study can be time consuming . sometimes, very long simulation runs
are necessary to obtain reliable results.
one has to be very careful when interpreting simulation results. determining the
reliability of results can be very treacherous indeed.
simulation does not provide any proof . things that can happen in reality may not
be witnessed during some simulation experiment.
today‚Äôs simulation tools can be used to rapidly construct simulation models using
drag-and-drop functionality. however, faulty simulation models or incorrectly in-
terpreted results may lead to bad decisions. therefore, this chapter will focus on
the validation of simulation models and the correct derivation and interpretation of
simulation results. we will highlight potential pitfalls of traditional simulation ap-
proaches. therefore, this chapter can be viewed as a ‚Äúsurvival guide‚Äù for people
new to the topic. moreover, we also aim to broaden the view for people familiar
with traditional business process simulation approaches. the availability of detailed
event data and possible connections between simulation tools and information sys-
tems enables new forms of simulation. for example, short-term simulation provides
users and managers with a ‚Äúfast forward button‚Äù to explore what will happen in the
near future under different scenarios.
the remainder of this chapter is organized as follows. section 2 introduces tra-
ditional business process simulation by describing the simulation-speciÔ¨Åc elements
of process models and by discussing the different phases in a typical simulation
project. section 3 discusses the role of pseudo-random numbers in simulation. sec-
tion 4 explains how to set up a simulation experiment and how to compute conÔ¨Å-
dence intervals. pitfalls that need to be avoided are discussed in section 5. section 6
discusses more advanced forms of simulation that exploit the availability of event
data and modern it infrastructures. section 7 concludes the chapter with sugges-
tions for further reading.4 wil m.p. van der aalst
2 traditional approach to business process simulation
the correctness, effectiveness, and efÔ¨Åciency of an organization‚Äôs business pro-
cesses are vital for survival in today‚Äôs competitive world. a poorly designed busi-
ness process may lead to long response times, low service levels, unbalanced re-
source utilization, angry customers, back-log, damage claims, and loss of goodwill.
this is why it is important to analyze processes before they are put into production
(to Ô¨Ånd design Ô¨Çaws), but also while they are running (for diagnosis and decision
support). in this section, we focus on the role of simulation when analyzing business
processes at design time.
2.1 simulation models
for the construction of a simulation model and to conduct experiments, we need a
simulation tool. originally, there were two typical kinds of simulation tools:
asimulation language is a programming language with special provisions for
simulation. classical examples of simulation languages are simula, gpss, sim-
script, simpas, must and gasp.
asimulation package is a tool with building blocks for a certain application area,
which allow the rapid creation of a simulation model, mostly graphically. classi-
cal examples of simulation packages for production processes are: sim-factory,
witness and taylor. examples of simulation packages speciÔ¨Åcally designed for
workÔ¨Çow analysis are protos, cosa, woped, and yasper. in fact, most of to-
day‚Äôs bpm systems provide such a simulation facility.
the advantage of a simulation language is that almost every situation can be mod-
eled. the disadvantage is that one is forced to chart the situation in terms of a pro-
gramming language. modeling thus becomes time-consuming and the simulation
program itself provides no insights. a simulation package allows to rapidly build an
intuitive model. because the model must be built from ready-made building blocks,
the area of application is limited. as soon as one transgresses the limits of the spe-
ciÔ¨Åc area of application, e.g., by changing the control structure, modeling becomes
cumbersome or even impossible.
fortunately, many tools have been introduced with characteristics of both a sim-
ulation language and a simulation package. these tools combine a graphical design
environment and a programming language while also offering graphical analysis
capabilities and animation. examples of such tools are petri-net-based simulators
such as exspect and cpn tools [6]. these allow for hierarchical models that can be
constructed graphically while parts can be parameterized and reused. the arena
simulation tool developed by rockwell automation also combines elements of both
a simulation language (Ô¨Çexibility and expensiveness) and simulation package (easy
to use, graphical, and offering predeÔ¨Åned building blocks). arena emerged from
the block-oriented simulation language siman. the use of proprietary buildingbusiness process simulation survival guide 5
blocks in tools such as arena makes it hard to interchange simulation models be-
tween packages. simulation tools based on more widely used languages such petri
nets or bpmn are more open and can exchange process models with bpm systems
and other analysis tools (e.g., process mining software).
in the remainder of this chapter we remain tool-independent and focus on the
essential characteristics of simulation.
register 
requestadd extra 
insurance
check driver‚Äôs 
licenceinitiate 
check-in
startselect
car
charge credit 
cardprovide car
end
(c)   bpmn (business process modeling notation) model
startregister 
requestxoradd extra 
insurance
xorinitiate 
check-inandcheck 
driver‚Äôs 
licenceselect
car
charge 
credit cardand provide car no needneeded addedready to 
be 
selected
ready to 
be 
checked
ready to 
be 
chargedready for 
check-indone
(d)   epc (event-driven process chain) modelbadd extra 
insurance
initiate 
check-ine
check driver‚Äôs 
license
f
charge credit 
cardd
select car
provide 
carina c g
out register 
request
(a)   petri net abcdefg
acedfg
acfedg
abcdfeg
abcfdeg
acdef
...
(b)   event log 
fig. 1 three types of models describing the same control-Ô¨Çow: (a) petri net, (c) bpmn, and (d)
epc. the event log (b) shows possible traces of this model using the short activity names provided
by the petri net.
to explain the typical ingredients of a model used for business process simula-
tion, we Ô¨Årst focus on the control-Ô¨Çow of a business process. figure 1 shows the
same control-Ô¨Çow using three widely used notations. figure 1(a) shows a petri net ;
awf-net (workflow net) to be precise [6, 17, 35]. activities are modeled by labeled
transitions and the ordering of these activities is controlled by places (represented by
circles). a transition (represented by a square) is enabled if each of its input places
contains a token. an enabled transition may occur thereby consuming a token from
each input place and producing a token for each output place. initially, source place
incontains a token. hence, transition ais enabled in the initial state. after regis-
tering a request (modeled by transition a), extra insurance can be added ( b) or not
(modeled by the silent transition). then the check-in is initiated ( c). subsequently,
the selection of the car ( d), the checking of the license ( e), and the charging of6 wil m.p. van der aalst
the credit card ( f) are executed (any ordering is allowed, including the concurrent
execution of d,e, and f). finally, the car is provided ( g). the process instance ter-
minates when place outis marked. figure 1(b) shows an event log describing some
example traces.
bpmn, epcs, uml ads, and many other business process modeling notations
have in common that they all use token-based semantics. therefore, there are many
techniques and tools to convert petri nets to bpmn, bpel, epcs and uml ads,
and vice versa. as a result, the core concepts of petri nets are often used indirectly,
e.g., to enable analysis, to enact models, and to clarify semantics. for example,
figure 1(c) shows the same control-Ô¨Çow modeled using the business process mod-
eling notation (bpmn). bpmn uses activities, events, and gateways to model the
control-Ô¨Çow. in figure 1(c) two types of gateways are used: exclusive gateways
are used to model xor-splits and joins and parallel gateways are used to model
and-splits and joins. bpmn also supports other types of gateways corresponding
to inclusive or-splits and joins, deferred choices, etc. [14, 17, 35]. event-driven
process chains (epcs) use functions, events, and connectors to model the control-
Ô¨Çow (cf. figure 1(d)). connectors in epcs are similar to gateways in bpmn. there
are or, xor, and and connectors. events in epcs are similar to places in petri
nets. just like places and transitions in a petri net, events and functions need to al-
ternate along any path in an epc. however, events cannot have multiple successor
nodes, thus making it impossible to model deferred choices [17]. uml activity dia-
grams (uml ads) ‚Äì not shown in figure 1 ‚Äì are similar to bpmn and epcs when
it comes to the basic control-Ô¨Çow constructs.
badd extra 
insurance
initiate 
check-ine
check driver‚Äôs 
license
f
charge credit 
cardd
select car
provide 
carina c g
out register 
requestrole a role bsimulation environmentarrival processsubrun 
settingsselected kpis
number of 
resources per 
role
resource 
requirements 
and usageresolution of 
control-flow 
choices (priorities 
and probabilities)
activity durationresolution of resource 
choices (selection and 
queueing discipline)
20%
80%
fig. 2 information required for business process simulation. this information is not needed for
enactment (using for example a bpm/wfm system), but needs to be added for simulation.business process simulation survival guide 7
the control-Ô¨Çow oriented models shown in figure 1 provide necessary but not
sufÔ¨Åcient information for business process simulation. figure 2 sketches the mini-
mal additional information that needs to be provided to conduct meaningful simu-
lation experiments. first of all, a simulation environment needs to be provided that
generates new cases according to some predeÔ¨Åned arrival process and that collects
statistics based on on the key performance indicators (kpis) of interest. often a so-
called poisson arrival process is used (the time in-between two arrivals is sampled
from a negative-exponential distribution). typical kpis are average Ô¨Çow time, ser-
vice level, mean utilization, etc. choices modeled in the process need to be resolved
when executing a simulation model. therefore, priorities andprobabilities can be
used. for example, in figure 2 one could specify that on average 80% of cases skip
the extra insurance (i.e., bis executed in 20% of cases). one also needs to model
theduration of activities . in most business processes, the average Ô¨Çow time of a
case is much longer than the average service time (i.e., the time actually worked on
the case). this is due to queueing for unavailable or busy resources. often activities
require a particular type of resource, commonly referred to as a role. several re-
sources may have the same role and several activities may require a particular role.
the simulation model needs to specify resource requirements and usage . also the
number of resources per role, the selection of resources and the ordering of pend-
ing activities need to be speciÔ¨Åed. for example, a round-robin mechanism can be
used to select available resources and a first-come first-served (fcfs) queueing
discipline can be used to order pending activities. other queueing disciplines are
last-come first-served (lcfs), random order (ro), rush orders first (rof),
and shortest processing time first (sptf).
to conduct experiments, one also needs to determine the number of subruns ,
subrun length , and warm-up period . as explained in section 4, these subrun settings
are needed to be able to compute conÔ¨Ådence intervals .
interestingly, one does not need to supply the additional information shown in
figure 2 when conÔ¨Åguring a business process management (bpm) or workÔ¨Çow
management (wfm) system [3, 14, 17, 35]. for example, activity durations and
routing probabilities emerge over time based on the real characteristics of cases and
resources.
2.2 life-cycle of bpm and simulation projects
to explain the role of simulation as an analysis tool, we start by discussing the bpm
life-cycle [3, 6] shown in figure 3. in the (re)design phase , a process model is de-
signed. this model is transformed into a running system in the implementation/conÔ¨Å-
guration phase . if the model is already in executable form and a wfm or bpm
system is already running, this phase may be very short. however, if the model is
informal and needs to be hard-coded using some conventional programming lan-
guage, this phase may take substantial time. after the system supports the designed
processes, the run&adjust phase starts. in this phase, the processes are enacted and8 wil m.p. van der aalst
adjusted when needed. in the run & adjust phase, the process is not redesigned and
no new software is created; only predeÔ¨Åned controls are used to adapt or reconÔ¨Ågure
the process. figure 3 shows two types of analysis: model-based analysis anddata-
based analysis . while the system is running, event data are collected. these data
can be used to analyze running processes, e.g., discover bottlenecks, waste, and de-
viations. this is input for the redesign phase. during this phase process models can
be used for analysis. for example, simulation is used for ‚Äúwhat if‚Äù analysis or the
correctness of a new design is veriÔ¨Åed using model checking.
(re)design
implement/configurerun & adjustmodel-based 
analysisdata-based analysis
fig. 3 bpm life-cycle consisting of three phases: (re)design, implement/conÔ¨Ågure, and run &
adjust. traditional simulation approaches can be seen as a form of model-based analysis mostly
used during the (re)design phase.
traditionally, simulation is positioned on the left-hand side of figure 3, i.e., busi-
ness process simulation is a form of model-based analysis conducted during the
(re)design phase. figure 4 shows the phases of a typical simulation project. these
phases should be seen as a further reÔ¨Ånement of the (re)design phase in figure 3.
the simulation process starts with a problem deÔ¨Ånition , describing the goals and
Ô¨Åxing the scope of the simulation study. the scope tells what will and what will
not be a part of the simulation model. the problem deÔ¨Ånition should also state the
questions to be answered. preferably, these questions should be quantiÔ¨Åable. instead
of asking ‚Äúare the customers satisÔ¨Åed?‚Äù, one should ask ‚Äúhow long do customers
have to wait on average?‚Äù
after deÔ¨Åning the problem, the next phase is modeling . in this phase the con-
ceptual model is created. the conceptual model deÔ¨Ånes classes of objects and the
relations between these objects. in the case of a car rental organization example
objects to be distinguished are cars, customers, staff members, parking spaces, etc.
the relevant characteristics (properties) of these objects need to be determined. the
construction of the conceptual model will most likely unveil incomplete and con-
tradictory aspects in the problem deÔ¨Ånition. also, the modeling process may bring
forth new questions for the simulation study to answer. in either case, the problem
deÔ¨Ånition should be adjusted.business process simulation survival guide 9
conceptual 
modelproblem 
definition
modeling
executable 
modelrealizing
validated 
modelverifying and 
validating
simulation 
resultsexpertimenting
answers 
solutionsinterpreting
fig. 4 phases of a traditional simulation study.
after the conceptual modeling phase, the realization phase starts. here, the con-
ceptual model is mapped onto an executable model . the executable model can be
directly simulated on the computer. how to create this model depends strongly on
the simulation tool used. simulation languages require a genuine design and imple-
mentation phase. simulation packages that Ô¨Åt the problem domain merely require a
correct parameterization. the objects of the conceptual model are mapped to build-
ing blocks from the package and their quantitative characteristics (e.g. speed) are
translated to parameter values of these building blocks.
an executable model is not necessarily correct, so it has to be veriÔ¨Åed . veriÔ¨Åca-
tion of the model is necessary to examine whether the model contains qualitative or
quantitative errors, like programming errors or wrong parameter settings. for veriÔ¨Å-
cation purposes, small trial runs can be simulated step-by-step, or a stress test can be
applied to the model. in the stress test the model is subjected to extreme situations,
like having more customers arrive than can be attended to. in such a case, waiting
times measured should increase dramatically in the course of time. some tools sup-
port more advanced forms of veriÔ¨Åcation [3, 6]. apart from veriÔ¨Åcation, validation
of the model is also required. during validation we compare the simulation model
with reality. when simulating an existing situation, the results of a simulation run
can be compared to observations from historical data. veriÔ¨Åcation and validation
may lead to adjustments of the simulation model. new insights may even lead to10 wil m.p. van der aalst
adjusting the problem deÔ¨Ånition and/or the conceptual model. a simulation model
found to be correct after validation is called a validated model .
starting from the validated model, experiments can be carried out. these ex-
periments have to be conducted in such a way that reliable results are obtained as
efÔ¨Åciently as possible. in this stage decisions will be made concerning the number
of simulation runs and the length of each run (cf. section 4).
the simulation results need to be interpreted to allow feedback to the problem
deÔ¨Ånition. conÔ¨Ådence intervals will have to be calculated for the various kpis based
on low-level measurements gathered during simulation. also, the results will have
to be interpreted to answer the questions in the problem deÔ¨Ånition. for each such
answer, the corresponding reliability should be stated. all these matters are sum-
marized in a Ô¨Ånal report with answers to questions from the problem deÔ¨Ånition and
proposals for solutions.
figure 4 shows that feedback is possible between phases. in practice, many
phases do overlap. speciÔ¨Åcally, experimentation and interpretation will often go
hand in hand.
figure 4 may be misleading as it refers to a single simulation model. usually,
several alternative situations are compared to one another. in that case, several sim-
ulation models are created and experimented with and the results are compared.
often, several possible improvements of an existing situation have to be compared
through simulation. we call this ‚Äúwhat if‚Äù analysis. simulation is well-suited for
‚Äúwhat if‚Äù analysis as it is easy to vary parameters and compare alternatives based
on selected kpis.
3 sampling from distributions
figure 2 illustrates that random variables need to be added to resolve choices, to
sample durations from some probability distribution, and to generate the arrival of
new cases. this section shows how to introduce ‚Äúrandomness‚Äù selectively.
3.1 pseudo-random numbers
a simulation experiment is little more than replaying a modeled situation. to replay
this situation in computer, we have to make assumptions not only for the modeled
business process itself but also for its environment (cf. figure 2). as we cannot or
will not model these matters in detail we turn to ‚Äúmonte carlo‚Äù. we do not know
when and how many customers will enter a car rental ofÔ¨Åce, but we do know the
mean and variation of customer arrivals. so, we have the computer take seemingly
random samples from a probability distribution. the computer is by nature a deter-
ministic machine, so we need to smartly generate so-called pseudo-random num-
bers.business process simulation survival guide 11
arandom generator is a piece of software for producing pseudo-random num-
bers. the computer does in fact use a deterministic algorithm to generate them,
which is why they are called ‚Äúpseudo random‚Äù. most random generators generate
pseudo-random numbers between 0 and 1. each value between 0 and 1 being equally
probable, these values are said to be distributed uniformly over the interval between
0 and 1.
most random generators generate a series of pseudo-random numbersxi
maccord-
ing to the formula:
xn= (axn 1+b)modulo m
for each i,xiis a number from the set f0;1;2;:::; m 1gandxi
mmatches a sample
from a uniform distribution between 0 and 1. the numbers a,bandmare chosen in
such a way that the sequence can hardly or not at all be distinguished from ‚Äútruly
random‚Äù numbers. this means that the sequence ximust visit, on average, each of
the numbers 0 ;1;2;:::; m 1 equally often. also, mis chosen as closely as possi-
ble to the largest integer that can be manipulated directly by the computer. there
are several tests to check the quality of a random generator (cf. [11, 26, 34, 22]):
frequency test, correlation test, run test, gap test and poker test.
a reasonable random generator for a 32-bit computer is:
xn=16807 xn 1modulo (231 1)
that is: a=16807, b=0 and m=231 1. for a 64-bit machine:
xn= (6364136223846793005 xn 1+1)modulo 264
is a good choice.
the Ô¨Årst number in the sequence ( x0) is called the seed. the seed completely
determines the sequence of random numbers. in a good random generator, different
seeds produce different sequences. sometimes the computer selects the seed itself
(e.g., based on a system‚Äôs clock). however, preferably the user should consciously
select a seed himself, allowing the reproduction of the simulation experiment later.
reproducing a simulation experiment is important whenever an unexpected phe-
nomenon occurs that needs further examination.
today‚Äôs simulation tools provide adequate random generators. this generator
can be seen as a black box: a device that produces (pseudo) random numbers upon
request. however, beware: pseudo-random numbers are not truly random! (a deter-
ministic algorithm is used to generate them.) do not use more than one generator
and take care when selecting the seed.
to illustrate the dangers in using random generators we mention two well-known
pitfalls.
the Ô¨Årst mistake is using the so-called ‚Äòlower order bits‚Äô of a random sequence.
for example, if a random generator produces the number 0.1321734234, the higher
order digits 0.13217 are ‚Äòmore random‚Äô than the lower order digits 34234. in general
the lower order digits show a clear cyclical behavior.12 wil m.p. van der aalst
another frequent mistake is the double use of a random number. suppose that
the same random number is used twice for generating a sample from a probability
distribution. this introduces a dependency into the model that does not exist in
reality, which may lead to extremely deceptive results.
3.2 example probability distributions
only rarely do we need random numbers uniformly distributed between 0 and 1. de-
pending on the situation, we need samples from different probability distributions .
a probability distribution speciÔ¨Åes which values are possible and how probable each
of those values is.
to simplify the discussion of random distributions and samples from probability
distributions, we introduce the term random variable . a random variable xis a
variable with a certain probability of taking on certain values. for example, we can
model the throwing of a dice by means of a variable xthat can take on the values 1,
2, 3, 4, 5 and 6. the probability of obtaining any value afrom this set is1
6. we can
write this as follows:
i p[x=a] =1
6ifa2f1;2;3;4;5;6g
0 else
given a random variable xwe can deÔ¨Åne its expectation andvariance . the ex-
pectation of x, denoted by i e [x], is the average to be expected from a large number
of samples from x. we also say the mean ofx. the variance, denoted as var [x], is
a measure for the average deviation of the mean (expectation) of x. ifxhas a high
variance, many samples will be distant from the mean. conversely, a low variance
means that, in general, samples will be close to the mean. the expectation of a ran-
dom variable xis often denoted with the letter m, the variance (var [x]) is denoted
ass2. the relation between expectation and variance is deÔ¨Åned by the following
equality:
var[x] =i e[(x m)2] =i e[x2] m2
as var [x]is the expectation of the square of the deviation from the mean, the square
root of var [x]is a better measure for the deviation from the mean. we call s=p
var[x]thestandard deviation ofx.
table 1, lists some well-known discrete probability distributions. for example,
a random variable xhaving a bernoulli distribution with parameter phas two pos-
sible values: 0 (no success) and 1 (success). parameter pmodels the probability of
success. hence, i p [x=1] =p. i e[x] =pand var [x] =p(1 p).
table 2 lists some continuous distributions. unlike discrete distributions, the
probability of a speciÔ¨Åc value is zero, i.e., i p [x=k] =0 for any k. therefore, the
probability density function fx(k)is used to describe the likelihood of different
values. consider for example a random variable x uniformly distributed on the in-business process simulation survival guide 13
table 1 discrete random distributions.
distribution domain i p[x=k] i e[x]var[x]
bernoulli
0p1 k2f0;1g
1 p k=0
p k =1p p(1 p)
homogeneous
a<b k2fa;:::; bg1
(b a)+1a+b
2(b a)((b a)+2)
12
binomial
0p1 k2f0;1;:::; ng
n
k
pk(1 p)n kn p n p(1 p)
n2f1;2;:::g
geometric
0p1 k2f1;2;:::g(1 p)k 1p1
p1 p
p2
poisson
l>0 k2f0;1;:::glk
k!e ll l
table 2 continuous random distributions.
distribution domain fx(x) i e[x] var[x]
uniform
a<b axb1
b aa+b
2(b a)2
12
exponential
l>0 x0 le lx 1
l1
l2
normal
m2i r x2i r1p
2ps2e (x m)2
2s2 m s2
s>0
gamma
r;l>0 x>0l(lx)r 1e lx
g(r)r
lr
l2
erlang
l>0 x>0l(lx)r 1e lx
(r 1)!r
lr
l2
r2f1;2;:::g
c2see gamma
v2f1;2;:::gx>0 r=v
2andl=1
2v 2v
beta
a<b axb1
b ag(r+s)
g(r)g(s)a+(b a)r
r+sr s(b a)2
(r+s)2(r+s+1)
r;s>0 x a
b ar 1 b x
b as 1
terval [a;b].fx(k) =1
b a, i.e., all values on the interval have the same likelihood.
i e[x] =a+b
2and var [x] =(b a)2
12.
arrival processes are often modeled using the negative-exponential distribution .
parameter lis called the intensity of the arrival process, i.e., lis the expected
number of new arrivals per time unit. negative-exponentially distributed random
variable xmodels the time in-between two subsequent arrivals. i e [x] =1
lis the
expected average time between two such arrivals. if there is a large population of14 wil m.p. van der aalst
potential cases (e.g., customers) that behave independently, then, by deÔ¨Ånition, the
inter-arrival times are distributed negative exponentially. this is referred to as a
poisson arrival process .
durations are often modeled using the normal orbeta distribution. the well-
known normal distribution has two parameters: m(mean value) and s(standard
deviation). if we use a normally distributed random variable for modeling time du-
rations, like processing times, response times or transport times, we must be aware
that this random variable can also take on negative values. in general negative du-
rations are impossible; this may even cause a failure of the simulation software.
to circumvent this problem, we might take a new sample whenever the given sam-
ple produces a negative value. note that this will affect the mean and the variance.
therefore, this solution is recommended only if the probability of a negative value is
very small. we use the following rule of thumb: if m 2s<0, the normal distribu-
tion should not be used to model durations. the normal distribution with parameters
m=0 and s=1 is called the standard normal distribution .
like the uniform distribution, the beta distribution is distributed over a Ô¨Ånite
interval. we use it for random variables having a clear upper and lower bound.
the beta distribution has four parameters a,b,rands. the parameters aandb
represent the upper and lower bounds of the distribution. the parameters r(r>0)
ands(s>0) determine the shape of the distribution. very different shapes of the
probability density function are possible, see [7] for examples.
it is impossible to describe all frequently used probability distributions here.
probability distributions often used for simulation are described in detail in [7].
also consult standard textbooks on probability theory and simulation [8, 20, 22,
26, 27, 30]. these references also explain how particular random variables can be
constructed from pseudo-random numbers. for example, if xiis a pseudo random
number from the set f0;1;:::; m 1g, then ln(xi
m)=lis a sample from a negative-
exponential distribution with parameter l.
4 processing the results
in section 2.1 we described the typical ingredients of a simulation model. sim-
ulation models abstract from details that cannot be fully modeled (e.g., perfectly
modeling human decision making and customer behavior) or that are too specify
(e.g., data entered into a form). such abstractions may necessitate the introduction
of stochastic elements in the model. for example, a path is selected with a certain
probability and the duration of an activity is sampled from some continuous proba-
bility distribution. in section 3 we showed that pseudo random numbers can be used
to introduce such stochastic elements. this section focuses on the interpretation of
the raw simulation results. in particular, we will show that subruns are needed to
compute conÔ¨Ådence intervals for kpis.
during simulation there are repeated observations of quantities, such as wait-
ing times, Ô¨Çow times, processing times, or stock levels. these observations pro-business process simulation survival guide 15
vide information on kpis (cf. section 2.1). suppose we have kconsecutive obser-
vations x1;x2;:::; xkalso referred to as random sample . the mean of a number of
observations is the sample mean . we represent the sample mean of observations
x1;x2;:::; xkbyx. we can calculate the sample mean xby adding the observations
and dividing the sum by k:
x=√•k
i=1xi
k
the sample mean is merely an estimate of the true mean. however, it is a so-called
unbiased estimator (i.e., the difference between this estimator‚Äôs expected value and
the true value is zero). the variance of a number of observations is the sample
variance . this variance is a measure for the deviation from the mean. the smaller
the variance, the closer the observations will be to the mean. we can calculate the
sample variance s2by using the following formula:
s2=√•k
i=1(xi x)2
k 1:
this is the unbiased estimator of the population variance, meaning that its expected
value is equal to the true variance of the sampled random variable.
in a simulation experiment, we can determine the sample mean and the sample
variance of a certain quantity. we can use the sample mean as an estimate for the
real expected value of this quantity (e.g., waiting time), but we cannot determine
how reliable this estimate is . the sample variance is not a good indicator for the
reliability for the results. consider for example the sample xaand sample variance
s2
aobtained from a long simulation run. we want to use xaas a predictor for some
performance indicator (e.g., waiting time). if we make the simulation experiment
ten times as long, we will obtain new values for the sample mean and the sample
variance, say, xbands2
b, but these values do not need to be signiÔ¨Åcantly different
from the previous values. although it is reasonable to assume that xbis a more
reliable predictor than xa, the sample variance will not show this. actually, s2
bmay
be greater than s2
a. this is the reason to introduce subruns .
if we have n independent subruns , then we can estimate the reliability of es-
timated performance indicators. there are two approaches to create independent
subruns. the Ô¨Årst approach is to take one long simulation run and cut this run into
smaller subruns. this means that subrun i+1 starts in the state left by subrun i. as
the subruns need to be independent, the initial state of a subrun should not strongly
correlate with the Ô¨Ånal state passed on to the next subrun. an advantage is that start-
up effects only play a role in the Ô¨Årst run. hence, by inserting a single start run at
the beginning (also referred to as ‚Äúwarm-up period‚Äù), we can avoid incorrect conclu-
sions due to start-up effects. the second approach is to simply restart the simulation
experiment ntimes. as a result, the subruns are by deÔ¨Ånition independent. a draw-
back is that start-up effects can play a role in every individual subrun. hence, one
may need to remove the warm-up period in all subruns.
there are two types of behavior that are considered when conducting simula-
tion experiments: steady-state behavior and transient behavior. when analyzing the16 wil m.p. van der aalst
(a) transient analysis (no warm-up period, initial state matters, bounded timeframe)
(b) steady-state analysis (separate runs each with warm-up period)
(c) steady-state analysis (long run with one warm-up period split into smaller subruns)
fig. 5 for transient analysis, the initial state and the Ô¨Årst part of the simulation are relevant. for
steady-state analysis, the initial state and warm-up period are irrelevant and only the behavior af-
ter the warm-up period matters. each graph shows one simulation run. the x-axis denotes time
whereas the y-axis represents the state of the process. for steady-state analysis one can take sep-
arate simulation runs (each with a warm-up period) or one large simulation run cut into smaller
subruns.
steady-state behavior, we are interested in long-term effects. for example, we may
consider two process designs and analyze the differences with respect to average
Ô¨Çow times and costs in the next Ô¨Åve years. when analyzing the transient behavior,
we are interested in short-term effects. for example, if there are currently many
backorders, we may want to know how many additional resources we need to tem-
porarily deploy to handle these orders. when analyzing transient behavior, we are
not interested in long-time averages given some stable situation but in the short-
term effects. if we investigate steady-state behavior, the simulation runs need to be
long and we may want to discard the initial part of the simulation. when analyzing
transient behavior, the simulation runs are short and the initial part is most rele-
vant. figure 5 illustrates the difference between steady-state and transient analysis.
moreover, figure 5(c) shows that one simulation run can be partitioned into sub-
runs (provided that the state at the beginning of subrun i+1 does not depend on the
state at the beginning of subrun i). in the remainder of this section, we concentrate
on the steady-state behavior and assume that warm-up periods have been removed.
note that for each of the three situations sketched in figure 5, we obtain a set of
independent subruns (in this case four subruns) with corresponding measurements.business process simulation survival guide 17
suppose we have executed nsubruns and measured a result yifor each subrun i.
hence, each result yiserves as an estimate for a performance indicator. we assume
that there exists a ‚Äútrue‚Äù value mthat each result yiapproximates. we want to derive
assertions about mfrom the values yi. for example, yiis the mean waiting time
measured in subrun iandmthe ‚Äútrue‚Äù mean waiting time that we would Ô¨Ånd by
conducting a hypothetical simulation experiment of inÔ¨Ånite length. also kpis other
than the mean waiting time could be considered, e.g., yicould be an estimate for
the mean variance of the waiting time, the mean occupation rate of a server, or the
mean length of a queue. however, we must be certain that the values yiare mutually
independent for all subruns. this can be ensured by choosing a long enough subrun
length or by using independent subruns. given the results y1;y2;:::; yn, we derive
the sample mean:
y=√•n
i=1yi
n
and the sample variance:
s2
y=√•n
i=1(yi y)2
n 1:
the sample standard deviation is sy=q
s2y. the sample mean and the sample vari-
ance for the results of the subruns should not be confused with the mean and the
variance of a number of measures within one subrun. we can consider the sample y
as an estimate of the true value m. value ycan be seen as a sample from a random
variable y= (x1+x2+:::+xn)=n, the estimator . nowsypnis an indication of the
reliability of the estimate y. ifsypnis small, it is a good estimate.
if there is a large number of subruns, we can consider the estimator yas nor-
mally distributed. here we use the well-known central limit theorem . for a set
x1;x2;:::; xnof independent uniformly distributed random variables with expec-
tation mand variance s2, the random variable
(x1+x2+:::+xn) nm
spn
converges for n!¬•to a standard normal distribution. thus, the sum or average
of a large number of independent random variables is approximately normally dis-
tributed. if the subrun results are indeed independent and there are plenty of such
results, we can assume that the estimator yis normally distributed. therefore, we
treat the situation with over 30 subruns as a special case.
given a large number of independent subruns (say, n30), we can easily deter-
mine a conÔ¨Ådence interval for the quantity to be studied. because the sample mean
yis the average of a large number of independent measures, we can assume that yis
approximately normally distributed. from this fact, we deduce the probability that
the true value mlies within a conÔ¨Ådence interval. given the sample mean yand the
sample standard deviation sy, the true value mconforms with conÔ¨Ådence (1 a)to
the following equation:18 wil m.p. van der aalst
y sypnz(a
2)<m<y+sypnz(a
2)
where z(a
2)is deÔ¨Åned as follows: if zis a standard normally distributed random
variable, then the probability that random variable zis greater than z(x)isx. table 3
shows for Ô¨Åve values of xthe value z(x). the value arepresents the unreliability;
that is, the probability that mdoes not conform to the equation. typical values for a
range from 0 :001 to 0 :100. the interval

y sypnz(a
2);y+sypnz(a
2)
is known as the (1 a)-conÔ¨Ådence interval for the estimated value m.
table 3 i p[z>z(x)] = xwhere zis standard normally distributed.
x z(x)
0.001 3.090
0.005 2.576
0.010 2.326
0.050 1.645
0.100 1.282
given a smaller number of independent subruns (say, n30), we need to make
more assumptions about the distribution of the individual subrun results. a common
assumption is that the individual subrun results are normally distributed. this is a
realistic assumption when the subrun result itself is calculated by taking the average
over a large set of independent measurements (see the central limit theorem, which
states that as the sample size increases the distribution of the sample average of these
random variables approaches the normal distribution irrespective of the shape of the
common distribution of the individual terms). by using this assumption, we can
deduce‚Äîgiven nsubruns with a sample mean y, sample deviation sy, and reliability
(1 a)‚Äîthe following conÔ¨Ådence interval:

y sypntn 1(a
2);y+sypntn 1(a
2)
where tv(x)is the critical value of a student‚Äôs t-distribution with vdegrees of free-
dom. table 4 shows for several values of vandxthe critical value tv(x).
contrary to the method discussed earlier, we can now also determine the conÔ¨Å-
dence interval if only a limited number of subruns (say, ten) is at our disposal. for
small numbers v, we have tv(x)>z(x). as vincreases, the value of tv(x)decreases
and in the limit we obtain tv(x) =z(x).
when two conÔ¨Ådence intervals are overlapping for a kpi, one cannot make any
Ô¨Årm statements about the superiority of one the corresponding alternatives. more-business process simulation survival guide 19
table 4 the critical values for a student‚Äôs t-distribution with vdegrees of freedom.
tv(x) x=
0.100 0.050 0.010 0.001
v=13.08 6.31 31.82 318.31
21.89 2.92 6.96 22.33
31.64 2.35 4.54 10.21
41.53 2.13 3.75 7.17
51.48 2.02 3.37 5.89
61.44 1.94 3.14 5.21
71.41 1.89 3.00 4.79
81.40 1.86 2.90 4.50
91.38 1.83 2.82 4.30
10 1.37 1.81 2.76 4.14
15 1.34 1.75 2.60 3.73
20 1.33 1.72 2.53 3.55
25 1.32 1.71 2.49 3.45
50 1.30 1.68 2.40 3.26
100 1.29 1.66 2.35 3.17
¬•1.28 1.64 2.33 3.09
over, one alternative may score better with respect to costs whereas the other alter-
native may reduce Ô¨Çow times signiÔ¨Åcantly.
using the above, we can compute conÔ¨Ådence intervals for any kpi. if the conÔ¨Å-
dence intervals are too wide, more subruns or longer subruns can be used to obtain
tighter conÔ¨Ådence intervals. as mentioned before, simulation is an excellent tool for
‚Äúwhat if‚Äù analysis. conÔ¨Ådence intervals can be computed for different kpis and dif-
ferent alternatives. alternatives can be created by varying parameters or by making
changes in the design.
5 pitfalls to avoid
simulation is a powerful and Ô¨Çexible tool that can be used to support decision mak-
ing. if simulation is applied incorrectly (Ô¨Çawed model or poor analysis of the re-
sults), then this may result in incorrect decisions that are very costly. therefore, we
point out 15 typical pitfalls of simulation that should be avoided. in section 5.1 we
present ten general risks that may result in incorrect conclusions and misleading in-
sights. these are linked to the different phases of a simulation study (cf. figure 6).
section 5.2 identiÔ¨Åes Ô¨Åve more speciÔ¨Åc risks caused by simulation models that do
not incorporate essential phenomena such as working speeds depending on work-
loads, partial availability of resources, and competition among activities in different
processes.20 wil m.p. van der aalst
5.1 general risks
in section 2.2 we described the different phases of a traditional simulation study.
figure 6 lists ten risks pointing to typical errors (pitfalls) frequently made when
applying simulation. these are described in the remainder.
conceptual 
modelproblem 
definition
modeling
executable 
modelrealizing
validated 
modelverifying and 
validating
simulation 
resultsexpertimenting
answers 
solutionsinterpretingrisk 1: one-sided 
problem definition
risk 2:  wrong level 
of detail or scope
risk 3:  hidden 
assumptions
risk 4:  validation by 
the wrong peoplerisk 5:  forcing the 
model to fit
risk 6:  underexposure of 
the sensitivity of the modelrisk 7:  no subruns
risk 8:  careless 
presentation of the results
risk 9:  dangers of 
animation
risk 10:  unnecessary 
use of simulation
fig. 6 various risks associated to the different phases of a simulation study.
5.1.1 risk 1: one-sided problem deÔ¨Ånition
a simulation study gets off on the wrong foot if the problem deÔ¨Ånition is drawn
up exclusively by either the user or the systems analyst. the user may possess ex-
tensive knowledge of the problem area, but lacks the experience needed for deÔ¨Åning
his problem. the systems analyst on the other hand, fully knows the elements which
should be present in a problem deÔ¨Ånition, but lacks the background of the speciÔ¨Åc
problem. the systems analyst is also aware of the possibilities and impossibilities of
simulation. the user on the other hand, generally knowing little about simulation, is
barely informed on this issue. therefore, for a simulation study to be successful, it
is important that both parties closely cooperate in setting up the problem deÔ¨Ånition.
the problem deÔ¨Ånition serves as a ‚Äúcontract‚Äù between the user and the builder of
the model. hence, the following rule of thumb should be used: ‚Äúdo not start a sim-
ulation study until it is clear to both user(s) and analyst(s) which questions need to
be answered!‚Äù.business process simulation survival guide 21
5.1.2 risk 2: wrong level of detail or scope
in making a simulation model, one chooses a certain level of detail . in a simulation
model for a manufacturing department, a machine may be modeled as an object with
a mean service time as its only parameter. alternatively, it can be modeled in detail,
taking into account aspects such as set-up times, faults, tool-loading, maintenance
intervals etc. many simulation studies end prematurely because a wrong level of de-
tail is selected initially. too much detail causes the model to become unnecessarily
complex and introduces extra parameters that need to be assessed (with all the risks
involved). too many abstractions can lead to a simulation model that leaves the es-
sential questions of the problem deÔ¨Ånition unanswered. the right level of detail is
chosen if:
1. information is present that allows experiments with the model,
2. the important questions from the problem deÔ¨Ånition are addressed by the model,
and
3. the complexity of the model is still manageable for all parties concerned.
if it is impossible to choose a suitable level of detail satisfying these three condi-
tions, the problem deÔ¨Ånition needs to be adjusted.
related to the level of detail is the scope of the model. when analyzing a pro-
cess handled within a department, one can also model the other processes within the
same department competing for the same resources and the other departments inter-
acting with the process. one can think of the scope as the ‚Äúbreadth‚Äù of the model
whereas the level of detail is the model‚Äôs ‚Äúdepth‚Äù. broadening the scope or increas-
ing the level of detail may lead to more accurate models. however, more detail or a
broader scope may result in increased modeling and data gathering efforts. in fact,
sometimes there is no data to support a more reÔ¨Åned model. this is why probability
distributions are used.
the well-known ‚Äú80/20-rule‚Äù also applies to simulation models: 80% of the
model‚Äôs accuracy is obtained from 20% of the model‚Äôs detail. hence, a small in-
crease in accuracy may require the addition of lots of details. hence, the following
rule of thumb should be used: ‚Äúminimize the breadth and depth of a model given a
set of predeÔ¨Åned questions and required level of accuracy‚Äù.
5.1.3 risk 3: hidden assumptions
during modeling and while realizing an executable simulation model, many as-
sumptions must be made. assumptions are made to Ô¨Åll gaps in an incomplete prob-
lem deÔ¨Ånition or because of a conscious decision to keep the simulation model sim-
ple. often these assumptions are documented poorly, if documented at all. these
hidden assumptions may lead to the rejection of the simulation model during val-
idation or later. hidden assumptions may also lead to invalid conclusions and bad
decisions. therefore, allassumptions must be documented and regularly discussed
with the user.22 wil m.p. van der aalst
5.1.4 risk 4: validation by the wrong people
sometimes, due to time pressure or indifference of the user, the simulation model is
only validated by its maker(s). discrepancies between the model and the ideas of the
user may thus be discovered too late, if at all. therefore, the user should be involved
in the validation of the simulation model before any experiments are conducted.
5.1.5 risk 5: forcing the model to Ô¨Åt
in the validation phase, often the results of the simulation model do not match the
observed or recorded actual data. one is then tempted to make the model ‚ÄúÔ¨Åt‚Äù by
changing certain parameter values, i.e., the analyst Ô¨Åddles around with the parameter
settings until a match is found. this, however, is very dangerous, since this match
with reality is most likely caused by sheer luck and not by a model that adequately
reÔ¨Çects reality. parameters should be adjusted only after having understood why the
model deviates from reality. this prevents the conscious or unconscious obscuring
of errors in the model.
5.1.6 risk 6: underexposure of the sensitivity of the model
certain model parameters (e.g. the intensity of the arrival process) are often set at
one speciÔ¨Åc value. the chosen parameter settings should be justiÔ¨Åable. however,
even if this is the case, small variations in the arrival process can have dramatic
effects.
consider for example the m=m=1 queue describing the situation with a pois-
son arrival process (the inter-arrival times are distributed negative exponentially),
negative-exponentially distributed service times and one server (i.e., at most one
customer is served at a time). assuming an arrival rate l(average number of cus-
tomers arriving per time unit) and service rate m(average number of customers that
can be handled per time unit), the average Ô¨Çow time is1
m l. ifl=98 (on average
98 customers arrive per day) and m=100 (the average service time is approximately
14 minutes), then the average Ô¨Çow time is1
100 98=0:5 (12 hours). if lincreases
to 99 (an increase of approximately 1%), then the average Ô¨Çow time doubles to
1
100 99=1, i.e., a full day. the example illustrates that a small increase in work-
load may have dramatic effects on the mean Ô¨Çow or waiting time. therefore, the
sensitivity of the model to minor adjustments of its parameters should be seriously
accounted for.
5.1.7 risk 7: no subruns
some people say: ‚Äúa sufÔ¨Åciently long simulation yields correct results!‚Äù they exe-
cute a simulation run for a night or weekend and then blindly trust, e.g., the meanbusiness process simulation survival guide 23
waiting time measured. this is a very risky practice, as no assertions about the re-
liability of the result can be given. others derive a conÔ¨Ådence interval from the
mean variance measured. this is also wrong because, for example, the mean vari-
ance of the waiting time measured is unrelated to the reliability of the estimated
mean waiting time. the only way to derive independent measurements is by having
independent subruns!
5.1.8 risk 8: careless presentation of the results
interpreting the results of a simulation study may require complex statistical analy-
ses. this is often a source of errors. translating the results from statistics into lan-
guage a user can understand, can be very tricky indeed. in darrel huff‚Äôs book ‚Äúhow
to lie with statistics‚Äù ([18]), there are numerous examples of sloppy and misleading
presentations. as an example, suppose the Ô¨Ånal report of a simulation study contains
the following conclusion ‚Äúwaiting times will be reduced by 10 percent‚Äù. this con-
clusion is very incomplete, as it contains no reference whatsoever to its reliability.
it is good practice to give a conÔ¨Ådence interval. the same conclusion suggests that
waiting times will be reduced by 10 percent for each customer. this, however, may
not be the case. the average waiting time may be reduced by 10 percent while it
increases for certain customers and is reduced somewhat more for others.
5.1.9 risk 9: dangers of animation
modern simulation tools allow for impressive visualizations of simulation results.
animation facilities graphically show the process while it is unfolding. these facil-
ities improve communication with the user. however, there is an inherent danger in
animation. as animation only shows the tangible aspects of the simulation model,
the user may develop an unfounded faith in the model. the choice of parameters or
decision making rules deeply inÔ¨Çuence the simulation results, yet are barely visible
in an animation. the same hold for the presentation of simulation results. impressive
3d charts do not replace a sound statistical analysis.
5.1.10 risk 10: unnecessary use of simulation
simulation is a Ô¨Çexible analysis tool that can be applied in almost any business
context. therefore, one may be tempted to use it regardless of the circumstances.
often, however, a simple mathematical model (e.g. a queuing model) or a simple
spreadsheet calculation is sufÔ¨Åcient. in such cases simulation is ‚Äúoverkill‚Äù. it should
only be used if and when the situation requires it. simulation is a means and not a
goal!24 wil m.p. van der aalst
5.2 speciÔ¨Åc risks
the ten risks highlighted in figure 6 cover the different phases of a simulation
project. besides these general risks there are more speciÔ¨Åc risks related to not in-
corporating relevant contextual factors (that may be changing over time) and not
capturing characteristics of human resources (working patterns, partial availability,
and varying working speeds). for example, human resources are typically modeled
in a rather na ¬®ƒ±ve manner. as a result, it is not uncommon that the simulated model
predicts Ô¨Çow times of minutes or hours while in reality Ô¨Çow times are weeks or even
months [5].
5.2.1 risk 11: abstracting away relevant contextual factors
processes unfold in a particular context [29] that is often neglected in simulation
studies. not capturing this context may result in simulation models with limited
predictive value. to explain the notion of ‚Äúcontext‚Äù consider figure 7 (taken from
[4]). in [4] four levels of context data are considered:
instance context. process instances (that is, cases) might have various properties
that inÔ¨Çuence their execution. consider the way businesses handle a customer
order. the type of customer placing the order can inÔ¨Çuence the path the instance
follows in the process. the order‚Äôs size can inÔ¨Çuence the type of shipping the
customer selects or the transportation time. these properties can directly relate
to the individual process instance; we refer to them as the instance context. typ-
ically, discovering relationships between the instance context and the case‚Äôs ob-
served behavior is not difÔ¨Åcult. we might, for example, discover that an activity
is typically skipped for vip customers.
process context. a process might be instantiated many times - for example, the
process can handle thousands of customer orders per year. yet, the corresponding
process model typically describes one order‚Äôs life cycle in isolation. although in-
teractions among instances are not very explicit in most simulation models, they
can inÔ¨Çuence each other. instances might compete for the same resources, and an
order might be delayed by too much work-in-progress. looking at one instance in
isolation is not sufÔ¨Åcient for understanding the real behavior. simulation models
should also consider the process context, such as the number of instances being
handled and resources available for the process. when analyzing the Ô¨Çow time of
cases, the simulation model should consider not only the order‚Äôs status (instance
context) but also the workload and resource availability (process context).
social context. the process context considers all factors directly related to a
process and its instances. however, people and organizations typically are not
allocated to a single process and might be involved in many different processes.
moreover, activities are executed by people operating in a social network. fric-
tion between individuals can delay process instances, and the speed at which
people work might vary due to circumstances that are not fully attributable to thebusiness process simulation survival guide 25
instance 
context
e.g. size of order or 
type of customerprocess contextsocial contextexternal context
e.g., number of resources 
allocated to process, number 
of cases in progress
e.g., prioritization over different 
processes, social network, 
stress levels, internal 
competition 
e.g., weather, economic 
climate, seasonal effects, 
changes in legislationexpanding scope (more instances, 
more processes, etc.)a more direct relationship
between cause and effect
fig. 7 levels of context data. context can inÔ¨Çuence processes and may change over time. never-
theless, simulation models seldom explicitly model the outer two context levels and do not antici-
pate context changes.
process being analyzed (see also risk 14). we refer to all these factors as the
social context, which characterizes how people work together within a particu-
lar organization. today‚Äôs simulation tools tend to neglect the social context even
though it directly impacts how people and organizations handle cases.
external context. the external context captures factors that are part of an ecosys-
tem that extends beyond an organization‚Äôs control sphere. for example, the
weather, the economic climate, and changing regulations might inÔ¨Çuence how
organizations handle cases. the weather might inÔ¨Çuence the workload, as when
a storm or Ô¨Çooding leads to increased insurance claims. changing oil prices can
inÔ¨Çuence customer orders, as when the demand for heating oil increases as prices
drop. more stringent identity checks inÔ¨Çuence the order in which a government
organization executes social-security-related activities. although external con-
text can have a dramatic impact on the process being analyzed, selecting relevant
variables is difÔ¨Åcult. learning the external context‚Äôs effects is closely related to
identifying concept drift (see also risk 12) - for example, a process might grad-
ually change due to external seasonal effects.26 wil m.p. van der aalst
simulation models tend to focus on the Ô¨Årst two levels of the ‚Äúunion model‚Äù depicted
in figure 7. this may be valid in many studies. however, if the social context and
external context matter, they should be incorporated explicitly.
5.2.2 risk 12: ignoring concept drift
the term concept drift refers to a situation in which the process is changing while
being analyzed [10, 36]. processes can change due to periodic or seasonal changes
(‚Äúin december, there is more demand‚Äù or ‚Äúon friday afternoon, fewer employees
are available‚Äù) or to changing conditions (‚Äúthe market is getting more competitive‚Äù).
such changes affect processes, and organizations must detect and analyze them. the
notion of concept drift is closely related to the context notion illustrated in figure 7.
large parts of the context cannot be fully controlled by the organization conduct-
ing a simulation study. therefore, contextual variability needs to be considered and
cannot be ignored.
predictable drifts (e.g., seasonal inÔ¨Çuences) with a signiÔ¨Åcant inÔ¨Çuence on the
process need to be incorporated in simulation models. for unpredictable drifts (e.g.,
changing economic conditions), several ‚Äúwhat if‚Äù scenarios need to be explored.
5.2.3 risk 13: ignoring that people are involved in multiple processes
in practice there are few people that only perform activities for a single process.
often people are involved in many different processes, e.g., a manager, doctor, or
specialist may perform tasks in a wide range of processes. the left-hand side of
figure 8 shows a gantt chart illustrating how an individual may distribute her time
over activities in different processes. simulation often focuses on a single process,
often ignoring competing processes.
suppose a manager is involved in a dozen processes and spends about 20 percent
of her time on the process that we want to analyze. in most simulation tools it is
impossible to model that she is only available 20 percent of the time. hence, one
needs to assume that the manager is there all the time and has a very low utilization.
as a result the simulation results are too optimistic. in the more advanced simulation
tools, one can indicate that resources are there at certain times in the week (e.g.,
only on monday morning). this is also an incorrect abstraction as the manager
distributes her work over the various processes based on priorities and workload.
suppose that there are 5 managers all working 20 percent of their time on the process
of interest. one could think that these 5 managers could be replaced by a single
manager (5*20%=1*100%). however, from a simulation point of view this is an
incorrect abstraction. there may be times that all 5 managers are available and there
may be times that none of them is available.
people are involved in multiple processes and even within a single process dif-
ferent activities and cases may compete for shared resources. one process may be
more important than another and get priority. in some processes cases that are de-business process simulation survival guide 27
layed may get priority while in other processes late cases are ‚ÄúsacriÔ¨Åced‚Äù to Ô¨Ånish
other cases in time. people need to continuously choose between work-items and set
priorities. although important, this is typically not captured by simulation models.
workloadspeedoptimal 
stress level
overloadedlethargicactivity a.1
activity a.2
‚Ä¶
activity a.8process a
activity b.1
activity b.2
‚Ä¶
activity b.6process b
activity c.1
activity c.2
‚Ä¶
activity c.9process c
time
fig. 8 people are typically involved in multiple processes and need to distribute attention over
these processes and related activities (left). moreover, people do not work at constant speed (right).
the ‚Äúyerkes-dodson law of arousal‚Äù [37] describes the phenomenon that people work at different
speeds based on their workload.
5.2.4 risk 14: assuming that people work at constant speeds
another problem is that people work at different speeds based on their workload,
i.e., it is not just the distribution of attention over various processes, but also the
absolute working speed that determines the resource‚Äôs contribution to the process.
there are various studies that suggest a relation between workload and performance
of people. a well-known example is the so-called ‚Äúyerkes-dodson law of arousal‚Äù
[37]. the yerkes-dodson law models the relationship between arousal and perfor-
mance as a\-shaped curve (see right-hand side of figure 8). this implies that, for
a given individual and a given type of task, there exists an optimal arousal level.
this is the level where the performance has its maximal value. thus work pressure
is productive, up to a certain point, beyond which performance collapses. although
this phenomenon can be easily observed in daily life [24], today‚Äôs business pro-
cess simulation tools typically do not support the modeling of workload dependent
processing times.
5.2.5 risk 15: ignoring that people work in batches
as indicated earlier, people may be involved in different processes. moreover, they
may work part-time (e.g., only in the morning). in addition to their limited avail-
abilities, people have a tendency to work in batches (cf. resource pattern 38: piled28 wil m.p. van der aalst
execution [33]). in any operational process, the same task typically needs to be
executed for many different cases (process instances). often people prefer to let
work-items related to the same task accumulate, and then process all of these in one
batch. in most simulation tools a resource is either available or not, i.e., it is assumed
that a resource is eagerly waiting for work and immediately reacts to any work-item
that arrives. clearly, this does not do justice to the way people work in reality. for
example, consider how and when people reply to e-mails. some people handle e-
mails one-by-one when they arrive while others process their e-mail at Ô¨Åxed times
in batch. related is the fact that calendars and shifts are typically ignored in simu-
lation tools. while holidays, lunch breaks, etc. can heavily impact the performance
of a process, they are typically not incorporated in the simulation model.
in [5] a general approach based on ‚Äúchunks‚Äù is used to model availability more
adequately. the basic idea is that people spend ‚Äúchunks of time‚Äù on a particular
process or task. within a period of time a limited number of chunks is available.
within a chunk, work is done in batches. as chunks become more coarse-grained,
Ô¨Çow times go up even when the overall utilization does not change [5].
6 advanced simulation
the 15 risks described in section 5 illustrate that many things can go wrong in a sim-
ulation project. fortunately, modern it infrastructures and the enormous amounts of
event data collected in many organizations also enable new forms of simulation. it
systems are becoming more and more intertwined with the business processes they
aim to support, resulting in an ‚Äúexplosion‚Äù of available data that can be used for
analysis purposes. today‚Äôs information systems already log enormous amounts of
events and it is clear that data-based analytics like process mining [2] will become
more important. increasingly, simulation techniques will need to incorporate actual
event data . moreover, there will be a shift from off-line analysis at design time to
on-line analysis at run-time .
figures 2 and 4 present a rather classical view on business process simulation.
this is the type of simulation supported by hundreds, if not thousands, of com-
mercial simulation packages. some vendors provide a pure simulation tool (e.g.,
arena, extend, etc.) while others embed this in a workÔ¨Çow management system
(e.g., filenet, cosa, etc.) or a business process modeling tool (e.g., protos, aris,
etc.). all of these tools use the information presented in figure 2 to simulate busi-
ness processes and subsequently measure obvious performance indicators such as
Ô¨Çow time, utilization, etc. using figure 9, we will show that it is possible to move
beyond ‚Äútraditional‚Äù simulation approaches.
the left-hand-side of figure 9 shows the role of a process-aware information
system (a wfm/bpm system or any other process-oriented information system,
e.g., an erp system like sap) in supporting operational business processes. the
information system supports, controls, and monitors operational processes. the re-
sources within the organization perform tasks in such processes and therefore alsobusiness process simulation survival guide 29
information 
systemoperational process
organization/
resources
process modelreal event data
process state
resource model
describe
configureinteract
record
usetraditional simulation 
(steady state, naive view of 
resources, only indirect use of 
historic information)advanced simulation 
(transient and steady state, 
refined view of resources, use 
of historic and state information)
enactment analysissimulation 
reportsimulated event 
dataunified view on 
simulated and 
real event data
fig. 9 advanced simulation compared to traditional simulation. note that real event data and
simulated event data can be stored in event logs and analyzed using the same process mining
tool. due to this uniÔ¨Åed view on process behavior, simulation can be embedded in day-to-day
management and decision making.
interact with the information system. the information system can only do meaning-
ful things if it has knowledge of the process, the resources within the organization
and the current states of active cases. moreover, today‚Äôs information systems often
record historical information for auditing and performance analysis. the lower four
ellipses in the middle of figure 9 show four types of data implicitly or explicitly
available when an information system is supporting an operational process: (1) real
event data, (2) process state, (3) process model, and (4) resource model. an event
log(i.e., real event data) contains historical information about ‚Äúwhen, how, and by
whom?‚Äù in the form of recorded events. the process state represents all information
that is attached to currently running cases, e.g., customer order xyz consists of 25
order lines and has been in the state ‚Äúwaiting for replenishment‚Äù since monday. the
process state may also contain context information relevant for the process, e.g.,
the weather or economic trends. the process model describes the ordering of tasks,
routing conditions, etc. the resource model holds information about people, roles,
departments, etc. clearly, the process state, process model, and resource model may
be used to enact the process. the event log merely records the process as it is actu-
ally enacted.
the right-hand-side of figure 9 focuses on analysis rather than enactment; it
links the four types of data to simulation. for traditional simulation (i.e., in the
sense of figures 2 and 4) a hand-made simulation model is needed. this simula-
tion model can be derived from the process model used by the information system.
moreover, information about resources, arrival processes, processing times, etc. is
added (cf. figure 2). the arcs between the box traditional simulation and the three
types of data (real event data, process model, and resource model) are curved to30 wil m.p. van der aalst
illustrate that the relationship between the data used by the information system and
the simulation tool is typically rather indirect. for example, the analyst cannot use
the process model directly, but needs to transform it to another language or nota-
tion. the resource model used for simulation is typically rather simple compared to
models that can be enacted by a wfm or bpm system. often each activity has a
single role and a Ô¨Åxed number of resources is available per role. moreover, often it
is assumed that these resources are available on a full-time basis. real event data are
not used directly. at best, event logs are used to estimate the parameters for some
of the probability distributions. traditional simulation models are nottightly cou-
pled to the actual information and historical data and model resource behavior in a
rather na ¬®ƒ±ve manner. moreover, the current state (including context information) is
not used at all. as such, simulation focuses on steady-state behavior and cannot be
used for operational decision making.
we advocate more advanced forms of simulation. first of all, we propose a tight
coupling with the information system supporting the process that is being analyzed.
simulation should exploit event logs and process state information. second, analysis
should not only focus on steady-state behavior but also on transient behavior in order
to also support operational decision making. this is illustrated by the box advanced
simulation in figure 9.
advanced simulation should exploit real event data to semi-automatically learn
better simulation models. therefore, we advocate using process mining techniques
[2]. process mining exploits the information recorded in audit trails, transaction
logs, databases, etc. process mining includes (automated) process discovery (i.e.,
extracting process models from an event log), conformance checking (i.e., monitor-
ing deviations by comparing model and log), social network/organizational mining,
model extension, and process model repair. the automated construction of simula-
tion models is possible by combining existing process mining techniques [31].
it is essential to note that, through process mining, events in the log can be re-
lated to model elements. this allows for the projection of dynamic information onto
models: the event log ‚Äúbreathes life‚Äù into otherwise static process models. consider
a control-Ô¨Çow model, e.g., the petri net, bpmn, or epc model shown in figure 1.
such a model may have been discovered or made by hand. by replaying the event
log on the model, it is possible to enrich the model with frequencies, probabilities
and delays [31]. this illustrates that the additional information described in figure 2
can indeed be discovered, thus resulting in a full-Ô¨Çedged simulation model.
establishing a good connection between event log and model may be difÔ¨Åcult
and require several iterations. however, when using a wfm or bpm system, this
connection already exists. wfm and bpm systems are driven by explicit process
models and provide excellent event logs. moreover, internally such systems also
have an explicit representation of the state of each running case. this enables a new
type of simulation called short-term simulation [2, 32]. the key idea is to start all
simulation runs from the current state and focus on transient behavior. this way a
‚Äúfast forward button‚Äù into the future is provided. to understand the importance of
short-term simulation, see figure 5 which explains the difference between transient
analysis and steady-state analysis. the key idea of simulation is to execute a modelbusiness process simulation survival guide 31
repeatedly. the reason for doing the experiments repeatedly, is to not come up with
just a single value (e.g., ‚Äúthe average response time is 10.36 minutes‚Äù) but to provide
conÔ¨Ådence intervals (e.g., ‚Äúthe average response time is with 90 percent certainty
between 10 and 11 minutes‚Äù). for transient analysis the focus is on the initial part
of future behavior, i.e., starting from the initial state the ‚Äúnear future‚Äù is explored.
for transient analysis the initial state is very important. if the simulation starts in a
state with long queues of work, then in the near future Ô¨Çow times will be long and it
may take quite some time to get rid of the backlog. for steady-state analysis the ini-
tial state is irrelevant. typically, the simulation is started ‚Äúempty‚Äù (i.e., without any
cases in progress) and only when the system is Ô¨Ålled with cases measurement starts.
steady-state analysis is most relevant for answering strategic and tactical questions.
transient analysis is most relevant for operational decision making. lion‚Äôs share of
contemporary simulation support aims at steady-state analysis and, hence, is limited
to strategic and tactical decision making. short-term simulation focuses on opera-
tional decision making ; starting from the current state (provided by the information
system) the ‚Äúnear future‚Äù is explored repeatedly. this shows what will happen if no
corrective actions are taken. moreover, ‚Äúwhat if‚Äù analysis can be used to explore
the effects of different interventions (e.g., adding resources and reconÔ¨Åguring the
process).
figure 9 shows that advanced simulation uses all information available, e.g.,
event data to learn process characteristics, the current state to enable short-term sim-
ulation (‚Äúfast forward button‚Äù), and a more reÔ¨Åned resource model to better capture
working patterns.
process mining techniques are driven by event logs recorded for the actual pro-
cess. similar event logs can be generated by simulation. in both cases events are
described by a reference to some process instance (the case), an activity, a times-
tamp, a resource, and other attributes (e.g., costs). the top-most ellipse in the middle
of figure 9 (tagged ‚Äúsimulated event data‚Äù) refers to event logs produced by simu-
lation rather than reality. as shown, both simulated and real events can be viewed
using the same tools . this is very important for operational decision making and
‚Äúwhat if‚Äù analysis. different future scenarios can be explored using visualizations
also used for past and current event data.
7 conclusion
this chapter provides a ‚Äúsurvival guide‚Äù to business process simulation. besides
providing a basic introduction to the topic, the chapter lists 15 risks, i.e., potential
pitfalls, when using simulation. moreover, the chapter also shows that more ad-
vanced forms of simulation come into reach as it and business processes get more
intertwined.
to conclude the chapter, we suggest books and articles for bpm academics and
professionals that want to learn more about business process simulation:32 wil m.p. van der aalst
there are many (text) books on simulation, see for example [8, 11, 16, 19, 20, 22,
25, 26, 27, 28, 30, 34]. books like [20, 27, 30] focus on the statistical aspects of
simulation. books like [8, 19, 16, 22] focus on the creation of simulation models.
the book ‚Äúsuccessful simulation: a practical approach to simulation projects‚Äù
[28] is one of the few books focusing on simulation projects (including topics
such as project management).
in [15, 23] various techniques for the analysis of stochastic petri nets (i.e., petri
nets extended with priorities, probabilities, and durations) are described. see [9,
12, 21] for some seminal papers on the analysis of processes using analytical
methods.
for more information on role of various analysis techniques (including simula-
tion) in bpm we refer to [3, 6, 14, 17, 35]. see [2, 31] for techniques to auto-
matically discover simulation models from event data and [32] for operational
decision support using simulation (e.g., short-term simulation).
this chapter is based on [1, 4, 5, 7]: in [1] we elaborate on the relation between
simulation and process mining, in [5] we focus on the proper modeling of resource
availability, in [4] we emphasize the importance of incorporating context, and in [7]
we provide a tutorial on conventional business process simulation.
acknowledgements. the author would like to thank joyce nakatumba, marc
v oorhoeve, anne rozinat, ronny mans, hajo reijers, michael westergaard, and
mariska netjes for their joint work on business process simulation. this work
was supported by the basic research program of the national research university
higher school of economics (hse).
references
1. w.m.p. van der aalst. business process simulation revisited. in j. barjis, editor, enter-
prise and organizational modeling and simulation , volume 63 of lecture notes in business
information processing , pages 1‚Äì14. springer-verlag, berlin, 2010.
2. w.m.p. van der aalst. process mining: discovery, conformance and enhancement of busi-
ness processes . springer-verlag, berlin, 2011.
3. w.m.p. van der aalst. business process management: a comprehensive survey. isrn soft-
ware engineering , pages 1‚Äì37, 2013. doi:10.1155/2013/507984.
4. w.m.p. van der aalst and s. dustdar. process mining put into context. ieee internet com-
puting , 16(1):82‚Äì86, 2012.
5. w.m.p. van der aalst, j. nakatumba, a. rozinat, and n. russell. business process simula-
tion: how to get it right? in j. vom brocke and m. rosemann, editors, handbook on busi-
ness process management , international handbooks on information systems, pages 313‚Äì338.
springer-verlag, berlin, 2010.
6. w.m.p. van der aalst and c. stahl. modeling business processes: a petri net oriented ap-
proach . mit press, cambridge, ma, 2011.
7. w.m.p. van der aalst and m. v oorhoeve. simulation handbook. bpm center report bpm-
00-04, bpmcenter.org, 2000. (original dutch version appeared as ‚Äúw.m.p. van der aalst.
handboek simulatie. computing science reports 95/32, eindhoven university of technol-
ogy, eindhoven, 1995‚Äù).business process simulation survival guide 33
8. t. altiok and b. melamed. simulation modeling and analysis with arena . elsevier academic
press, amsterdam, 2007.
9. f. baskett, k.m. chandy, r.r. muntz, and f.g. palacios. open, closed and mixed networks
of queues with different classes of customers. journal of the association of computing
machinery , 22(2):248‚Äì260, april 1975.
10. r.p. jagadeesh chandra bose, w.m.p. van der aalst, i. zliobaite, and m. pechenizkiy. han-
dling concept drift in process mining. in h. mouratidis and c. rolland, editors, interna-
tional conference on advanced information systems engineering (caise 2011) , volume 6741
oflecture notes in computer science , pages 391‚Äì405. springer-verlag, berlin, 2011.
11. p. bratley, b.l. fox, and l.e. schrage. a guide to simulation . springer-verlag, berlin, 1983.
12. j.a. buzacott. commonalities in reengineered business processes: models and issues. man-
agement science , 42(5):768‚Äì782, 1996.
13. o.j. dahl and k. nygaard. simula: an algol based simulation language. communica-
tions of the acm , 1:671‚Äì678, sept 1966.
14. m. dumas, m. la rosa, j. mendling, and h. reijers. fundamentals of business process
management . springer-verlag, berlin, 2013.
15. p.j. haas. stochastic petri nets: modelling, stability, simulation . springer series in opera-
tions research. springer-verlag, berlin, 2002.
16. a.k. hartmann. practical guide to computer simulations . world scientiÔ¨Åc publishing,
singapore, 2009.
17. a.h.m. ter hofstede, w.m.p. van der aalst, m. adams, and n. russell. modern business
process automation: yawl and its support environment . springer-verlag, berlin, 2010.
18. d. huff. how to lie with statistics . penguin books, new york, 1954.
19. d.w. kelton, r. sadowski, and d. sturrock. simulation with arena . mcgraw-hill, new york,
2003.
20. j. kleijnen and w. van groenendaal. simulation: a statistical perspective . john wiley and
sons, new york, 1992.
21. l. kleinrock. queueing systems, vol. 1:theory . wiley-interscience, london, 1975.
22. a.m. law and d.w. kelton. simulation modeling and analysis . mcgraw-hill, new york,
1982.
23. m. ajmone marsan, g. balbo, g. conte, s. donatelli, and g. franceschinis. modelling with
generalized stochastic petri nets . wiley series in parallel computing. wiley, new york, 1995.
24. j. nakatumba and w.m.p. van der aalst. analyzing resource behavior using process mining.
in s. rinderle-ma, s. sadiq, and f. leymann, editors, bpm 2009 workshops, proceedings of
the fifth workshop on business process intelligence (bpi‚Äô09) , volume 43 of lecture notes in
business information processing , pages 69‚Äì80. springer-verlag, berlin, 2010.
25. t.h. naylor, j.l. balintfy, d.s. burdick, and kong chu. computer simulation techniques .
wiley, new york, 1966.
26. m. pidd. computer modelling for discrete simulation . john wiley and sons, new york,
1989.
27. b. ripley. stochastic simulation . wiley-interscience, hoboken, usa, 2006.
28. s. robinson. successful simulation: a practical approach to simulation projects . mcgraw-
hill, maidenhead, uk, 1994.
29. m. rosemann, j. recker, and c. flender. contextualisation of business processes. interna-
tional journal of business process integration and management , 3(1):47‚Äì60, 2008.
30. s.m. ross. a course in simulation . macmillan, new york, 1990.
31. a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering simulation models.
information systems , 34(3):305‚Äì327, 2009.
32. a. rozinat, m. wynn, w.m.p. van der aalst, a.h.m. ter hofstede, and c. fidge. workÔ¨Çow
simulation for operational decision support. data and knowledge engineering , 68(9):834‚Äì
850, 2009.
33. n. russell, w.m.p.van der aalst, a.h.m. ter hofstede, and d. edmond. workÔ¨Çow resource
patterns: identiÔ¨Åcation, representation and tool support. in o. pastor and j. falcao e cunha,
editors, proceedings of the 17th conference on advanced information systems engineering
(caise‚Äô05) , volume 3520 of lecture notes in computer science , pages 216‚Äì232. springer-
verlag, berlin, 2005.34 wil m.p. van der aalst
34. r.e. shannon. systems simulation: the art and science . prentice-hall, englewood cliffs,
1975.
35. m. weske. business process management: concepts, languages, architectures . springer-
verlag, berlin, 2007.
36. g. widmer and m. kubat. learning in the presence of concept drift and hidden contexts.
machine learning , 23:69‚Äì101, 1996.
37. r.m. yerkes and j.d. dodson. the relation of strength of stimulus to rapidity of habit-
formation. journal of comparative neurology and psychology , 18:459‚Äì482, 1908.