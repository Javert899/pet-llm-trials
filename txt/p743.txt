a general divide and conquer approach for
process mining
wil m.p. van der aalst
architecture of information systems, eindhoven university of technology,
p.o. box 513, nl-5600 mb, eindhoven, the netherlands.
international laboratory of process-aware information systems,
national research university higher school of economics (hse),
33 kirpichnaya str., moscow, russia.
email: w.m.p.v.d.aalst@tue.nl
abstract ‚Äîoperational processes leave trails in the information
systems supporting them. such event data are the starting point
for process mining ‚Äì an emerging scientiÔ¨Åc discipline relating
modeled and observed behavior. the relevance of process mining
is increasing as more and more event data become available.
the increasing volume of such data (‚Äúbig data‚Äù) provides both
opportunities and challenges for process mining. in this paper
we focus on two particular types of process mining: process
discovery (learning a process model from example behavior
recorded in an event log) and conformance checking (diagnosing
and quantifying discrepancies between observed behavior and
modeled behavior). these tasks become challenging when there
are hundreds or even thousands of different activities and millions
of cases. typically, process mining algorithms are linear in the
number of cases and exponential in the number of different
activities. this paper proposes a very general divide-and-conquer
approach that decomposes the event log based on a partitioning of
activities. unlike existing approaches, this paper does not assume
a particular process representation (e.g., petri nets or bpmn)
and allows for various decomposition strategies (e.g., sese- or
passage-based decomposition). moreover, the generic divide-and-
conquer approach reveals the core requirements for decomposing
process discovery and conformance checking problems.
i. i ntroduction
recently, process mining emerged as a new scientiÔ¨Åc
discipline on the interface between process models and
event data [1]. conventional business process management
(bpm) [2] and workÔ¨Çow management (wfm) [3] approaches
and tools are mostly model-driven with little consideration
for event data. data mining (dm) [4], business intelligence
(bi), and machine learning (ml) [5] focus on data without
considering end-to-end process models. process mining aims
to bridge the gap between bpm and wfm on the one hand
and dm, bi, and ml on the other hand (cf. figure 1).
the practical relevance of process mining is increasing as
more and more event data become available (cf. the recent
attention for ‚Äúbig data‚Äù). process mining techniques aim to
discover, monitor and improve real processes by extracting
knowledge from event logs . the two most prominent process
mining tasks are: (i) process discovery : learning a process
model from example behavior recorded in an event log, and (ii)
conformance checking : diagnosing and quantifying discrepan-
cies between observed behavior and modeled behavior.
starting point for any process mining task is an event log .
each event in such a log refers to an activity (i.e., a well-
process 
mining
data-oriented analysis  
(data mining, machine learning, business intelligence)process model analysis  
(simulation, verification, optimization, gaming, etc.)
performance-
oriented 
questions, 
problems and 
solutionscompliance-
oriented 
questions, 
problems and 
solutionsfig. 1. process mining is on the interface between process model analysis
and data-oriented analysis and can be used to answer a variety of performance
and compliance-related questions.
deÔ¨Åned step in some process) and is related to a particular
case (i.e., a process instance ). the events belonging to a case
are ordered, and can be seen as one ‚Äúrun‚Äù of the process. such
a run is often referred to as a trace . it is important to note that
an event log contains only example behavior, i.e., we cannot
assume that all possible runs have been observed.
lion‚Äôs share of process mining research has been devoted
to process discovery [1]. here the challenge is to turn a
multiset of example traces (observed cases) into a process
model. process representations allowing for concurrency and
choice, e.g., petri nets, bpmn models, uml activity diagrams,
or epcs, are preferred over low-level notations such as Ô¨Ånite
state machines of hidden markov models [1].
given a process model (discovered or made by hand) and
an event log one can try to align modeled and observed
behavior . an alignment relates a trace in a event log to its
corresponding path in the model. if there is not a direct match,
the trace is aligned with the closest or most likely path. such
alignments can be used to answer performance-oriented and
compliance-oriented questions (cf. figure 1). alignments can
be used to show how often paths are taken and activities are
being executed. moreover, events often bear a timestamp whichcan be used to compute Ô¨Çow times, waiting times, service
times, etc. for example, alignments can be used to highlight
bottlenecks in the process model. similarly, alignments can
be used to show where model and event log disagree. this is
commonly referred to as conformance checking .
the incredible growth of event data is also posing new
challenges [6]. as event logs grow, process mining techniques
need to become more efÔ¨Åcient and highly scalable. moreover,
torrents of event data need to be distributed over multiple
databases and large process mining problems need to be
distributed over a network of computers. several approaches
have been described in literature [7], [8], [9], [10], [11] (also
see the related work described in section vii). in this paper,
we describe a generic divide-and-conquer approach based on
a (valid) partitioning of the activities in sets. the activity
sets should overlap if there is a direct dependency. we will
illustrate the divide-and-conquer approach for the two main
process mining tasks:
 for conformance checking, we decompose the process
model into smaller partly overlapping submodels using
projection. the event log is decomposed into sublogs,
also using projection. any trace that Ô¨Åts into the
overall model also Ô¨Åts all submodels. the reverse only
holds if the partitioning is valid . metrics such as the
fraction of Ô¨Åtting cases can be computed by checking
the conformance of the submodels.
 to decompose process discovery, we Ô¨Årst create an
activity partitioning, i.e., we split the set of activities
into a collection of partly overlapping activity sets. for
each activity set, we project the log onto a sublog and
discover a submodel for it. the different submodels
can be merged to create an overall process model.
again it is guaranteed that all traces in the event
log that Ô¨Åt into the overall model also Ô¨Åt into the
submodels and vice versa.
unlike existing papers [7], [8], [9], [10], [11], we abstract
from a concrete process representation and do not select a
particular decomposition strategy. instead we focus on the core
requirements to enable decomposition.
the remainder is organized as follows. section ii in-
troduces preliminaries ranging from multisets to event logs.
section iii provides abstract high-level deÔ¨Ånitions for process
discovery and conformance checking. section iv shows that
any process mining problem can be decomposed trivially,
but with a possible loss of precision. section v shows that
exact results can be obtained (not just bounds) if the activity
partitioning is valid. section vi discusses possible strategies to
obtain valid (or otherwise suitable) activity partitionings. re-
lated work is described in section vii. section viii concludes
the paper.
ii. p reliminaries
before describing the two main process mining tasks and
the ways in which these tasks can be distributed, we introduce
some basic notations to reason about event logs and process
models.a. multisets, sequences and projection
multisets are used to represent the state of a petri net and to
describe event logs where the same trace may appear multiple
times.
b(a)is the set of all multisets over some set a. for some
multisetb2b(a),b(a)denotes the number of times element
a2aappears inb. some examples: b1= [ ] ,b2= [x;x;y ],
b3= [x;y;z ],b4= [x;x;y;x;y;z ],b5= [x3;y2;z]are
multisets over a=fx;y;zg.b1is the empty multiset, b2
andb3both consist of three elements, and b4=b5, i.e., the
ordering of elements is irrelevant and a more compact notation
may be used for repeating elements.
the standard set operators can be extended to multisets,
e.g.,z2b3,b2]b3=b4,b5nb2=b3,jb5j= 6, etc. bags
are compared in the usual manner, i.e., b2b4andb26b3.
fa2bgdenotes the set with all elements afor whichb(a)1.
[f(a)ja2b]denotes the multiset where element f(a)appearsp
x2bjf(x)=f(a)b(x)times.
p(x)is the powerset of x, i.e.,y2p(x)ifyx.
=ha1;a2;:::;ani2xdenotes a sequence over x.
jj=nis its length. a2if and only if a2fa1;a2;:::;ang.
hiis the empty sequence.
projection is deÔ¨Åned for sequences and sets or bags of
sequences.
deÔ¨Ånition 1 (projection): let2xandyx.y
is the projection of ony, i.e., all elements in xnyare
removed (e.g.,hx;y;z;x;y;zifx;yg=hx;y;x;yi). projec-
tion is generalized to sets and bags. if s2 p(x), then
sy=fyj2sgifb2b(x), thenby= [yj
2b]. in the latter case frequencies are respected, e.g.,
[hx;y;z;yi10;hz;y;z;yi5]fx;yg= [hx;y;yi10;hy;yi5].
without proof we mention some basic properties for se-
quences and projections.
lemma 1 (projection properties): let2x,yx,
s2p(x), andb2b(x).
2s)y2sy,
2b)y2by,
2sy, 902s=0y,
2by, 902b=0y, and
 for any12x1and22x2:1x2=2x1,
932(x1[x2)3x1=1^3x2=2.
b. activities, traces, event logs, and models
event logs serve as the starting point for process mining.
an event log is a multiset of traces. each trace describes
the life-cycle of a particular case (i.e., a process instance) in
terms of the activities executed. process models are represented
as sets of traces. as indicated earlier, we avoid restricting
ourselves to a speciÔ¨Åc process notation. however, we will show
some petri nets and a bpmn model for illustration purposes.
deÔ¨Ånition 2 (universe of activities, universe of traces):
ais the universe of activities , i.e., the set of all possible and
relevant activities. other activities cannot be observed (or areabstracted from). elements of amay have attributes , e.g.,
costs, resource information, duration information, etc. a trace
2ais a sequence of activities found in an event log or
corresponding to a run of some process model. u=ais
the universe of all possible traces over a.
we assume that an activity is identiÔ¨Åed by attributes
relevant for learning, i.e., irrelevant attributes are removed
and attribute values may be coarsened. jajis the number of
unique activities. process models with hundreds of activities
(or more) tend to be unreadable. in the remainder we will refer
to activities using a single letter (e.g. a), however, an activity
could also be decide (gold;manager;reject )to represent a
decision to reject a gold customer‚Äôs request by a manager.
in a process model a speciÔ¨Åc trace 2u is possible or
not. hence, a model can be characterized by its set of allowed
traces.
deÔ¨Ånition 3 (process model): aprocess model mis a
non-empty collection of traces, i.e., m2p(u)andm6=;.
am=s
2mfa2gis the set of activities possible in
m. figure 2 shows a process model musing the business
process model and notation (bpmn) [12]. for this paper the
representation itself is irrelevant. trace ha;b;d;e;f;c;d;giis
one of the inÔ¨Ånitely many possible traces of m.
an event log is a multiset of sample traces from a known
or unknown process. the same trace can appear multiple times
in the log. moreover, the event log contains only example
behavior. often only few of the possible traces are observed
[1].
deÔ¨Ånition 4 (event log): anevent logl2 b(u)is a
multiset of observed traces.
al=s
2lfa2gis the set of activities occurring in
l. note that projection (see deÔ¨Ånition 1) is deÔ¨Åned for both
models and event logs.
l= [ha;b;d;e;gi5;ha;c;d;e;hi4;ha;b;d;e;f;c;d;e;g i]
is an event log containing 10 traces that could have been
generated by the bpmn model in figure 2, e.g., Ô¨Åve cases
followed the path ha;b;d;e;gi.
iii. p rocess discovery and conformance
checking
in the introduction we already informally introduced the
two main process mining tasks: process discovery (learning
a model from a collection of example behaviors) and con-
formance checking (identifying mismatches between observed
and modeled behavior). using deÔ¨Ånitions 3 and 4 we can now
formalize these notions at a high abstraction level.
deÔ¨Ånition 5 (process discovery technique): a process
discovery technique disc2b(u)!p (u)is a function that
produces a process model disc(l)2p(u)for any event log
l2b(u).
given an event log l= [ha;ci5;ha;b;ci4;ha;b;b;b;b;ci],
the discovery technique may discover the process model that
always starts with activity a, followed by zero or more b
activities, and always ends with a cactivity: disc(l) =
fha;ci;ha;b;ci;ha;b;b;ci;:::g.an example of a discovery algorithm is the algorithm
[13] that produces a petri net based on the patterns identiÔ¨Åed in
the event log. many discovery techniques have been proposed
in literature [14], [13], [15], [16], [17], [18], [19], [20], [21],
[22], [23], [24] and are supported by open source tools such
as prom and commercial tools such as disco (fluxicon),
perceptive process mining (also known as futura reÔ¨Çect),
aris process performance manager (software ag), qpr
processanalyzer, interstage process discovery (fujitsu), dis-
covery analyst (stereologic), and xmanalyzer (xmpro). it
is impossible to provide an complete overview of all techniques
here. very different approaches can be followed, e.g., using
heuristics [19], [23], inductive logic programming [20], state-
based regions [14], [18], [22], language-based regions [16],
[24], and genetic algorithms [21].
there are four quality dimensions for comparing model
and log: (1) Ô¨Åtness , (2) simplicity , (3) precision , and (4)
generalization [1]. a model with good Ô¨Åtness allows for most
of the behavior seen in the event log. a model has a perfect
Ô¨Åtness if all traces in the log can be replayed by the model
from beginning to end. the simplest model that can explain
the behavior seen in the log is the best model. this principle is
known as occam‚Äôs razor. fitness and simplicity alone are not
sufÔ¨Åcient to judge the quality of a discovered process model.
for example, it is very easy to construct an extremely simple
petri net (‚ÄúÔ¨Çower model‚Äù) that is able to replay all traces in
an event log (but also any other event log referring to the
same set of activities). similarly, it is undesirable to have a
model that only allows for the exact behavior seen in the event
log. remember that the log contains only example behavior
and that many traces that are possible may not have been
observed yet. a model is precise if it does not allow for ‚Äútoo
much‚Äù behavior. clearly, the ‚ÄúÔ¨Çower model‚Äù lacks precision.
a model that is not precise is ‚ÄúunderÔ¨Åtting‚Äù. underÔ¨Åtting
is the problem that the model over-generalizes the example
behavior in the log (i.e., the model allows for behaviors very
different from what was seen in the log). at the same time,
the model should generalize and not restrict behavior to just
the examples seen in the log. a model that does not generalize
is ‚ÄúoverÔ¨Åtting‚Äù. overÔ¨Åtting is the problem that a very speciÔ¨Åc
model is generated whereas it is obvious that the log only
holds example behavior (i.e., the model explains the particular
sample log, but there is a high probability that the model is
unable to explain the next batch of cases).
we often focus on Ô¨Åtness, e.g., event log l=
[ha;b;d;e;gi5;ha;c;d;e;hi4;ha;b;d;e;f;c;d;e;g i]is per-
fectly Ô¨Åtting model mdescribed in figure 2.
deÔ¨Ånition 6 (conformance checking technique): a con-
formance checking technique check2(b(u)p(u))!
dis a function that computes conformance diagnostics
check (l;m )2 d (e.g., Ô¨Åtness or precision metrics) given
an event log l2b(u)and process model m2p(u).dis
the set of all possible diagnoses (e.g., a Ô¨Åtness value between
0 and 1) and depends on the metric chosen.
as indicated, we will often focus on Ô¨Åtness. hence, we
introduce some functions characterizing Ô¨Åtness.
deÔ¨Ånition 7 (conformance checking functions): given
an event log l2b(u)and process model m2p(u), we
deÔ¨Åne the following functions:register 
requestexamine 
casuallyexamine 
thoroughly
check ticketdecidepay 
compensation
reject 
request
reinitiate 
requeststartenda = register request
b = examine thoroughly
c= examine casually
d= check ticket
e = decide
f = reinitiate request
g = pay compensation
h = reject requestfig. 2. a process model m= fha; b; d; e; g i;ha; c; d; e; g i;ha; d; b; e; g i;ha; d; c; e; g i;ha; b; d; e; h i;ha; c; d; e; h i;ha; d; b; e; h i;ha; d; c; e; h i;
ha; b; d; e; f; c; d; e; g i;ha; c; d; e; f; b; d; e; h i; : : :gexpressed in terms of bpmn.
 t(l;m ) = [2lj2m]is the multiset of Ô¨Åtting
traces,
 not (l;m ) = [2lj62m]is the multiset of
non-Ô¨Åtting traces,
 checkpft(l;m ) =jt(l;m )j
jljis the fraction of traces
in the event log perfectly Ô¨Åtting the model,
 checkbpf(l;m ) = ( t(l;m ) =l)is a boolean
function returning true if all traces in the event log
Ô¨Åt.
note that t(l;m )]not (l;m ) =l. clearly,
checkpft(l;m )andcheckbpf(l;m )are conformance check-
ing functions in the spirit of deÔ¨Ånition 6.
simply counting the fraction of Ô¨Åtting cases is often too
simplistic. typically, one is interested in conformance metrics
at the event level. for example, petri-net based conformance
checking approaches [25] may count the number of miss-
ing and remaining tokens during replay. many conformance
checking techniques have been proposed [26], [27], [28], [29],
[30], [31], [20], [32], [33], [25], [34]. the alignment-based
approach described in [26], [27] is much more sophisticated
and provides much better diagnostics than simple metrics such
ascheckpft(l;m ). to illustrate the notion of alignments,
let us consider the non-Ô¨Åtting trace ha;b;c;e;giand process
modelmdepicted in figure 2. an optimal alignment is:
1=abceg
abdeg
thesymbols indicate the problems. the third column shows
a ‚Äúmove on log only‚Äù (c;)indicating that the observed c
event cannot be matched with a move of the model. the fourth
column shows a ‚Äúmove on model only‚Äù (;d)indicating
that the necessary execution of din the model cannot be
matched with an event in the log. all other columns refer to
‚Äúsynchronous moves‚Äù, i.e., model and log agree. alignment 1
has lowest costs assuming equal costs to all non-synchronous
moves, i.e., simply count the number of symbols. a non-
optimal alignment is:
2=abceg
abdefcdeg
alignment2has four non-synchronous moves, i.e., double the
number of non-synchronous moves compared to 1. therefore,
it is not optimal and not considered during analysis.the alignment-based approach is very Ô¨Çexible because it
can deal with arbitrary cost functions and any model represen-
tation. for example, one can associate costs to activities that
are executed too late or by the wrong person. alignments can
also be used for computing precision and generalization [26],
[33]. however, the approach can be rather time consuming.
therefore, the efÔ¨Åciency gains obtained through decomposition
can be considerable for larger processes.
for simplicity we will focus in the remainder on the
fraction of perfectly Ô¨Åtting traces checkpft(l;m ). however,
as illustrated by the results in [7], we can use our decompo-
sition approach also for more sophisticated alignment-based
approaches.
iv. d ecomposing models and logs
as events logs and process models grow in size, process
mining may become a time consuming activity. conformance
checking may become intractable when many different traces
need to be aligned with a model that allows for an exponential
(or even inÔ¨Ånite) number of traces. event logs may contain
millions of events. finding the best alignment may require
solving many optimization problems or repeated state-space
explorations. in worst case, a state-space exploration of the
model is needed per event. when using genetic process mining,
one needs to check the Ô¨Åtness of every individual model in
every generation. as a result, millions of conformance checks
may be required. for each conformance check, the whole event
log needs to be traversed.
for process discovery there are similar problems. now the
model is not given and the challenge is to Ô¨Ånd a model that
scores good with respect to different objectives, e.g., Ô¨Åtness,
simplicity, precision, and generalization. depending on the
representational bias, there may be inÔ¨Ånitely many candidate
models.
given these challenges, we are interested in reducing the
time needed for process mining tasks by decomposing the
associated event log. in this section, we show that it is possible
to decompose any process mining problem by partitioning the
set of activities .
deÔ¨Ånition 8 (activity partitioning): p=fa1;a2;:::;
angis an activity partitioning of a setaifa=s
1inai.
the activity sets may overlap. ~ai=ai\s
j6=iajare all
activities that aishares with other activity sets. ai
i=ain~aiare the internal activities of ai.ai=an(ai
i) =s
j6=iajare
the non-internal activities of ai.
note thatai\ai=~ai. a possible activity par-
titioning for the activities used in figure 2 is p=
ffa;b;c;d;e;fg;fe;f;g;hgg. note that both activity sets in
pshare activities eandf.
given an activity partitioning p, activity set a2p, trace
2u, modelm2p(u), and event log l2b(u), we deÔ¨Åne
the following terms:
ais asubtrace of,
ma2p(u)is asubmodel ofm, and
la2b(u)is asublog ofl.
given an activity partitioning pconsisting of nactivity sets,
we can partition the overall model into nsubmodels and the
overall event log into nsublogs.1
it is easy to see that any trace that Ô¨Åts the overall model
also Ô¨Åts any submodel (use the Ô¨Årst property of lemma 1). the
reverse does not need to hold in case the behavior of one sub-
model may depend on internal behavior of another submodel.
nevertheless, we can compute bounds for conformance and
use this insight for decomposed process discovery.
deÔ¨Ånition 9 (alternative conformance functions): let
m2p(u)be a process model, p=fa1;a2;:::;angan
activity partitioning of am, andl2b(u)an event log. we
deÔ¨Åne variants of the functions in deÔ¨Ånition 7 that only use
submodels and sublogs.
 tp(l;m ) = [2lj81inai2mai],
 checkp
pft(l;m ) =jtp(l;m )j
jlj, and
 checkp
bpf(l;m ) = ( tp(l;m ) =l).
theorem 1 (conformance bounds): letm2 p (u)be
a process model and p=fa1;a2;:::;angan activity
partitioning of am. for any event log l2b(u):
 t(l;m )tp(l;m ),
 checkpft(l;m )checkp
pft(l;m ), and
 checkbpf(l;m ))checkp
bpf(l;m ).
proof: let2t(l;m ), i.e.,2land2m. using
lemma 1 we can deduce that ai2maifor anyi. hence,
2tp(l;m ). this proves that t(l;m )tp(l;m ).
the two other statements follow directly from this.
consider activity partitioning p =fa1;a2g
witha1=fa;b;c;d;e;fg, anda2=fe;f;g;hg
for model min figure 2 and l= [ha;b;d;e;gi5;
ha;c;d;e;hi4;ha;b;d;e;f;c;d;e;g i].ma1=fha;b;d;ei;
ha;c;d;ei;ha;d;b;ei;ha;d;c;ei;ha;b;d;e;f;c;d;ei;
ha;c;d;e;f;b;d;ei;:::gandma2=fhe;gi;he;hi;
he;f;e;gi;he;f;e;hi;:::g.la1= [ha;b;d;ei5;ha;c;d;ei4;
ha;b;d;e;f;c;d;ei]andla2= [he;gi5;he;hi4;
1note that we use the term ‚Äúpartition‚Äù in a loose manner. as indicated
before, activity sets may overlap and hence submodels and sublogs can also
overlap in terms of events/activities.he;f;e;gi].t(l;m ) = tp(l;m ) =l, i.e., all
traces Ô¨Åt into the overall model and all submodels.
hence, checkpft(l;m ) = checkp
pft(l;m ) = 1 , and
checkbpf(l;m ) =checkp
bpf(l;m ) =true.
v. v alid activity partitioning
consider the following four event logs each containing
100 traces: l1= [ha;c;di50;hb;c;ei50],l2= [ha;c;di25;
ha;c;ei25;hb;c;di25;hb;c;ei25],l3= [ha;c;di49;ha;c;ei1;
hb;c;di1;hb;c;ei49], andl4= [ha;c;di25;hd;c;ai25;
hb;c;ei25;he;c;bi25]. also consider the process models m1=
fha;c;di;hb;c;eigandm2=fha;c;di;ha;c;ei;hb;c;di;
hb;c;eig. figure 3 shows both models in terms of a petri net.
m1is the model with placesp1andp2andm2is the model
without these places. note that the petri net is just shown for
illustration purposes. none of the deÔ¨Ånitions or results in this
paper depends on a particular representation (see deÔ¨Ånition 3).
bca
ed p1
p2
fig. 3. two petri nets used to illustrate valid activity partitioning. m1=
fha; c; d i;hb; c; e igis the model with places p1andp2andm2=fha; c; d i;
ha; c; e i;hb; c; d i;hb; c; e igis the model without these places.
given these three event logs and two process models, we
can compute the following fractions of Ô¨Åtting traces:
checkpft(l1;m 1) = 1 checkpft(l1;m 2) = 1
checkpft(l2;m 1) = 0:50 checkpft(l2;m 2) = 1
checkpft(l3;m 1) = 0:98 checkpft(l3;m 2) = 1
checkpft(l4;m 1) = 0:50 checkpft(l4;m 2) = 0:50
consider now the activity partitioning p=fa1;a2gwith
a1=fa;b;cganda2=fc;d;eg. using this partitioning
more events logs will perfectly Ô¨Åt the individual submodels:
checkp
pft(l1;m 1) = 1 checkp
pft(l1;m 2) = 1
checkp
pft(l2;m 1) = 1 checkp
pft(l2;m 2) = 1
checkp
pft(l3;m 1) = 1 checkp
pft(l3;m 2) = 1
checkp
pft(l4;m 1) = 0:50 checkp
pft(l4;m 2) = 0:50
this illustrates that in general checkpft(l;m )
checkp
pft(l;m ), but both values do not need to be the
same, e.g., checkpft(l2;m 1)6=checkp
pft(l2;m 1). in this
case the difference is caused by the dependency between
the two choices in m1which is not ‚Äúcommunicated‚Äù via
the activities in a1\a2=fcg. this example triggers the
question when checkpft(l;m ) = checkp
pft(l;m ), or more
precisely, what properties must activity partitioning phave
such that t(l;m ) =tp(l;m )?
an activity partitioning is valid if the ‚Äúinternal behavior‚Äù
of one set of activities aidoes not depend on the internals ofanother activity set aj. it other words: the activity sets need
to synchronize on non-local phenomena.
deÔ¨Ånition 10 (valid activity partitioning): letm2
p(u)be a process model with activities amand
p =fa1;a2;:::;angan activity partitioning of
the setam.pisvalid form if and only if
m=f2amj81inai2maig.
activity partitioning p=fa1;a2gwitha1=fa;b;cg
anda2=fc;d;egis valid form2but not form1. note that
ha;c;eia1=ha;ci 2m1a1andha;c;eia2=hc;ei 2
m1a2, butha;c;ei62m1.
the following theorem shows that a valid activity partition-
ing allows us to compute conformance per submodel without
loosing precision, i.e., we get exact values rather than bounds.
theorem 2 (conformance checking can be decomposed):
letm2 p (u)be a process model and
p=fa1;a2;:::;anga valid activity partitioning of
am. for any event log l2b(u):
 t(l;m ) =tp(l;m ),
 checkpft(l;m ) =checkp
pft(l;m ), and
 checkbpf(l;m ) =checkp
bpf(l;m ).
proof: t(l;m ) = [2lj2m] = [2lj
2 f02amj 81in0ai2maig] = [2lj
81inai2mai] = tp(l;m ). this proves the Ô¨Årst
statement. the two other statements follow directly from this.
theorem 2 shows that conformance checking can be de-
composed. next we show that also discovery can be decom-
posed. here we only have an event log to start with. however,
while constructing the overall model we can simply assume
independence and thus ensure a valid activity partitioning.
corollary 1 (process discovery can be decomposed):
letl2b(u)be an event log and p=fa1;a2;:::;angan
activity partitioning of al. let disc2 b (u)! p (u)
be a discovery algorithm used to obtain the
submodels mi=disc(lai)withi2 f 1;:::;ng.
m=f2uj 8 1inai2migis the overall
model constructed by merging the discovered submodels.
pis a valid activity partitioning for m,
 t(l;m ) =tp(l;m ),
 checkpft(l;m ) =checkp
pft(l;m ), and
 checkbpf(l;m ) =checkp
bpf(l;m ).
by applying the construction of corollary 1 we can de-
compose process discovery. if all the sublogs Ô¨Åt perfectly, then
the overall event log will also Ô¨Åt the overall model perfectly.
however, if activity sets are not overlapping sufÔ¨Åciently, the
model may be underÔ¨Åtting (too general).
one may try to relax the validity requirement. for example,
by considering one activity set aiand its complete environ-
mentai.
deÔ¨Ånition 11 (weakly valid activity partitioning):
letm2 p (u)be a process model with activitiesamandp=fa1;a2;:::;angan activity partitioning
of the set am.pisweakly valid if and only if
m=f2amj91inai2mai^ai2maig.
clearly, any valid activity partitioning is also weakly
valid. ifai2maiandai2mai, then we can
apply lemma 1 to show that aj2majforj6=i.
the reverse does not hold. consider for example m=
fha;b;d;e;gi;ha;c;d;f;giandp=fa1;a2;a3;a4gwith
a1=fa;b;cg,a2=fb;c;dg,a3=fd;e;fg, and
a4=fe;f;gg.p=fa1;a2;a3;a4gis not a valid activity
partitioning because the traces ha;c;d;e;giandha;b;d;f;gi
are not inm. however,pis weakly valid. this example also
shows that theorem 2 in general does not hold for weakly
valid activity partitionings.
sn
process
model
l
event logdecomposition 
techniqueconformance
checking 
technique
m1
submodel
l1
sublogconformance 
checkm2
submodel
l2
sublogconformance 
checkmn
submodel
ln
sublogconformance 
check
conformance diagnosticsdecompose 
model
decompose 
event loge.g., maximal decomposition, passage-based 
decomposition, or sese/rpst-based decompositione.g., a* based alignments, token-based replay, or 
simple replay until first deviation
yields a (valid) activity partitioning
fig. 4. overview of decomposed conformance checking showing the con-
Ô¨Ågurable elements of the approach: (a) the decomposition technique yielding
the activity partitioning that is used to split the overall model and event log,
and (b) the conformance checking technique used to analyze the individual
models and sublogs.
m
process
modell
event logdecomposition 
techniqueprocess 
discovery
technique
m1
submodell1
sublog
discovery
m2
submodell2
sublog
mn
submodelln
sublog
compose 
modeldecompose 
event log
discovery discoverye.g., causal graph based on frequencies is 
decomposed using passages or sese/rpste.g., language/state-based region discovery, 
variants of alpha algorithm, genetic process mining
yields a (valid) activity partitioning
fig. 5. overview of decomposed process discovery showing the conÔ¨Ågurable
elements of the approach: (a) the decomposition technique yielding the activity
partitioning that is the basis for creating sublogs and (b) the process discovery
technique used to infer submodels from sublogs.
figures 4 and 5 summarize the overall approach proposed
in this paper. moreover, these Ô¨Ågures point out the conÔ¨Ågurable
elements. for conformance checking we need to Ô¨Ånd an
activity partitioning pand a conformance checking techniquecheck2(b(u)p(u))!d (see deÔ¨Ånition 6). for process
discovery we need to Ô¨Ånd an activity partitioning p(based on
only the event log since there is no initial model) and a process
discovery technique disc2b(u)!p(u)(see deÔ¨Ånition 5).
vi. f inding a (v alid ) activity partitioning
theorems 1 and 2 are very general, but stand or fall with
a suitable activity partitioning. consider the following two ex-
treme activity partitionings for an activity set a:pone=fag
(just one activity set containing all activities) and pall=ffagj
a2ag(one activity set per activity). both are not very useful.
ponedoes not decompose the problem, i.e., there is still one
big task.palldecomposes the set of activities into singleton
activity sets. pallconsiders all activities in isolation, hence
conformance checking and discovery are only considering
frequencies of activities and not their order. for conformance
checkingpallis typically not valid and decomposed discovery
usingpallwill most likely result in a severely underÔ¨Åtting
model.
for conformance checking we can exploit the structure
of the process model when searching for a (valid) activity
partitioning. for example, the process model (e.g., a petri
net) can be decomposed using the so-called reÔ¨Åned process
structure tree (rpst) [35], [36] as shown in [10], [9]. the
rpst allows for the construction of a hierarchy of sese
(single-exit-single-entry) components. slicing the sese at
the desired level of granularity corresponds to a decomposition
of the graph [9] that can be used for process mining.
in [7] an algorithm providing the so-called ‚Äúmaximal
decomposition‚Äù of a petri net is given. the construction of
the maximal decomposition is based on partitioning the edges.
each edge will end up in precisely one submodel. edges are
taken together if they are connected through a place, through
an internal transition (invisible action), or through multiple
transitions having the same label. the algorithm iterates until
no edges need to joined. any labeled petri net has a unique
maximal decomposition and this decomposition deÔ¨Ånes a valid
activity partitioning.
the notion of ‚Äúpassages‚Äù deÔ¨Åned in [8], [37] provides an
alternative approach to decompose a petri net. a passage is
a pair of two non-empty sets of activities (x;y )such that
the set of direct successors of xisyand the set of direct
predecessors of yisx. as shown in [8], any petri net can be
partitioned using passages such that all edges sharing a source
vertex or sink vertex are in the same set. this is done to ensure
that splits and joins are not decomposed. note that passages
do not necessarily aim at high cohesion and low coupling.
nevertheless, they deÔ¨Åne a valid activity partitioning.
for discovery we cannot exploit the structure of the model
to ensure the validity or suitability of an activity partitioning.
therefore, often an intermediate step is used [7]. for example,
one can mine for frequent item sets to Ô¨Ånd activities that
often happen together. another, probably better performing,
approach is to Ô¨Årst create a causal graph (a;r)whereais
the set of activities and raais a relation on a. the
interpretation of (a1;a2)2ris that there is a ‚Äúcausal relation‚Äù
betweena1anda2. most process mining algorithms already
build such a graph in a preprocessing step. for example, the 
algorithm [13], the heuristic miner [23], and the fuzzy miner[38] scan the event log to see how many times a1is followed
bya2. if this occurs above a certain threshold, then it is
assumed that (a1;a2)2r. even for large logs it is relatively
easy to construct a causal graph (linear in the size of the event
log). moreover, counting the frequencies used to determine
a causal graph can be distributed easily by partitioning the
cases in the log. also sampling (determining the graph based
on representative examples) may be used to further reduce
computation time.
given a causal graph, one can view decomposition as a
graph partitioning problem [39], [40], [41], [42]. there are
various approaches to partition the graph such that certain
constraints are satisÔ¨Åed while optimizing particular metrics.
for example, in [42] a vertex-cut based graph partitioning
algorithm is proposed ensuring the balance of the resulting
partitions while simultaneously minimizing the number of
vertices that are cut (and thus replicated).
some of the notions in graph partitioning are related to
‚Äúcohesion and coupling‚Äù in software development [43]. cohe-
sion is the degree to which the elements of a module belong
together. coupling is the degree to which each module relies on
the other modules. typically, one aims at ‚Äúhigh cohesion‚Äù and
‚Äúlow coupling‚Äù. in terms of our problem this means that we
would like to have activity sets that consist of closely related
activities whereas the overlap between the different activity
sets is as small as possible while still respecting the causalities.
deÔ¨Ånition 10 also suggests to investigate correlations be-
tween activity sets. an activity set ai2pmay be inÔ¨Çuenced
through ~ai=ai\s
j6=iajbut not through ainai. the goal
is to Ô¨Ånd suitable ‚Äúmilestone activities‚Äù, i.e., shared activities
‚Äúdecoupling‚Äù two activity sets.
the ideas mentioned above have only been explored su-
perÔ¨Åcially, but nicely illustrate that there are many promising
directions for future research.
interestingly, we can merge activity sets without jeopar-
dizing validity. this allows us to decompose process mining
problems at different levels of granularity or to provide a ‚Äútree
view‚Äù on the process and its conformance.
theorem 3 (hierarchy preserves validity): letm2
p(u)be a process model and p=fa1;a2;:::;anga valid
activity partitioning of amwithn2. activity partitioning
p0=fa1[a2;a3:::;angis also valid.
proof: sincepis validm=f2amj81inai2
maig. we need to prove: f2amja1[a22
ma1[a2^ 8 3inai2maig=m.a1[a22
ma1[a2implies that a12ma1anda22ma2(lemma 1). hence, f2amja1[a22ma1[a2^
83inai2maig  f2amj 8 1inai2
maig=m. moreover, for any 2m,a1[a22
ma1[a2^ 8 3inai2maitrivially holds. the
observation that mf2amja1[a22ma1[a2^
83inai2maigmcompletes the proof.
theorem 3 can be applied iteratively. hence, any combina-
tion of activity sets originating from a valid activity partition-
ing yields another valid activity partitioning. this allows us to
coarsen any valid activity partitioning. note that if p=fa1;
a2;:::;angis not valid, then p0=fa1[a2;a3:::;angmay still be valid. therefore, we can try to merge problematic
activity sets in order to get a valid activity partitioning and
better (i.e., more precise) process mining results. for example,
when we are using alignments as described in [26], [27] we
can diagnose the activity sets that disagree. we can also give
preference to alignments that to not disagree on the interface
of different activity sets. last but no least, we can create
a hierarchy of conformance/discovery results, similar to a
dendrogram in hierarchical clustering.
vii. r elated work
for an introduction to process mining we refer to [1]. for
an overview of best practices and challenges, we refer to the
process mining manifesto [44]. also note the availability of
open source tools such as prom and commercial tools such
as disco (fluxicon), perceptive process mining (also known
as futura reÔ¨Çect), aris process performance manager (soft-
ware ag), qpr processanalyzer, interstage process discovery
(fujitsu), discovery analyst (stereologic), and xmanalyzer
(xmpro).
the goal of this paper is to decompose challenging process
discovery and conformance checking problems into smaller
problems [6]. therefore, we Ô¨Årst review some of the techniques
available for process discovery and conformance checking.
process discovery, i.e., discovering a process model from
a multiset of example traces, is a very challenging problem
and various discovery techniques have been proposed [14],
[13], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24].
many of these techniques use petri nets during the discovery
process and/or to represent the discovered model. it is im-
possible to provide an complete overview of all techniques
here. very different approaches are used, e.g., heuristics [19],
[23], inductive logic programming [20], state-based regions
[14], [18], [22], language-based regions [16], [24], and ge-
netic algorithms [21]. classical synthesis techniques based
on regions [45] cannot be applied directly because the event
log contains only example behavior. for state-based regions
one Ô¨Årst needs to create an automaton as described in [14].
moreover, when constructing the regions, one should avoid
overÔ¨Åtting. language-based regions seem good candidates for
discovering transition-bordered petri nets that can serve as
submodels [16], [24]. unfortunately, these techniques still have
problems dealing with infrequent/incomplete behavior.
there are four competing quality criteria when comparing
modeled behavior and recorded behavior: Ô¨Åtness, simplicity,
precision, and generalization [1]. in this paper, we focused
on Ô¨Åtness, but also precision and generalization can also
be investigated per submodel. various conformance checking
techniques have been proposed in recent years [26], [27],
[28], [29], [30], [31], [20], [32], [33], [25], [34]. conformance
checking can be used to evaluate the quality of discovered
processes but can also be used for auditing purposes [46]. most
of the techniques mentioned can be combined with our decom-
position approach. the most challenging part is to aggregate
the metrics per model fragment and sublog into metrics for the
overall model and log. we consider the approach described
in [27] to be most promising as it constructs an optimal
alignment given an arbitrary cost function. this alignment
can be used for computing precision and generalization [26],[33]. however, the approach can be rather time consuming.
therefore, the efÔ¨Åciency gains obtained through decomposition
can be considerable for larger processes with many activities
and possible subnets.
little work has been done on the decomposition and distri-
bution of process mining problems [6], [7]. in [47] mapreduce
is used to scale event correlation as a preprocessing step
for process mining. in [48] an approach is described to
distribute genetic process mining over multiple computers. in
this approach candidate models are distributed and in a similar
fashion also the log can be distributed. however, individual
models are not partitioned over multiple nodes. therefore, the
approach in this paper is complementary. moreover, unlike
[48], the decomposition approach in this paper is not restricted
to genetic process mining.
more related are the divide-and-conquer techniques pre-
sented in [49]. in [49] it is shown that region-based synthesis
can be done at the level of synchronized state machine
components (smcs). also a heuristic is given to partition the
causal dependency graph into overlapping sets of events that
are used to construct sets of smcs. in this paper we provide a
different (more local) partitioning of the problem and, unlike
[49] which focuses speciÔ¨Åcally on state-based region mining,
we decouple the decomposition approach from the actual
conformance checking and process discovery approaches.
also related is the work on conformance checking of
proclets [50]. proclets can be used to deÔ¨Åne so-called artifact
centric processes, i.e., processes that are not monolithic but that
are composed of smaller interacting processes (called proclets).
in [50] it is shown that conformance checking can be done per
proclet by projecting the event log onto a single proclet while
considering interface transitions in the surrounding proclets.
several approaches have been proposed to distribute the
veriÔ¨Åcation of petri net properties, e.g., by partitioning the
state space using a hash function [51] or by modularizing
the state space using localized strongly connected components
[52]. these techniques do not consider event logs and cannot
be applied to process mining.
most data mining techniques can be distributed [53], e.g.,
distributed classiÔ¨Åcation, distributed clustering, and distributed
association rule mining [54]. these techniques often partition
the input data and cannot be used for the discovery of petri
nets.
this paper generalizes the results presented in [7], [8], [9],
[10], [11] to arbitrary decompositions (petri-net based or not).
in [8], [55], [11] it is shown that so-called ‚Äúpassages‚Äù [37] can
be used to decompose both process discovery and conformance
checking problems. in [10], [9] it is shown that so-called sese
(single-exit-single-entry) components obtained through the
reÔ¨Åned process structure tree (rpst) [35], [36] can be used
to decompose conformance checking problems. these papers
use a particular particular decomposition strategy. however,
as shown in [7], there are many ways to decompose process
mining problems.
the results in [7] are general but only apply to petri nets.
this paper further generalizes the divide and conquer approach
beyond petri nets. this allows us to simplify the presentationand clearly show the key requirements for decomposing both
process discovery and conformance checking problems.
viii. c onclusion
in this paper we provided a high-level view on the decom-
position of process mining tasks. both conformance checking
and process discovery problems can be divided into smaller
problems that can be distributed over multiple computers.
moreover, due to the exponential nature of most process
mining techniques, the time needed to solve ‚Äúmany smaller
problems‚Äù is less than the time needed to solve ‚Äúone big
problem‚Äù. therefore, decomposition is useful even if the
smaller tasks are done on a single computer. moreover, decom-
posing process mining problems is not just interesting from a
performance point of view. decompositions can also be used
to pinpoint the most problematic parts of the process (also in
terms of performance) and provide localized diagnostics. this
also helps us to better understand the limitations of existing
conformance checking and process discovery techniques.
in this paper we discussed a very general divide-and-
conquer approach without focusing on a particular representa-
tion or decomposition strategy. nevertheless, it provided new
and interesting insights with respect to the essential require-
ments of more concrete approaches. the paper also provides
pointers to approaches using petri nets as a representational
bias and seses [10], [9], passages [8], [11], or maximal
decompositions [7] as a decomposition strategy. it is clear that
these are merely examples of the broad spectrum of possible
techniques to decompose process mining problems. given the
incredible growth of event data, there is an urgent need to
explore and investigate the entire spectrum in more detail.
acknowledgements
this work was supported by the basic research program of
the national research university higher school of economics
(hse). the author would like to thank eric verbeek, jorge
munoz-gama and joseph carmona for their joint work on de-
composing petri nets for process mining (e.g., using passages
and seses).
references
[1] w. van der aalst, process mining: discovery, conformance and en-
hancement of business processes . springer-verlag, berlin, 2011.
[2] ‚Äî‚Äî, ‚Äúbusiness process management: a comprehensive survey,‚Äù isrn
software engineering , pp. 1‚Äì37, 2013, doi:10.1155/2013/507984.
[3] w. van der aalst and k. van hee, workÔ¨Çow management: models,
methods, and systems . mit press, cambridge, ma, 2004.
[4] d. hand, h. mannila, and p. smyth, principles of data mining . mit
press, cambridge, ma, 2001.
[5] t. mitchell, machine learning . mcgraw-hill, new york, 1997.
[6] w. van der aalst, ‚Äúdistributed process discovery and conformance
checking,‚Äù in international conference on fundamental approaches
to software engineering (fase 2012) , ser. lecture notes in computer
science, j. lara and a. zisman, eds., vol. 7212. springer-verlag,
berlin, 2012, pp. 1‚Äì25.
[7] ‚Äî‚Äî, ‚Äúdecomposing petri nets for process mining: a generic ap-
proach,‚Äù bpm center report bpm-12-20 (accepted for distributed and
parallel databases), bpmcenter.org, 2012.
[8] ‚Äî‚Äî, ‚Äúdecomposing process mining problems using passages,‚Äù in
applications and theory of petri nets 2012 , ser. lecture notes in com-
puter science, s. haddad and l. pomello, eds., vol. 7347. springer-
verlag, berlin, 2012, pp. 72‚Äì91.[9] j. munoz-gama, j. carmona, and w. van der aalst, ‚Äúconformance
checking in the large: partitioning and topology,‚Äù in international
conference on business process management (bpm 2013) , ser. lecture
notes in computer science, f. daniel, j. wang, and b. weber, eds.,
vol. 8094. springer-verlag, berlin, 2013, pp. 130‚Äì145.
[10] ‚Äî‚Äî, ‚Äúhierarchical conformance checking of process models based
on event logs,‚Äù in applications and theory of petri nets 2013 , ser.
lecture notes in computer science, j. colom and j. desel, eds., vol.
7927. springer-verlag, berlin, 2013, pp. 291‚Äì310.
[11] h. verbeek and w. van der aalst, ‚Äúdecomposing replay problems: a
case study,‚Äù bpm center report bpm-13-09, bpmcenter.org, 2013.
[12] omg, ‚Äúbusiness process model and notation (bpmn),‚Äù object man-
agement group, formal/2011-01-03, 2011.
[13] w. van der aalst, a. weijters, and l. maruster, ‚ÄúworkÔ¨Çow mining:
discovering process models from event logs,‚Äù ieee transactions on
knowledge and data engineering , vol. 16, no. 9, pp. 1128‚Äì1142, 2004.
[14] w. van der aalst, v . rubin, h. verbeek, b. van dongen, e. kindler,
and c. g ¬®unther, ‚Äúprocess mining: a two-step approach to balance
between underÔ¨Åtting and overÔ¨Åtting,‚Äù software and systems modeling ,
vol. 9, no. 1, pp. 87‚Äì111, 2010.
[15] r. agrawal, d. gunopulos, and f. leymann, ‚Äúmining process models
from workÔ¨Çow logs,‚Äù in sixth international conference on extending
database technology , ser. lecture notes in computer science, vol.
1377. springer-verlag, berlin, 1998, pp. 469‚Äì483.
[16] r. bergenthum, j. desel, r. lorenz, and s. mauser, ‚Äúprocess mining
based on regions of languages,‚Äù in international conference on
business process management (bpm 2007) , ser. lecture notes in
computer science, g. alonso, p. dadam, and m. rosemann, eds., vol.
4714. springer-verlag, berlin, 2007, pp. 375‚Äì383.
[17] j. carmona and j. cortadella, ‚Äúprocess mining meets abstract in-
terpretation,‚Äù in ecml/pkdd 210 , ser. lecture notes in artiÔ¨Åcial
intelligence, j. balcazar, ed., vol. 6321. springer-verlag, berlin, 2010,
pp. 184‚Äì199.
[18] j. carmona, j. cortadella, and m. kishinevsky, ‚Äúa region-based
algorithm for discovering petri nets from event logs,‚Äù in business
process management (bpm2008) , 2008, pp. 358‚Äì373.
[19] j. cook and a. wolf, ‚Äúdiscovering models of software processes from
event-based data,‚Äù acm transactions on software engineering and
methodology , vol. 7, no. 3, pp. 215‚Äì249, 1998.
[20] s. goedertier, d. martens, j. vanthienen, and b. baesens, ‚Äúrobust
process discovery with artiÔ¨Åcial negative events,‚Äù journal of machine
learning research , vol. 10, pp. 1305‚Äì1340, 2009.
[21] a. medeiros, a. weijters, and w. van der aalst, ‚Äúgenetic process
mining: an experimental evaluation,‚Äù data mining and knowledge
discovery , vol. 14, no. 2, pp. 245‚Äì304, 2007.
[22] m. sole and j. carmona, ‚Äúprocess mining from a basis of regions,‚Äù
inapplications and theory of petri nets 2010 , ser. lecture notes in
computer science, j. lilius and w. penczek, eds., vol. 6128. springer-
verlag, berlin, 2010, pp. 226‚Äì245.
[23] a. weijters and w. van der aalst, ‚Äúrediscovering workÔ¨Çow models
from event-based data using little thumb,‚Äù integrated computer-
aided engineering , vol. 10, no. 2, pp. 151‚Äì162, 2003.
[24] j. van der werf, b. van dongen, c. hurkens, and a. serebrenik,
‚Äúprocess discovery using integer linear programming,‚Äù fundamenta
informaticae , vol. 94, pp. 387‚Äì412, 2010.
[25] a. rozinat and w. van der aalst, ‚Äúconformance checking of processes
based on monitoring real behavior,‚Äù information systems , vol. 33,
no. 1, pp. 64‚Äì95, 2008.
[26] w. van der aalst, a. adriansyah, and b. van dongen, ‚Äúreplaying
history on process models for conformance checking and performance
analysis,‚Äù wires data mining and knowledge discovery , vol. 2, no. 2,
pp. 182‚Äì192, 2012.
[27] a. adriansyah, b. van dongen, and w. van der aalst, ‚Äúconformance
checking using cost-based fitness analysis,‚Äù in ieee international
enterprise computing conference (edoc 2011) , c. chi and p. john-
son, eds. ieee computer society, 2011, pp. 55‚Äì64.
[28] ‚Äî‚Äî, ‚Äútowards robust conformance checking,‚Äù in bpm 2010 work-
shops, proceedings of the sixth workshop on business process intelli-
gence (bpi2010) , ser. lecture notes in business information process-ing, m. muehlen and j. su, eds., vol. 66. springer-verlag, berlin,
2011, pp. 122‚Äì133.
[29] a. adriansyah, n. sidorova, and b. van dongen, ‚Äúcost-based fitness in
conformance checking,‚Äù in international conference on application of
concurrency to system design (acsd 2011) . ieee computer society,
2011, pp. 57‚Äì66.
[30] t. calders, c. guenther, m. pechenizkiy, and a. rozinat, ‚Äúusing
minimum description length for process mining,‚Äù in acm symposium
on applied computing (sac 2009) . acm press, 2009, pp. 1451‚Äì1455.
[31] j. cook and a. wolf, ‚Äúsoftware process validation: quantitatively mea-
suring the correspondence of a process to a model,‚Äù acm transactions
on software engineering and methodology , vol. 8, no. 2, pp. 147‚Äì176,
1999.
[32] j. munoz-gama and j. carmona, ‚Äúa fresh look at precision in process
conformance,‚Äù in business process management (bpm 2010) , ser.
lecture notes in computer science, r. hull, j. mendling, and s. tai,
eds., vol. 6336. springer-verlag, berlin, 2010, pp. 211‚Äì226.
[33] ‚Äî‚Äî, ‚Äúenhancing precision in process conformance: stability, conÔ¨Å-
dence and severity,‚Äù in ieee symposium on computational intelligence
and data mining (cidm 2011) , n. chawla, i. king, and a. sperduti,
eds. paris, france: ieee, april 2011, pp. 184‚Äì191.
[34] j. weerdt, m. de backer, j. vanthienen, and b. baesens, ‚Äúa robust
f-measure for evaluating discovered process models,‚Äù in ieee sym-
posium on computational intelligence and data mining (cidm 2011) ,
n. chawla, i. king, and a. sperduti, eds. paris, france: ieee, april
2011, pp. 148‚Äì155.
[35] a. polyvyanyy, j. vanhatalo, and h. v ¬®olzer, ‚ÄúsimpliÔ¨Åed computation
and generalization of the reÔ¨Åned process structure tree,‚Äù in ws-
fm 2010 , ser. lecture notes in computer science, m. bravetti and
t. bultan, eds., vol. 6551. springer-verlag, berlin, 2011, pp. 25‚Äì41.
[36] j. vanhatalo, h. v ¬®olzer, and j. koehler, ‚Äúthe reÔ¨Åned process structure
tree,‚Äù data and knowledge engineering , vol. 68, no. 9, pp. 793‚Äì818,
2009.
[37] w. van der aalst, ‚Äúpassages in graphs,‚Äù bpm center report bpm-12-
19, bpmcenter.org, 2012.
[38] c. g ¬®unther and w. van der aalst, ‚Äúfuzzy mining: adaptive process
simpliÔ¨Åcation based on multi-perspective metrics,‚Äù in international
conference on business process management (bpm 2007) , ser. lecture
notes in computer science, g. alonso, p. dadam, and m. rosemann,
eds., vol. 4714. springer-verlag, berlin, 2007, pp. 328‚Äì343.
[39] u. feige, m. hajiaghayi, and j. lee, ‚Äúimproved approximation algo-
rithms for minimum-weight vertex separators,‚Äù in proceedings of the
thirty-seventh annual acm symposium on theory of computing . acm,
new york, 2005, pp. 563‚Äì572.
[40] g. karpis and v . kumar, ‚Äúa fast and high quality multilevel scheme
for partitioning irregular graphs,‚Äù siam journal on scientiÔ¨Åc comput-
ing, vol. 20, no. 1, pp. 359‚Äì392, 1998.
[41] b. kernighan and s. lin, ‚Äúan efÔ¨Åcient heuristic procedure for par-
titioning graphs,‚Äù the bell systems technical journal , vol. 49, no. 2,
1970.
[42] m. kim and k. candan, ‚Äúsbv-cut: vertex-cut based graph par-
titioning using structural balance vertices,‚Äù data and knowledge
engineering , vol. 72, pp. 285‚Äì303, 2012.[43] h. dhama, ‚Äúquantitative models of cohesion and coupling in soft-
ware,‚Äù journal of systems and software , vol. 29, no. 1, pp. 65‚Äì74,
1995.
[44] ieee task force on process mining, ‚Äúprocess mining manifesto,‚Äù in
business process management workshops , ser. lecture notes in busi-
ness information processing, f. daniel, k. barkaoui, and s. dustdar,
eds., vol. 99. springer-verlag, berlin, 2012, pp. 169‚Äì194.
[45] p. darondeau, ‚Äúunbounded petri net synthesis,‚Äù in lectures on concur-
rency and petri nets , ser. lecture notes in computer science, j. desel,
w. reisig, and g. rozenberg, eds., vol. 3098. springer-verlag, berlin,
2004, pp. 413‚Äì438.
[46] w. van der aalst, k. van hee, j. van der werf, and m. verdonk,
‚Äúauditing 2.0: using process mining to support tomorrow‚Äôs auditor,‚Äù
ieee computer , vol. 43, no. 3, pp. 90‚Äì93, 2010.
[47] h. reguieg, f. toumani, h. m. nezhad, and b. benatallah, ‚Äúus-
ing mapreduce to scale events correlation discovery for business
processes mining,‚Äù in international conference on business process
management (bpm 2012) , ser. lecture notes in computer science,
a. barros, a. gal, and e. kindler, eds., vol. 7481. springer-verlag,
berlin, 2012, pp. 279‚Äì284.
[48] c. bratosin, n. sidorova, and w. van der aalst, ‚Äúdistributed genetic
process mining,‚Äù in ieee world congress on computational intelli-
gence (wcci 2010) , h. ishibuchi, ed. barcelona, spain: ieee, july
2010, pp. 1951‚Äì1958.
[49] j. carmona, j. cortadella, and m. kishinevsky, ‚Äúdivide-and-conquer
strategies for process mining,‚Äù in business process management (bpm
2009) , ser. lecture notes in computer science, u. dayal, j. eder,
j. koehler, and h. reijers, eds., vol. 5701. springer-verlag, berlin,
2009, pp. 327‚Äì343.
[50] d. fahland, m. de leoni, b. van dongen, and w. van der aalst,
‚Äúconformance checking of interacting processes with overlapping
instances,‚Äù in business process management (bpm 2011) , ser. lecture
notes in computer science, s. rinderle, f. toumani, and k. wolf, eds.,
vol. 6896. springer-verlag, berlin, 2011, pp. 345‚Äì361.
[51] m. boukala and l. petrucci, ‚Äútowards distributed veriÔ¨Åcation of petri
nets properties,‚Äù in proceedings of the international workshop on
veriÔ¨Åcation and evaluation of computer and communication systems
(vecos‚Äô07) . british computer society, 2007, pp. 15‚Äì26.
[52] c. lakos and l. petrucci, ‚Äúmodular analysis of systems composed of
semiautonomous subsystems,‚Äù in application of concurrency to system
design (acsd2004) . ieee computer society, 2004, pp. 185‚Äì194.
[53] m. cannataro, a. congiusta, a. pugliese, d. talia, and p. trunÔ¨Åo,
‚Äúdistributed data mining on grids: services, tools, and applications,‚Äù
ieee transactions on systems, man, and cybernetics, part b , vol. 34,
no. 6, pp. 2451‚Äì2465, 2004.
[54] r. agrawal and j. shafer, ‚Äúparallel mining of association rules,‚Äù ieee
transactions on knowledge and data engineering , vol. 8, no. 6, pp.
962‚Äì969, 1996.
[55] h. verbeek and w. van der aalst, ‚Äúan experimental evaluation of
passage-based process discovery,‚Äù in business process management
workshops, international workshop on business process intelligence
(bpi 2012) , ser. lecture notes in business information processing,
m. rosa and p. soffer, eds., vol. 132. springer-verlag, berlin, 2013,
pp. 205‚Äì210.