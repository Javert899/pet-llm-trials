opera: object-centric performance analysis⋆
gyunam park[0000−0001−9394−6513],
jan niklas adams[0000−0001−8954−4925], and wil. m. p. van der aalst[0000−0002−0955−6940]
process and data science group (pads), rwth aachen university
{gnpark,niklas.adams,wvdaalst }@pads.rwth-aachen.de
abstract. performance analysis in process mining aims to provide insights on
the performance of a business process by using a process model as a formal rep-
resentation of the process. existing techniques for performance analysis assume
that a single case notion exists in a business process (e.g., a patient in healthcare
process). however, in reality, different objects might interact (e.g., order, delivery,
and invoice in an o2c process). in such a setting, traditional techniques may yield
misleading or even incorrect insights on performance metrics such as waiting time.
more importantly, by considering the interaction between objects, we can define
object-centric performance metrics such as synchronization time, pooling time,
and lagging time. in this work, we propose a novel approach to performance anal-
ysis considering multiple case notions by using object-centric petri nets as formal
representations of business processes. the proposed approach correctly computes
existing performance metrics, while supporting the derivation of newly-introduced
object-centric performance metrics. we have implemented the approach as a web
application and conducted a case study based on a real-life loan application process.
keywords: performance analysis ·object-centric process mining ·object-centric
petri net · actionable insights · process improvement
1 introduction
process mining provides techniques to extract insights from event data recorded by infor-
mation systems, including process discovery, conformance checking, and performance
analysis [1]. especially performance analysis provides techniques to analyze the perfor-
mance of a business process using process models as representations of the process [6].
existing techniques for performance analysis have been developed, assuming that
a single case notion exists in business processes, e.g., a patient in a healthcare pro-
cess [5, 6, 8, 11 –14]. such a case notion correlates events of a process instance and repre-
sents them as a single sequence, e.g., a sequence of events of a patient. however, in real-life
business processes supported by erp systems such as sap and oracle, multiple objects
(i.e., multiple sequences of events) exist in a process instance [3, 7] and they share events
(i.e., sequences are overlapping). fig. 1(a) shows a process instance in a simple blood
test process as multiple overlapping sequences. the red sequence represents the event se-
quence of test t1, whereas the blue sequences indicate the event sequences of samples s1
⋆this work is supported by the alexander von humboldt (avh) stiftung.
an extended version is available online: https://arxiv.org/abs/2204.106622 g. park, j. n. adams, and w.m.p. van der aalst
ands2, respectively. the objects share conduct test event ( e4), i.e., all the sequences over-
lap, and the samples share transfer samples event ( e6), i.e., the sample sequences overlap.
fig. 1: a motivating example showing misleading insights from existing approaches to perfor-
mance analysis and the proposed object-centric performance analysis
the goal of object-centric performance analysis is to analyze performance in such
“object-centric” processes with multiple overlapping sequences using 1) existing perfor-
mance measures and 2) new performance measures considering the interaction between
objects. fig. 1(b)(1) visualizes existing performance measures related to event conduct
test.waiting time ofconduct test is the time spent before conducting the test after preparing
testt1and samples s1ands2, while the service time is the time spent for conducting the
test and sojourn time is the sum of waiting time andservice time . furthermore, fig. 1(b)(2)
shows new performance measures considering the interaction between objects. first, syn-
chronization time is the time spent for synchronizing different objects, i.e., samples s1and
s2with test t1to conduct the test. next, pooling time is the time spent for pooling all ob-
jects of an object type, e.g., the pooling time of conduct test w.r.t. sample is the time taken
to pool the second sample. third, lagging time is the time spent due to the lag of an object
type, e.g., the lagging time of conduct test w.r.t. testis the time taken due to the lag of the
second sample. finally, flow time is the sum of sojourn time andsynchronization time .
a natural way to apply existing techniques to multiple overlapping sequences is to
flatten them into a single sequence. to this end, we select an object type(s) as a case notion,
removing events not having the object type and replicating events with multiple objects
of the selected type [3]. for instance, fig. 1(a) is flattened to fig. 1(c) by using test as aopera: object-centric performance analysis 3
case notion, to fig. 1(d) by using sample as a case notion, and fig. 1(e) by using both test
and sample as a case notion.
however,depending on the selection,flattening results in misleading insights. fig. 1(f)
summarizes the correctness of object-centric performance analysis on flattened sequences.
1) flattening on test provides a misleading waiting time, measured as the time difference
between the complete time of prepare test and the start time of conduct test , and, thus, a
misleading sojourn time. 2) flattening on sample results in misleading insights on the ser-
vice time since two service times are measured despite the single occurrence of the event.
3) by flattening on both test and sample, the waiting time for take sample is measured in
relation to prepare test although they are independent events from different object types.
in this work, we suggest a novel approach to object-centric performance analysis.
the approach uses an object-centric event log (ocel) that store multiple overlapping
sequences without flattening (cf. fig. 1(g)) as an input. moreover, we use object-centric
petri nets (ocpns) [3] as a formalism to represent process models, and the object-centric
performance is analyzed in the context of process models. with formal semantics of
ocpns, we can reliably compute and interpret performance analysis results, considering
the concurrency, loops, etc [2].
more in detail, we first discover an ocpn that formally represents a process model
from the ocel. next, we replay the ocel on the discovered ocpn to produce token
visits andevent occurrences . finally, we compute object-centric performance measures
using the token visit and event occurrence. for instance, in the proposed approach, the
waiting time of conduct test is computed as the difference between e4’s start and e1’s
complete. the synchronization time is computed as the time difference between e3’s
complete and e1’s complete.
in summary, we provide the following contributions.
–our approach correctly calculates existing performance measures in an object-centric
setting.
–our approach supports novel object-centric performance metrics taking the interac-
tion between objects into account, such as synchronization time.
–the proposed approach has been implemented as a web application and a case study
with a real-life event log has been conducted to evaluate the effectiveness of the
approach.
2 related work
performance analysis has been widely studied in the context of process mining. table 1
compares existing work and our proposed work in different criteria: 1) if formal semantics
exist to analyze performance in the context of process models, 2) if aggregated measures,
e.g., mean and median, are supported, 3) if frequency analysis is covered, 4) if time anal-
ysis is covered, and 5) if multiple case notions are allowed to consider the interactions of
different objects. existing algorithms/techniques assume a single case notion, not consid-
ering the interaction among different objects.
traditionally, methods in process mining have the assumption that each event is as-
sociated with exactly one case, viewing the event log as a set of isolated event sequences.
a demo video and manuals: https://github.com/gyunamister/opera4 g. park, j. n. adams, and w.m.p. van der aalst
table 1: comparison of algorithms/techniques for performance analysis
author technique form. agg. freq. perf. obj.
mat´e et al. [13] business strategy model -✓ ✓ ✓ -
denisov et al. [8] performance spectrum -✓ ✓ ✓ -
hornix [11] petri nets ✓ ✓ ✓ ✓ -
rogge-solti et al. [14] stochastic petri nets ✓ ✓ -✓ -
leemans et al. [12] directly follows model ✓ ✓ ✓ ✓ -
adriansyah et al. [6] robust performance ✓ ✓ ✓ ✓ -
adriansyah [5] alignments ✓ ✓ ✓ ✓ -
our work object-centric ✓ ✓ ✓ ✓ ✓
object-centric process mining breaks with this assumption, allowing one event to be asso-
ciated with multiple cases and, thus, having shared events between event sequences. an
event log format has been proposed to store object-centric event logs [10], as well as a
discovery technique for ocpns [3] and a conformance checking technique to determine
precision and fitness of the net [4]. furthermore, esser and fahland [9] propose a graph
database as a storage format for object-centric event data, enabling a user to use queries
to calculate different statistics. a study on performance analysis is, so far, missing in the
literature, with only limited metrics being supported in [3] by flattening event logs and
replaying them. however, object-centric performance metrics are needed to accurately
assess performance in processes where multiple case notions occur.
3 background
definition 1 (universes). letueibe the universe of event identifiers, uactthe universe of
activity names, utimethe universe of timestamps, uotthe universe of object types, and uoi
the universe of object identifiers. type∈uoi→uotassigns precisely one type to each object
identifier. uomap={omap∈uot̸→p(uoi)|∀ot∈dom(omap )∀oi∈omap (ot)type(oi)=ot}is the
universe of all object mappings indicating which object identifiers are included per type.
uevent=uei×uact×utime×utime×uomap is the universe of events.
given e=(ei,act,st,ct,omap )∈uevent,πei(e)=ei,πact(e)=act,πst(e)=st,πct(e)=ct,
andπomap(e)=omap , where πst(e)andπct(e)denotes start and complete timestamps.
definition 2 (object-centric event log (ocel)). an object-centric event log is a
tuple l=(e,≺e), where e⊆uevent is a set of events and ≺e⊆e×eis a total order
underlying e. ulis the set of all possible object-centric event logs.
fig. 1(b) describes a fraction of a simple ocel with two types of objects. for the
event in the fourth row, denoted as e4,πei(e4)=e4,πact(e4)=conduct test ,πst(e4)=180,
πct(e4)=240,πomap(e4)(test)={t1}, and πomap(e4)(sample )={s1,s2}. note that the
timestamp in the example is simplified using the relative scale.
definition 3 (object-centric petri net (ocpn)). letn=(p,t,f,l)be a labeled petri
net with pthe set of places, tthe set of transitions, p∩t=/ 0,f⊆(p×t)∪(t×p)the
flow relation, and l∈t̸→uacta labeling function. an object-centric petri net is a tuple
on=(n,pt,fvar),pt∈p→uotmaps places to object types, and fvar⊆fis the subset of
variable arcs.opera: object-centric performance analysis 5
fig. 2(a) depicts an ocpn, on1=(n,pt,fvar)with n=(p,t,f,l)where p={p1,...,p9},
t={t1,...,t6},f={(p1,t1),(p2,t2),...},l(t1)=prepare test , etc., pt(p1)=test,pt(p2)=
sample , etc., and fvar={(p4,t3),(t3,p6),...}.
a token consists of a place and an object, e.g., (p3,t1)denotes a token of object t1
inp3. a marking of an ocpn is a multiset of tokens. for instance, marking m1=[(p3,
t1),(p4,s1),(p4,s2)]denotes three tokens, among which place p3has one token of
object t1andp4has two tokens of objects s1ands2.
a binding describes the execution of a transition consuming objects from its input
places and producing objects for its output places. a binding (t,b)is a tuple of transition
tand function bmapping the object types of the surrounding places to sets of object
identifiers. for instance, (t3,b1)describes the execution of transition t3with b1where
b1(test)={t1}andb1(sample )={s1,s2}, where testandsample are the object types of
its surrounding places (i.e., p3,p4,p5, and p6).
a binding (t,b)isenabled in marking mif all the objects specified by bexist in the
input places of t. for instance, (t3,b1)is enabled in marking m1since t1,s1, and s2exist
in its input places, i.e., p3andp4. a new marking is reached by executing enabled binding
(t,b)atm. for instance, as a result of executing (t1,b1),t1is removed from p3and added
top5. besides, s1ands2are removed from p4and added to p6, resulting in new marking
m′=[(p5,t1),(p6,s1),(p6,s2)].
4 object-centric performance analysis
this section introduces an approach to object-centric performance analysis. in the ap-
proach, we first discover an ocpn based on an ocel. next, we replay the ocel with
timestamps on the discovered ocpn to connect events in the ocel to the elements
of ocpn and compute event occurrences andtoken visits . finally, we measure various
object-centric performance metrics based on the event occurrence and token visit. the
discovery follows the general approach presented in [3]. in the following subsections, we
focus on explaining the rest.
4.1 replaying ocels on ocpns
we couple events in an ocel to an ocpn by “playing the token game” using the formal
semantics of ocpns. as a result, a set of event occurrences are annotated to each visible
transition, and a set of token visits are recorded for each place. first, an event occurrence
represents the occurrence of an event in relation to a transition.
definition 4 (event occurrence). leton=(n,pt,fvar)be an object-centric petri net,
where n=(p,t,f,l). an event occurrence eo∈t×ueventis a tuple of a transition and an
event. o onis the set of possible event occurrences of on.
for instance, (t3,e4)∈oon1indicates that transition t3ofon 1shown in fig. 2(a) is
associated with event e4.
a token visit describes “visit” of a token to the corresponding place with the begin
time of the visit, i.e., the timestamp when the token is produced, and the end time of the
visit, i.e., the timestamp when the token is consumed.6 g. park, j. n. adams, and w.m.p. van der aalst
fig. 2: an example of replaying object-centric event logs on an object-centric petri net
definition 5 (token visit). leton=(n,pt,fvar)be an object-centric petri net, where
n=(p,t,f,l).qon={(p,oi)∈p×uoi|type(oi)=pt(p)}is the set of possible tokens. a
token visit tv∈qon×utime×utimeis a tuple of a token, a begin time, and an end time.
vonis the set of possible token visits of on.
given token visit tv=((p,oi),bt,et),πp(tv)=p,πoi(tv)=oi,πbt(tv)=bt,andπet(tv)=et.
for instance, ((p3,t1),15,180)∈von1represents that token (p3,t1)∈qon1is produced
in place p3at 15 and consumed at 180.
given an ocel, a replay function produces event occurrences and token visits of an
ocpn, connecting events in the log to the model.
definition 6 (replay). letonbe an object-centric petri net. a replay function replayon∈
ul→p(oon)×p(von)maps an event log to a set of event occurrences and a set of
token visits.
fig. 2(b) shows the result of replaying the events in l1shown in fig. 2(a) on model
on 1depicted in fig. 2(a). the dark gray boxes represent event occurrences o1and the
light gray boxes represent token visits v1, where replayon1(l1)=(o1,v1). for instance,
replaying event e1ande4inl1produces event occurrences, (t1,e1)and(t3,e4), respec-
tively, and token visit ((p3,t1),15,180)where 15is the time when e1completes and 180
is the time when e4starts.
4.2 measuring object-centric performance measures
we compute object-centric performance measures per event occurrence. for instance, we
compute synchronization ,pooling ,lagging , and waiting time of (t3,e4)that analyzes anopera: object-centric performance analysis 7
event of conduct test . to this end, we first relate an event occurrence to the token visits
1) associated with the event occurrence’s transition and 2) involving the objects linked to
the event occurrence’s event.
definition 7 (relating an event occurrence to token visits). letlbe an object-
centric event log and onan object-centric petri net. let eo=(t,e)∈obe an event
occurrence. oi(eo)=s
ot∈dom(πomap(e))πomap(e)(ot)denotes the set of objects related
to the event occurrence. relon∈oon×p(von)→p(von)is a function mapping
an event occurrence and a set of token visits to the set of the token visits related to
the event occurrence, s.t., for any eo∈oonandv⊆von,relon(eo,v)=s
oi∈oi(eo)
argmaxtv∈{tv′∈v|πp(tv′)∈•t∧πoi(tv′)=oi}πbt(tv).
fig. 3(a) shows the token visits related to eo1=(t3,e4).relon1(eo1,v1)={tv1=((p3
,t1),15,180),tv2=((p4,s1),120,180),tv3=((p4,s2),150,180)}since p3,p4∈ •t3,
{t1,s1,s2}⊆oi(eo1), and each token visit is with the latest begin time among other token
visits of the corresponding object, e.g., tv1is the only (and thus the latest) token visit of t1.
fig. 3: an example of the token visits related to an event occurrence and object-centric performance
measures of the event occurrence.
a measurement function computes a performance measure of an event occurrence by
using the related token visits.
definition 8 (measurement). letonbe an object-centric petri net. measure ∈oon×
p(von)→ris a function mapping an event occurrence and its related token visits to a
performance value. umdenotes the set of all such functions.
in this paper, we introduce seven functions to compute object-centric performance
measures as shown in fig. 3(c). with lan ocel, onan ocpn, and (o,v)=replayon(l),
we introduce the functions with formal definitions and examples as below:8 g. park, j. n. adams, and w.m.p. van der aalst
–flow∈umcomputes flow time . formally, for any eo=(t,e)∈o,flow(eo,v)=πct(e)−
min(t)with t={πbt(tv)|tv∈relon(eo,v)}.
–sojourn ∈umcomputes sojourn time . formally, for any eo=(t,e)∈o,sojourn (eo,
v)=πct(e)−max(t)with t={πbt(tv)|tv∈relon(eo,v)}.
–wait∈umcomputes waiting time . formally, for any eo=(t,e)∈o,wait(eo,v)=πst
(e)−max(t)with t={πbt(tv)|tv∈relon(eo,v)}.
–service ∈umcomputes service time . formally, for any eo=(t,e)∈o,service (eo,v)
=πct(e)−πst(e).
–sync∈umcomputes synchronization time . formally,forany eo=(t,e)∈o,sync(eo,v)
=max(t)−min(t)with t={πbt(tv)|tv∈relon(eo,v)}.
–poolot∈umcomputes pooling time w.r.t. object type ot. formally, for any eo=(t,e)∈
o,poolot(eo,v)=max(t)−min(t)with t={πbt(tv)|tv∈relon(eo,v)∧type(πoi
(tv))=ot}.
–lagot∈umcomputes lagging time w.r.t. object type ot. formally, for any eo=(t,e)∈o,
lagot(eo,v)=max(t′)−min(t)with t={πbt(tv)|tv∈relon(eo,v)}andt′={πbt
(tv)|tv∈relon(eo,v)∧type(πoi(tv))̸=ot}ifmax(t′)>min(t). 0 otherwise.
5 case study
the approach discussed in sec. 4 has been fully implemented as a web application with a
dedicated user interface. using the implementation, we conduct a case study on a real-life
loan application process of a dutch financial institute. two object types exist in the pro-
cess: application andoffer. an application can have one or more offers. first, a customer
creates an application by visiting the bank or using an online system. in the former case,
submit activity is skipped. after the completion and acceptance of the application, the
bank offers loans to the customer by sending the offer to the customer and making a call.
an offer is either accepted or canceled.
in this case study, we focus on the offers canceled due to various reasons. we fil-
ter infrequent behaviors by selecting the ten most frequent types of process executions.
moreover, we remove redundant activities, e.g., status updates such as completed after
complete application . the resulting event log, available at github repository, contains
20,478 events by 1 ,682 applications and 3 ,573 offers.
first, we compare our approach to a traditional technique for performance analysis
based on alignments [5]. to apply the traditional technique, we first flatten the log using
the application and offer as a case notion. fig. 4(a) shows the performance analysis results
from inductive visual miner inprom framework. as shown in 1⃝,1,799applications
repeat activity send . in reality, as shown in 1, no repetition occurs while the activity
is conducted once for each offer except 92offers skipping it. furthermore, the average
sojourn time for the activity is computed as around 2days and 23hours, whereas, in reality,
it is around 15 minutes as shown in 1.
furthermore, 2⃝shows that activity cancel application is repeated 1891 times, but
it occurs, in reality, 1,682times for each application, as depicted in 2. in addition, the
average sojourn time for the activity is measured as around 12days and 22hours, but in
fact, it is around 31 days and 22 hours, as shown in 2.
doi.org/10.4121/uuid:3926db30-f712-4394-aebc-75976070e91fopera: object-centric performance analysis 9
fig. 4: (a) performance analysis results based on inductive visual miner inprom framework and
(b) performance analysis results based on our proposed approach.
next, we analyze the newly-introduced object-centric performance measures, includ-
ing synchronization, lagging, and pooling time. as described in 3, the average synchro-
nization time of activity cancel application is around 4days and 11hours. moreover, the
average lagging time of applications is3days and 15hours and the lagging time of offers
is19hours, i.e., offers are more severely lagging applications . furthermore, the pooling
time of offers is almost the same as the synchronization time, indicating that the applica-
tion is ready to be cancelled almost at the same time as the first offer, and the second offer
is ready in around 4 days and 11 hours.10 g. park, j. n. adams, and w.m.p. van der aalst
6 conclusion
in this paper, we proposed an approach to object-centric performance analysis. to that
end, we first replay ocels on ocpns to couple events to process models, producing
event occurrences and token visits. next, we measure object-centric performance metrics
per event occurrence by using the corresponding token visits of the event occurrence. we
have implemented the approach as a web application and conducted a case study using a
real-life loan application process.
the proposed approach has several limitations. first, our approach relies on the qual-
ity of the discovered process model. discovering process models that can be easily in-
terpreted and comprehensively reflect the reality is a remaining challenge. second, non-
conforming behavior in event data w.r.t. a process model can lead to misleading insights.
as future work, we plan to extend the approach to support reliable performance analysis of
non-conforming event logs. moreover, we plan to develop an approach to object-centric
performance analysis based on event data independently from process models.
references
1. van der aalst, w.m.p.: process mining, second edition. springer (2016)
2.van der aalst, w.m.p., adriansyah, a., van dongen, b.f.: replaying history on process models
for conformance checking and performance analysis. wires data mining knowl. discov.
2(2), 182–192 (2012)
3.van der aalst, w.m.p., berti, a.: discovering object-centric petri nets. fundam. informaticae
175(1-4), 1–40 (2020)
4.adams, j.n., van der aalst, w.m.p.: precision and fitness in object-centric process mining. in:
icpm 2021. pp. 128–135 (2021)
5.adriansyah, a.: aligning observed and modeled behavior. ph.d. thesis, mathematics and
computer science (2014)
6.adriansyah, a., dongen, van, b., piessens, d., wynn, m., adams, m.: robust performance
analysis on yawl process models with advanced constructs. journal of information
technology theory and application 12(3), 5–26 (2011)
7.bayomie, d., ciccio, c.d., rosa, m.l., mendling, j.: a probabilistic approach to event-case
correlation for process mining. in: er 2019. pp. 136–152 (2019)
8.denisov, v ., fahland, d., van der aalst, w.m.p.: unbiased, fine-grained description of
processes performance from event data. in: bpm 2018, pp. 139–157 (2018)
9.esser, s., fahland, d.: multi-dimensional event data in graph databases. j. data semant.
10(1-2), 109–141 (2021)
10.ghahfarokhi, a.f., park, g., berti, a., van der aalst, w.m.p.: ocel. in: bellatreche, l., et.
al. (eds.) simpda 2021. pp. 169–175 (2021)
11.hornix, p.t.: performance analysis of business processes through process mining. master’s
thesis, mathematics and computer science (2007)
12.leemans, s.j.j., poppe, e., wynn, m.t.: directly follows-based process mining: exploration
& a case study. in: icpm 2019. pp. 25–32 (2019)
13.mat´e, a., trujillo, j., mylopoulos, j.: conceptualizing and specifying key performance
indicators in business strategy models. in: er 2012. pp. 282–291 (2012)
14.rogge-solti, a., weske, m.: prediction of remaining service execution time using stochastic
petri nets with arbitrary firing delays. in: icsoc. pp. 389–403 (2013)