detecting surprising situations in event data
christian kohlschmidt, mahnaz sadat qafari, and wil m. p. van der aalst
process and data science chair (pads)
rwth aachen university aachen, germany
christian.kohlschmidt@rwth-aachen.de,
{m.s.qafari,wvdaalst}@pads.rwth-aachen.de
abstract. process mining is a set of techniques that are used by or-
ganizations to understand and improve their operational processes. the
ﬁrst essential step in designing any process reengineering procedure is to
ﬁnd process improvement opportunities. in existing work, it is usually
assumed that the set of problematic process instances in which an un-
desirable outcome occurs is known prior or is easily detectable. so the
process enhancement procedure involves ﬁnding the root causes and the
treatments for the problem in those process instances. for example, the
set of problematic instances is considered as those with outlier values
or with values smaller/bigger than a given threshold in one of the pro-
cess features. however, on various occasions, using this approach, many
process enhancement opportunities, not captured by these problematic
process instances, are missed. to overcome this issue, we formulate ﬁnd-
ingtheprocessenhancementareasasacontext-sensitiveanomaly/outlier
detection problem. we deﬁne a process enhancement area as a set of sit-
uations (process instances or preﬁxes of process instances) where the
process performance is surprising. we aim to characterize those situa-
tions where process performance/outcome is signiﬁcantly diﬀerent from
what was expected considering its performance/outcome in similar situ-
ations. to evaluate the validity and relevance of the proposed approach,
we have implemented and evaluated it on several real-life event logs.
keywords: process mining ·process enhancement ·context-sensitive
outlier detection ·surprising instances.
1 introduction
considering the current highly competitive nature of the economy, it is vital for
organizations to continuously improve/enhance their processes in order to meet
the best market standards and improve customer experience. process enhance-
ment involves many steps, including ﬁnding the process areas where improve-
ments are possible, designing the process reengineering steps, and estimating the
impact of changing each factor on the process performance. by conducting all
these steps, organizations can beneﬁt from applying process mining techniques.
the ﬁrst step of process enhancement is detecting those process areas where an
improvement is possible. process mining includes several techniques for processarxiv:2208.13515v1  [cs.ai]  29 aug 20222 c. kohlschmidt et al.
monitoring and ﬁnding their friction points. however, these techniques have the
hidden assumption that all the process instances (cases) are the same. so the
set of problematic cases can be easily identiﬁed. for example, the problematic
cases can be identiﬁed as the ones with an outlier value with respect to a pro-
cess feature. another common method is using a threshold for a speciﬁc process
feature. however, considering the variety of the cases, it is possible that a so-
lution solves the problem for one group of cases while aggravating the problem
for another group. moreover, using the current techniques, the performance of
the process in some cases can be considered normal/acceptable compared to the
overall behavior of the process, while it can be considered surprising (anoma-
lous/undesirable) when just considering their similar cases. this phenomenon
can lead to overlooking some of the process enhancement opportunities.
as another issue, there are several process instances where the process per-
forms signiﬁcantly better than other similar process instances. analyzing the
process behavior while performing these process instances can lead to invalu-
able clues on how to improve the process. usually, this source of information is
neglected by the current process mining techniques.
to overcome these issues, we formulate ﬁnding those areas where a process
enhancement is possible, as the problem of ﬁnding those groups of process situ-
ations where the process performance is signiﬁcantly diﬀerent from their similar
situations. here, we deﬁne a process situation (or simply a situation ) as a process
instance, or a preﬁx of it. the proposed method includes four steps, (1) enriching
and extracting the data from the event log, (2) ﬁnding a set of sets of similar
situations (which we call a vicinity cover and each set of similar situations is
avicinity). naturally, a measure is needed to measure the similarity between
instances and identify vicinities. however, having access to such a measure is a
strong assumption. thus we use a machine learning technique to determine the
vicinities in the absence of such a measure. (3) the next step involves ﬁnding
the set of surprising situations in each vicinity (if any exist). (4) finally, a list
of detected sets of surprising situations is presented to the user ordered by their
eﬀect on the process and how surprising they are. these ﬁndings can be fur-
ther analyzed to understand the reason for the diﬀerent behavior of the process
in these surprising situations and gain insights on how to improve the process.
figure 1 shows the general overview of the proposed method.
for example, consider that in a loan application process with 20 cases, we
are interested in ﬁnding those cases where their throughput is surprising. in this
example, each process instance (case) is a situation. also, we consider two sit-
uations similar if the levenshtein distance of their activity sequence is at most
one. figure 2 shows the graph for the cases of this loan application, where each
fig.1: the general overview of the proposed method.detecting surprising situations in event data 3
fig.2: a graph representing the similarity of situations in a loan application ex-
ample. each node represents a situation (a process instance). two situations are
similar if the levenshtein distance of their activity sequences is at most one. the
vicinity of a node is the set of process instances in the same community. three
vicinities have been detected in this example, which are colored red, blue, and
green. surprising situations are highlighted with a darker color. the throughput
of each situation is proportional to the size of its corresponding node.
case corresponds to a node. two cases are connected if they are similar. the size
of each node is proportional to its throughput. the colors (blue, green, and red)
indicate the vicinities found by the louvain community detection algorithm. the
nodes highlighted with darker colors are the surprising cases where the through-
put time is signiﬁcantly diﬀerent from the other cases in the same vicinity. in this
example, the throughput was worse than expected for cases 5 and 16 and better
than expected for cases 4 and 10. the process owner can gain actionable insights
by analyzing the behavior of the process in these cases, particularly in compar-
ison with their vicinity, to improve/enhance the performance of the process in
other similar cases in the future. note, if we just had considered the overall
performance of this process, these four cases would not have been detected.
the rest of the paper is organized as follows. in section 2, a brief overview
of the related work is given. in section 3, the proposed method is presented.
the experimental results are discussed in section 4. finally, in section 5, the
conclusion is presented.
2 related work
existingresearchoncontext-awareanomalydetectioninprocessminingisclosest
to our work. here we provide an overview of anomaly detection techniques.
mostexistingmethodsinvestigateanomaliesconsideringthecontrol-ﬂowper-
spective (e.g., [1,2,7,9,10,16]). these methods generate a reference model from
the event log and apply conformance checking to detect anomalous behavior. a
subgroupofthesemethodsknownas deviance mining approaches investigateper-
formance anomalies. [9]. in [16], the authors identify deviations and bottlenecks4 c. kohlschmidt et al.
by replaying the event log on an enrich process model with performance infor-
mation. in [7], the authors analyze the deviations between a process model and
an event log to identify which deviations enforce positive performance. in [8], the
anomalous traces in event logs are detected using window-based and markovian-
based techniques. the drawback of control-ﬂow approaches is that they ignore
a wide range of non-control-ﬂow data, which can be used for more sophisticated
context-sensitive anomaly detection methods.
the authors of [4] propose an anomaly detection approach that incorporates
perspectives beyond the control-ﬂow perspective, such as time and resource-
related information. this approach marks events as anomalies based on a certain
likelihood of occurrence, however, case anomalies are not considered.
other approaches in this category only focus on speciﬁc use cases. the au-
thors of [13] analyze suspicious payment transactions to identify money laun-
dering within a money transfer service. they propose an approach to match
the transactions with the expected behavior given by a process model to iden-
tify many small transactions that end up on the same account. [14] identiﬁes
surprisingly short activity execution times in a process by automatically infer-
ring a bayesian model from the petri net representation of the process model.
the authors of [15] use fuzzy association rule learning to detect anomalies. as
these approaches specialize in speciﬁc use cases, they do not apply to identify
anomalies in a general process.
a third category is domain-based anomaly detection. for example, the au-
thors of [11] propose an approach that supports the identiﬁcation of unusual
or unexpected transactions by encoding the cases and assigning an anomaly
score to each case. they use the domain knowledge of domain experts to update
the assigned anomaly scores. the approaches in this category require domain
knowledge to label cases, which limits their applicability.
3 method
process mining techniques usually start by analyzing an event log. an event log
is a collection of cases where each case is a sequence of events, in which each
event refers to a case, an activity, and a point in time. more formally,
deﬁnition 1 (event, case, event log). letcbe the universe of case identi-
ﬁers,abe the universe of activities, tbe the universe of timestamps. moreover,
letd=fd1;:::;dngbe the universe of domain-dependent data attributes. we
deﬁne the universe of events as e=catd 1dnand each element
e= (c;a;t;d 1;:::;dn)2eanevent. lete+be the universe of (non-empty)
ﬁnite and chronologically ordered sequences of events. we deﬁne a caseas a se-
quence of events 2e+in which all events have the same case identiﬁer; i.e.
8ei;ej2c(ei) =c(ej)wherec(e)returns the case identiﬁer of event e2e.
we deﬁne an event log ,l, as a set of cases in which each case has a unique
case identiﬁer; i.e., 8;02l(9e29e02c(e) =c(e0)) =)=0. we
denote the universe of all event logs with l.detecting surprising situations in event data 5
we assume that we know the process feature that captures the property of
the process that the process owner is interested in its optimization. we call this
featuretarget feature and denote it with tfwhere tf2tf =ad. note that
thetargetiscomposedofanattributenameandanactivityname,whichindicate
the attribute value should be extracted from the events with that activity name.
the attribute name can be any of the attributes captured by the event log or a
derived one. moreover, we assume that we know descriptive features , which are
the set of process features that are relevant in measuring the similarity of the
situations. in the following, we explain the surprising situation detection steps.
3.1 situation feature table extraction
to ﬁnd the surprising situations, we have to extract the data in the form of
tabular data from the event log. as the detected surprising situations are meant
to be used for root cause analysis, to respect the temporal precedence of cause
and eﬀect, indicating that the cause must occur before the eﬀect, we extract
the data from that preﬁx of the case that has been recorded before the target
feature. we call such a preﬁx of a case a situation . more formally:
deﬁnition 2 (situation). letl2l,=he1;:::;eni2l, and
prfx(he1;:::;eni) =fhe1;:::;eiij1ing, a function that returns the set of
non-empty preﬁxes of a given case. we deﬁne the universe of all situations as
s=s
l2lslwheresl=fj2prfx(0)^02lgis the set of situations
of event log l. we call each element 2sasituation . moreover, we deﬁne
sit2(ltf )2sto be the a function that returns f2slja() =actgfor
a givenl2land tf= (att;act)2tf, wherea()returns the activity name
of the last event of .
we call the data table created by extracting data from situations a situation
feature table . please note that each row of the situation feature extracted from
sit(l;tf)corresponds to a situation in it and this correspondence forms a bijec-
tion. to enrich the event log and extract the situation feature table, we use the
method presented in [12].
3.2 vicinity detection
informally, a vicinity is a set of similar situations and a vicinity cover of ss
is a set of vicinities of its situations such that their union covers s. let cov2
2s!22sin which8ss8s02cov(s) 
s06=;^(8;02s0sim(;0) = 1)
and8ss[s02cov(s)s0=s. here, sim2ss !f 0;1gis an indicator
function indicating if and0are similar, for ;02s.
using a coverage function, we deﬁne a vicinity cover of a set of situations
extracted from an event log with respect to a speciﬁc target feature as follows:
deﬁnition 3 (vicinity and vicinity cover). lets=sit(l;tf)be the set
of situations extracted from l2lwith respect to the target feature tf2tfand
cov22s!22sbe a coverage function. we simply deﬁne a vicinity cover ofs6 c. kohlschmidt et al.
ascov(s)and we call each member of v2cov(s)avicinityofs. we denote
the universe of all vicinities by v.
in the sequel, we explain the vicinity detection method separately for the
case where we know the similarity measure and the case where such a similarity
measure is not known.
vicinity detection with a similarity measure. letd2ss! rbe
a distance measure. then we can say a situation is similar to another situation
if their distance is less than . now, we can deﬁne the similarity function as
simd;2ss!f 0;1gsuch that simd;(1;1)returns 1 if d(;0)and 0
o.w. for all ;02s. in this case, we can determine the vicinity cover of the set
of situations through the coverage function (deﬁnition 3) in which simd;(:;:)
is the similarity function. another method is to create a graph g= (s;e)in
which each node corresponds to one of the situations extracted from the event
log. there is an edge between two nodes if the distance of their corresponding
situations is smaller than . using a community detection algorithm on this
graph, we can determine the vicinities. note that in this case two situations
are similar if their corresponding nodes are in the same community and each
detectedcommunityisavicinity.acommunitydetectionfunctionaimsatﬁnding
(potentially overlapping) sets of nodes that optimize the modularity within the
similarity graph. modularity measures the relative density of edges inside the
communities compared to edges outside the communities.
vicinity detection without a similarity measure. the availability of a
distance function is a strong assumption. considering the complexity of the real-
life event data, even for specialists, it is a challenging task to determine such a
distancefunction.hence,weusemachinelearningtechniquestodetectsurprising
situations in the data. in this case, the process expert needs to know the set of
processfeaturesrelevanttomeasuringthesimilarityofthesituationsandnotthe
exact distance measure. here we brieﬂy mention the vicinity detection method
using a clustering and classiﬁcation model.
surprising situation detection using a clustering model we usek-means as the
clustering model to explain the method; however, the general idea is similar to
using other clustering models. to ﬁnd the surprising situations using a clustering
model, we ﬁrst cluster the situations using k-means, with a predeﬁned k, based
on their descriptive features. in this method, two situations are similar if they
belong to the same cluster and each cluster forms a vicinity.
surprising situation detection using a classiﬁcation model we mainly use a
decision tree as the classiﬁcation model. we train a decision tree on the data
trying to predict the target feature tfusing descriptive features. in this method,
we consider two situations similar if they belong to the same node of the tree.
moreover, we consider the set of situations corresponding to each node of thedetecting surprising situations in event data 7
decision tree (or each node in a subset of nodes of the decision tree, such as
leaves) as a vicinity.
3.3 surprising situation detection
we deﬁne the surprising situations in each vicinity as those situations in that
vicinity that signiﬁcantly diﬀer from the other situations (in that vicinity). sup-
pose thatd2v!s
v2v2vwhere8v2v:d(v)vis a function that, given
a set of similar situations (a vicinity), returns its subset of surprising ones. we
call such a function a detector. for example, a detector function can be a func-
tion that returns the subset of situations that exceed a user-deﬁned threshold
value for the target feature. using this function, we deﬁne the set of surprising
situations of a vicinity as follows:
deﬁnition 4 (surprising situation set). letv2vbe a vicinity and d2
v !s
v2v2vwhere8v2v :d(v)vbe a detector function. we deﬁne
d(v)as the set of surprising situations inv.
we can ﬁnd the set of all sets of surprising situations of the set of situations by
applying the detector function on all the vicinities of its vicinity cover.
deﬁnition 5 (surprising situation sets). lets=sit(l;tf)be the set of
situations extracted from l2lwith respect to target feature tf2tf,cov(s)
a vicinity cover of s, and detection function d2v!s
v2v2v. we deﬁne the
surprising situation sets ofsasfd(v)jv2cov(s)g.
3.4 ordering surprising situations
we deﬁne two criteria to order the detected surprising situations: surprisingness
andeﬀectiveness . supposeuis the set of surprising situations in a vicinity v.
surprisingness of umeasures how rare it is to see such a situation in its vicinity,
whereas eﬀectiveness measures how beneﬁcial it is to enhance the process based
on the ﬁndings of root cause analysis of u. more precisely:
deﬁnition 6. letv2vbe a vicinity and uvthe set of surprising situations
inv, and2(0;1]a threshold. we deﬁne the surprisingness ofuas:
surp(u) =javg(u) avg(vnu)j+(1 )(u)
(v)
and theeﬀectiveness ofuas:
e(u) =(
(avg(vnu) avg(u))(vnu)avg(u)<avg(vnu)
(avg(u) avg(vnu))(u) avg(u)>avg(vnu)
where (a)denotes the cardinality of aandavg(a) =p
s2atf(s)
(a)for eachas
is the average value of the target feature tffor the situations in a.
intheabovedeﬁnition,weassumethatthelowervaluesfor tfaremoredesirable.
if this assumption does not hold, the eﬀectiveness can be similarly deﬁned.8 c. kohlschmidt et al.
(a) distribution of the throughput time
for the bpi challenge 2017 event log cap-
turing the duration from the start to the
end of each case.
(b) detected outliers of throughput time
of cases of bpi challenge 2017 event log
using boxplot. cases durations above 61
days are considered anomalous.
fig.3: the throughput time for the bpi challenge 2017 event log.
4 experimental results
to evaluate the proposed framework1, we present the result of applying it on the
event log for bpi challenge 2017 [5]. this event log represents an application
process for a personal loan or overdraft within a global ﬁnancing organization
taken from a dutch ﬁnancial institute. we consider throughput as the target
feature. the majority of the cases in the process take between 5 and 40 days.
the average duration for all cases in the event log is around 22 days. figure 3a
shows the distribution of the throughput time.
boxplots are frequently used to identify performance anomalies [6]. thus we
use boxplots as the baseline and call this approach the baseline. the resulting
boxplot is shown in figure 3b. using this method, 255 cases with a throughput
of more than 61 days have been considered anomalous. these are the detected
anomalies without any context-awareness of the process. we also used boxplots
to detect surprising situations in a vicinity cover composed of a set of 25 non-
overlapping randomly selected vicinities. however, we do not present the results
of this method as the detected anomalies were almost identical to the ones de-
tected by the baseline method.
to apply our approach, we used the following case-level attributes as descrip-
tive features: application type ,loan goal ,applicant’s requested loan amount , and
thenumber of oﬀers which is a derivative attribute indicating how many times
the loan application institute oﬀered a loan to the customer. note that in this
experiment, each case is a situation.
we apply surprising situation detection using a similarity measure, a clas-
siﬁcation method (using a decision tree), and also a clustering method (using
1the implemented tool is available at https://github.com/ckohlschm/
detecting-surprising-instances .detecting surprising situations in event data 9
fig.4: detected surprising situations in each vicinity deﬁned by the decision tree
method.
k-means clustering). we call these three approaches similarity based method ,
decision tree method , andk-means clustering method respectively. in all these
methods, to maximize the applicability of the implemented tool and to minimize
therequireddomainknowledge,weusetheboxplotasthedetectorfunction(def-
inition 4) to ﬁnd the surprising situations in each vicinity.
decision tree method. for this experiment, we trained a decision (regression)
tree with a maximum depth of 5 and a minimum number of instances per leaf of
100. for simplicity, we consider the vicinities described by the leaves of the tree.
figure 4 shows the detected surprising situations for the leaves in the decision
tree where each leaf is labeled with a number.
some of the highlights of the comparison of the results of the decision tree
method and the baseline-1 are as follows:
fig.5: surprisingness and eﬀectiveness for the surprising situations identiﬁed by
the decision tree method.10 c. kohlschmidt et al.
–application_1839367200 (case duration 62 days) is barely considered an
outlier in the total dataset, but in its vicinity (vicinity 4: one oﬀer, limit
raise, loan goal car, requested amount > 11.150) it is far from the average
which is 14 days.
–vicinity 19, where the number of oﬀers is more than 3 and the requested
amount13.162 includes seven surprising situations. these situations have
notbeenconsideredoutliersbythebaseline-1method.onepossibleinterpre-
tation of this result is that high throughput is acceptable in such situations.
the same applies to vicinity 20.
–vicinity 5 (one oﬀer, limit raise, unknown loan goal, requested amount 
3000) contains 3 surprising situations that are all overlooked by the baseline-
1 method. the vicinity contains 338 cases with an average throughput time
of13dayswhichmakescaseswithadurationofmorethan40dayssurprising.
the same applies to vicinities 3 and 6.
figure 5 shows the surprisingness (on the left) and eﬀectiveness (on the right)
of the sets of surprising situations detected by the decision tree method. the set
of surprising situations in vicinity 8 has the highest surprisingness. this vicinity
includes 6136 situations, where 13 are surprising with an average throughput
of 96 days, whereas the other situations in the vicinity have an average of 19
days. the set of surprising situations in vicinity 14 has the highest eﬀectiveness.
removing the problem that causes the delay in these surprising situations would
reduce the average throughput time for similar cases by more than one day.
k-means clustering method. in this approach, we used k-means clustering to
identify vicinities. for kwe use the value 25, which is the number of the leaves
of the decision tree model in the previous part of the experiment. this method
results in detecting a total of 280 surprising situations. the plot on the left side
of figure 6 shows the surprising situations detected in each vicinity.
fig.6: detected surprising situations for the k-means clustering and similarity
based method.detecting surprising situations in event data 11
fig.7: venn diagram showing the intersection of detected surprising situations
using the diﬀerent methods.
similarity based method. we run the similarity based approach where the dis-
tance measure is the euclidean distance of normalized descriptive features (using
min-max method). then, we use 1.4 as the threshold to generate a graph. to
ﬁnd the vicinities, we used the louvain community detection method [3] on this
graph. the plot on the right side of figure 6 shows the surprising situations
detected in each vicinity.
it is worth noting that the set of surprising situations detected by diﬀerent
methods was not exactly the same. figure 7 shows that all the methods agree
on 176 detected surprising situations and for all other situations at least one
method does not select it.
5 conclusion
finding the process enhancement areas is a fundamental prerequisite for any
process enhancement procedure that highly aﬀects its outcome. it is usually
assumed that these process areas are known in advance or can be detected easily.
however, utilizing simple methods have the danger of overlooking some of the
opportunitiesforprocessenhancementortargetingthewrongones.inthispaper,
we formulate the process of ﬁnding process enhancement areas as a method for
ﬁnding surprising situations; i.e., detecting those situations where the process
behavior is signiﬁcantly diﬀerent from similar situations.
we have implemented the proposed framework with diﬀerent methods and
evaluated it using real event logs. the experiment shows that the detected sur-
prising (anomalous) situations are overlapping but not identical to the ones of
thebaseline,whichiscurrentlyacommonmethodforﬁndinganomalies.itshows
that to ﬁnd the best result, it is best to use our framework complementary to
the existing methods; i.e., using both context-sensitive and non-context-sensitive
methods for ﬁnding the process enhancement areas.
acknowledgment
we thank the alexander von humboldt (avh) stiftung for supporting our re-
search.12 c. kohlschmidt et al.
references
1. f. d. l. bezerra and j. wainer. fraud detection in process aware systems. inter-
national journal of business process integration and management , 5(2):121–129,
2011.
2. f. d. l. bezerra and j. wainer. a dynamic threshold algorithm for anomaly
detection in logs of process aware systems. 2012.
3. v. d. blondel, j.-l. guillaume, r. lambiotte, and e. lefebvre. fast unfolding
of communities in large networks. journal of statistical mechanics: theory and
experiment , 2008(10):p10008, oct 2008.
4. k. böhmer and s. rinderle-ma. multi-perspective anomaly detection in business
process execution events. in otm confederated international conferences" on
the move to meaningful internet systems" , pages 80–98. springer, 2016.
5. j. j. carmona, m. de leoni, b. depaire, and t. jouck. process discovery contest
2017. 5 2021.
6. r. conforti, m. la rosa, and a. h. m. ter hofstede. filtering out infrequent
behavior from business process event logs. ieee transactions on knowledge and
data engineering , 29(2):300–314, 2016.
7. m. dees, m. d. leoni, and f. mannhardt. enhancing process models to improve
business performance: a methodology and case studies. in otm confederated
international conferences" on the move to meaningful internet systems" , pages
232–251. springer, 2017.
8. n. gupta, k. anand, and a. sureka. pariket: mining business process logs for root
cause analysis of anomalous incidents. in international workshop on databases in
networked information systems , pages 244–263. springer, 2015.
9. h. nguyen, m. dumas, m. l. rosa, f. m. maggi, and s. suriadi. business process
deviance mining: review and evaluation. corr, abs/1608.08252, 2016.
10. s. pauwels and t. calders. an anomaly detection technique for business pro-
cesses based on extended dynamic bayesian networks. in proceedings of the 34th
acm/sigapp symposium on applied computing , pages 494–501, 2019.
11. r.post,i.beerepoot,x.lu,s.kas,s.wiewel,a.koopman,andh.reijers. active
anomaly detection for key item selection in process auditing. in international
conference on process mining , pages 167–179. springer, cham, 2021.
12. m. s. qafari and w. m. p. van der aalst. feature recommendation for structural
equation model discovery in process mining. progress in artiﬁcial intelligence ,
pages 1–25, 2022.
13. r. rieke, m. zhdanova, j. repp, r. giot, and c. gaber. fraud detection in mobile
payments utilizing process behavior analysis. in 2013 international conference on
availability, reliability and security , pages 662–669. ieee, 2013.
14. a. rogge-solti and g. kasneci. temporal anomaly detection in business pro-
cesses. in international conference on business process management , pages 234–
249. springer, 2014.
15. r. sarno, f. sinaga, and k. r. sungkono. anomaly detection in business processes
using process mining and fuzzy association rule learning. journal of big data ,
7(1):1–19, 2020.
16. w. m. p. van der aalst, a. adriansyah, and b. van dongen. replaying history
on process models for conformance checking and performance analysis. wiley
interdisciplinary reviews: data mining and knowledge discovery , 2(2):182–192,
2012.