a generic framework for context-aware
process performance analysis
bart f.a. hompes1,2(b), joos c.a.m. buijs1, and wil m.p. van der aalst1
1department of mathematics and computer science,
eindhoven university of technology, eindhoven, the netherlands
{b.f.a.hompes,j.c.a.m.buijs,w.m.p.v.d.aalst }@tue.nl
2philips research, eindhoven, the netherlands
abstract. process mining combines model-based process analysis with
data-driven analysis techniques. the role of process mining is to extract
knowledge and gain insights from event logs. most existing techniques
focus on process discovery (the automated extraction of process models)and conformance checking (aligning observed and modeled behavior).
relatively little research has been performed on the analysis of busi-
ness process performance. cooperative business processes often exhibita high degree of variability and depend on many factors. finding root
causes for ineﬃciencies such as delays and long waiting times in such ﬂex-
ible processes remains an interesting challenge. this paper introduces anovel approach to analyze key process performance indicators by consid-
ering the process context. a generic context-aware analysis framework is
presented that analyzes performance characteristics from multiple per-spectives. a statistical approach is then utilized to evaluate and ﬁnd
signiﬁcant diﬀerences in the results. insights obtained can be used for
ﬁnding high-impact points for optimization, prediction, and monitoring.the practical relevance of the approach is shown in a case study using
real-life data.
keywords: process mining
·performance analysis ·context-aware ·
root cause analysis
1 introduction
process mining is an emerging discipline that deals with extracting knowledge
and non-trivial insights from event data recorded by information systems. such
event logs capture the diﬀerent steps (activities) recorded for cases (customers,
patients, etc.) that follow a process. usually, information is stored about whatactivity was performed by whom and at what time. additionally, information
about the involved resources or process-speciﬁc data attributes such as the cus-
tomer type or the age of a patient may be recorded as well. existing processmining techniques have focused on three main areas: process discovery, confor-
mance checking and process enrichment. process discovery can be deﬁned as the
automated extraction of process models from event logs. insights can be gained
c/circlecopyrtspringer international publishing ag 2016
c. debruyne et al. (eds.): otm 2016 conferences, lncs 10033, pp. 300–317, 2016.doi: 10.1007/978-3-319-48472-3
17a generic framework for context-aware process performance analysis 301
on the order of activities, parallel parts, alternative ﬂows or iterative steps in a
process. conformance checking compares the observed and modeled behavior byaligning the cases in the event log with the process described in a model. this
way, process compliance can be analyzed and skipped activities, improper execu-
tion orders or deviations from protocols can be discovered. process enhancementdeals with the extension or improvement of an existing a-priori process model
with information about the actual process recorded in the log. models can for
example be extended to show performance information or conformance issues.
typically, discovering process models for ﬂexible processes results in models
that are diﬃcult to interpret, as most cases exhibit unique behavior. often, no a-
priori model is present, making conformance checking and process enhancementchallenging tasks. as a result, gaining an understanding of the underlying process
and ﬁnding points for optimization is far from trivial.
from most real-life event logs, we can gain information about diﬀerent perfor-
mance characteristics. typically, we are interested in characteristics such as wait-
ing times, throughput times, and utilization rates. existing process performanceanalysis techniques, however, are limited to describing the overall behavior, such
as mean waiting times and durations. by looking at the frequency distributions
of these measures, we can see that these typically do not follow a single dis-tribution curve. rather, density plots give the impression of being composed of
multiple components, as depicted in fig. 1. the ideas presented in this paper aim
to discover such underlying components. often times, performance characteris-tics of a speciﬁc activity, case, or entire process highly depend on the context.
for example, preceding tasks, involved resources and their workload, or even the
weather can have a big eﬀect on performance. in business intelligence tools andtechniques, data is sliced and diced to view key performance information from
diﬀerent perspectives. the idea is that contextual properties of process entities
such as cases and resources form the underlying components in the frequency
fig. 1. frequency distributions are composed of multiple components. we aim to dis-
cover the underlying contextual properties that lead to these components.302 b.f.a. hompes et al.
distributions mentioned above, and are considered as the analysis perspectives.
in this paper, we introduce a context-aware process performance analysis app-roach that can be used to analyze event logs in a similar way. process entities
are labeled with their context and their performance is calculated. hypothesis
testing is used to automatically discover signiﬁcant diﬀerences in performancemeasures for diﬀerent contexts.
the remainder of the paper is structured as follows. section 2introduces pre-
liminary deﬁnitions. the notion of process context and performance is introducedin sect. 3. how to automatically ﬁnd signiﬁcant diﬀerences in performance using
hypothesis testing is explained in sect. 4. in sect. 5, the practical relevance of the
approach is shown using a case study on a real-life dataset. the paper is posi-tioned and related work is outlined in sect. 6. in sect. 7the paper is concluded
and ideas for possible future work are given.
2 preliminaries
the executed events of multiple cases of a process are recorded in an event
log. event logs serve as input for any process mining technique. an event is a
particular execution of an activity for a case, potentially having additional data
attributes such as a timestamp or the responsible resource. a trace is a ﬁnite
sequence of events, and describes one speciﬁc instance (i.e. a case) of the process
at hand in terms of the executed activities. a case can also have additional (case-
level) attributes such as a birthdate or customer type. deﬁnitions for events andcases used here are based on those in [ 2].
deﬁnition 1 (event, attribute). letebe the event universe, i.e. the set of
all possible event identiﬁers. events may be characterized by various attributes.
letnbe a set of attribute names. for any event e∈e and attribute name
n∈n:n(e)is the value of attribute nfor event e. if event edoes not have an
attribute named n, then n(e)=⊥(null value).
typically, the following attributes are present for all events: activity (e)i s
the activity associated to event e,time(e)i st h e timestamp ofe,resource (e)i s
the resource associated to e,a n d trans(e)i st h e transaction type ofe. possible
fig. 2. standard transactional life-cycle model.a generic framework for context-aware process performance analysis 303
transaction types are scheduled, assigned, suspended, etc. as depicted in the
standard transactional life-cycle model in fig. 2. each event is associated with a
state transition for a single activity instance. these states are used to calculate
performance information such as duration and waiting times for the activity.
an example event log ( l1) can be found in table 1. here, next to the standard
attributes, cases have the data attributes ‘age’ and ‘type’, and events have
attribute ‘cost’. note that case 4 has no value for the attribute ‘age’.
deﬁnition 2 (case, trace, event log). letcbe the case universe, i.e. the
set of all possible case identiﬁers. cases, like events, have attributes. for any
casec∈c and attribute name n∈n:n(c)is the value of attribute nfor case c
(n(c)=⊥ifchas no attribute named n). each case has a mandatory attribute
‘trace’: trace(c)∈e∗.ˆc=trace(c)is a shorthand notation for referring to the
trace of a case. a trace is a ﬁnite sequence of events σ∈e∗, such that each
event appears only once, i.e. for 1≤i<j ≤|σ|:σi/negationslash=σj. for any sequence
s=/angbracketlefts1,s2,...,s n/angbracketright,set(s)={s1,s2,...,s n}converts a sequence into a set, e.g.
set(/angbracketlefta,b,c,b,c,d /angbracketright)={a,b,c,d }. an event log is a set of cases l⊆c such that
each event appears at most once in the entire log, i.e. for any c,c/prime∈lsuch that
c/negationslash=c/prime:set(ˆc)∩set(ˆc/prime)=∅.
table 1. example event log l1.
case id case attributes event id event attributes
agetype time activity transition resource cost
1 33premium 1 2016-1-4 8:00 a start john 10
2 2016-1-4 9:15 a complete john 0
3 2016-1-4 10:12 b complete bob 20
4 2016-1-4 14:00 c schedule sue 0
5 2016-1-4 14:05 c start sue 15
2 27basic 6 2016-1-6 10:43 a start bob 15
7 2016-1-6 11:00 a complete bob 0
8 2016-1-7 09:33 b complete john 30
9 2016-1-7 09:35 c schedule sue 30
3 18basic 10 2016-1-7 9:27 a start john 15
11 2016-1-7 10:40 a complete john 0
12 2016-1-7 15:03 b complete bob 30
4 ⊥premium 13 2016-1-7 12:10 a start bob 10
14 2016-1-7 12:24 a complete bob 0
15 2016-1-8 08:47 b complete john 30
5 41basic 16 2016-1-8 15:32 a start bob 15
17 2016-1-8 15:51 a complete bob 0
... ...... ... ... ... ... ... ...304 b.f.a. hompes et al.
3 context-aware performance analysis
performance correlates with contextual information. as explained in sect. 1, this
information is lost in a single distribution. hence, a distribution per context maybe more precise, as shown in fig. 1. note that a composed distribution without
context has limited value. for example, it could be that an activity for which
one of two resources is involved, on average has a waiting time of one week. oneresource might be overbooked, leading to waiting times of several weeks, while
the other resource might be able to perform the task in a few hours. clearly,
which resource is assigned to perform the task for a certain case will determinethe waiting time for that speciﬁc case. the average waiting time for all cases will
not accurately represent the waiting time for either resource. typically, multiple
contextual properties having many possible values are in play. our aim is toﬁnd, given the distribution of performance measures, which, if any, contextual
properties compose this distribution. such insights can lead to better predictions,
help in monitoring for change, aid in optimizing scheduling, etc.
in this section, the concept of context-aware performance analysis is intro-
duced. subsection 3.1describes process entities and the process context, and
typical examples of contextual properties are given. subsection 3.2explains the
concept of performance. the interrelation between context and performance is
explained in subsect. 3.3.
3.1 process entities and context
process entities have a type and represent a collection of events. the default
process entity types are case,activity instance ,event,a n d resource . resources
are process entities as an event log can be seen as a collection of resources, eachof which is performing a set of events. this list can be extended with additional
entity types depending on the information that is available in the event log at
hand. formally, process entities are deﬁned as follows.
deﬁnition 3 (process entity). lettbe the universe of process entity types,
anddthe universe of entity identiﬁers. let i=d×p (e)
1denote the universe
of process entities. itdenotes the set of process entities of type t∈t .f u n c t i o n
φ:p(c)×t →p (i)maps an event log to a set of entities of a given entity type.
for example, applying φto event log l1and the resource, activity, and case
entity types we obtain:
φ(l1,resource )={(bob,{3,6,7,12,13,14}),(sue,{4,5,9}),
(john, {1,2,8,10,11,15})}
φ(l1,activity )={(a,{1,2,6,7,10,11,13,14,16,17}),(b,{3,8,12,15}),
(c,{4,5,9})}
φ(l1,case)={(1,{1,2,3,4,5}),(2,{6,7,8,9}),(3,{10,11,12}),
(4,{13,14,15}),(5,{16,17})}
1p(e) denotes the powerset over e, i.e. all possible subsets of e.a generic framework for context-aware process performance analysis 305
table 2. example context functions.
context function applicable to entity type
number of cases process
number of previous events case
preﬁx activity instance, event
suﬃx activity instance, event
number of occurrences activity instance
utilization rate of resource event
number of concurrent events event
resource id event
... ...
typically, entities are related to other entities. for example, activity instances
are made of one or more events (representing a certain life-cycle transition,mentioned in sect. 2) and, at the same time, are part of a trace of a case.
the contextual properties of a process entity are obtained by applying a
context function to that entity. a context function maps a process entity to acontext label (descriptive value) that aims to describe the entity’s context. for
example, taking activity instances as entities and the executing resource as the
context, we can see how diﬀerent resources aﬀect activity kpis such as waitingtime, duration, etc. context functions are deﬁned only for certain types of process
entities. for example, cases typically do not have one resource associated with
them, but events do. context can be explicit (i.e. attribute values such as the
involved resource or customer type) or implicit (i.e. calculated values such as
the number of days spent in the hospital or the cost-proﬁt ratio of a customer).formally, context functions are deﬁned as follows.
deﬁnition 4 (context function). letibe the universe of process entities
andtthe universe of entity types. let vbe the universe of contexts. a context
function υ:i
t→v maps a process entity of type t∈t to a context.
for example, we can deﬁne the case-type context function of case entities as
type:icase→v. consequently, {type(i)|i∈φ(l1,case)}={basic,premium }.
other examples of context functions can be found in table 2. note that additional
context functions can be deﬁned based on the data available in the event log at
hand. after mapping each process entity of a certain type to its context with oneor more applicable context functions, performance characteristics are calculated.
3.2 performance
process performance analysis aims to improve processes with respect to time,
cost, and/or quality [ 2]. in traditional business intelligence methods, key perfor-
mance indicators are typically used to discover and monitor bottlenecks, devi-
ations from protocol, violations of regulations, service level agreements, etc. in306 b.f.a. hompes et al.
process mining, measures such as throughput times of activity instances or cases,
sojourn times, waiting times, frequencies, time between activities, etc. are calcu-lated based on the data stored in event logs. metrics such as utilization rates and
case load or the cost to gain new customers are derived from these measures.
both measures and metrics can be kpis, depending on their business value.performance can be seen as the result orscore of a certain entity on a certain
performance function. performance functions are formally deﬁned as follows.
deﬁnition 5 (performance function). letibe the universe of process enti-
ties and tthe universe of entity types. a performance function λ:i
t→ rmaps
a process entity of type t∈t to a kpi result.
we let the result of performance functions be numeric (continuous) val-
ues. for example, we can deﬁne the duration of activity instance entities asduration :i
activity → r. consequently, {duration (i)|i∈φ(l1,activity )}=
{75,0,0,17,0,0,73,0,14,0,19}(in minutes). note that only activities that have
start and complete events have a duration. otherwise a duration of 0 is recorded.
in order to calculate these kpis, information from the events related to the
entity is necessary. typically, information about when events (activity transi-
tions) were performed is required. sometimes information from events relatedto related process entities is necessary as well. for example, the duration of an
activity is calculated as the time diﬀerence between the start and completion
of the activity. these time values are stored in two separate events represent-
ing the respective life-cycle transitions of the activity. after calculating kpis,
performance characteristics are related to contextual properties of the processentities.
3.3 context-aware performance
by splitting performance measurements for a speciﬁc entity over the diﬀer-
ent context labels assigned to it, we obtain context-aware performance results.
relating the performance characteristics of process entities to their contextual
properties shows whether and where correlations exist. from these results, wecan see if (and how) contextual properties inﬂuence the performance of the
process. for example, we can analyze the duration of activity a from l
1.
the resource involved in executing the activity is taken as the context. for-
mally, we take all entities from φ(l1,activity ) that are related to activity a
and compute their duration. these durations are then linked to the context bygrouping them based on the context label assigned to the speciﬁc activity, i.e.
resource (φ(l
1,activity )). as activity a can only be performed by either john or
bob, this leads to two groups of measurements. the speciﬁc values are: john {75,
73}averaging 74 min, and bob {17, 14, 19 }, averaging 16.7 min. clearly, using
the overall average of 39.6 min as an estimation for the duration of activity a in
calculations, prediction and planning is imprecise, while using the context-awareaverages gives a much better estimation.
manually analyzing every possible combination of performance and context
function is a tedious and error-prone task. therefore, we propose an automateda generic framework for context-aware process performance analysis 307
fig. 3. a graphical overview of the approach. performance measurements for process
entities are related to their context. hypothesis testing is used to automatically ﬁnd
statistically signiﬁcant diﬀerences.
approach to test for signiﬁcant diﬀerences between contexts for all entities and
applicable context and performance functions. this analysis is done by meansof statistical hypothesis testing, and will be explained in sect. 4.
4 statistical hypothesis testing
as explained in subsect. 3.3, context-aware performance results are used to ﬁnd
correlations between contextual properties of process entities and process perfor-
mance. however, the number of combinations and therefore possible correlationsis often quite high, complicating manual analysis. in order to automate the analy-
sis of signiﬁcance of diﬀerences between context results, we follow a statistical
approach. a graphical overview can be seen in fig. 3.
performance results for diﬀerent contexts are seen as diﬀerent samples. for
these samples, the variance is analyzed. the null hypothesis is that no signiﬁcant
diﬀerences exists between the samples, and therefore, that the chosen context
function does not have a signiﬁcant eﬀect on the performance results. hence, if
the null hypothesis is rejected, a possible cause for performance diﬀerences isfound. by automating these analyses, many combinations of context and per-
formance functions can be tested, and possible points for performance improve-
ment can be rapidly discovered. nonetheless, this automated technique has somedrawbacks, which are discussed in subsect. 4.4.
in the automated approach, the samples are ﬁrst tested for normality, i.e. it
is tested whether the values are sampled from a normally distributed population.if so, the one-way analysis of variance test is used. if not, a power transformation
is applied in an attempt to make the data follow a normal distribution. when
the data cannot be transformed, a non-parametric analysis of variance test isused (subsect. 4.1). in case the null hypothesis is rejected, post-hoc analysis
is performed using a multiple comparison procedure (subsect. 4.2), in order to
identify which samples are signiﬁcantly diﬀerent from each other, as the analysisof variance only indicates the existence of such a diﬀerence in a set of samples, but
not the location. in other words, by applying our approach, those contexts that
lead to signiﬁcantly diﬀerent performance results are discovered (subsect. 4.3).308 b.f.a. hompes et al.
besides relating individual contextual properties to performance results, con-
texts can be grouped to ﬁnd combined correlations. for example, the involvedresource or the previous activities might not inﬂuence an activity’s waiting time
individually, but the combination might. the analysis of combined contexts is
analogous to that of a single context. however, it should be noted that thisanalysis signiﬁcantly increases the search space.
4.1 hypothesis testing
statistical models can be used to analyze the diﬀerence (variance) between
groups. analysis of variance (anova) provides a statistical test of whether
or not the means of several groups have the same standard deviation. the one-
way (single-factor) anova tests whether a single factor leads to a signiﬁcantdiﬀerence in the groups [ 16]. hence, it generalizes the t-test to more than two
groups. in our case, it is used to test whether diﬀerent contexts lead to signiﬁcant
diﬀerences in kpi results for a given process entity and context function.
as explained, anova is based on a hypothesis test where the null hypothesis
is that the means of all groups are equal. a critical value (or p-value) is used
as a number that the test statistic must exceed to reject the null hypothesis.
typically, a value of 0.05 is used. multiple variants of the anova have been
proposed in literature and are widely used [ 16,17,21]. the basic assumptions are
independence of observations, homogeneous variances, and population normality.
the former two will be discussed in subsect. 4.4.
in order to be able to perform an analysis of variance test on the performance
results, ﬁrst, the samples are tested for normality by a goodness-of-ﬁt test. the
shapiro-wilk test [ 25] was found to have the best power for a given signiﬁcance
in several studies [ 23]. in case the null hypothesis is accepted, i.e. the data come
from a normally distributed population, we can proceed with the analysis of
variance. in case the null hypothesis is rejected, i.e. the data do not follow a nor-
mal distribution, we attempt to transform the data to make it follow a normaldistribution by applying the box-cox power transformation [ 8]. if the data does
not come from a normally distributed population and cannot be transformed,
we apply a non-parametric analysis of variance test. these types of tests, known
as anova on ranks, are less powerful but are designed for situations where nor-
mality cannot be assumed. we use the kruskal-wallis test [ 17] in case normality
cannot be assumed for the kpi values for the diﬀerent contexts.
in order to evaluate the eﬀect of a combination of contexts, we can either
create combined context functions or use a multiple-factor analysis of varianceprocedure.
4.2 post hoc analysis
in case the analysis of variance’s null hypothesis is rejected for a given context
and performance function, we know for which entity the context function can
explain diﬀerences in performance. however, we do not know yet how these dif-
ferences can be explained, as the analysis of variance tests indicate the existencea generic framework for context-aware process performance analysis 309
of diﬀerences, but not their location. for example, the anova can indicate
that the resource responsible for executing an activity has an eﬀect on its dura-tion, but not which resources stand out. post hoc analyses are typically used
to perform multiple comparisons with the aim of ﬁnding which samples can be
considered as distinct.
we use tukey’s range test [ 26], which compares the means of every sam-
ple to the means of every other sample. it identiﬁes any diﬀerence between
two means that is greater than the expected standard error. like the single-factor anova described in subsect. 4.1, tukey’s range test assumes normality.
as a non-parametric alternative (i.e. after applying the kruskall-wallis test)
nemenyi’s distribution-free multiple comparison test (also known as nemenyi-damico-wolfe-dunn test) is used as a post hoc test [ 17]. both tests do not require
sample sizes to be balanced and correct for the multiple comparison problem [ 17].
note that it is possible that the null hypothesis for the analysis of variance is
rejected, but the post hoc test fails to reject all pairwise tests for a given critical
value (e.g. because of the multiple comparison correction). in other words, acrossall samples there can be a signiﬁcant diﬀerence in means, while between every
pair of samples there is not. in this case, further automated or manual inspec-
tion is necessary. however, when this is the case, the discovered diﬀerences inperformance are generally of low impact to the business process being analyzed.
4.3 analysis of results
after the automated context-aware process performance analysis has been per-
formed, the results need to be interpreted. by showing the entities and context
functions for which the most signiﬁcant diﬀerences in performance have beenfound, we obtain a list of possible optimization points. however, statistical sig-
niﬁcance does not equal real-world impact. it might be the case that even though
the means of two or more contexts are very diﬀerent, their absolute values diﬀerlittle. for example, consider a process with two activities: make scan (machine
activity) and read scan (human activity). some scanners are faster than others,
and some people read faster than others. it is possible that the signiﬁcance indiﬀerences between scanners is much higher than that between readers, even
though usually, bulk of the time will be spent in reading a scan rather than
making it. thus, the importance of a performance diﬀerence is not determined
only by its signiﬁcance. it is important to determine the impact of a discov-
ered diﬀerence. this can be done by implementing an impact formula that forexample multiplies the signiﬁcance of the diﬀerence with the absolute variance.
once signiﬁcant and impactful diﬀerences are discovered they can be trans-
formed into performance insights in natural language or by visual representationssuch as those in sect. 5. for example, sentences such as “activity x takes three
times longer when resource r is involved in the preceding activity” or “cases
often violate the maximum throughput sla if the caseload is higher than 80%at the time of activity x” can be constructed. since the impact provides a nat-
ural ordering it is possible to, for example, only show the top 10 most impactful
context-dependent performance diﬀerences.310 b.f.a. hompes et al.
4.4 assumptions and drawbacks
automating the analysis of variance between diﬀerent samples has some draw-
backs. the existence of outliers can aﬀect the test for normality. filtering outoutliers ﬁrst can restore normality. depending on the desired results of the
context-aware performance analysis, outliers may need to be removed before
testing for signiﬁcant diﬀerences in performance for diﬀerent contexts.
besides outliers, sample sizes are most critical in determining the value of
the automated test. this is related to the homogeneity of variance assumption of
the analysis of variance tests. since normality tests have little power with smalldata sets and can be too sensitive with large data sets, an automated approach
might give false conﬁdence of normality, and consequently the assumptions of
the chosen analysis of variance test might be violated [ 16]. for example, this
assumption is violated when sample sizes are very unbalanced. in this case, the
null hypothesis is at risk of being falsely rejected. in other words, in case a certain
context is very infrequent and/or there are big diﬀerences in the frequencies ofdiﬀerent contexts, the results might falsely indicate (in)signiﬁcant diﬀerences
in performance. as such, the quality of the results depend on the size of the
samples that are tested. the f-statistic used by this test is considered robust tothe homogeneity of variance assumption when sample sizes are balanced [ 16].
analysis of variance also assumes independence of observations. however,
there might exist some relation between performance characteristics of diﬀerent
process entities. for example, it might be the case that a machine takes an
extra 10 min every 100th task, or the duration of the task alternates betweentwo values every 50 times. this however has no eﬀect on the results of our
hypothesis tests. in fact, the analysis of variance tests whether the samples are
drawn from the same distribution. if the context function does not explain anydiﬀerence in results, the test statistic will not be signiﬁcant. in other words,
taking the two examples mentioned before, each 100th task performed by the
machine or the diﬀerent durations will randomly reside in any of the samples,in case the context function does not describe those problems.
in conclusion, results of the automated approach need to be carefully inter-
preted before using them as basis for process performance statements. this canfor example be done by visual comparison of the performance results. nonethe-
less, the results provide a powerful basis for context-aware process performance
analysis, and can provide important insights into root causes for performanceproblems such as bottlenecks or deviations from protocol and can be used for
better scheduling of resources.
5 case study
the context-aware performance analysis approach described above has been
implemented as an extensible analysis framework in the process mining tool
prom2. new process entities or context and performance functions can be easily
2seehttp://promtools.org .a generic framework for context-aware process performance analysis 311
added in order to analyze their eﬀect on performance. we evaluate our technique
on a publicly available, real-life event log. this event log was used so that resultscan be reproduced and compared. the aim is to demonstrate our approach rather
than to exhaustively analyze the process recorded in this log. the dataset stems
from a loan application process from a dutch bank, and was originally used inthe business processing intelligence challenge (bpic) in 2012 [ 11]. the log con-
tains 13,087 cases of a loan application process, for which in total 262,200 events
have been recorded. there are 36 distinct activities and 69 diﬀerent resourcesare involved in this process. there are 4,366 diﬀerent control-ﬂow variants.
in order to test our approach, we analyze the duration of activities with
respect to their context. this is done by measuring the time between the eventsthat represent the start and complete transitions for an activity. we look at
the measurements from two diﬀerent perspectives: the resource involved in the
activity and the activities preceding the activity (preﬁx of the trace). in other
words, one performance function and two context functions are used. of course,
other functions potentially leading to additional insights can be applied as well.
applying the technique as described in sect. 3for both context functions and
all 36 activities, results in 72 sets of measurements. here, each measurement set
represents the duration of a speciﬁc activity when analyzed for a speciﬁc contextfunction, i.e. each set contains multiple samples of duration values representing
a speciﬁc context (label). for each set, we analyze the variance between the set
of samples using the statistical approach described in sect. 4. the post hoc tests
are used to discover exactly which context stands out.
for the preﬁx context function, the length-2 preﬁx of activities in their trace
is taken. the result is abstracted to a set. in this way, we look at whether thelast two activities (in any order) have an aﬀect on the duration. signiﬁcant
diﬀerences are found for two activities: “w afhandelen leads” and “w beoordelen
fraude”. these results are shown in figs. 4and5respectively. for “w afhandelen
leads”, it can be seen that if the activity is performed three times in a row,
the duration is signiﬁcantly higher than when it is preceded by “w beoordelen
fraude” or “w completeren aanvraag”. similarly, in fig. 5, we can see that when
“w beoordelen fraude” is preceded by “w completeren aanvraag” and itself, it
takes signiﬁcantly more time. from these results we might conclude that reworkleads to an increase in duration. however, note that even though the diﬀerences
in duration are signiﬁcant, the impact in this case is limited to maximally several
minutes diﬀerence, and as a result the diﬀerences might be negligible for theprocess owner.
using the resource context function, we check whether the resource involved
in the execution of an activity has an eﬀect on its duration. a signiﬁcant dif-ference in duration is found for the activity “w completeren aanvraag”, as can
be seen in fig. 6. we can see that two resources (11079 and 11254) take consid-
erably more time to perform the activity. in fig. 7, we can see that the other
resources generally take up to half an hour. in this case, the diﬀerences span
several hours. this big diﬀerence might be due to the fact that the two resources
handle diﬃcult cases or that the activities they perform span multiple days.312 b.f.a. hompes et al.
fig. 4. duration for the activity “w afhandelen leads” for diﬀerent preﬁx-sets of length
2. the third consecutive execution of the activity is found to take signiﬁcantly moretime. the impact is in the order of several minutes.
fig. 5. duration for the activity “w beoordelen fraude” for diﬀerent preﬁx-sets of
length 2. when the activity is preceded by “w completeren aanvraag” and itself, it
takes signiﬁcantly longer. the impact of the discovered diﬀerences is limited to several
seconds.
fig. 6. duration for the activity “w completeren aanvraag” for diﬀerent resources.
two resources are found to take signiﬁcantly more time. an impact of several hours
can be seen.a generic framework for context-aware process performance analysis 313
fig. 7. figure 6zoomed in to show diﬀerences between resources. most other resources
take a comparable time to execute “w completeren aanvraag”.
6 related work
as mentioned, relatively little work has been done in automatically analyzing
process performance characteristics. in general, related work can be divided in
the following groups: research on performance characteristic calculation, whichaims at proposing new performance measurements and metrics, analysis, which
aims to ﬁnd root causes for performance issues, and prediction, which tries to
predict remaining waiting times, cycle times, etc.
in [15], the authors approximate the cycle time of processes based on queuing
theory, using expected times and process structure. however, no context is used
in the prediction process. techniques as [ 5,13,14] focus on context-aware perfor-
mance predictions by applying a clustering approach, where diﬀerent context-
related scenarios relate to separate prediction models. diﬀerent clusters of behav-
ior can be discovered for which diﬀerent prediction models are created. new casescan then be compared to all clusters, and predictions can be obtained from the
most closely related cluster. however, in these techniques, the context is limited
to a representation of the features (attributes) of cases or events. also, no rulesor descriptions are given as to what diﬀerences exist between the clusters. in [ 14],
the prediction is restricted to predicates that can be evaluated over completed
cases.
diﬀerent techniques have been proposed to predict the remaining running
time of processes [ 4,6,20,22,24]. for example, [ 24] uses stochastic petri nets with
arbitrary ﬁring delays as a basis for prediction. in [ 22], a technique to learn a
prediction model is proposed that can predict performance characteristics such
as remaining waiting time, but also the following activity or resource can bepredicted. though having their merits and speciﬁc use cases, these approaches
heavily rely on a process model to be present. in ﬂexible process environments,
these models are diﬃcult to obtain and change continuously, restricting the useof these techniques.
simulation can be used to analyze process performance characteristics. in [ 1],
the authors highlight possibilities. the downsides of simulation is that it is oftendiﬃcult to mimic the steady-state behavior in ﬂexible processes. as a result,314 b.f.a. hompes et al.
analyzing the eﬀects of changes becomes infeasible. also, contextual properties
of process characteristics underlying performance diﬀerences are not discovered.
in [19], the authors aim to predict behavior based on classiﬁcation of event-
and case attributes using decision trees. though contextual properties can be
used, the user needs to specify the dependent and independent variables in orderto perform a single analysis. the interpretation of the signiﬁcance of the result
is left to the user as well. as a result, multiple analyses need to be performed
and interpreted to ﬁnd root causes for performance issues.
most related to the technique used in this paper is the approach proposed
in [12], where non-parametric regression is used to predict remaining cycle time,
activity durations or attribute values. here, however, contextual properties ofprocess entities are not considered yet. as such, no deﬁnite description of what
is causing performance diﬀerences can be given.
in our technique, performance diﬀerences are explained by the contextual
information underlying those diﬀerences. furthermore, our approach does not
depend on a process model, and thus can be applied to both structured as wellas ﬂexible processes where no process description is present. we purposely utilize
broad deﬁnitions for context and performance functions in order to generalize
our analysis approach. however, more detailed formalizations can be found in lit-erature and can be used to further clarify, formally deﬁne, and represent context
and performance functions. for example, in [ 9], the authors provide an approach
to characterize the context of a process in a given domain through conceptualmodels structured in layers. here, both internal and external context is included
and the relationship between entities is formalized. in [ 10] a meta-model is pro-
posed that can be used to unambiguously deﬁne process performance indicatorsthat are amenable to automated analysis. techniques such as these can be used
in conjunction with our approach to further automate the analysis of process
performance.
7 conclusion
most existing process mining techniques focus on process discovery and confor-mance checking. relatively little research has been performed on the analysis
of business process performance. performance characteristics of process entities
such as events, activities, cases, resources, or entire processes typically highly
depend on their context. this paper has introduced a novel approach to analyze
key process performance indicators by considering the process context .w eh a v e
introduced a generic framework that aids in discovering signiﬁcant diﬀerences
in performance results and their causes. process entities are assigned descriptive
context labels by applying context functions to them. statistical hypothesis test-ing is used to verify whether a context label explains a signiﬁcant diﬀerence in
performance. in other words, using this technique, the eﬀect of any context on
kpis can be automatically analyzed. insights can be gained on which contextualproperties of process entities have an eﬀect on the key performance indicators
of business processes. as such, root causes for delays, bottlenecks, deviations to
protocol and violations of service level agreements, etc. can be discovered.a generic framework for context-aware process performance analysis 315
even though a generic framework was introduced, often speciﬁc context func-
tions need to be created to analyze real-life processes. to this end, several contextfunctions have been mentioned. sometimes, however, the contexts underlying
performance diﬀerences are domain-dependent and therefore have to be deﬁned
by the process analyst. to this end, we have implemented the approach as ageneric and extensible framework in the process mining tool prom. also, as
described in subsect. 4.3, careful interpretation of the results of the automated
analysis technique is essential. in order to better assist the analyst in provid-ing performance optimizations, more work is needed to analyze the impact of
discovered diﬀerences in performance. information on signiﬁcant performance
diﬀerences can be used as input for better prediction techniques or can be usedin a streaming data monitoring setting, where states of alert are reached once
diﬀerences become signiﬁcant.
besides using only event data, information obtained from process models can
aid in providing more accurate measurements. in case of parallelism for example,
process models can help to identify simultaneous activities. furthermore, processmodels can be used when timing information stored in the event log is imprecise
or (partially) missing. using alignments, process models and event logs can be
combined to show conformance and performance information. however, how touse process models to better calculate performance is outside the scope of this
paper. more information on this topic can be found in [ 2,3,7,18]. in the future
we would also like to look into how to visualize the results in diﬀerent ways.for example, the most impactful diﬀerences in performance can be translated
in natural language. process models can also be extended with information on
performance issues and their root causes.
references
1. van der aalst, w.m.p.: business process simulation revisited. in: barjis, j. (ed.)
enterprise and organizational modeling and simulation. lnbip, vol. 63, pp. 1–14.springer, heidelberg (2010)
2. van der aalst, w.m.p.: process mining - data science in action. springer,
heidelberg (2016)
3. van der aalst, w.m.p., adriansyah, a., van dongen, b.f.: replaying history on
process models for conformance checking and performance analysis. wiley inter-
disc. rev. data mining knowl. disc. 2(2), 182–192 (2012)
4. van der aalst, w.m.p., schonenberg, m.h., song, m.: time prediction based on
process mining. inf. syst. 36(2), 450–475 (2011)
5. bevacqua, a., carnuccio, m., folino, f., guarascio, m., pontieri, l.: a data-driven
prediction framework for analyzing and monitoring business process performances.
in: hammoudi, s., cordeiro, j., maciaszek, l.a., filipe, j. (eds.) enterprise infor-
mation systems. lnbip, vol. 190, pp. 100–117. springer, heidelberg (2014)
6. bolt, a., sep´ ulveda, m.: process remaining time prediction using query catalogs.
in: lohmann, n., song, m., wohed, p. (eds.) bpm 2013. lnbip, vol. 171, pp.
54–65. springer, heidelberg (2014). doi: 10.1007/978-3-319-06257-0
5316 b.f.a. hompes et al.
7. jagadeesh chandra bose, r.p., aalst, w.: trace alignment in process mining:
opportunities for process diagnostics. in: hull, r., mendling, j., tai, s. (eds.)
bpm 2010. lncs, vol. 6336, pp. 227–242. springer, heidelberg (2010). doi: 10.
1007/978-3-642-15618-2 17
8. box, g.e., cox, d.r.: an analysis of transformations. j. r. stat. soc. ser. b
(methodological) 26(2), 211–252 (1964)
9. da cunha mattos, t., santoro, f.m., revoredo, k., nunes, v.t.: a formal rep-
resentation for context-aware business processes. comput. ind. 65(8), 1193–1214
(2014)
10. del-r´ ıo-ortega, a., resinas, m., cabanillas, c., cort´ es, a.r.: on the deﬁnition and
design-time analysis of process performance indicators. inf. syst. 38(4), 470–490
(2013)
11. van dongen, b.f.: bpi challenge 2012 (2012). http://dx.doi.org/10.4121/uuid:
3926db30-f712-4394-aebc-75976070e91f
12. dongen, b.f., crooy, r.a., aalst, w.m.p.: cycle time prediction: when will this
case ﬁnally be ﬁnished? in: meersman, r., tari, z. (eds.) otm 2008. lncs, vol.
5331, pp. 319–336. springer, heidelberg (2008). doi: 10.1007/978-3-540-88871-0 22
13. folino, f., guarascio, m., pontieri, l.: context-aware predictions on business
processes: an ensemble-based solution. in: appice, a., ceci, m., loglisci, c., manco,
g., masciari, e., ras, z.w. (eds.) nfmcp 2012. lncs (lnai), vol. 7765, pp.215–229. springer, heidelberg (2013). doi: 10.1007/978-3-642-37382-4
15
14. francescomarino, c.d., dumas, m., maggi, f.m., teinemaa, i.: clustering-based
predictive process monitoring. corr abs/1506.01428 (2015)
15. ha, b.-h., reijers, h.a., bae, j., bae, h.: an approximate analysis of expected
cycle time in business process execution. in: eder, j., dustdar, s. (eds.) bpm 2006.
lncs, vol. 4103, pp. 65–74. springer, heidelberg (2006). doi: 10.1007/11837862 8
16. hill, t., lewicki, p.: statistics: methods and applications: a comprehensive ref-
erence for science, industry, and data mining. statsoft inc., tulsa (2006)
17. hollander, m., wolfe, d.a., chicken, e.: nonparametric statistical methods.
wiley, new york (2014)
18. de leoni, m., van der aalst, w.m.p.: data-aware process mining: discovering deci-
sions in processes using alignments. in: shin, s.y., maldonado, j.c. (eds.) pro-ceedings of the 28th annual acm symposium on applied computing (sac 2013),
coimbra, portugal, 18–22 march 2013, pp. 1454–1461. acm (2013)
19. de leoni, m., van der aalst, w.m.p., dees, m.: a general process mining framework
for correlating, predicting and clustering dynamic behavior based on event logs.
inf. syst. 56, 235–257 (2016)
20. maggi, f.m., francescomarino, c., dumas, m., ghidini, c.: predictive monitor-
ing of business processes. in: jarke, m., mylopoulos, j., quix, c., rolland, c.,
manolopoulos, y., mouratidis, h., horkoﬀ, j. (eds.) caise 2014. lncs, vol. 8484,
pp. 457–472. springer, heidelberg (2014). doi: 10.1007/978-3-319-07881-6
31
21. marques de s´ a, j.p.: applied statistics using spss, statistica, matlab and
r. springer, heidelberg (2007)
22. pravilovic, s., appice, a., malerba, d.: process mining to forecast the future of
running cases. in: appice, a., ceci, m., loglisci, c., manco, g., masciari, e.,
ras, z.w. (eds.) nfmcp 2013. lncs (lnai), vol. 8399, pp. 67–81. springer,heidelberg (2014). doi: 10.1007/978-3-319-08407-7
5
23. razali, n.m., wah, y.b.: power comparisons of shapiro-wilk, kolmogorov-
smirnov, lilliefors and anderson-darling tests. j. stat. model. analytics 2(1),
21–33 (2011)a generic framework for context-aware process performance analysis 317
24. rogge-solti, a., weske, m.: prediction of remaining service execution time using
stochastic petri nets with arbitrary ﬁring delays. in: basu, s., pautasso, c., zhang,
l., fu, x. (eds.) icsoc 2013. lncs, vol. 8274, pp. 389–403. springer, heidelberg(2013). doi: 10.1007/978-3-642-45005-1
27
25. shapiro, s.s., wilk, m.b.: an analysis of variance test for normality (complete
samples). biometrika 52(3/4), 591–611 (1965)
26. tukey, j.w.: comparing individual means in the analysis of variance. biometrics
5(2), 99–114 (1949)