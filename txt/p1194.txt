trustworthy articial intelligence and process
mining: challenges and opportunities
andrew pery1
/envelope, majid raei2
, michael simon3
, and wil m.p. van
der aalst2
1abbyy, ottawa, canada
2chair of process and data science, rwth aachen university, aachen, germany
3xpan law partners, boston, usa
abstract. the premise of this paper is that compliance with trustwor-
thy ai governance best practices and regulatory frameworks is an inher-
ently fragmented process spanning across diverse organizational units,
external stakeholders, and systems of record, resulting in process un-
certainties and in compliance gaps that may expose organizations to
reputational and regulatory risks. moreover, there are complexities asso-
ciated with meeting the specic dimensions of trustworthy ai best prac-
tices such as data governance, conformance testing, quality assurance of
ai model behaviors, transparency, accountability, and condentiality re-
quirements. these processes involve multiple steps, hand-os, re-works,
and human-in-the-loop oversight. in this paper, we demonstrate that
process mining can provide a useful framework for gaining fact-based
visibility to ai compliance process execution, surfacing compliance bot-
tlenecks, and providing for an automated approach to analyze, remediate
and monitor uncertainty in ai regulatory compliance processes.
keywords: ai ethics Â·fairness Â·articial intelligence Â·trust mining Â·
process mining
1 introduction
ai-based technologies are becoming pervasive, impacting virtually every facet of
our lives. while ai has a lot of promise, not all of its impacts are good. there
is growing evidence that ai models can embed human and societal biases and
deploy them at scale. as such, the ever-increasing growth of ai highlights the
vital importance of balancing ai utility with the fairness of outcomes, thereby
engender a culture of trustworthy ai. fairness is the foundation for trustwor-
thy ai. intuitively, fairness seems like a simple concept. however, it embodies
consideration of a number of dimensions, such as trade-os between algorithmic
accuracy versus human values, demographic parity versus policy outcomes and
power-focused questions such as who gets to decide what is fair.
these are vexing challenges for ai developers, policy-makers and consumers
alike. for ai developers, clarity of what constitutes ai fairness is a key con-
sideration given the juxtaposition of ethical, legal, and reputational issues. for
policy-makers and regulators, the challenge is how to promote innovation whilearxiv:2110.02707v1  [cs.se]  6 oct 20212 andrew pery et al.
protecting consumers from the harmful impacts of ai. for consumers of ai, its
about trustworthiness, whether they can rely upon ai outputs to be accurate and
transparent, with safeguards in place to protect them from adverse outcomes.
this paper explores the challenges and opportunities associated with foster-
ing a culture of trustworthy ai, with particular focus on: (1) the current state
of trustworthy ai, including a survey of key industry and standards organiza-
tion initiatives with emphasis on the proposed eu articial intelligence act, (2)
the relationship between trustworthy ai and responsible data science (rds),
and (3) contribution of trust aware process mining to facilitate a data-driven
analytical framework to surface uncertainties, variabilities, and vulnerabilities in
trustworthy ai compliance processes.
the remainder of the paper is organized as follows. in section 2, we dene the
contours of trustworthy ai principles. in section 3, we explore the proposed eu
articial intelligence act (aia) that intends to operationalize and implement
rigorous risk-based prescriptive processes for ensuring a culture of trustworthy
ai. in section 4, we map the relationship between rds and trustworthy ai,
including a discussion of challenges associated with contextualizing ai fairness
as a foundation for trustworthy ai. in section 5, we discuss the applications and
benets of process mining as an important tool to enable organizations to make
data-driven decisions relating to the obligations and conformance requirements
inherent in the proposed eu ai regulation.
2 trustworthy ai
surveys reveal an undercurrent of pervasive distrust of ai systems. cathy o'neil,
a leading advocate for ai algorithmic fairness, highlighted three main reasons
behind consumer distrust of ai: opacity ,scale, and damage [12]. fairness is the
foundation for trustworthy ai. it is the connective tissue that binds together
the principles of ethical use, interpretability, transparency, accountability, and
condentiality that engenders trust and promotes the use of ai for social good.
trustworthy ai is a governance framework designed to mitigate potential adverse
impacts on consumers as ai is poised to profoundly and indelibly change our
lives. as mentioned in [17], trustworthy ai is changing the dynamic between
user and system into a relationship.
2.1 achieving trust in ai
trustworthy ai starts with human agency and autonomy. trust in ai systems
is enhanced when there is a human-in-the-loop who monitors the overall per-
formance of ai systems and when circumstances dictate, remediates potential
adverse outcomes. trust in ai is strengthened by giving users the ability to
make informed decisions about the impact of ai on their personal and economic
well-being.
ai is perceived by consumers to be a black box . data inputs to the ai systems,
their learning models, and how they arrive at decisions are neither visible, nortrustworthy ai and pm: challenges and opportunities 3
understood by consumers. furthermore, many ai developers defensively protect
their algorithms as proprietary and a competitive dierentiator. interpretability
andexplainability of ai are two important elements that strengthen trust in ai.
interpretability of ai provides insight into the cause and eect between inputs
and outputs of an ai system and how ai predicts outcomes. explainability of
ai goes one step further by providing users with not only insight into how ai
models work but also traceability of ai decisions and documentation relating
to the process of data gathering, labeling, and methods used for training ai
algorithms.
consumers have limited recourse to hold ai developers accountable for the
adverse impacts of ai systems. while there is sectoral legislation, e.g., section 5
of the ftc (federal trade commission) act4, available for consumers to rem-
edy disparate treatment attributable to ai systems it is an onerous process to
prevail. moreover, for the disparate impact, the burden of proof requires statis-
tical analysis that a protected class is treated dierently from others, which is
hardly something that would be accessible to average consumers. for these rea-
sons, accountability, including redress mechanisms in the event of demonstrated
harmful impact need to be addressed to achieve trust in ai.
2.2 the emergence of trustworthy ai principles
we can see eorts being made, to varying degrees, that recognize and deal with
issues relating to trust in ai by the data sciences community (see section 4),
standards organizations, e.g., ieee [16], nist (national institute of standards
and technology) [13], and by public sector organizations.
in 2019, oecd member countries adopted oecd council recommendation
on articial intelligence5consisting of ve principles of human centered val-
ues of fairness of ai, inclusive investments in ai, transparency, accountability,
and robustness of ai systems. the oecd recommendations were subsequently
endorsed by the g20 with particular reference to the view that the \digital so-
ciety must be built on trust among all stakeholders including governments, civil
society, international organizations, academics, and businesses through sharing
common values and principles including equality, justice, transparency, and ac-
countability taking into account the global economy and interoperability".
while trustworthy ai principles serve as a helpful framework, they are just
that. adherence to trustworthy ai is fragmented at best and they lack eec-
tive enforcement mechanisms to safeguard against potentially harmful impacts.
for this reason, the momentum has shifted towards the regulation of ai: \the
calls for modest regulation that lets industry take the lead are part of a failed
regulatory philosophy, one that saw its natural experiment over the past several
decades come up lacking. ai is too important and too promising to be governed
in a hands-o fashion, waiting for problems to develop and then trying to x
them after the fact".6
4https://www.federalreserve.gov/boarddocs/supmanual/cch/ftca.pdf
5https://legalinstruments.oecd.org/en/instruments/oecd-legal-0449
6https://www.brookings.edu/research/ai-needs-more-regulation-not-less/4 andrew pery et al.
3 the proposed eu regulation of ai
on april 20, 2021 the european commission released the proposal for the reg-
ulation of articial intelligence7, the ambition of which is to balance the socio-
economic benets of ai and new risks or negative consequences for individuals
or society. the proposed articial intelligence act (aia) takes a risk-based
approach to regulate ai by fostering an \ecosystem of trust that should give
citizens the condence to take up ai applications and give companies and pub-
lic organisations the legal certainty to innovate using ai". in the following, we
demonstrate ve governing principles for trustworthy ai proposed by aia.
3.1 scope of the proposed regulation
the proposed aia applies to all providers, i.e., natural or legal persons, public
authorities, agencies, or any other body that develops an ai system, that places
or makes available on the market or puts into service ai systems or services in
the eu (cf. article 3). the aia also assigns responsibility to users, importers,
distributors, and operators who make use of or make substantial modications
to the functionality and performance of ai systems (cf. article 26-29). the ge-
ographic scope for the aia will operate irrespective of whether such providers
are established in the eu or a third country, and so will cover where the system
users are in the eu or the output of the systems is used in the eu (cf. article 2).
ai systems under the regulation encompass a wide range of methods and algo-
rithms including supervised, unsupervised, and reinforcement machine learning
for a given set of human-dened objectives that generate outputs such as con-
tent, predictions, recommendations, or decisions inuencing the environments
they interact with (cf. article 3).
3.2 risk-based approach
the foundation of the aia is a risk-based approach that classies ai systems
into three categories based on a combination of factors that include the intended
purpose, the number of impacted persons, and the potential risk of harms (cf.
article 5-7):
{prohibited ai: systems that use subliminal techniques that cause physio-
logical or psychological harm, exploit vulnerable groups, eectuate social
scoring by public authorities that may result in discrimination or unfavor-
able treatment, and remote biometric systems used by law enforcement in
public spaces (subject to well-dened exceptions) (cf. article 5).
{high risk: annex iii provides a list of systems that are used in critical in-
frastructures, educational or vocational training, human resources, essential
private and public services, law enforcement, migration, asylum and border
control management, and administration of justice and democratic processes
(cf. article 7).
7https://ec.europa.eu/commission/presscorner/detail/en/ip_21_1682trustworthy ai and pm: challenges and opportunities 5
{low risk: while not explicitly named (we use the term low risk of our own
choosing), by default, all systems not categorized as prohibited orhigh-risk .
providers of such systems are encouraged to institute responsible use of ai
best practices on a voluntary basis (cf. article 69).
3.3 promote fair and trustworthy ai best practices
the aia sets forth a comprehensive legislative mandate to ensure fairness in the
application of ai systems that safeguards fundamental human values and pro-
motes socio-economic rights. some of these mandates are as follows: obligation
on providers to implement appropriate risk management measures throughout
the entire lifecycle of ai systems (cf. article 9), rigorous data governance pro-
cesses (cf. article 10), technical documentation, and record-keeping processes to
enable monitoring of compliance (cf. article 11-12), transparency that enables
full interpretation of outputs (cf. article 13), and human-in-the-loop oversight
(cf. article 14).
3.4 transparency and accountability
according to the aia, providers of ai systems will be required to implement
a range of processes to ensure full transparency into and accountability for ai
systems (cf. article 19-23) such as (1) conformity assessment and certication
processes, (2) auditability, including accessible event logs, and (3) explainabil-
ity, potentially to coordinate with the human-in-the-loop for adjudication and
remediation.
3.5 enforcement
the aia incorporates an onerous enforcement mechanism that even surpasses
the nes under the gdpr (cf. article 71). some examples are as follows: up to
e10m or 2% of the total worldwide annual turnover for the supply of incorrect,
incomplete or misleading information to the authorities, up to e20m or 4% of
the total worldwide annual turnover for non-compliance with any other aia
requirement or obligation, and up to e30m or 6% of the total worldwide annual
turnover for violations of prohibited practices.
while the proposed aia is far from ratication and still subject to vigor-
ous debate within the eu parliament and council, the momentum towards its
adoption is inevitable. like the gdpr, the aia will serve as a model for other
jurisdictions that will seek to nally exert control over what has been the un-
regulated, hyperbolic growth of ai across the globe.
4 responsible data science and trustworthy ai
responsible data science (rds) is a discipline that is inuential in shaping
trustworthy ai best practices. rds refers to the collection of techniques and6 andrew pery et al.
fig. 1: the data science pipeline facing the four fact challenges [2].
approaches trying to reap the benets of data science and big data while ensuring
fairness ,accuracy ,condentiality and transparency [2]. to minimize adverse ai
outcomes of ai the role of rds is to: (1) avoid unfair conclusions even if they
are true, i.e., the fairness principle, (2) answer questions with a guaranteed level
of accuracy, i.e., the accuracy principle, (3) answer questions without revealing
secrets, i.e., the condentiality principle, and (4) clarify answers such that they
become indisputable, i.e., the transparency principle.
rds applies a methodology throughout the entire life cycle of information
to support trustworthy ai best practices by applying these four principles of
fairness, accuracy, condentiality, and transparency to the data science pipeline
resulting in rigorous data governance as illustrated in figure 1.
rds delivers a robust framework for the ethical design of ai systems that
addresses the following key areas: (1) unbiased outcomes through the applica-
tion of appropriate fairness constraints to the training data, (2) algorithmic
outcomes interpreted in a manner that is meaningful to end users, (3) resilience
in how ai systems deliver accurate results and respond to change in inputs, (4)
accountability for the system's outcomes, and (5) safeguarding the conden-
tiality of training data through privacy enhancing measures. however, providing
each aspect of rds has its own challenges from contextualizing the aspect to
implementing it in data science and ai systems. in [6], the authors describe the
challenges regarding the condentiality aspect for process mining which combines
process and data science. in the following, we provide the challenges regarding
thefairness aspect.
4.1 contextualizing fairness in ai systems: challenges
the idea of fairness is somewhat amorphous. at its highest level of abstraction,
fairness is a normative concept that comes from our conscience. dator denes
a fair system as follows: \what is fairness then? we all have desires and wetrustworthy ai and pm: challenges and opportunities 7
want people to treat us according to those desires. we also know that people
around us have similar desires and want to be treated accordingly. fairness is
closely related to fair play so it seems logical to conclude that a fair system is
a system where everybody is treated in a similar way" [4]. there are a number
of challenges associated with contextualizing and applying such a high level of
abstraction to a more concrete algorithmic ai fairness framework.
first, fairness may be inuenced by cultural, sociological, economic, and legal
considerations. what may be considered as fair in one culture may be perceived
as unfair in another. unequal distribution of opportunity may require the appli-
cation of distributive fairness that levels the playing eld. for example, in the
context of credit applications, there ought to be an equal probability of loan
eligibility by ensuring that ai algorithmic outcomes do not discriminate against
members of protected groups [3]. there are other instances where the application
of corrective fairness may be necessary, for example, to remedy adverse impacts
in the administration of justice, housing, education, and employment.
second, equality does not necessarily result in the fairness of outcomes. while
under human rights legislations disparate treatment on the basis of race, gen-
der, nationality, disability, and sexual orientation is prohibited there may still
be instances of adverse outcomes, based on other facially-neutral variables that
cause a disparate impact, i.e., unintentional discrimination [5]. consider ama-
zon's free same day delivery service based on an ai algorithm that included
attributes, such as distance to the nearest fulllment center, local demand in
designated zip code areas, and frequency distribution of prime members to de-
termine protable locations for free same-day delivery. the algorithm was found
to be biased against minorities even though race was deemed not to be a factor
in the determination of same day delivery, and minority residents in the selected
zip codes were about half as likely to be eligible as white residents.8
the third challenge is balancing algorithmic fairness with fairness outcomes
[10]. in this context, fairness encompasses policy and legal considerations, and
leads us to ask: what ought to be fair? for example, in the context of hiring
practices, what ought to be a fair percentage of women in management positions
that ai algorithms should incorporate as thresholds to promote gender parity?
the fourth challenge relates to trade-o in balancing demographic parity
with the utility of outcomes. for example, if ai algorithms remove disparate
impact in the incarceration of minorities, how would that impact broader policy
considerations such as the administration of justice?
finally, fairness implicates issues of power. before we can decide what is fair,
we need to decide who gets to decide that. the conundrum we must confront
is that the minority groups who are so typically the victims of algorithmic bias
are rarely given a seat at the table when it is time to dene what is fair. the
unfortunate result is that far too often, the denition of fairness is simply what
those already in power need it to be to maintain that power.
8https://eu.usatoday.com/8 andrew pery et al.
4.2 implementing fairness: challenges for data scientists
fairness constraints need to be considered in the context of specic use cases
and for desired outcomes. bias may be introduced at various levels within an ai
system. training data may introduce proxies that discriminate. historical bias
may unconsciously result in adverse outcomes, for example through word embed-
dings [4]. representation bias through under or, over representation of training
data may produce disparate impacts. the algorithms may not suciently adjust
for fairness constraints. inadequate testing for disparate treatment and impact
may have adverse consequences for protected groups. while some argue that ai
algorithms in fact minimize bias there is compelling evidence that they can and
often amplify biases. examples span facial recognition, criminal justice, hiring
practices, and loan approvals [9].
regardless of any contextualization, any denition, and any implementation
approach of the fairness which is the cornerstone for trustworthy ai, what is
essential is to gain visibility to and remediate potential gaps in trustworthy ai
compliance processes. in the next section, we demonstrate how process mining
could play a role in fullling such requirements.
5 process mining for promoting trustworthy ai
compliance with the proposed eu aia requires an understanding of process
execution and interactions between multiple internal and external stakeholders,
risk assessment of diverse systems of record that incorporate ai systems, and
cooperation with various regulatory bodies and standards organizations.
the proposed ai regulation operationalizes and codies trustworthy ai prin-
ciples with prescribed mandates to institute appropriate data governance and
management practices . the governance mechanism is complex and requires hu-
man and systems-based interactions between diverse internal and external stake-
holders and eu and national regulators. monitoring conformance with aia is
delegated to national supervisory authorities, they are empowered to order com-
panies to take corrective actions, access all information, documentation, and
data required to enforce compliance with the proposed regulation.
given the complexity and variability of interactions implicit in achieving com-
pliance with the proposed regulation it is our contention that process mining can
be a valuable tool to help organizations gain visibility to various dimensions of
prescribed process ows stipulated by the regulation, accelerate the analysis of
how information ows, surface process bottlenecks, visualize interactions gener-
ated by event logs from disparate systems of record that may reveal areas of
compliance and reputational risks. process mining bridges the gap between data
science and process science using event data captured from dierent types of in-
formation systems [1]. it is a data-driven approach that enables organizations to
gain insight into interactions between people, systems, and organizations based
on \as-is" visualization of process execution.
there are many techniques and activities in the context of process mining.
however, the three main types of activities in process mining are process discov-trustworthy ai and pm: challenges and opportunities 9
ery,conformance checking , and enhancement . process discovery techniques take
an event log and discover a process model without using any other information.
conformance checking techniques take a process model and an event log of the
same process to check whether reality, as recorded in the event log, conforms to
the model and vice versa. enhancement techniques are used to extend or im-
prove a given process model using the information about the process recorded
in some event logs [1].
process mining can facilitate compliance with aia by many functionalities
such as: (1) surfacing ai regulatory compliance process gaps and uncertainties,
(2) capturing user interactions performing compliance tasks, (3) comparing
process execution variations, (4) highlighting compliance task outliers and er-
rors, (5) identifying potential root causes for improper execution, (6) real-time
monitoring of processes to ensure conformance to prescribed process execution
paths, and (7) triggering alerts in the event of non-compliant process tasks or
changes in conditions. furthermore, the aia proposed regulation is inherently
collaborative in nature wherein process execution spans across dierent organi-
zations.
as discussed in [11], in collaborative processes where dierent organizations
execute dierent parts of a shared process, the internal activities carried out
by each organization are beyond the control of the other collaborators resulting
in uncertainty regarding process execution. whenever there is uncertainty in a
process, there is a need for trust. hence, collaborative business processes are
especially trust-intensive. in such trust-intensive environments, process mining
can be used to clarify the ow of activity execution among several organizations.
compliance with aia constitutes a number of interdependent steps. perform-
ing these steps may involve variabilities in process execution paths and hand o
between dierent stakeholders and prescribed conformance obligations to meet
articles 16-23 and annex vii of the aia:
{step 1: r&d teams develop and bring to market ai systems in accordance
with the risk classication system dened by the proposed regulation. if it is
a high-risk ai system then a priori conformance assessment must be under-
taken and a declaration of conformity must be submitted to the appropriate
national supervisory authority. then the ai system may be placed on the
market.
{step 2: legal and compliance teams must institute compliance measures in
accordance with chapter 2 of the proposed regulation that ensures adherence
to data governance, accountability, transparency, accuracy, robustness, and
cybersecurity provisions.
{step 3: data science teams must undertake continuous monitoring of ai
systems, collect data on the system's operation and take corrective action
if needed. the post-market monitoring system must actively and systemat-
ically collect, document, and analyze relevant data provided by users.
{step 4: customer-facing functions such as sales, marketing, and support, are
responsible for providing clarity and certainty as to the expected ai system
inputs and outputs in a way that users are informed that they are interacting10 andrew pery et al.
fig. 2: process mining cadence to meet aia prescriptive compliance obligations.trustworthy ai and pm: challenges and opportunities 11
with an ai system, augmented with human oversight who monitor their
operation and be able to decide, to override or reverse the output of the
high-risk ai system.
{step 5: implementation of a quality management system with auditable and
traceable documentation relating to the techniques, procedures for the de-
sign, of the high-risk ai systems, including procedures for data management,
data analysis, data labeling, data storage, data aggregation, data retention
and report serious incidents that may result in adverse outcomes.
figure 2 further maps the compliance steps, the obligation provisions of the
aia, and process mining functionality to support trustworthy ai. the gure
illustrates how process mining techniques can facilitate aia obligations. the
fact challenges of rds are also taken into consideration in process mining
as a subdiscipline called responsible process mining (rpm) which is recently
receiving increasing attention [15,14,7,8].
6 conclusion
trustworthy ai engenders a climate of trust essential for achieving sustainable
competitive advantages in an intensely competitive environment where the ap-
plication of ai is a disruptive force. the proposed eu regulation of ai is a
comprehensive prescriptive measure which imposes onerous obligations, redress
mechanisms on ai developers and businesses deploying ai systems. to mitigate
compliance, reputational, and business risks process mining is poised to provide
a data-driven approach to discover how existing trustworthy ai compliance pro-
cesses work, surface and remediate process bottlenecks, visualize dierent path-
ways of process execution and identify and remediate variations from prescribed
protocols. process mining can be a useful toolbox for ensuring that certain ai
systems are designed and developed in accordance with common necessary re-
quirements before they are put on the market and operationalized through har-
monized technical standards.
acknowledgments
funded under the excellence strategy of the federal government and the l ander.
we also thank the alexander von humboldt stiftung for supporting our research.
references
1. van der aalst, w.m.p.: process mining - data science in action, second edition.
springer (2016). https://doi.org/10.1007/978-3-662-49851-4
2. van der aalst, w.m.p.: responsible data science: using event data in a "people
friendly" manner. in: hammoudi, s., maciaszek, l.a., missiko, m., camp, o.,
cordeiro, j. (eds.) enterprise information systems - 18th international confer-
ence, iceis 2016, rome, italy, april 25-28, 2016, revised selected papers. lec-
ture notes in business information processing, vol. 291, pp. 3{28. springer (2016).
https://doi.org/10.1007/978-3-319-62386-3 112 andrew pery et al.
3. binns, r.: on the apparent conict between individual and group fairness. in:
proceedings of the 2020 conference on fairness, accountability, and transparency.
pp. 514{524 (2020)
4. dator, j.: chapter 3. what is fairness?, pp. 19{34. university of hawaii
press (2006). https://doi.org/doi:10.1515/9780824841966-004, https://doi.org/
10.1515/9780824841966-004
5. dwork, c., hardt, m., pitassi, t., reingold, o., zemel, r.: fairness through
awareness. in: proceedings of the 3rd innovations in theoretical computer sci-
ence conference. p. 214{226. itcs '12, association for computing machinery,
new york, ny, usa (2012). https://doi.org/10.1145/2090236.2090255, https:
//doi.org/10.1145/2090236.2090255
6. elkoumy, g., fahrenkrog-petersen, s.a., sani, m.f., koschmider, a., mannhardt,
f., von voigt, s.n., raei, m., von waldthausen, l.: privacy and condentiality in
process mining - threats and research challenges. corr abs/2106.00388 (2021),
https://arxiv.org/abs/2106.00388
7. elkoumy, g., pankova, a., dumas, m.: mine me but don't single me out: dif-
ferentially private event logs for process mining. corr abs/2103.11739 (2021),
https://arxiv.org/abs/2103.11739
8. fahrenkrog-petersen, s.a., van der aa, h., weidlich, m.: pripel: privacy-
preserving event log publishing including contextual information. in: business pro-
cess management - 18th international conference, bpm. lecture notes in com-
puter science, vol. 12168, pp. 111{128 (2020)
9. grother, p., ngan, m., hanaoka, k.: face recognition vendor test part 3: demo-
graphic eects (2019)
10. kleinberg, j., ludwig, j., mullainathan, s., rambachan, a.: algorithmic fairness.
in: aea papers and proceedings. vol. 108, pp. 22{27 (2018)
11. m uller, m., ostern, n., koljada, d., grunert, k., rosemann, m., k upper, a.:
trust mining: analyzing trust in collaborative business processes. ieee access 9,
65044{65065 (2021). https://doi.org/10.1109/access.2021.3075568
12. o'neil, c.: weapons of math destruction: how big data increases inequality and
threatens democracy. crown (2016)
13. phillips, p., hahn, a., fontana, p., broniatowski, d., przybocki, m.: four princi-
ples of explainable articial intelligence (2020)
14. raei, m., van der aalst, w.m.p.: group-based privacy preservation
techniques for process mining. data knowl. eng. 134, 101908 (2021).
https://doi.org/10.1016/j.datak.2021.101908
15. raei, m., van der aalst, w.m.p.: privacy-preserving continuous event data pub-
lishing. corr abs/2105.11991 (2021), https://arxiv.org/abs/2105.11991
16. shahriari, k., shahriari, m.: ieee standard review | ethically aligned design: a
vision for prioritizing human wellbeing with articial intelligence and autonomous
systems. in: 2017 ieee canada international humanitarian technology confer-
ence (ihtc). pp. 197{201 (2017). https://doi.org/10.1109/ihtc.2017.8058187
17. stanton, b., jensen, t.: trust and articial intelligence (2021-03-02 05:03:00 2021),
https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=931087