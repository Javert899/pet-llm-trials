process mining and visual analytics: breathing life
into business process models
wil m.p. van der aalst1, massimiliano de leoni1, and arthur h.m. ter hofstede1;2
1eindhoven university of technology, eindhoven, the netherlands
{w.m.p.v.d.aalst,m.d.leoni }@tue.nl
2queensland university of technology, brisbane, australia
a.terhofstede@qut.edu.au
abstract. process mining and visual analytics are two disciplines that emerged
over the last decade. the goal of process mining is to use event data to extract
process-related information, e.g., to automatically discover a process model by
observing events recorded by some information system or to check the confor-
mance of a process model with actual process executions. the spectacular growth
of event data provides unprecedented opportunities and has triggered the devel-
opment of a range of process mining techniques over the last decade. despite
the wonderful capabilities of existing algorithms, it has become clear that human
judgment is essential in ﬁnding interesting and relevant patterns. visual analytics
combines automated analysis with interactive visualizations so as to allow deci-
sion makers to combine their ﬂexibility, creativity, and background knowledge to
come to an effective understanding of situations in the context of large data sets.
this paper combines ideas from these two disciplines (i.e., process mining and
visual analytics). in particular, we focus on replaying event logs on “maps” (i.e.,
visual representations of a process from a particular angle). if the visualization
of a business process at a particular moment corresponds to “photo”, then the
(iterative) replay of an event log can be seen as a “movie”. this way event logs
can be used to “breathe life” into otherwise static process models. the insights
obtained from such visualizations can be used to improve processes by removing
inefﬁciencies and addressing non-compliance.
key words : process mining, visual analytics, business intelligence, business process
management
1 introduction
process mining provides a new means to improve processes in a variety of application
domains. there are two main drivers for this new technology. on the one hand, more
and more events are being recorded thus providing detailed information about the his-
tory of processes. despite the omnipresence of event data, most organizations diagnose
problems based on ﬁction rather than facts. on the other hand, vendors of business pro-
cess management (bpm) and business intelligence (bi) software have been promising
miracles. although bpm and bi technologies received lots of attention, they did not live
up to the expectations raised by academics, consultants, and software vendors. processmining is able to effectively overcome these limitations by bridging the gap between
process modeling and data mining.
there are basically three types of process mining. the ﬁrst type of process mining is
discovery . a discovery technique takes an event log and produces a model without us-
ing any a priori information. the second type of process mining is conformance . here,
an existing process model is compared with an event log of the same process. confor-
mance checking can be used to check if reality, as recorded in the log, conforms to the
model and vice versa [1, 2]. the third type of process mining is enhancement . here,
the idea is to extend or improve an existing process model using information about the
actual process recorded in some event log [1]. whereas conformance checking mea-
sures the alignment between model and reality, this third type of process mining aims
at changing or extending the a priori model. one type of enhancement is repair , i.e.,
modifying the model to better reﬂect reality. another type of enhancement is extension ,
i.e., adding a new perspective to the process model by cross-correlating it with the log.
an example is the extension of a process model with performance data. for instance,
by using timestamps in the event log it is possible to highlight bottlenecks.
over the last decade event data has become readily available and process mining
techniques have matured. moreover, process mining algorithms have been implemented
in various academic and commercial systems. today, there is an active group of re-
searchers working on process mining and it has become one of the “hot topics” in bpm
research. moreover, there is a huge interest from industry in process mining. more and
more software vendors started adding process mining functionality to their tools. the
open-source process mining tool prom (cf. processmining.org ) is widely used
all over the globe and provides an easy starting point for practitioners, students, and
academics.
the amount of data recorded in various domains has been growing exponentially,
thereby following moore’s law. this offers opportunities for algorithmic techniques,
but also creates new challenges. one of the challenges is to combine purely automatic
analysis and visualization methods. while automatic algorithms for process mining and
analysis are certainly needed to ﬁlter out irrelevant data and to produce preliminary re-
sults, visual inspection, domain knowledge, human judgment and creativity are needed
for proper interpretation of the results. visual analytics provides an answer to these
problems by proposing a tight integration between automatic techniques and visual-
ization. the term visual analytics was coined by jim thomas to mean “the science
of analytical reasoning facilitated by visual interactive interfaces” [3]. over time, the
scope of visual analytics broadened. now the term refers to a multidisciplinary ﬁeld
that combines elements from human-computer interaction, geo-spatial and temporal
data processing, data analysis and statistics [4, 5]. a more recent deﬁnition is “visual
analytics combines automated analysis techniques with interactive visualizations for an
effective understanding, reasoning and decision making on the basis of very large and
complex data sets” [5].
figure 1 positions visual analytics. traditionally, visual analytics combined visual-
ization with data mining techniques [5]. however, given the maturity of process mining
techniques and the interest in business process management (bpm) and business intel-
ligence (bi), it makes sense to develop visual analytics based on process mining. visualdata-
related
questions
process-
related
questions
process
mining
visualization
visualanalyticsdata
miningfig. 1. visual analytics combines analytical techniques (e.g., data mining) and visualization.
whereas data mining aims to answer data-related questions, process mining aims to answer
process-related questions.
analytics have established a synergy between visualization and data mining. now it is
time to realize similar synergetic effects between visualization and process mining. ex-
amples such as the dotted chart and the fuzzy miner illustrate the importance of the re-
lation between process mining and visualization. the dotted chart provides a helicopter
view of the process and is used as the starting point for any process mining project [1].
in a dotted chart, each event is depicted as a colored dot in a two dimensional plane.
this is used to ﬁlter the event log and often immediately provides interesting insights.
another example is the so-called fuzzy miner [6] which interactively creates a model
using the metaphor of a map. in this approach process models are used as if they are
geographic maps (e.g., road maps or hiking maps). depending on the map, insigniﬁcant
roads and cities can be removed and streets and suburbs can be amalgamated into bigger
structures.
fig. 2. the focus of this paper is on the visualization of event-related data projected on models
obtained through process mining.
figure 2 shows a high-level characterization of visual analytics based on process
mining. assume that one has an event log, i.e., large collections of events ordered in
time. the events in this log, i.e., the input data, can be visualized directly (e.g., using
dotted charts). event logs can also be converted into models (e.g., process models, or-
ganizational models, decision models, or predictive models), which can be visualized
in a static manner. for instance, the model can show the discovered process, e.g. rep-resented by an uml activity diagram or bpmn diagram. however, the event log and
model can also be combined and visualized. for example, the event log can be replayed
on a discovered process model. in general, the concept of model can be interpreted in a
broader sense: in principle, any ﬂat image can be considered as a model. in fact, models
can take different forms, such as a geographic map, a gantt chart, an organizational
diagram, a social network, a depiction of various deadlines and several more.
in general a model, discovered or designed by hand, can be interpreted as a map
which focuses on showing a speciﬁc view on the process (the process control ﬂow, the
organizational structure, the geo-spatial or temporal characteristics of the process and
its composing tasks, etc.). after each event, the process is in a particular state, which
can be projected onto such deﬁned maps. for instance, if the map shows the chart of the
different ofﬁces, the state is projected as a set of dots, one per task; each dot is located
onto the ofﬁce in the map where the respective task needs to be executed. vice versa, if
the map is an organization chart, every dot represents one task and is placed on the role
that participants need to play in order to execute it.
the projection onto maps is a kind of photograph of the process, seen from a cer-
tain viewpoint (e.g., the organization or the geographic perspective). since such a pho-
tograph is available after each event, for each map considered, it is possible to create
a“movie” by showing the photographs in succession. movies can be played at differ-
ent speeds and users are allowed to switch from one “movie” to another at any time.
through such “movies”, process analysts can evaluate the performance of past process
instances from different views. the amount of information shown in the “movie” is
customizable (e.g., a process analyst may be interested to visualize all the work per-
formed by all participants or simply that of speciﬁc individuals). indeed, by interacting
with the user interface, the analysts can “drill down” into the piece of information in
which they are interested (e.g., they may want to get a deeper insight into the work
performed by a speciﬁc participant) or “roll up” to have an aggregated view (e.g., the
work performed by a larger group of participants). when rolling up, some information
is automatically ﬁltered out to simplify the interpretation of the “movie”. using this
movie metaphor, process analysts can see behaviors and issues that would remain un-
detected using purely algorithmic techniques. for instance, let us consider the movie
related to an organization chart: if the dots that correspond to work that needs to be
done by people having a speciﬁc role seem to be cluttering the diagram during movie
replay, then probably process performance can be improved by assigning that role to a
larger number of participants.
although figure 2 may suggest the application of visual analytics to process mining
to be a waterfall approach, it is actually iterative. the visualization of models and the
projection of the current and past states onto maps can lead to the desired information.
nonetheless, it is more probable that the preliminary results need to be reﬁned and,
hence, some parameters need further tuning. for instance, it may be the case that the
event ﬁltering, the process mining techniques or, simply, the visualization need to be ad-
justed further. therefore, several iterations are, in general, needed, alternating between
fully-automatic techniques and visualization approaches.
the remainder of this paper is organized as follows. section 2 provides an overview
of process mining using a concrete example. section 3 shows the analogy between acertain type of process representation and cartographic maps, pointing out the impor-
tance of the visualization of the different business process views. this section illustrates
initial ideas using the fuzzy mining technique and then shows how the discovered pro-
cess models can be used as maps for which movies are constructed. section 4 describes
how to use information in the log to a posteriori build the photographs, i.e. the pro-
jections of the different states onto maps, and to play the photographs in succession
for obtaining the movies. by playing these movies, process analysts can evaluate past
process executions from different perspectives encoded in corresponding maps so as to
ﬁnd issues and bottlenecks. section 5 brieﬂy describes existing tool support for process
mining, whereas related work is discussed in section 6. finally, section 7 concludes
this paper by outlining future research directions.
2 process mining
to introduce the basic idea of process mining, we use an example taken from [1]. ta-
ble 1 shows just a fragment of a possible event log . each line captures one event . events
are already grouped per case. each case corresponds to a process instance , i.e., one run
of the process from beginning to end. in table 1, each case corresponds to the handling
of a request for compensation. case 1 has ﬁve associated events. the ﬁrst event of case
1 is the execution of activity register request by pete on december 30th 2010. table 1
also shows a unique id for this event: 35654423. this is merely used for the identiﬁca-
tion of the event, e.g., to distinguish it from event 35654483 that also corresponds to the
execution of activity register request (ﬁrst event of second case). table 1 shows a date
and a timestamp for each event. in some events logs this information is more coarse-
grained and only a date or partial ordering of events is given. in other logs there may
be more elaborate timing information also showing when the activity was started, when
it was completed, and sometimes even when it was offered to the resource. the times
shown in table 1 should be interpreted as completion times. in this particular event
log, activities are considered to be atomic and the table does not reveal the duration of
activities. in the table, each event is associated to a resource. in some event logs this
information may be missing. in other logs more detailed information about resources
may be stored, e.g., the role a resource has or elaborate authorization data. the table
also shows the costs associated with events. this is an example of a data attribute. there
may be many other data attributes. for example, in this particular example it would be
interesting to record the outcome of the different types of examinations and checks.
another data element that could be useful for analysis is the amount of compensation
requested. this could be an attribute of the whole case or stored as an attribute of the
register request event.
depending on the process mining technique employed and the questions at hand,
only part of the information in the event log is used. the minimal requirements for
process mining are that any event can be related to both a case and an activity and
that events within a case are ordered. hence, the “case id” and “activity” columns in
table 1 represent the bare minimum for process mining. by projecting the information
in these two columns we obtain the more compact representation shown in table 2. in
this table, each case is represented by a sequence of activities also referred to as a trace .case id event id properties
timestamp activity resource cost : : :
35654423 30-12-2010:11.02 register request pete 50 : : :
1 35654424 31-12-2010:10.06 examine thoroughly sue 400 : : :
35654425 05-01-2011:15.12 check ticket mike 100 : : :
35654426 06-01-2011:11.18 decide sara 200 : : :
35654427 07-01-2011:14.24 reject request pete 200 : : :
35654483 30-12-2010:11.32 register request mike 50 : : :
2 35654485 30-12-2010:12.12 check ticket mike 100 : : :
35654487 30-12-2010:14.16 examine casually pete 400 : : :
35654488 05-01-2011:11.22 decide sara 200 : : :
35654489 08-01-2011:12.05 pay compensation ellen 200 : : :
35654521 30-12-2010:14.32 register request pete 50 : : :
3 35654522 30-12-2010:15.06 examine casually mike 400 : : :
35654524 30-12-2010:16.34 check ticket ellen 100 : : :
35654525 06-01-2011:09.18 decide sara 200 : : :
35654526 06-01-2011:12.18 reinitiate request sara 200 : : :
35654527 06-01-2011:13.06 examine thoroughly sean 400 : : :
35654530 08-01-2011:11.43 check ticket pete 100 : : :
35654531 09-01-2011:09.55 decide sara 200 : : :
35654533 15-01-2011:10.45 pay compensation ellen 200 : : :
35654641 06-01-2011:15.02 register request pete 50 : : :
4 35654643 07-01-2011:12.06 check ticket mike 100 : : :
35654644 08-01-2011:14.43 examine thoroughly sean 400 : : :
35654645 09-01-2011:12.02 decide sara 200 : : :
35654647 12-01-2011:15.44 reject request ellen 200 : : :
35654871 06-01-2011:15.02 register request mike 50 : : :
6 35654873 06-01-2011:16.06 examine casually ellen 400 : : :
35654874 07-01-2011:16.22 check ticket mike 100 : : :
35654875 07-01-2011:16.52 decide sara 200 : : :
35654877 16-01-2011:11.47 pay compensation mike 200 : : :
35654711 06-01-2011:09.02 register request ellen 50 : : :
5 35654712 07-01-2011:10.16 examine casually mike 400 : : :
35654714 08-01-2011:11.22 check ticket pete 100 : : :
35654715 10-01-2011:13.28 decide sara 200 : : :
35654716 11-01-2011:16.18 reinitiate request sara 200 : : :
35654718 14-01-2011:14.33 check ticket ellen 100 : : :
35654719 16-01-2011:15.50 examine casually mike 400 : : :
35654720 19-01-2011:11.18 decide sara 200 : : :
35654721 20-01-2011:12.48 reinitiate request sara 200 : : :
35654722 21-01-2011:09.06 examine thoroughly sue 400 : : :
35654724 21-01-2011:11.34 check ticket pete 100 : : :
35654725 23-01-2011:13.12 decide sara 200 : : :
35654726 24-01-2011:14.56 reject request mike 200 : : :
: : : : : : : : : : : : : : : : : : : : :
table 1. a fragment of some event log: each line corresponds to an event.case id trace
1 ⟨a; b; d; e; h ⟩
2 ⟨a; d; c; e; g ⟩
3 ⟨a; c; d; e; f; b; d; e; g ⟩
4 ⟨a; d; b; e; h ⟩
5 ⟨a; c; d; e; g ⟩
6 ⟨a; c; d; e; f; d; c; e; f; b; d; e; h ⟩
: : : : : :
table 2. a more compact representation of the log shown in table 1: a=register request ,b=
examine thoroughly ,c=examine casually ,d=check ticket ,e=decide ,f=reinitiate request ,
g=pay compensation , and h=reject request .
for clarity the activity names have been transformed into single-letter labels, e.g., a
denotes activity register request .
process mining algorithms for process discovery can transform the information
shown in table 2 into process models. for instance, the process model in figure 3
can be the result of applying some basic process discovery technique [1]. for exam-
ple, theα-algorithm [7, 1] is able to discover a petri net based on a sequence of events.
heuristic mining [8, 1] is an enhanced approach that can deal with noisy logs, in the
sense that it is able to distinguish between low frequency behaviors, i.e. the noise, and
high frequency ones. indeed, many algorithms consider all behaviors in the same way
and, hence, the mined model allows for many behaviors, of which some are occurring
many times and others a few times in the event log. some of these infrequent behaviors
recorded in the log can be the result of erroneous process performances or of excep-
tional conditions which required the activation of special procedures. the presence of
these infrequent behaviors can compromise model readability. when showing the main-
stream behavior the diagram should not be cluttered by infrequent/exceptional behavior.
the genetic process mining approach presented in [9, 1] proposes algorithms that incre-
mentally try to ﬁnd the most suitable process model. in the ﬁrst step, possible suitable
process models are generated and their ﬁtness is computed. the models that ﬁt best are
kept for the next step; the least ﬁtting models are removed. some of the best models are
merged and mutated through speciﬁc operators and the models resulting from crossover
and mutation are considered for the next step. the algorithm progresses through poten-
tially thousands of iterations and stops when no further improvements can be found.
then the best ﬁtting process model is presented as the ﬁnal result. the generic min-
ing is robust against noise (just like heuristic mining) and can be combined with other
approaches. genetic mining can be very time consuming. however, the approach can
easily be parallelized using a grid infrastructure.
let us consider again the model in figure 3. given an event log
l={⟨a,b,d,e,h ⟩,⟨a,d,c,e,g ⟩,⟨a,c,d,e,f,b,d,e,g ⟩,⟨a,d,b,e,h ⟩,⟨a,c,d,e,g ⟩,
⟨a,c,d,e,f,d,c,e,f,b,d,e,h ⟩}(i.e., table 2), most process discovery algorithms will
construct this model (although the representation may be different). it is easy to check
that all six traces in lﬁt(i.e., conform to) the model since they are are possible inthe model. typically, the trace conformance is based on the principle of replay , i.e.,
the event log is replayed on the process model. the events in the traces are mapped
to a task in the process model; when a trace is replayed, events are sorted by their
timestamp. tasks that belong to logged events in the trace are executed in the order
recorded. if the trace does not ﬁt completely, then some tasks need to be executed
according to the log, while this is not possible according to the model. for instance,
a task is not allowed to occur since some tasks that precede in the model have not
occurred in the event log. there are different ways to measure errors in the course of
replaying; see [1, 2] for metrics to measure the degree of ﬁtness of a trace with respect
to a process model.
fig. 3. a model that can be obtained by some basic process discovery technique. the discovered
model is based on the set of traces shown in table 2.
the process model shown in figure 3 also allows for traces not present in ta-
ble 2. for example, the traces ⟨a,d,c,e,f,b,d,e,g ⟩and⟨a,c,d,e,f,c,d,e,f,c,d,e,
f,c,d,e,f,b,d,e,g ⟩are also possible. this is a desired phenomenon as the goal is not
to represent just the particular set of example traces in the event log. process mining
algorithms need to generalize the behavior contained in the log to show the most likely
underlying model that is not invalidated by the next set of observations. one of the chal-
lenges of process mining is to balance between “overﬁtting” (the model is too speciﬁc
and only allows for the “accidental behavior” observed) and “underﬁtting” (the model
is too general and allows for behavior unrelated to the behavior observed) [1].
as explained in section 1, process mining is not limited to process discovery. event
logs can be used to check conformance and enhance existing models. moreover, differ-
ent perspectives may be taken into account. to illustrate this, let us ﬁrst consider the
event log shown in table 3. the ﬁrst six cases are as before. it is easy to see that case
7 with trace ⟨a,b,e,g ⟩is not possible according to the model in figure 3. the model
requires the execution of dbeforee, butddid not occur. this means that the ticket
was not checked at all before making a decision and paying compensation. confor-
mance checking techniques aim at discovering such discrepancies [2]. when checking
the conformance of the remainder of the event log it can be noted that cases 8 and 10
do not conform either. case 9 conforms although it is not identical to one of the earliercase id trace
1 ⟨a; b; d; e; h ⟩
2 ⟨a; d; c; e; g ⟩
3 ⟨a; c; d; e; f; b; d; e; g ⟩
4 ⟨a; d; b; e; h ⟩
5 ⟨a; c; d; e; g ⟩
6 ⟨a; c; d; e; f; d; c; e; f; b; d; e; h ⟩
7 ⟨a;b;e;g⟩
8 ⟨a;b;d;e⟩
9 ⟨a; d; c; e; f; d; c; e; f; b; d; e; h ⟩
10 ⟨a;c;d;e;f;b;d;g⟩
table 3. another event log: cases 7, 8, and 10 are not possible according to figure 3.
traces. trace ⟨a,b,d,e ⟩(i.e. case 8) has the problem that no concluding action was
taken (rejection or payment). trace ⟨a,c,d,e,f,b,d,g ⟩(case 10) has the problem that
the airline paid compensation without making a ﬁnal decision. note that conformance
can be viewed from two angles: (a) the model does not capture the real behavior (“the
model is wrong”) and (b) reality deviates from the desired model (“the event log is
wrong”). the ﬁrst viewpoint is taken when the model is supposed to be descriptive , i.e.,
capture or predict reality. the second viewpoint is taken when the model is normative ,
i.e., used to inﬂuence or control reality.
the original event log shown in table 1 also contains information about resources,
timestamps and costs. such information can be used to discover other perspectives,
check the conformance of models that are not solely control-ﬂow models, and to extend
models with additional information. for example, one could derive a social network
based on the interaction patterns between individuals. the social network can be based
on the “handover of work” metric, i.e., the more often individual xperformed an activity
that is causally followed by an activity performed by individual y, the stronger the
relation between xandyis [10].
figure 4 illustrates in what ways a control-ﬂow oriented model can be extended
with the other perspectives (data perspective, resource/organizational perspective, time
perspective). analysis of the event log shown in table 1 may reveal that sara is the
only one performing the activities decide andreinitiate request. this suggests that there
is a “manager role” and that sara is the only one having this role. activity examine
thoroughly is performed only by sue and sean. this suggests some “expert role” asso-
ciated to this activity. the remaining activities are performed by pete, mike and ellen.
this suggests some “assistant role” as shown in figure 4. techniques for organizational
process mining [10] will discover such organizational structures and relate activities to
resources through roles. by exploiting resource information in the log, the organiza-
tional perspective can be added to the process model. similarly, information on times-
tamps and frequencies can be used to add performance related information to the model.
figure 4 sketches that it is possible to measure the time that passes between an exam-
ination (activities borc) and the actual decision (activity e). if this time is remarkably
long, process mining can be used to identify the problem and discover possible causes.fig. 4. the process model extended with additional perspectives: the organizational perspective
(“what are the organizational roles and which resources are performing particular activities?”),
the case perspective (“which characteristics of a case inﬂuence a particular decision?”), and the
time perspective (“where are the bottlenecks in my process?”).
if the event log contains case-related information, this can be used to further analyze
the decision points in the process. for instance, through decision point analysis it may
be learned that requests for compensation of more than e800 tend to be rejected.
using process mining, the different perspectives can be cross-correlated to ﬁnd sur-
prising insights [1]. examples of such ﬁndings could be: “requests examined by sean
tend to be rejected more frequently”, “requests for which the ticket is checked after ex-
amination tend to take much longer”, “requests of less than e500 tend to be completed
without any additional iterations”. moreover, these perspectives can also be linked to
conformance questions. for example, it may be shown that pete is involved in relatively
many incorrectly handled requests.
3 process visualization: the map metaphor
models—discovered by process mining techniques or made by hand—can be seen as
the “maps” describing the operational processes of organizations. cartography evolved
over many centuries. today, there are standard techniques to create maps thereby ad-
dressing problems such as clearly representing desired traits, eliminating irrelevant de-
tails, reducing complexity, and improving understandability. generally, maps are of
high quality and can easily be understood by humans. moreover, modern car naviga-
tion systems (e.g., tomtom, garmin, and navigon), google maps, and mashups using
geo-tagging show innovative ways of using maps. all of this is stark contrast with thestate-of-the-art in business process modeling. accurate business process maps are typ-
ically missing. process models tend to be outdated and not aligned with reality. more-
over, unlike geographic maps, process models are typically not well understood by end
users.
process mining techniques—speciﬁcally process discovery and conformance
checking—can be used to improve the accuracy of maps. however, more accurate mod-
els are not necessarily better models. therefore, it is interesting to see what one can
learn from maps.
figure 5 shows a map. the map abstracts from less signiﬁcant roads and cities.
roads that are less important are not shown. a cut-off criterion could be based on
the average number of cars using the road per day. similarly, the number of citizens
could be used as a cut-off criterion for cities. for example, in figure 5 cities of less
than 50,000 inhabitants are abstracted from. maps also aggregate local roads and lo-
cal districts (neighborhoods, suburbs, centers, etc.) into bigger entities. figure 5, for
instance, shows eindhoven as a single dot while it consists of many roads, various dis-
tricts (strijp, gestel, woensel, gestel, etc.), and neighboring cities (e.g., veldhoven).
people interested in eindhoven can look at a city map to see more details.
fig. 5. road map of the netherlands. the map abstracts from smaller cities and less signiﬁcant
roads; only the bigger cities, highways, and other important roads are shown. moreover, cities
aggregate local roads and local districts.
models that describe views on processes need to abstract from less signiﬁcant
things. activities can be removed if they are less frequent, e.g., activities that occur
in less than 20% of completed cases are abstracted from. also time and costs can be
taken into account, e.g., activities that account for less than 8% of the total service time
are removed unless the associated costs are more than e50,000.there may be different geographic maps of the same area using different scales.
moreover, using electronic maps it is possible to seamlessly zoom in and out. note that,
while zooming out, insigniﬁcant things are either left out or dynamically clustered into
aggregate shapes (e.g., streets and suburbs amalgamate into cities). navigation systems
and applications such as google maps provide such a seamless zoom. traditionally,
process models are static, e.g., it is impossible to seamlessly zoom in to see part of
the process in more detail. to deal with larger processes, typically a static hierarchical
decomposition is used. such a decomposition does not allow for a seamless abstraction.
moreover, the hierarchy forces people to see less signiﬁcant lower-level connections at
the highest level [1].
cartographers not only eliminate irrelevant details, but also use colors to highlight
important features. for instance, the map shown in figure 5 emphasizes the importance
of highways using the color red. moreover, graphical elements have a particular size
to indicate their signiﬁcance, e.g., the sizes of lines and dots may vary. for instance, in
figure 5 the size of a city name is proportional to the number of citizens, e.g., zaanstad
is clearly smaller than amsterdam. geographical maps also have a clear interpretation
of thex-axis andy-axis, i.e., the layout of a map is not arbitrary as the coordinates of
elements have a meaning.
ideas from cartography can easily be incorporated in the construction of maps.
some examples:
–thesize of an activity can reﬂect its frequency or some other property indicating its
signiﬁcance (e.g., costs or resource use) or the time required for its performance.
–thecolor of an activity can reﬂect the state (e.g., whether it is started, assigned or
concluded).
–thewidth of an arc can reﬂect the importance of the corresponding causal depen-
dency among activities.
–thecoloring of arcs can be used to highlight bottlenecks.
–the positioning of activities can have a well-deﬁned meaning. similar to swim-
lanes they-axis could reﬂect the role associated to an activity. similar to a gantt
chart, thex-axis could reﬂect some temporal aspect.
section 4 describes ongoing research that employs some of these ideas with the aim
of developing a tool to allow for analytical reasoning of the past execution of business
processes. the process of reasoning will be supported by interactive graphical interfaces
that provide several visual representations of the process execution and data involved.
in the remainder of this section we illustrate some of the ideas using fuzzy min-
ing[6]. first, we apply ideas obtained from cartography to build process-model maps
(section 3.1). then, we show the use of animation as a tool for gaining a better under-
standing of the actual behavior found in event logs (section 3.2).
3.1 fuzzy mining
various real-life applications of the different traditional process mining techniques have
shown that the discovered models often look like “spaghetti”, showing all details with-
out highlighting what is important. indeed, as previously said in section 2, logs mayusually include less-relevant or infrequent behavior. in [6] the authors propose fuzzy
mining as a new process mining approach to avoid spaghetti-like models that are in-
comprehensible. in the same way as roadmaps provide suitable abstractions of reality,
process models should provide meaningful abstractions of operational processes.
fig. 6. fuzzy model based on the event log shown in table 1. the log contains 7539 events
corresponding to 1391 process instances. the most detailed view is shown, i.e., all activities are
included in the model.
figure 6 shows a fuzzy model corresponding to the event log that was used to con-
struct the process model of figure 3. this model shows all activities and all causal
dependencies. it can be seen as the most detailed map of the process.
by moving a slider in the fuzzy miner of prom, the less frequent or less impor-
tant activities can be removed. the simplest model would only show the most frequent
activity and abstract from all other activities. less frequent activities can be removedfig. 7. fuzzy model where only the ﬁve most frequent activities are shown at the highest level of
abstraction. the cluster node contains three less frequent, but correlated, activities.or hidden in so-called cluster nodes. figure 7 shows a fuzzy model based on the same
event log used to construct figure 6. however, the three least frequent activities are
hidden in a cluster node. one can think of such a cluster node as a subprocess. the
activities in a cluster node are related, but not important enough to be shown at the top
level. a cluster node can be seen as a “city map”.
fig. 8. fuzzy model where all activities are included at the highest level of abstraction. however,
the less frequent paths in the model are removed. although b,c, ordcan directly precede e, in
most cases ddirectly precedes e. although fmay be followed by b,cand/or d, it is followed
most frequently by b.
less frequent activities can be removed or hidden at a lower level. similarly, one
can remove less frequent connections in a process model. figure 8 shows a fuzzy model
where only the most important connections are shown. note that figure 6 is based on the
same event log but has more arcs than the fuzzy model in figure 8. using the metaphor
of a roadmap, one could say that figure 8 only shows the highways whereas figure 6
also shows less important roads.
the fuzzy miner of prom has many parameters to seamlessly simplify models [6].
for our simple example there is no need to simplify the model. however, real-life pro-
cesses tend to be spaghetti-like involving dozens of activities and hundreds of con-nections. such models cannot be understood by end-users. therefore, simpliﬁcation is
essential, just like a map not showing all details.
3.2 fuzzy animation
the actual process behavior, as found in the event logs, can be projected onto fuzzy
models. the result is a movie that can be played in order to come up with a better
understanding of what has occurred in reality [6]. in this way, while watching the movie,
a process analyst becomes aware which parts of the model are important and where
problems occur.
tokencorresponding
torunningprocess
instanceactivityawasexecuted519
timesandallprocessinstances
startedwiththisactivity
runningprocess
instances
thicknessand
colorindicate
recentbehavior
animationspeed timetimelineplay
button
fig. 9. screenshot of the fuzzy miner while animating the event log consisting of 7539 events
related to 1391 process instances. note that unlike the animations in simulation tools, the anima-
tion is based on factual data. for example, it is possible to follow concrete cases. moreover, it is
easy to see where in the process bottlenecks appear and disappear over time.
figure 9 shows the fuzzy model animation described in [6, 11] and implemented
in the prom framework (see also section 5). replaying an event log can be done by
simply passing control from one node to another in the fuzzy model through one of the
available arcs. as the net is replayed based on information in the log, no executable
semantics are needed. however, while replaying, the nature of splits and joins becomes
clear. if control passes from a node a to another node b, then this is visualized througha token that moves along the arc from a to b. when passing along an arc, the token
leaves a trail of glowing hot particles as it were a comet. the approach projects all log
traces onto the model at once, resulting in multiple traces animated at the same time.
the colors of the connections and the thickness of the arcs indicate recent activity. in
this way, users can distinguish individual process instances and see the overall activity at
a particular point in time. for example, a path that is being traveled frequently becomes
wider while the animation progresses. therefore, every token that travels along arcs
will help to increase the thickness of the arc itself. hence, again the map metaphor is
used: on a road map highways are shown using thicker lines.
the fuzzy miner in prom illustrates some important observations:
–process models can be seen as maps. hence, we should try to use ideas from car-
tography to simplify and clarify processes.
–given a process or event log there may be many different maps depending on the
intended use and the aspects of interest.
–by projecting states and events on such maps, we can “breathe life” into process
models. showing an animation based on historic data reveals problems and insights
that cannot be seen by looking at static graphs and charts.
based on these observations, we propose an approach to relate visual analytics to pro-
cess mining as is shown next.
4 visual spatio-temporal analysis of process executions
this section concerns a framework that leverages the map metaphor to allow process
analysts to replay history on a map to identify bottlenecks and learn more about the
actual process. speciﬁcally, the event log is replayed: after the occurrence of every
event, the system state changes and, hence, the framework builds the sequence of states
which the system has gone through. the framework envisages the existence of several
maps; each one showing a different process view on which the system state can be
projected.
after the occurrence of every event, the system state changes and, hence, its projec-
tion onto maps results in a new photograph. for each map, the different photographs can
be ordered in a sequence and merged in succession; the ﬁnal result is a set of movies.
each movie allows process analysts to view the process executions from a particular
angle, thus highlighting some distinctive peculiarities that are less evident in the other
perspectives.
4.1 the framework architecture
figure 10 shows the architecture of the framework. the framework assumes that there
exists an environment in which processes are executed; this environment is, in general,
an information system which is not necessarily process-oriented. the only assumption
is that the execution of a process instance can be broken down into the sequence of
steps, i.e., its activity instances, that are carried out during process performance, and
such steps are recorded and exported into an execution log .fig. 10. architecture of the framework for the analysis of process executions.
the events in the log can be replayed, thus allowing for rebuilding the execution
history . an execution history is a sequence of states which the system went through
together with the timestamps marking the times when the system entered these states.
once the execution history has been reconstructed using replay, it is possible to
create a sequence of photographs. in addition to the execution history, this step requires
as input the set mof maps of interest, and the functions that determine how to project
single activity instances onto maps. the result is a sequence of photographs for each
mapm∈m. one photograph is built after the occurrence of every event for all maps.
finally, each sequence of photographs is turned into a movie by playing them in
succession. in general, a process execution can last days, even months. therefore, if a
photograph was built after each event, the movie would be far too long. therefore, the
step of making the movies is more than just playing photographs in succession. pho-
tographs need to be grouped in a number of “aggregated” photographs. each aggregated
photograph summarizes the information of its constituent photographs. one can think
of this as a “refresh rate”: the process time is divided in periods and all photographs
falling in the same time period are merged. also note that the duration of activity in-
stances could be very short compared to the overall ﬂow times. in fact, in some cases
activities are atomic and a na ¨ıve concatenation of steps would not show these (as they
take no time).
section 4.2 discusses the execution history, whereas section 4.3 describes the pro-
jection of states to maps in order to obtain photographs. finally, section 4.4 illustrates
how to obtain a movie by merging photographs and playing them in succession.
4.2 building the execution history
anactivity instance refers to the execution of an activity for a speciﬁc instance. there
may be multiple events that describe the life cycle of such an activity instance. the
goal is to visualize how activity instances evolve over time. an activity instance is
represented by a pair (aname,apid)whereaname ∈aandapid∈c.ais the universeof activity names. cis the universe of process identiﬁers, i.e., apidrefers to a particular
process instance (sometimes referred to as a case). a process data variable is a pair
(vname,vpid)wherevname ∈vandvpid∈cwherevdenotes the universe of variable
names. note that different process instances can have different values for some variable
vname .
the possible states in which an activity instance can be are the following:
–unscheduled. the activity instance is not yet scheduled for execution; this is the
initial state.
–scheduled. the activity instance is scheduled for execution.
–assigned. the activity instance is assigned to a resource for execution.
–executing. the execution of the activity instance started.
–suspended. the execution of the activity instance is paused.
–concluded. the execution of the activity instance is concluded.
in the following, zdenotes the set of possible activity instance states: z =
{unscheduled ,scheduled,assigned,executing,suspended,concluded }. as men-
tioned in section 2, each event is recorded in the execution log together with the times-
tamp when it occurred:
deﬁnition 1 (event). an eventeis a tuple (aname,cid,t,z,p )where:
–aname is an activity name;
–cidis a case identiﬁer;
–tis the timestamp when event eoccurred;
–z∈zis the state to which the corresponding activity instance moves, as a result
of the occurrence of event e.
–p={v1,...,v n}is a set of data properties. every data property viis a pair
(vni,val i)wherevniis a property name and valiis a property value.
the events stored in the execution logs trigger changes in the system state. a system
state is deﬁned as follows:
deﬁnition 2 (system state). letzbe the activity instance states. let a,candvbe
the universe of activity names, process identiﬁers and variable names, respectively. u
is the universe of variable values. a system state s= (α,ν)consists of:
–a functionα: (a×c)̸→zwhereα(aname,apid) =zdenotes that activity
instance (aname,apid)is in statez∈zwhen the system state is s.
–a functionν: (v×c)̸→uwhereν(vname,vpid) =vvalue denotes that variable
(vname,vpid)has valuevvalue in system state s.
in the remainder, for each event e= (aname,cid,t,z,p ), we use the following func-
tions to refer to the elements of this tuple: activity (e) =aname ,case (e) =cid,
timestamp (e) =t,state (e) =zandproperties (e) =p. moreover, given a func-
tionf, we denote with dom (f)the domain of function f.
letf(ϕ1,...,ϕ n)be ann−ary function and let φ={ϕ1,...,ϕ m}be a set of
pairsϕj= (ϕj,vj)whereϕj= (ϕj
1,...,ϕj
n)is an-dimensional vector and vjis an
arbitrary value. we denote with f′=f⊕φthe function:
f′(ϕ) ={f(ϕ)if¬∃v.(ϕ,v)∈φ
v if(ϕ,v)∈φmoreover, let ψ={ψ1,...,ψm}be a set of n-dimensional vectors ψj=
(ψj
1,...,ψj
n). we denote with f′=f⊖ψthe function:
f′(ψ) ={f(ψ) ifψ̸∈ψ
undeﬁned otherwise
similarly to existing algorithms for conformance checking [1], this framework is
based on the principle of replay. nevertheless, the replay used here is slightly different
as will be shown next. the initial replay state is s0= (α0,ν0)where dom (α0) =∅
anddom (ν0) =∅.
deﬁnition 3 (replaying of events). lets= (α,ν)be the current state during the
replay. letebe the next event to replay. the replaying of event ewill cause the replay
state to move from state sto states′= (α′,ν′), denoted as se− →s′, where
functionα′.if the eventeconcerns activity instance a= (activity (e),case (e))anda
concludes, then the function α′is deﬁned on the same domain as function α, except
fora, and the function values are the same as those of α. conversely, if erefers
to an activity transition to a state different from conclusion, the function domain
remains unchanged and the function value is only changed for activity instance a,
i.e.α′(a) =state (e). more precisely:
α′=

α⊕{((
activity (e),case (e))
,state (e))}
ifstate (e)̸=concluded
α⊖{(
activity (e),case (e))}
ifstate (e) =concluded
functionν′.for each property (name,val )∈properties (e), the value of the ν′func-
tion is obtained as follows: ν′(name, case (e)) =val. for all other domain ele-
ments ofν′, the function values are the same as those of function ν. more precisely:
ν′=ν⊕{(
(name, case (e)),val)
|(name,val )∈properties (e)}
replaying is used to reconstruct the execution history :
deﬁnition 4 (execution history). let< e 1,...,e n>be the sequence of events
in an execution log. let s0e1− →s1e2− →...en− →snbe the sequences of states
through which the system went. an execution history is a sequence of pairs h=<
(s1,t1),..., (sn,tn)>where (si,ti)denotes that the system entered state siat time
ti=timestamp (ei).
4.3 mapping states onto maps
when replaying, the process moves from state si= (αi,νi)to statesi+1 =
(αi+1,νi+1)and these states need to be projected onto maps.
by leveraging on the map metaphor described in earlier sections, activity instances
can be visualized by dots on the map. by not ﬁxing the type of map, but allowing this
choice to be conﬁgurable, different types of relationships can be shown thus providing
a deeper insight into the context of the work to be performed. as mentioned before, amap can be a geographical map (e.g., the map of a university’s campus), but other maps
can also be used, e.g., process schemas, organizational diagrams, gantt charts, etc.
an activity instance is represented as a dot positioned along certain coordinates on
a background map. a map is meant to capture a particular perspective of the context
of the process. since an activity instance can be associated with several perspectives,
it can be visualized on several maps at different positions. maps can be designed at
design time as needed. when the use of a certain map is envisaged, the relationship
between activities and their position on the map should be speciﬁed through a function
determined at design time.
deﬁnition 5 (position function). letaandvbe the universe of the names of activ-
ities and process variables, respectively. let ube the universe of the values of process
variables. let mbe the set of maps of interest. for each available map m∈m, there
exists a function
positionm:a̸→expr (v)
whereexpr (v)is the domain of all expressions that use some of the variables v∈v.
letξ:v̸→ube a value assignment of a subset of the variable names v∈v. we
deﬁneeval as a function which, given a position function fand a value assignment ξ,
yields a pair of non-negative numbers:
eval [ [f] ] (ξ) = (c1,c2)
where (c1,c2)∈r+
0×r+
0.
given a map m∈m, a statesi= (αi,νi), an activity instance a=
(aname,apid)∈dom (αi)and a function fa=position m(a), the coordinates of the
position of activity instance aonto mapmfor statesiis:
position m(a)
si=eval [ [fa] ] (ξa)
whereξa(vname ) =νi(vname,apid).
for a mapm∈m, the function positionmmay be partial, since some elements of
amay not have an associated position. it can also be the case that, for some activity
a∈dom (α),dom (ξa)⊂dom (positionm(a)); in such a case, some variables of f=
positionm(a)have no assignment. consequently, eval [ [f] ] (ξ)is undeﬁned and, hence,
ais not associated with any position on map m.
the projection of a state si= (αi,νi)onto a mapmis the projection of each and
every activity a∈dom (αi)ontomat positionposition m(a)
si. the dot associated to
activityais also ﬁlled with a color that depends on αi(a), i.e. the state of activity a.
table 4 summarizes the choice of colors used in the framework.
when dots overlap in a certain map, they are joined to form bigger dots, since other-
wise some of them would be invisible. the diameters of such dots grow logarithmically
with the number of activities amalgamated. the amalgamated dots are divided in as
many slices as there are constituting dots and each slice is ﬁlled with the color of the
dot that it corresponds to.
section 4.4 will discuss how the different photographs capturing the various states
can be merged, thus obtaining a movie. the remainder of this section summarizes thestate associated color
unscheduled not applicable
scheduled white
allocated cyan
executing green
suspended black
concluded not applicable
table 4. the color used to ﬁll an activity dot depends on the state of the activity. the table shows
the selection of colors that is envisioned in the framework. activity instances that are unscheduled
or concluded are not represented on a map.
results of earlier work [12] that is based on a framework which aims to provide vi-
sual run-time support to process participants for the complex decision of choosing the
next activity instance to work on. although the framework is slightly different, we be-
lieve that its discussion can be of support to the readers to understand the framework
described in this paper.
visual support for activity assignment in real scenarios, users can be confronted
with a very large number of activity instances that stem from multiple cases of different
processes. in this “jungle of work items”, users may ﬁnd it hard to choose the right
activity to work on next. the system cannot autonomously decide which is the right ac-
tivity, since the decision is also dependent on conditions that are somehow “outside the
system”. for instance, what is “best” for an organization should be mediated with what
is “best” for its employees. therefore, in our earlier work [12], a tool has been devised
which provides an intuitive graphical interface that uses contextual information about
activities and process participants to provide suggestions about prioritization of activity
instances to perform. while the basic foundation is mostly identical, the earlier frame-
work is slightly different from the one proposed in this paper. first, in [12] the state that
is projected onto the map is always the current one. moreover, different process partici-
pants are offered different sets of activity instances, since they may have different roles
and privileges. therefore, for a given participant, the projected activity instances are
only those which the participant is allowed to view or to work on. in order to suggest
the next activities to perform, the scheduled activities are not always colored white but
with colors that range from white to black with different shades of yellow, orange, red
and brown. dots are colored according to a “distance notion”: different process partic-
ipants may ﬁnd the same activity closer or farther to their sphere, meaning they have
different experiences with such an activity type, have different working speeds, and so
on. a activity that is close tends to be colored black, meaning a participant is suggested
to pick that as next; an activity that is far away is colored white, meaning the execution
of that activity can be postponed.
figure 11 shows two screenshots of the tool for two different maps. in particu-
lar, figure 11(a) shows the projection of activity instances onto a geographic map. on
this map, activity instances are placed at the physical location where they should be(a) projection of the current process state
onto a geographic map.
(b) projection of the current process state
onto a timeline map.
fig. 11. using the map metaphor to distribute work. dots show the current state on various maps
used by end-users and managers.
executed. if the locations of some of them are so close that their corresponding dots
overlap, these are amalgamated into a larger dot. the number inside such a larger dot
corresponds to the number of activity instances represented by it. the larger dot is also
divided in slices, one per amalgamated dot, and each slice is ﬁlled with the same color
as the corresponding dot. figure 11(b) illustrates the projection using a different map:
activity instances are positioned onto the maps so that the x-axis position represents
the time remaining before an activity instance expires, whereas the y-axis position is
computed as a function of the case identiﬁer, an positive integer.
4.4 mapping logs on maps
in the previous subsections, we showed how to create an execution history hand a
mapping of activity instance states onto a map m∈mbased on function positionm.
recall that the execution history is sequence of states and corresponding timestamps:
h=<(s1,t1),..., (sn,tn)>
at timetitheithevent causes the process to move to state si= (αi,νi). the challenge
is now to map such a sequence of states onto a map. a state corresponds to a photograph
and an execution history corresponds to a movie. process instances can run for days,
weeks, or even months. there may be many events per process instance. moreover,
activities may take a very short time compared to the overall ﬂow time of a process in-
stance. therefore, a na ¨ıve approach that simply concatenates photographs into a movie
is destined to fail. some of the complications are:
–the number of events may be too large to visualize in a movie due to performance
reasons or visualization problems (cluttered diagrams).–the speed of the movie should correspond to real time rather than the number of
events. for example, a day with just a few events should take the same time as a
day with many events. (unless the user deliberately wants to use logical timestamps
rather than real timestamps.)
–the duration of activities may be very short compared to the ﬂow time of process
instances. for example, an activity may be atomic (takes no time according to the
event log) or takes just a few minutes in a process that has an average ﬂow time of
weeks. note that an activity of one minute corresponds to 0.00992 percent of the
ﬂow time of a process taking a week. hence, a na ¨ıve visualization approach would
make such event invisible.
to address these problems we select a refresh rate 1/τand build an aggregate pic-
ture for each period of τtime units. this is similar to a television using ntsc or pal.
according to the ntsc standard the image is refreshed 60 times per second (60 hz).
pal uses a refresh rate of 50 hz. figure 12 shows the basic idea. the time period cov-
ered by the event log is partitioned into smaller periods of τtime units. per τperiod,
there is a collection of events, resulting in a sequence of states. the photographs of
these states are aggregated into a single photograph. the aggregated photographs of all
time periods are concatenated into a movie. given an event log, different refresh rates
can be used to create a more ﬁne-grained movie or a more coarse-grained movie.
fig. 12. creating movies based on an event log using a refresh rate of 1=; one photograph is
created for every period of time units.
the approach depicted in figure 12 helps us to address the problems mentioned
before. first of all, the aggregation per period can be used to avoid cluttering the map
and to improve performance for huge data sets. second, by showing all aggregated
images equally long, the speed of the movie automatically corresponds to the real timeprogression. third, through aggregation and scaling, the visualization can also show
activities that run for a short period compared to the overall ﬂow time. even when
activities take only a fraction of the ﬂow time, the depicted level of activity can be
shown relative to other periods.
again we use the notion of dots having a position, color, and diameter. the position
of a dot on a map depends on the properties of the corresponding events. smaller dots
can be amalgamated into larger dots. the color and size of such amalgamated dots may
depend on various properties of the underlying events (frequency, duration, etc.).
(a) projection of an activity as a
dot in six subsequent system states
s0;s1;s2;s3;s4;s5of an execution
history h. for the photograph of s5, the
activity was concluded and, hence, the as-
sociated dot is no longer visualized.
(b) projection of the activity as a
dot in a composite photograph that
merges the photographs of system states
s0;s1;s2;s3;s4;s5.
fig. 13. example of computing the position, the radius and the colors of a dot in a composite
photograph.
figure 13 shows an example focusing on a particular activity instance
that goes through a sequence of states. the photograph aggregates six states
s0,s1,s2,s3,s4,s5of the history h=< ..., (s0,t0),..., (s5,t5),... > . fig-
ure 13(a) illustrates the projection of an activity as a dot in the photographs for system
statess0,s1,s2,s3,s4. in states5the activity instance was concluded and, hence,
the associated dot is no longer visualized. in the photographs associated to the dif-
ferent states, the dots are colored differently, since the activity instance is in different
states. figure 13(b) shows the visualization of the activity-instance dot in the aggre-
gated photograph for the time period. the dot’s position is computed as the average
of the positions of the dots in the original photographs. the average is weighted with
respect to the durations the dot was located at the various positions in the time period.
the dot area is split in ﬁve rings: one is white colored, two are cyan, and two are green
since the activity instance was, respectively, in the scheduled state for system state s0,
in the allocated state for s1ands2and in state executing for s3ands4(see table 4).the radius of each ring is directly proportional to the duration the activity instance was
in the state corresponding to that ring
5 tool support
the process mining framework prom was developed based on experiences with simple
process mining tools such as mimo (α-miner based on exspect), emit (α-miner tak-
ing transactional information into account), little thumb (predecessor of the heuristic
miner), inwolve (miner based on stochastic activity graphs), and process miner (miner
assuming structured models) [13]. to avoid “reinventing the wheel” each time a new
process mining algorithm was developed, researchers at eindhoven university of tech-
nology developed prom, a “plug-able” environment for process mining using mxml
(mining xml format) as input format. the goal of the ﬁrst version of this framework
was to provide a common basis for all kinds of process mining techniques, e.g., sup-
porting the loading and ﬁltering of event logs and the visualization of results. this way
people developing new process discovery algorithms did not have to worry about ex-
tracting, converting, and loading event data. moreover, for standard model types such
as petri nets, epcs, and social networks default visualizations were provided by the
framework. in 2004, the ﬁrst fully functional version of prom framework ( prom 1.1 )
was released. this version contained 29 plug-ins. with each version of prom the num-
ber of plug-ins increased. for example, prom 5.2 was released in 2009 and contained
286 plug-ins: 47 mining plug-ins, 96 analysis plug-ins, 22 import plug-ins, 45 export
plug-ins, 44 conversion plug-ins, and 32 ﬁlter plug-ins. note that the fuzzy miner is
just one of these 286 plug-ins. the spectacular growth of the number of plug-ins in the
period from 2004 to 2009 illustrates that prom realized its initial goal to provide a plat-
form for the development of new process mining techniques. prom has become the de
facto standard for process mining. research groups from all over the globe contributed
to the development of prom and thousands of organizations downloaded prom.
prom 6 (released in november 2010) is based on xes rather than mxml. xes is
the new process mining standard adopted by the ieee task force on process mining.
although prom 5.2 was already able to load enormous event logs, scalability and efﬁ-
ciency were further improved by using openxes. prom 6 can distribute the execution
of plug-ins over multiple computers. this can be used to improve performance (e.g.,
using grid computing) and to offer prom as a service. the user interface has been re-
implemented to be able to deal with many plug-ins, logs, and models at the same time.
plug-ins are now distributed over so-called packages and can be chained into composite
plug-ins. packages contain related sets of plug-ins. prom 6 provides a so-called pack-
age manager to add, remove, and update packages. users should only load packages
that are relevant for the tasks they want to perform. this way it is possible to avoid
overloading the user with irrelevant functionality. moreover, prom 6 can be customized
for domain speciﬁc or even organization speciﬁc applications.
figure 14 shows the architecture of the implementation of the framework to provide
visual spatio-temporal analysis of process executions as described in section 4. in par-
ticular, the framework is being implemented as a prom plug-in. the plug-in requires
two input objects:the event log. the xml ﬁle of the event log in xes format. this event log is as-
sumed to be produced by some information system. the assumption of using event
logs in this format is not a strong assumption since prom is provided with a number
of different import plug-ins that can convert execution logs from many formats to
xes. moreover, prom is highly extensible and, hence, it is possible to extend it
with new import plug-ins to load logs in whichever format.
map speciﬁcations & speciﬁcation of the projection of activity instances on maps.
this is an additional xml ﬁle which includes crucial information. in particular,
such an xml ﬁle codes the set mof available maps (i.e. the map name and
the url where the map image can be retrieved) as well as the deﬁnition of the
position function (deﬁnition 5) for each map.
when the plug-in is launched with the required input objects, the user is asked to specify
the value for the time-slot period τin order to deﬁne the level of aggregation initially
requested. the result of the plug-in application is a set of movies, one for each map.
users can play the movie, move forward or backward, or jump to a certain time slot of
interest. moreover, in order to drill down or roll up, user can also zoom in or out of a
movie and change the time-slot period in order to split a composite photograph into a
set of them or to merge several into a single one. note that the implementation of the
plug-in is ongoing as part of a master project at tu/e.
fig. 14. architecture of the implementation of the framework described in section 4 as prom
plug-in6 related work
in this paper, we proposed to combine process mining and visual analytics. both are
emerging domains that attracted considerable attention in the last couple of years. in-
terested readers can see [13] for an overview of the early work on process mining,
whereas the book [1] provides a more comprehensive overview of the state-of-the-art
on process mining.
in the past, many automatic techniques for process mining, but also for statistics
and data mining, have been developed without taking the visualization aspects into
account. on the other hand, the research community focusing on information visualiza-
tion (e.g. [14] or [15]) did not address process-related issues like in the process mining
domain.
for what concerns visualizations in the ﬁeld of business processes, the work de-
scribed in [16] allows the current status of the running business process instances to be
visualized in 2d diagrams. these diagrams merge different viewpoints, as our frame-
work aims to do. unfortunately, the admissible diagrams are restricted to traditional
bar charts and histograms meshed to process schemas, which are visualized as undi-
rected graphs. therefore, the approach is not fully ﬂexible, since users cannot deﬁne
speciﬁc domain-dependent maps that may give an insight into relevant perspectives for
a certain class of processes, unless they are expressed as bar charts or histograms. the
research work reported in [17] builds on [16] and, additionally, provides a 3d busi-
ness process visualization. it relies on the concept of 3d gadgets, which are a set of
graphical primitives that can be combined to deﬁne relevant diagrams. however, the
possible alternative diagrams that can be obtained are quite restricted, since the number
of available gadgets is limited and new ones cannot be deﬁned by users.
also related is work on business process mash-ups, which is a technique for building
applications that combine information from multiple sources with process data to create
an integrated view. nowadays, there is not a complete framework to mash up process
data with those of external sources as this is non-trivial: it would be necessary to agree
upon standard ontologies that need to be integrated with the process data perspective.
hence contemporary process mash-up solutions are still ad-hoc, developed either for
speciﬁc process speciﬁcations or for certain data sources. for instance, for mashing up
geographical information and process data, there exist several research papers [18, 19]
and even commercial products.3combining geographical information with business
processes is only one of the usages that we allow for. the framework proposed in this
paper is not restricted to mere geographical data: maps can be geographical but also
other map types are allowed and for non-geographical maps the concept of activity
locations takes on a completely different meaning.
the map metaphor has been widely used to provide user-friendly visual query
languages to retrieve data from databases [20, 21]. in particular, chang [20] proposes
the concept of sentient maps , which may be of any nature (e.g., geographic, documental)
and are conceptually similar even though applied to querying databases.
of course, visual analytics is more than only visualization: it is an integrated ap-
proach that tries to incorporate human perceptiveness into techniques techniques that
3e.g., kinetic by linkuistics http://www.linkuistics.com.au/productscombine visualization and data analysis. a ﬁrst attempt of merging these aspects has
successfully been conducted for data mining [22].
the term “visual analytics” was coined in [3], which reviews the early work in this
ﬁeld. an up-to-date and comprehensive reference for readers interested in the topic
is [5]. examples of recent signiﬁcant research in the area of visual analytics can be
found in document analysis [23], ﬁnancial analysis [24, 25] and geo-spatial object anal-
ysis [26]. another interesting example of the application of visual analytics is provided
in willems et al. [27], where a technique is proposed to visually summarize the move-
ments of vessels along the dutch coast in a single display.
obviously, the scope of visual analytics does not exclude the visualization of
process-related data. however, most of the work is either quite generic or quite speciﬁc
for a particular application. what is missing is a systematic approach to make visual
analytics “process aware”. temporal aspects, concurrency, causality etc. are process
aspects that need to be visualized in a consistent and systematic manner.
7 conclusion
process mining is an emerging discipline that analyzes event data from a process-
oriented perspective. today’s process mining techniques are able to extract important
insights from semi-structured processes. visual analytics focuses on visualizing infor-
mation in a simple and human-understandable way, thereby using the amazing capabil-
ities of humans to see patterns in unstructured data. as advocated in this paper, process
mining and visualization can be combined to maximize their effectiveness.
we positioned data mining, process mining, visualization and visual analytics and
showed that a combination of approaches is needed. to do this we used the metaphor
of a map. process models can be seen as maps and ideas from cartography can be
used to make these models better understandable. moreover, process models are just
one view on processes and, depending on the questions one seeks to answer, an array
of maps should be provided. the current state of a process can be projected onto such
maps, thus visualizing a “photograph of the process”. as shown, individual photographs
can be aggregated into images that can be put into sequence and thus form a “process
movie”. earlier experiments with the fuzzy miner in prom and work assignment in the
context of yawl, show that such an approach is feasible and effective. however, these
techniques should only be seen as the starting point of a more comprehensive approach
to “breathe life” into otherwise static business process models.
future research focuses on two main directions. first of all, we are implementing
the framework described in section 4. as indicated in section 5, we expect to oper-
ationalize the approach in terms of a prom plug-in. second, we want to make use of
visual-analytics techniques in the ﬁeld of operational support [1, 28] to guide users in
executing activities in business processes. operational support is a set of techniques to
recommend users about the next actions to perform for reaching certain desired goals
without violating business and operative constraints. usually, there exist multiple appli-
cations, referred to as “operational support providers”, that provide recommendations to
process participants. in [12] we used maps to guide users in selecting work items. how-ever, this is only one of many possible applications. we plan to provide comprehensive
support for this in the context of prom [1].
references
1.aalst, w.: process mining: discovery, conformance and enhancement of business pro-
cesses. springer-verlag, berlin (2011)
2.rozinat, a., aalst, w.: conformance checking of processes based on monitoring real
behavior. information systems 33(2008) 64–95
3.thomas, j., cook, k., eds.: illuminating the path: the research and development agenda
for visual analytics, ieee cs press (2005)
4.keim, d., mansmann, f., schneidewind, j., thomas, j., ziegler, h.: visual analytics: scope
and challenges. in simoff, s.j., b ¨ohlen, m.h., mazeika, a., eds.: visual data mining.
springer-verlag (2008) 76–90
5.keim, d., kohlhammer, j., ellis, g., mansmann, f., eds.: mastering the information age:
solving problems with visual analytics, vismaster, http://www.vismaster.eu/book/ (2010)
6.g¨unther, c., aalst, w.: fuzzy mining: adaptive process simpliﬁcation based on multi-
perspective metrics. in alonso, g., dadam, p., rosemann, m., eds.: international conference
on business process management (bpm 2007). volume 4714 of lecture notes in computer
science., springer-verlag, berlin (2007) 328–343
7.aalst, w., weijters, a., maruster, l.: workﬂow mining: discovering process models from
event logs. ieee transactions on knowledge and data engineering 16(2004) 1128–1142
8.weijters, a., aalst, w., medeiros, a.: process mining with the heuristics miner-algorithm.
beta working paper series, wp 166, eindhoven university of technology, eindhoven, the
netherlands (2006)
9.medeiros, a., weijters, a., aalst, w.: genetic process mining: an experimental evaluation.
data mining and knowledge discovery 14(2007) 245–304
10.song, m., aalst, w.: towards comprehensive support for organizational mining. decision
support systems 46(2008) 300–317
11.g¨unther, c.: process mining in flexible environments. phd thesis, eindhoven university
of technology, eindhoven, the netherlands (2009)
12.leoni, m., aalst, w., hofstede, a.: visual support for work assignment in process-aware
information systems. in dumas, m., reichert, m., shan, m., eds.: international conference
on business process management (bpm 2008). volume 5240 of lecture notes in computer
science., springer-verlag, berlin (2008) 67–83
13.aalst, w., dongen, b., herbst, j., maruster, l., schimm, g., weijters, a.: workﬂow mining:
a survey of issues and approaches. data and knowledge engineering 47(2003) 237–267
14.chen, c.: information visualization: beyond the horizon. springer-verlag, new york, inc.
(2006)
15.spence, r.: information visualization: design for interaction. 2nd edn. pearson education
limited, harlow, england (2006)
16.sch¨onhage, b., eli ¨ens, a.: management through vision: a case study towards require-
ments of bizviz. in: a vi 2000: internation conference of information visualisation, ieee
computer society (2000) 387–392
17.sch¨onhage, b., van ballegooij, a., elli ¨ens, a.: 3d gadgets for business process
visualization—a case study. in: vrml ’00: proceedings of the ﬁfth symposium on virtual
reality modeling language (web3d-vrml), acm (2000) 131–138
18.alonso, g., hagen, c.: geo-opera: workﬂow concepts for spatial processes. in: ssd’97:
proceedings of the 5th international symposium on advances in spatial databases. volume
1262 of lecture notes in computer science., springer (1997) 238–25819.kaster, d., bauzer-medeiros, c., da rocha, h.v.: supporting modeling and problem solving
from precedent experiences: the role of workﬂows and case-based reasoning. environ-
mental modelling and software 20(2005) 689–704
20.chang, s.: the sentient map. journal of visual language and computing 11(2000) 455–
474
21.camara, k., jungert, e.: a visual query language for dynamic processes applied to a
scenario driven environment. journal of visual languange and computing 18(2007) 315–
338
22.keim, d.: visual exploration of large data sets. communications of the acm 44(2001)
38–44
23.oelke, d., ming, c., rohrdantz, c., keim, d., dayal, u., lars-erik, h., janetzko, h.: visual
opinion analysis of customer feedback data. in: proceedings of the ieee symposium on
visual analytics science and technology (ieee v ast 2009), ieee (2009) 187–194
24.keim, d., nietzschmann, t., schelwies, n., schneidewind, j., schreck, t., ziegler, h.: a
spectral visualization system for analyzing financial time series data. in: proceedings of
the eurographics/ieee-vgtc symposium on visualization (eurovis 2006), eurographics
association (2006) 195–200
25.ziegler, h., nietzschmann, t., keim, d.: relevance driven visualization of financial per-
formance measures. in: proceedings of the eurographics/ieee-vgtc symposium on vi-
sualization (eurovis 2007), eurographics association (2007) 19–26
26.bak, p., mansmann, f., janetzko, h., keim, d.: spatio-temporal analysis of sensor logs
using growth ring maps. ieee transactions on visualization and computer graphics 15
(2009) 913–920
27.willems, n., van de wetering, h., van wijk, j.: visualization of vessel movements. in:
proceedings of the eurographics/ieee-vgtc symposium on visualization (eurovis 2009),
eurographics association (2009) 959–966
28.rozinat, a., wynn, m., aalst, w., hofstede, a., fidge, c.: workﬂow simulation for opera-
tional decision support. data and knowledge engineering 68(2009) 834–850