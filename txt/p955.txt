processprofiler3d
wynn, m.t.; poppe, e.; xu, j.; ter hofstede, a.h.m.; brown, r.; pini, a.; van der aalst,
w.m.p.
published in:
decision support systems
doi:
10.1016/j.dss.2017.04.004
published: 01/08/2017
document version
publisher’s pdf, also known as version of record (includes final page, issue and volume numbers)
please check the document version of this publication:
• a submitted manuscript is the author's version of the article upon submission and before peer-review. there can be important differences
between the submitted version and the official published version of record. people interested in the research are advised to contact the
author for the final version of the publication, or visit the doi to the publisher's website.
• the final author version and the galley proof are versions of the publication after peer review.
• the final published version features the final layout of the paper including the volume, issue and page numbers.
link to publication
citation for published version (apa):
wynn, m. t., poppe, e., xu, j., ter hofstede, a. h. m., brown, r., pini, a., & van der aalst, w. m. p. (2017).
processprofiler3d: a visualisation framework for log-based process performance comparison. decision support
systems, 100, 93-108. doi: 10.1016/j.dss.2017.04.004
general rights
copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners
and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.
            • users may download and print one copy of any publication from the public portal for the purpose of private study or research.
            • you may not further distribute the material or use it for any profit-making activity or commercial gain
            • you may freely distribute the url identifying the publication in the public portal ?
take down policy
if you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately
and investigate your claim.
download date: 14. jan. 2018decision support systems 100 (2017) 93–108
contents lists available at sciencedirect
decision support systems
journal homepage: www.elsevier.com/locate/dss
processproﬁler3d: a visualisation framework for log-based process
performance comparison
m.t. wynna,*, e. poppea,*,j .x ua, a.h.m. ter hofstedea,b, r. browna,a .p i n ic, w.m.p. van der aalstb,a
aqueensland university of technology, queensland, australia
beindhoven university of technology, eindhoven, the netherlands
cdensitydesign research lab, politecnico di milano, milan, italy
article info
available online 2may 2017
keywords:
process analysisprocess miningperformance analysisvisualisationabstract
an organisation can signiﬁcantly improve its performance by observing how their business operations
are currently being carried out. a great way to derive evidence-based process improvement insights is to
compare the behaviour and performance of processes for different process cohorts by utilising the infor-mation recorded in event logs. a process cohort is a coherent group of process instances that has one or
moresharedcharacteristics.suchprocessperformancecomparisonscanhighlightpositiveornegativevari-
ationsthatcanbeevidentinaparticularcohort,thusenablingatailoredapproachtoprocessimprovement.although existing process mining techniques can be used to calculate various statistics from event logs
for performance analysis, most techniques calculate and display the statistics for each cohort separately.
furthermore, the numerical statistics and simple visualisations may not be intuitive enough to allow usersto compare the performance of various cohorts eﬃciently and effectively. we developed a novel visualisa-
tion framework for log-based process performance comparison to address these issues. it enables analysts
to quickly identify the performance differences between cohorts. the framework supports the selectionof cohorts and a three-dimensional visualisation to compare the cohorts using a variety of performance
metrics. the approach has been implemented as a set of plug-ins within the open source process mining
framework prom and has been evaluated using two real-life datasets from the insurance domain to assessthe usefulness of such a tool. this paper also derives a set of design principles from our approach which
provideguidance for the developmentofnewapproaches to process cohortperformance comparison.
© 2017 elsevier b.v. all rights reserved.
1. introduction
performance analysis can provide valuable insights into business
processes of organisations, such as where bottlenecks and wait-
ing times occur. such analyses provide a valuable starting pointfor business process redesign aimed at cost reduction, time sav-
ings and/or productivitygains. process mining [1], a specialised ﬁeld
of research in business process management, uses process-related
data, recorded in event logs to uncover the real behaviour and
performance of business processes.
*corresponding authors at: queensland university of technology, school of infor-
mation systems, 2 georgest, brisbaneqld 4000, queensland, australia.
e-mail addresses: m.wynn@qut.edu.au (m. wynn), erik.poppe@qut.edu.au
(e. poppe), j15.xu@qut.edu.au (j. xu),a.terhofstede@qut.edu.au (a.t. hofstede),
r.brown@qut.edu.au (r. brown), azzurra.pini@polimi.it (a. pini),
w.m.p.v.d.aalst@tue.nl (w. van der aalst).a key limitation of contemporary process mining techniques for
performance analysis is the lack of support for a detailed compar-
ison of the characteristics of multiple cohorts of process instances.
we consider a process cohort to be a group of process instances that
has one or more shared characteristics. for example, one may wish to
beabletocontrasttheprocessingoflow-valueclaims(cohort1)with
that of high-value claims (cohort 2) in an insurance company or to
gaininsightintothedifferentpathwaysofpatientsthroughanemer-gencydepartmentbasedontheseverityoftheirinjuries,asreported
in several industry case studies [2–4]. while the performance statis-
tics for each process cohort in these scenarios were computed using
existing process mining techniques, the detailed comparison itself isstillamanualprocess.onlyrecently,afewapproacheshavedemon-
stratedthevisualcomparisonoftwoprocesscohortsinoneanalysis.
however, the comparison of more than two cohorts in a singlevisualisation is stillnot well-developed.
the focus of this paper, therefore, is to present a novel com-
parative process visualisation framework that supports process per-formance comparison for multiple cohorts in a single visualisation
http://dx.doi.org/10.1016/j.dss.2017.04.004
0167-9236/©2017elsevier b.v. allrights reserved.94 m. wynn et al. / decision support systems 100 (2017) 93–108
and a set of generalised design principles to guide the development
of further approaches for process cohort performance comparison.
fig. 1shows an overview of the approach. the framework takes
an event log and a representative process model as inputs and
supports dynamic categorisation of process cohorts and computa-
tionofperformancemetrics.theframeworksubsequentlygenerates
comparative process visualisations, which can then be interactivelyexplored by process stakeholders. these visualisations extend thetwo-dimensional graphs proposed by pini et al. [5]to a three-
dimensional space, creating a new visual technique that enables
global comparison. the rest of the paper is organised as follows.section 2 discusses related work, while in section 3 the approach
proposed in this paper is discussed in detail. in section 4 aspects of
the implementation of the framework are discussed and section 5 is
concerned with the framework’s evaluation. section 6 summarises
our contributionsand presentssome avenuesfor future work.
2. related work
information systems nowadays are designed to automatically
capture process related data, such as activities, time stamps,
resources and contextual information (e.g. customer details, case-
speciﬁc data) [1], which has enabled the application of process min-
ing techniques to obtain indicators of organisational performance
from such data. in addition to academic interest in this topic [6–9],
there are currently over 20 commercial process mining tools that
include performance analysis features [1], mostly comparable to the
features provided by disco [10]. most of these techniques analyse a
single dimension of a business process at a time. however, in prac-
tice, process stakeholders are often interested in performance com-
parisons which focus on comparing performance between processinstanceswithdifferentcharacteristics(e.g.performancedifferences
between teams, types of applications) [2–4]. comparing variants of
the same process in such a way can help identify root causes of pro-
cess performance differences. in such scenarios process instances
fromaneventlogarepartitionedintomultiplecohortsbasedondif-
ferentattributes(e.g.resource,caseattribute,contextvariables).thebehaviour and performance of these processes for different cohorts
arethencompared.duetoalackoftoolsupportforsuchcomparative
analyses, they are commonly performed by expert process analystsanalysingeachcohortindividuallyandthenmanuallycomparingtheresults as reported in several recent case studies [2–4].s u r i a d ie t
al.[2]report on comparing cohorts in the event log of a major insur-
ance company. they report having to use a complex chain of tools
for the process, dealing repeatedly with ﬁltering procedures to split
the event log into meaningful cohorts and encountering interoper-
ability issues between various tools. consequently, they describedthe analysis process as “time-consuming, tedious and error-prone”.partington et al. [3]present a comparative study of processes at
four hospitals. they use side-by-side comparisons of process maps
to identify differences in process ﬂow, but report that there is a lack
of tools to support this kind of analysis. while some recent work [4]
has focussed on automating the involved log ﬁltering and metric
computation, these approaches still present the analysis results for
each cohort in separate windows and rely on process analysts tospot the differences. as such, these approaches still make the pro-cessbotherrorproneandnotveryscalable.allthesestudiesrequired
signiﬁcant effort including massaging the data, using multiple pro-
cess mining tools and manually comparing multiple visualisations.consequently, receiving an answer to the simple analysis question
“how does my process variant a differ from process variant b?”,
required organisations in all three cases to engage research teamsoverextendedperiodsoftime.
a research question of interest to both researchers and industry
is therefore: “how can the comparison of process cohorts be sup-portedinan intuitivewaytoenablenon-expertstakeholderstogain
insights from their process data?”. four high-level requirements can
be derived out of the presented analysis scenarios and can be usedto assess the suitability of existing approaches for the presentedanalysis scenarios.
firstly, the researchers had to ﬁlter cohorts to compare out of
one or more event logs. this ﬁltering step sometimes had to berepeated iteratively to identify boundaries of some cohorts or as
the researchers’ understanding of the data evolved. being able to
deﬁne cohorts and split event logs interactively, therefore, appearsto be an important feature for comparing multiple cohorts. while
many tools already support interactive ﬁltering of the event log
being analysed, some approaches [6,11-14] expect the user to pre-
ﬁlter or annotate event logs using separate tools. this increases
the danger of interoperability issues and generally makes interac-
tive exploration of the data infeasible. on the other hand, severalrecent approaches [4,15,16] apply data warehousing techniques to
enable users to interactively specify and explore process cohorts by
proposingtheconceptof “processcubes”.
secondly, the researchers needed to calculate metrics to con-
ceptualise process performance for different parts of the analysedprocess. these metrics all related to frequencies of occurrence and
the time perspective of the process [3]. two issues are of relevance
tothecomputationofthesemetrics.theﬁrstissueinthecalculation
of process performance from an event log is whether the analysis is
awareofthestructureoftheunderlyingprocessornot.forexample,
many existing approaches do not consider parallelism of activities,
which
can distort the results of the analysis [1]. the second issue
is whether the approach can compute the metrics for the compar-
ison interactively, as otherwise interoperability with other tools orinteractivityare again problematic.
fig. 1.overview ofthe proposed approach for processperformance comparisons.m. wynn et al. / decision support systems 100 (2017) 93–108 95
thirdly, the researchers had to compare these metrics for dif-
ferent parts of the process being analysed. notably, all existing
approaches to cohort performance analysis use visualisation to
presentandcompareperformancemetrics.forthistask,theymostlyused side-by-side comparisons of visualised metrics which meant
they had to manually compare visual attributes, such as colour
and line thickness, across multiple visualisations. many existingapproaches, such as existing process mining [6,7,10] and process
cube tools [4,15,16] present their analysis results in such a fashion.
however, approaches using juxtaposition, i.e. side-by-side images
or even matrices of images, are problematic as such comparisonsrequire the analyst to spot the difference between multiple visu-
alisations. this process is cognitively ineﬃcient and scales badly
when more than two values need to be compared [17]. instead,
an integrated approach to present the performance data in one
visualisation could effectively oﬄoad some of the comparison
effort onto the visual perceptual system using preattentive pro-cessing[18]. for example, minit [19], the visual analytics tools for
event log comparison [20–22] and recent comparative visualisation
approaches [11–13] doprovideintegratedvisualisationsforthecom-
parisonoftwocohortstofacilitateunderstandingcohortdifferences.however, most of these approaches visually present the differ-
ence between cohorts, rather than the performance indicator values
themselves. consequently, they are limited to comparing two pro-cess cohorts at a time. van mourik [12]presents the only approach
that presents performance metrics for more than two cohorts in oneintegratedvisualisation.
fourthly, the researchers mentioned interoperability issues
between the numerous tools they used for the analysis slowingdown the process. an integrated approach should therefore be ableto handle all three stages of the comparative analysis: splitting the
event log into cohorts, computing the performance metrics for each
cohort and presentingthedifferencesbetweencohorts totheuser.
the proposed approach therefore ﬁlls a gap as it is the only
solution that fully covers analysis scenarios such as presented by
partington et al. [3], by providing both an integrated and interactive
approach to multi-cohort process performance comparison. ourprevious work [5]proposed projecting performance statistics from
multiplecohortsontoaprocessmodelintheformofbarandtrianglecharts. some designs of visual graphs are adopted from there. how-
ever, the visualisations shown in [5]were manually drawn using
process statistics computed by another application and a simpli-
ﬁed process model. the approach used for visualising waiting times
differences between cohorts is also problematic as it is based ona linear layout of the process. to address these issues we revisedourapproachtousethreedimensionalvisualisationtovisualiseper-
formance data on top of the process model rather than setting the
process model elements into different sizes and colours. with theadditional dimension, more metrics and multiple cohorts can be
displayedinoneintegratedview.italsoenablesuserstointeractively
split an event log and thus to easily explore different cohorts in thedataset.
in summary, comparing the performance of process cohorts is
a problem of interest to industry and academia. however, whilevariousapproacheshavebeenpresentedthatsupportdifferentparts
of such an analysis, existing work on visual comparison of the
performance of multiple process cohorts using event logs still doesnot provide the full capabilities required for some analysis scenariosof interestto industry, as shown in table 1.
3. approach
as the literature review shows there is a lack of tools that enable
an intuitive and direct comparison of multiple process cohorts. inorder to address this issue, we propose a novel tool that enables a
visual comparison of such cohorts. this tool has been designed fol-
lowing a design science methodology as discussed in section 3.1 by
identifyingrequirementsforprocesscohortcomparisonin section3.2
and proposing design principles to satisfy these requirements insection 3.5. these requirements have been met by computing
performance indicators, as described in section 3.3 and applying
visualisation theory, as described in section 3.4.
table 1
comparison of existing tools for comparative process performanceanalysis.
tools cohort split metric computation comparison capabilities results presentation
interactive
cohort
explorationconsiders
parallelismprocessmetric
computationprocess
frequenciesprocesstimingtwocohortsmanycohortsintegratedtwo cohortsintegratedmany cohorts
promreplay plugin [6] no yes yes yes yes no no no no
prominductive visual miner [7],d i s co[10] yes yes yes yes yes no no no no
minit[19] yes yes yes yes yes yes no yes no
procube [15],p m c[4] yes yes yes yes yes yes yes no no
pmcube [16] yes yes yes yes no yes yes yes no
misue[23] yes no no yes yes yes yes no no
buijs[14] no yes yes no no yes yes no no
malik et al. [20] yes no yes yes yes yes no yes no
basoleet al. [21] yes no yes yes no yes no yes no
zhanget al. [22] yes no yes yes yes yes no yes no
boltet al. [11] no no yes yes yes yes no yes no
kriglstein et al. [13] no yes yes yes no yes no yes no
van mourik [12] no yes no yes yes yes yes yes yes
processproﬁler3d yes yes yes yes yes yes yes yes yes
bold entries highlight gaps in currenttool support for comparative process cohortperformance analysis.96 m. wynn et al. / decision support systems 100 (2017) 93–108
fig. 2.methodology overview.
source:adaptedfromhevner [25].
3.1. methodology
the goal of the presented work is to develop a tool that enables a
detailedcomparisonoftheperformanceofmultipleprocesscohorts.
rather than ﬁnding a theoretical truth, it is therefore focussed on
achieving utility. the proposed tool has consequently been designed
and implemented following a design science methodology [24],a s
describedin fig. 2.
the work was started by identifying an industry demand for a
tool to enable process cohort comparison. this need is evidenced ina) the questions that our industry partners were asking and b) at
leastthreerecentcasestudies [2–4]reportingsimilarquestionsfrom
industry. this industry need is therefore an input to the relevance
cycle[25]. furthermore, in section 2, we discussed why current
approaches are not well suited to address these questions. based on
this analysis and by building on knowledge from visualisation and
processminingweidentiﬁedwaystoovercomethelimitationsoftheexistingapproaches. theseinputscomefrom therigorcycle.
consequently,thedesigncycleofthisprojectwasconcernedwith
designingandimplementingatoolforvisualcohortcomparisonand
a rigorous evaluation of this tool’s utility for the described problem.
in the evaluation of our tool we were guided by munzner’s nested
model for visualisation design and evaluation [26]. we focussed
our validation efforts primarily on layers two and three of the
model,namelythedata/operationabstractiondesignandtheencod-
ing/interaction technique design. validating the domain problemcharacterisationisalongtermendeavourandcanonlybedoneoncea suitable problem solution has been developed. algorithm design
on the other hand was not really a concern as this work builds on
existing algorithms rather than proposing new ones. the validationof the encoding/interaction technique design was complicated by
the fact that existing approaches do not fully support the intended
task of cohort comparison making a direct comparison unsuitable.we therefore opted for a descriptive validation by demonstration
as described by hevner [24]. in doing so we demonstrated that the
proposed tool can be used to answer questions about two industry
datasets with little effort. to validate the data/operation abstraction
design and complete the relevance cycle we evaluated the resulting
tool through a user study with two industry partners. the resultingfeedback motivated the implementation of additional features, butalso conﬁrmed that the industry partners found the proposed tool
useful for some analysis scenariosof interest.
in the rigor cycle, the abstraction of our solution, presented in
the form of design principles, adds to the scientiﬁc knowledge onhow to compare process cohorts. since our contribution to knowl-
edgedrawsonmatureapproachesfromtheﬁeldofvisualisationandapplies them to the novel problem of comparing process cohorts, it
can be classiﬁed as an “exaptation” as per gregor and hevner [27].
in the following sections we will describe which theories were usedand howtheywereappliedtoaddress asetofnewproblemsrelatedto comparison of multipleprocess cohorts.
3.2. detailed requirements
inordertodesignanapproachandimplementatool,weproceed
to discuss the requirements that stem from the given task. the aim
of the work presented here is to facilitate the comparison of perfor-
mance of multiple cohorts of cases in an event log. as was discussed
in the related work, this aim already determines some high-levelrequirements.
overall, our approach needs to cover both preparing the data for
comparative analysis and presenting the data in a way that makes it
easyfortheusertointerpret.preparingthedatarequiressupportfor
two steps. firstly, there needs to be a way to specify the cohorts the
user wants to compare (r1). secondly, computing metrics throughwhich the performance of these cohorts can be compared is neces-sary(r2).presentingthedatainawaythatmakesiteasyfortheuser
tointerpretcanmostlikelybeachievedthroughvisualisation.asdis-
cussed in the related work, an integrated approach to present thedata of more than two cohorts in one visualisation (r3) and to facili-
tatethecomparisonofthisdata(r4)isneeded.next,webreakdown
theserequirementsinmoredetailbothbymakinglogicalargumentsand by using examples from the case studies [2–4]motivating this
research.
firstly,weidentifywaystosplitaneventlogintoprocesscohorts
that can be compared. generally, event logs contain information
related to cases and activities. we chose to deﬁne cohorts on the
case level, because a) many contextual factors affecting a case areconstant over the time of its execution, and b) the occurrence andexecutionofactivitiesthatformacaseisoftenbasedonthesefactors.
for example, suriadi et al. [2]analyse cohorts of insurance claims
deﬁnedbytheamountofpayoutandthetotaltimeittooktoprocess
theseclaims.consequently,usersshouldbeabletodeﬁnecohortsat
the case level (r1.1). the approach should then be able to automati-
cally split the event log so that cases are grouped for the subsequentcomputation of performance indicators and comparison (r1.2) to
avoid lengthydata migrationbetweendifferenttools.
secondly, we identify metrics to compare the speciﬁed process
cohorts. the performance of cohorts can be compared by calculat-ing different performance indicators using data in event logs both at
the case and at the model level [28]. for this work we focus on com-
parisonsatthemodellevelusingnodeandnode-pairrelatedperfor-
mance indicators. conceptually, these indicators describe attributes
of activities (nodes in the model), such as the duration of an activ-
ity,andattributesrelatedtopairsofactivitiesthatoccurinsequence,suchasthewaitingtimebetweentwoactivities.wechosethisfocus
as the model level is most likely to give interesting insights and can
beneﬁtfromcontextualisationoftheperformancedata.forexample,m. wynn et al. / decision support systems 100 (2017) 93–108 97
fig. 3.summary ofthe detailed requirements for an approach to visually compare process cohorts.
partington et al. [3]use frequencies of occurrence between pairs
of activities to compare processes cohorts. therefore, the proposed
approach needs to be able to compute these performance indicators
on the level of activities (r2.1) and activity-pairs (r2.2). in addition,
itshouldbepossibletoaggregatethesevalues(r2.3)athigherlevelsof abstraction. this can help with the analysis of very complex pro-
cesses,asforexamplewasthecasewithhospitalprocessesdiscussed
by partington et al. [3]. we furthermore identiﬁed the need to con-
sider parallelism of activities in the performance analysis (r.2.4) in
therelated work.
thirdly, we need to identify how these performance indicators
canbepresentedtotheuserinawaythatfacilitatesmakingsenseofthe data. consequently, we need to ﬁnd ﬁrst of all a way to visually
present the performance indicators for activities (r3.1) and activity-pairs(r3.2).however,theperformanceindicatorvalueshavelimitedmeaning if presented on their own. the contextual variables that
givemeaningtothemarethecohort,andtheactivityoractivity-pair
that these values describe. this means that these three values needto be shown in combination to enable users to understand them.
furthermore,inordertoanalysewhydifferencesexistbetweenpro-
cess cohorts, the user also needs to see these differences in thecontext of the interdependencies between activities. for example,
a bottleneck in a process can be found by ﬁnding an activity that
takesmuchlongerthanactivitiesprecedingandfollowingthisactiv-ity. the dependencies and ordering of activities can be represented
using a process model [1]. this contextual information will help the
user to better understand problems in the process. consequently, it
is important to contextualise the performance data by visualising ittogether with the process model (r3.3) and clearly showing which
cohort it describes(r3.4).
in relation to the speciﬁc task at hand, i.e. comparing process
cohorts, it should be possible to display multiple sets of data valuesat once. depending on the speciﬁc scenario, the analysis might then
require the user to compare performance indicators across activi-tiesoractivitypairstoidentifytrendsandbottlenecks(r4.1,r4.2)as
discussed above, compare values across cohorts (r4.3) or even both.
forexample,partingtonetal. [3],compare“hourstillinpatientcare”and “hours in inpatient care” by aggregating time from duration andwaiting times along parts of the process model and then comparethesevalues betweenmultiplecohorts.
an additional set of requirements (r5) is rooted in the generic
tasks users perform to explore and understand visual data [29].a
number of visual mapping parameters (such as data normalisation
modes) should be accessible to the user to suit their scenario and
individualpreferences(r5.1).furthermore,displayingalargedatasetin an integrated way will lead to high visual complexity, therefore
theuser should be able toreduce thevisual complexity(r5.2).
a ﬁnal requirement (r6) stems from the way these tasks are
integrated. not only does such an integration remove tool chaininteroperability issues as discussed by partington et al. [3],i ti s
also the only way to enable truly interactive exploration of process
data. interactivity is important for knowledge generation in visual-isation[30]and its effects on knowledge generation processes and
outcomes have been demonstrated even for small interaction laten-cies[31]. the need to repeat steps of data ﬁltering and to iteratively
adjustthespeciﬁcationofcohortsinordertoﬁndmeaningfulcohorts
tocomparehasalsobeenreported [3].fig.3summarisestherequire-
ments that have been derived from the task of visually comparing
process cohortsas discussed above.
buildingatoolthatmeetstheserequirementsshouldenableusers
tointuitivelycompareprocesscohortsbasedoneventdata.thenext
sectionsdiscussdesigndecisionsmadetosatisfytheserequirements
in turn.
3.3. computation of performance-related statistics
to compute the performance statistics, we generally follow the
algorithms presented by adriansyah [28]. we compute an align-
ment between a given event log and a petri net process model [32]
using an existing prom [33]plugin (“ replay a log on petri net for
performance/conformance analysis” [6]). given this alignment we
can reconstruct the movement of tokens through the petri net and
create a graph of dependencies between events in the event log, as
fig. 4.computationofperformanceindicatorsforcase1inaneventlog.eachedgeinthegraphrepresentsatimeinterval.someperformanceindicatorscanbe thesumofseveral
edges.98 m. wynn et al. / decision support systems 100 (2017) 93–108
shown in fig. 4. conceptually, each edge in this graph then repre-
sents a time interval. therefore these edges can be used to calculate
timing statistics such as durations and waiting times of activities
usingonlyadditionandsubtraction.thissatisﬁesrequirementsr2.1and r2.2. in addition, since process structure is encoded in the petri
net, this approach also deals with concurrency of events in the log.
for example, without the graph, the waiting time of c would beincorrectlycalculatedasc
start −bcomplete.theapproachthereforealso
satisﬁesrequirementr2.4.
our approach differs from that of adriansyah [28]in two ways.
firstly, the order of individual steps in the algorithm is reversed to
reduce computational overhead and enable interactive data explo-
ration. adriansyah’s approach assumes a fully prepared event log
for analysis. that means that to analyse two cohorts, the originallog would be split into two event logs and then each log is aligned
with the model before computing performance statistics. in order
to compare two different cohorts, the original log would have tobe split again, and both alignments with the model and the perfor-
mance indicators would have to be recomputed. our approach ﬁrst
aligns log and model once, then computes performance indicatorsonce. then, instead of statistically summarising the calculated per-formance indicators at the time they are computed, we store each
individual value (i.e. edge in the dependency graph) for each case
contained in the log, using an online analytical processing (olap)approach. this approach enables users to repeatedly split perfor-
mance data into cohorts and quickly aggregated summary statistics
for each cohort from the individual values. consequently, while thealignment may still take a long time to compute (as in the approach
by adriansyah), we only have to compute it once and can then cal-
culate the performance data for each new cohort in real-time andwith much less overhead. this enables the dynamic aggregation of
performance statistics for user speciﬁed cohorts (at runtime), satis-
fying r1.2. secondly, for hierarchical petri nets we aggregate valuesat higher levels of the process by adding up the time intervals ofconnected edges that together represent a sub-process. doing so
enables the display of performance indicators at multiple levels of
abstraction of theprocess, as required by r2.3.
an underlying assumption of this approach is that the structure
of the process model used for the computation does not change,as the organisational process represented by the model should bestatic over the course of analysis. however, analysts could be inter-
estedinaddinglevelsofhierarchytoaggregateperformancedatafor
different segments of the model. in principle, this is supported bythe approach, as the underlying process structure does not change
and only the aggregation step would have to be repeated for new
subprocesses, whichgenerallytakeslittletime.3.4. visualisation design
our requirements discuss that all cohort performance values
including their association to a cohort, an activity in the processand any dependencies with other activities should be presented inone view. we therefore need to encode performance statistics and
contextual variables pertaining to these statistics, such as process
cohorts and activity they belong to, in different visual dimensions ofthatview.ingeneral,datacanbeencodedinoneofsevenvisualvari-
ables,suchasshape,colour,size,orientation,brightness,textureand
position of a visual element [34]. the performance data exists in the
formofcounts,suchasfrequencyofoccurrence,andtimespans,such
as activity duration and waiting time. in both forms it is continuous
and can potentiallyhave a large range of values. the largest capacity
ofvaluesthatcanbevisuallydistinguishedisinthesizevariable [35],
making sizean idealdimensionto encodeperformance data in.
existing approaches to performance visualisation therefore often
encode performance data in the visual parameters of process modelelements and consequently present a process model, such as the
size of an activity. however, such an approach can only encode one
dimensionofdata.forthecomparisonoftwocohortsonecaninsteadencode the difference between these cohorts to work around this
limitation,butwewanttobeabletocomparemorethantwocohorts.
barchartsareacommonapproachtovisuallycomparemultipleval-ues encoded in size along the same dimension. however, bar chartsdo not provide a way of encoding dependencies the way a process
model does. we therefore combine principles from both visualisa-
tions, by overloading the space of the process model with additional
visual elements [36], one for each cohort per activity. however, we
encode the data values in the size of the visual elements in a dimen-sion that is orthogonal to the two dimensions used for the processmodel. using this third, orthogonal, dimension of height exclusively
to visualise the performance statistics values means that all values
canbeseenrelativetothegroundplane.ourencodingusestheprin-ciple of superimposition as all data is encoded along one dimension
(i.e. “height”) and therefore facilitates comparing values in the same
wayabarchart does [36],supportingbothglobalcomparison ofval-
ues and comparison of local values within a model wide overviewcontext [29]. at the same time this approach minimises occlusion
and layout issues and maximises perceptual popout, enabling the
user toviewthedata whilenot losingany ofthedata’s context [18].
as mentioned in the requirements earlier, the data also requires
context information to understand it properly. the visual elements
are drawn connected to the model elements they describe, usingthe principle of “connectedness” [35]to signify which piece of data
belongstowhichactivityorpairofactivitiesintheprocessmodel.in
fig. 5.visualisation ofperformance statistic values relative to red cohortvalue using colour coded bar charts(left) and triangle charts(right) on top of activities.m. wynn et al. / decision support systems 100 (2017) 93–108 99
addition,therearealwaysmultiplebutfewcohorts(2–8),whichcan
be considered a nominal variable in terms of data. the human visual
systemcandistinguishcoloursmosteffectively,especiallyarangeof
7–10 different colours [35]. we therefore chose colour to represent
visual glyphsof onecohort satisfying requirementr3.4.
in the case of performance statistics belonging to an activity we
draw visual glyphs, previously introduced by pini et al. [5],o nt o p
of the activity. the two main techniques that are used to comparerelative values between cohorts for each activity are bar charts and
triangle charts (see fig. 5). the ﬁrst technique shows the value of
the ﬁrst variable for a transition for each cohort as the height of a
coloured bar and the relative value of a second variable as width of
each bar segment. this enables displaying performance indicators
suchasthedurationofanactivitytogetherwithcontextualinforma-tion, such as how often the activity occurred. the second technique
can show two variables as width and height of an isosceles triangle
tothesame effect.
for activity pairs, we utilise an arc visualisation, inspired by an
iso-line approach taken from sun radiation visualisations [37].a r c
visualisationshavetraditionallysoughttoshowconnectednessrela-tionships between diagram components [38]and in our approach,
the arc starts at one activity of the respective activity pair and ends
at the other. the height of the arc signiﬁes the magnitude of the
visualised value as shownin fig. 6.
to prevent cognitive overload, users are provided with ways to
ﬁlter out and aggregate information as forms of complexity man-agement. firstly, due to the use of a three-dimensional space forvisualisation the user can move and rotate the camera in all three
dimensions.thiswaytheusercanfocustheviewonregionsofinter-
est in the process model so that uninteresting data is outside of theview region or to avoid occlusion issues. secondly, users can see
aggregated data using hierarchy in the process model and ﬁlter out
irrelevant data by selecting individual model elements or cohorts ofinterest.thesefeatures satisfy requirementsr5.1 and r5.2.
overall these principles have been chosen to enable an intuitive
visualisation and comparison of performance data from multiplecohorts.
3.5. design principles
we have shown in the related work, that support for process
cohort comparison is still fragmented and no existing approach sat-
isﬁesalltherequirementswehaveidentiﬁedintheprevioussection.
weseethisasanindicationthatgeneralguidanceondesigningsolu-tions that address this problem may be needed. while we have dis-
cussed speciﬁc design decisions that were made in order to develop
a system that addresses all requirements, we also want to abstractout general design principles from this solution that will provideguidance in the development of other tools for process cohort com-
parison. these principles explicate abstract features of form and
function inherent in the design of our instantiation and relate thesefeatures to the identiﬁed requirements in order to provide guid-
ance for the development of further artifacts of the same class. they
thereby constitute explanatory design theory as per baskerville andpries-heje [39].
fundamentally, comparing the performance of process cohorts
requires preparing and presenting the performance data. prepara-
tionusuallyincludessplittingtheeventlogintocohorts,aggregatingevent data to a sensible level of detail and computing performance
indicators for each cohort. as reported by partington et al. [3]this
processisoftenrepeatedascohortshavetobeadjustedandthefocus
ofinterestshiftsbetweendifferentpartsoftheprocess.wediscussed
earlierthatforgaininginsightsintodatainteractivedataexploration
is important [30]. in order to make data exploration interactive, we
neededtoreducea)thetimeusersspendmovingdatabackandforth
between different tools and b) the time spent recomputing align-
ments between log and model. to this end, we needed to integratebothdatapreparationanddatapresentation.wethereforepositthatatightintegrationofdatapreparationandpresentationshouldallow
userstointeractivelyexploretheirprocessdataandinturncompare
process cohortsmore effectively:
•dp1: integrate data preparation and data presentation to
enableinteractivedata exploration.
to address requirements relating to the computation of process
performance metrics for cohort comparison in more detailed wepropose threeadditionaldesign principles:
•dp2: enable users to specify concurrent activities to correctlycomputeperformanceindicatorsinthepresenceofparallelism
•dp3: enable users to deﬁne cohorts interactively to test
hypotheses
•dp4:presentperformancedataatmultiplelevelsofabstraction
to allow users to gain an overview of the data and drill-down
fordetails-on-demand.
firstly, process data in the form of event logs usually serialises
the entire process and loses dependency and concurrency informa-tion in doing so. however, this information can often be relevant in
performance analysis, for example when computing waiting times
between different parts of the process. an approach for cohort com-parison should therefore enable the user to provide domain knowl-
edge,forexampleintheformofaprocessmodel,sothattheanalysis
is aware of the underlying process structure. secondly, as has been
fig. 6.visualisation ofperformance statistic values using colour coded arcs betweenactivity pairs.100 m. wynn et al. / decision support systems 100 (2017) 93–108
table 2
summary of design decisions that implement design principlesand satisfy our requirements.
dp1olap approach enables interactive data preparation and presentation r6
dp2align event log with processmodel for computation of node and node pair relatedpis in the presenceof parallelismr2.1
r2.2
r2.3
dp3olap approach enables splitting data into cohorts, activities and pi typesr1.1
r1.2
dp4 olap approach can aggregate data on multiple levelsof abstraction interactively r2.3
dp6visual glyphs from pini et al. [5]enable presentation ofnode related pis r3.1
use of arcsenables presentation ofnode pair relatedpis r3.2
showﬂat process model r3.3
use of colour to show association ofvisual glyphs with cohorts r3.4
dp5node related pi visual glyphs and node pair related pi arcs areconnected to nodesin processmodel, superimposed in shared vertical axis for easy comparisonr4.1
r4.2
values for different cohorts share vertical axis, related values arelocated nearby r4.3
dp7differentglyphs and normalisation modes canbe used to customize visualisation r5.1
navigation of 3dspace, zoom and ﬁlter can beused to manage view complexity r5.2
discussed above, the ability to interactively deﬁne cohorts and split
the event log is important for cohort comparison. finally, real-world
processes can be very complex, therefore comparing them at a high
level and then drilling down into the details that are of interest canhelptomakethecomparisonmoremanageable.partingtonetal. [3],
forexample,discusshowtheyaggregatedmetricsforseveralhigher-
level stages of the hospital process to deal with the complexity oftheir process model for analysis. we therefore argue that it is neces-
sary that an effective approach to compare process cohorts needs to
enableusers to compare theircohortsat differentlevelsof detail.
when comparing process cohorts using performance metrics the
presentation of cohort performance should make the identiﬁcation
andunderstandingofdifferencesbetweenmultiplecohortseasy.wepresent three more design principles that can be used to guide thedesignof process cohort comparison approachesto do so.
•dp5:visualisecohortperformancedatainoneintegratedview
to facilitatecomparison
•dp6: present related data in orthogonal dimensions to enable
contextualisationof thedata
•dp7: enable users to navigate and ﬁlter the visualisation to
manage viewcomplexity.
firstly, we propose that all the relevant data attributes for cohort
performance comparison need to be presented in one integrated
view. we reiterate that multiple data attributes (such as associa-tion of cohort, activity, performance indicator) are integral to the
analysis task and juxtaposing multiple complex visualisations scales
badly and makes the analysis harder for the user [17]. a solution to
this problem is therefore an integrated visualisation that shows allthe relevant data in one view. secondly, presenting multiple data
attributesinoneviewisnottrivialasthisrequiresthatmultiplesets
of values (i.e. the average waiting time in each cohort for one spe-
ciﬁc activity) a) can be viewed at the same time, b) can be clearlydistinguishedfromeachotherandc)canbedistinguishedfromunre-
lated values (such as the waiting times for other activities) so that
no visual overload occurs. one way to ensure that different valuescan be clearly separated and related values can be clearly compared
is to use a separate visual dimension for each attribute. this way
superimposition can be used to ensure good comparability of values
and preattentive processing can be used to ﬁlter out unrelated data.
lastly, in addition to presenting the data in a cognitively eﬃcient
way,theusershouldalsobeprovidedwithwaystomanuallymanageviewcomplexity.
together,thesedesignprinciplesinformthedesignofanapproach
tocompareprocesscohortperformanceeffectively. table2showshow
the requirements identiﬁed earlier are met by design decisions thatwere made and which design principles these decisions implement.
nextwewilldemonstratethatthedesignedapproachforcohortcom-
parisonisfeasibleandhasbeenimplementedasaresearchprototypetool by discussing our implementation.
4. implementation
as a proof of concept the computation of performance indicators
as described above, as well as the visualisation of the performance
indicators, have been implemented in two separate plug-ins for
prom[33]. the “process proﬁler 3d: generate performance proﬁle”
plug-in calculates performance statistics for a given petri net by
fig. 7.process proﬁler3d: generate performanceproﬁle- prom plugin overview.m. wynn et al. / decision support systems 100 (2017) 93–108 101
fig. 8.anexampleoftheperformancedatathatisstoredinthedatacube.tocomputethesummarystatisticswegrouprowsbya)cohortb)nodeornodepairidc)pi labeland
then d) summarise over the grouped values.
replaying a given event log (section 4.1). the “process proﬁler 3d:
visualise performance proﬁle” plug-in visualises the data in vari-
ous ways that support the identiﬁcation of performance differences
betweenprocesscohorts(section4.2).
4.1. creation of a performance statistics enriched net
for the computation of performance data, a number of steps are
performed which are discussed in this section. fig. 7provides a high
leveloverviewoftheoperationsthepluginperforms.
for this work we assume the presence of an event log that
contains at least timestamps for the completion of all activities. fur-
thermore, we assume the existence of a process model which has
a high ﬁtness for the event log in the form of a petri net. a mis-aligned process model can result in the computation of incorrect
performance metrics. while this assumption is not trivial, several
techniques are available to manually create or automatically minesuchmodelsfromeventlogs [1].similarly,hierarchyinprocessmod-
els can be achieved either by automatic decomposition or manual
editinginprocessmodellingtoolssuchaswoped [40].forthereplay
of logs on hierarchical petri nets the hierarchical net is projected
into a ﬂat net. this projection is performed automatically by recur-
sively replacing each activity with its corresponding subnet. then areplay of the event log on the process model is performed using thereplay plugin of prom to create an alignment between the petri net
model and the log. using the resulting alignment, the ﬂow of tokens
through the petri net is reconstructed. the reconstruction enablestheidentiﬁcationofdependenciesbetweentheeventsinthelogand
is used to calculate the required performance indicators. we calcu-
late the performance indicators by recording a token path for eachmove of a token on the petri net from one place to another. each
token path instance is linked to preceding token path instances that
created thetokensit consumedand storestheeventintheeventlogthatitcorrespondsto.eachtokenpathinstancealsohastimestampsattached to its beginning and end based on when the token in thestart place was created and when it was created in the end place.
each activity in the process is now represented by one or more
consecutive token path instances that each represent a time span.consequently, each case of the process is represented by a directed
graphannotatedwithtimestamps.wecanthereforecomputetimes-
pans between different activities by traversing this graph, whichresultsinacompositepathwithastartandcompletetimestamp.the
time span that is represented by this composite path is one perfor-
mance indicator value. the resulting performance indicator valuesare thenstored inthedata cube.
theinteractivecomparisonofprocesscohortsissupportedbythe
use of data warehousing techniques [41], in the form of a relational
online analytical processing (rolap) datacube, to store individualperformance indicator values and attributes that describe their con-
text in a database. fig. 8shows an example of the data that is
stored in this datacube. as shown, there exist zero or more perfor-
mance indicator values for each case in the database. an example
of a database row for a performance indicator value would be a
numeric value representing the waiting time for one activity exe-cuted in one case of the event log, the case identiﬁer of the case,
the identiﬁer of the activity and the label identifying the seman-
tics of the stored value, i.e. identifying the value as a waiting time.the identiﬁer of the cohort that case is currently assigned to is also
stored and updated whenever the cohort speciﬁcation changes. this
approach enables us to dynamically split the dataset into cohortsbased on these attributes, which is known as “slice&dice” (satisfyingr1.2) and to aggregate statistical summaries of the indicators (such
as minimum, maximum and mean) at runtime, which is commonly
referredtoas“roll-up”operation(satisfyingr2.3).furthermore,per-formance values for activities are computed and stored at each level
of the hierarchy provided by the process model, so that the user
can view performance summaries at different levels-of-detail. byusing these operations, users can interactively explore the dataset
fig. 9.process proﬁler3d: visualiser - promplugin.102 m. wynn et al. / decision support systems 100 (2017) 93–108
fig. 10. left: visualisation of differencesin waiting time between transitions; center and right: speciﬁcation ofprocess cohorts based on case levelattri butes of the event log.
and test their hypotheses rather than having to recompute the
performance statistics for each different question they would liketo investigate. in addition, since the performance data is computed
and stored independently of the layout of the process model, users
can modify the model layout and still visualise the data withouthaving to recompute it. while it would be possible in principle to
let users insert additional levels of hierarchy into the model inter-
actively by re-aggregating performance data, our implementationcurrently does not support this, as adding model editing features
would have signiﬁcantly increased the complexity of the imple-
mentation. the complete implementation of the algorithm can befound in the code repository at https://svn.win.tue.nl/repos/prom/
packages/processproﬁler3d/.
4.2. performance data visualisation
theperformancedataisvisualisedinwidgetsontopofthe(hier-
archical) petri net. fig. 9shows an example of cohort performance
data visualised using the performance proﬁle visualisation plugin
for the prom framework. in order to reduce layout and overlapissueswhenvisualisingthisdata,athree-dimensionalapproachwas
chosen in which the petri net is shown in two dimensions and per-
formance data is visualised in the third dimension. this approachenablestheusertohandleoverlaporinformationoverloadbychang-
ing the perspective from which the data is shown. as suggested by
the design principles (see section 3.5), the plug-in provides func-
tionality for visualising cohort performance data, managing view
complexityand deﬁningprocesscohorts.
currently several visualisation techniques are available to com-
pare the statistics data calculated for each transition including two-dimensional barcharts and triangle glyphs. furthermore, statistical
datathatrelatestoconnectionsbetweentransitions,suchaswaitingtimesbetweenactivities,canbevisualisedusingthearcvisualisation
techniquedescribedin section3.4 (seefig.10).ifthevaluesofsome
cohorts are close and overlap, we merge the arcs to avoid visibility
issues. in that case the arc will be drawn with coloured stripes for
each cohortthat itisrepresenting.
in order to manage the complexity of the visualisation, users of
the plug-in are provided with options to abstract, ﬁlter and nor-
malise data. firstly, abstraction is provided on the level of the petrinet.ifthenetishierarchicaltheusercanviewtheaggregatedperfor-
mance statistics of a transition and open up the subprocess to view
data at a lower level (see fig. 9). secondly, the user can choose to
hide visualisations concerning speciﬁc transitions, arcs and cohorts.
thirdly,threenormalisationmodesareprovidedtonormalisevisual-
isationelementsatthelevelofatransition,sub-processortheentiremodel. additionally, visualisation arcs can be normalised by cohort,as discussed in section3.4.
processcohortscanbespeciﬁedbytheuseratruntime.tospecify
a cohort, the user selects a case attribute available in the event log
andthenspeciﬁeswhichcasesareincludedinthecohortbyselecting
the set of attribute values that should be included (see fig. 10). the
plug-in then automatically aggregates and displays the performance
statisticsforthespeciﬁedprocesscohorts.
overall, the two prom plug-ins together implement the frame-
work for visual process performance comparison that has beendescribed in section 3. they enable the comparison of event log
cohort performancein aquickand intuitivevisual manner.
5. validation
inthissection,twoevaluationsoftheutilityoftheprototypetool
willbepresented.wedeﬁneutilityas the tool’s ability to enable users
to compare the performance of multiple process cohorts interactively .
fig. 11. analysisofcaseruntimebyinjuryseveritygroupedintofourcohortsinprocessproﬁler3d.atrendchangecanbeobservedafterthecheckliabilityac tivityintheprocess
for both the injuryseverity “not reported” cases (red) and the “high” injury severity cases (yellow).m. wynn et al. / decision support systems 100 (2017) 93–108 103
firstly,thisutilitywillbedemonstratedbyshowinghowthetoolcan
be used to analyse twoindustrydatasets. secondly,an in-depthuser
study that was performed with the practitioners from two organi-
sations will be discussed. these evaluations were performed in thecontext of a larger research initiative on identifying impediments
to insurance claims processing which is supported by queensland
motoraccidentsinsurancecommissionandthequeenslandgovern-ment. the scope of the analysis reported in this paper is limited tothe evaluation of the utility of the prototype and the comments pro-
vided by the participants in the user study are also limited to the
impressions thattheparticipantshave about theprototypetool.
5.1. demonstration with industry datasets
asaﬁrststepinthevalidationoftheprototypetool,twoindustry
data-setswereanalysedusingthedifferentfunctionalitiessupported
by the tool. the ﬁrst event log was provided by the nominal defen-
dant(nd),anorganisationthatprovidesinsurancecompensationfor
injuries resulting from negligent driving of unidentiﬁed or unregis-teredmotorvehiclesinqueensland,australia.theeventlogcontains
data relating to 964 insurance claim cases handled by the nominal
defendantbetween2006and2015.thelogconsistsof25,571eventswith 66 distinct activities. the median claim took 23.3 months tohandle from start to ﬁnish. another event log was provided by the
royalautomobileclubofqueensland(racq),alicensedqueensland
ctp insurer. the process for claims handling is similar to the nom-inal defendant on a high level, but the details of claims handling
differ. the event log contains data relating to 1091 claim cases han-
dled by racq between january 2012 and july 2015 and consists of44,786eventswith65distinctactivities.themedianclaimtook16.7
months to handle from start to ﬁnish. both logs also include several
case attributes that describe the context of the handled claim, suchas the severity of claimant injury, plaintiff and defendant law ﬁrms
involvedinthecaseandanonymisedinformationabouttheclaimant.
after an initial cleaning of the log data, hierarchical petri net modelsof both claim handling processes were constructed from these logs.we validated the models with the nominal defendant and racq
by explaining the model to their process managers and conﬁrming
that they represent the processes correctly. we analysed both logsto answer multiple questions for both industry partners. to demon-
strate the utility of the tool, two examples taken from this analysis
will be discussed. a question of particular interest to the nominaldefendant was how the severity of the injury affects process per-
formance. racq wanted to know whether there are differences in
process performance based on the region the solicitor’s oﬃces arelocated in.the ﬁrst question was investigated by splitting the dataset into
processcohortsbasedonthereportedinjuryseverityoftheclaimant.
this resulted in four cohorts: “not reported” (235 cases), “low”
(666 cases), “high” (25 cases) and “uncertain” (38 cases). the “notreported” cohort contains cases for which the dataset did not con-
tain injury severity scores. cases with “low” injury severity involve
injuries that are generally considered not life-threatening, rangingfromminorlacerationstomultiplebonefractures.caseswith“high”injury severity involve injuries that are considered life-threatening
or fatal. the “uncertain” cohort contains cases where it has not yet
been possible to judge the impact of an injury, e.g. in the case of asevere head injury. the average case runtime per cohort was then
visualised on top of the high-level process model, normalised per
activity(see fig.11).itcanbeclearlyseenthatcaseswithhighinjury
severity overall take longer than cases with low injury severity, as
indicated by the bar chart on the last activity. interestingly, we can
also clearly observe that cases with the injury severity being either“not reported” or “uncertain” take more time than any other cohort
in the early stages of the process and then proceed much faster
towards theendof theprocess.
the second question was investigated by splitting the event log
into four cohorts, based on the postcode of the claimant solicitor’s
oﬃces.tothisend,thepostcodesweregroupedintofourgeographic
regions that are meaningful to the industry partner. the ﬁrst cohortincludesbrisbane’surbanandsuburbanarea(394cases).thesecond
cohort includes the remainder of south east queensland including
the gold coast and sunshine coast regions (186 cases). the thirdcohortcontainstheremainderofqueensland(67cases)andtheﬁnal
region groups all solicitors with oﬃces outside of queensland (22
cases). when the average waiting time between all activities is visu-alisedpercohort(see fig.12),itcanbeseenthatnocleardifferences
emergeandonlytwoarcsstickoutoftherestofthevisualisation.oncloser investigation, these two arcs represent only three cases each,so they constitute outliers, rather than signiﬁcant trends. from this,we can conclude that there are no signiﬁcant differences visible for
cohortsbased on thelocationof claimantsolicitor’soﬃces.
overall, we successfully used the tool to investigate multiple
questions that were of interest to our industry partners and dis-cussedtwoofthemasexamples.theproposedtoolexposespatterns
in the data that would have remained unnoticed using traditionalspreadsheet-based approaches. moreover, the results can be related
much better to the actual process as trends over time (in this case
not relating to absolute time spans, but rather progression throughthe process) can also be discerned. these examples involving real-
world data-sets demonstrate that the tool can indeed be useful for
an objectivecomparison of processcohorts.
fig. 12. analysisoftheaveragewaitingtimebyclaimantsolicitor’soﬃcelocationgroupedintofourcohortsinprocessproﬁler3d.mostarcsaremergedforal lcohorts,indicating
that there is no signiﬁcant differencein waiting times betweenthe cohorts. a few individual case outliers canbe seen sticking out.104 m. wynn et al. / decision support systems 100 (2017) 93–108
5.2. user study
while the demonstration provided some evidence that the pro-
posed approach to comparative analysis works, demonstrating the
relevance of the tool in a real-world setting is an important part ofdesign science. to gather in-depth feedback on how the tool would
perform in such an environment, a study was performed with our
twoindustry partners(ndand racq, see section5.1).
in this study we investigate ease-of-use and usefulness of the
proposed tool for industry practitioners, as they are major factors
inﬂuencing adoption of technology [42]. we adopt the deﬁnitions of
davis[42],whodeﬁnesease-of-useas“thedegreetowhichaperson
believesthatusingaparticularsystemwouldbefreeofeffort”anduse-
fulnessas“thedegreetowhichapersonbelievesthatusingaparticular
system would enhance his or her job performance”. we thereforewanted to identify individuals in the organisations that would use
such a tool in their work. we used a purposeful sampling strategy,
snowballsampling [43],toidentify12individualsinvolvedinprocess
management and execution in both organisations across a variety
of roles, includingteamleaders, managers, businessintelligenceand
data analysis roles. the tool prototype was demonstrated to theseindividualsbyvisualisinglogdatafromeachorganisationandletting
the stakeholders propose conﬁgurations of visualisation parameters
to gain insights from the data. the purpose of this demo was to givethem an understanding of what kind of insights can be gained withthe proposed tool and how much effort would be involved in using
it.afterwardstheiropinionsandfeedbackonthetoolwerecollected
withasetoflikert-scalequestionsmodiﬁedfromtheperceivedease-of-useandperceivedusefulnessscalesofthetamquestionnaire [42]
and a semi-structured interview with open-ended questions. thequestionnaire covers two topic areas: the perceived ease-of-use ofthevisualisation(pt1–pt10)andtheperceivedusefulnessofthepro-
totype tool (pt11–pt16). answers on a 7-point likert-scale ranged
from “strongly disagree” (1) to “strongly agree” (7).
both measurement scales showed high reliability, with cron-
bach’s alpha coeﬃcients of 0.832, 0.934 respectively. the perceived
ease-of-usewasoverallratedpositive,whereastheperceiveduseful-nesswas ratedless positive.thisobservation hasbeenconﬁrmedbytesting whether responses are signiﬁcantly different from the neu-
tral response using a one-sample wilcoxon signed rank test (see
table 3). a precondition for this test is that each pair is chosen ran-
domly and independently. while a purposeful sampling approach
was used to identify the participants, the preconditions for the test
have not been violated, as each individual was engaged in a sepa-ratetimeslotandnoscreeningofparticipantswasperformedbythe
research team. there is no indication that the sample of participantsengaged in this way would differ signiﬁcantly from the target popu-
lation (i.e. all process data analysts in any organisation). the results
show that for 13 of the 16 questions the responses are signiﬁcantly
different and on the positive side. the medians for pt1-pt10, how-ever,arehigherthanthoseforpt11–pt16.whiletheseresultsshould
not be over-interpreted due to the low number of participants, we
were able to conﬁrm these sentiments in the qualitative analysis ofour interviewswiththesame participantsas well.
theinterviewsweretranscribedandthecommentsofthe12par-
ticipantswerecodedindependentlybytwomembersoftheresearch
team to categorise the comments. a meeting to converge on sharedcategories found that, despite slight differences, the categories of
both coders mapped well to each other. as a result three main
categories of statements made by the participants were identiﬁed:positivecommentsaboutthetool,negativecommentsaboutthetool
and suggestions for improving the tool. the categories of the second
coder also led to the decision to split both the positive and neg-ative comment categories into ease-of-use and usefulness related
subcategories.
regardingtheease-of-useofthetool,themajorityofparticipants
stated that it helped them to quickly identify anomalies and trends
in the data . some participants felt that the visualisation integrates
well with their mental model of the process and therefore enables an
easy comparison with existing process knowledge. the participants
generally found the visualisation impressive and appealing and many
participants stated that overview, drill-down and the normalisation
modes were helpful ingaininginsightsintothedata.whilesomepar-
ticipantsfeltthatthetoolwouldbe easy to learn and easier to use than
spreadsheets, a few participants thought the 3d aspect could makethe tool diﬃcult to use and would require training. there were alsoconcerns that business users might be unfamiliar with the terminol-
ogy used for visualisation parameters and the interface being more
complex than some existing (but less powerful) tools. two speciﬁcissues with the visualisation were mentioned. firstly, two partic-ipants noted that the arc visualisation can be hard to read when
it gets crowded. secondly, a participant pointed-out that bolder
colours used to indicate speciﬁc cohorts might affect the perceptionoftheirdominanceovertheprocessmodel.asummaryofthethemes
concerningtheease-of-use of thetool isprovidedin table 4.
talkingaboutusefulness,themajorityoftheparticipantsthought
thetoolcanbeusedtodraw relevant insights from process data ifdata
andprocessmodelsofhighqualityareavailable.onepersonpointed
out that the tool could improve process analysis by reducing the role of
instinct and guesswork in analysing the data .manyparticipantsagreed
that the tool enabled them to quickly identify areas that required fur-
ther analysis andhelpedthemtoconﬁrmorquestionpre-conceptions
table 3
one-samplewilcoxonsignedranktesttodeterminesigniﬁcantdifferencefromneutralresponse.answersdifferstatisticallysigniﬁcantlyfromth eneutralresponseat p<0.05.
pt question zm ed. s ig.
1 i found the visualisation easy to learn. 3.140 6 0.002
2 i found exploringthe data using the visualisation was easy. 2.818 5 0.005
3 i found the parameters of the visualisation system easy to understand. 2.790 6 0.005
4 i found it easy to combine parameters to createvisualisations. 2.842 6 0.004
5 i found it easy to see the relationships between cohortsin the visualisation. 2.980 5.5 0.003
6 i found the data in 3d visualisation to behard to track when moved. −0.426 3.5 0.670
7 i found the organisation of the data in the visualisation to beclear. 3.035 6 0.002
8 i found it straightforward to understand the visualisation tasks presented to me bythe researchstaff. 3.213 6 0.001
9 i found it easy to compare a cohort with other cohorts. 3.134 6 0.002
10 i found it easy to view a subset of cohorts fromthe set of cohorts presented. 3.002 6 0.003
11 using the 3dvisualisation would enableme to accomplish tasks morequickly. 2.326 5 0.020
12 using the 3dvisualisation would improve myjob performance. 2.333 4.5 0.02
13 using the 3dvisualisation in my jobwould increase myproductivity. 1.667 4 0.096
14 using the 3dvisualisation would enhancemy effectiveness onthe job. 2.157 5 0.031
15 using the 3dvisualisation would make it easier to do my job. 1.035 4 0.301
16 i would ﬁnd the 3dvisualisation useful in my job. 2.156 4.5 0.031
boldentries highlight gaps in currenttool support for comparative process cohortperformanceanalysis.m. wynn et al. / decision support systems 100 (2017) 93–108 105
table 4
themes surrounding the ease-of-use ofthe tool.
positive negative
•visualisation is impressive and appealing •user interface not (business) user-friendly
•would be easier to use than spreadsheets and easy to learn •tool has more overhead than simpler tools
•helped quickly and easily identify anomalies, outliers, differencesand trendsin data •3d is perceived as diﬃcult and would requiretraining
•overview, drill-downand normalisation modes are good to gain insight into data •arc visualisation sometimes hardto read
•visualisation integrates well with mental model of process •colour codes forcohort can affectperceived dominance of a cohort
about process performance for different cohorts. the various fea-
tures of the tool, such as providing a quick overview of all data,
drill-downintothedetailsandnormalisationmodes,wereperceived
asgood for analysing and managing complex processes. some partic-
ipants also came up with additional use-cases for the tool that we
hadnotconsidered.firstly,itwassuggestedthattheinteractiveview
could improve process understanding of stakeholders as it was easier
to understand than paper printouts of the process. secondly, some
participants suggested that the visualisation could be used to justify
process changes by demonstrating differences in process performance
to otherstakeholders.
despitetheseoverallpositivecomments,threeparticipantswere
uncertain about the business value of the application, due to per-ceived limitations of the tool. one problem mentioned is that thedata that is currently recorded and available for analysis often does
notprovideenoughdetailtocreateinterestingandbusinessrelevant
insights. consequently, while the participants saw the usefulness ofthe visualisation aspect in the demonstration of the tool, some of
themdidnotﬁndtheinsightsgainedfromthepresentedanalysissce-
narios particularly surprising from a business perspective. anotherissue is the availability of a good process model that ﬁts the event log
whilebeinghuman-readable.someparticipantsalsomentionedthat
managing simple processes may not require the level of sophistication
provided by the tool and is already covered by simpler tools.
thespeciﬁcskillsrequiredtousethetoolmayalsocreateabarrier
to using the tool for business users. for example, four participants
were concerned that people without suﬃcient process modellingexpertise or domain knowledge would not be able to understand
and use the tool. an interesting discussion, as to whether the tool’s
analytic capabilities would be more beneﬁcial for managers, processparticipants or both, emerged from these points. however, many
of the issues constraining the usefulness of the tool are contextual
rather than inherent to the tool itself. accordingly, given high qual-ity data on a complex process and for a business user with process
knowledge, the tool would likely be very useful. these issues are all
summarised in table 5below:
the participants also suggested a number of features that would
improve the usefulness of the tool in a business scenario. while the
toolcurrentlyworksexclusivelyonthelevelofprocesscohortsmul-
tiple participants thought it would be good to be able to identify
speciﬁc cases in an event log (e.g. outliers) and to export those cases
for further analysis using other tools. furthermore, while peoplethoughtthevisualisationenabledaquickcomparisonofcohortstheywanted additional features to quantify these differences and conﬁrm
their statistical signiﬁcance. participants also wanted to be able to
deﬁne more complex cohorts, by splitting the data using multiple logattributes at once. it was suggested that the tool should be abletoguide the user to unexpected insights in the analysis, rather than
just conﬁrm hypotheses the user has already got an intuition about.finally, some participants were interested in seeing other perspec-tives such as the resource and cost perspectives integrated into the
analysis. these suggestionsare summarised in table 6.
insummary,theparticipantslikedthewaydatawasvisualisedon
theprocessmodel.however,the3daspectwasreceivedwithmixed
perceptions. the participants felt that the 3d is both appealing and
made sense for the visualisation, but also felt that they would needtrainingoratleastmoretimetogetusedtoit.ontheotherhand,per-ceptionsofthetool’susefulnessweremorehesitant,suggestingthat
it would likely be of use once an appropriate target user group has
beenidentiﬁedandtrainedinbothprocessknowledgeandtheuseofthetool.furthermore,thelimitedavailabilityofgoodprocessmodels
and high quality process data could undermine the usefulness of the
tool. these ﬁndings therefore reﬂect the sentiments present in thequestionnaire results, but provide more in-depth insights into how
theseperceptionswere formed.
5.3. discussion
overall, our evaluation provides support for the approach we
have developed. while the user study uncovered several constraints
that currently limit the usefulness of the proposed tool in a busi-
nessenvironment,participantsbelievedthatorganisationscoulduse
it to pinpoint the inﬂuence of different contextual factors on theircomplex processes quickly and easily, once issues with availability
andqualityofdataareresolvedandindividualsreceivedappropriate
training. as the tool embodies our design principles, the evaluationofourtoolinabroadersensealsoreﬂectsontheutilityofourdesignprinciples [44]. this also shows in some comments made by partic-
ipants in the user study. people saying that the tool helped them to
quickly and easily identify differences between cohort supports ourdesign principle of presenting data in one integrated view for com-
parison (dp5). the comment that overview and drill-down features
helped to identify areas on which to focus the analysis supports ourprinciple of presenting data at different levels of abstraction (dp4).
furthermore, the suggestions that the visualisation integrates well
with the stakeholders’ mental model, could improve understandingof the process and would be useful for presenting analysis results
indicate that the contextualisation of the data worked as intended,
whichprovidessupportforourprincipleofusingorthogonaldimen-sions to contextualisetheperformance data (dp6).
a factor that limits the validity of our conclusions regarding
individualdesignprinciplesisthequestionofhowwellourprototype
table 5
themes surrounding the usefulness of the tool.
positive negative
•could be used to draw insights, if constraints addressed •availability ofgood process model and data are perceived as limiting currentanalyses
•would replaceinstinct with hard facts •users need process and domain knowledge to interpret ﬁndings
•could improve understanding of process •simpler tools exist for many use cases
•helped identify areas to focus analysis on •need to identify target audience: managers or process participants?
•good for managing complexprocesses
•useful for presentation of analysis ﬁndings106 m. wynn et al. / decision support systems 100 (2017) 93–108
table 6
additional features suggested byinterview participants.
•should beable to identify and exportcases from analysis
•should have quantitative analyses and link numbers and visualisation more strongly
•should have multidimensional splits
•could have more dimensions
•should beable to guide user to unexpected results
tool actually implements each principle, i.e. the instantiation valid-
ity of our tool [45]. as the principles abstract the design choices we
have made for our approach, we expect that the tool implements allof the principles, however, the level of abstraction still leaves much
ﬂexibilityinthedesignthatcouldinvalidatesomeoftheconclusions.
forexample,observationsthatthearcvisualisationscangetcrowdedand that colour codes might affect the perceived dominance of cer-
tain cohorts in the visualisation can either indicate a problem of our
implementation(i.e.ourchoiceofvisualglyphsanddimensions)oraproblemwithourprinciplestovisualisealldatainorthogonaldimen-
sions and in one integrated view (dp5 & dp6). overall, however, we
regardtheutilityofthetoolasanemergentpropertyofthecombinedfeaturescapturedinallthedesignprinciplesputtogether.therefore,
while we generally regard the principles as falsiﬁable, we chose not
tofocusourevaluationonindividualdesignprinciples.consequently,weseetheoverallpositiveresultsofourevaluationassupportforourapproachingeneralandprovisionalsupportforthedesignprinciples.
whileourevaluationsprovidesomesupportingevidencethatthe
proposedapproachcanbeofusetoorganisationstherearesomelim-
itations to this claim. an important limitation stems from the lack
oftrulycomparableapproachesthatalsovisuallyshowperformance
differences for process cohorts. we chose not to perform a deﬁni-tive and quantitative evaluation of our approach as this could only
have been applied to aspects, such as the visualisation component,
oftheapproach.theinternalvalidityofourevaluationregardingthedesignprinciplesisthereforelimited.insteadweoptedforincreased
ecological validity by using the approach with industry partners
and applying it to industry datasets. this improved construct valid-ity (with the exception of the link to the design principles) as wewere able to measure utility in a realistic environment. however,
we acknowledge that we only used subjective measures of this util-
ity. in addition, the organisations used in the evaluation had fairlystructured processes and were able to automatically log large parts
of their processes. consequently, both the representativeness and
generalisability (i.e. the external validity) of our ﬁndings is some-what limited as well and further research will need to establish
whether organisations with more dynamic and diﬃcult to log pro-
cesses,forexampleinhealthcare,wouldﬁndtheapproachasuseful.furthermore,summarisingstatementsintocategoriesbyparaphras-
ing carries some danger of researcher bias. we used dual-coding to
reduce this risk, but interpreting natural language is inherently sub-jective. thus, while we note these limitations may affect the level ofsupportwefoundforourprototypetool,webelievethattheylendat
least tentative support for the main contribution of our work, which
provides an approach for comparative process cohort analysis andthe design principles that provide general guidance for the design of
otherprocess cohort comparison systems.
6. conclusion
the interest in process mining is rapidly growing as is reﬂected
bythenumberofcommercialtoolsandreal-lifeapplications.current
tools provide functionality to analyse the performance and compli-
anceofoneprocess.unfortunately,thecomparisonofcohortsofcasesisseldomsupportedbycontemporarytools.wearguethatsuchcom-
parisons are vital for process analysis. one may wish to compare
different types of costumers, different outcomes, different processvariants,differentdepartments,etc.theseprocesscohortscanbecate-
gorisedbasedonanyrelevantcontextofinterest(e.g.insuranceclaimssubmitted during storm season, patients with a high injury severityscorethatarriveatthehospitalduringpeakhours).consequently,this
research proposed, implemented and evaluated a comparative pro-
cess visualisation tool to address this issue. firstly, requirements forsuchtoolsupportwereelaborated.anumberofdesignprinciplesare
then proposed to meet these requirements. a prototype implemen-
tationoftheapproachaspartoftheprocessminingframeworkpromdemonstrated the viability of building a working system based on
theproposedprinciples.ourvalidationofthetoolwithtwoindustry
datasets and practitioners shows that it can be applied to real worldevent log analysis scenarios and that business users see the tool as
potentially useful. however, factors that currently limit the useful-
ness of the tool have also been identiﬁed. future research thereforeneedstofocusonhowtoovercometheseconstraintsandincreasetheperceivedusefulnessofthetoolinorganisations.inaddition,theeval-
uationpointedtoseveralwaysthecomparativecapabilitysupported
by the tool can be extended. for instance, the tool can be extendedto include additional perspectives in the visual comparison, such as
the involvement of different resources/roles across multiple cohorts
and the potential impact that could have on the performance statis-tics.anotherinterestingextensionwouldbetoaddautomatedvisual
analytics algorithms to the tool to suggest points-of-interest for the
user to investigate.
acknowledgments
this work was supported by australian research council (arc)
discovery grants dp120101624, dp150103356 and a 2014 queens-
land accelerate partnership grant (in partnership with qld motoraccidentinsurancecommission).inadditionwewouldliketograte-
fully acknowledge the contributions to this research made by the
study participants from the nominal defendant (nd) and the royalautomobileclubofqueensland(racq),aswellastheinputfromour
colleaguesrobert andrewsand willemmertens.
references
[1]w.m.p. van der aalst, processmining: data science in action, springer. 2016.
[2]s.suriadi,m.t.wynn,c.ouyang,a.h.m.terhofstede,n.j.vandijk,understand-
ingprocessbehavioursinalargeinsurancecompanyinaustralia:acasestudy,
in: c. salinesi, m.c. norrie, o. pastor (eds.), advanced information systems
engineering,lecturenotesincomputersciencevol.7908, springer.2013, pp.
449–464.
[3]a. partington, m. wynn, s. suriadi, c. ouyang, j. karnon, process miningfor clinical processes: a comparative analysis of four australian hospitals, acm
trans.manag. inf. syst. 5 (4) (2015) 19:1–19:18.
[4]a. bolt, m. de leoni, w.m.p. van der aalst, p. gorissen, exploiting process
cubes, analytic workﬂows and process mining for business process reporting:
a case study in education, international symposium on data-driven process
discoveryand analysis, ceur-ws.org. 2015, pp. 33–47.
[5]a. pini, r. brown, m.t. wynn, process visualization techniques for multi-perspective process comparisons, in: j. bae, s. suriadi, l. wen (eds.), asia
paciﬁc business process management, lecture notes in business informationprocessing vol. 219, springer, busan, korea, 2015, pp. 183–197.
[6]w.m.p. van der aalst, a. adriansyah, b. van dongen, replaying history onprocessmodelsforconformancecheckingandperformanceanalysis,datamin.
knowl.disc. 2(2)(2012)182–192.
[7]s.j. leemans, d. fahland, w.m. van der aalst, exploring processes and devi-ations, international conference on business process management, springer
international publishing. 2014, pp. 304–316.m. wynn et al. / decision support systems 100 (2017) 93–108 107
[8]m. de leoni, m. adams, w.m.p. van der aalst, a.h.m. ter hofstede, visual
support for work assignment in process-aware information systems: frame-
work formalisation and implementation, decis. support. syst. 54 (1) (2012)
345–361.
[9]b.f. van dongen, a. adriansyah, process mining: fuzzy clustering and perfor-
mance visualization, in: s. rinderle-ma, s. sadiq, f. leymann (eds.), business
process management workshops, lecture notes in business information pro-
cessing vol. 43, springer. 2010, pp. 158–169.
[10] fluxicon, disco, 2016, https://ﬂuxicon.com/disco/ . version 1.9.3.
[11]a. bolt, m. de leoni, w.m.p. van der aalst, a visual approach to spot statistical-
ly-signiﬁcant differences in event logs based on process metrics, in: s. nurcan,
p. soffer, m. bajec, j. eder (eds.), advanced information systems engineering,lecture notes in computer science9694, springer. 2016, pp. 151–166.
[12]j. van mourik, comparing business processes using event data: a visualapproach, technische universiteit eindhoven, eindhoven, the netherlands,
2015.master’s thesis .
[13]s.kriglstein,g.wallner,s.rinderle-ma,avisualizationapproachfordifferenceanalysis of process models and instance traﬃc, in: f. daniel, j. wang, b. weber
(eds.), business process management, lecture notes in computer science vol.8094, springer. 2013, pp. 219–226.
[14]j.c.a.m. buijs, h.a. reijers, comparing business process variants using modelsand event logs, in: i. bider, k. gaaloul, j. krogstie, s. nurcan, h.a. proper, r.
schmidt,p.soffer(eds.),enterprise,business-processandinformationsystems
modeling,lecturenotesinbusinessinformationprocessingvol.175, springer.
2014, pp. 154–168.
[15]t. mamaliga, realizing a process cube allowing for the comparison of event
data, eindhoven university of technology, eindhoven, 2013.master’s thesis .
[16]t. vogelgesang, h.-j. appelrath, pmcube: a data-warehouse-based approachfor multidimensional process mining, international conference on business
process management, springer. 2015, pp. 167–178.
[17]m. gleicher, d. albers, r. walker, i. jusuﬁ, c.d. hansen, j.c. roberts, visualcomparison for information visualization, inf. vis. 10 (4) (2011) 289–309.
[18]c. healey,j. enns,attentionandvisualmemoryinvisualizationandcomputer
graphics, ieee trans. vis. comput. graph.18 (7) (2012)1170–1188.
[19] minitlabs, minit, 2016, http://www.minitlabs.com/ .v e r s i o n2 . 0 .
[20]s. malik, f. du, m. monroe, e. onukwugha, c. plaisant, b. shneiderman, cohort
comparison of event sequences with balanced integration of visual analytics
and statistics, proceedings of the 20th international conference on intelligent
user interfaces - iui ’15, acm, new york, newyork, usa, 2015, pp. 38–49.
[21]r.c. basole, m.l. braunstein, v. kumar, h. park, m. kahng, d.h.p. chau,
a. tamersoy, d.a. hirsh, n. serban, j. bost, et al. understanding variations
in pediatric asthma care processes in the emergency department using visual
analytics, j.am. med. inform. assoc. 22 (2) (2015)318–323.
[22]z. zhang, d. gotz, a. perer, iterative cohort analysis and exploration, inf. vis.14(4)(2015)289–307.
[23]k. misue, s. yazaki, panoramic view for visual analysis of large-scale activitydata,in:m.larosa,p.soffer(eds.),businessprocessmanagementworkshops,
lecturenotesinbusinessinformationprocessingvol.132, springer.2013, pp.
756–767.
[24]a.r. hevner,s.t. march,j. park,s. ram,designscienceininformationsystems
research,mis q. 28(1) (2004) 75–105.
[25]a.r.hevner,athreecycleviewofdesignscienceresearch,scand.j.inf.syst.19( 2)( 20 0 7)4.
[26]t.munzner,anestedmodelforvisualizationdesignandvalidation,ieeetrans.vis. comput. graph.15 (6) (2009) 921–928.
[27]s. gregor, a.r. hevner, positioning and presenting design science research for
maximum impact, mis q. 37(2) (2013) 337–355.
[28]a. adriansyah, performance analysis of business processes from event logsandgivenprocessmodels, eindhovenuniversityoftechnology.2009.doctoral
thesis.
[29]b.shneiderman,theeyeshaveit:ataskbydatatypetaxonomyforinformationvisualizations,ieeesymposiumonvisuallanguages, ieee.1996, pp.336–343.
[30]d. sacha, a. stoffel, f. stoffel, b.c. kwon, g. ellis, d.a. keim, knowledge
generation model for visual analytics, ieee trans. vis. comput. graph. 20 (12)
(2014)1604–1613.
[31]z. liu, j. heer, the effects of interactive latencyon exploratoryvisual analysis,ieee trans. vis. comput. graph. 20(12) (2014) 2122–2131.
[32]w.m.p.vanderaalst,theapplicationofpetrinetstoworkﬂowmanagement,j.circuits syst. comput. 8(01) (1998)21–66.
[33] prom framework, 2016, http://www.promtools.org . version 6.6.
[34]j.
bertin, semiology of graphics: diagrams, networks, maps, university of
wisconsin press, madison, wisconsin, usa, 1983.
[35]d.l. moody, the “physics” of notations: toward a scientiﬁc basis for construct-ing visual notations in software engineering, ieee trans. softw. eng. 35 (6)
(2009) 756–779.
[36]w. javed, n. elmqvist, exploring the design space of composite visualization,ieee paciﬁc visualization symposium (paciﬁcvis), ieee. 2012, pp. 1–8.
[37]w.p.abbett,themagneticconnectionbetweentheconvectionzoneandcorona
in the quiet sun, astrophys. j.665(2) (2007) 1469–1488.
[38]m. wattenberg, arc diagrams: visualizing structure in strings, proceedings oftheieeesymposiumoninformationvisualization, ieee,losalamitos,ca,usa,
2002, pp. 110–116.
[39]r. baskerville,j. pries-heje,explanatorydesigntheory,bus.inf.syst.eng.2(5)(2010) 271–282.
[40] (dhbw) karlsruhe, woped, 2014, http://woped.dhbw-karlsruhe.de/woped/.
version 3.2.0.[41]s. chaudhuri, u. dayal, an overview of data warehousing and olap technol-
ogy, acm sigmod rec. 26(1) (1997)65–74.
[42]f.d. davis, perceived usefulness, perceived ease of use, and user acceptance ofinformation technology, mis q. (1989) 319–340.
[43]l.a. palinkas, s.m. horwitz, c.a. green, j.p. wisdom, n. duan, k. hoag-
wood,purposefulsamplingforqualitativedatacollectionandanalysisinmixed
methodimplementationresearch,adm.policyment.healthment.healthserv.
res. 42(5) (2015) 533–544.
[44]j. venable, j. pries-heje, r. baskerville, a comprehensive framework for evalu-ation in design science research, international conference on design science
researchininformationsystems,springerberlinheidelberg.2012,pp.423–438.
[45]r. lukyanenko, j. evermann, j. parsons, guidelines for establishing instantia-tionvalidityinitartifacts:asurveyofisresearch,international conferenceon
designscienceresearchininformationsystems, springer.2015, pp.430–438.
dr. moe t. wynn is a senior lecturer in the ﬁeld of busi-
ness process management (bpm) within the school of
informationsystemsatqueenslanduniversityoftechnol-ogy. her research interests include process automation,process mining, comparative process analytics and cost-
aware business process management. she has published
over 60 refereed research papers. her work appeared inwell-known journals in the ﬁeld including informationsystems,informationsciences,dataandknowledgeengi-neering, information and software technology, formalaspects of computing, journal of computer and systemsciences,andtransactionsonpetrinetsandothermodelsof concurrency.
dr. erik poppe is a research fellow with the business
process management discipline of the school of infor-mation systems at the queensland university of tech-nology in brisbane, australia. with a background in thegames industry and an interest in information systems,his research looks at improving technological supportfor human work practice through the application ofgame technologies and novel user interfaces. his cur-rentresearchfocusesontheuseofadvancedvisualisation
techniques and visual analytics for comparative process
analysis.
dr. jingxin xu received his bachelor’s degree in telecom-
munications engineering from xidian university, xi’an,china, in 2008, master’s degree in information technol-ogy from the queensland university of technology (qut),brisbane,qld,australia,in2010,andphddegreeinsignalprocessing from qut, in 2014. he is currently a post-doctoral research fellow with qut, investigating processmining techniques for business process management.
prof. arthur ter hofstede is a professor in the school
of information systems in the science and engineeringfaculty, queensland university of technology, brisbane,australia.heisalsoaprofessorintheinformationsystemsgroup of the department of industrial engineering of thetechnische universiteit eindhoven (tu/e). his researchinterests are in the areas of business process automationand processmining.108 m. wynn et al. / decision support systems 100 (2017) 93–108
dr. ross brown is a senior lecturer with the science and
engineeringfacultyatthequeenslanduniversityoftech-
nologyinbrisbane,australia,whereheisamemberofthechi discipline, in the school of electrical engineering andcomputerscience.rossgraduatedwithaphdfromqutin2003.heteachescomputergraphicsandﬁnalyearprojectunits in the bachelor of games and interactive entertain-ment. his main research interests are in the applicationof 3d games technology to other research domains. inparticular, his latest research involves the development
of virtual world technology for the representation of bpm
information. a number of projects are currently under-way, including: the embedding of executable workﬂowsin virtual environments, collaborative 3d process mod-elling, 3d spatial visualisation of process model data and
virtual world-based process elicitation. more information on his work can be foundat:http://www.bpmve.org .
dr. azzurra pini isaresearchfellowwiththedensityde-
sign research lab( www.densitydesign.org)a tp o l i t e c n i c o
di milano, italy. azzurra is a communication designerand her phd research has been focusing on the role of
visualization for the design of visual interfaces for explor-
ing, analysing and designing organisational processes toassist researchers, analysts, and managers in their inquiryactivity.hercurrentresearchinterestspertaintoallﬁeldsof application of communication and information design,including interdisciplinary research on complex phenom-ena and decision-support bymeans of visualization.
prof.dr.ir. wil van der aalst is a full professor of infor-
mation systems at the technische universiteit eindhoven(tu/e), the netherlands. he is also the academic super-visor of the international laboratory of process-awareinformation systems of the national research university,higher school of economics in moscow. moreover, since2003 he has a part-time appointment at queensland uni-
versity of technology (qut). at tu/e he is the scientiﬁc
director of the data science centre eindhoven (dsc/e).wil van der aalst has published more than 175 jour-nal papers, 17 books (as author or editor), 400 refereedconference/workshop publications, and 60 book chapters.many of his papers are highly cited (he is one of the mostcitedcomputerscientistsintheworldandhasanh-indexof 126 according to google scholar) and his ideas have
inﬂuenced researchers, software developers, and standardization committees work-
ing on process support. in 2012, he received the degree of doctor honoris causa from
hasselt university. in 2013, he was appointed as distinguished university professorof tu/e and was awarded an honorary guest professorship at tsinghua university. heis also a member of the royal holland society of sciences and humanities (konin-klijke hollandsche maatschappij der wetenschappen) and the academy of europe(academia europaea).