towards a natural language conversational
interface for process mining
luciana barbieri1, edmundo roberto mauro madeira1, kleber stroeh2, and
wil m. p. van der aalst3;4
1institute of computing, university of campinas (unicamp), brazil
fluciana.barbieri,edmundo g@ic.unicamp.br
2everow process mining, brazil
kleber.stroeh@everflow.ai
3fraunhofer institute for applied information technology fit, germany
4rwth aachen university, germany
wvdaalst@pads.rwth-aachen.de
abstract. despite all the recent advances in process mining, making it
accessible to non-technical users remains a challenge. in order to democ-
ratize this technology and make process mining ubiquitous, we propose
a conversational interface that allows non-technical professionals to re-
trieve relevant information about their processes and operations by sim-
ply asking questions in their own language. in this work, we propose a ref-
erence architecture to support a conversational, process mining oriented
interface to existing process mining tools. we combine classic natural
language processing techniques (such as entity recognition and seman-
tic parsing) with an abstract logical representation for process mining
queries. we also provide a compilation of real natural language ques-
tions (aiming to form a dataset of that sort) and an implementation of
the architecture that interfaces to an existing commercial tool: everow.
last but not least, we analyze the performance of this implementation
and point out directions for future work.
keywords: process mining Â·process querying Â·natural language in-
terface.
1 introduction
process mining (pm) aims to discover, monitor and enhance processes using
information extracted from event logs [2]. there exist mature academic and
commercial process mining techniques and tools that provide analyses over event
log data. the use of these tools, however, requires knowledge of the technology
itself and is mostly done by technical teams (process analysts, data scientists
and alike).
to make process mining more ubiquitous, i.e., accessible on a daily basis
by non-technical teams, we propose a natural language conversational interface.
business level and operations teams, for example, can take great benet from2 l. barbieri et al.
the insights produced by process mining tools when accessed through such an
intuitive conversational interface.
in spite of recent advances in natural language processing (nlp), under-
standing the semantics of a natural language question and translating it to a
correct corresponding logical query is still a challenging task. problems such as
ambiguity (same natural language expression having multiple interpretations)
and variability (many dierent expressions having the same meaning) are yet
dicult to handle. context awareness brings yet another level of complexity to
the task, as the meaning of a natural language question may depend on previous
questions and responses.
the main objective of this ongoing research is to propose, implement and
evaluate an architecture for a process mining natural language conversational
interface that takes questions in natural language and translates them to logical
queries that can be run against existing process mining tools. the contributions
presented in this paper are:
{introduce a reference architecture for a process mining natural language
conversational interface
{propose an abstract logical representation for process mining queries that
is, on the one hand, independent of the underlying concrete process mining
tool and, on the other, mappable to its api calls
{an initial collection and categorization of natural language process mining
questions aiming to create a public dataset
{a proof of concept of the proposed architecture, including integration to a
commercial tool (everow process mining5) through its (restful) api
the remainder of this paper is organized as follows. section 2 reviews re-
lated work. section 3 introduces the proposed architecture. section 4 describes
the pm question dataset under construction. section 5 presents the conducted
proof of concept. section 6 concludes this paper and points out future work and
directions.
2 related work
natural language interfaces to databases from the many existing nlp applica-
tions, the ones that are mostly related to this research are the so called natural
language interfaces to databases (nlidb). the main objective of nlidb is to
enable users who are not familiar with complex query languages such as sql
to easily formulate queries over information stored in databases using natural
language.
even though nlidb is not a new research topic, recent advances in natural
language processing have raised its importance and popularity during the last
decade [3]. current methods dier in the use of natural language itself (from
queries restrictedly written according to specic grammatical constraints to full
5https://everow.ai/towards a natural language conversational interface for process mining 3
natural language sentences), as well as in the technical approaches used to parse
and convert them to a machine-readable format such as sql or sparql. most
common parsing techniques are based on rule matching or machine learning. in
either case, the types of queries that can be handled by the system are limited
either by the set of rules, in the rst case, or by the training data in the second.
while most of the existing nlidb methods are designed to handle queries
over any domain (metadata and/or domain ontologies are usually taken as input
to map domain terminology to database entities), using specic process mining
domain knowledge yields context to the design of a potentially more robust
natural language interface.
natural language processing applications in business process management and
process mining one of the most important applications of nlp techniques to the
business process management (bpm) domain is the extraction of process mod-
els from natural language text [4]. other existing applications of nlp to bpm
include the automatic generation of textual descriptions from process models [6]
and the comparison of process models to textual descriptions [9]. in [1], the au-
thors discuss future challenges for nlp applications in the bpm eld, including
the use of conversational systems to support the execution of business processes.
most related to our research is the work presented in [5], where the authors
propose a method to answer natural language queries over process automation
event logs. the method extends the athena nlidb system [8] to translate
natural language queries to queries over process execution data (event logs)
stored in elasticsearch.
existing process mining techniques and tools can provide automatic analysis
over event log data, which can be used to answer high-level user questions. to
the best of our knowledge, this is the rst research work aiming to automatically
understand and answer natural language questions over process mining data and
analyses.
3 proposed method
our proposed method can be best described by the architecture depicted in
figure 1. in broad terms, it can be viewed as a pipeline moving from top to bot-
tom. the input is a question in regular natural language (in our case, english).
questions can be provided as text or speech - planned future work includes
an automatic speech recognition module, which will provide \speech-to-text"
functionality.
to close the pipeline, we envision response generation and text to speech
modules to provide a conversational response to the user. in the scope of this
work, this response was simplied and corresponds to a piece of information
directly derived from the call to the pm tool's api. the following sections
detail the modules responsible for understanding the input natural language
question and mapping it to an api call.4 l. barbieri et al.
fig. 1. process mining natural language querying interface architecture overview
3.1 pre-processing and tagging
the input text passes initially through a pre-processing and tagging step, where
the following processing occurs:
{tokenization, which is the splitting of text into tokens. separation is based
on whitespaces, punctuation marks and apostrophes, among others.
{part-of-speech (pos) tagging, which performs morphological analysis over
the text, marking tokens with tags such as pron (pronoun), adj (adjec-
tive) and verb.
{dependency parsing, which provides semi-syntactic analysis and marks to-
kens with grammatical structure information and dependency relations be-
tween them.
{lemmatization, which nds the base (non-inected) form of words.
{entity recognition, which identies and tags real-world entities in the text,
as detailed below.
entity recognition identies general entities from pre-dened categories, such
as names of people and organizations, geographic locations, time and quantities,
among others. in addition to that, a natural language interface for process mining
must be able to recognize the process mining entities present in sentences. terms
such as event, case, activity, resource and variant (along with its synonyms) must
be recognized and tagged appropriately. the resulting tags are a crucial input
for the next task in the processing pipeline (semantic parsing). figure 2 depicts
the process mining data model that underlies the recognition of such terms.
although this model is based in [2], one should notice that, for the purpose of
this work, the term \event" refers to both event and activity instance.towards a natural language conversational interface for process mining 5
fig. 2. process mining data model underlying entity recognition
besides dealing with general process mining terms, the system must be able
to recognize domain-specic terms. this includes the names of non-standard at-
tributes present in the event log along with possible categorical values, among
others. to be able to recognize such terms, this module uses event log metadata
(names, types and possible values) of these attributes. as the proposed natural
language interface does not deal directly with the event log, the pm tool inter-
face mapping layer takes the responsibility of interfacing with the pm tool to
gather these metadata. figure 3 shows examples of questions tagged with recog-
nized entities. notice that \hailey lee" and \chicago" are categorical attribute
values gathered from event log metadata and used to tag these terms during
entity recognition.
fig. 3. entity recognition examples
3.2 semantic parsing
semantic parsing aims to understand the meaning of a natural language sentence
and map it to a logical (machine-readable) representation. the most common
methods used for semantic parsing are rule-based and neural approaches. while
rule-based methods are usually more appropriate to build domain specic sys-
tems targeted to understand a nite set of sentences, neural systems are more
suitable to handle complex scenarios at the cost of requiring large training cor-
pora. logical representations usually take the form of lambda calculus, query
languages such as sql and sparql or executable programs, among others.
rule matching as, to the best of our knowledge, there is no process mining
question dataset that could be annotated and used to train traditional machine6 l. barbieri et al.
learning or neural models, we have initially adopted a rule matching approach
for semantic parsing. besides requiring no training data, the method has the
advantage of achieving high accuracy in answering predictable questions.
in our proof of concept, we used the spacy open-source natural language
processing library6. its rule matcher component allows the denition of rules
that match sequences of tokens. rules are based on tags lled in the previous
steps in the pipeline (part-of-speech tags, dependency parsing results, entity
recognition labels), together with actual words or expressions (in our case, words
or expressions used to express the sort of process mining relationship/analysis
being queried). figure 4 illustrates the matching of the question \what activities
have been assigned to hailey lee?" to a rule pattern.
fig. 4. rule matching example
in this case, the matched pattern leads the system to the conclusion that
the user wants the list of activity instances associated to a particular resource
(hailey lee).
logical representation after the semantics of a question is understood (i.e.
after it matches a rule), it must be converted to a corresponding logical (pm
tool independent) representation. the question decomposition meaning repre-
sentation (qdmr) proposed in [11] and inspired by sql has been used for this
purpose with some extensions.
in qdmr questions are represented by a sequence of steps where each step
corresponds to an operator. each operator (except for select ) is applied to the
results of a previous step in the sequence. additional parameters may be given to
logical operators depending on the entities (concepts, attributes, aggregations,
etc.) recognized in the natural language question. table 1 presents the most
6https://spacy.io/towards a natural language conversational interface for process mining 7
relevant qdmr operators used in this research work to compose the logical
representation of pm queries. for the complete set, please refer to [11].
table 1. some qdmr operators used for pm question logical representation
operator description example logical form
select return all instances of the
given concept.show me all cases. select case
filter return the referenced
instances for which the
given condition holds.show me all cases from
chicago.select case
filter city chicago #1
project return the given at-
tribute/relation for the
referenced instances.how long does each pro-
cess instance take to exe-
cute?select case
project duration #1
aggregate apply the given aggrega-
tion to the referenced val-
ues.what is the average case
duration?select case
project duration #1
aggregate average #2
group apply the given aggrega-
tion to each subset of val-
ues corresponding to each
keywhat is the average cost
of each activity?select event
project cost #1
project activity #1
group average #2 #3
superlative return the referenced
instances for which the
given value is the high-
est/lowest.what was the slowest
case?select case
project duration #1
superlative max #1 #2
notice that hash tags are used to refer to the results of a previous logical
operation in the sequence, which may be a set of event or case instances or their
attribute values. for example, in the following sequence, #1refers to the results
ofselect case , which are all case instances and #2refers to the values of the
duration attribute for #1.
select case
project duration #1
aggregate average #2
the original set of qdmr operators was extended by this work to allow
querying the behavioral aspects of process execution. inspired by and initially
based on the set of predicates dened by the process query language (pql) [7],
the predicate operator was introduced to logically represent questions over
behavioral relations between executed activities. supported predicates can be
applied over cases or traces and are presented in table 2.
rule to logical representation mapping as one of the architectural goals
of the proposed method is to allow integration to any process mining tool, it
makes as few assumptions as possible on how the integrated process mining
tool models the event log data. as a result, a minimal process mining data
model based in the xes standard event log format [10] drives the mapping of
matched rules to logical representation. some of the entities tagged and handled
as concepts during entity recognition and rule matching (activity, resource, trace)
are, at this point, mapped to attributes of event and case, which are the only8 l. barbieri et al.
table 2. predicates used for pm question logical representation
predicate parameters description
occurs activity return the referenced cases or traces that execute
the given activity.
cooccur activity1, activity2 return the referenced cases or traces that execute
both activity1 and activity2 or none.
conict activity1, activity2 return the referenced cases or traces that execute
either activity1, activity2 or none.
causal activity1, activity2 return the referenced cases or traces where any
occurrence of activity1 precedes any occurrence
of activity2.
concurrent activity1, activity2 return the referenced cases or traces where some
occurrence of activity1 occurs at the same time
as some occurrence of activity2.
activity-count - return the number of activities executed by each
referenced case or trace, including repetitions.
distinct-activity-count - return the number of distinct activities executed
by each referenced case or trace.
occurence-count activity return the number of times the given activity is
executed for each referenced case or trace.
selectable concepts (assuming that processes are queried one at a time). non-
standard attributes contained in the event log are mapped based on the metadata
obtained from the pm tool.
once a rule res, a corresponding logical representation must be put together.
this depends not only on what rule has been matched, but also on the entities
(concepts, attributes, etc.) recognized in the sentence. as an example, figure 5
depicts the possible logical representations to be created when the \aggregate
attribute query" rule is matched.
fig. 5. logical forms for attribute query rules
the matched rule indexes the rst column in the table, while the entities
tagged in the sentence index the next four (concept, attribute, lter and ag-
gregation). the last column corresponds to the logical representation that will
be used to drive the calls to the pm tool api detailed in the following sub-
section. asterisks indicate optional entities and the corresponding logical op-towards a natural language conversational interface for process mining 9
erations that are added to the sequence when they are present. the complete
set of correspondences between rules and logical representations is available at
https://ic.unicamp.br/~luciana.barbieri/ruletological.pdf .
3.3 pm tool interface mapping
the nal step in the question processing pipeline is to map the logical represen-
tation of the query into a real api call provided by a process mining tool.
in this work, we integrated the architecture into everow's restful api.
this api presents endpoints that mimic process mining main concepts and nat-
urally maps into the pm data model used to create logical representations.
using everow's \cases" and \events" endpoints, altogether with their as-
sociated parameters (such as \lter" and \aggregate"), it is straightforward to
map the logical representation into actual api calls. figure 6 illustrates the
end-to-end mapping of a natural language question to a nal api call.
fig. 6. end to end mapping of question to api call
the integration of a new pm tool currently requires a dierent instantiation
of the pm tool interface mapping component. planned future work includes the
denition of a standard api to replace this component and allow pm tools to
easily integrate our natural language conversational interface.
4 sample questions
an initial set of natural language questions was collected from graduate students
with beginner to intermediate level of expertise in process mining, resulting in
250 general (not specic to any existing event log) questions originally written10 l. barbieri et al.
in portuguese. free translation was performed by 3 volunteers resulting in 794
questions in english (multiple translations were done by the volunteers for some
of the questions).
questions were then categorized into 4 groups: event log data questions (ques-
tions over case/event instances, attributes and counts), process model questions
(model structure, behavior and quality), process mining analysis questions (con-
formance checking, bottleneck analysis, transitions, root cause analysis, social
network, etc.) and advanced analysis questions (prediction, prescription and sim-
ulation). table 3 summarizes these categories.
variability in both language and contents of questions can be improved in
the future by collecting them directly in english and eliminating the translation
step. nonetheless, as no public dataset of pm questions is currently available, the
samples collected so far played an important role in setting the ground for this
research and being the initial input for building the rules used for semantic pars-
ing. the complete set of 794 questions, with their corresponding classications,
is available at https://ic.unicamp.br/~luciana.barbieri/pmquestions.csv .
table 3. question categories
category # samples example
event log data 327 which activity has the highest mean resolution time?
process model 107 what are the possible start and end activities in my log?
analysis 240 what are the most frequent non-conformances in my process?
advanced analysis 120 what is the predicted completion time for case x?
5 proof of concept
in order to verify the applicability of the proposed method, we implemented a
subset of the architecture (blue colored components) presented in figure 1. for
this proof of concept, we used the spacy open-source natural language processing
library, targeting questions from the \event log data" category of the original
collected set. the library's rule matcher component was used and fed with
34 semantic rules covering event log attribute querying, instance querying and
counting, aggregations and superlatives (\most", \least"), among others.
in order to test the implementation, the set of questions from the \event log
data" category was further rened by removing compound questions (questions
containing multiple embedded subquestions) and time-bound questions (ques-
tions containing time-related lters as in \what is the average duration of cases
completed in the rst quarter of 2020?"), as these constructions were not covered
by the implemented set of semantic rules. this led to a testing dataset of 203
questions.
this testing set was executed against a work force management based event
log that was uploaded into the everow process mining tool. however, any
process mining event log could be used, as the collected questions are not context-
specic (not bounded to any particular event log).towards a natural language conversational interface for process mining 11
from the 203 testing questions, 163 (80.3%) were correctly answered, 22
(10.8%) were not responded because the system was not able to match any
semantic rule, and 18 (8.9%) were incorrectly answered, because they red
the wrong semantic rule or because they were falsely tagged during the pre-
processing and tagging phase.
examples of successfully answered questions are \what is the most common
ow of activities?", \which activity has the highest mean resolution time?"
and \what are the 10% slower cases?" unmatched questions include \what
resources execute what activities?" and \which resources are the most agile in
task execution?". likewise, examples of questions that red the wrong semantic
rule are \what resources take the longest to execute activity a?" and \what
are the resources assigned to the fastest cases?". actually, all these failed tests
illustrate the shortcomings of a rule-based approach, where the nal result is
sensitively connected to the rules in use. this means that they could be xed by
a more crafted, possibly longer, rule set, which is hard to achieve and dicult
to maintain.
on the other hand, properly answered questions such as \what is the average
execution time of the process in chicago?" illustrate the ability of the system to
use terms that are specic to the event log. in this example, \chicago" is a value
under the attribute \city" in the event log, and could be used in the question
due to the capacity to handle metadata coming from the process mining tool.
this question was, of course, not present in the original testing dataset.
overall, in spite of the limited size and variation of the testing questions and
rules, the 80.3% accuracy seems promising as a rst result. as expected, a rule-
based approach has limitations in treating questions that stray too much away
from the structures implemented in the rules. in general, this method presents
high precision, but low generalization.
6 conclusions and future work
implementing the proposed reference architecture and testing it against the
aforementioned sample question dataset has led to some interesting conclusions.
rule-based semantic parsing was an appropriate choice for bootstrapping a nat-
ural language interface for pm as no training data set of any kind or size is
currently available to train any supervised or semi-supervised machine learning
technique.
furthermore, as the pm general ontology is small (few entities and relations),
it was possible to answer questions for a selected, pre-dened, set with high
accuracy using a relatively small number of rules. however, this approach does
come with limitations. rule-based semantic parsing does not generalize well,
with new rules being required for most new/unpredicted questions.
in order to overcome this generalization limitation and to evolve the study
towards a fully functional architecture, we envision the following future work:
{use machine learning for semantic parsing by using the developed rule match-
ing parser to create an annotated training dataset.12 l. barbieri et al.
{increase our experiment by working with questions in other categories (pro-
cess model, analysis, advanced analysis).
{extend the response mechanism to include natural language response gen-
eration, making responses more natural and user-friendly.
{extend the training dataset and make it public. this implies collecting addi-
tional questions, if possible, directly in english and associated with a selected
event log, so that questions can be more context-based and closer to what
real business users would ask in a specic domain.
acknowledgements we would like to thank coordena c~ ao de aperfei coamento de
pessoal de n vel superior { brasil (capes) { finance code 001, for providing
the nancial support for this work. likewise, we would like to thank professors
sarajane marques peres and marcelo fantinato for helping us collect questions
from their students for our dataset.
references
1. van der aa, h., carmona vargas, j., leopold, h., mendling, j., padr o, l.: chal-
lenges and opportunities of applying natural language processing in business pro-
cess management. in: international conference on computational linguistics. pp.
2791{2801. association for computational linguistics (2018)
2. van der aalst, w.m.p.: process mining: data science in action. springer (2016)
3. aolter, k., stockinger, k., bernstein, a.: a comparative survey of recent natural
language interfaces for databases. the vldb journal 28(5), 793{819 (2019)
4. friedrich, f., mendling, j., puhlmann, f.: process model generation from natu-
ral language text. in: advanced information systems engineering. pp. 482{496.
springer berlin heidelberg (2011)
5. han, x., hu, l., sen, j., dang, y., gao, b., isahagian, v., lei, c., efthymiou,
v.,ozcan, f., quamar, a., huang, z., muthusamy, v.: bootstrapping natural
language querying on process automation data. in: 2020 ieee international con-
ference on services computing (scc). pp. 170{177 (2020)
6. leopold, h., mendling, j., polyvyanyy, a.: generating natural language texts from
business process models. in: advanced information systems engineering. pp. 64{
79. springer berlin heidelberg (2012)
7. polyvyanyy, a., ter hofstede, a.h., la rosa, m., ouyang, c., pika, a.: pro-
cess query language: design, implementation, and evaluation. arxiv preprint
arxiv:1909.09543 (2019)
8. saha, d., floratou, a., sankaranarayanan, k., minhas, u.f., mittal, a.r., ozcan,
f.: athena: an ontology-driven system for natural language querying over relational
data stores. proceedings of the vldb endowment 9(12), 1209{1220 (2016)
9. s anchez-ferreres, j., carmona, j., padr o, l.: aligning textual and graphical de-
scriptions of processes through ilp techniques. in: advanced information systems
engineering. pp. 413{427. springer international publishing (2017)
10. verbeek, h.m.w., buijs, j.c.a.m., van dongen, b.f., van der aalst, w.m.p.:
xes, xesame, and prom 6. in: information systems evolution. vol. 72, pp. 60{75.
springer berlin heidelberg (2010)
11. wolfson, t., geva, m., gupta, a., gardner, m., goldberg, y., deutch, d., be-
rant, j.: break it down: a question understanding benchmark. transactions of the
association for computational linguistics 8, 183{198 (2020)