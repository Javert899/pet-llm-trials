improving business process models using
observed behavior
j.c.a.m. buijs1;2, m. la rosa2;3, h.a. reijers1, b.f. van dongen1, and
w.m.p. van der aalst1
1eindhoven university of technology, the netherlands
fj.c.a.m.buijs,h.a.reijers,b.f.v.dongen,w.m.p.v.d.aalst g@tue.nl
2queensland university of technology, australia
m.larosa@qut.edu.au
3nicta queensland research lab, australia
abstract. process-aware information systems (paiss) can be cong-
ured using a reference process model, which is typically obtained via
expert interviews. over time, however, contextual factors and system
requirements may cause the operational process to start deviating from
this reference model. while a reference model should ideally be updated
to remain aligned with such changes, this is a costly and often neglected
activity. we present a new process mining technique that automatically
improves the reference model on the basis of the observed behavior as
recorded in the event logs of a pais. we discuss how to balance the
four basic quality dimensions for process mining (tness, precision, sim-
plicity and generalization) and a new dimension, namely the structural
similarity between the reference model and the discovered model. we
demonstrate the applicability of this technique using a real-life scenario
from a dutch municipality.
1 introduction
within the area of process mining several algorithms are available to automat-
ically discover process models. by only considering an organization's records of
its operational processes, models can be derived that accurately describe the op-
erational business processes. organizations often use a reference process model,
obtained via expert interviews, to initially congure a process. during execution
however the operational process typically starts deviating from this reference
model, for example, due to new regulations that have not been incorporated
into the reference model yet, or simply because the reference model is not accu-
rate enough.
process mining techniques can identify where reality deviates from the orig-
inal reference model and especially how the latter can be adapted to better t
reality. not updating the reference model to reect new or changed behavior
has several disadvantages. first of all, such a practice will overtime drastically
diminish the reference model's value in providing a factual, recognizable viewon how work is accomplished within an organization. second, a misaligned ref-
erence model cannot be used to provide operational support in the form of, e.g.,
predictions or recommendations during the execution of a business process.
a straightforward approach to x the misalignment between a reference
model and reality is to simply discover a new process model from scratch, using
automated process discovery techniques from process mining [1]. the resulting
model may reect reality better but may also be very dierent from the initial ref-
erence model. business analysts, process owners and other process stakeholders,
may heavily rely on the initial reference model to understand how a particular
process functions. confronting them with an entirely new model may make it
dicult for them to recognize its original, familiar ingredients and understand
the changes in the actual situation. as a result, a freshly discovered process
model may actually be useless in practice.
in this paper, we propose to use process mining to discover a process model
that accurately describes an existing process yet is very similar to the initial
reference process model. to explain our approach, it is useful to reect on the
four basic quality dimensions of the process model with respect to the observed
behavior [1,2] (cf. figure 1a). the replay tness dimension quanties the extent
to which the discovered model can accurately replay the cases recorded in the
log. the precision dimension measures whether the discovered model prohibits
behavior which is not seen in the event log. the generalization dimension assesses
the extent to which the resulting model will be able to reproduce possible future,
yet unseen, behavior of the process. the complexity of the discovery process
model is captured by the simplicity dimension, which operationalizes occam's
razor.
following up on the idea to use process mining for aligning reference process
models to observed behaviors, we propose to add a fth quality dimension to this
spectrum: similarity to a given process model. by incorporating this dimension,
we can present a discovered model that maximizes the four dimensions while
remaining aligned, as far as possible, with the intuitions and familiar notions
modeled in a reference model.
‚Äúable to replay event log‚Äù ‚Äúoccam‚Äôs razor‚Äù
‚Äúnot overfitting the log‚Äù ‚Äúnot underfitting the log‚Äù
(a) dierent quality dimensions for pro-
cess model discovery [1]
(b) incorporating similarity
fig. 1: adding similarity as a process model quality dimension.
2figure 1b illustrates the eects of introducing this additional dimension. by
setting a similarity boundary , the search for a model that balances the initial
four quality dimensions is restrained. in this way, a new version of the reference
model can be found that is similar to the initial reference model yet is improved
with respect to its t with actual behavior. clearly, if the similarity boundary is
being relaxed suciently (i.e. the discovered model is allowed to deviate strongly
from the reference model), it is possible to discover the optimal process model.
such an optimal model, as explained, may not be desirable to use for process
analysts and end users as a reference point, since they may nd it dicult to
recognize the original process set-up within it.
the remainder of the paper is structured as follows. in section 2 we present
related work in the area of process model improvement and process model repair.
in section 3 we present our approach using a genetic algorithm to balance the
dierent quality dimensions while in section 4 we show how to incorporate the
similarity dimension in our approach. in section 5 we show the results of applying
our technique to a small example. in section 6 the technique is applied to a real
life case. finally, section 7 concludes the paper.
2 related work
automatically improving or correcting process models using dierent sources of
information is an active research area. li et. al. [15] discuss how a reference
process model can be discovered from a collection of process model variants. in
their heuristic approach they consider the structural distance of the discovered
reference model to the original reference model as well as the structural distance
to the process variants. by balancing these two forces they make certain changes
to the original reference model to make it more similar to the collection of process
model variants. compared to our approach, here the starting point is a collection
of process variants, rather than a log.
an approach aimed to automatically correct errors in an unsound process
model (a process model aected by behavioral anomalies) is presented by gam-
bini et. al. [11]. their approach considers three dimensions: the structural dis-
tance, behavioral distance and `badness' of a solution w.r.t. the unsound process
model, whereby `badness' indicates the ability of a solution to produce traces
that lead to unsound behavior. the approach uses simulated annealing to simul-
taneously minimize all three dimensions. the edits applied to the process model
are aimed to correct the model rather than to balance the ve dierent forces.
detecting deviations of a process model from the observed behavior has been
researched, among others, by adriansyah et. al. [2,4]. given a process model and
an event log, deviations are expressed in the form of skipped activities (activities
that should be performed according to the model, but do not occur in the log)
and inserted activities (activities that are not supposed to happen according to
the model, but that occur in the log). a cost is attributed to these operations
based on the particular activity being skipped/inserted. based on this informa-
tion an alignment can be computed between the process model and the log,
3which indicates how well the process model can describe the recorded behavior.
while this approach provides an eective measure for the replay tness quality
dimension of figure 1a, the approach per se does not suggest any corrections to
rectify the process model's behavior.
the work of fahland et. al. [10] provides a rst attempt at repairing pro-
cess models based on observed behavior. in their notion, a process model needs
repair if the observed behavior cannot be replayed by the process model. this
is detected using the alignment between the process model and the observed
behavior of [2, 4]. the detected deviations are then repaired by extending the
process model with sub-processes nested in a loop block. these xes are applied
repeatedly until a process model is obtained that can perfectly replay the ob-
served behavior. this approach extends the original process model's behavior
by adding new fragments that enable the model to replay the observed behavior
(no existing fragments are removed). the main disadvantage of this approach is
that only one aspect of deviation, namely that of not being able to replay the
observed behavior, is considered. moreover, since repairs add transitions to the
model, by denition, the model can only become more complex and less precise.
it is unclear how to balance all ve quality dimensions by extending the work
in [10].
3 our mining technique
in this section we briey introduce our exible evolutionary algorithm rst pre-
sented in [6]. this algorithm can seamlessly balance four process model quality
dimensions during process discovery.
3.1 process trees
our approach internally uses a tree structure to represent process models. be-
cause of this, we only consider sound process models. this drastically reduces
the search space thus improving the performance of the algorithm. moreover, we
can apply standard tree change operations on the process trees to evolve them
further, such as adding, removing and updating nodes.
figure 2 shows the possible operators of a process tree and their translation
to a petri net. a process tree contains operator nodes and leaf nodes. an operator
node species the relation between its children. possible operators are sequence
(!), parallel execution ( ^), exclusive choice ( ), non-exclusive choice ( _) and
loop execution ( 	). the order of the children matters for the sequence and loop
operators. the order of the children of a sequence operator species the order
in which the children are executed (from left to right). for a loop, the left child
is the `do' part of the loop. after the execution of this part the right child,
the `redo' part, might be executed. after this execution the `do' part is again
enabled. the loop in figure 2 for instance is able to produce the traces hai,
ha;b;ai,ha;b;a;b;aiand so on. existing process models can be translated
to the process tree notation, possibly by duplicating activities.
43.2 quality dimensions
to measure the quality of a process tree, we consider one metric for each of the
four quality dimensions, as we proposed in [6]. we base these metrics on existing
work in each of the four areas [2, 4] and we adapt them for process trees, as
discussed below. for the formalization of these metrics on process trees we refer
to [6].
replay tness quanties the extent to which the model can reproduce the
traces recorded in the log. we use an alignment-based tness computation
dened in [4] to compute the tness of a process tree. basically, this tech-
nique aligns as many events as possible from the trace with activities in an
execution of the model (this results in a so-called alignment ). if necessary,
events are skipped, or activities are inserted without a corresponding event
present in the log. penalties are given for skipping and inserting activities.
the total costs for the penalties are then normalized, using information on
the maximum possible costs for this event log and process model combina-
tion, to obtain a value between 1 (perfect) and 0 (bad).
precision compares the state space of the tree execution while replaying the
log. our metric is inspired by [5] and counts so-called escaping edges, i.e.
decisions that are possible in the model, but never made in the log. if there
are no escaping edges, the precision is perfect. we obtain the part of the
state space used from information provided by the replay tness, where we
ignore events that are in the log, but do not correspond to an activity in the
model according to the alignment.
generalization considers the frequency with which each node in the tree needs
to be visited if the model is to produce the given log. for this we use the
alignment provided by the replay tness. if a node is visited more often, then
we are more certain that its behavior is (in)correct. if some parts of the tree
are very infrequently visited, generalization is bad.
simplicity quanties the complexity of the model. simplicity is measured by
comparing the size of the tree with the number of activities in the log. this
is based on the nding that the size of a process model is the main factor
fig. 2: relation between process trees and block-structured petri nets.
5for perceived complexity and introduction of errors in process models [16].
furthermore, since we internally use binary trees, the number of leaves of the
process tree has a direct inuence on the number of operator nodes. thus,
the tree in which each activity is represented exactly once is considered to
be as simple as possible.
the four metrics above are computed on a scale from 0 to 1, where 1 is
optimal. replay tness, simplicity and precision can reach 1 as optimal value.
generalization can only reach 1 in the limit i.e., the more frequent the nodes are
visited, the closer the value gets to 1. the exibility required to nd a process
model that optimizes a weighted sum over the four metrics can eciently be
implemented using a genetic algorithm.
3.3 the etm algorithm
in order to be able to seamlessly balance the dierent quality dimensions we
implemented the etm algorithm (which stands for evolutionary tree miner ).
in general, this genetic algorithm follows the process shown in figure 3. the
input of the algorithm is an event log describing the observed behavior and,
optionally, one or more reference process models. first, the dierent quality
dimensions for each candidate currently in the population are calculated, and
using the weight given to each dimension, the overall tness of the process tree
is calculated. in the next step certain stop criteria are tested such as nding a
tree with the desired overall tness, or exceeding a time limit. if none of the
stop criteria are satised, the candidates in the population are changed and the
tness is again calculated. this is continued until at least one stop criterion is
satised and the best candidate (highest overall tness) is then returned.
the genetic algorithm has been implemented as a plug-in for the prom frame-
work [18]. we used this implementation for all experiments presented in this
paper. the algorithm stops after 1 ;000 generations or sooner if a candidate
with perfect overall tness is found before. in [7] we empirically showed that
1;000 generations are typically enough to nd the optimal solution, especially
fig. 3: the dierent phases of the genetic algorithm.
6for processes with few activities. all other settings were selected according to
the optimal values presented in [7].
4 similarity as the 5th dimension
in order to extend our etm algorithm for process model improvement we need
to add a metric to measure the similarity of the candidate process model to the
reference process model. similarity of business process models is an active area
of research [3, 8, 9, 12{15, 19]. we distinguish two types of similarity: i) behav-
ioral similarity and ii) structural similarity . approaches focusing on behavioral
similarity, e.g. [3, 8, 9, 13, 19], encode the behavior described in the two process
models to compare using dierent relations. examples are causal footprints [9],
transition adjacency relations [19], or behavioral proles [13]. by comparing two
process models using such relations, it is possible to quantify behavioral similar-
ity in dierent ways.
approaches focusing on structural similarity only consider the graph struc-
ture of models and abstract from the actual behavior, e.g., heuristic approaches
like [15], only focus on the number of common activities ignoring the connecting
arcs, or vice versa, ignore the actual activities to only consider the arcs. most
approaches [8, 12, 14] provide a similarity metric based on the minimal number
of edit operations required to transform one model into the other model, where
an edit is either a node or an arc insertion/removal.
both behavioral and structural similarity approaches rst require a suitable
mapping of nodes between the two models. this mapping can be best achieved
by combining techniques for syntactic similarity (e.g. using string-edit distance)
with techniques for linguistic similarity (e.g. using synonyms) [8].
our algorithm only needs to consider the structural similarity, since the event
log already captures the behavior that the process model should describe. recall
that the behavior of the reference model w.r.t. the logs is already measured
by means of the four mining dimensions (fig. 3.2). hence, we use structural
similarity to quantify the fth dimension.
4.1 tree edit distance as a metric for similarity
since we use process trees as our internal representation, similarity between two
process trees can be expressed by the tree edit distance for ordered trees. the
tree edit distance dimension indicates how many simple edit operations (add,
remove and change) need to be made to nodes in one tree in order to obtain the
other tree. since the other four quality metrics are normalized to values between
0 and 1, we need to do the same for the edit distance. this is easily done by
making the number of edits relative to the sum of the size of both trees. the
similarity score nally is calculated as 1 minus the edit distance ratio. hence,
a similarity score of 1 :000 means that the process model is the same as the
reference model.
7figure 4 shows examples of each of the three edit operations. the reference
tree is shown in figure 4a. figure 4b shows the result after deleting activity b
from the tree. our trees are binary trees, meaning that each non-leaf node has
exactly 2 children. therefore, the operator node is also removed. the removal
ofbfrom the tree results in an edit distance of 2. the similarity is 1  2
5+3= 0:75.
the process tree shown in figure 4c has activity dadded in parallel to activity
a. this also results in 2 edits since a new ^operator node needs to be added,
including a leaf for activity d. since the resulting tree has grown, the relative
edit distance is less than when part of the tree is deleted. finally, changing a
node as shown in figure 4d, where the root !operator is changed into an ^
operator, only requires 1 edit operation.
we use the robust tree edit distance (rted) algorithm [17] to calculate the
edit distance between two ordered trees. the rted approach rst computes the
optimal strategy to use for calculating the edit distance. it then calculates the
edit distance using that strategy. since the overhead of determining the optimal
strategy is minimal, this ensures best performance and memory consumption,
especially for larger trees. however, it is important to realize that our approach is
not limited to the rted algorithm. furthermore, although in this paper we only
consider a single distance metric, it is possible to incorporate multiple metrics
(for example looking at both structural and behavioral similarity).
!

cba
(a) refer-
ence tree.!
casim: 0.750 2 edits
(b) removing b!

cb^
dasim: 0.833 2 edits
(c) adding d in par-
allel to a^

cbasim: 0.900 1 edit
(d) change root to
^.
fig. 4: examples of possible edits on a tree (a) and respective similarities.
table 1: the event log
trace # trace #
a b c d e g 6a d b c f g 1
a b c d f g 38 a d b c e g 1
a b d c e g 12 a d c b f g 4
a b d c f g 26 a c d b f g 2
a b c f g 8a c b f g 1
a c b e g 1
fig. 5: petri net of a loan application
process. ( a= send e-mail, b= check
credit, c= calculate capacity, d= check
system, e= accept, f= reject, g= send
e-mail)
8table 2: dierent weight combinations and the resulting tness values for the
simple example.
weights quality
sim fpgssimedits f p g s
100101111.000 00.880 1.000 0.668 0.737
10101110.935 31.000 0.885 0.851 0.737
1101110.667 121.000 0.912 0.889 1.000
0.1101110.639 131.000 0.923 0.889 1.000
1001111.000 00.880 1.000 0.668 0.737
10100110.935 31.000 0.849 0.851 0.737
10101010.978 10.951 0.992 0.632 0.737
10101100.935 31.000 0.885 0.851 0.737
5 experimental evaluation
throughout this section we use a small example to explain the application and
use of our approach. figure 5 describes a simple loan application process of a
nancial institute which provides small consumer credits through a webpage. the
gure shows the process as it is known within the company. when a potential
customer lls in a form and submits the request from the website, the process
starts by executing activity awhich noties the customer with the receipt of the
request. next, according to the process model, there are two ways to proceed. the
rst option is to start with checking the credit (activity b) followed by calculating
the capacity (activity c), checking the system (activity d) and rejecting the
application by executing activity f. the other option is to start with calculating
the capacity (activity c) after which another choice is possible. if the credit is
checked (activity b) then nally the application is rejected (activity f). another
option is the only one resulting in executing e, concerned with accepting the
application. here activity dfollows activity c, after which activity bis executed,
and nally activity efollows. in all three cases the process ends with activity g,
which noties the customer of the decision made.
however, the observed behavior, as is recorded in the event log shown in
table 1, deviates from this process model. the event log contains 11 dierent
traces whereas the original process model only allows for 3 traces, i.e., modeled
and observed behavior dier markedly. to demonstrate the eects of incorporat-
ing the similarity between process trees, we run the extended etm algorithm
on the example data of table 1.
in [6] we showed that, on this data set, the optimal weights are 10 for replay
tness and 1 for precision, generalization and simplicity. in the rst experiment
(section 5.1), we only change the similarity weight to vary the amount of change
we allow. in the second experiment (section 5.2) we x the weight for similar-
ity and ignore each of the other four quality dimensions, one at a time. the
experiment settings and their results are shown in table 2.
95.1 varying the similarity weight
figure 6a shows the process tree that is discovered when giving the similarity a
weight of 100. the similarity ratio is 1 :000, indicating that no change has taken
place. apparently no change in the tree would improve the other dimensions
enough to be benecial.
!
g!

!

!
!
ebd!
fbc!
!
fd!
cbasim: 1.000 f: 0.880 p: 1.000
0 edits s: 0.737 g: 0.668
(a) similarity x100!
g!

^
_
_
!
ebd!
fbc!
!
fd!
cbasim: 0.935 f: 1.000 p: 0.885
3 edits s: 0.737 g: 0.851
(b) similarity x10
!
g!
^
!

efc_
dbasim: 0.667 f: 1.000 p: 0.912
12 edits s: 1.000 g: 0.889
(c) similarity x1!
g!
!

ef_
d^
cbasim: 0.693 f: 1.000 p: 0.923
13 edits s: 1.000 g: 0.889
(d) similarity x0.1
fig. 6: varying similarity weight
if we reduce the similarity weight to 10, the process tree as shown in figure 6b
is discovered. three edits have been applied: in the bottom-right part of the
tree two!and anoperator have been changed to ^and_. this allows for
more behavior, as is indicated by the increase in replay tness of 0 :220. also,
generalization increased by 0 :183, at the cost of a decrease in precision of 0 :115.
if we lower the weight of the similarity to 1, we get the process tree as shown
in figure 6c. this process tree requires 12 edits starting from the original tree
and is very dierent from the process tree we started with. however, compared
to the previous process tree, the other 4 quality dimensions have improved over-
all. replay tness has now reached a value of 1 :000 since this process tree allows
skipping activity d. also, simplicity reached 1 :000 since no activities are dupli-
cated or missing.
10table 3: dierent weight combinations and the resulting tness values for the
practice application.
weights quality
sim fpgssimedits f p g s
1000 101111.000 00.744 0.785 0.528 0.755
100101110.990 10.858 0.799 0.566 0.792
10101110.942 60.960 0.770 0.685 0.815
1101110.650 420.974 0.933 0.747 0.613
0.1101110.447 830.977 0.862 0.721 0.519
finally, reducing the similarity weight to 0 :1 provides us with the process
tree shown in figure 6d, which is also the process tree that would be found
when no initial process tree has been provided, i.e., pure discovery. the only
improvement w.r.t. the previous tree is the slight increase in precision. however,
the tree looks signicantly dierent. the resemblance to the original tree is little
as is indicated by a similarity of 0 :693, caused by the 13 edits required to the
original model.
5.2 ignoring one quality dimension
in [6] we showed that ignoring one of the four quality dimensions in general does
not produce meaningful process models. however, many of these undesirable and
extreme models are avoided by considering similarity. to demonstrate this we
set the similarity weight to 10. the other weights are the same as in the previous
experiment: 10 for tness, 1 for the rest. we then ignore one dimension in each
experiment. the results are shown in figure 7.
ignoring the tness dimension results in the process tree as shown in fig-
ure 7a. no changes were made, demonstrating that no improvement could be
made on the other three dimensions that was worth the edit.
if precision is ignored, the result is the process tree as shown in figure 7b.
replay tness and generalization improved by applying 3 edits. the tree of
figure 6b, where we used the same similarity weight but included precision,
only 1 edit was allowed. by removing the restriction on precision, it is worth to
apply more edits to improve replay tness and generalization.
we do not see this eect as strongly when we ignore generalization or sim-
plicity. the resulting process trees, shown in figure 7c and figure 7d, are very
similar to the original one with only 1 edit.
this experiment shows that considering similarity to a reference process
model avoids the extreme cases encountered in [6].
11!
g!

!

!
!
ebd!
fbc!
!
fd!
cbasim: 1.000 f: 0.880 p: 1.000
0 edits s: 0.737 g: 0.668
(a) ignoring replay tness!
g!

_
_
_
!
ebd!
fbc!
!
fd!
cbasim: 0.935 f: 1.000 p: 0.849
3 edits s: 0.737 g: 0.851
(b) ignoring precision
!
g!

!

!
!
ebd!
fbc^
!
fd!
cbasim: 0.978 f: 0.951 p: 0.992
1 edit s: 0.737 g: 0.632
(c) ignoring generalization!
g!

^
_
_
!
ebd!
fbc!
!
fd!
cbasim: 0.935 f: 1.000 p: 0.885
3 edits s: 0.737 g: 0.851
(d) ignoring simplicity
fig. 7: ignoring one dimension.
6 application in practice
within the context of the coselog project, we are collaborating with ten dutch
municipalities that are facing the problem addressed in this paper.1the munici-
palities have implemented case management support, using a particular reference
model. now they are deriving new, possibly shared, reference models because
they want to align each model with their own real process and the real processes
in the municipalities they are collaborating with.
one of the municipalities participating in the coselog project recently
started looking at one of their permit processes. the reference model used in
the implementation was very detailed, with many checks that the employees in
practice did not always do (usually with good reasons). therefore, they were
interested in a model that looks similar to the original reference model, but still
shows most of the behavior actually observed. for this we applied our technique
to discover dierent variants of the process model, focusing on dierent quality
combinations, while maintaining the desired similarity to the reference model.
1seehttp://www.win.tue.nl/coselog
12!
^
!


!
z!
	
x!
y	
xwv!
u!
	
s!
t	
sr!
p	
_
!
!
!
jih!
gf!
ke!
d	
bc
sim: 1.000 0 edits
f: 0.744 p: 0.785
s: 0.755 g: 0.528
(a) similarity x1000
!
^
!


!
z!
	
x!
y	
xwv!
u!
	
s!
t	
sr!
p	
_
!
!
!
jih!
gf!
ke!
d	
bcl
sim: 0.990 1 edit
f: 0.858 p: 0.799
s: 0.792 g: 0.566
(b) similarity x100
_
^
!


!
z!
	
x!
y	
xwv!
u!
	
s!
t	
sr!
p	
_

!

jih!
gf!
ke!
d	
bc^
al
sim: 0.942 6 edits
f: 0.960 p: 0.770
s: 0.815 g: 0.685
(c) similarity x10

!
_
!


!
z!
	
x!
y	
xwv!
u!

s!
t	
srq!
pe_
!
dc!
	
e

gfe^
a!

!
!

!
abpe!

e!

bll sim: 0.650 42 edits
f: 0.974 p: 0.933
s: 0.613 g: 0.747
(d) similarity x1
fig. 8: process trees for the municipality process.
13for this application we only used the rst part of the process which contains a
total of 27 dierent activity labels, which we anonymized using letters from ato
zplus aa.
the experiment settings and their results are shown in table 3. we exper-
imented with xed weights for the original four quality dimensions, and only
changed the weight for the similarity to the reference model. the results conrm
the intuition that reducing the weight of the similarity dimension allows more
edits to be made (cf. the quality part of the table). in general, we also see that
by allowing more edits, most of the quality dimensions improve. of course, there
is a trade-o between dierent dimensions. since we weight the replay tness
dimensions 10 times more than the others, we see that this dimension always
improves, sometimes at the cost of the other dimensions.
figure 8a shows the process tree that is discovered using a similarity weight of
1;000. this is the same process tree as created from the process model provided
by the municipality. all four quality dimensions are relatively bad and many
improvements are possible. however, none of these improvements were applied
since one change needs to drastically improve the process tree to be worth it.
if we set the similarity weight to 100 we obtain the process tree of figure 8b.
here one edit has been made, namely the left-most activity leaf node has been
changed from tol. this single edit causes all four quality dimensions to im-
prove, especially replay tness. the original process model used a signicantly
dierent activity name than the one present in the event log, which was trans-
lated to ain the process tree.
if we further relax the importance of similarity by using a weight of 10, we
obtain the process tree of figure 8c. here 6 edits have been made from the
original model. the root node now changed to an _to allow more behavior. the
left branch of the root node also changed to allow more behavior, better suiting
the recorded behavior. also the operator node of activities iand jchanged as
well as the operator of their grandparent node. it appears that the event log
contains a lot of short traces, only containing activities from the rst part of
the process. some traces even contain activity lonly. all the dimensions have
improved after these changes, except precision which has slightly decreased.
further relaxing the similarity we obtain the process trees of figure 8d
(weight of 1 { 42 changes) and figure 8e (weight of 0 :1 { 83 changes). both these
models have little to do with the original reference model. at the same time,
the quality of these two process trees with respect to the log did not improve
!
_
!


!
z!
!
y	
xwvu!


	
o!
t!
rqp!

pe!
!

p!

ed_

a!
abc!

!
!
ape!

	

f!

g!

j!

fe!

!

!

dca!

e!

alsim: 0.447 83 edits
f: 0.977 p: 0.862
s: 0.519 g: 0.721
(e) similarity x0.1
fig. 8: process trees for the municipality process (cont'ed).
14much, while their appearance did. therefore, for this experiment, we propose
the process tree of figure 8c as the improved version of the reference model. by
applying only 6 edits the process model has improved signicantly, mainly on
replay tness (from 0 :744 to 0:960), while still showing a great resemblance to
the original reference model.
7 conclusion
in this paper, we proposed a novel process mining algorithm that improves a
given reference process model using observed behavior, as extracted from the
event logs of an information system. a distinguishing feature of the algorithm is
that it takes into account the structural similarity between the discovered pro-
cess model and the initial reference process model. the proposed algorithm is
able to improve the model with respect to the four basic quality aspects (tness,
precision, generalization and simplicity) while remaining as similar as possible to
the original reference model (5th dimension). the relative weights of all ve di-
mensions can be congured by the user, thus guiding the discovery/modication
procedure. we demonstrated the feasibility of the algorithm through various
experiments and illustrated its practical use within the coselog project.
a limitation of this paper is that it assumes that the deviations discovered
from the logs are always rightful. indeed, some process deviations do reect
an evolving business process due to new acceptable practices or regulations,
and as such should be accommodated into the reference model. however, some
other deviations may be the result of non-compliance or be caused by a sub-
ecient execution. these undesirable deviations should be isolated and discarded
in order to prevent bad practices form becoming a part of the reference model.
in future work, we plan to implement a more ne-grained control on the dierent
costs for edit actions on dierent parts of the process model. for example, edits
on operators may have lower costs than edits on labels. in this way we can
for instance restrict our changes to extensions of the original reference model,
and prevent existing parts of the model from being changed. also, pre-dened
domain-specic constraints which the process model should adhere to can be
xed in this way. however, while these techniques may help produce better
results, the identied deviations still need to be validated by a domain expert
before making their way into the reference model. only in this way we can ensure
that false positives are properly identied.
finally, we plan to conduct an empirical evaluation of the understandability
of the process models discovered using our algorithm, as perceived by domain
experts, and compare the results with those obtained with other process mining
algorithms, which ignore the similarity dimension.
acknowledgments nicta is funded by the australian department of broad-
band, communications and the digital economy and the australian research
council through the ict centre of excellence program.
15references
1. w.m.p. van der aalst. process mining: discovery, conformance and enhancement
of business processes . springer, 2011.
2. w.m.p. van der aalst, a. adriansyah, and b. van dongen. replaying history
on process models for conformance checking and performance analysis. wires
data mining and knowledge discovery , 2(2):182{192, 2012.
3. w.m.p. van der aalst, a. de medeiros, and a. weijters. process equivalence:
comparing two process models based on observed behavior. in proceedings of
bpm , lncs. springer, 2006.
4. a. adriansyah, b. van dongen, and w.m.p. van der aalst. conformance checking
using cost-based fitness analysis. in proceedings of edoc , pages 55{64. ieee
computer society, 2011.
5. a. adriansyah, j. munoz-gama, j. carmona, b.f. van dongen, and w.m.p.
van der aalst. alignment based precision checking. in proceedings of the 8th
bpi workshop , lnbip. springer, 2012. (to appear).
6. j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst. on the role of fit-
ness, precision, generalization and simplicity in process discovery. in proceedings
of coopis , lncs. springer, 2012.
7. joos c. a. m. buijs, boudewijn f. van dongen, and wil m. p. van der aalst. a ge-
netic algorithm for discovering process trees. in ieee congress on evolutionary
computation , pages 1{8. ieee, 2012.
8. r.m. dijkman, m. dumas, b.f. van dongen, r. k a arik, and j. mendling. simi-
larity of business process models: metrics and evaluation. information systems ,
36(2):498 { 516, 2011.
9. b.f. van dongen, r.m. dijkman, and j. mendling. measuring similarity between
business process models. in proceedings of caise , volume 5074 of lncs , pages
450{464. springer, 2008.
10. dirk fahland and w.m.p. van der aalst. repairing process models to reect
reality. in proceedings of bpm , lncs. springer, 2012.
11. mauro gambini, marcello la rosa, sara migliorini, and arthur h. m. ter hofstede.
automated error correction of business process models. in proceedings of bpm ,
lncs. springer, 2011.
12. tao jin, jianmin wang, and lijie wen. ecient retrieval of similar business
process models based on structure. in proceedings of coopis , lncs. springer,
2011.
13. m. kunze, m. weidlich, and m. weske. behavioral similarity { a proper metric.
inproceedings of bpm , volume 6896 of lncs , pages 166{181. springer, 2011.
14. m. la rosa, m. dumas, r. uba, and r. dijkman. business process model merging:
an approach to business process consolidation. acm transactions on software
engineering and methodology , 22(2), 2013.
15. c. li, m. reichert, and a. wombacher. the minadept clustering approach for
discovering reference process models out of process variants. ijcis , 19(3-4):159{
203, 2010.
16. j. mendling, h.m.w. verbeek, b.f. van dongen, w.m.p. van der aalst, and
g. neumann. detection and prediction of errors in epcs of the sap reference
model. data and knowledge engineering , 64(1):312{329, 2008.
17. mateusz pawlik and nikolaus augsten. rted: a robust algorithm for the tree
edit distance. corr , abs/1201.0230, 2012.
1618. h.m.w. verbeek, j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst.
xes, xesame, and prom 6. in proceedings of caise forum , volume 72 of lnbip ,
pages 60{75, 2010.
19. h. zha, j. wang, l. wen, c. wang, and j. sun. a workow net similarity measure
based on transition adjacency relations. computers in industry , 61(5):463{471,
2010.
17