data-driven process discovery : revealing conditional
infrequent behavior from event logs
mannhardt, f.; de leoni, m.; reijers, h.a.; van der aalst, w.m.p.
published in:
advanced information systems engineering: 29th international conference, caise 2017, essen, germany,
june 12-16, 2017, proceedings
doi:
10.1007/978-3-319-59536-8_34
published: 01/01/2017
document version
accepted manuscript including changes made at the peer-review stage
please check the document version of this publication:
• a submitted manuscript is the author's version of the article upon submission and before peer-review. there can be important differences
between the submitted version and the official published version of record. people interested in the research are advised to contact the
author for the final version of the publication, or visit the doi to the publisher's website.
• the final author version and the galley proof are versions of the publication after peer review.
• the final published version features the final layout of the paper including the volume, issue and page numbers.
link to publication
citation for published version (apa):
mannhardt, f., de leoni, m., reijers, h. a., & van der aalst, w. m. p. (2017). data-driven process discovery :
revealing conditional infrequent behavior from event logs. in e. dubois, & k. pohl (eds.), advanced information
systems engineering: 29th international conference, caise 2017, essen, germany, june 12-16, 2017,
proceedings (pp. 545-560). (lecture notes in computer science; vol. 10253). cham: springer. doi:
10.1007/978-3-319-59536-8_34
general rights
copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners
and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.
            • users may download and print one copy of any publication from the public portal for the purpose of private study or research.
            • you may not further distribute the material or use it for any profit-making activity or commercial gain
            • you may freely distribute the url identifying the publication in the public portal ?
take down policy
if you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately
and investigate your claim.
download date: 14. jan. 2018data-driven process discovery - revealing conditional
infrequent behavior from event logs
felix mannhardt1, massimiliano de leoni1, hajo a. reijers2,1,
wil m.p. van der aalst1
1eindhoven university of technology, eindhoven, the nether lands
2vrije universiteit amsterdam, amsterdam, the netherlands
f.mannhardt, m.d.leoni, h.a.reijers, w.m.p.v.d.aalst@t ue.nl
abstract. process discovery methods automatically infer process mod els from
event logs. often, event logs contain so-called noise, e.g. , infrequent outliers or
recording errors, which obscure the main behavior of the pro cess. existing meth-
ods ﬁlter this noise based on the frequency of event labels: i nfrequent paths and
activities are excluded. however, infrequent behavior may reveal important in-
sights into the process. thus, not all infrequent behavior s hould be considered as
noise. this paper proposes the data-aware heuristic miner ( dhm), a process dis-
covery method that uses the data attributes to distinguish i nfrequent paths from
random noise by using classiﬁcation techniques. data- and c ontrol-ﬂow of the
process are discovered together. we show that the dhm is, to s ome degree, ro-
bust against random noise and reveals data-driven decision s, which are ﬁltered
by other discovery methods. the dhm has been successfully te sted on several
real-life event logs, two of which we present in this paper.
keywords: process mining ·process discovery ·event logs ·noise·rules
1 introduction
process models are used by organizations to document, speci fy, and analyze their pro-
cesses [1]. a process model describes the expected behavior of a process in terms of
its activities (i.e., units of work) and their ordering. mos t contemporary processes are
supported by information systems. often, those systems rec ord information about the
execution of processes in databases. with the abundance of s uch data, there is a growing
interest in process discovery [2], i.e., revealing the actual execution of processes from
events. process discovery methods automatically infer pro cess models from event logs .
one important challenge for process discovery methods is to handle event logs with
noise [2,3]. in practice, event logs often contain noise, e.g., ou t-of-order events, ex-
ceptional behavior, or recording errors [4]. including all such infrequent events in the
process discovery often leads to unusable, complex models. therefore, noise ﬁltering
methods that distinguish noise from the regular behavior of the proc ess may be useful.
some of the early techniques for process discovery assumed n oise-free event logs
(e.g., the alpha algorithm [5] and the region based approach es [6]). these techniques
are of limited use in real-life settings. most of the more rec ent and more sophisticated
process discovery methods support noise ﬁltering [3]. exis ting noise-ﬁltering methodsare based on frequencies [7,8,9,10], machine-learning tec hniques [11,12], genetic algo-
rithms [13], or probabilistic models [14,15]. all of those m ethods focus on the control-
ﬂow perspective (i.e., the event labels) when ﬁltering noise. dedicated noi se ﬁltering
methods [16,17] are also based on frequencies.
however, processes are often governed by rules. decision ar e taken on the basis
of available data, available resources, and the process con text. some paths may be ex-
ecuted infrequently because the corresponding conditions are rarely fulﬁlled. existing
methods based solely on the control-ﬂow perspective would d isregard such infrequent
behavior as noise. however, some infrequent behavior may be characterized by v ery de-
terministic rules, and, thus, be of great interest to proces s analysts (e.g., in the context of
risks and fraud). for example, shortcuts in a process might o nly be taken by a speciﬁc
resource, undesired behavior might be subject to condition s, and infrequently actions
might be legitimate only for special types of cases. these ki nd of events should not be
set aside as noise . methods exist to discover such decision rules [18,19,20] b ut all rely
on a previously discovered process model of the process. hen ce, existing methods do
not leverage the full potential of the data perspective . data- and control-ﬂow need to be
discovered together. recent work on declarative process di scovery [21] considers the
data perspective. however, similar to association rule min ing, sets of rules rather than
full process models are returned.
in this work, we propose the data-aware heuristic miner (dhm ), which takes the
data perspective into account when discovering the control ﬂow of a process. the dhm
uses classiﬁcation techniques to reveal data dependencies between activities, and uses
these data dependencies to distinguish noise from infrequent conditional behavior . it
returns process models that yield a better insight into the d ata perspective of processes
by revealing hidden data dependencies while ﬁltering rando m noise. the evaluation on
real-life cases shows that the dhm reveals additional insig htsnotreturned by state-
of-the-art process discovery methods. we conﬁrmed the disc overed conditions with a
domain expert for one of the real-life event logs. the experi ment on the synthetic data
shows that the dhm is resilient to a certain degree of randoml y injected noise, which is
not characterized by data conditions. it rediscovers the or iginal model, whereas earlier
techniques either show too much, or too little behavior. the contribution of this paper is
a process discovery method that is able to distill important information from infrequent
behavior instead of dismissing it as noise.
the remainder of this paper is structured as follows. we star t by introducing the
problem with an example in sect. 2. then, required prelimina ries are introduced in
sect. 3. section 4 presents our novel process discovery meth od. we evaluate our method
using both synthetic and real-life data in sect. 5. finally, sect. 6 concludes the paper.
2 problem description
figure 1 shows a simpliﬁed process from the health care domai n. we use this example
in the paper to motivate the relevance of the data perspectiv e for noise ﬁltering. when
patients arrive at the hospital they are assigned a triage pr iority, registered and assigned
to a responsible nurse. only in exceptional cases, patients are assigned the white triage
priority. those patients typically, leave the emergency wa rd directly after registrationfig. 1. a simpliﬁed process in bpmn notation from the emergency ward of a hospital, which is
used as motivating example throughout this paper.
(a) im ﬁlters little of the injected noise
and fails to reveal behavior aand b.(b) hm ﬁlters the injected noise well, but
fails to show behavior a,band c.
fig. 2. models discovered by im and hm on an event log generated from t he example process.
since their injuries do not require the attendance of a docto ra. all other patients are
admitted to the emergency ward. while patients are in the eme rgency ward a nurse
periodically checks their condition. in parallel to this, f or the group of patients under
consideration, an x-ray is taken and a doctor visits the pati ent. there are two different
work practices regarding these two activities. normally, t he doctor visits the patients af-
ter which the x-ray is taken. one particular nurse (alice) re -sequences these activities
in the reversed order to improve the process: ﬁrst the x-ray i s taken and, only there-
after, the doctor visits the patient b. as this work practice is only followed by one
nurse, it is observed less frequently. afterwards, the doct or visits the patient one more
time and decides on the type of dismissal. then, the patient i s prepared for a possible
transfer. for patients with the outdismissal type an ambulance needs to be organized
c. this process contains three examples of infrequent, data- dependent behavior: aa
data-dependent path, bdata-dependent re-sequencing, and ca data-dependent activ-
ity. the goal of our work is to rediscover such behavior, whil e ignoring random noise.
assume an event log of the process in figure 1 obtained from th e information sys-
tems of the hospital. as motivated in the introduction, it is likely that this event log
contains noise. we applied both the heuristic miner (hm) [8] and the inductive miner
(im) [9] as representatives of discovery methods supportin g noise ﬁltering on such an
event log with a controlled degree of noise1. figure 2 shows the resulting process mod-
1here, in 5% of the cases one additional event was randomly exe cuted out of the original order.table 1. three traces of the example process with attributes activity, priority, nurse, and type.
(a) trace σ1∈l
id act p n t
e11triage red
e12register joe
e13check
e14check
e15check
e16visit
e17x-ray
e18f. visit icu
e19prepare(b) trace σ2∈l
id act p n t
e21triage red
e22register alice
e23check
e24x-ray
e25visit
e26check
e27f. visit out
e28prepare
e29org. amb.(c) trace σ3∈l
id act p n t
e31triage red
e32register joe
e33check
e34visit
e35x-ray
e36check
e37check
e38f. visit nc
e39prepare
els in bpmn notation. clearly, both methods are unaware of th e data perspective. there-
fore, they fail to distinguish between random noise and the i nfrequent data-dependent
behavior a,b, and c. it might be possible to tweak the parameters of the algorith ms
such that more behavior is revealed (e.g., through grid sear ch). still, ﬁnding the correct
parameter setting that does not include unrelated noise req uires deep knowledge about
the underlying process. therefore, this is often not feasib le. moreover, it is not possible
to reveal the infrequent data-dependent behavior by using d ecision mining techniques.
those techniques can only reveal decision rules for paths th at are reﬂected in the process
model, thus low-frequent but deterministic behavior remai ns undetected.
in the remainder of this paper, we describe the dhm, which ext ends the ideas of the
hm with the use of classiﬁcation techniques to reveal data de pendencies. our method,
indeed, rediscovers the behavior of the process as shown in f igure 1.
3 preliminaries
anevent log stores information about activities that were recorded by i nformation sys-
tems supporting the execution of a process [2]. each executi on of a process instance
results in a sequence of events. each events corresponds to t heexecution of one activity .
given universes of attributes aand values u, an event log l=(e,σ,#,l)consists of:
–ea ﬁnite set of unique event identiﬁers;
–σ⊆ua ﬁnite set of activities;
–# :e→(a/ne}ationslash→u)obtains the attribute values recorded for an event;
–l⊆e∗the set of traces over e. a traceσ∈lrecords the sequence of events for
one process instance. each event occurs only in a single trac e.
given an event e∈e, we write # a(e)∈uto obtain the value u∈urecorded for at-
tribute a∈a. we require events to record at least the activity attribute : #act(e)∈σis
thename of the activity that caused the event. given a trace /an}bracketle{te1,..., en/an}bracketri}ht ∈l, we de-
ﬁneval:e→(a/ne}ationslash→u)to collect the latest attribute values recorded before an event
occurred, i.e., val(ei)=val(ei−1)⊕#(ei−1)with special case val(e1)=f∅.2we denote
2f⊕gdenotes the overriding union of fandg, and f∅:∅→uis the empty function.ⓐⓑ ⓒso si
fig. 3. a causal net (c-net) of the example process. activities are d epicted with boxes, the depen-
dency relations as edges, and the binding functions as black dots on the edges. the unique start
and end activities are shown as black boxes. the dotted edges are explained in sect. 5.
thepredecessor event in the trace by•(ei)=ei−1with special case•(e1)=⊥. finally,
in the remainder of this paper, we assume that a particular ev ent log l=(e,σ,#,l)
exists to avoid unnecessary notation.
example 1. table 1 shows three traces σ1,σ2,σ3∈lbased on the process shown in
fig 1. each event has a unique identiﬁer. we can identify the a ctivity of event e11as
#act(e11) =triage . moreover, event e11writes the attribute value # priority(e11) =red.
we obtain the latest attribute values recorded before e18occurred as val(e18)=f, with
f(priority)=red and f(nurse)=joe.
our method uses causal nets (c-nets) to represent the discovered process model [8,22].
a c-net is a tuple (σ,si,so,d,i,o)where:
–σis a ﬁnite set of activities;
–si∈σis the unique start activity;
–so∈σis the unique end activity;
–d⊆σ×σis the dependency relation;
–b={x⊆p(σ)|x={∅}∨∅/∈x}are possible bindings;3
–i∈σ→bis the set of input bindings per activity;
–o∈σ→bis the set of output bindings per activity,
such that the dependency relations match the input and outpu t bindings, i.e., d=
{(s1,s2)∈σ×σ|s1∈/uniontext
β∈i(s2)β∧s2∈/uniontext
β∈o(s1)β}. we require c-nets to have a unique
start and end activity, i.e., {si}={s∈σ|i(s) ={∅}} {so}={s∈σ|o(s) ={∅}}.
the input and output binding functions of a c-net deﬁne its la nguage. we describe the
c-net semantics by example, the full semantics are describe d in [22].
example 2. figure 3 shows how the example from figure 1 can be modeled as c -net.
activities are depicted with boxes and dependency relation s as edges. there are unique
start and end activities: siandso. output and input bindings are depicted by black dots
on the edges in figure 3. bindings indicate which combinatio ns of activities can pre-
cede or follow a given activity. connected dots show activit ies belonging to the same
binding. we abbreviate activity names by using the ﬁrst lett er. for example, after ac-
tivity si, activities t and r follow in a sequence, i.e., o(si) ={{t}},i(t) ={{si}}
ando(t)={{r}},i(r)={{t}}. then, there are multiple alternative choices. three
3p(σ)denotes the powerset of set σ.output bindings are deﬁned for r: o(r) ={{so},{c,x},{c,v}}. each set of activi-
ties represents a possible choice of following activities ( xor gateway). either only so,
or both c and x, or both c and v need to happen. activities in the same set can be
executed in parallel (and gateway).
4 data-driven process discovery
the dhm builds on the insight that infrequent but data-depen dent process behavior is
of great interest to process analysts and, thus, should not b e disregarded as noise. we
extend the ideas of the hm [8] with a measure for conditional dependency .
4.1 data-aware dependency measure
to discover data-dependent behavior in the event log, we mak e use of classiﬁcation
techniques (e.g., decision trees). more speciﬁcally, we re ly on binary classiﬁers predict-
ing directly-follows relations based on attribute values r ecorded in the event log. we
denote these classiﬁers as dependency conditions .
deﬁnition 1 (dependency conditions). given universes of attributes a, values u, and
activities σ⊆u, we deﬁne the dependency conditions c ∈(σ×σ)→((a/ne}ationslash→u)→
{0,1}). adependency condition ca,b(x) = ( c(a,b))(x)is a binary classiﬁer that pre-
dicts whether an event of activity a is directly followed by a n event of activity b for the
attribute values x ∈(a/ne}ationslash→u), i.e., c a,b(x)=1when bis predicted to directly follow a
and c a,b(x)=0when a different activity is predicted.
in the remainder of the paper, we denote with 1a special dependency condition function
that returns classiﬁers predicting 1 regardless of the attr ibute values, i.e., ∀a,b∈σ,∀x∈
(a/ne}ationslash→u):1a,b(x)=1. given a dependency condition, we establish the frequency with
which activities are observed to directly follow other acti vities in the event log when
the condition holds. we denote this as: conditional directly follows .
deﬁnition 2 (conditional directly follows relation). given activities a ,b∈σand de-
pendency conditions c, we write a >c,lb if and only if an execution of activity a with
the latest attribute values x is directly followed by an execution of activity b under de-
pendency condition c a,b(x). we denote the frequency of a conditional directly follows
relation a >c,lb in the event log as:
/vextendsingle/vextendsinglea>c,lb/vextendsingle/vextendsingle=|{e∈e|#act(•(e))= a∧•(e)/ne}ationslash=⊥∧#act(e)=b
∧ca,b(val(e))= 1}|.
now, we deﬁne a data-aware variant of the dependency measure proposed by the hm.
deﬁnition 3 (conditional dependency measure). given activities a ,b∈σand depen-
dency conditions c. we deﬁne a ⇒c,lb:ς×σ→[−1,1]as the strength of the causal
dependency from a to b under condition c a,bin the event log:
a⇒c,lb=

|a>c,lb|−|b>c,la|
|a>c,lb|+|b>c,la|+1for a/ne}ationslash=b,
|a>c,la|
|a>c,la|+1otherwise.the intuition behind the data-aware variant of these measur es is that a relation (a,b)
should be included in the dependency relations of the discov ered causal net when it is
clearly characterized by a certain dependency condition ca,b.
example 3. consider an event log lwith 50 traces like σ1, 50 traces like σ2and 50
traces like σ3as shown in table 1. we determine the conditional dependency mea-
sure x⇒c,lvfrom activity x-ray (x) to activity visit (v). we assume that condi-
tion cx,v(v)returns 1 only if attribute nurse values takes on the value alice. then,
we obtain the number of times x is directly followed by v under condition cx,vas/vextendsingle/vextendsinglex>c,lv/vextendsingle/vextendsingle=50, and the number of times v is directly followed by x under co nditions
cas/vextendsingle/vextendsinglev>c,lx/vextendsingle/vextendsingle=0. therefore, the conditional dependency measure under con ditions
cisx⇒c,lv=50−0
50+0+1≈0.98. this indicates a strong dependency relation from activ-
ity x to activity v under condition cx,v. by contrast, if we consider the unconditional
dependency measure x⇒1,lv, then we obtain50−100
50+100+1≈ −0.33. thus, when disre-
garding the data perspective, both activities appear to be e xecuted in parallel.
4.2 discovering data conditions
we described the conditional directly-follows relation and the conditional dependency
measure . we use the latter measure to determine which relations shou ld be included in
the c-net. both concepts rely on discovered dependency conditions . here, we describe
how to train a classiﬁer that can be used as dependency condit ion. we build a set of
training instances for every combination of activities (a,b)∈σ×σ.
in the remainder, b(x)denotes the set of all multi-sets over a set x. we use x=
[a2,b]as a short-hand notation to denote the multi-set x=[a,a,b], and/unionmultitextto denote the
sum of two multi-sets, i.e., x/unionmultitext[b,c]=[a2,b2,c].
deﬁnition 4 (training instances). given a source activity a ∈σ, a candidate activity
b∈σ, and a dependency threshold θdep∈[0,1]. let a•⊆σbe the set of activities s that
directly follow a in the event log with an unconditional depe ndency measure above the
threshold θdep, i.e., a•={s∈σ|a⇒1,ls≥θdep}. we collect those events x l,a,b⊆e
that directly follow an execution of ain the event log, and refer to activities in a•, or to
the candidate activity b, i.e., x l,a,b={e∈e|•(e)=a∧#act(e)∈a•∪{b}}. function
tl,θdep∈(σ×σ)→b((a/ne}ationslash→u)×{1,0})returns the multi-set of training instances:
tl,θdep(a,b)=/unionmultidisplay
e∈xl,a,b[(val(e),cl(e))]with cl(e)=/braceleftbigg1,for#act(e)=b
0,for#act(e)/ne}ationslash=b
conceptually, our method is independent of the used classiﬁ cation algorithm. con-
cretely, we employ decision trees (c4.5) [23] as an efﬁcient method that result in human
interpretable conditions. we build the dependency conditi onscby assembling a set of
training instances tl,θdep(a,b)and training a decision tree for each possible relation
(a,b)∈σ×σ. only good dependency conditions with discriminative powe r are used
later on. we use a score q(ca,b)∈[0,1]to determine the quality of a particular condition
ca,b. there are many possible performance measures for binary cl assiﬁcation algorithmthat can be used together with our method. none of the measure s is universally accepted,
the correct choice depends on the concrete application area .
we opted for cohen’s kappa ( κ) [24], which indicates whether the prediction was
better than a prediction by chance (i.e., for κ>0). kappa favors a good prediction per-
formance on the minority class, which is a desirable propert y in our setting. moreover,
it has been recommended for nonparametric binary classiﬁer s, such as c4.5, on data
with imbalanced class priors [25]. however, we do notclaimκto be the best measure
and, thus, foresee other measures to be plugged-in dependin g on the application area.
example 4. consider the dependency threshold θdep=0.9 and an event log contain-
ing 150 traces, where 50 traces record the same values as σ1, 50 traces the same
values as σ2and 50 traces the same values as σ3. we train a classiﬁer for the de-
pendency condition cx,v, i.e., the dependency relation from x-ray (x) to visit (v)
using the training instances tl,θdep(x,v). the training instances are tl,θdep(x,v) =
[(v1,final visit )50,(v2,visit)50]with attribute value functions v1(p) =red, v1(n) =
joe and v2(p)=red, v2(n) =alice. please note that there is no instance with the ac-
tivity check (c) since the unconditional dependency measur ex⇒1,lcis below the
threshold of 0.9. therefore, the instances based on trace σ3are not included as we al-
ready know that activity c is in parallel to x. we train a c4.5 d ecision tree and obtain
the dependency condition cx,vwith cx,v(v2)=1 and cx,v(v1)=0.
4.3 data-driven discovery of causal nets
we describe the dhm method that builds c-nets based on conditional dependencies .
the dhm supports four user-speciﬁed thresholds that can be u sed to tune the noise
ﬁltering capabilities to speciﬁc needs of the user. all thre sholds range between 0 and 1:
–θobs, the observation threshold, which controls the relative fr equency of relations;
–θdep, the dependency threshold, which controls the strength of c ausal dependencies;
–θbin, the binding threshold, which controls the number of bindin gs;
–θcon, the condition threshold, which controls the quality of dat a-dependencies.
we discover a c-net (σ,si,so,d,i,o)from event log l=(e,σ,#,l)and thresholds
θobs,θdep,θbin,θconin the following steps.
1. we want to ensure that the resulting c-net has a unique start and end activ-
ity. therefore, we add artiﬁcial start and end events to all trac es, i.e.,∀σ∈l(σ=
(ei,e1,..., en,eo)∧#act(ei)=si∧#act(eo)=so)andς=σ∪{si,so}.
2. we build the set of standard dependency relations as follows:
d={(a,b)∈σ×σ|a⇒1,lb≥θdep∧/vextendsingle/vextendsinglea>1,lb/vextendsingle/vextendsingle
|l|≥θobs}.
3. we discover the dependency conditions cby training classiﬁers for each pair
(a,b)∈σ×σusing the training instances tl,θdep(a,b).
4. we add the conditional dependency relations tod. we useθconinstead of θobsto
obtain infrequent, high-quality data conditions:
d=d∪{(a,b)∈σ×σ|q(ca,b)≥θcon∧a⇒c,lb≥θdep}.5. some activities s∈σmight not have a predecessor or successor in the directed
graph induced by d. intuitively, each task in a process should have a cause (pre de-
cessor) and an effect (successor) [8], all tasks in the c-net should be connected .
therefore, we propose two alternative heuristics to enforc e this:
–all-task-connected heuristic proposed by the hm [8], or
–theaccepted-task-connected heuristic , a new heuristic.
here, we describe the new accepted-task-connected heuristic . we repeatedly con-
nect only those activities that are already part of the depen dency graph using their
best neighboring activities until all activities have a cau se and an effect. then, set
dof relations necessary to connect all activities accepted s o far is:
d={(a,b)∈σ×σ|(∄x(a,x)∈d∧∀y(a⇒1,lb)≥(a⇒1,ly))
∨(∄x(x,b)∈d∧∀y(a⇒1,lb)≥(y⇒1,lb)}.
we extend the dependency relations with the new relations, i .e.,d=d∪d. there
might be new, unconnected activities in d. therefore, we repeat adding the best
neighboring activities until set dis empty.
6. we discover the input and output binding functions of the c-net. for the output
binding function o(a)of an activity a∈σ, we need to determine which executions
ofb∈σ(with(a,b)∈d) were caused by an execution of activity a. we use the
heuristic proposed by the hm [8] and repeat it for completene ss. the heuristic
considers activity bto be caused by activity aonly if it is the nearest activity that
may have caused b. any other activity sexecuted in between aandbshould not
be a possible cause of b, i.e.,(s,b)/∈d. given a trace σ=/an}bracketle{te1,..., ei,..., en/an}bracketri}ht∈l,
the set of activities o(ei)⊆σthat were caused by an event eiis:
o(ei)={b∈σ|#act(ei)=a
∧∃ i<j≤n#act(ej)=b∧(a,b)∈d
∧∀ i<k<j(#act(ek),b)/∈d}.
we determine the frequency |o|l,a∈nof an output binding o⊆σfor activity a∈σ
in the event log las:
|o|l,a=/vextendsingle/vextendsingle{e∈e|#act(e)=a∧o(e)=o}/vextendsingle/vextendsingle.
then, we build the complete multi-set of output bindings wit h the most frequent
bindings. those bindings that fulﬁll the user-speciﬁed bin ding threshold θbin:
o(a)={o⊆σ||o|l,a
max o⊆σ(|o|l,a)≥θbin}.
the input binding function iis obtained by reversing the same approach.
within the scope of this paper, we do not elaborate on the othe r heuristics of the hm [8],
such as long-distance, length-two loops, and the relative- to-best. those heuristics and
improvements to the hm described by the fodina miner [26] can be used together
with the dhm. the choice which heuristics to apply highly dep ends on the process athand. for example, the all-task-connected heuristic results in a process model with all
observed activities regardless of the chosen observation f requency threshold θobs. even
activities that are only observed once are added. this might not be desirable as very
infrequent activities might be considered as noise. theref ore, we introduced the new
accepted-task-connected heuristic.
5 evaluation
we implemented the dhm in the open-source framework prom4. the package data-
awarecnetminer provides a highly interactive tool , which allows to quickly discover
c-nets for different parameter settings and to explore the d iscovered data dependencies.
c-nets can be converted to petri nets or bpmn models. therefo re, existing tools can be
used on the results. we applied our method to both synthetic a nd real-life event logs.
5.1 synthetic - handling noise
event log & methods. we generated an event log with 100,000 traces and approxi-
mately 900,000 events by simulating the process model shown in fig 3. there are three
data attributes: priority (p), nurse (n), and type (t). we ad just the frequency distri-
butions of these attributes such that paths a, b, and c in mode l figure 3 are recorded
infrequently. speciﬁcally, only 1.4% of the traces record p=white , 19.1% of the traces
record n=alice , and 4.3% of the traces record t=out. we compared three methods:
our proposed method (dhm), the heuristic miner with frequen cy ﬁltering (hmf), and
the heuristic miner without frequency ﬁltering (hma). all t hree methods, used thresh-
oldsθobs=0.06(0.0 for hma ),θdep=0.9,θbin=0.1,θcon=0.5 together with the
accepted-task-connected heuristic . we used c4.5 as classiﬁer and estimated its perfor-
mance using 10 times 10-fold cross validation.
experimental design. the experiment should evaluate the noise ﬁltering capabili ties
of our method. therefore, we injected noise into the event lo g by randomly adding one
additional event to an increasing number of traces.5then, we compared the discovered
dependency relations with those of the reference model (fig ure 3) in terms of graph
edit distance (ged) [27]. we did not use ﬁtness, precision, o r behavioral comparison
measures as those would not be applicable in this setting. fi tness and precision do not
measure the performance wrt. the reference model (gold stan dard). moreover, when
the discovered models are not sound (e.g., having a deadlock ), the behavior may be
undeﬁned even when the model is close to the original. behavi oral measures would also
fail to distinguish the difference between the data-depend ent re-sequencing of activities
(pattern cin figure 3) and simple parallelism. for example, both in fig ure. 3 and in
figure 2(b) activities visit andx-ray are behaviorally in parallel.
4the package dataawarecnetminer can be downloaded from http://promtools.org .
5the synthetic event logs can be downloaded from http://dx.doi.org/10.4121/uuid:
32cad43f-8bb9-46af-8333-48aae2bea037 .0246810
0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
noise levelgraph edit distancemethod
hma
hmf
dhm
fig. 4. graph edit distances between the dependency relations disc overed by the compared meth-
ods and the reference dependency relations for varying amou nts of injected noise.
results. all models could be discovered in about 3 seconds using 2 gb of memory.
our method was able to rediscover the conditional relations a,band c, i.e., the red
edges in figure 3. the original rules p=white andt=outwere discovered for rela-
tions aandb. for path c, two rules were discovered: n=alice for the edge from x-
ray to visit and n/ne}ationslash=alice for the edge from visit to x-ray. our method discovered the
data-dependent re-sequencing of activities visit to x-ray , whereas the standard hm (cf.
bpmn model in figure 2(b)) considered both activities as par allel. figure 4 shows the
result of the ged measurement for noise levels ranging from 0 % to 40%. our method
(dhm) handles the added noise well until 25% of the traces wer e modiﬁed. the hm
with frequency-based noise ﬁltering (method hmf) is also un affected by the injected
noise. however, it fails to discover the reference model eve n without noise, as shown
in figure 2(b). the ged of the method hmf improves after injec ting noise in 20% of
the traces because the frequency of relation cincreases by chance. when lowering the
observation frequency threshold (method hma), the injecte d noise quickly affects the
discovery and undesirable dependencies appear. we did not i nclude the im in figure 4,
as it returns models with a different structure. however, th e models returned by the im
are already undesirable for an event log with 5% noise, c.f., figure 2(a).
5.2 real-life - revealing data dependencies
we used two real-life event logs to show that our method can re veal infrequent behavior
in a practical setting. using the dhm important conditional dependencies can be found
where existing methods abstract away such dependencies.
data and methods. the road fines (rf) event log was recorded by an information
system that handles road-trafﬁc ﬁnes by an italian local pol ice force [28,29]. this event
log contains about 150,000 cases, 500,000 events, and 9 data attributes. the hospi-
tal billing (hb) event log was obtained from the erp system of a hospital. it contains
100,000 cases with 550,000 events and 38 data attributes rel ated to the billing of medical
services. we applied the proposed method (dhm), the hm with t he same frequency ﬁl-
ter settings (hmf) and the inductive miner (im) to both event logs. without a reference
model and knowledge about expected noise levels, we could no t compare the discov-
ered models to a gold standard. therefore, we compare the nov el insights obtained by
using our method with those from the other methods.①
②
③
fig. 5. process model discovered for the rf log. the numbered edges w ere added by our method.
table 2. dependency conditions discovered for the rf log.
nr source target count quality dependency used attributes
1 appeal to judge add penalty 279 0.86 0.93 amount, dismissal , points, article
2 payment add penalty 3,629 0.89 1 amount, ispaid
3 not. res. appeal to off. end 83 0.56 0.98 dismissal, expense
road fines. figure 5 shows the c-net discovered by the dhm in about 4 secon ds
for the rf log. we used the all-task-connected heuristic of the original hm, since we
know that each activity is of interest. we used eight of the at tributes including a derived
ispaid attribute since this process is about the payment of ﬁnes. we used c4.5 with
10-fold cross validation and only accepted classiﬁcations withθcon≥0.5. most of the
observed behavior (97.8%) can be replayed on the c-net using the alignment method
presented in [22]. our method reveals three additional rela tions (red edges), which are
numbered in figure 5. table 2 lists the conditional data-dep endency measure, the fre-
quency, as well as quality and used attributes of the obtaine d dependency condition for
each relation. the ﬁrst two relations target activity add penalty and both have a very
good quality score. the decision rule for relation 1mainly depends on the value of the
dismissal attribute. cases with values gdo not receive a penalty, whereas cases with
valuenil receive a penalty depending on the ﬁne amount, the number of p oints, and
the article. according to [29] this is to be expected as those cases are dismissed by the
judge. relation 2is mainly based on the attribute ispaid . unpaid ﬁnes that have with
a smallamount of less than 35 eur receive a penalty. relation 3was discovered for
cases with a dismissal value of # or g. it is to be expected that the process ﬁnishes fo r
cases with this code, since those cases are dismissed by the p refecture. interestingly, this
relation also occurs for cases with a dismissal value of nil and high postal expenses.
this should not happen, since those ﬁnes still need to be paid [29]. the dhm revealed
three data dependencies that give more insights into the rec orded behavior without ob-
structing the process model with infrequent noise. in the mo del obtained by im none
of the three relations are directly visible. therefore, cur rent decision mining techniques
would not be able to discover the conditions.①
②
③④
⑤ ⑥
fig. 6. process model discovered for the hb. the numbered edges are a dded by our method.
table 3. dependency conditions discovered for the hb log.
nr source target count quality dependency used attributes
1 fin end 3,619 0.98 1 closecode
2 release code nok 1,674 0.62 0.99 casetype
3 release billed 468 0.93 0.98 casetype
4 code nok billed 1,481 0.84 0.99 casetype, specialty
5 reopen delete 1,128 0.83 0.81 closed
6 reopen change diagn 212 0.97 0.99 closed
hospital billing. figure 6 shows the c-net discovered by the dhm in about 3 secon ds
for the hb event log. the discovered model ﬁts 97% of the obser ved behavior. we used
the new accepted-task-connected heuristic since not all of the 21 activities may be of
of interest. we discovered the model using c4.5 on a subset of 13 attributes. here, the
quality threshold is set to θcon≥0.6 and the quality is, again, determined by 10-fold
cross validation. compared to the model returned by the hmf, our method revealed
six additional dependencies. again, we numbered these rela tions in figure 6, and list
some key statistics in table 3. for the purpose of this evalua tion, we discussed the dis-
covered conditional dependencies with a domain expert from the hospital who works
in this process. relation 1is based on a special closecode that is used when nothing
can be billed and, hence, the process ends. relation 2occurs mostly for two speciﬁc
casetype values. according to the domain expert both case types corre spond to excep-
tional cases: one is used for intensive care and the other for cases for which codes cannot
be obtained ( code nok ). relation 3is, again, related to a speciﬁc casetype . this type
is used for intensive-care activities as well and, often, do es not require a code to be ob-
tained. relation 4is also mainly related to the casetype and to some degree to the
medicalspecialty . both relation 5and relation 6are conditional to the attribute
closed , which indicates whether the invoice is closed or not. clear ly, deleted cases
should not be in the closed status, whereas reopened cases wi th a change in diagnosis
can be eventually closed in the future. the process model dis covered by the dhm pro-
vides a balanced view on the interesting infrequent paths of the billing process together
with the more frequent, regular behavior. moreover, additi onal insight is provided by
revealing the conditions with which infrequent paths occur . again, the model returned
by the im did not include any of the six paths.limitations we acknowledge that there are some limitations to our method . first, we
only consider conditional directly-follows dependencies . like most process mining ap-
proaches, our method requires sufﬁciently large event logs . small event logs might, by
chance, not contain all directly-follows relations. moreo ver, more complex patterns of
conditional infrequent behavior, e.g., longer sequences o r sub-processes, cannot be dis-
covered. second, there is a risk that the returned c-nets are unsound [22] since our
method is based on the hm. however, recent research shows tha t it is possible to struc-
ture the discovered model afterwards [30]. third, as all dat a-driven method the dhm
relies on data attributes and infrequent process paths bein g recorded. last, we used only
two real-life event logs in the evaluation. therefore, only limited claims on the general
applicability of the method can be made. we have also tested t he dhm on other event
logs. however, very few event logs with data attribute are pu blicly available.
6 conclusion
we presented the data-aware heuristic miner (dhm), a process discovery method that
reveals conditional infrequent behavior from event logs. the dhm distinguishes unde-
sired noise from infrequent behavior that can be characteri zed by conditions over the
data attributes of the event log. this is the ﬁrst approach that uses both event labels and
data attributes when discovering the control-ﬂow . dependency conditions are discov-
ered using classiﬁcation techniques, and, then, embedded i n a complete process discov-
ery algorithm built upon the heuristic miner. the returned p rocess models are annotated
with information on the discovered rules. we applied the dhm to a synthetic and two
real-life events logs of considerable size and complexity. we showed that the dhm
can efﬁciently handle large event logs and is robust against typical levels of random
noise. the evaluation on two real-life cases shows that the d hm provides insights that
could be easily missed when relying on state-of-the-art, fr equency-based techniques.
in our future work, we would like to extend the idea from direc tly-follows relations
to more complex patterns of conditional behavior (e.g., lon g-term dependencies). the
dhm successfully reveals data dependencies based on direct ly-follows relations, but
dependencies that cannot be captured by directly-follows r elations might be missed.
references
1. davies, i., green, p., rosemann, m., indulska, m., gallo, s.: how do practitioners use
conceptual modeling in practice? data knowl. eng. 58(3) (2006) 358–380
2. van der aalst, w.m.p.: process mining - data science in act ion, second edition. springer
(2016)
3. weerdt, j.d., backer, m.d., vanthienen, j., baesens, b.: a multi-dimensional quality as-
sessment of state-of-the-art process discovery algorithm s using real-life event logs. inf. syst.
37(7) (2012) 654–676
4. suriadi, s., andrews, r., ter hofstede, a., wynn, m.: even t log imperfection patterns for
process mining: towards a systematic approach to cleaning e vent logs. information systems
64(2017) 132 – 150
5. van der aalst, w.m.p., weijters, t., maruster, l.: workﬂo w mining: discovering process
models from event logs. ieee trans. knowledge data eng. 16(9) (2004) 1128–11426. carmona, j., cortadella, j., kishinevsky, m.: a region-b ased algorithm for discovering petri
nets from event logs. in: bpm. v olume 5240 of lncs., springer (2008) 358–373
7. günther, c.w., van der aalst, w.m.p.: fuzzy mining - adapt ive process simpliﬁcation based
on multi-perspective metrics. in: bpm. v olume 4714 of lncs. , springer (2007) 328–343
8. weijters, a., ribeiro, j.: flexible heuristics miner (fh m). in: cidm, ieee (2011) 310–317
9. leemans, s.j.j., fahland, d., van der aalst, w.m.p.: disc overing block-structured process
models from event logs containing infrequent behaviour. in : bpm workshops. v olume 171
of lnbip., springer (2013) 66–78
10. liesaputra, v ., yongchareon, s., chaisiri, s.: efﬁcien t process model discovery using maxi-
mal pattern mining. in: bpm. v olume 9253 of lncs., springer ( 2015) 441–456
11. goedertier, s., martens, d., vanthienen, j., baesens, b .: robust process discovery with
artiﬁcial negative events. j. mach. learn. res. 10(2009) 1305–1340
12. ponce de león, h., carmona, j., vanden broucke, s.k.l.m. : incorporating negative infor-
mation in process discovery. in: bpm. v olume 9253 of lncs., s pringer (2015) 126–143
13. buijs, j.c.a.m., van dongen, b.f., van der aalst, w.m.p. : a genetic algorithm for discover-
ing process trees. in: ieee congress on evolutionary comput ation, ieee (2012) 1–8
14. rembert, a.j., omokpo, a., mazzoleni, p., goodwin, r.: p rocess discovery using prior
knowledge. in: icsoc. v olume 8274 of lncs., springer (2013) 328–342
15. bellodi, e., riguzzi, f., lamma, e.: statistical relati onal learning for workﬂow mining. intell.
data anal. 20(3) (2016) 515–541
16. ghionna, l., greco, g., guzzo, a., pontieri, l.: outlier detection techniques for process
mining applications. in: ismis. v olume 4994 of lncs., sprin ger (2008) 150–159
17. conforti, r., rosa, m.l., t. hofstede, a.h.m.: filterin g out infrequent behavior from busi-
ness process event logs. ieee trans. knowl. data eng. 29(2) (feb 2017) 300–314
18. rozinat, a., mans, r.s., song, m., van der aalst, w.m.p.: discovering simulation models.
inf. syst. 34(3) (2009) 305–327
19. de leoni, m., van der aalst, w.m.p.: data-aware process m ining: discovering decisions in
processes using alignments. in: sac’13, acm (2013) 1454–14 61
20. bazhenova, e., bülow, s., weske, m.: discovering decisi on models from event logs. in: bis.
v olume 255 of lnbip., springer (2016) 237–251
21. schönig, s., di ciccio, c., maggi, f.m., mendling, j.: di scovery of multi-perspective declar-
ative process models. in: icsoc. v olume 9936 of lncs., sprin ger (2016) 87–103
22. van der aalst, w.m.p., adriansyah, a., van dongen, b.f.: causal nets: a modeling language
tailored towards process discovery. in: concur. v olume 690 1 of lncs., springer (2011)
28–42
23. quinlan, j.r.: c4.5: programs for machine learning. mor gan kaufmann (1993)
24. cohen, j.: a coefﬁcient of agreement for nominal scales. educ. psychol. meas. 20(1) (1960)
37–46
25. ben-david, a.: about the relationship between roc curve s and cohen’s kappa. eng. appl.
artif. intell. 21(6) (2008) 874 – 882
26. vanden broucke, s.: advances in process mining: artiﬁci al negative events and othertech-
niques. phd thesis, ku leuven (2014)
27. dijkman, r.m., dumas, m., garcía-bañuelos, l.: graph ma tching algorithms for business
process model similarity search. in: bpm. v olume 5701 of lnc s., springer (2009) 48–63
28. de leoni, m., mannhardt, f.: road trafﬁc ﬁne management p rocess (2015)
doi:10.4121/uuid:270fd440-1057-4fb9-89a9-b699b47990 f5.
29. mannhardt, f., de leoni, m., reijers, h.a., van der aalst , w.m.p.: balanced multi-
perspective checking of process conformance. computing 98(4) (2016) 407–437
30. augusto, a., conforti, r., dumas, m., rosa, m.l., bruno, g.: automated discovery of
structured process models: discover structured vs. discov er and structure. in: er. v olume
9974 of lncs. (2016) 313–329