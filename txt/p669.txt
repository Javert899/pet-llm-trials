ecient discovery of understandable
declarative process models from event logs
fabrizio m. maggi, r.p. jagadeesh chandra bose, and wil m.p. van der aalst
eindhoven university of technology, the netherlands.
ff.m.maggi, j.c.b.rantham.prabhakara, w.m.p.v.d.aalst g@tue.nl
abstract. process mining techniques often reveal that real-life pro-
cesses are more variable than anticipated. although declarative process
models are more suitable for less structured processes, most discovery
techniques generate conventional procedural models. in this paper, we
focus on discovering declare models based on event logs. a declare model
is composed of temporal constraints. despite the suitability of declara-
tive process models for less structured processes, their discovery is far
from trivial. even for smaller processes there are many potential con-
straints. moreover, there may be many constraints that are trivially true
and that do not characterize the process well. naively checking all pos-
sible constraints is computationally intractable and may lead to models
with an excessive number of constraints. therefore, we have developed
an apriori algorithm to reduce the search space. moreover, we use new
metrics to prune the model. as a result, we can quickly generate under-
standable declare models for real-life event logs.
keywords: process mining, business process management, declarative
process models
1 introduction
the increasing availability of event data recorded by contemporary information
systems makes process mining a valuable instrument to improve and support
business processes [2]. starting point for process mining is an event log . each
event in a log refers to an activity (i.e., a well-dened step in some process) and
is related to a particular case (i.e., a process instance ). the events belonging to
a case are ordered and can be seen as one \run" of the process (often referred to
as a trace of events). event logs may store additional information about events
such as the resource (i.e., person or device) executing or initiating the activity,
thetimestamp of the event, or data elements recorded with the event.
typically, three types of process mining can be distinguished [2]: (a) process
discovery (learning a model from example traces in an event log), (b) confor-
mance checking (comparing the observed behavior in the event log with the
this research has been carried out as a part of the poseidon project at thales under
the responsibilities of the embedded systems institute (esi). the project is partially
supported by the dutch ministry of economic aairs under the bsik program.structured unstructuredfig. 1. procedural models for structured and unstructured processes
modeled behavior), and (c) model enhancement (extending models based on ad-
ditional information in the event logs, e.g., to highlight bottlenecks). in this
paper, we focus on process discovery which is generally considered as the most
challenging process mining task.
fig. 1 shows two example models discovered based on two dierent event
logs. the petri net on the left shows a relatively structured process that is
easy to understand. the spaghetti-like model on the right is less structured and
much more dicult to comprehend. in practice, process models are often less
structured than anticipated. therefore, one could argue that procedural models
such as the ones depicted in fig. 1 are less suitable. nevertheless, almost all
process discovery techniques [1,5,6,10,12,14,18] aim to discover procedural model
expressed in terms of bpmn, uml activity diagrams, petri nets, epcs, and the
like. in this paper, we use a dierent approach and aim to discover declarative
models from event logs.
fig. 2. declare response constraint: (a!b)
fig. 2 shows a declare model [4,13,20] consisting of only one constraint. the
arrow connecting activity atobmodels a so-called response constraint, i.e.,
activityais always followed by b. this response constraint is satised for traces
such asha;a;b;ci,hb;b;c;di, andha;b;c;a;bi, but not forha;b;a;cibecause the
secondais not followed by b. the semantics of declare constraints are rooted
in linear temporal logic (ltl), e.g., the response constraint can be formalized
as(a!b) and checked or enforced automatically.
a declare model consists of a set of constraints which, in turn, are based on
templates . a template denes a particular type of constraint (like \response").
templates have formal semantics specied through ltl formulas and are equipped
with a user-friendly graphical front-end that makes the language easy to under-
stand also for users that are not familiar with ltl [19,23]. templates are pa-
rameterized, e.g., the response constraint in fig. 2 is instantiated for activities a
2andb. hence, in a process model with nevents there are n2potential response
constraints.
in [17], the authors present a technique to automatically infer declare con-
straints. this technique exhaustively generates all possible constraints and then
checks them on the event log. this approach suers from two important draw-
backs:
{first of all, such an exhaustive approach is intractable for processes with
dozens of activities. for example, in a process with 30 activities there are
already 900 possible response constraints. some of the other templates have
four parameters, resulting in 304= 810;000 potential constraints for a sin-
gle template. since there are dozens of templates in the standard declare
language, this implies that the log needs to be traversed millions of times to
check all potential constraints. as event logs may contain thousands or even
millions of events, this is infeasible in practice.
{second, of the millions of potential constraints, many may be trivially true.
for example, the response constraint in fig. 2 holds for any event log that
does not contain events relating to activity a. moreover, one constraint may
dominate another constraint. if the stronger constraint holds (e.g., (a!
b)), then automatically the weaker constraint (e.g., a!b) also holds.
showing all constraints that hold typically results in unreadable models.
this paper addresses these two problems using a two-phase approach. in the
rst phase, we generate the list of candidate constraints by using an apriori al-
gorithm. this algorithm is inspired by the seminal apriori algorithm developed
by agrawal and srikant for mining association rules [7]. the apriori algorithm
uses the monotonicity property that all subsets of a frequent item-set are also
frequent. in the context of this paper, this means that sets of activities can only
be frequent if all of their subsets are frequent. this observation can be used to
dramatically reduce the number of interesting candidate constraints. in the sec-
ond phase, we further prune the list of candidate constraints by considering only
the ones that are relevant (based on the event log) according to (the combination
of) simple metrics, such as condence andsupport , and more sophisticated met-
rics, such as interest factor (if) and conditional-probability increment ratio
(cpir), as explained in section 4. moreover, discovered constraints with high
cpir values are emphasized like highways on a roadmap whereas constraints
with low cpir values are greyed out. this further improves the readability of
discovered declare models.
the paper is structured as follows. section 2 introduces the declare formalism
using a running example. section 3 describes how an apriori algorithm can be
applied to generate a list of candidate constraints. section 4 explains how metrics
proposed in the literature on association rule mining can be used to evaluate
the relevance of a declare constraint. section 5 presents experimental results
comparing our new discovery algorithm with the naive approach presented in
[17]. section 6 provides an illustrative case study. section 7 concludes the paper.
32 declare
in this paper, we present an approach to eciently discover understandable de-
clare models. therefore, we rst introduce the declare language [4,13,20] which
is grounded in linear temporal logic (ltl).
ltl can be used to specify constraints on the ordering of activities (see also
[11]). for instance, a constraint like \whenever activity ais executed, eventually
activity bis executed" can be formally represented using ltl and, in partic-
ular, it can be written as (a!b). in a formula like this, it is possible to
nd traditional logical operators (e.g., implication !), but also temporal oper-
ators characteristic of ltl (e.g., always , and eventually ). in general, using
the ltl language it is possible to express constraints relating activities (atoms)
through logical operators or temporal operators. the logical operators are: im-
plication (!), conjunction (^), disjunction (_), and negation ( :). the main
temporal operators are: always (p, in every future state pholds), eventually
(p, in some future state pholds), next (p, in the next state pholds), and
until (ptq,pholds until qholds).
ltl constraints are not very readable for non-experts. declare [4,13,20] pro-
vides an intuitive graphical front-end together with a formal ltl back-end. in
fig. 2 we already showed the graphical declare representation for the response
constraint. there are dozens of dierent declare constraints possible. each type
of constraint is described using a parameterized template. besides the response
constraint, we have constraints such as responded existence (formally: a!b)
and precedence (formally: (:bta)_(:b)).
2.1 running example
fig. 3 shows a simple declare model with some example constraints for an insur-
ance claim process. the model includes eight activities (depicted as rectangles,
e.g., contact hospital ) and ve constraints (shown as connectors between the
activities, e.g., co-existence ).
the responded existence constraint species that if high medical history is
executed also high insurance check is executed in the same process instance.
the precedence constraint indicates that, if receive questionnaire response is
executed, send questionnaire must be executed before. in contrast, the response
fig. 3. running example: declare model consisting of ve constraints
4constraint indicates that if create questionnaire is executed this is eventually fol-
lowed by send questionnaire . the not succession constraint means that contact
hospital cannot be followed by high insurance check . finally, the co-existence
constraint indicates that if low insurance check andlow medical history occur
in a process instance, they always coexist. we refer the reader to [4,13,20] for
more details about the declare language (graphical notation and ltl seman-
tics).
2.2 discovering relevant declare constraints using vacuity
detection
as shown in [3], ltl constraints can be checked for a particular trace and
therefore also for an entire event log. for example, one may nd that responded
existence constraint between high medical history and high insurance check
holds for 955 of 988 insurance claims. hence, declare models can be discovered
by simply checking all possible constraints as shown in [17]. first, all possible
constraints need to be constructed. since there is a nite number of constraint
templates and in a given setting there is also a nite set of activities, this is
always possible. then, the set of potential constraints can be pruned on the
basis of simple metrics such as the percentage of process instances where the
constraint holds, e.g., keep all constraints satised in at least 90% of cases.
such an approach will result in the discovery of many constraints that are
trivially valid. consider for example a process instance ha;a;b;a;b;ai. the con-
straint (c!d) (\whenever activity cis executed, eventually activity dis
executed") holds. this constraint holds trivially because cnever happens. using
the terminology introduced in [8,15], we say that the constraint is vacuously sat-
ised . in general, a formula 'isvacuously satised in a path, ifsatises'
and there is some sub-formula of 'that does not aect the truth value of 'in
[8]. in our example, the rst term of the implication (c!d) is always false.
therefore, sub-formulas dandddo not aect the truth value of (c!d) in
ha;a;b;a;b;ai.
to address this issue, in [17], the authors use techniques for ltl vacuity
detection [8,15] to discriminate between instances where a constraint is generi-
cally non-violated and instances where the constraint is non-vacuously satised.
only process instances where a constraint is non-vacuously satised are con-
sidered interesting witnesses for that constraint. roughly speaking, to ensure
that a process instance is an interesting witness for a constraint, it is necessary
to check the validity of the constraint in the process instance with some extra
conditions. the authors in [15] introduce an algorithm to compute these extra
conditions. for example, for the constraint (c!d) the condition is c. this
means that the constraint is non-vacuously satised in all the process instances
where \whenever activity cis executed, eventually activity dis executed" and
\eventually activity cis executed". the percentage of interesting witnesses for a
constraint is a much better selection mechanism than the percentage of instances
for which the constraint holds.
5in [21], the authors extend the list of vacuity detection conditions to ensure
that if a process instance is an interesting witness for a declare constraint, no
stronger constraint holds in that process instance. table 1 species the list of
vacuity detection conditions for some types of declare constraints. for instance, a
response constraint is non-vacuously satised in all the process instances where it
is satised ( (a!b)), the vacuity detection condition derived from [15] is valid
(a) and, in addition, constraints that are stronger than response (i.e., succession
and alternate response) do not hold ( :((:bta)_(:b))^:((a! (:atb)))).
in this paper, we refer to this extended notion of vacuity detection.
for completeness we also mention the approach described in [16]. this ap-
proach also learns declare models, but requires negative examples. this implies
that everything that did not happen is assumed not to be possible. we consider
this an unrealistic assumption as logs only contain example behavior.
3 apriori algorithm for declare discovery
vacuity detection can be used to prune set of constraints, but this can only be
done after generating a set of candidate constraints. as discussed in the intro-
duction, even for smaller processes, there can be millions of potential constraints.
therefore, we adopt ideas from the well-known apriori algorithm [7] for discov-
ering association rules. using an apriori-like approach we can eciently discover
frequent sets of correlated activities in an event log.
letbe the set of potential activities. let t2be a trace over , i.e.,
a sequence of activities executed for some process instance. an event log lis a
multi-set over , i.e., a trace can appear multiple times in an event log.
the support of a set of activities is a measure that assesses the relevance of
this set in an event log.
denition 1 (support). the support of an activity set ain an event log
l= [t1;t2;:::;tn]is the fraction of process instances in lthat contain all of the
activities in a, i.e.,
supp(a) =jlaj
jlj;wherela= [t2lj8 x2ax2t]
an activity set is considered to be frequent if its support is above a given thresh-
oldsuppmin. letakdenote the set of all frequent activity sets of size k2nand
letckdenote the set of all candidate activity sets of sizekthat may potentially
be frequent. the apriori algorithm uncovers all frequent activity sets in an event
log. the algorithm starts by considering activity sets of size 1 and progresses
iteratively by considering activity sets of increasing sizes in each iteration and is
based on the property that any subset of a frequent activity set must be frequent .
the set of candidate activity sets of size k+ 1,ck+1, is generated by joining
relevant frequent activity sets from ak. this set can be pruned eciently using
the property that a relevant candidate activity set of size k+ 1 cannot have an
infrequent subset. the activity sets in ck+1that have a support above a given
6table 1. vacuity detection conditions for some declare constraints
template ltl semantics vacuity detection conditions
responded existence a!b a^ :((a!b))^ :(a$b)
co-existence a$b a^b^ :((a!b)^(:bta)_(:b))
response (a!b)a^ :((:bta)_(:b))^ :((a! (:atb)))
precedence (:bta)_(:b)b^ : a^:((a!b))^
:(((:bta)_(:b))^(b! ((:bta)_(:b))))
not succession (a!:(b)) a^b
threshold suppminconstitute the frequent activity sets of size k+ 1 (ak+1) used
in the next iteration.
we explain the apriori algorithm with an example. consider an event log
l= [he;a;b;a;a;c;ei;he;a;a;b;c;ei;he;a;a;d;d;ei;hb;b;c;ci;he;a;a;c;d;ei] de-
ned over the set of activities =fa;b;c;d;eg. let us try to nd frequent
activity sets whose support is above 50%. the apriori algorithm starts by rst
considering activity sets of size 1, i.e., the individual activities. the candidate
sets inc1correspond to the singletons of the elements of . fig. 4(a) depicts the
candidate activity sets and their support. among the candidate sets, activity d
has a support of only 40% in the event log, which is below the specied threshold.
therefore, the frequent activity sets correspond to the singletons of the elements
ofnfdg. in the next iteration, the apriori algorithm considers candidate activ-
ity sets of size 2, c2. since the support of dis less than the specied threshold,
all activity sets that involve dare bound to have their support less than the
threshold. the apriori algorithm elegantly captures this by deriving candidates
at iteration k+ 1,ck+1, from frequent activity sets of iteration k. fig. 4(b) de-
picts such candidate activity sets of size 2 along with their support values. only
4 activity sets among c2satisfy the minimum support criteria and hence are
considered frequent (see a2in fig. 4(b)). proceeding further, we get only one
frequent activity set of size 3 as depicted in fig. 4(c). the algorithm terminates
after this step as no further candidates can be generated. the frequent activity
sets inlarea1[a 2[a 3.
the apriori algorithm returns frequent activity sets, which indicate that the
activities involved in an activity set are correlated. however, it doesn't specify
the type of correlation. declare templates capture dierent relationships between
activities. for instance, for any frequent activity set fa;bg, one can generate
constraints such as the response (a!b).
in general, to discover constraints deriving from a declare template with k
parameters, we have to generate frequent activity sets of size k. afterwards,
we generate the list of candidate constraints. to do that, we instantiate the
considered template by specifying as parameters all the possible permutations
of each frequent set. for instance, for the frequent activity set fa;bg, we generate
the response constraints (a!b) and (b!a).
limiting ourselves to frequent activity sets drastically reduces the number
of candidate constraints to be checked. for instance, if we take the example in
fig. 4(b), to generate the candidate constraints deriving from a template with
7candidate
activity sets
c1supp
a 80
b 60
c 80
d 40
e 80frequent
activity sets
a1supp
a 80
b 60
c 80
e 80candidate
activity sets
c2 supp
{a,b}40
{a,c}60
{a,e}80
{b,c}60
{b,e}40
{c,e}60frequent
activity sets
a2 supp
{a,c}60
{a,e}80
{b,c}60
{c,e}60candidate
activity sets
c3 supp
{a,b,c}40
{a,b,e}40
{a,c,e}60
{b,c,e}40frequent
activity sets
a3 supp
{a,c,e}60
(a) (b) (c)fig. 4. discovering frequent activity sets using the apriori algorithm in the event log
l. the support values are expressed in %
2 parameters we consider all the permutations of each frequent activity set in
a2and we generate 12 candidate constraint (we also include pairs ( a;a), (b;b),
(c;c), (e;e) by considering repetitions of elements of frequent activity sets of size
1). in contrast, with the naive approach we need to consider all the dispositions
of length 2 of 5 activities ( a;b;c;d;e ), i.e., 25 (52) candidate constraints. in gen-
eral, to discover constraints deriving from a declare template with kparameters
from a log with nactivities, the state space exploration using the naive approach
always leads to nkcandidate constraints. in contrast, applying our apriori algo-
rithm and considering only the frequent activity sets, the number of candidate
constraints depends on the support value we specify for the apriori algorithm.
this number is often signicantly lower than nkbecause we ignore the item sets
with low support.
one could also look at negative events (non-occurrence) within the apriori
setup. such information might be useful for inferring, for instance, events that
act as mutually exclusive, e.g., if aoccurs then bdoes not occur. to facilitate
this, we can also consider the negative events :a, for alla2. fig. 5 depicts the
discovery of frequent items sets considering non-occurrence of events using the
candidate
activity sets
c1supp
a 80
b 60
c 80
d 40
e 80
Â¬a20
Â¬b40
Â¬c20
Â¬d60
Â¬e20frequent
activity sets
a1supp
a 80
b 60
c 80
e 80
Â¬d60candidate
activity sets
c2 supp
{a,b} 40
{a,c} 60
{a,e} 80
{a,Â¬d}40
{b,c} 60
{b,e} 40
{b,Â¬d}60
{c,e} 60
{c,Â¬d}60
{e,Â¬d}60frequent
activity sets
a2 supp
{a,c} 60
{a,e} 80
{b,c} 60
{b,Â¬d}60
{c,e} 60
{c,Â¬d}60
{e,Â¬d}60candidate
activity sets
c3 supp
{a,b,c} 40
{a,b,e} 40
{a,c,e} 60
{a,b,Â¬d}40
{a,c,Â¬d}40
{a,e,Â¬d}40
{b,c,e} 40
{b,c,Â¬d}60
{b,e,Â¬d}40
{c,e,Â¬d}40frequent
activity sets
a3 supp
{a,c,e} 60
{b,c,Â¬d}60
(a) (b) (c)
fig. 5. discovering frequent activity sets considering negative (non-occurrence) events
using the apriori algorithm in the event log l. the support values are expressed in %
8table 2. association rule formulation for some declare constraints
template ltl semantics rule antecedent consequent
responded existence a!b ifaoccurs then boccurs a b
co-existence a$bifaoccurs then boccurs^(a_b) (a_b)ifboccurs then aoccurs
response (a!b) ifaoccurs then bfollows a b
precedence (:bta)_(:b) ifboccurs then aprecedes b a
not succession (a!:(b))ifaoccurs then bdoes not follow a b
apriori algorithm on the event log l. note that we now have additional frequent
activity sets such as fb;c;:dgsignifying that if bandcoccurs then ddoes not
occur.
4 post-processing
the set of frequent activity sets helps in reducing the preliminary set of con-
straints that one uncovers. in particular, the candidate constraints generated
from frequent sets all involve activities that occur frequently in the log. however,
this does not mean that these constraints are also frequently (non-vacuously) sat-
ised in the log. let us consider, for example, fa;eg, a frequent activity set for the
event loglmentioned earlier. one can dene various declare constraints involv-
ing these two activities, e.g., the response constraints (a!e) and (e!a).
however, only the former constraint holds for all cases in lwhereas the latter
constraint is only satised in one of the ve cases. even more, according to the
vacuity detection conditions illustrated in table 1, (a!e) is non-vacuously
satised in four cases, whereas (e!a) is never non-vacuously satised. ob-
viously, there is a need to further prune constraints that are less relevant, i.e.,
non-vacuously satised in a lower percentage of process instances than others.
we can consider a declare constraint as a rule or as a conjunction/disjunction
of rules, e.g., (a!e) can be thought of as the rule \if ais executed, then
efollows". a rule is comprised of two components, the antecedent part and the
consequent part. table 2 depicts the interpretation of declare constraints as as-
sociation rules. we can adopt various metrics proposed in the association rule
mining literature to evaluate the relevance of a rule and thereby the declare
constraints. we use four metrics, i.e., support ,condence ,interest factor , and
cpir . the latter three metrics are dened on the primitive measure of support
of the antecedent, consequent, and the rule.
denition 2 (support (of a declare constraint)). the support of a declare
constraint in an event log lis dened as the fraction of process instances in
which the constraint is non-vacuously satised, i.e., the percentage of interesting
witnesses for that constraint in the log.
denition 3 (condence). the condence of a declare constraint expressed
as an association rule in an event log lis the ratio between the support of the
9rule and the support of the antecedent
conf(rule) =supp(rule)
supp(antecedent )
for the above event log l, the support of the constraint (a!e) is 0:8 and
the condence of the constraint is 1. one can use the support and condence
metrics to prune constraints, e.g., consider only those constraints whose sup-
port is above a minimum support threshold and/or whose condence is above
a minimum condence threshold. condence measures might be misleading in
scenarios where the support of either the antecedent or the consequent is 1. on
a general note, frequent activity sets involving an activity whose support is 1
do not reect the real correlation between the activities. brin et al. [9] have
proposed a measure called interest factor to deal with such scenarios. a stronger
dependency between the antecedent and the consequent is associated with a
value of this measure that is further from 1.
denition 4 (interest factor). the interest factor of a declare constraint
expressed as an association rule in an event log lis the ratio between the support
of the rule and the product of the support of the antecedent and the consequent.
interestfactor (rule) =supp(rule)
supp(antecedent )supp(consequent )
wu et al. [22] have proposed a conditional-probability increment ratio (cpir)
measure that assesses whether two entities (in our case activities) aandbare
positively or negatively related.
denition 5 (cpir). the cpir measure of a declare constraint expressed
as an association rule in an event log lis dened as
cpir (rule) =supp(rule) supp(antecedent )supp(consequent )
supp(antecedent )(1 supp(consequent ))
cpir can be used as a measure of condence of a constraint and can be used to
mine negative constraints as well. if cpir (rule) involving the activities aand
bis greater than some threshold, then the constraint dened over aandbis
a positive constraint of interest. if cpir (rule) involving the activities aandb
is negative then aandbare negatively related or in other words aand:bare
positively related.
5 experiments and discussion
to analyze the performance of our approach, we have simulated multiple event
logs of the insurance claim example with varying numbers of cases/events.
in the rst phase of our approach, we generate a set of candidate constraints.
for a declare template with kparameters, we use the apriori algorithm to
generate frequent sets of size k. then, we generate all permutations of each
10 200 400 600 800 1000 1200 1400
 200 400 600 800 1000 1200 1400 1600 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000time (msecs)
number of permutations
number of tracesavg. time apriori
no. perm. (size 2)no. perm. (size 3)
no. perm. (size 4)(a) average computation time needed
for the generation of the frequent sets
(with support of at least 0.4) and their
permutations for varying sizes of the
event log; numbers of permutations gen-
erated for frequent sets of sizes 2, 3 and
4
 0 1000 2000 3000 4000 5000 6000 7000 8000 9000 10000
 200 400 600 800 1000 1200 1400 1600time (secs)
number of tracestotal pruning time apriori (all templates)
total pruning time traditional (all templates)(b) average computation time for
pruning needed for the pruning phase
in the naive approach and in the apri-
ori approach for varying sizes of the
event log
fig. 6. experimental results for the insurance claim process
frequent set. fig. 6(a) shows the average computation time along with the 95%
condence interval (over ve independent runs) required for this rst phase1. we
generated frequent sets of dierent sizes (2, 3 and 4) and with a support of (at
least) 0.4. we can see that the time required varies linearly with the size of the
log. fig. 6(a) also depicts the number of permutations generated. as expected,
the number of permutations is close to constant and is not signicantly inuenced
by the size of the event log. moreover, these results show that we need to generate
(on average) 126 candidate constraints to discover constraints deriving from a
declare template with 2 parameters, (on average) 1,140 candidate constraints
to discover constraints deriving from a declare template with 3 parameters, and
(on average) 8,800 candidate constraints to discover constraints deriving from a
declare template with 4 parameters. considering that the number of activities in
each of the considered logs is 15, these numbers are small compared to the naive
approach where 152(225), 153(3,375) and 154(50,625) candidate constraints
would be generated for constraints with 2, 3 and 4 parameters respectively.
in the second phase of our approach, we prune the set of candidate constraints
using the metrics described in section 4. fig. 6(b) shows the average computation
time required for pruning for the dierent event logs (with a 95% condence
interval computed over ve independent runs). we compare the time needed for
the pruning phase using the naive approach and the apriori-based approach. in
1all the computation times reported in this section are measured on a core 2 quad
cpu @2.40 ghz 3 gb ram.
11 0 200 400 600 800 1000 1200 1400
 200 400 600 800 1000 1200 1400 1600no permutations (size 2 + size 3)
number of tracessupport=40
support=50
support=60support=70
support=80
support=90(a) number of permutations generated
for varying sizes of the event log and for
dierent support values
 0 500 1000 1500 2000 2500 3000
 200 400 600 800 1000 1200 1400 1600time (secs)
number of tracessupport = 40
support = 50
support = 60support = 70
support = 80
support = 90(b) average computation time for the
pruning phase for varying sizes of the
event log and for dierent support val-
ues
fig. 7. analysis of the apriori-based approach
both cases, the time required varies linearly with respect to the size of the log.
however, the apriori-based approach clearly outperforms the naive approach.
the computation time for the apriori algorithm itself is negligible (less than
0.05% of the computation time needed for pruning).
fig. 7(a) shows the number of permutations generated for varying sizes of the
event log and for dierent support values for the apriori algorithm (again with
95% condence intervals over ve independent runs). as expected, the number of
frequent sets does not depend on the number of process instances in the log but
on the support value used by the apriori algorithm. the number of permutations
clearly increases when the support value increases. fig. 7(b) shows the average
computation time in relation to the support and number of traces. the time
required varies linearly with respect to the size of the log. however, the gradient
of the lines increases when the support increases.
the declare models obtained after pruning using the naive approach and the
approach based on the apriori algorithm are always the same but the latter is
more ecient.
table 3 shows a set of four constraints discovered from one of our synthetic
logs (with 250 process instances). these constraints have been discovered using
a minimum value for support (0.4), a minimum value for condence (0.9), and a
minimum value for cpir (0.03). it is important to highlight that all these metrics
are important when selecting relevant constraints. consider, for instance, the two
responded existence constraints in the table. both constraints have a condence
close to 1, but the responded existence between send notication by phone and
receive questionnaire response has cpir equal to 0.035, whereas the responded
existence between high medical history and high insurance check has cpir
12table 3. constraints discovered from a synthetic logs with 250 process instances
template ltl semantics parameter a parameter b support condenceinterestcpirfactor
response (a!b)contact receive0.400 0.925 1.028 0.259hospital questionnaire response
not succession (a!:(b))contact high insurance0.432 1.000 1.633 1.000hospital check
respondeda!bsend notication receive0.712 0.903 1.000 0.035existence by phone questionnaire response
respondeda!bhigh medical high insurance0.496 1.000 1.633 0.999existence history check
equal to 0.999. this is due to the fact that the existence of high medical history
is strongly related to the existence of high insurance check (the former can only
be executed if the latter has been executed), whereas in the other responded
existence constraint the connection between send notication by phone and
receive questionnaire response is less relevant.
6 case study
after showing experimental results focusing on the performance of our new ap-
proach to discover declare models, we now demonstrate its applicability using
an event log provided by a dutch municipality. the log contains events related
to requests for excerpt from the civil registration. the event log contains 3,760
cases and 19,060 events. there are 26 dierent activities.
fig. 8(a) depicts the declare model discovered using the naive approach
showing all constraints with at least 30% of interesting witnesses in the log.
the resulting spaghetti-like model has 45 constraints. the computation time to
(a) 30% of interesting witnesses
 (b) 50% of interesting witnesses
fig. 8. declare models discovered using the naive approach
13generate this model is 1,711 seconds. this model can be improved by increasing
the percentage of required interesting witnesses. fig. 8(b) depicts the resulting
declare model using the naive approach including only constraints with at least
50% of interesting witnesses. this model has 33 constraints and the computation
time needed to generate it is 1,743 seconds. note that the computational time
needed to discover the declare models in fig. 8 is approximatively the same
because in both cases 2,028 (3 262) constraints must be checked (we search for
three types of constraints with 2 parameters, i.e., precedence, response and not
succession).
fig. 9 shows the results obtained using our new approach based on the apriori
algorithm and the pruning techniques described in this paper. this model is
fig. 9. declare model discovered using the new approach. note that the most impor-
tant constraints are highlighted
14composed of 9 constraints and the computation time needed to generate it is 76
seconds. the model contains only constraints with a support greater than 0.5
and cpir value greater than 0.7.
moreover, the discovered model emphasizes the most important constraints,
just like highways are highlighted on a roadmap. constraints with a cpir value
of at least 0.85 (considered more relevant) are indicated in black, whereas the
constraints with cpir less than 0.85 (less relevant) are indicated in gray. each
constraint is annotated with support and cpir values (in red). the graphical
feedback facilitates the interpretation of the discovered declare model.
we evaluate the support of a declare constraint on the basis of the vacuity
detection conditions in table 1. these conditions guarantee that a process in-
stance is an interesting witness for a constraint if no stronger constraint holds
in the same instance. this means that if two constraints hold in the log and one
of them is stronger than the other, our approach will discover the stronger one.
7 conclusion
although real-life processes discovered through process mining are often spaghetti-
like, lion's share of process discovery algorithms try to construct a procedural
model (e.g., bpmn models, epcs, petri nets, or uml activity diagrams). the
resulting models are often dicult to interpret. therefore, it is interesting to
discover declarative process models instead.
in this paper, we present an approach to eciently discover declare mod-
els that are understandable. unlike earlier approaches we do not generate all
possible constraints and only check the most promising ones using an apriori
algorithm. this results in dramatic performance improvements. we also dened
several criteria to evaluate the relevance of a discovered constraint. the discov-
ered model is pruned using these criteria and the most interesting constraints are
highlighted. as demonstrated using a case study, this results in understandable
process models.
references
1. van der aalst, w., weijters, t., maruster, l.: workow mining: discovering process
models from event logs. knowledge and data engineering pp. 1128{1142 (2004)
2. van der aalst, w.: process mining: discovery, conformance and enhancement of
business processes. springer-verlag (2011)
3. van der aalst, w., de beer, h., van dongen, b.: process mining and verication of
properties: an approach based on temporal logic. in: coopis 2005. pp. 130{147
4. van der aalst, w., pesic, m., schonenberg, h.: declarative workows: balancing
between flexibility and support. computer science - r&d pp. 99{113 (2009)
5. van der aalst, w., reijers, h., weijters, a., van dongen, b., de medeiros, a.a.,
song, m., verbeek, h.: business process mining: an industrial application. infor-
mation systems pp. 713{732 (2007)
6. agrawal, r., gunopulos, d., leymann, f.: mining process models from workow
logs. in: edbt 1998. pp. 469{483
157. agrawal, r., srikant, r.: fast algorithms for mining association rules. in: vldb
1994. pp. 487{499
8. beer, i., eisner, c.: ecient detection of vacuity in temporal model checking. in:
formal methods in system design. pp. 200{1 (2001)
9. brin, s., motwani, r., silverstein, c.: beyond market baskets: generalizing asso-
ciation rules to correlations. in: acm sigmod 1997. pp. 265{276
10. cook, j.e., wolf, a.l.: discovering models of software processes from event-based
data. acm trans. on software engineering and methodology pp. 215{249 (1998)
11. damaggio, e., deutsch, a., hull, r., vianu, v.: automatic verication of data-
centric business processes. in: bpm. pp. 3{16 (2011)
12. datta, a.: automating the discovery of as-is business process models: proba-
bilistic and algorithmic approaches. info. systems research pp. 275{301 (1998)
13. declare (2008), http://declare.sf.net
14. g unther, c.w., van der aalst, w.: fuzzy mining: adaptive process simplication
based on multi-perspective metrics. in: bpm 2007. pp. 328{343 (2007)
15. kupferman, o., vardi, m.y.: vacuity detection in temporal model checking. in-
ternational journal on software tools for technology transfer pp. 224{233 (2003)
16. lamma, e., mello, p., montali, m., riguzzi, f., storari, s.: inducing declarative
logic-based models from labeled traces. in: bpm 2007. pp. 344{359 (2007)
17. maggi, f.m., mooij, a.j., van der aalst, w.m.p.: user-guided discovery of declar-
ative process models. in: cidm 2011
18. de medeiros, a.a., weijters, a., van de aalst, w.: genetic process mining: an ex-
perimental evaluation. data mining and knowledge discovery pp. 245{304 (2007)
19. pesic, m.: constraint-based workow management systems: shifting controls
to users. ph.d. thesis, beta research school for operations management and
logistics, eindhoven (2008)
20. pesic, m., schonenberg, h., van der aalst, w.: declare: full support for
loosely-structured processes. in: edoc 2007. pp. 287{298
21. schunselaar, d.m.m., maggi, f.m., sidorova, n.: patterns for a log-based
strengthening of declarative compliance models. in: ifm 2012 (2012), to appear
22. wu, x., zhang, c., zhang, s.: ecient mining of both positive and negative
association rules. acm transactions on information systems pp. 381{405 (2004)
23. zugal, s., pinggera, j., weber, b.: the impact of testcases on the maintainability
of declarative process models. in: bmmds/emmsad. pp. 163{177 (2011)
16