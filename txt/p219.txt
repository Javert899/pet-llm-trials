process mining: a research agenda
w.m.p. van der aalst and a.j.m.m. weijters
department of technology management, eindhoven university of technology, p.o.
box 513, nl-5600 mb, eindhoven, the netherlands.
{w.m.p.v.d.aalst,a.j.m.m.weijters }@tm.tue.nl
abstract. enterprise information systems support and control opera-
tional business processes ranging from simple internal back-oﬃce pro-
cesses to complex interorganizational processes. technologies such as
workﬂowmanagement(wfm),enterpriseapplicationintegration(eai),enterprise resource planning (erp), and web services (ws) typically
focus on the realization of it support rather than monitoring the opera-
tional business processes. process mining aims at extracting informationfrom event logs to capture the business process as it is being executed.
in this paper, we try to put the topic of process mining into context,
discuss the main issues around process mining, and ﬁnally we introducethe papers in this special issue.
key words : process mining, workﬂow mining, workﬂow management, data mining,
petri nets.
1 introduction
during the last decade explicit process concepts (e.g., workﬂow models)[2,4,
17,30,32,33,36,57] have been applied in many enterprise information systems.
these concepts are also playing a major role in cross-organizational processes,
cf. the work on web services composition languages such as bpel4ws andbpml [13,9]. workﬂow management (wfm)systems such as staﬀware, ibm
mqseries, cosa, etc. oﬀer generic modeling and enactment capabilities for
structured business processes. by making graphical process deﬁnitions, i.e., mod-els describing the life-cycle of a typical case (process instance)in isolation, one
can conﬁgure these systems to support business processes. besides pure wfm
systems many other software systems use explicit process models. consider for
example erp (enterprise resource planning)systems such as sap, peoplesoft,
baan and oracle, crm (customer relationship management)software, etc.although enterprise information systems are increasingly “process aware” and
there are generic languages and tools (e.g., wfm languages and systems), little
attention is devoted to process monitoring and improvement. note that typicallywfm systems do not provide functionality to diagnose the running workﬂow.
the strong focus on process automation and little attention to issues like
ﬂexibility and diagnosis, resulted in many failures. for example, many workﬂow
projects failed. as a result, e.g., workﬂow vendors are broadening their scope.currently, many workﬂow vendors are positioning their systems as bpm (busi-
ness process management)systems. gartner expects the bpm market to growand also identiﬁes business process analysis (bpa)as an important aspect [18].
it is expected that the bpa market will continue to grow. note that bpa covers
aspects neglected by traditional workﬂow products (e.g., diagnosis, simulation,etc.). business activity monitoring (bam)is one of the emerging areas in bpa.
the goal of bam tools is to use data logged by the information system to di-
agnose the operational processes. an example is the aris process performancemanager (ppm)of ids scheer [29]. aris ppm extracts information from audit
trails (i.e., information logged during the execution of cases)and displays this
information in a graphical way (e.g., ﬂow times, bottlenecks, utilization, etc.).the trend to focus more on bpa and bam is not limited to wfm systems. for
example, erp systems are oﬀering so-called business intelligence (bi)tools.
for example, sap states that “business intelligence integrates all your corpo-
rate information so you can turn information into insight, insight into action,
and action into improved business operations.”.
buzzwords like bpa, bam, and bi illustrate the desire to oﬀer tools to mon-
itor operational business processes. process mining can be seen as a technology
to contribute to this. the goal of process mining is to extract an explicit pro-cess model from event logs, i.e., the challenge to create a process model given
a log with events such that the model is consistent with the observed dynamic
behavior. note that this is not limited to performance data, i.e., a process ismore than its average ﬂow time. process mining also focuses on causal relations
between activities.
process mining generates a number of scientiﬁc and practical challenges (e.g.,
which processes can be discovered and how much data is needed to provide
useful information). in this paper, we discuss some of these challenges. first, we
deﬁne process mining using an example. then, we review existing literature inthis domain. section 4 highlights the main challenges. section 5 discusses the
spectrum of solution approaches. finally, section 6 brieﬂy discusses the papers
in this special issue, and section 7 concludes the paper.
2 process mining
instead of starting with a process design, process mining starts by gathering in-formation about the processes as they take place. we assume that it is possible torecord events such that we have information about the order in which the events
of a case are executed. any information system using transactional systems such
as erp, crm, b2b, scm and wfm systems will oﬀer this information in someform. note that we do not assume the presence of a wfm system. the only as-
sumption we make, is that it is possible to collect a process log with data about
the order the events take place. this process log is used to construct a processspeciﬁcation, which adequately models the behavior registered. we use the term
process mining for the method of distilling a structured process description from
a set of real executions. in recent years we have developed techniques for processmining and have evaluated these techniques in diﬀerent domains.
to illustrate the principle of process mining,case identiﬁer task identiﬁer
case 1 task a
case 2 task a
case 3 task a
case 3 task b
case 1 task b
case 1 task c
case 2 task c
case 4 task a
case 2 task b
case 2 task d
case 5 task e
case 4 task c
case 1 task d
case 3 task c
case 3 task d
case 4 task b
case 5 task f
case 4 task d
table 1. a process log.we consider the process log shown in table 1.
this log contains information about ﬁve cases
(i.e., process instances). the log shows that forfour cases (1,2,3, and 4)the tasks a, b, c, and
d have been executed. for the ﬁfth case only
two diﬀerent tasks are executed: tasks e and f.if task b is executed, then also task c is exe-
cuted. however, for some cases task c is exe-
cuted before task b. based on the informationshown in table 1 and by making some assump-
tions about the completeness of the log (i.e., as-
suming that the cases are representative and asuﬃcient large subset of possible behaviors is
observed)we can deduce for example the pro-
cess model shown in figure 1. the model is rep-
resented in terms of a petri net [46]. the petri
net can start with task a and ﬁnish with taskd. these tasks are represented by transitions.
after executing a tasks b and c are in parallel.
note that for this example we assume that twotasks are in parallel if they appear in any other.
by distinguishing between start events and end events for tasks it is possible
to explicitly detect parallelism. instead of starting with a the process can alsostart with e. task e is always followed by task f.
ab
cd
e f
fig. 1.a process model corresponding to the process log.
table 1 contains the minimal information we assume to be present. in many
applications, the process log contains a timestamp for each event and this in-
formation can be used to extract additional causality information. moreover, wealso investigate the relation between attributes of the case and the actual route
taken by a particular case. for example, when handing traﬃc violations: is themake of a car relevant for the routing of the corresponding traﬃc violations?
(e.g., people driving a ferrari always pay their ﬁnes in time.)
for this simple example, it is quite simple to construct a process model that is
able to regenerate the process log. for larger process models this is much more
diﬃcult. for example, if the model exhibits alternative and parallel routing, then
the process log will typically not contain all possible combinations. consider 10tasks which can be executed in parallel. the total number of interleavings is
10! = 3628800. it is not realistic that each interleaving is present in the log.
moreover, certain paths through the process model may have a low probabilityand therefore remain undetected. noisy data (i.e., errors in the log)can further
complicate matters. these are just some of the problems we that we need to face
in this project.
3 literature on process mining
the idea of process mining is not new [7,10–12,23–28,37–39,48–52,54–56]. cookand wolf have investigated similar issues in the context of software engineering
processes. in [10] they describe three methods for process discovery: one using
neural networks, one using a purely algorithmic approach, and one markovianapproach. the authors consider the latter two the most promising approaches.
the purely algorithmic approach builds a ﬁnite state machine where states are
fused if their futures (in terms of possible behavior in the next k steps)areidentical. the markovian approach uses a mixture of algorithmic and statisti-
cal methods and is able to deal with noise. note that the results presented in
[10] are limited to sequential behavior. related, but in a diﬀerent domain, isthe work presented in [34,35] also using a markovian approach restricted to
sequential processes. cook and wolf extend their work to concurrent processes
in [11]. they propose speciﬁc metrics (entropy, event type counts, periodicity,and causality)and use these metrics to discover models out of event streams.
however, they do not provide an approach to generate explicit process models.
in [12] cook and wolf provide a measure to quantify discrepancies between a
process model and the actual behavior as registered using event-based data. the
idea of applying process mining in the context of workﬂow management was ﬁrstintroduced in [7]. this work is based on workﬂow graphs, which are inspired by
workﬂow products such as ibm mqseries workﬂow (formerly known as flow-
mark)and inconcert. in this paper, two problems are deﬁned. the ﬁrst problemis to ﬁnd a workﬂow graph generating events appearing in a given workﬂow log.
the second problem is to ﬁnd the deﬁnitions of edge conditions. a concrete
algorithm is given for tackling the ﬁrst problem. the approach is quite diﬀer-ent from other approaches: because the nature of workﬂow graphs there is no
need to identify the nature (and or or)of joins and splits. as shown in [31],
workﬂow graphs use true and false tokens which do not allow for cyclic graphs.nevertheless, [7] partially deals with iteration by enumerating all occurrences
of a given task and then folding the graph. however, the resulting conformalgraph is not a complete model. in [39], a tool based on these algorithms is pre-
sented. schimm [48,49,52] has developed a mining tool suitable for discovering
hierarchically structured workﬂow processes. this requires all splits and joins tobe balanced. herbst and karagiannis also address the issue of process mining
in the context of workﬂow management [25,23,24,27,28,26] using an inductive
approach. the work presented in [26,28] is limited to sequential models. theapproach described in [25,23,24,27] also allows for concurrency. it uses stochas-
tic task graphs as an intermediate representation and it generates a workﬂow
model described in the adonis modeling language. in the induction step tasknodes are merged and split in order to discover the underlying process. a no-
table diﬀerence with other approaches is that the same task can appear multiple
times in the workﬂow model, i.e., the approach allows for duplicate tasks. the
graph generation technique is similar to the approach of [7,39]. the nature of
splits and joins (i.e., and or or)is discovered in the transformation step, wherethe stochastic task graph is transformed into an adonis workﬂow model with
block-structured splits and joins. in contrast to the previous papers, the follow-
ing papers are characterized by the focus on workﬂow processes with concurrentbehavior (rather than adding ad-hoc mechanisms to capture parallelism). in
[54–56] a heuristic approach using rather simple metrics is used to construct
so-called “dependency/frequency tables” and “dependency/frequency graphs”.in [37] another variant of this technique is presented using examples from the
health-care domain. the preliminary results presented in [37,54–56] only pro-
vide heuristics and focus on issues such as noise. the approach described in [6]diﬀers from these approaches in the sense that for the αalgorithm it is proven
that for certain subclasses it is possible to ﬁnd the right workﬂow model. in [3]
the emit tool is presented which uses an extended version of αalgorithm to
incorporate timing information.
process mining can be seen as a tool in the context of business (process)
intelligence (bpi). in [22,47] a bpi toolset on top of hp’s process manager isdescribed. the bpi tools set includes a so-called “bpi process mining engine”.
however, this engine does not provide any techniques as discussed before. instead
it uses generic mining tools such as sas enterprise miner for the generation of
decision trees relating attributes of cases to information about execution paths
(e.g., duration). in order to do workﬂow mining it is convenient to have a so-called “process data warehouse” to store audit trails. such as data warehouse
simpliﬁes and speeds up the queries needed to derive causal relations. in [15,
41–43] the design of such warehouse and related issues are discussed in thecontext of workﬂow logs. moreover, [43] describes the pisa tool which can be
used to extract performance metrics from workﬂow logs. similar diagnostics are
provided by the aris process performance manager (ppm)[29]. the later toolis commercially available and a customized version of ppm is the staﬀware
process monitor (spm)[53] which is tailored towards mining staﬀware logs.
note that none of the latter tools is extracting the process model. the mainfocus is on clustering and performance analysis rather than causal relations as
in [7,10–12,23–28,37–39,48–52,54–56].
more from a theoretical point of view, the rediscovery problem discussed in
this paper is related to the work discussed in [8,20,21,45]. in these papers the
limits of inductive inference are explored. for example, in [21] it is shown that
the computational problem of ﬁnding a minimum ﬁnite-state acceptor compati-
ble with given data is np-hard. several of the more generic concepts discussed
in these papers could be translated to the domain of process mining. it is pos-sible to interpret the problem described in this paper as an inductive inference
problem speciﬁed in terms of rules, a hypothesis space, examples, and criteria
for successful inference. the comparison with literature in this domain raisesinteresting questions for process mining, e.g., how to deal with negative exam-
ples (i.e., suppose that besides log wthere is a log vof traces that are not
possible, e.g., added by a domain expert). however, despite the many relationswith the work described in [8,20,21,45] there are also many diﬀerences, e.g., we
are mining at the net level rather than sequential or lower level representations
(e.g., markov chains, ﬁnite state machines, or regular expressions).
there is a long tradition of theoretical work dealing with the problem of
inferring grammars out of examples: given a number of sentences (traces)out
of a language, ﬁnd the simplest model that can generate these sentences. thereis a strong analogy with the process-mining problem: given a number of pro-
cess traces, can we ﬁnd the simplest process model that can generate these
traces. many issues important in the language-learning domain are also relevantfor process mining (i.e. learning from only positive examples, how to deal with
noise, measuring the quality of a model, etc.). however, an important diﬀer-
ence between the grammar inference domain and the process-mining domain isthe problem of concurrency in the traces: concurrency seems not relevant in the
grammar inference domain. in spite of this important diﬀerence, it seems usefully
to investigate which theoretical results, measurements, and mining techniquescan be used or updated so that they become useful in process mining. a good
overview of prominent computational approaches for learning diﬀerent classes
of formal languages is given in [44] and a special issue of the machine learningjournal about this subject [ ?].
additional related work is the seminal work on regions [16]. this work in-
vestigates which transition systems can be represented by (compact)petri nets(i.e., the so-called synthesis problem). although the setting is diﬀerent and our
notion of completeness is much weaker than knowing the transition system, there
are related problems such as duplicate transitions, etc.
for more information on existing research, we also refer to [5] for a survey.
4 challenging problems
process mining raises a number of interesting scientiﬁc questions. as indicated
in the previous section, some of these questions have been answered while others
require further research. therefore, we review the most challenging problems.4.1 mining hidden tasks
one of the basic assumptions of process mining is that each event (i.e., the
occurrence of a task for a speciﬁc case)is registered in the log. clearly, it is notpossible to ﬁnd information about tasks that are not recorded. however, given a
speciﬁc language it is possible to register that there is a so-called “hidden task”.
consider, for example, that in table 1 the events referring to task a are removed.although the log does not reveal task a it is clear that there has to be an and-
split if we assume tasks b and c to be in parallel. similarly, we can detect that
there has to be an and-join if we remove all events referring to task d fromthe log. suppose that both a and d are removed from table 1. in this case it
is still possible to automatically construct a process model similar figure 1 (see
figure 2). however, for more complicated processes it is more diﬃcult to addthese “hidden tasks”, and thus posing a interesting problem also related to issues
such as observable behavior and (branching)bisimulation [19].
b
c
e fand-split and-join
fig. 2.a process model with two hidden tasks.
4.2 mining duplicate tasks
the problem of duplicate tasks refers to the situation that one can have a process
model (e.g., a petri net)with two nodes referring to the same task. supposethat in table 1 and figure 1 task e is renamed to b (see figure 3). clearly,
the modiﬁed log could be the result of the modiﬁed process model. however, it
becomes very diﬃcult to automatically construct a process model from table 1with e renamed to b because it is not possible to distinguish the“b” in case 5
from the “b’s” in the other cases. note that the presence of duplicate tasks is
related to hidden tasks. many processes with hidden tasks but with no duplicatetasks can be modiﬁed into equivalent processes with duplicate tasks but with no
hidden tasks.
4.3 mining non-free-choice constructs
free-choice petri nets are petri nets where there are no two transitions consuming
from the same input place but where one has an input place which is not anbab
cd
f
fig. 3.a process model with duplicate tasks.
input place of the other [14]. this excludes the possibility to merge choice and
synchronization into one construct. free-choice petri nets are a well-known andwidely used subclass of petri nets. however, many processes cannot be expressed
in terms of a free-choice net. unfortunately, most of the mining techniques (also
those that are not using petri nets)assume process models corresponding to theclass of free-choice nets. non-free-choice constructs are diﬃcult to model since
they represent “controlled choices”, i.e., the choice between two tasks is not
determined inside some node in the process model but may depend on choicesmade in other parts of the process model. clearly, such non-local behavior is
diﬃcult to mine and may require many observations.
a
cd
b e
fig. 4.a process model with a non-free-choice construct.
figure 1 is free-choice since synchronization (task d)is separated from the
choice between a and e. figure 4 shows a non-free-choice construct. after exe-
cuting task c there is a choice between task d and task e. however, the choicebetween d and e is “controlled” by the earlier choice between a and b. note
that tasks d and e are involved in a choice but also synchronize two ﬂows.
clearly such constructs are diﬃcult to mine since the choice is non-local and themining algorithm has to “remember” earlier events.
4.4 mining loops
in a process it may be possible to execute the same task multiple times. if this
happens, this typically refers to a loop in the corresponding model. figure 5shows an example with a loop. after executing task b, task c can be executed
arbitrarily many times, i.e., possible event sequences are bd, bcd, bccd,bcccd, etc. loops like the one involving task c are easy to discover. however,
loops can also be used to jump back to any place in the process. for more complex
processes, mining loops is far from trivial since there are multiple occurrencesof the same task in a given case. some techniques number each occurrence, e.g.,
b1 c1 c2 c3 d1 denotes bcccd. these occurrences are then mapped onto a
single task.
a
ca
b d
fig. 5.a process model with a loop.
as illustrated by figure 5 there is a relation between loops and duplicate
tasks. in figure 5 task a is executed multiple times (i.e., twice)but is not
in a loop. many mining techniques make some assumptions about loops which
restricts the class of processes that can be mined correctly.
4.5 using time
table 1 shows the minimal information needed to conduct some form of process
mining. each line corresponds to an event (i.e., the execution of a task for a
speciﬁc case). in many cases, the log also contains time information, i.e., each
event has a timestamp . to model the duration of the execution of a task one
can log start events and end events. by comparing the diﬀerence between the
timestamp of a start event and the timestamp of the corresponding end event
it is possible the determine the processing time. the timing information can beused for two purposes: (1)adding time information to the process model and (2)
improve the quality of the discovered process model.
it is relatively easy to augment a process model with time information. an
approach is to ﬁrst mine the process model while ignoring the timestamps andthen “replay” the log in the process model. by replaying the log, it is easy
to calculate (average, variance, minimum, and maximum)ﬂow times, waiting
times, and processing times [3]. one complication may be that for some cases,the discovered process model may not ﬁt. this information may be used to
modify the process model (e.g., modify the resulting model directly, clean the
log, or add knowledge and rerun the mining algorithm).using timing information to improve the quality of the log is more involved.
for example, if two events occur within a short time interval, it is likely thatthere is some causal relation. a notion of “time distance” could be used in the
mining algorithms. however, the added value of this is not clear yet. in fact, as
far as we know, no work has been done on this.
4.6 mining diﬀerent perspectives
the dominant perspective of process mining is the so-called control-ﬂow per-
spective. the essence of this perspective is the ordering of tasks. as indicated,
the control-ﬂow perspective can be extended to include timing information (i.e.,
events have timestamps). however, in addition to the control-ﬂow perspectiveone could also consider: the organization perspective, the information perspec-
tive, and the application perspective. in the organization perspective, the organi-
zational structure and the population are speciﬁed. the organizational structuredescribes relations between roles (resource classes based on functional aspects)
and groups (resource classes based on organizational aspects), and other arti-
facts clarifying organizational issues (e.g., responsibility, availability). resources,
ranging from humans to devices, form the organizational population and are al-
located to roles and groups. the information perspective deals with control andproduction data. control data are data introduced solely for process manage-
ment purposes, e.g., variables introduced for routing purposes. production data
are information objects (e.g., documents, forms, and tables)whose existence doesnot depend on process management. the application perspective deals with the
applications being used to execute tasks (e.g., the use of a text editor).
in an event log one can ﬁnd traces of these other perspectives. an event in
the log may give information about the resource (e.g., worker)that executedthe corresponding task. this information can be used to derive knowledge about
the organization perspective (e.g., roles and groups, collaboration structures,
eﬃciency of cooperation, etc.). for example, process mining could be used to ﬁndthat cases that require the cooperation of two speciﬁc workers have signiﬁcantly
longer processing times. the log may also record the “dataﬂow”, e.g., which
process variables are updated in a given event and what are their values. such
logs could be used to derive knowledge about the information perspective. it
is particularly interesting to link the information perspective to the control-ﬂow perspective. for example, is there a correlation between the ﬂow time and
certain process variables (e.g., large orders take more time)or is there a relation
between the routing of a case and its process variables (e.g., cases of customerslocated in a speciﬁc region typically require several additional checks)? similarly,
the log could be augmented with information about the applications being used
to derive knowledge about the application perspective. thus far, most researcheﬀorts have focused on the control-ﬂow perspective. therefore, it is an interesting
challenge to include the organization perspective, the information perspective,
and/or the application perspective.4.7 dealing with noise
most mining algorithms assume the information to be correct. although this is a
valid assumption in most situations, the log may contain “noise”, i.e., incorrectly
logged information. for example, it could be that sometimes an event is notrecorded or recorded some time after it actually took place. the mining algorithm
needs to be robust with respect to noise, i.e., causal relations should not be based
on a single observation. in fact, one could argue that the mining algorithm needs
to distinguish exceptions from the “normal ﬂow”. when considering noise, one
often has to determine a threshold value to cut-oﬀ exceptional or incorrectlylogged behavior. see [37,54–56] for some heuristics to deal with noise.
4.8 dealing with incompleteness
related to the issue of noise is the notion of incompleteness. a log is incomplete if
it does not contain suﬃcient information to derive the process. consider table 1
and the derived process model shown in figure 1. suppose that figure 1 is a
correct representation of the actual process but that that the route representedby case 5 is very rare. when mining only a few cases it could be that only cases
similar to cases 1, 2, 3, and 4 are recorded. as a result, the discovered process
model is not correct because tasks e and f are missing. this example may seemtrivial, however, for real-life processes there are easily up to a million possible
paths when allowing for parallel, conditional and iterative routing. consider for
example figure 6. note that in this process there are no choices, i.e., all tasksare executed only once. however, task b and the sequence of 9 tasks c1, c2,
..., c9 are executed in parallel. as a result there are ten possible routes, i.e.,
even though there are no choices at least 10 cases are needed to derive theprocess model shown in figure 6. in fact, observations where b is executed after
the sequence of 9 tasks c1, c2, ..., c9 may be highly unlikely and perhaps
thousands of logged cases are needed to discover the correct model. if we change
the process in figure 6 such that tasks c1, c2, ..., c9 are executed in parallel,
then there are 10! = 3628800 possible routes. in this case, the log is likely tobe incomplete and heuristics are needed to tackle this problem. these heuristics
are typically based on occam’s razor, i.e., the principle that states ”when you
have two competing theories which make exactly the same predictions, the onethat is simpler is the better.”.
4.9 gathering data from heterogeneous sources
today’s enterprise information systems are incredibly complex and typically
composed of a large number of applications/components. applications typically
support fragments of a process and as a result the information required for
process mining is scattered over the enterprise information system. therefore, thestep to collect the event log used as input for process mining is far from trivial.
even within a single product, events may be logged at several levels of parts of
the system. consider for example an erp system like sap: there are dozensab
c1d
c2
c3
c9...
fig. 6.a process model where it is diﬃcult to pinpoint the synchronization.
of logs relevant for process mining. one approach is to use a data warehouse
which extract the information from these logs [15]. in [3] a tool independent
xml format is proposed to serve as input format for several tools for process
mining.
4.10 visualizing results
another challenge is to present the results of process mining in such as way that
people actually gain insight in the process. non-trivial management information
should visualized in such a way that it is easy to understand. a typical term used
in this context is “management cockpit” to emphasize the relevance of presentingthe results of process mining. existing commercial products such as aris ppm
[29] focus mainly on performance indicators such as ﬂow time, work in progress,
etc. visualizing the complete control-ﬂow perspective or the other perspectivesis more diﬃcult and requires further research.
4.11 delta analysis
process mining always results in a process model including the control-ﬂow per-
spective and, perhaps, some of the other perspectives. however, there may al-
ready be descriptive or normative models. for example, business consultantsmay have modeled the process by hand using a simple diagramming tool or even
a simulation package. moreover, the conﬁguration of a wfm system requires an
explicit process model and erp systems are conﬁgured on basis of so-called ref-erence models. given the fact that there may be descriptive or normative models
made by people, it is interesting to compare these models with the models result-
ing from process mining. delta analysis is used to compare the two models andexplain the diﬀerences. few techniques are know to detect diﬀerences and com-
monalities of process models [1,12]. both from a practical point of view and a
scientiﬁc point of view, delta analysis is interesting and deserves more attention.in this section, we identiﬁed a number of domains comprising challenging prob-
lems that remain unsolved (satisfactorily). by tackling these problems, it is pos-
sible to improve the applicability and relevance of process mining.
5 diﬀerences in mining algorithms
in the previous section (section 4), we reviewed a number of (partly) solvedand unsolved problems related to process mining. in this section we focus on
diﬀerences in mining algorithms . there is of course a strong relation between
the mining algorithm and the type of problems that can be successfully handled
by that algorithm. therefore, if we try to characterize a mining algorithm, we can
start with a enumeration of the types of problems that can be successful handled
by the algorithm at hand (e.g. dealing with noise, incomplete logs, using time,
duplicate tasks, non-free-choice constructs, loops, mining diﬀerent perspectives,visualizing the mining results, etc.).
so far it appears almost impossible to use existing data mining techniques
directly (i.e. without some modiﬁcations)for process mining (for a an excellent
overview of the key mining algorithms we refer to [40]). that means that most
of the process mining techniques have some very speciﬁc properties. in spite ofthis, process mining can be seen as a sub-domain of data mining in general.
many of the characteristics relevant for data mining algorithms appear also
relevant for process mining (e.g. the inductive bias, the local-global dimension,
computational complexity, memory requirement, etc.). below we will discuss
them in the context of process mining.
workﬂow logs can also contain information about the attributes of cases and
the actual route taken by a particular case. given a process model, traditionaldata mining techniques can be used for the mining of decision rules that predict
the routing of a speciﬁc case. for this reason the focus during process mining
is on mining the process model, not on the induction of the rules for predictingthe routing of a individual case.
most workﬂow logs only contain positive examples and, in case of noise,
perhaps even negative examples without a mark that they are negative. only
if domain specialists are involved, it is sometimes possible to generate negative
examples (this event-pattern can not appear). it seems that if a process mining
algorithm needs negative examples, the practical application of that algorithm
becomes questionable.
5.1 the inductive bias during process mining algorithm
in data mining, but also in process mining, the mining process can be seen as
searching through a large space of possible models implicitly deﬁned by the lan-guage we use to represent discovered process models. the goal of this search is
to ﬁnd the process model that best ﬁts with the data in the workﬂow log. it is
very important to realize that the choice of the process representation languagestrongly inﬂuences the mining process. examples of process model representation
languages are petri nets, block-oriented process models, and event dependencymodels. some modeling languages are stronger than other modeling languages.
for instance each block-oriented process model can easily be translated in a
petri-net, the other way around is not always possible. for that reason a petri-net is a stronger representation language than block-oriented process models. if
we know nothing about the process we try to mine, it seems attractive to use the
strongest process model representation language available. after all, the choicefor a to weak language will make it impossible to ﬁnd an appropriate model. but
the choice for the most general representation language has the negative eﬀect
that the size of the search space grows. an enlarged search space (i)makes themining technique more sensitive for noise, (ii)needs more data for successful min-
ing, and (iii)has a negative eﬀect on the computational complexity and memory
requirement . the situation is more or less comparable with the situations were
we are searching for the right regression model: if we know that we are looking
for a linear model and we are using linear regression as our modeling technique(i)a few data examples are appropriate, (ii)the approach is less sensitive for
noise, and (iii)the computing time is shorter then for the non linear case. if we
know in advance witch type of process model we are looking for and we use thisinformation during the selection of our process model representation language
we have a strong inductive bias . in practice, many process mining algorithms
have a strong inductive bias.
5.2 the local-global dimension
given the process representation languages of a process mining technique we can
look to the mining process as a search for the most appropriate process out of the
search space of candidate process models. mining algorithms can use diﬀerent
strategies to ﬁnd the most appropriate model. two extreme strategies can bedistinguished (i) local strategies primarily based on a step by step building of the
optimal process model based on very local information, and (ii) global strategies
primarily based on a one strike search for the optimal model.
example of a very local strategies are the α-algorithm as presented in [6] and
mining techniques based an markovian approach. only very local information
about binary relations between events is used.
an example of a very global search strategy is a genetic search for the optimal
process model. a genetic search starts with a population of complete processmodels. because the quality or ﬁtness of a candidate model is calculated by
comparing the process model with all traces in the workﬂow log the search
process is very global.
both approaches have their advantages and disadvantages. general speak-
ing, local strategies are less complex from a computational point of view and
the memory requirement is lower than for global strategies. however, for local
strategy there is no guarantee that the outcome of the locally optimal steps
(at the level of binary event relations)will result in a globally optimal process
model. hence, the performance of such local mining techniques can be hamperedseriously when the necessary information is not local available. for instance the
α-algorithm mentioned above can not handle the non-free choice constructs as
mentioned in section 4.3 because the choice between tasks is not determined
inside some node in the process model but may depend on choices made in other
parts of the process model. for a more global technique there is the chance thatnon-free-choice construct will be discovered.
in practical situations logs are rarely complete and/or noise free. then it
becomes important how sensitive an algorithm is for noise : can one erroneous
example completely mess up the derivation of a right model or is the algorithm
robust for noise. mostly, global strategies are more robust for noise.
in some approaches local and global strategies are combined. first a local
search approach is used. afterwards a global check is performed on the whole
model and all data in the workﬂow log. in case of some deﬁciencies the model is
automatically updated or suggestions are given on how to repair the model.
in this section, we discussed important issues that can be used for the char-
acterization of diﬀerent process mining techniques. first, we can characterizealgorithms on the basis of the type of problems that can be successfully han-
dled by it. other dimensions are the inductive bias, the global-local dimensions
and strongly related dimensions as the sensitivity for noise, the amount of dataneeded, computational complexity, and memory requirement.
6 in this special issue
in this section we brieﬂy introduce the six papers selected for this special issue on
process mining. the ﬁrst three papers describe mining systems that result more
or less in complete process models. the fourth paper focuses on the problem of
the detection of concurrent behavior in processes. the result of the mining of
the systems introduced in the last two papers is not a complete process model,but information about some global properties of the process at hand.
6.1 workﬂow mining with inwolve
in the ﬁrst paper of this special issue on process mining, joachim herbst and
dimitris karagiannis give an overview of the algorithms that were implemented
within the inwolve workﬂow mining system. inwolve solves the workﬂow min-
ing problem in two steps. in the ﬁrst step it creates a stochastic activity graph
from the example set and in the second step it transforms this stochastic graph
into a well-deﬁned workﬂow model. the presented experiments shows that in-
wolve is applicable for a wide range of workﬂow models (i.e. that the inductive
bias is low).
6.2 mining exact models of concurrent workﬂows
the paper of guido schimm presents an approach to mine exact workﬂow models
from workﬂow logs. the process model representation language is block-oriented.a process model consists of a arbitrary number of nested building blocks (i.e.
sequence ,parallel ,alternative ,a n d loop). the advantage of the use of the block-
oriented representation language is the relation with process algebra (i.e., well
deﬁned semantics, modularity, and extensibility)and the property that resulting
workﬂow models are always exact (e.g. complete, speciﬁc and minimal). thedisadvantage seems the inductive bias of the mining technique.
6.3 discovering workﬂow models from activities’ lifespans
the paper of shlomit pinter and mati golani is more or less a extension of the
work of agrawal, gunopulos, and leymann [7] with time information. two new
algorithms for synthesizing (mining)process models out of workﬂow logs (au-
dit logs)are presented. the model graph generated by each of the algorithmscaptures all the executions and dependencies that are present in the log, and
preserves existing parallelism. the algorithms presented in this paper are com-
pared with the algorithm in [7] by running them on simulated data. the authorsclaim that the new algorithm outperforms the original one in the sense that the
number of excess and absent edges in the resulting graphs is consistently smaller.
6.4 discovering models of behavior for concurrent workﬂows
the focus of the paper of jonathan cook, zhidian du, chongbing liu, and
alexander wolf is on concurrent behavior of processes. the paper presents tech-
niques to discover patterns of concurrent behavior from traces of workﬂow events.the techniques are based on a probabilistic analysis of the event traces. using
metrics for the number, frequency, and regularity of event occurrences, a deter-
mination is made of the likely concurrent behavior manifested by the system.
the focus of the last two papers in this special issue is not on the discovery
of the complete underlying process model out of a workﬂow log. the goal is to
discover more global properties of the process. for this reason, the inductive biasfor both techniques is low.
6.5 business process intelligence
the paper of fabio casati, malu castellanos, umeshwar dayal, mehmet sayal,
and ming-chien shan presents a set of integrated tools (bpi)that supports
business and it users in managing process execution quality by providing several
features, such as analysis, prediction, monitoring, control, and optimization. thetool is based on the use of more general data mining techniques to business
processes. experimental results of the use of the bpi-tool are presented in the
paper.
6.6 discovery of temporal patterns from process instances
the paper of san-yih hwang, chih-ping wei, and wan-shiou yang focuses on
the discovering frequently occurring temporal patterns and does not assume theexistence of a single process model to which all process instances comply. discov-
ery of temporal patterns seems sensible in domains with very weak structuredprocess models. health care is an example of a domain in which many of the
process models are weak structured and for this reason very diﬃcult to mine for
techniques with a strong inductive bias. in this paper the temporal pattern dis-covery problem is formally deﬁned and three diﬀerent temporal pattern discovery
algorithms are evaluated, namely tp-graph, tp-itemset and tp-sequence.
7 conclusion
this paper introduced the topic of process mining. using a number of simple
examples, we illustrated the potential of process mining but also the many scien-
tiﬁc challenges that need to be addressed. problems like hidden tasks, duplicate
tasks, non-free-choice constructs, loops, time, noise and lack of completenesslimit the practical application of process mining. this special issue provides in-
sight into the state-of-the-art on process mining at this point in time. we hope
that this will trigger new research eﬀorts to solve some of the open problems.
references
1. w.m.p. van der aalst and t. basten. identifying commonalities and diﬀerences
in object life cycles using behavioral inheritance. in j.m. colom and m. koutny,
editors, application and theory of petri nets 2001 , volume 2075 of lecture notes
in computer science , pages 32–52. springer-verlag, berlin, 2001.
2. w.m.p. van der aalst, j. desel, and a. oberweis, editors. business process man-
agement: models, techniques, and empirical studies , volume 1806 of lecture notes
in computer science . springer-verlag, berlin, 2000.
3. w.m.p. van der aalst and b.f. van dongen. discovering workﬂow performance
modelsfromtimedlogs. iny.han,s.tai,andd.wikarski,editors, international
conference on engineering and deployment of cooperative information systems
(edcis 2002) , volume 2480 of lecture notes in computer science , pages 45–63.
springer-verlag, berlin, 2002.
4. w.m.p.vanderaalstandk.m.vanhee. workﬂow management: models, methods,
and systems . mit press, cambridge, ma, 2002.
5. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , pages ??–??, 2003.
6. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining:
which processes can be rediscovered? beta working paper series, wp 74,eindhoven university of technology, eindhoven, 2002.
7. r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
ﬂow logs. in sixth international conference on extending database technology ,
pages 469–483, 1998.
8. d. angluin and c.h. smith. inductive inference: theory and methods. computing
surveys, 15(3):237–269, 1983.
9. a. arkin et al. business process modeling language (bpml), version 1.0, 2002.10. j.e. cook and a.l. wolf. discovering models of software processes from event-
based data. acm transactions on software engineering and methodology ,
7(3):215–249, 1998.
11. j.e. cook and a.l. wolf. event-based detection of concurrency. in proceedings
of the sixth international symposium on the foundations of software engineering(fse-6), pages 35–45, 1998.
12. j.e. cook and a.l. wolf. software process validation: quantitatively measuring
the correspondence of a process to a model. acm transactions on software
engineering and methodology , 8(2):147–176, 1999.
13. f. curbera, y. goland, j. klein, f. leymann, d. roller, s. thatte, and s. weer-
awarana. business process execution language for web services, version 1.0.
standards propsal by bea systems, international business machines corporation,
and microsoft corporation, 2002.
14. j. desel and j. esparza. free choice petri nets , volume 40 of cambridge tracts
in theoretical computer science . cambridge university press, cambridge, uk,
1995.
15. j. eder, g.e. olivotto, and wolfgang gruber. a data warehouse for workﬂow
logs. in y. han, s. tai, and d. wikarski, editors, international conference on
engineering and deployment of cooperative information systems (edcis 2002) ,
volume 2480 of lecture notes in computer science , pages 1–15. springer-verlag,
berlin, 2002.
16. a. ehrenfeucht and g. rozenberg. partial (set) 2-structures - part 1 and part 2.
acta informatica , 27(4):315–368, 1989.
17. l. fischer, editor. workﬂow handbook 2001, workﬂow management coalition .
future strategies, lighthouse point, florida, 2001.
18. gartner. gartner’s application development and maintenance re-
search note m-16-8153, the bpa market cathes another major updraft.
http://www.gartner.com, 2002.
19. r.j. van glabbeek and w.p. weijland. branching time and abstraction in bisim-
ulation semantics. journal of the acm , 43(3):555–600, 1996.
20. e.m. gold. language identﬁcation in the limit. information and control ,
10(5):447–474, 1967.
21. e.m.gold. complexityofautomatonidentiﬁcationfromgivendata. information
and control , 37(3):302–320, 1978.
22. d. grigori, f. casati, u. dayal, and m.c. shan. improving business process qual-
ity through exception understanding, prediction, and prevention. in p. apers,
p. atzeni, s. ceri, s. paraboschi, k. ramamohanarao, and r. snodgrass, ed-
itors, proceedings of 27th international conference on very large data bases
(vldb’01) , pages 159–168. morgan kaufmann, 2001.
23. j.herbst. amachinelearningapproachtoworkﬂowmanagement. in proceedings
11th european conference on machine learning , volume 1810 of lecture notes in
computer science , pages 183–194. springer-verlag, berlin, 2000.
24. j. herbst. dealing with concurrency in workﬂow induction. in u. baake, r. zo-
bel, and m. al-akaidi, editors, european concurrent engineering conference .s c s
europe, 2000.
25. j. herbst. ein induktiver ansatz zur akquisition und adaption von workﬂow-
modellen . phd thesis, universit¨ at ulm, november 2001.
26. j. herbst and d. karagiannis. integrating machine learning and workﬂow man-
agement to support acquisition and adaptation of workﬂow models. in pro-
ceedings of the ninth international workshop on database and expert systems
applications , pages 745–752. ieee, 1998.27. j. herbst and d. karagiannis. an inductive approach to the acquisition and
adaptation of workﬂow models. in m. ibrahim and b. drabble, editors, proceed-
ings of the ijcai’99 workshop on intelligent workﬂow and process management:the new frontier for ai in business , pages 52–57, stockholm, sweden, august
1999.
28. j. herbst and d. karagiannis. integrating machine learning and workﬂow man-
agementtosupportacquisitionandadaptationofworkﬂowmodels. international
journal of intelligent systems in accounting, finance and management , 9:67–92,
2000.
29. ids scheer. aris process performance manager (aris ppm). http://www.ids-
scheer.com, 2002.
30. s. jablonski and c. bussler. workﬂow management: modeling concepts, architec-
ture, and implementation . international thomson computer press, london, uk,
1996.
31. b. kiepuszewski. expressiveness and suitability of languages for con-
trol flow modelling in workﬂows (submitted) . phd thesis, queens-
land university of technology, brisbane, australia, 2002. available via
http://www.tm.tue.nl/it/research/patterns.
32. p. lawrence, editor. workﬂow handbook 1997, workﬂow management coalition .
john wiley and sons, new york, 1997.
33. f. leymann and d. roller. production workﬂow: concepts and techniques .
prentice-hall ptr, upper saddle river, new jersey, usa, 1999.
34. h. mannila and d. rusakov. decomposing event sequences into independent
components. in v. kumar and r. grossman, editors, proceedings of the first
siam conference on data mining , pages 1–17. siam, 2001.
35. h. mannila, h. toivonen, and a.i. verkamo. discovery of frequent episodes in
event sequences. data mining and knowledge discovery , 1(3):259–289, 1997.
36. d.c. marinescu. internet-based workﬂow management: towads a semantic
web,v o l u m e4 0o f wiley series on parallel and distributed computing . wiley-
interscience, new york, 2002.
37. l. maruster, w.m.p. van der aalst, a.j.m.m. weijters, a. van den bosch, and
w. daelemans. automated discovery of workﬂow models from hospital data. in
b. kr¨o s e ,m .d er i j k e ,g .s c h r e i b e r ,a n dm .v a ns o m e r e n ,e d i t o r s , proceedings of
the 13th belgium-netherlands conference on artiﬁcial intelligence (bnaic 2001) ,
pages 183–190, 2001.
38. l. maruster, a.j.m.m. weijters, w.m.p. van der aalst, and a. van den bosch.
process mining: discovering direct successors in process logs. in proceedings of
the 5th international conference on discovery science (discovery science 2002) ,
volume 2534 of lecture notes in artiﬁcial intelligence , pages 364–373. springer-
verlag, berlin, 2002.
39. m.k. maxeiner, k. k¨ uspert, and f. leymann. data mining von workﬂow-
protokollen zur teilautomatisierten konstruktion von prozemodellen. in proceed-
ings of datenbanksysteme in b¨ uro, technik und wissenschaft , pages 75–84. infor-
matik aktuell springer, berlin, germany, 2001.
40. t.m. mitchell. machine learning . mcgraw-hill, new york, 1997.
41. m. zur m¨ uhlen. process-driven management information systems combining
data warehouses and workﬂow technology. in b. gavish, editor, proceedings of
the international conference on electronic commerce research (icecr-4) ,p a g e s
550–566. ieee computer society press, los alamitos, california, 2001.42. m. zur m¨ uhlen. workﬂow-based process controlling-or: what you can mea-
sure you can control. in l. fischer, editor, workﬂow handbook 2001, workﬂow
management coalition , pages 61–77. future strategies, lighthouse point, florida,
2001.
43. m. zur m¨ uhlen and m. rosemann. workﬂow-based process monitoring and con-
trolling - technical and organizational issues. in r. sprague, editor, proceedings
of the 33rd hawaii international conference on system science (hicss-33) , pages
1–10. ieee computer society press, los alamitos, california, 2000.
44. r. parekh and v. honavar. automata induction, grammar inference, and lan-
guage acquisition. in dale, moisl, and somers, editors, handbook of natural lan-
guage processing . new york: marcel dekker, 2000.
45. l. pitt. inductive inference, dfas, and computational complexity. in k.p. jan-
tke, editor, proceedings of international workshop on analogical and inductive
inference (aii) , volume 397 of lecture notes in computer science , pages 18–44.
springer-verlag, berlin, 1889.
46. w. reisig and g. rozenberg, editors. lectures on petri nets i: basic models ,
volume 1491 of lecture notes in computer science . springer-verlag, berlin, 1998.
47. m. sayal, f. casati, and m.c. shan u. dayal. business process cockpit. in pro-
ceedings of 28th international conference on very large data bases (vldb’02) ,
pages 880–883. morgan kaufmann, 2002.
48. g. schimm. process mining. http://www.processmining.de/.49. g.schimm. genericlinearbusinessprocessmodeling. ins.w.liddle,h.c.mayr,
and b. thalheim, editors, proceedings of the er 2000 workshop on conceptual
approaches for e-business and the world wide web and conceptual modeling ,
volume 1921 of lecture notes in computer science , pages 31–39. springer-verlag,
berlin, 2000.
50. g. schimm. process mining elektronischer gesch¨ aftsprozesse. in proceedings e lek-
tronische gesch¨ aftsprozesse , 2001.
51. g. schimm. process mining linearer prozessmodelle - ein ansatz zur automa-
tisierten akquisition von prozesswissen. in proceedings 1. konferenz profes-
sionelles wissensmanagement , 2001.
52. g. schimm. process miner - a tool for mining process schemes from event-
based data. in s. flesca and g. ianni, editors, proceedings of the 8th european
conference on artiﬁcial intelligence (jelia) ,v o l u m e2 4 2 4o f lecture notes in
computer science , pages 525–528. springer-verlag, berlin, 2002.
53. staﬀware. staﬀware process monitor (spm). http://www.staﬀware.com, 2002.
54. a.j.m.m. weijters and w.m.p. van der aalst. process mining: discovering work-
ﬂow models from event-based data. in b. kr¨ ose, m. de rijke, g. schreiber, and
m. van someren, editors, proceedings of the 13th b elgium-netherlands conference
on artiﬁcial intelligence (bnaic 2001) , pages 283–290, 2001.
55. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models
from event-based data. in v. hoste and g. de pauw, editors, proceedings of
the 11th dutch-belgian conference on machine learning (benelearn 2001) , pages
93–100, 2001.
56. a.j.m.m. weijters and w.m.p. van der aalst. workﬂow mining: discovering
workﬂow models from event-based data. in c. dousson, f. h¨ oppner, and
r. quiniou, editors, proceedings of the ecai workshop on knowledge discovery
and spatial data , pages 78–84, 2002.
57. wfmc. workﬂow management coalition workﬂow standard: workﬂow pro-
cess deﬁnition interface – xml process deﬁnition language (xpdl) (wfmc-tc-1025). technical report, workﬂow management coalition, lighthouse point,
florida, usa, 2002.about the authors
wil van der aalst is a full professor of information systems and head of
the section of information and technology of the department of technologymanagement at eindhoven university of technology. he is also a part-time full
professor at the computing science faculty at the department of mathematics
and computer science at the same university and an adjoint professor at thecentre for technology innovation (citi)of queensland university of technology
(qut). his research interests include information systems, simulation, petri
nets, process models, workﬂow management systems, veriﬁcation techniques,enterprise resource planning systems, computer supported cooperative work, and
interorganizational business processes.
ton weijters is associate professor at the department of technology manage-
ment of the eindhoven university of technology (tue), and member of thebeta research group. currently he is working on (i)the application of knowl-
edge engineering and machine learning techniques for planning, scheduling, and
process mining (ii)fundamental research in the domain of machine learning andknowledge discovering. he is the author of many scientiﬁc publications in the
mentioned research ﬁeld.