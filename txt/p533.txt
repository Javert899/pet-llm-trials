workow simulation for
operational decision support
a. rozinat1, m. t. wynn2, w. m. p. van der aalst1;2, a. h. m. ter hofstede2,
and c. j. fidge2
1information systems group, eindhoven university of technology,
p.o. box 513, nl-5600 mb, eindhoven, the netherlands.
fa.rozinat,w.m.p.v.d.aalst g@tue.nl
2business process management group, queensland university of technology,
gpo box 2434, brisbane qld 4001, australia.
fm.wynn,a.terhofstede,c.fidge g@qut.edu.au
abstract. simulation is widely used as a tool for analyzing business
processes but is mostly focused on examining abstract steady-state sit-
uations. such analyses are helpful for the initial design of a business
process but are less suitable for operational decision making and contin-
uous improvement. here we describe a simulation system for operational
decision support in the context of workow management. to do this we
exploit not only the workow's design , but also use logged data describ-
ing the system's observed historic behavior, and incorporate information
extracted about the current state of the workow. making use of actual
data capturing the current state and historic information allows our sim-
ulations to accurately predict potential near-future behaviors for dier-
ent scenarios. the approach is supported by a practical toolset which
combines and extends the workow management system yawl and the
process mining framework prom.
1 introduction
business process simulation is a powerful tool for process analysis and improve-
ment. one of the main challenges is to create simulation models that accurately
reect the real-world process of interest. moreover, we do not want to use simu-
lation just for answering strategic questions but also for tactical and even oper-
ational decision making. to achieve this, dierent sources of simulation-relevant
information need to be leveraged. in this paper, we present a new way of creating
a simulation model for a business process supported by a workow management
system, in which we integrate design, historic, and state information.
figure 1 illustrates our approach. we consider the setting of a workow
system that supports some real-world process based on a workow and orga-
nizational model . note that the workow and organizational models have been
designed before enactment and are used for the conguration of the workow sys-
tem. during the enactment of the process, the performed activities are recorded
inevent logs . an event log records events related to the oering, start, andworkflow & 
organizational
modelevent
logs
workflow
system
recordssupports /
controls
current state informationmodels
simulation
modelspecifies 
configures
simulation 
logs
simulationengine
recordssimulates
models
historic informationdesign information
analyzesimulated process real-world process
specifies 
configuresfig. 1. overview of our integrated workow management (right) and simulation (left)
system
completion of work items, e.g., an event may be `mary completes the approval
activity for insurance claim xy160598 at 16.05 on monday 21-1-2008'.
the right-hand side of figure 1 is concerned with enactment using a workow
system while the left-hand side focuses on analysis using simulation. in order to
link enactment and simulation we use three types of information readily available
in workow systems to create and initialize the simulation model.
{design information. the workow system has been congured based on an
explicit process model describing control and data ows. moreover, the work-
ow system uses organizational data, e.g., information about users, roles,
groups, etc.
{historic information. the workow system records all events that take place
in `event logs' from which the complete history of the process can be recon-
structed. by analyzing historic data, probability distributions for workow
events and their timing can be extracted.
{state information. at any point in time, the workow process is in a partic-
ular state. the current state of each process instance is known and can be
used to initialize the simulation model. note that this current state informa-
tion includes the control-ow state (i.e., `tokens' in the process model), case
data, and resource data (e.g., resource availability).
by merging the above information into a simulation model, it is possible to
construct an accurate model based on observed behavior rather than a manually-
constructed model which approximates the workow's anticipated behavior.
moreover, the state information supports a `fast forward' capability, in which
simulation can be used to explore dierent scenarios with respect to their eect
2in the near future . in this way, simulation can be used for operational decision
making .
based on this approach, the system design in figure 1 allows dierent simu-
lation experiments to be conducted. for the `as-is' situation, the simulated and
real-world processes should overlap as much as possible, i.e., the two process
`clouds' in figure 1 need to coincide. for the `to-be' situation, the observed dif-
ferences between the simulated and real-world processes can be explored and
quantied. in our implementation we ensure that the simulation logs have the
same format as the event logs recorded by the workow system. in this way we
can use the same tools to analyze both simulated and real-world processes.
to do this, we need state-of-the art process mining techniques to analyze the
simulation and event logs and to generate the simulation model. to demonstrate
the applicability of our approach, we have implemented the system shown in
figure 1 using prom [1] and yawl [2]. yawl is a workow management system
that, as reported in this paper, has been extended to provide high-quality design,
historic, and state information. the process mining framework prom has been
extended to merge the three types of information into a single simulation model.
moreover, prom is also used to analyze and compare the logs in various ways.
in [3] three common pitfalls in current simulation approaches were presented.
1.modeling from scratch rather than using existing artifacts , which leads to
mistakes and unnecessary work,
2.focus on design rather than operational decision making , which is helpful
for the initial design of a business process but less suitable for operational
decision making and continuous improvement,
3.insucient modeling of resources , i.e., the behavior or resources is typically
modeled in a rather na ve manner.
this paper addresses the rst two pitfalls. while addressing the third problem
is a challenging research topic in itself [3], we concentrate here on the rst two
problems. that is, we integrate existing artifacts that can be extracted from a
workow system into a ready-to-use simulation model, and we incorporate the
current state of the workow system in our simulation model to enable short-
term simulation.
this paper extends our previous work [20], in that we go into more detail
about the architecture of the realized system, describe the generated simulation
models and how they can load a specied initial state more closely, and present
a new xml le format for workow states that enables other workow systems
to interface with our tools in a standardized way.
the paper is organized as follows. related work is reviewed in section 2.
section 3 describes the approach proposed. section 4 presents a running ex-
ample, which is then used in section 5 to explain the implementation realized
using yawl and prom. section 6 describes our approach to incorporate state
information in more detail and presents the new xml le format for workow
states. section 7 concludes the paper by discussing the three main innovations
presented in this paper.
32 related work
our work combines aspects of workow management, simulation, and process
mining. some of the most relevant contributions from these broad areas are
reviewed below.
prominent literature on workow management [7, 14, 22] focuses on enact-
ment, and research on workow analysis usually focuses on verication, rather
than simulation. conversely, publications on simulation typically concentrate on
statistical aspects [12, 17, 13] or on a specic simulation language [11]. several
authors have used simulation or queuing techniques to address business process
redesign questions [5, 6, 15], and most mature workow management systems
provide a simulation component [8, 9]. however, none of these systems uses his-
toric and state information to learn from the past and to enable operational
decision making. we are not aware of any toolset that is able to extract the
current state from an operational workow management system and use this as
the starting point for transient analysis.
in earlier work we rst introduced the notion of using historic and state in-
formation to construct and calibrate simulation models [16, 23], and used protos,
exspect, and cosa to realize the concept of short-term simulation [16]. how-
ever, this research did not produce a practical publicly available implementation
and did not use process mining techniques.
process mining aims at the analysis of event logs [4]. it is typically used to
construct a static model that is presented to the user to reect on the process.
previously we showed that process mining can be used to generate simulation
models [19, 18], but design and state information were not used in that work.
3 approach
a crucial element of the approach in figure 1 is that the design ,historic and
state information provided by the workow system are used as the basis for
simulation. table 1 describes this information in more detail.
the design information is static, i.e., this is the specication of the process
and supporting organization that is provided at design time. this information
is used to create the structure of the simulation model. the historic and state
information are dynamic, i.e., each event adds to the history of the process
and changes the current state. historic information is aggregated and is used
to set parameters in the simulation model. for instance, the arrival rate and
processing times are derived by aggregating historic data, e.g., the (weighted)
average over the last 100 cases is used to t a probability distribution. typically,
these simulation parameters are not very sensitive to individual changes. for
example, the average processing time typically changes only gradually over a
long period. the current state, however, is highly sensitive to change. individual
events directly inuence the current state and must be directly incorporated into
the initial state of the simulation. therefore, design information can be treated
as static, while historic information evolves gradually, and state information is
highly dynamic.
4table 1. process characteristics and the data sources from which they are obtained
design information historic information state information
(obtained from the workow
and organization model
used to congure the
workow system)(extracted from event logs
containing information on
the actual execution of
cases)(based on information
about cases currently being
enacted using the workow
system)
control and data ow
(activities and causalities)data value range
distributionsprogress state of cases
(state markers)
organizational model
(roles, resources, etc.)execution time
distributionsdata values for running
cases
initial data values case arrival rate busy resources
roles per task availability patterns of
resourcesrun times for cases
to realize the approach illustrated in figure 1 we need to merge design,
historic and state information into a single simulation model. the design infor-
mation is used to construct the structure of the simulation model. the historic
information is used to set parameters of the model (e.g., t distributions). the
state information is used to initialize the simulation model. following this, tra-
ditional simulation techniques can be used. for example, using a random value
generator and replication, an arbitrary number of independent simulation exper-
iments can be conducted. then statistical methods can be employed to estimate
dierent performance indicators and compute condence intervals for these es-
timates.
by modifying the simulation model, various `what-if' scenarios can be investi-
gated. for example, one can add or remove resources, skip activities, etc. and see
what the eect is. because the simulation experiments for these scenarios start
from the current state of the actual system, they provide a kind of `fast-forward
button' showing what will happen in the near future, to support operational de-
cision making. for instance, based on the predicted system behavior, a manager
may decide to hire more personnel or stop accepting new cases.
importantly, the simulations yield simulation logs in the same format as the
event logs. this allows process mining techniques to be used to view the real-
world processes and the simulated processes in a unied way . moreover, both can
be compared to highlight deviations, etc.
4 running example
to illustrate the approach let us consider a credit card application process. the
corresponding yawl workow model is shown in figure 2. the process starts
when an applicant submits an application. upon receiving an application, a
credit clerk checks whether it is complete. if not, the clerk requests additional
information and waits until this information is received before proceeding. for
a complete application, the clerk performs further checks to validate the appli-
cant's income and credit history. dierent checks are performed depending on
5whether the requested loan is large (e.g., greater than $500) or small. the val-
idated application is then passed on to a manager to decide whether to accept
or reject the application. in the case of acceptance, the applicant is notied of
the decision and a credit card is produced and delivered to the applicant. for
a rejected application, the applicant is notied of the decision and the process
ends.
fig. 2. a credit application process modeled in yawl
here we assume that this example workow has been running for a while. in
yawl but also any other workow system the following runtime statistics can
be gathered about the long-term behavior of this process.
{ case arrival rate: 100 applications per week
{ throughput time: 4 working days on average
with respect to resources, there are eight members of sta available, which
include three capable of acting as `managers' and seven capable of acting as
`clerks'. (one person can have more than one role.)
further assume that due to a successful christmas promotion advertised in
november, the number of credit card applications per week has temporarily
doubled to 200. the promotion period is now over and we expect the rate to
decrease to 100 applications per week again. however, as a result of the increased
interest, the system now has a backlog of 150 applications in various stages of
processing, some of which have been in the system for more than a week. since
it is essential that most applications are processed before the holiday season,
which begins in a fortnight from now (the `time horizon' of interest), manage-
ment would like to perform simulation experiments from the current state (`fast
forward') to determine whether or not the backlog can be cleared in time.
5 realization through yawl and prom
we now use the example introduced in section 4 to describe our proof-of-concept
implementation supporting the approach depicted in figure 1. the realization is
based on the yawl workow environment [2] and the process mining framework
prom [1]. for the actual simulation we use cpn tools [10].
6in this section, we rst provide an overview about how yawl, prom and
cpn tools have been integrated to realize our approach (section 5.1). then we
focus on the new capabilities that have been added to these systems, and briey
explain the main steps that need to be performed to extract simulation-relevant
information from yawl (section 5.2), create a simulation model based on this
data in prom (section 5.3), load an initial state into this simulation model
(section 5.4), and to analyze the simulation runs (section 5.5). the concrete
structure of the simulation models and how they incorporate the current state
are described in more detail in section 6.
5.1 architecture
consider figure 3, which provides an overview of the tools and data sources that
are involved in the realization of our approach.
prom  yawlworkflowspecorgmodelworkflowlogimportyawl 2.0
simu-lationmodelcpntools
initialstateimportorgmodelanalyselog exportcpn
designhistoricstatetype of simulation-relevantinformationmxmlÔ¨Ålessimu-lationlogsmxmlÔ¨ÅlesgnuplotscriptsmxmlÔ¨Ålesotherlogsmergeconvert
import / exportwfstate 
workflowstatemxmlwfstatemxmlorgmodelcpnsmlyawl 2.0figure 5 
fig. 3. overall architecture of the realized system (the dotted area is shown in more
detail in figure 5)
the yawl system enacts the business process and provides design informa-
tion (yawl's workow specication and organizational model), historic infor-
mation (workow log le in mxml format), and state information (workow
state in our newly dened wfstate format). the design and historic informa-
tion are used to create and congure the simulation model, which is output as
a coloured petri net (cpn) le. the generated cpn le is accompanied by an
sml le (a cpn input le), which represents the (empty) initial state. this ini-
tial state can be repeatedly replaced by the actual current workow state without
7changing the simulation model. finally, cpn tools generates various output les
from a simulation run. among these simulation logs are mxml les, which can
be loaded in prom and analyzed in the same way as the actual workow logs.
a detailed step-by-step description of how to generate a simulation model
including operational decision support is provided in our technical report [21]3.
note that through the use of standardized interfaces|the orgmodel format
for organizational models, mxml for event logs, and the newly dened wfstate
format presented in this paper|it is very easy to extend our toolset for other
environments (e.g., yawl can be replaced by another workow management
system). to apply our approach to another type of workow system, the same
le formats can be used and only an import facility for the new type of workow
specication (plus potentially a conversion of the new type of process model into
a petri net) needs to be provided.
5.2 extracting simulation-relevant information
as illustrated in figure 3, the information contained in the yawl workow
specication is supplemented with historical data obtained from the event logs
and data from the organizational model database. this was achieved by imple-
menting two new functions in the workow engine to export historical data from
the logs for a particular specication and to export the organizational model
(i.e., information about roles and resources). furthermore, the current workow
state can be exported, which is not used to create the simulation model, but
loaded afterwards to initialize the simulation model.
in the yawl workow system, event logs are created whenever an activity
is enabled, started, completed or cancelled, together with the time when this
event occurred and with the actor who was involved. logs are also kept for data
values that have been entered and used throughout the system. therefore, we
can retrieve historical data about process instances that have nished execution.
in this work we assume that the simulation experiments are being carried out on
`as-is' process models for which historical data is available. a function has been
created which extracts the historical data for a specication from the workow
engine and exports audit trail entries in the mining xml (mxml) log format.
some sample data for the credit application example is shown in figure 4(a).
this historical data is used for mining information about case arrival rates and
distribution functions for the data values used in future simulation experiments.
similarly, the yawl workow system gives access to the organizational
model through a function which extracts all available role and resource data
in an organization and exports this information in the orgmodel xml format
that is used by prom. some sample data with the roles of clerk and manager
is shown in figure 4(b). this information is used to identify available roles and
resources that are relevant for a given specication.
3the prom framework (including source code and documentation) can be down-
loaded from prom.sf.net and the example les for our tutorial are available at
prom.win.tue.nl/research/wiki/yawltutorial (via www.processmining.org ).
8<process>
       <processinstance id="5">              <audittrailentry>                  <data>
                      <attribute name="loanamt">550</attribute>
                  </data>                  <workflowmodelelement>
              receive_application_3
                  </workflowmodelelement>                  <eventtype>complete</eventtype>                  <timestamp>
              2008-02-29t15:20:01.050+01:00
                  </timestamp>                  <originator>moew</originator>
              </audittrailentry>
...
       </processinstance>
...
</process>(a) a log entry for the completion of ac-
tivity `receive application' carried out by
resource moew with loan amount $550
<orgmodel>       
       <orgentity>      <entityid>1</entityid>       <entityname>manager</entityname> 
      <entitytype>role</entitytype> 
       </orgentity>       <orgentity>      <entityid>2</entityid>       <entityname>clerk</entityname>       <entitytype>role</entitytype>        </orgentity>    ...       <resource>    <resourceid>pa-529f00b8-0339</resourceid> 
      <resourcename>jonesa</resourcename> 
      <hasentity>2</hasentity>        </resource>
...
</orgmodel>(b) an excerpt from an organizational
model with roles and resources, where re-
source jonesa has role `clerk'
fig. 4. part of the historical data (a) and organizational model (b) extracted from the
workow engine
finally, a function has been created to extract the current workow state
from yawl in the wfstate xml format, which we introduce and explain in
more detail later in this paper.
5.3 generating the simulation model
from (1) the extracted workow specication, (2) the newly extracted organi-
zational model, and (3) the event log le, we can now generate a simulation
model that reects the process as it is currently enacted. the direct use of de-
sign information avoids mistakes that are likely to be introduced when models
are constructed manually, and the automated extraction of data from event logs
allows the calibration of the model based on actually observed parameters.
to capture simulation-relevant information independently of a concrete work-
ow language (e.g., yawl) we created a generic data structure in prom that we
call \high-level process". with high-level information we refer to process infor-
mation beyond the pure control ow, i.e., additional information like data and
time that can be either attached to the process as a whole, or to certain elements
in the process. figure 5 shows the data structures that are produced by each
step in the simulation model creation process. extra information that is attached
to activities or choice points in the process is visualized as clouds, while global
process information is listed textually at the bottom of each high-level struc-
ture. because this extra information is orthogonal to the actual control-ow, it
is separated and dierent types of process models can be enriched with high-level
information. currently, petri nets, yawl and protos models can be enriched
with simulation-relevant information, and there are several plug-ins that either
9 yawl 2.0import
mergeorgmodel import+ roles and their corresponding resources in the whole organization
log analysisabc+ time+ case arrival rate+ data attributes    (value range) + time+ timecpnexportconvert
+ case arrival rate+ data attributes (inital    value and value range)+ roles and resources per roleabc............+ case arrival rate+ data attributes (inital    value and value range)+ roles and resources per rolemanagerceoclerkfredlisajoe...sarah+ data attributes    (inital value)+ roles in processabc+ link condition+ data+ role+ data+ role+ data+ roleabc+ link condition+ data+ role+ time+ data+ role+ time+ data+ role+ timefig. 5. a generic data structure in prom captures simulation-relevant information in
a language-independent way
deal with, or produce, high-level structures that can be used to generate simu-
lation models.
figure 5 illustrates how the dierent pieces of simulation-relevant informa-
tion are integrated and transformed to create the simulation model. for example,
while the yawl 2.0 import produces a yawl-based high-level process includ-
ing information about link conditions, data, and roles, the log analysis step
produces a set of activities with associated time information but no concrete
control ow model (i.e., no information about the causal activities between ac-
tivities in the process). after integrating the yawl-based high-level process
with the information obtained from the orgmodel import and the log analy-
sisas illustrated by the merge operation in figure 5, the control ow model
is translated into a petri net (the convert operation in figure 5), which then
yields a petri net-based high-level process that can be used as input for the cpn
export .
in summary, four basic steps need to be performed within prom to generate
the simulation model for a running yawl process (a sample screenshot of the
implementation is shown in figure 6):
step 1: the workow, the organizational model and the event log are imported
from the yawl workow system and analyzed.
10(a) the organizational model and the information obtained from the log analysis are
integrated into the imported yawl model
(b) the integrated yawl model is translated into a petri net while preserving all the
simulation-relevant information
fig. 6. the approach has been implemented in prom. here, the choice point `check
for completeness' is shown before and after the convert operation in figure 5
{ the information that we can get from the workow specication covers
a yawl process model including roles associated with tasks, data ows,
and link conditions at choice points in the process.
{ from the workow log we can extract information about the case ar-
rival rate, value range distributions for data attributes, and observed
execution times at tasks in the process.
11{ the orgmodel le provides information about the relationship between
all roles and resources in the whole organization.
step 2: simulation-relevant information from the organizational model and log
analysis are integrated into the yawl model.
step 3: the yawl model is converted into a petri net model (because our
simulation tool is based on coloured petri nets), wherein we preserve all the
extra information (e.g., time and data) that is relevant for the simulation
model.
step 4: finally, the integrated and converted model is exported as a cpn
model.
we can then use the cpn tools system [10] to simulate the generated model.
however, to produce useful results we do not want to start from an empty initial
state. instead we load the current state of the actual yawl system into the
cpn tools for simulation.
5.4 loading the current state
to carry out simulation experiments for operational decision making purposes
(the `fast forward' approach), it is essential to include the current state of the
workow system. this allows us to make use of the data values for the current
cases as well as the status of the work items for current cases within the sim-
ulation experiments. a new function has been created to extract current state
information of a running workow from the yawl system and to export this
information as a cpn tools input le ( initialstate node in figure 3).
the following information is obtained about the current state and is intro-
duced as the initial state of a simulation run.
{ all the running cases of a given workow and their marking.
{ all the data values associated with each case.
{ information about enabled work items.
{ information about executing work items and the resources used.
{ the date and time at which the current state le is generated.
when the empty initial state le of the generated simulation model is replaced
with the sml le as depicted in figure 3, tokens are created in the cpn model
that reect the current system status (see figure 7). for example, we can see
that there are three tokens in the case data place, which each correspond to a
credit card application being processed. we will go into more detail about the
cpn representation and the sml input le in section 6.
we now experiment with the various scenarios described in section 4. re-
call that due to the christmas promotion 150 cases are in the system. we load
the state le containing these 150 cases into the model and perform simula-
tion experiments for the coming two weeks assuming no changes in terms of
resource availability. we also add more resources to the model and observe how
this inuences the backlog and the throughput times for processing credit card
applications within this time horizon.
12fig. 7. the generated cpn model after loading the current state le
5.5 analyzing the simulation logs
we simulate the process from the generated cpn model for four dierent sce-
narios.
1. an empty initial state (`empty' in figure 8). note that this scenario illus-
trates the warm-up eect in traditional simulation without an explicit initial
state.
2. after loading the current state le with the 150 applications that are cur-
rently in the system and no modications to the model, i.e., the `as-is' situ-
ation (`as is' in figure 8).
3. after loading the current state le but adding four extra resources (two
having the role `manager' and three having the role `clerk'), i.e., a possible
`to-be' situation to help clear the backlog more quickly (`to be a' in figure 8).
4. after loading the current state le and adding eight extra resources. of these
eight additional resources four have the role `manager' and six have the role
`clerk' (`to be b' in figure 8).
we can see the dierence among these four scenarios in figure 8, which de-
picts the development of the number of cases (i.e., applications) in the workow
system over the coming two weeks for an example simulation run per scenario. in
the case of scenario 1 the simulation starts with having 0 credit card applications
in the system. this neither reects the normal situation nor does it capture our
current backlog of cases. note that after a while (the \warm-up period") this
simulation stabilizes to normal behavior of the credit card application process
(i.e., with ca. 100 applications arriving per week). the other three scenarios load
13 0 20 40 60 80 100 120 140 160 180
 0 5000 10000 15000 20000 25000no. of applications in the system
time horizon: two weeks (in seconds)number of applications that are in the system for four different scenarios1)2)3)4)'as is''to be a''to be b''empty'time horizon: two weeks (20160 minutes)fig. 8. number of applications in the simulated process for the dierent scenarios.
while the scenario with the empty state has initially 0 applications, the other scenarios
are initialized by loading 150 applications from the current state le. note that these
are just sample runs. see figure 9 for condence intervals
a dened initial state, which contains the 150 applications that we assume to
be currently in the system. furthermore, one can observe that in the scenarios
where we add extra resources to the process, the case load decreases more quickly
to a normal level than without further intervention. however, the scenario `to be
b' does not seem to perform much better than the scenario `to be a' although
twice as many resources have been added. this way, we can assess the eect of
possible measures to address the problem at hand, i.e., we can compare dierent
`what-if' scenarios in terms of their estimated real eects.
cpn tools has powerful simulation capabilities, which we can leverage. for
example, it is possible to automatically replicate simulation experiments to en-
able statistical analyses, such as calculating condence intervals for specic pro-
cess characteristics. for instance, figure 9 depicts the 95% condence intervals
of the average case throughput times based on 50 replicated simulations for each
of the four simulation scenarios. one can observe that the estimated through-
put time for the `empty' scenario is ca. 4 days, while the expected throughput
time for the `as is' scenario (i.e., actually expected based on the current backlog
situation) is almost 6 days.
while cpn tools already provides powerful logging facilities and even gener-
ates gnuplot scripts that can be used to plot certain properties of the simulated
14 5000 5500 6000 6500 7000 7500 8000 8500 9000
 0 1 2 3 4 5confidence interval
simulation scenarios95 % confidence intervals average throughput time in minfor the four simulation scenarios (50 replications each)confidence intervals'as is'5.88 days'to be a'4.91 days'empty'3.86 days'to be b'4.72 daysfig. 9. simulation run showing the 95% condence intervals of the throughput times
for the dierent simulation scenarios. the length of the condence interval indicates
the degree of variation
process, we also generate mxml event log fragments during simulation, similar
to the one shown in figure 4(a) for the workow log. these fragments can then
be combined using the cpn tools lter of the prom import framework, which
facilitates the conversion of event logs from various systems into the mxml
format that is read by prom.
the ability to use the same toolset for analyzing the simulation logs and
analyzing the actual workow logs constitutes a big advantage because the sim-
ulation analysis results can be more easily related to the initial properties of
the process. in particular, since we support the loading of current cases into
the initial state at the beginning of the simulation, we can easily combine the
real process execution log (`up to now') and the simulation log (which simulates
the future `from now on') and look at the process in a unied manner (with the
possibility of tracking both the history and the future of particular cases that
are in the system at this point in time).
figure 10 shows a screenshot of prom while analyzing the simulation logs
generated by cpn tools. various plug-ins can be used to gain more insight
into the simulated process. for example, in figure 10 the log dashboard (top
left), the basic statistics plug-in (bottom left), the performance analysis plug-
in (bottom right), and the ltl checker (top right) are shown. the former
two provide a general overview about the cases and activities in the process,
15fig. 10. the generated simulation logs can be analyzed with the same tool set as the
initial workow logs
whereas the performance analysis plug-in nds bottlenecks (e.g., in figure 10 a
bottleneck for starting the activity `make decision' is highlighted), and the ltl
checker can be used to verify specic properties of interest (e.g., \how many
cases could be processed until they are in the stage where a decision can be made
in under 3 days?").
6 the current state
having demonstrated the importance of incorporating an initial state into the
simulation model, we now want to explain in more detail how the state of a
workow system can be specied and incorporated. in this section, we describe
how a workow state can be exported from the yawl engine using a generic
workow state xml schema format and how this could be translated into a
cpn input le for simulation purposes using the running example.
6.1 from workow state-xml to sml file
figure 11 depicts the xml schema denition of the wfstate schema. the key
elements of interest for simulation purposes are as follows:
{workflowstate : this is the root element of the schema and contains infor-
mation about the workow state, including among others, the time at which
16<workflowstate>
<sou rce p rogram="yawl current state export"/>
<timestamp>2008-0 9-24t14:05:16.252+10:00</timestamp>
<process id ="creditapp.ywl" descrip tion="credit card application  process.">
<processinstance id="39" des cription="application 39">
<data>
<attribute name="loanamt">500</attribute>
<attribute name="completeapp">fa lse</attribute>
<attribute name="decidea pp">false</attribute>
</data>
<timesta mp>2008-08-27t12:03: 40.301+10:00</timestamp>
<wfmodelelementrecord id="1">
<wfmode lelement type=‚Äùcon d‚Äù>c2_15</wfmo delelement>
<status>m arked</status>
</wfmodelelementrecord>
</processinstance>
<processinstance id="40" de scription="application 40">
<data>
<attribute name="loanamt">0</attribu te>
<attribute name="completeapp">fa lse</attribute>
<attribute name="decidea pp">false</attribute>
</data>
<timesta mp>2008-09-24t14:02: 16.252+10:00</timestamp>
<wfmodelelementrecord id="3">
<wfmode lelement type=‚Äùcond‚Äù >inputcondition_1</wfmodelelement>
<status>marked</stat us>
</wfmodelelementrecord>
</processinstance>
<processinstance id="41" de scription="application 41">
<data>
<attribute name="loanamt">1500</attribute>
<attribute name="completeapp">fa lse</attribute>
<attribute name="decidea pp">false</attribute>
</data>
<timesta mp>2008-09-24t14:02: 16.252+10:00</timestamp>
<wfmodelelementrecord id="5">
<wfmode lelement type=‚Äùtask‚Äù>check_ for_completen ess_4<wfmodelelement>
<status>executing</status>
<timestamp>2 008-09-24t14 :02:36.416+10:00 </timestamp>
<originator>jonesa</originator>
</wfmodelelementrecord>
</processinstance>
</process>
</workflowstate>fig. 12. the wfstate xml le for the running example
fun getinitialcasedata() = [(41, {loanamt = 1500,completeapp = false,decideapp = false}),
(40, {loanamt = 0,completeapp = false,decideapp = false}),
(39, {loanamt = 500,completeapp = false,decideapp = false})];
fun getnextcaseid() = 42;fun getinitialtokensexeplace(pname:string) = case pname of 
"task_check_for_completeness_4`e"=>[(41,"-154","jonesa")] | _ => empty;
fun getinitialtokens(pname:string) = case pname of 
"process`cond_c2_15"=>[(39,"-43200")] | "overview`start"=>[(40,"-155")] | _ => empty;
fun getbusyresources() = ["jonesa"];
fun getcurrenttimestamp() = ‚Äú1205203218‚Äù;fun gettimeunit() = ‚Äúsec‚Äù;
fig. 13. cpn tools input le with initial state information. several cases are in dif-
ferent states in the system. for example, application no. 41 is currently being checked
by jonesa for completeness, and has a run time of 154 sec, i.e., ca. 2.57 min.
18this snapshot is taken. in addition, it contains a set of process elements
which represents the set of active yawl specications.
{process : each process element may contain a set of data attributes and val-
ues as well as a set of running cases of a yawl specication ( processinstance
elements).
{processinstance : each process instance element may contain a set of data
attributes and values as well as the identier of a parent process instance
in the case of hierarchical models. in addition, it contains the start time of
a particular case ( timestamp ) and a set of currently executing yawl tasks
and enabled yawl conditions ( wfmodelelementrecord elements).
{wfmodelelementrecord : each wfmodelelementrecord element may con-
tain a set of data attributes and values. in addition, it contains informa-
tion regarding a task or a condition ( wfmodelelement ) which has the status
marked for an enabled condition or the status executing for an executing
task, the start time ( timestamp ) and also who has started a currently run-
ning task ( originator ).
an example wfstate xml le is given in figure 12 for the running ex-
ample. for the credit card application process, three currently running process
instances (39, 40, and 41) with their respective values for the three data at-
tributes (`loanamt', `completeapp', and `decideapp') are shown. you can see
that for process instance 39, condition `c2' is enabled, and the input condition
is enabled for process instance 40. for process instance 41, it shows that the
`check for completeness' task is currently being worked on by `jonesa'. all the
timestamps are represented as instances of the datetime datatype.
a prom plug-in has been implemented to translate this information into a
cpn tools input le for the initial state. the corresponding sml le is shown
in figure 13. we will explain the functions in this sml le and their role in
linking the current state to the simulation model in section 6.3.
6.2 cpn representation
coloured petri nets (cpns) are a modeling formalism that combine petri nets
with a high-level programming language [10]. petri nets can be used to model
processes based on a bi-partite structure that consists of places, which may hold
tokens, and transitions, which under certain rules may re and move tokens in
that structure to change the state of the process. in ordinary petri nets tokens are
indistinguishable, but in cpns every token has a value (i.e., they are \colored"
and can be distinguished and used in computations). cpn tools is a tool for
coloured petri nets, where the values of tokens are typed, and can be tested and
manipulated with a functional programming language, which is called standard
ml (sml). furthermore, the cpns are extended by the notion of hierarchy
and time, and their behavior can be simulated. in the following, we provide a
brief summary of the cpn representation for business processes our simulation
approach is based on. we then describe in detail how we modied this cpn
19representation to dynamically load an initial state into the simulation model in
section 6.3.
consider figure 14, which illustrates the hierarchical structure of the gener-
ated cpn models. a model is distributed over several modules called pages , and
next to the depicted decomposition relationships these pages may be linked by
shared places (so-called fusion places). for example, in figure 7 one can see that
the data attributes (`loanamt', `completeapp', and `decideapp') for each newly
created case are stored in a separate token in the case data place. the same
case data place can be accessed on a sub page to test or modify the value, like,
for example, shown in figure 15 for activity `check for completeness', where
the outcome of the check activity is randomly determined and stored in the
corresponding case data token.
activity 'start approval'overviewenvironment (cf. figure 7)processactivity 'get more info'activity 'check for completeness' (cf. figure 15)...sub page sub page sub page sub page sub page 
fig. 14. the generated cpn models have a hierarchical structure: new cases are cre-
ated on the environment page and placed into the `start' place of the process (cf.
figure 7). details about each task are provided on the corresponding activity sub page
(cf. figure 15)
furthermore, the concept of time allows us to delay the progress of tokens
in the process, which we used to model the time between the start and the end
of an activity in the business process. for example, in figure 15 the execution
of activity `check for completeness' takes on average 1800 seconds (i.e., 30 min-
utes) and the actual delay during simulation is randomly determined based on
a normal distribution with a variance of 519.42. finally, a resource that is cur-
rently performing an activity (cf. resource `jonesa' in figure 15) is not available
for the execution of concurrently enabled activities, i.e., it is not available in the
global resources place, where available resources reside. further details on our
cpn representation can be found elsewhere [19].
6.3 incorporating the current state
now we explain how the sml functions depicted in figure 13 for the running
example are used by the parameterized simulation model to dynamically load
tokens for executing cases, busy resources, etc.
20fig. 15. sub page for task `check for completeness' of the simulation model with loaded
current state
the functions that are dened in the sml le are included in the cpn
model by the declaration use "creditapp.sml"; shown in the following cpn
declaration fragment. after this declaration clause, the sml functions dened
in the external le can be used as if they were dened within the cpn itself and,
thus, dynamically changed.
...
colset slist = list string;
use "creditapp.sml";
val busy:slist = getbusyresources();
fun freeresources i = not (mem busy i);
colset free = subset anybody by freeresources;
...
figure 7 shows the environment page of the cpn model where the simulation
parameters are set up and the information from the initial state data is loaded.
one can see that the case data place makes use of the getinitialcasedata()
function, which is dened in the sml le depicted in figure 13, as the initial
marking function to generate three tokens with case data for current cases.
similarly, the next case id place makes use of the getnextcaseid() function
to generate a token with `42' as the starting case id. the function getbusyre-
sources() is used to identify available resources by removing busy resources from
21all resources (which were previously obtained from the orgmodel le and are
dened elsewhere by the anybody data type) to create a subset of free
resources (see also cpn declaration fragment above). this set of free resources
is then used to populate the initial tokens for the resources place before starting
the simulation.
figure 15 shows the actual process status after loading the sml le. the
gure depicts the subpage for task `check for completeness' where the executing
place of that task ( e) contains a token. here we use the the getinitialtokensex-
eplace() function in the sml le to initialise the values of the token4. similarly,
thegetinitialtokens() function is used to initialise all those places in the cpn
model with an appropriate number of tokens that mark the progress of a case
but that do not represent a currently ongoing action.
finally, the functions getcurrenttimestamp() and gettimeunit() are used
to translate the cpn model's time into the actual process time. this is needed
to create simulation logs with time stamps that can be related to the real process
and the simulated time horizon.
7 discussion
in this paper we presented an innovative way to link workow systems, simu-
lation, and process mining. by combining these ingredients it becomes possible
to analyze and improve business processes in a consistent way. the approach
is feasible, as demonstrated by our implementation using yawl and prom. to
conclude, we would like to discuss the three main challenges that have been
addressed in this research.
7.1 faithful simulation models
although the principle of simulation is easy to grasp, it takes time and expertise
to build a good simulation model. in practice, simulation models are often awed
because of incorrect input data and a na ve representation of reality. in most
simulation models it is assumed that resources are completely dedicated to the
simulated processes and are eager to start working on newly arriving cases. in
reality this is not the case and as a result the simulation model fails to capture
the behavior of resources accurately. moreover, in manually constructed models
steps in the processes are often forgotten. hence simulation models are usually
too optimistic and describe a behavior quite dierent from reality. to compensate
for this, articial delays are added to the model to calibrate it and as a result
4note that for a running activity we calculate the remaining run time by halving a
random value based on the execution time distribution of the activity. this is realized
by the time delay `round(normal(1800.0,519.42)) div 2' added to the token created
by the getinitialtokensexeplace() function in figure 15. looking at an arbitrary
point in time, half the time is the best estimate. this could be improved further by
using the passed run time of the activity from the wfstate le, but would require
an analysis of the probability distribution function.
22its predictive value and trustworthiness are limited. in the context of workow
systems, this can be partly circumvented by using the workow design (the
process as it is enforced by the system) and historic data. the approach presented
in this paper allows for a direct coupling of the real process and the simulation
model. however, the generated cpn models in this paper can be improved by a
better modeling of resource behavior. furthermore, this resource behavior needs
to be approximated in some way. here, the mining of historic data can help to
automatically choose suitable simulation parameters. as a consequence, more
advanced process mining algorithms that extract characteristic properties of
resources are needed to create truly faithful simulation models.
7.2 short-term simulation
although most workow management systems oer a simulation component,
simulation is rarely used for operational decision making and process improve-
ment. one of the reasons is the inability of traditional tools to capture the real
process (see above). however, another, perhaps more important, reason is that
existing simulation tools aim at strategic decision making. existing simulation
models start in an arbitrary initial state (without any cases in the pipeline)
and then simulate the process for a long period to make statements about the
steady-state behavior. however, this steady-state behavior does not exist (the
environment of the process changes continuously) and is thus considered irrele-
vant by the manager. moreover, the really interesting questions are related to the
near future. therefore, the `fast-forward button' provided by short-term simula-
tion is a more useful option . because of the use of the current state and historic
data, the predictions are more reliable andvaluable, i.e., of higher quality and
easier to interpret and apply. the approach and toolset presented in this paper
enable short-term simulation. a drawback is that in the current implementation
three dierent systems are used. for example, the translation of insights from
simulation via prom and cpn tools to concrete actions in the workow system
yawl can be improved. further research is needed to provide a seamless, but
generic, integration. an interesting question regarding short-term simulation is
how long this \short-term" can actually be. in general, the time horizon of in-
terest depends on the questions that people have. however, assuming that a
business process owner has a short-term simulation tool at hand, one also needs
to consider the delay of decisions, or the delay of the realization of decisions,
which has an impact on the estimated values in the predicted interval.
7.3 viewing real and simulated processes in a unied manner
both simulation tools and management information systems (e.g., bi tools)
present information about processes. it is remarkable that, although both
are typically used to analyze the same process, the results are presented
in completely dierent ways using completely dierent tools. this may be
explained by the fact that for a simulated process dierent data is available
than for the real-world process. however, the emergence of process mining
23techniques allows for a unication of both views . process mining can be used to
extract much more detailed and dynamic data from processes than traditional
data warehousing and business intelligence tools. moreover, it is easy to extend
simulation tools with the ability to record event data similar to the real-life
process. hence, process mining can be used to view both simulated and real
processes. as a result, it is easier to both compare and to interpret `what-if'
scenarios. finally|while a detailed evaluation of the generated simulation
models is beyond the scope of this paper|a unied view of real-life logs and
simulation logs enables the validation of the simulation model by re-analyzing
the simulation logs in a `second pass' [18]. this way, we can ensure that
the `as-is' situation is captured appropriately by the simulation model (by
comparing process run times, availabilities, etc.) before starting to analyze
`what-if' scenarios.
acknowledgements . this research was supported by the iop program of the
dutch ministry of economic aairs and by australian research council grant
dp0773012. the authors would like to especially thank michael adams, eric
verbeek, ronny mans, and also christian g unther, minseok song, lindsay brad-
ford, and chun ouyang plus the code review team for their valuable support in
implementing the approach for yawl and prom. we also would like to thank
marlon dumas for sharing his valuable insights during the many discussions we
had about this topic.
references
1. w.m.p. van der aalst, b.f. van dongen, c.w. g unther, r.s. mans, a.k. alves
de medeiros, a. rozinat, v. rubin, m. song, h.m.w. verbeek, and a.j.m.m.
weijters. prom 4.0: comprehensive support for real process analysis. in j. kleijn
and a. yakovlev, editors, application and theory of petri nets and other models of
concurrency (icatpn 2007) , volume 4546 of lecture notes in computer science ,
pages 484{494. springer-verlag, berlin, 2007.
2. w.m.p. van der aalst and a.h.m. ter hofstede. yawl: yet another workow
language. information systems , 30(4):245{275, 2005.
3. w.m.p. van der aalst, j. nakatumba, a. rozinat, and n. russell. business process
simulation: how to get it right? bpm center report bpm-08-07, bpmcenter.org,
2008.
4. w.m.p. van der aalst, h.a. reijers, a.j.m.m. weijters, b.f. van dongen, a.k.
alves de medeiros, m. song, and h.m.w. verbeek. business process mining: an
industrial application. information systems , 32(5):713{732, 2007.
5. r. ardhaldjian and m. fahner. using simulation in the business process reengi-
neering eort. industrial engineering , pages 60{61, july 1994.
6. j.a. buzacott. commonalities in reengineered business processes: models and
issues. management science , 42(5):768{782, 1996.
7. m. dumas, w.m.p. van der aalst, and a.h.m. ter hofstede. process-aware infor-
mation systems: bridging people and software through process technology . wiley
& sons, 2005.
8. c. hall and p. harmon. a detailed analysis of enterprise architecture, process
modeling, and simulation tools. technical report 2.0, bptrends, september 2006.
249. m. jansen-vullers and m. netjes. business process simulation { a tool survey.
inworkshop and tutorial on practical use of coloured petri nets and the cpn
tools , aarhus, denmark, october 2006.
10. k. jensen, l.m. kristensen, and l. wells. coloured petri nets and cpn tools
for modelling and validation of concurrent systems. international journal on
software tools for technology transfer , 9(3-4):213{254, 2007.
11. d.w. kelton, r. sadowski, and d. sturrock. simulation with arena . mcgraw-hill,
new york, 2003.
12. j. kleijnen and w. van groenendaal. simulation: a statistical perspective . john
wiley and sons, new york, 1992.
13. m. laugna and j. marklund. business process modeling, simulation, and design .
prentice hall, upper saddle river, new jersey, 2005.
14. f. leymann and d. roller. production workow: concepts and techniques .
prentice-hall ptr, upper saddle river, new jersey, usa, 1999.
15. h. reijers. design and control of workow processes: business process manage-
ment for the service industry , volume 2617 of lecture notes in computer science .
springer-verlag, berlin, 2003.
16. h.a. reijers and w.m.p. van der aalst. short-term simulation: bridging the gap
between operational control and strategic decision making. in m.h. hamza,
editor, proceedings of the iasted international conference on modelling and
simulation , pages 417{421. iasted/acta press, anaheim, usa, 1999.
17. s.m. ross. a course in simulation . macmillan, new york, 1990.
18. a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering simulation
models. accepted for publication in information systems (pre-version available as
beta working paper, wp 223) .
19. a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering col-
ored petri nets from event logs. international journal on software tools for
technology transfer , 10(1):57{74, 2008.
20. a. rozinat, m. wynn, w.m.p. van der aalst, a.h.m. ter hofstede, and c. fidge.
workow simulation for operational decision support using design, historic and
state information. in m. dumas, m. reichert, and m.-c. shan, editors, bpm
2008, volume 5240 of lecture notes in computer science , pages 196{211. springer-
verlag, berlin, 2008.
21. a. rozinat, m. wynn, w.m.p. van der aalst, a.h.m. ter hofstede, and c. fidge.
workow simulation for operational decision support using yawl and prom.
bpm center report bpm-08-04, bpmcenter.org, 2008.
22. m. weske. business process management: concepts, languages, architectures .
springer-verlag, berlin, heidelberg, 2007.
23. m.t. wynn, m. dumas, c.j. fidge, a.h.m. ter hofstede, and w.m.p. van der
aalst. business process simulation for operational decision support. in a.h.m.
ter hofstede, b. benatallah, and h.-y. paik, editors, bpm 2007 workshops , volume
4928 of lecture notes in computer science , pages 66{77. springer-verlag, 2008.
25