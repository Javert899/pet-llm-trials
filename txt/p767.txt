this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
ieee transactions on neural networks and learning systems 1
dealing with concept dri fts in process mining
r. p. jagadeesh chandra bose, wil m. p. van der aalst, indr˙ e žliobait˙ e, and mykola pechenizkiy
abstract — although most business processes change over time,
contemporary process mining techniques tend to analyze theseprocesses as if they are in a steady state. processes may changesuddenly or gradually. the drift may be periodic (e.g., becauseof seasonal inﬂuences) or one-of-a-kind (e.g., the effects ofnew legislation). for the process management, it is crucial todiscover and understand such concept drifts in processes. thispaper presents a generic framework and speciﬁc techniques todetect when a process changes and to localize the parts of theprocess that have changed. different features are proposed tocharacterize relationships among activities. these features areused to discover differences between successive populations. theapproach has been implemented as a plug-in of the prom processmining framework and has been evaluated using both simulatedevent data exhibiting controlled concept drifts and real-life eventdata from a dutch municipality.
index terms — concept drift, ﬂexibility, hypothesis tests,
process changes, process mining.
i. i ntroduction
business processes are nothing more than logically
related tasks that use the resources of an organization to
achieve a deﬁned business outcome. business processes can be
viewed from a number of perspectives, including the control
ﬂow, data, and the resource perspectives. in today’s dynamic
marketplace, it is increasingly necessary for enterprises tostreamline their processes so as to reduce cost and to improve
performance. in addition, today’s customers expect organiza-
tions to be ﬂexible and adapt to changing circumstances. newlegislations such as the w abo act [1] and the sarbanes–oxley
act [2], extreme variations in supply and demand, seasonal
effects, natural calamities and disasters, deadline escalations
[3], and so on, are also forcing organizations to change
their processes. for example, governmental and insuranceorganizations reduce the fraction of cases being checked when
there is too much of work in the pipeline. as another example,
in a disaster, hospitals, and banks change their operatingprocedures. it is evident that the economic success of an
organization is more and more dependent on its ability to
react and adapt to changes in its operating environment.
therefore, ﬂexibility and change have been studied in-depth
in the context of business process management (bpm). for
manuscript received may 15, 2012; revised june 24, 2013; accepted
august 2, 2013.
r. p. j. c. bose, w. m. p. van der aalst, and m. pechenizkiy
are with the department of mathematics and computer science,
eindhoven university of technology, eindhoven 5600 mb, the nether-
lands (e-mail: j.c.b.rantham.prabhaka ra@tue.nl; w.m.p.v.d.aalst@tue.nl;
m.pechenizkiy@tue.nl).
i. žliobait˙ e is with the department of information and computer science,
aalto university, aalto fi-00076, finlan d (e-mail: indre.zliobaite@aalto.ﬁ).
color versions of one or more of the ﬁgures in this paper are available
online at http://ieeexplore.ieee.org.
digital object identiﬁer 10.1109/tnnls.2013.2278313example, process-aware information systems (paiss) [4] have
been extended to be able to ﬂexibly adapt to changes in the
process. state-of-the-art wo rkﬂow management (wfm) and
bpm systems [5] provide such ﬂexibility, e.g., we can easily
release a new version of a process. in addition, in processes
not driven by wfm/bpm systems (such as the usage ofmedical systems) there is even more ﬂexibility as processes
are controlled by people rather than information systems.
many of today’s information systems are recording an
abundance of event logs. process mining is a relatively young
research discipline aimed at di scovering, monitoring, and
improving real processes by extracting knowledge from event
logs [6] (section ii-a for a brief introduction). although
ﬂexibility and change have been studied in-depth in the contextof wfm and bpm systems, contemporary process mining
techniques assume the processes to be in a steady state. for
example, when discovering a process model from event logs,it is assumed that the process at the beginning of the recorded
period is the same as the process at the end of the recorded
period. using prom,
1we have analyzed processes in more
than 100 organizations. these practical experiences show that
it is very unrealistic to assume that the process being studiedis in a steady state. as mentioned earlier, processes may
change to adapt to changing circumstances. concept drift
refers to the situation in which the process is changing whilebeing analyzed. there is a need for techniques that deal with
such second-order dynamics. analyzing such changes is of
utmost importance when supporting or improving operational
processes and to obtain an accurate insight on process execu-
tions at any instant of time. when dealing with concept driftsin process mining, the following three main challenges emerge.
1)change point detection: the ﬁrst and most fundamental
problem is to detect concept drift in processes, i.e., todetect that a process change has taken place. if so, the
next step is to identify the time periods at which changes
have taken place. for example, by analyzing an event log
from an organization (deploying seasonal processes), we
should be able to detect that process changes happen andthat the changes happen at the onset of a season.
2)change localization and characterization: once a point
of change has been identiﬁed, the next step is to charac-terize the nature of change, and identify the region(s) of
change (localization) in a pro cess. uncovering the nature
of change is a challenging problem that involves both
the identiﬁcation of change perspective (e.g., control
ﬂow, data, resource, sudden, gradual, and so on) and theidentiﬁcation of the exact change itself. for instance, in
the example of a seasonal process, the change could be
1see www.processmining.org for more information.
2162-237x © 2013 ieeethis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
2 ieee transactions on neural networks and learning systems
x xchange
point
detectionchange
localization and
characterizationchange
process
discovery
online
analysisoffline
analysis
control-flow
data
resources
fig. 1. different dimensions of concept drift analysis in process mining.
that more resources are deployed or that special offers
are provided during holiday seasons.
3)change process discovery: having identiﬁed, localized,
and characterized the changes, it is necessary to put all of
these in perspective. there is a need for techniques/toolsthat exploit and relate these discoveries. unraveling the
evolution of a process should result in the discovery of
the change process describing the second-order dynam-ics. for instance, in the example of a seasonal process,
we could identify that the process recurs every season.
in addition, we can show an animation on how the
process evolved over a period with annotations showing
several perspectives such as the performance metrics(service levels, throughput time, and so on) of a process
at different instances of time.
we can differentiate between two broad classes of dealing
with concept drifts when analyzing event logs (fig. 1).
1)ofﬂine analysis: this refers to the scenario where the
presence of changes or the occurrence of drifts need
not be uncovered in a real time. this is appropriate in
cases where the detection of changes is mostly usedin postmortem analysis, the results of which can be
considered when designing/improving processes for later
deployment. for example, ofﬂine concept drift analysiscan be used to better deal with seasonal effects (hiring
less staff in summer or skipping checks in the weeks
before christmas).
2)online analysis: this refers to the scenario where
changes need to be discovered in near real time. thisis appropriate in cases where an organization would be
more interested in knowing a change in the behavior of
their customers or a change in demand as and when it ishappening. such real-time triggers (alarms) will enable
organizations to take quick remedial actions and avoid
any repercussions.
in this paper, we focus on two of the challenges: 1) change
(point) detection and change lo calization and 2) characteriza-
tion in an ofﬂine setting (fig. 1). we deﬁne different features
and propose a framework for dealing with these two problems
from a control-ﬂow perspective. initially, we show the promiseof the techniques proposed in this paper on a synthetic log and
later evaluate them on a real-life case study from a large dutch
municipality.
the rest of this paper is organized as follows. section ii pro-
vides background on process mining and concept drifts in datamining. related work is presented in section iii. section iv
describes the various aspects and nature of change, whereassection v presents the basic idea for change detection in
event logs. section vi introduces various features that capture
the characteristics of event logs. section vii illustrates thesigniﬁcance of statistical hypothesis tests for detecting drifts.
section viii presents the framework for dealing with concept
drifts in process mining, whereas section ix presents the
realization of the proposed approaches in the prom framework.
section x describes the effect iveness of the features and the
techniques proposed in this paper on a synthetic log as well as
a real-life case study. finally, this paper is summarized with
a conclusion and an outlook on some of the open researchquestions in section xi.
ii. b
ackground
in this section, we discuss the basic concepts in process
mining and concept drifts in data mining/machine learning.
a. process mining
process mining serves a bridge between data mining and
business process modeling [6]. business processes leave trails
in a variety of data sources (e.g., audit trails, databases, and
transaction logs). process mining aims at discovering, moni-
toring, and improving real processes by extracting knowledge
from event logs recorded by a variety of systems (ranging fromsensor networks to enterprise information systems). the start-
ing point for process mining is an event log, which is a collec-
tion of events. we assume that events can be related to processinstances (often called cases) and are described by some activ-
ity name. the events within a process instance are ordered.
therefore, a process instance is often represented as a trace
over a set of activities. in addition, events can have attributes
such as timestamps, associated resources (e.g., the person exe-cuting the activity), transactional information (e.g., start, com-
plete, suspend, and so on), and data attributes (e.g., amount or
type of customer). for a more formal deﬁnition of event logsused in process mining, the reader is referred to [6]. fig. 2
shows a fragment of an example log. event logs like in fig. 2
are completely standard in the process mining community andevent log formats such as mxml [7] and xes [8] are used.
the topics in process mining can be broadly classiﬁed
into three categories: 1) discovery; 2) conformance; and
3) enhancement [6]. process discovery deals with the discovery
of models from event logs. these models may describe controlﬂow, organizational aspects, time aspects, and so on. for
example, there are dozens of techniques that automatically
construct process models (e.g., petri nets or bpmn mod-els) from event logs [6]. fig. 2 shows the basic idea of
process discovery. an event log containing detailed infor-
mation about events is transformed into a multiset of traces
l=[abcdjkln ,aefjkmn ,abgchdjkln ,...]. process
discovery techniques are able to discover process models suchas the petri net shown in fig. 2. conformance deals with
comparing an ap r i o r i process model with the observed behav-
ior as recorded in the log and aims at detecting inconsisten-cies/deviations between a process model and its corresponding
execution log. in other words, it checks for any violationthis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 3
fig. 2. process discovery aims to learn a process model (in this case a petri net) from event logs. an event log consists of events related to cases and
referring to activities. to discover control ﬂow, traces are projected onto activity names.
between what was expected to happen andwhat actually has
happened . enhancement deals with extending or improving
an existing model based on information about the process
execution in an event log. for example, annotating a process
model with performance data to show bottlenecks, throughput
times, and so on.
being a relatively young research discipline, several process
mining challenges remain to be addressed. the process mining
manifesto [9] lists 11 challenges. the fourth challenge is
dealing with concept drift and, thus far, a little work has beendone on this highly relevant topic [10], [11].
b. concept drift
concept drift [12] in machin e learning and data mining
refers to situations when the relation between the input dataand the target variable, which the model is trying to predict,
changes over time in unforeseen ways. therefore, the accuracyof the predictions may degrade over time. to prevent that,
predictive models need to be able to adapt online, i.e., to
update themselves regularly with new data. the setting istypically looped over an inﬁnite data stream as follows:
1) receive new data; 2) make a prediction; 3) receive feedback
(the true target value); and 4) update the predictive model.
while operating under such circumstances, predictive models
are required: 1) to react to concept drift (and adapt if needed)as soon as possible; 2) to distinguish drifts from once-off noise
and adapt to changes, but be robust to noise; and 3) to operate
in less than data arrival time and use limited memory forstorage. in this setting, many adaptive algorithms have been
developed (e.g., overviews [13], [14]).this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
4 ieee transactions on neural networks and learning systems
concept drift is a relatively young research topic that
has gained popularity in data mining and machine learningcommunities in the last 10 years. concept drift research
primarily has been focusing on two directions: 1) how to detect
drifts (changes) online (e.g., [15]–[20]) and 2) how to keeppredictive models up to date (e.g., [21]–[23]). concept drift
has been shown to be important in many applications (e.g.,
[24]–[26]). the basis for drift detection could be a raw data
stream, a stream of prediction errors, and, more rarely, a stream
of predictions or a stream of updated model parameters. twotypes of concept drift detection approaches have been used:
monitoring evolution of a stream [15], [17] or comparing data
distributions in two time windows [16], [18]. the cumulativesum (cusum) approach [27] is a representative sequential
analysis technique for change detection, different extensions
to which have been proposed. one notable example is com-
putational intelligence-based cusum or ci-cusum [19]
that aims to detect a nonstationarity condition by monitoringa multidimensional vector, i.e., multiple features. adaptive
windowing [16] is a representative approach for online change
detection using an adaptive size sliding detection window.in this paper, we consider ofﬂine change detection and its
localization and therefore focus on studying what features to
monitor and how to identify when these characteristics change.
iii. r
elated work
over the last two decades many researchers have been
working on process ﬂexibility, e.g., making workﬂow systemsadaptive. in [28] and [29] collections of typical change patterns
are described. in [30] and [31] extensive taxonomies of the
various ﬂexibility approaches and mechanisms are provided.
ploesser et al. [32] have classiﬁed business process changes
into three broad categories: 1) sudden; 2) anticipatory; and3) evolutionary. this classiﬁcation is used in this paper, but
now in the context of event logs.
despite the many publications on ﬂexibility, most process
mining techniques assume a process to be in a steady state.
a notable exception is the approach in [33]. this approach
uses process mining to provide an aggregated overview of allchanges that have happened so far. this approach, however,
assumes that change logs are available, i.e., modiﬁcations of
the workﬂow model are recorded. at this point of time, very
few information systems provide such change logs. therefore,
this paper focuses on concept drift in process mining assumingonly an event log as input.
the topic of concept drift is well studied in various branches
of the data mining and machin e learning community. concept
drift has been studied in both supervised and unsupervised set-
tings and has been shown to be important in many applications
[12], [14], [25], [26], [34]–[37]. the problem of concept drift,
however, has not been studied in the process mining setting.
unlike in data mining and mach ine learning, where concept
drift focuses on changes in simple structures such as variables,
concept drift in process min ing deals with changes to com-
plex artifacts such as process models describing concurrency,choices, loops, and cancelation. although experiences from
data mining and machine learning can be used to investigateconcept drift in process mining, the complexity of process
models and the nature of process change pose new challenges.this paper extends the work presented in [10]. in this extended
paper, we introduce the topic of concept drift in process mining
and present the basic idea an d the features capturing the
characteristics of traces in an event log in a more rigorous
manner. in addition, this extended paper provides a generic
framework for handling concept drifts in process mining and
presents details on the realization of the approach in the prom
framework. furthermore, this paper reports new experimentalresults of the proposed approach. more speciﬁcally, in this
extended paper, we study the inﬂuence of population size on
change point detection and the applicability of the approach indealing with gradual drifts. in addition, we present the results
of applying the approach on a real-life case study from a large
dutch municipality.
recently, carmona and gavaldà [11] have proposed an
online technique for detecting process changes. they ﬁrstcreated an abstract representation of the process in the form
of polyhedra using the preﬁxes of some initial traces in the
event log. subsequent traces are sampled and assessed whetherthey lie within the polyhedra or not. if a sample lies within
the polyhedra, it is considered to be from the same process.
if signiﬁcant number of samples lies outside the polyhedra,
a process change is said to be detected. this work differs
from our approach in several ways: 1) this approach constructsan abstract representation o f a process unlike ours where
we consider features charact erizing the traces and 2) this
technique is applicable only for change detection whereas ourframework is applicable for both change (point) detection and
change localization. furthermore, the tool support provided
by the authors has some limitations in its applicability. the
tool does not detect change points and does not work on
logs with multiple process changes, i.e., it does not detectthe presence/absence of multiple changes and does not report
when (the trace index) process changes have happened. the
tool just reports that a change exists and terminates (if changesexist) and does not terminate if no changes exist. in contrast,
our tool can handle multiple process changes and can detect
both the presence of and the points of change in addition tobeing able to assist in change localization.
iv . c
haracterization of changes
inbusiness processes
in this section, we discuss the various aspects of
process change. initially, we describe change perspectives
(control ﬂow, data, and resource). then, the different types ofdrift (sudden, gradual, recurring, periodic, and incremental)
are discussed.
a. perspectives of change
there are three important perspectives in the context of
business processes: 1) control ﬂow; 2) data; and 3) resource.one or more of these perspectives may change over time.
1)control ﬂow/behavioral perspective: this class of
changes deals with the behavioral and structural changes
in a process model. just like the design patterns inthis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 5
fig. 3. different types of drifts. x-axis: time. y-axis: process variants. shaded rectangles: process ins tances. (a) sudden drift. (b) gradual drift. (c) recurring
drift. (d) incremental drift.
software engineering, there exist change patterns cap-
turing the common control-ﬂow changes [29]. control-ﬂow changes can be classiﬁed into operations such
as insertion, deletion, substitution, and reordering of
process fragments. for example, an organization whichused to collect a fee after processing and acceptance of
an application can now change their process to enforce
payment of that fee before processing an application.
here, the reordering change pattern had been applied
on the payment and the application processing processfragments. as another example, with the addition of
new product offerings, a choice construct is inserted
into the product development process of an organization.in the context of paiss, various control-ﬂow change
patterns have been proposed in [28], [29]. most of these
control-ﬂow change patterns are applicable to traditional
information/workﬂow systems as well.
sometimes, the control-ﬂow structure of a process
model can remain intact but the behavioral aspects of
a model change. for example, consider an insurance
agency that classiﬁes claims as high or low dependingon the amount claimed. an insurance claim of e1000
which would have been classiﬁed as high last year is
categorized as a low insura nce claim this year because
of the organization’s decision to increase the claim
limit. the structure of the process remains intact butthe routing of cases changes.
2)data perspective: this class of changes refer to the
changes in the production and consumption of data andthe effect of data on the routing of cases. for example,
it may no longer be required to have a particular
document when approving a claim.
3)resource perspective: this class deals with the changes
in resources, their roles, and organizational structure,and their inﬂuence on the e xecution of a process. for
example, there could have been a change pertaining
to who executes an activity. roles may change andpeople may change roles. as another example, certain
execution paths in a process could be enabled (disabled)
upon the availability (nonavailability) of resources.
furthermore, resources tend to work in a particular
manner and such working patterns may change overtime, e.g., a resource can have a tendency of executing
a set of parallel activities in a speciﬁc sequential order.
such working patterns could be more prominent whenonly few resources are available; the addition of new
resources can remove this bias.b. nature of drifts
with the duration for which a change is active, we can
classify changes into momentary andpermanent .m o m e n t a r y
changes are short lived and affect only a very few cases,whereas permanent changes are persistent and stay for a
while [31]. in this paper, we focus on permanent changes
as momentary changes often cannot be discovered because
of insufﬁcient data.
2momentary changes correspond to the
notion of outliers/noise in data mining. changes are perceivedto induce a drift in the concept (process behavior). as shown
in fig. 3, we identify four classes of drifts.
1)sudden drift: this corresponds to a substitution of an
existing process m
1with a new process m2,a ss h o w n
in fig. 3(a). m1ceases to exist from the moment
of substitution. in other words, all cases (processinstances) from the instant of substitution emanate from
m
2. this class of drifts is typically seen in scenarios
such as emergencies, crisis situations, and change of
law. as an example, a new regulation by the ﬁnance
ministry of india mandates all banks to procure andreport the customer’s personal account number in their
transactions.
2)gradual drift: this refers to the scenario, as shown in
fig. 3(b) where a current process m
1is replaced with
a new process m2. unlike the sudden drift, here both
processes coexist for some time with m1discontinued
gradually. for example, a supply chain organization
might introduce a new delivery process. this process is,however, applicable only for orders taken henceforth. all
previous orders still have to follow the former delivery
process.
3)recurring drift: this corresponds to the scenario where
a set of processes reappear after some time (sub-
stituted back and forth), as shown in fig. 3(c). it
is quite natural to observe such a phenomenon with
processes having a seasonal inﬂuence. for example, atravel agency might deploy a different process to attract
customers during christmas period. the recurrence of
processes may be periodic or nonperiodic. an exampleof a nonperiodic recurrence is the deployment of a
process subjected to market conditions. the point of
deployment and the duration of deployment are both
dependent on external factors (here, the market condi-
tions). periodic drifts may be caused by seasonal effects,
2to analyze momentary changes we can also use standard conformance
checking techniques to discover deviations from some normative model [38].this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
6 ieee transactions on neural networks and learning systems
e.g., during the summer holidays there tends to be
less demand and fewer resources thus inﬂuencing theprocess.
4)incremental drift: this refers to the scenario where a
substitution of process m
1with mnis done via smaller
incremental changes, as shown in fig. 3(d). this class of
drifts is more pronounced in organizations adopting an
agile bpm methodology and in processes undergoing
sequences of quality improvements (most total quality
management) initiatives are examples of incrementalchange [39]).
recurring and incremental drifts in fig. 3 are shown as discrete
sudden changes. these two types of concept drift, however,
can also be gradual. similar categorization of drifts havebeen proposed in [40] in the context of machine learning.
drifts in [40] are further cl assiﬁed based on the severity
of change into severe (and intersected). the categories of
severity, as deﬁned in [40], are too coarse to be applied to
business process changes. nonetheless, the degree of severityin process changes and their impact on dealing with concept
drifts is an interesting topic for further research. in the rest, we
propose approaches to detect potential control-ﬂow changes ina process manifested as sudden/gradual drifts over a period.
detecting drifts in the other perspectives are beyond the scope
of this paper. in addition, as already shown in fig. 1, we focus
on ofﬂine concept drift analysis (although our techniques can
easily be adapted to the online setting). in practice, a mixtureof any or all of the drifts may happen.
v. b
asic idea of drift detection in event logs
in this section, we present the basic idea for the detection
of changes by analyzing event logs. initially, we introduce the
notations used in this paper.
1)ais the set of activities. a+is the set of all nonempty
ﬁnite sequences of activities from a.
2) a process instance (i.e., case) is described as a trace
overa, i.e., a ﬁnite sequence of activities. examples of
traces are abcd and abbbad.
3) let t=t(1)t(2)t(3)...t(n)∈a+be a trace over a.
|t|=nis the length of the trace t.t(k)is the kthactivity
in the trace and t(i,j)is the continuous subsequence of
tthat starts at position iand ends at position j.ti=
t(i,|t|)represents the sufﬁx of tthat begins at position
i.
4) an event log, l, corresponds to a multiset (or bag) of
traces from a+. for example, l=[abcd,abcd,abbbad ]
is a log consisting of three cases. two cases follow trace
abcd and one case follows trace abbbad.
5) n,n0,a n d r+
0are the set of all natural numbers, the
set of all natural numbers including zero, and the set of
all positive real numbers including zero, respectively.
we can consider an event log las a time series of traces
(traces ordered based on the timestamp of the ﬁrst event).
fig. 4 shows such a perspective on an event log along with
change points in the sudden drift scenario. the basic premisein handling concept drifts is that the characteristics of the
traces before the change point differ from the characteristicsfig. 4. event log visualized as a time series of traces along with change
points. the basic premise of change (point) detection is that characteristic
differences exist in the traces before and after the change.
of the traces after the change point. the problem of change
point detection is then to identify the points in time where the
process has changed, if any. change point detection involves
two primary steps:
1) capturing the characteristics of the traces;
2) identifying when the characteristics change.
we refer to the former step as feature extraction and the latter
step as drift detection. the characteristics of the traces can
either be deﬁned for each trace separately or can be done at asublog level. an event log can be split into sublogs of straces
(s∈nis the split size). we can consider either overlapping or
nonoverlapping sliding windows when creating such sublogs.fig. 4 shows the scenario where two subsequent sublogs do
not overlap. in this case, we have k=⌈
n
s⌉sublogs for an event
log of ntraces. thus, the logs processed to determine the char-
acteristics of traces can be observed as a data stream of feature
values where statistical tests can be used to detect changes.
as mentioned earlier, dealing w ith concept drifts in process
mining involves two primary steps. first, we need to capture
the characteristics of traces; we propose a few feature setsthat address this in section vi. second, we need to identify
when these characteristics change; we look at techniques that
address this in section vii.
vi. f
eature extraction
event logs are characterized by the relationships between
activities. dependencies between activities in an event log can
be captured and expressed using the follows (or precedes)relationship, also referred to as causal footprints. for any pair
of activities a, b ∈a, and a trace t=t(1)t(2)t(3)...t(n)∈
a
+, we say b follows a if and only if for all 1 ≤i≤n
such that t(i)=a there exists a jsuch that i<j≤n
andt(j)=b. in temporal logic notation: /square(a⇒(♦b)).w e
say a precedes b if and only if for all 1 ≤j≤nsuch that
t(j)=b there exists an isuch that 1 ≤i<jandt(i)=a,
i.e.,¬awbw h e r e wis the weak until in linear temporal
logic notation. the follows an d precedes relationships can be
lifted from traces to logs. if b follows a in all the traces
in an event log, then we say that b always follows a. if b
follows a only in some subset of the traces, then we say that
bsometimes follows a. if b does not follow a in all traces,
then we say that b never follows a. consider an event log
l=[acaebfh ,ahijebd ,aeghijk ]containing three traces deﬁned
overa={ a ,b ,c ,d ,e ,f ,g ,h ,i ,j ,k } .t h ef o l l o w i n gr e l a t i o n s
hold in l: e always follows a, e never follows b, and b
sometimes follows a. fig. 5(a) shows the relationship betweenthis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 7
fig. 5. feature extraction (a) causal footprint matrix for all activity pairs
(b) relation type count (rc) and (c) re lation entropy (re) feature values. a:
always follows, n: never follows, and s: sometimes follows.
every pair of activities in a. the value in a cell (i,j)is either
a,s,o rncorresponding to the relation whether the activity
represented by column jalways, sometimes, or never follows
the activity represented by row i, respectively.
the variants of precedes relation can be deﬁned along sim-
ilar lines. the follows/precedes relationship is rich enough to
reveal many control-ﬂow changes in a process. we exploit this
relationship and deﬁne various features for change detection.
we distinguish between two classes of features: 1) global
and 2) local features. global features are deﬁned over an event
log, whereas local features can be deﬁned at a trace level.
with the follows (precedes) relation, we propose two global
features: 1) relation type count (rc) and 2) relation entropy(re), and two local features: 1) window count (wc) and 2)
jmeasure. these features are deﬁned as follows.
1)rc: the rc with respect to the f ollows (precedes) rela-
tion is a function, f
l
rc:a→ n0×n0×n0, deﬁned over
the set of activities a.fl
rcof an activity, x ∈a, with
respect to the follows (preced es) relation over an event
loglis the triple /angbracketleftca,cs,cn/angbracketrightwhere ca,cs,and cn
are the number of activities in athat always, sometimes,
and never follows (precedes) x , respectively, in the event
logl. for the event log lmentioned above, fl
rc(a)=
/angbracketleft2,9,0/angbracketrightbecause e and h always follows a while all
other activities in a\{e,h}sometimes follows a.
fl
rc(i)=/angbracketleft1,4,6/angbracketrightbecause only j always follows i; b,
d, e, and k sometimes follows i while a, c, f, g, h, andi never follows i. fig. 5(b) shows the rcs for all the
activities in a[the value in a row corresponds to the
rcs of the activity represented by that row in fig. 5(a)].
for an event log containing |a|activities, this results
in a feature vector of dimension 3 ×|a|(if either
the follows or the precedes relation is considered) or
2×3×|a|(if both the follows and the precedes relations
are considered).
2)re: the re with respect to th e follows (precedes)
relation is a function, f
l
re:a→ r+
0, deﬁned over thefig. 6. wc values for the relation b follows a for the different traces in the
event log.
set of activities. fl
reof an activity, x ∈awith respect
to the follows (precedes) rel ation is the entropy of the
rc metric. in other words, fl
re(x)=− palog2(pa)−
pslog2(ps)−pnlog2(pn)where pa=ca/|a|,ps=
cs/|a|,a n d pn=cn/|a|and/angbracketleftca,cs,cn/angbracketright= fl
rc(x).
for the above example event log l,fl
re(a)=0.684
(corresponding to fl
rc(a)=/angbracketleft2,9,0/angbracketright)a n d fl
re(i)=
1.322 (corresponding to fl
rc(i)=/angbracketleft1,4,6/angbracketright). fig. 5(c)
shows the re for all the activities in a[the value in
a row corresponds to the re of the activity represented
by that row in fig. 5(a)].
for an event log containing |a|activities, this results
in a feature vector of dimension |a|or 2×|a|depend-
ing on whether either or bot h of the follows/precedes
relations are considered.
3)wc: given a window of size l∈ n, the wc with
respect to follows (precedes) relation is a function, fl,t
wc:
a×a→ n0, deﬁned over the set of activity pairs. given
a trace tand a window of size l,l e tsl,t(a)be the bag of
all subsequences t(i,i+l−1), such that t(i)=a.3let
fl,t(a,b)=[s∈sl,t(a)|∃1<k≤|s|s(k)=b],i . e . ,t h e
bag of subsequences in tstarting with a and followed by
b within a window of length l. the wc of the relation
b follows a, fl,t
wc(a,b)=|fl,t(a,b)|.
fig. 6 shows the wc values for the relation b follows
a in the event log lusing a window of length four.
4)jm e a s u r e : smyth and goodman [41] have proposed a
metric called jmeasure based on [42] to quantify the
information content (goodness) of a rule. we adopt this
metric as a feature to characterize the signiﬁcance of
relationship between activities. the basis lies in the factthat we can consider the relation b follows a as a rule: if
activity a occurs, then activity b will probably occur. the
jmeasure with respect to follo ws (precedes) relation
is a function fl,t
j:a×a→ r+deﬁned over the set of
activity pairs and a given window of length l∈n.l e t
pt(a)and pt(b)are the probabilities of occurrence of
activities a and b, respectively, in a trace t.l e t pl,t(a,b)
be the probability that b follows a within a window of
length l, i.e., pl,t(a,b)=|fl,t(a,b)|/|sl,t(a)|. then,
thejmeasure for a window of length lis deﬁned as
fl,t
j(a,b)=pt(a)cel,t(a,b)where cel,t(a,b)is the
cross entropy of a and b (b follows a within a window
of length l) and is deﬁned as4
cel,t(a,b)=pl,t(a,b)log2/parenleftbiggpl,t(a,b)
pt(b)/parenrightbigg
3ifi+l−1>|t|,t h e n t(i,i+l−1)=ti, i.e., the sufﬁx of the trace t
starting at i.
4log2(0/x)and log2(x/0)for any x∈r+
0is taken as 0.this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
8 ieee transactions on neural networks and learning systems
fig. 7. basic idea of detecting drifts u sing hypothesis tests. the dataset of
feature values is considered as a time series for hypothesis tests. p1and p2
are two populations of size w.
+(1−pl,t(a,b))log2/parenleftbigg1−pl,t(a,b)
1−pt(b)/parenrightbigg
.
the jmeasure of a relation, b follows a, captures
the dissimilarity between the ap r i o r i anda posteriori
beliefs about b. in other words, it measures the
difference between the ap r i o r i distribution of b (i.e.,
probability that b occurs in a trace and the probability
that b does not occur), and the posteriori distribution
of b (i.e., probability that b occurs in a trace given thata occurred and the probability that b does not occur in
a trace given that a occurred).
the jmeasures for the relation b follows a using a
window of length four for the three traces in the event
loglin our previous example are 0 .147, 0 .032, and 0,
respectively.
normally, the window size is chosen to be the average trace
length, i.e., the average number of events in a process instance,
if no ap r i o r i information about the process is known. in case,
we have some ap r i o r i information about the process, we
can use the process characteristics to choose an appropriate
window size. having deﬁned the features, we next look at thesecond step in change point detection, i.e., drift detection.
vii. h
ypothesis tests for drift detection
an event log can be transformed into a data stream/sequence
dby choosing one of the feature sets deﬁned in the previous
section. the dataset dof feature values can be considered as
a time series of mvalues, as shown in fig. 7. each di∈d
corresponds to the feature value(s) for a trace (or sublog)
and can be a scalar or a vector (depending on the choice
of feature).5comparing with fig. 4, m=norm=k
depending on whether t he feature values are computed for each
trace or for each sublog, respectively. as mentioned earlier,
we expect a characteristic diff erence in the manifestation of
feature values in the traces (sublogs) before and after the
change points with the difference being more pronounced at
the boundaries. to detect this, we can consider a series of
successive populations of values (of size w) and investigate
if there is a signiﬁcant difference between two subsequentpopulations. the premise is that differences are expected to be
perceived at change points provided appropriate characteristics
of the change are captured as features. a moving windowof size wis used to generate the populations. fig. 7 shows
a scenario where two populations p
1=/angbracketleftd1,d2,..., dw/angbracketright
5the re, wc, and jmeasure feature sets propos ed in section vi generate
univariate (scalar) and multivariate (vector) data depending on whether we
consider an individual activity/activity pair or a set of activities/activity pairs,
respectively. the rc feature set always generates multivariate data.and p2=/angbracketleft dw+1,dw+2,..., d2w/angbracketrightof size ware consid-
ered. in the next iteration, the populations correspond to
p1=/angbracketleftd2,d3,..., dw+1/angbracketrightandp2=/angbracketleftdw+2,dw+3,..., d2w+1/angbracketright.
given a dataset of mvalues, the number of population pairs
(iterations) will be m−2w+1.
we propose the use of statistical hypothesis testing
to discover these change points. hypothesis testing is a
procedure in which a hypothesis is evaluated on a sample
data. one of the important uses of hypothesis testing is to
evaluate and compare groups of data. numerous varieties ofhypothesis tests exist [43]. the choice of a particular test is
largely dependent on the nature of the data and the objectives
of an experiment. for example, hypothesis tests can beclassiﬁed into parametric and nonparametric tests. parametric
tests assume that the data have a particular distribution, e.g.,
normal, whereas the nonparametric tests do not make any
assumption with regards to the data distribution. because we
do not know the ap r i o r i distribution of the feature values in
an event log, we consider only nonparametric tests. another
perspective of classiﬁcation is based on the number of
samples (populations) on which the hypothesis is deﬁned. wecan classify the hypothesis tests into 1) one-sample; 2) two-
sample; and 3) multisample tests. because we need to analyze
two populations for detecting drifts, we are interested in two-
sample hypothesis tests. another classiﬁcation of hypothesis
tests is concerned with the dimensionality of each dataelement in a sample. tests dea ling with scalar data elements
are called univariate tests while those dealing with vector
data elements are called multivariate tests. if only a particularactivity or activity pair is considered, then every data item
d
i∈dis a scalar value corresponding to the trace/sublog i.i f
we, however, consider sets of activities or activity pairs, then
each data item is a vector. therefore, we need to consider
both univariate and multivariate hypothesis tests.
we will use the univariate two-sample kolmogorov–
smirnov test (ks test) and mann–whitney utest (mw test)
as hypothesis tests for univariate data, and the two samplehotelling t
2test for multivariate data. the ks test evaluates
the hypothesis “do the two independent samples represent
two different cumulative frequency distributions?” whereas themw test evaluates the hypothesis “do the two independent
samples have different distributions with respect to the rank
ordering of the values?”. the multivariate hotelling t
2test is
a generalization of the t-test and evaluates the hypothesis “do
the two samples have the same mean pattern?”. all of thesetests yield a signiﬁcance probability assessing the validity of
the hypothesis on the samples. we refer [43] for a classic
introduction to various hypothesis tests.
viii. f
ramework
we propose the framework shown in fig. 8 for analyzing
concept drifts in process mining. the framework identiﬁes the
following steps:
1)feature extraction and selection: this step pertains in
deﬁning the characteristics of the traces in an event log.in this paper, we have deﬁned four features that charac-
terize the control-ﬂow perspective of process instancesthis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 9
fig. 8. framework for handling concept drifts in process mining.
in an event log. depending on the focus of analysis, we
may deﬁne additional features, e.g., if we are interested
in analyzing changes in organizational/resource perspec-tive, we may consider features derived from social
networks as a means of characterizing the event log.
in addition to feature extraction, this step also involvesfeature selection. feature sel ection is important when the
number of features extracted is large. we may consider
dimensionality reduction techniques [44], [45] such as
pca [46] or random projection [47] to deal with high
dimensionality.
2)generate populations: an event log can be transformed
into a data stream based on the features selected in
the previous step. this step deals with deﬁning thesample populations for studying the changes in the
characteristics of traces. diffe rent criteria/scenarios may
be considered for generating these populations from
the data stream. in section vii, we have considered
nonoverlapping, continuous, and ﬁxed-size windowsfor deﬁning the populations. we may also consider,
for example, noncontinuous windows (there is a gap
between two populations), adaptive windows (windowscan be of different lengths) [16], and so on, which are
more appropriate for dealing with gradual and recurring
drifts.
3)compare populations: once the sample populations are
generated, the next step is to analyze these populations
for any change in characteris tics. in this paper, we advo-
cate the use of statistical hypothesis tests for comparing
populations. the null hypothesis in statistical tests statesthat distributions (or means, or standard deviations) of
the two sample populations are equal. depending on
desired assumptions and the focus of analysis, differentstatistical tests can be used.
4)interactive visualization: the results of comparative
studies on the populations of trace characteristics can
be intuitively presented to an analyst. for example, the
signiﬁcance probabilities o f the hypothesis tests can be
visualized as a drift plot. troughs in such a drift plot
signify a change in the signiﬁcance probability thereby
implying a change in the characteristics of traces.
5)analyze changes: visualization techniques such as the
drift plot can assist in identifying the change points.
fig. 9. visualization of the drift plot in the concept drift plug-in in prom.
having identiﬁed that a change had taken place, thisstep deals with techniques that assist an analyst in char-
acterizing and localizing the change and in discoveringthe change process.
the framework can be used for designing new change detec-
tion approaches.
ix. i
mplementation
the concepts presented in thi s paper have been realized
as the concept drift plug-in in the prom6framework. prom
is a plug-able environment for process mining envisioned to
provide a common basis for all kinds of process mining tech-
niques ranging from importing, exporting, and ﬁltering eventlogs (process models) to analysis and visualization of results.
over years, prom has emerged to be the de facto standard for
process mining. the concept drift plug-in implements all of thesteps in the proposed framework and can be easily extended
with additional elements (e.g., new features can be easily
added). the plug-in supports visualization of the signiﬁcance
probability for the hypothesis tests as a drift plot. fig. 9 shows
a drift plot from the plug-in.
x. e
xperimental results and discussion
now, we put the ideas proposed for handling concept
drifts in practice. initially, we illustrate the effectiveness of
the proposed approaches using a synthetic example of an
insurance claim process and later discuss the results from areal-life case study in a large dutch municipality.
a. synthetic log-insurance claim process
this process corresponds to the handling of health insurance
claims in a travel agency. upon registration of a claim, a
general questionnaire is sent to the claimant. in parallel, a
registered claim is classiﬁed as high or low. for low claims,two independent tasks: 1) check insurance and 2) check
medical history need to be executed. for high claims, three
tasks need to be executed: 1) check insurance; 2) check
medical history; and 3) contact doctor/hospital for veriﬁcation.
if one of the checks shows that the claim is not valid, thenthe claim is rejected; otherwi se, it is accepted. a cheque and
acceptance decision letter is prepared in cases where a claim is
accepted while a rejection decision letter is created for rejected
claims. in both cases, a notiﬁca tion is sent to the claimant.
6see www.processmining.org for more information and to download prom.this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
10 ieee transactions on neural networks and learning systems
fig. 10. variants of an insurance claim process of a travel agency represented
in yawl notation. dashed rectangles : regions of change from its previous
model. (a) model 1. (b) model 2. (c) model 3. (d) model 4. (e) model 5.
three modes of notiﬁcation are supported by: 1) email;
2) telephone (fax); and 3) postal mail. the case should be
archived upon notifying the claimant. this can be done withor without the response for the questionnaire. the decision of
ignoring the questionnaire, however, can only be made aftera notiﬁcation is sent. the case is closed upon completion of
archiving task.
fig. 10 shows ﬁve variants of this process represented
in yawl [48] notation. dashed rectangles: a change has
been done in the process model with respect to its previous
variant. the changes can have various reasons. for example,
in fig. 10(a), the different checks for high insurance claims are
modeled using a parallel (
and) construct. a claim, however,
can be rejected if any one of the checks fail. in such cases,
the time and resources spent on other checks go waste.
to optimize this process, the agency can decide to enforcean order on these checks and proceed on checks only if
the previous check results are positive. in other words, the
process is modiﬁed with a knockout strategy [49] adopted for
the process fragment involving the different checks for high
insurance claims, as shown in fig. 10(b). as another example,the
or-construct pertaining to the sending of notiﬁcation to
claimants in fig. 10(c) has been modiﬁed to an exclusive-or
(xor) construct in fig. 10(d). the organization could have
taken a decision to reduce their workforce as a cost-cutting
measure. because of the availability of limited resources,
they would like to minimize the redundancy of sending the
notiﬁcation through different modes of communication and
restrict it to only one of the modes. considering an eventlog containing cases that belong to such a mix of process
variants, the objective of change point detection is to detect
when the processes have changed. in this section, we illustratethe handling of concept drifts in the context of sudden and
gradual drifts. we have modeled each of these ﬁve process
variants in cpn tools [50] and simulated 1200 traces for each
model.
1) sudden drift change (point) detection: to simulate the
sudden drift phenomenon, we created an event log lconsisting
of 6000 traces by juxtaposing each set of the 1200 traces. the
event log contains 15 activities or event classes (i.e., |a|=15)
and 58 783 events (which is the total number of events in thelog for all the traces). given this event log l, our ﬁrst objective
is to detect the four change points pertaining to these ﬁve
process variants, as shown in fig. 11(a). global features canbe applied only at the log level; to facilitate this, we have
split the log into 120 sublogs using a split size of 50 traces.
in this scenario, the four change points corresponding to the
ﬁve process variants are, as shown in fig. 11(b). we have
computed the follows rc of all 15 activities thereby generatinga multivariate vector of 45 f eatures for each sublog. we have
applied the hotelling t
2hypothesis test on this multivariate
dataset using a moving window population of size, w=10.
for this hypothesis test, we have randomly chosen 12 of the
45 features with a 10-fold cross validation.7fig. 12(a) shows
the average signiﬁcance probability of the hotelling t2test
for the 10 folds on this feature set. the troughs in the plot
signify that there is a change in the distribution of the feature
7the random selection of a subset of f eatures is primarily for two reasons:
1) to deal with the curse of dimensionality and 2) the changes being centered
around a few activities are prominently reﬂected only in those features
corresponding to these activities.this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 11
fig. 11. event log with traces from each of the ﬁve models juxtaposed. also shown are change points between models both at the trace and sublog levels.
the event log is split into 120 sublogs, each containing 50 traces. (a) trace level. (b) sub-log level.
fig. 12. (a) signiﬁcance probability of hotelling t2test on relation counts. average signiﬁcance proba bility (over all activity pairs) of (b) ks test on j
measure and (c) mw test on jmeasure. the event log is split into sublogs of 50 traces each. x-axis: sublog index. y-axis: signiﬁcance probability of the
test. troughs: change points. vertical grid lines: the actual (sudden) change points.
values in the log. in other words, they show that there is a drift
(change) in the concept, which here corresponds to the process.
it is interesting to observe that the troughs are observed aroundindexes 24, 72, and 96 which are indeed the points of change
(remember that, we have split the log into 120 sublogs with
the change points at indexes 24, 48, 72, and 96). the change at
index 48 corresponding to the transition from m
2tom3could
not be uncovered using this feature set because the rcs wouldbe alike for logs generated from these two process variants.
we have considered the jmeasure for each sublog and for
every pair of activities, a and b in a(b follows a within a
window of length l=10). the univariate ks and the mw
tests using a population of size w=10 are applied on the
jmeasure of each activity pair. fig. 12(b) shows the average
signiﬁcance probability of the ks test on all activity pairs,
whereas fig. 12(c) shows the same for the mw test. wecan observe that signiﬁcant troughs are formed at indexes
24, 48, 72, and 96 which correspond to the actual change
points. unlike the rc feature, the jmeasure feature is able
to capture all the four changes in the models. this can be
attributed to the fact that the jmeasure uses the probability of
occurrence of activities and their relations. in m
2, there could
be cases where all the modes of notiﬁcation are skipped ( xor
construct). in m3at least one of the modes, however, needs
to be executed ( orconstruct). this results in a difference in
the distribution of activity probabilities and their relationship
probabilities, which is elegantly captured by the jmeasure.
our experiences showed that ks test is more robust than the
mw test. henceforth, we report our results only using the
ks test.
we have considered the jmeasure for each trace separately
instead of at the sublog level. each activity pair generates a
vector of dimension 6000 corresponding to the jmeasure
of that activity pair in each trace. the univariate ks test
using a population size of w=400 is applied to the vectorfig. 13. average signiﬁcance probability (over all activity pairs) of ks test
on the jmeasure and wc feature sets estimated for each trace. x-axis: trace
index. y-axis: signiﬁcance probability of the test. troughs: change points.
vertical grid lines: actual (sudden) change points. (a) j-measure. (b) wc.
corresponding to each activity pair in a×a. fig. 13(a) shows
the average signiﬁcance probability of ks test on all activity
pairs, whereas fig. 13(b) shows the average signiﬁcanceprobability of ks test on all activity pairs using the wc feature
set. we can observe that signiﬁcant troughs are formed at
indexes 1200, 2400, 3600, and 4800. these are indeed the
points where the models have been changed.
inﬂuence of population size: it is imperative to note that
the goodness of the results of hypothesis tests depends onthe population size. the statistical analysis assumes that each
population is independent. a good population size is largely
dependent on the application and the focus of analysis. tostudy the inﬂuence of population size, we have considered the
jmeasure for every pair of activities and the univariate ks
test for change point detection. fig. 14 shows the results for
varying sizes of the population. we observe a lot of noise
for small populations and the drift tends to be smooth as thepopulation size increases. this can be attributed to the fact
that as the population size increases (i.e., as we consider more
cases), the variability in the nature of cases reduces and attainsthis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
12 ieee transactions on neural networks and learning systems
fig. 14. average signiﬁcance probability (over all activity pairs) for different population sizes of ks test on the jmeasure estimated over all activity pairs
in each trace. x-axis: trace index. y-axis: signiﬁcance probability of the test. troughs: change point s. vertical grid lines: actual (sudden) change points. (a) w
=150, (b) w =300, (c) w =450, and (d) w =600.
a stability, e.g., there can be a ﬂux of low-insurance claims
initially and after a certain tim e the proportion stabilizes.
2) sudden drift change localization: our second objective
in handling concept drifts is that of change localization. to
localize the changes (identify the regions of change), we need
to consider activity pairs individually or subsets of activitypairs. for example, the change from m
1tom2is localized
in the region pertaining to high insurance claim checks. we
expect characteristic changes i n features pertaining to these
activities and other activities related to these activities. for
example, in m1, the activities high medical history check and
contact hospital always follow the activity register whenever
a claim is classiﬁed as high. in contrast, in m2, these activities
need not always follow register because both these activitiesare skipped if high insurance check fails while contact
hospital is skipped if high medical history check fails.
during simulation, we have set the probability of success ofa check to 90%. we have considered the wc feature for
the activity relation contact hospital follows register on a
window length of l=10 in each trace separately. fig. 15(a)
shows the signiﬁcance probability of the univariate ks test
using a population size of w=400 on this feature. we can
observe that one dominant trough is formed at index 1200
showing that there exists a change in the region between
register and contact hospital. no subsequent changes withrespect to this activity pair can be noticed, which is indeed
the case in the sequence of models used.
as another example, we have considered the activity
prepare notiﬁcation along with all the three send notiﬁ-
cation activities. there exists a change pertaining to these
activities between models m
2and m3,m3and m4,a n d
m4and m5. more speciﬁcally, we have considered the wc
feature on the activity relations: send notiﬁcation by phonefollows prepare notiﬁcation, send notiﬁcation by email fol-
lows prepare notiﬁcation, and send notiﬁcation by post
follows prepare notiﬁcation. fig. 15(b) shows the averagesigniﬁcance probability of the univariate ks tests using a
population size of w=400 on the wc feature for various
modes of send notiﬁcation follows prepare notiﬁcation. we
observe three dominant troughs around indexes 2400, 3600,
and 4800 signifying the changes in the models. certain falsealarms (minor troughs) can also be noticed in this plot.
one means of alleviating this is to consider only those alarms
with an average signiﬁcance probability less than a thresh-old,δ. another means is to consider a larger population size.
in this fashion, by considering activities (and/or activity pairs)of interest, we can localize the regions of change. furthermore,
using this approach, we can obtain answers to diagnostic
questions such as is there a change with respect to activity
ain the process at time period t ?
the wc feature performs better in change localization
in comparison with the jmeasure. this is because the j
measure uses the probability of activities which can be affected
because of changes anywhere in the process irrespective of our
region of focus. for example, consider the jmeasure for the
relation contact hospital follows register. the probability of
occurrence of both register and contact hospital is affectedby the changes in the process model corresponding to the
sending of notiﬁcations as well, e.g., in m
3because all the
modes of send notiﬁcation can be executed, the probability ofcontact hospital in a trace is smaller than a corresponding
trace (contact hospital is executed) in m
4where only one
of the notiﬁcations is possible. fig. 15(c) shows the signiﬁ-
cance probability of the univariate ks test on the jmeasure
for the activity relation contact hospital follows register,whereas fig. 15(d) shows the average signiﬁcance probability
of the univariate ks tests on the jmeasure of various
send notiﬁcation modes following prepare notiﬁcation usinga population size of w=400. although the jmeasure
can identify changes, it has problems localizing the change
regions. therefore, we recommend the use of wc feature for
change localization.
3) gradual drift change (point) detection: now, we assess
the accuracy of the proposed framework in handling gradualdrifts. recall that in gradual drifts, one concept fades gradually
while the other takes over. this phenomenon of gradual
change can be modeled in many ways. in this paper, we
consider the scenario wher e the change is linear between
two sources, as shown in fig. 16(a). in this ﬁgure, weobserve the fading of one concept m
1and the taking over
of another concept m2happen linearly. within this setup,
we can alter the extent to which the two concepts coexist.for the insurance claim example, we generated two event
logs exhibiting gradual drifts by varying the duration of
change. in the ﬁrst case, the process variants m
1and m2
coexist between trace indexes 1000 and 1400, the variants
m2and m3coexist between indexes 2200 and 2600, the
variants m3and m4coexist between indexes 3400 and
3800, and the variants m4and m5coexist between indexes
4600 and 5000, as shown in fig. 16(b). the point of crossover is still retained at indexes 1200, 2400, 3600, and
4800.this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 13
fig. 15. (a) signiﬁcance probability of ks test for the relation, contact hosp ital follows register using the wc feature. (b) average signiﬁcance pro bability
(over activity pairs) of ks test estimated for the various modes of send notiﬁ cation follows prepare notiﬁcation r elation using the wc feature. (c) si gniﬁcance
probability of ks test for the relation, contact hospital follows register using the jmeasure. (d) average signiﬁcance probability (over activity pairs) of ks
test estimated for the various modes of send notiﬁcatio n follows prepare notiﬁcation relation using the jmeasure. troughs: change point with respect to
these activities. x-axis: trace index. y-axis: signiﬁcance probability of the test.
fig. 16. experimental setup for gra dual drifts. (a) generic scenario of
linear gradual change between different p rocess variants. (b) linear gradual
change with an overlapping window of 400 instances between any two process
variants.
fig. 17. average signiﬁcance probability (over all activity pairs) of ks test
on the jmeasure for linear gradual change with an overlapping window of
(a) 400 instances between any two process variants and (b) 900 instances
between any two process variants. dashed vertical grid lines: actual onset ofgradual change. corresponding solid ver tical grid lines: actual end points of
gradual change.
fig. 17(a) shows the average signiﬁcance probability of the
univariate ks test over all activity pairs on the jmeasure using
a population of size 300. we can observe that the proposed
approach is able to detect the change points. it is, however,
noteworthy that the width of the troughs is wider (at the top)
in the gradual drift scenario when compared with the suddendrift scenario [compare figs. 14(b) and 17(a)] signifying an
earlier onset of change in the gradual drift phenomenon. we
generated another event log with a linear gradual drift but witha longer duration of change. in this case, the process variants
m
1andm2coexist between trace indexes 750 and 1650, the
variants m2andm3coexist between indexes 1950 and 2850,
the variants m3and m4coexist between indexes 3150 and
4050, and the variants m4and m5coexist between indexes
4350 and 5150. fig. 17(b) shows the average signiﬁcance
probability of the univariate ks test over all activity pairs on
thejmeasure using a population of size 450. even in this
case, we can clearly identify the points and the duration of
change is captured as a much wider trough when compared
with the sudden drift scenario [compare figs. 14(c) and 17(b)].
4) gradual drift change localization: similar to sudden
drift change localization, we have considered the wc featurefig. 18. (a) signiﬁcance probability of ks test for the relation, contact
hospital follows register using the wc feature. (b) average signiﬁcanceprobability (over activity pairs) of ks test estimated for the various modes of
send notiﬁcation follows prepare notiﬁcation relation using the wc feature.
for the activity relation contact hospital follows register on
a window length of l=10 in each trace separately on the
gradual drift log with a longer duration of graduality (i.e., a
log with linear gradual change with an overlapping window of
900 instances between any two process variants.). fig. 18(a)
shows the signiﬁcance probability of the univariate ks testusing a population size of w=400 on this feature. we can
observe that one dominant trough is formed at index 1200
showing that there exists a change in the region betweenregister and contact hospital. no subsequent changes with
respect to this activity pair can be noticed, which is indeed the
case in the sequence of models used. unlike the sudden drift
scenario, the onset of change, however, happens much earlier
[compare it with fig. 15(a)]. fig. 18(b) shows the averagesigniﬁcance probability of the univariate ks tests using a
population size of w=400 on the wc feature for various
modes of send notiﬁcation follows prepare notiﬁcation. evenhere, we observe three dominant troughs around indexes 2400,
3600, and 4800 signifying the changes in the models with
earlier onsets of change [compare it with fig. 15(b)].
b. real-life log: advertisement permit process
of a dutch municipality
the synthetic event data created through simulation allow
us to compare the controlled (ground truth) changes with the
detected changes. we, however, have also applied our conceptdrift analysis techniques to various real-life event logs. here,
we report on a case study where we analyzed concept drifts
in processes within a large dutch municipality. municipalitiesare interested in obtaining insights into their processes, e.g.,
the way they are planned to be executed vis-a-vis the waythis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
14 ieee transactions on neural networks and learning systems
they are actually executed. recently, different municipalities
in the netherlands have evinced interest in comparing theirprocesses and learning from each other (the interested reader is
referred to the coselog project [51] for further information).
their vision is to have a form of standardization througha centrally managed process management system [52]–[55].
when analyzing event logs, we need to factor in the possibility
of process changes, i.e., concept drifts, that could have taken
place. in this section, we present the results of analysis of
concept drifts in event logs pertaining to one of the processesrelated to permits for advertisements. if a person/organization
wants to advertise on a building in the netherlands, for exam-
ple, on a billboard or an illuminated sign, a permit is neededusually, which can be obtained from the local municipality.
we considered an event log containing 116 cases and 2335
events referring to 25 activities. the cases pertain to permit
requests for placing advertisements spanning over the period
between july 7, 2003 and march 18, 2008. we considered the
jmeasure feature on the follows relation for all activity pairs
using a window of size 10. this choice of window size was
made based on the characteristics of the process. the processhas four high-level subprocesses: 1) application and initial
checks; 2) regulation compliance checks; 3) decision and
administration; and 4) enforcement, with clear dependencies
between them. one subprocess cannot start until the previous
one ﬁnished. therefore, the dependencies between activitiesare primarily manifested between one subprocess and the
initial few activities of its immediate successor. the event
log contains 25 event classes (distinct activities) with eachsubprocess on an average deﬁned over six activities. because
the dependencies are mostly reﬂected in one subprocess and
the initial few activities of the next subprocess, a window size
of 10 is deemed appropriate. in fact, we have tried using other
window sizes larger than 10 as well; however, we did notnotice any difference in perfo rmance with respect to change
detection and change localiza tion. because a smaller window
size is computationally efﬁcient, we report the results onwindow size of 10.
the jmeasure values of each activity pair deﬁne a vector
of size 116, corresponding to the traces in the event log.the univariate ks test is applied on each of these vectors
using a population size of 10. fig. 19 shows the average
signiﬁcance probability of the ks test on all activity pairs.
we observe four troughs formed at indexes 42, 74, 84, and
103. these troughs signify a change in behavior in the tracespreceding and succeeding them. among the four troughs, the
one at index 42 is particularly signiﬁcant. fig. 19 also shows
the start timestamps (october 4, 2004, october 27, 2005,february 13, 2006, and august 31, 2006, respectively) of the
cases corresponding to these troughs.
with the four change points, we split the log into ﬁve
partitions, the ﬁrst, l
1, containing the traces from the
beginning until the ﬁrst cha nge point (i.e., traces 1–42), the
second, l2, containing the traces between the ﬁrst and second
change points (i.e., traces 43–74) and so on. fig. 20 shows the
process model discovered using the heuristic miner [56] onthe event log l
1. the process can be divided into four high-
level subprocedures, as shown in the ﬁgure, and are listed asfig. 19. average signiﬁcance probability (over all activity pairs) of ks test
onjmeasure. the population size for the ks test is 10. there are four
troughs signifying a change in behavior.
follows.
1) upon submission of an application, the municipality
acknowledges the receipt of documents and (optionally)
tests for its completeness.
2) then, the municipality proceeds with a follow-up
procedure that veriﬁes whether the application and
submitted documents are in compliance with the
regulations.
3) with the investigations, then the municipality makes a
decision on the application and informs the applicant
with the decision along with a fee letter.
4) finally, the municipality registers the advertisements
placed and enforces them.
fig. 20(b) shows the process model discovered using the
heuristic miner [56] on the event log l2. the ﬁgure highlights
regions that differ from the process model in fig. 20(a). there
are two changes in this model with respect to the previous one.
the ﬁrst change is related to the checking for completenessof the registered documents. in the initial process model
[fig. 20(a)], this check was not mandatory (only two of the 43
applications were checked for completeness). the municipalitychanged this process by making the checks mandatory before
proceeding. the second change is the introduction of a new
activity ‘end procedure; enforcement is next,’ as shown in
fig. 20(b). the initial process model had only the activity
‘end procedure, possibly choose enforcement’ where as thenew model has both these activities. similar changes have
been observed in the rest of the models. we do not provide
them here because of space constraints. for a more detaileddiscussion on this case study refer [57].
the experiments demonstrate that the features and the
framework proposed in this paper for handling concept drifts
show signiﬁcant promise in detecting behavioral changes by
analyzing event logs.
c. time complexity
in this section, we assess the time complexity of the pro-
posed approach. the feature extraction is dependent on the sizeof the event log (i.e., the number of events). the feature values
for all of the features proposed in this paper can be extracted in
linear time with respect to the size of the event log. fig. 21(a)shows the average time along with 95% conﬁdence intervals
(over ﬁve independent runs) for extracting the jmeasurethis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 15
fig. 20. heuristic net of the permit process for advertisements discovered using the event log l1(a) marked regions: high-leve l subprocedures in this process
and (b) dashed rectangles: regions of change with respect to the previous m odel in (a). for a more detailed discussion on this case study refer to [57].
fig. 21. time complexity analysis: average time along with 95% conﬁdence i ntervals (over ﬁve independent runs ) for feature extraction and hypothesi st e s t s .
(a) j-measure. (b) inﬂuence of number of traces. (c) inﬂuence of population size.
feature for varying sizes of event log. for this experiment, we
considered the ﬁrst 1000 ,2000,3000,4000,5000,and 6000
traces in the juxtaposed event log (of the insurance claimexample used in section x-a). because the average number
of events is the same in each of these logs, we depict the
number of traces in the x-axis. we can observe that time
complexity varies linearly with respect to the size of the
log. the hypothesis tests on the other hand depend on the
population size and the number of traces in the event log(because the data stream of feature values is dependent on
the number of traces). the number of hypothesis tests to be
performed for a given data stream of nvalues (i.e., ntraces)
using a population size of pisn−2∗p+1. the time for
each hypothesis test is depende nt on the speciﬁc hypothesis
test adopted and the population size. fig. 21(b) shows theaverage time along with the 95% conﬁdence intervals (over
ﬁve independent runs) for the ks and mw tests using a
population size of 300 over all activity pairs on the jmeasurethis article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
16 ieee transactions on neural networks and learning systems
feature for varying number of traces. fig. 21(c) shows the
average time along with the 95% conﬁdence intervals (overﬁve independent runs) for the ks and mw tests over all
activity pairs on the jmeasure feature for varying population
sizes (we have used the event log with 6000 traces for thisexperiment). we can observe that the time complexity of the
hypothesis tests varies linearly with respect to both the number
of traces and the population size. because our approach is
primarily intended for ofﬂine use, the overall time for change
detection is reasonable. furthermore, we have consideredall activity pairs as features and the average signiﬁcance
p-values over them for this experiment. the overall compu-
tation time can be further redu ced by robust feature selection
techniques.
xi. c
onclusion
in this paper, we have introduced the topic of concept
drift in process mining, i.e., analyzing process changes based
on event logs. we proposed feature sets and techniques toeffectively detect the changes in event logs and identify the
regions of change in a process. our initial results show that
heterogeneity of cases arising because of process changes canbe effectively dealt with by de tecting concept drifts. once
change points are identiﬁed, the event log can be partitioned
and analyzed. this is the ﬁrst step in the direction of dealingwith changes in any process monitoring and analysis efforts.
we have considered changes only with respect to the control-
ﬂow perspective manifested as sudden and gradual drifts.
therefore, our analysis should only be observed as the starting
point for a new subﬁeld in the process mining domain andthere are lots of challenges that still need to be addressed.
some of these challenges include.
1)change-pattern speciﬁc features: in this paper, we pre-
sented very generic features (based on follows/precedes
relation). these features are neither complete nor suf-
ﬁcient to detect all classes of changes. an importantdirection of research would be to deﬁne features catering
to different classes of changes and investigate their effec-
tiveness. a taxonomy/classiﬁcation of change patternsand the appropriate features for detecting changes with
respect to those patterns are needed.
2)feature selection: the feature sets presented in this
paper result in a large number of features. for example,
the activity relation count feature type generates 3 ×|a|
features whereas the wc and jmeasure generate |a|
2
features (corresponding to all activity pairs). on the
one hand, such high dimensionality makes analysisintractable for most real-life logs. on the other hand,
changes being typically con centrated in a small region
of a process make it unnecessary to consider all features.
there is a need for tailored dimensionality reduction
techniques [44], [45] that can efﬁciently select the mostappropriate features.
3)holistic approaches: in this paper, we discussed ideas
on change detection and localization in the contextof sudden and gradual changes to the control-ﬂow
perspective of a process. as mentioned in section iv,the data and resource perspectives are also, however,
equally important. features and techniques thatcan enable the detection of changes in these other
perspectives need to be discovered. furthermore, there
could be instances where more than one perspective(e.g., both control and resource) change simultaneously.
hybrid approaches considering all aspects of change
holistically need to be developed.
4)recurring drifts: when dealing with recurring drifts,
in addition to change point detection and changelocalization, it is important to identify the variant(s)
that recur. this requires robust metrics to assess the
similarity between process variants and/or event logs.
5)change process discovery: as mentioned earlier, after
detecting the change points and the regions of change,
it is necessary to put them together in perspective.
organizations would be interested in discovering the
evolution of change (e.g., as an animation depictinghow the process has changed/evolved over time). in
addition, there are other applications such as deriving
a conﬁgurable model for the process variants. aconﬁgurable process model describes a family of
similar process models [58]. the process variants
discovered using concept drift can be merged to derive
a conﬁgurable process model.
6)sample complexity: sample complexity refers to the
number of traces (size of the event log) needed
to detect, localize, and characterize changes within
acceptable error bounds. this should be sensitive to thevariability in processes (in the manifestation of various
process model constructs used), nature of changes, their
inﬂuence and manif estation in traces, and the feature
space and algorithms used for detecting drifts. on a
broader note, the topic of sample complexity is relevantto all facets of process mining and is hardly addressed.
for example, it would be interesting to know the lower
bound on the number of traces required to discover aprocess model with a desired ﬁtness.
7)online (on-the-ﬂy) drift detection: in this paper, we have
looked at detecting drifts in an ofﬂine setting, i.e., forpostmortem analysis. although detecting concept drifts
is important for ofﬂine analysis, it is more interesting
and appropriate for online analysis. we believe the
proposed framework to be applicable even for online
analysis. few new challenges, however, emerge, e.g.,the number of samples required remains an issue. in
addition, we need additional computational power and
efﬁcient techniques to do such analysis in near real time.
r
eferences
[1] (2010). all-in-one permit for physical aspects: (omgev-
ingsvergunning) in a nutshell [online]. available: http://www.
answersforbusiness.nl/regulation/al l-in-one-permit-physical-aspects
[2] united states code. (2002, jul.). sarbanes-oxley act of 2002,
pl 107-204, 116 stat 745 [online]. available: http://ﬁles.ﬁndlaw.
com/news.ﬁndlaw.com/cnn/docs/gwbush/sarbanesoxley072302.pdf
[3] w. m. p. van der aalst, m. rosemann, and m. dumas, “deadline-based
escalation in process-aware information systems,” decision support
syst., vol. 43, no. 2, pp. 492–511, 2011.this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
bose et al. : dealing with concept drifts 17
[4] m. dumas, w. m. p. van der aalst, and a. h. m. ter hofstede, process-
aware information systems: bridging people and software throughprocess technology . new york, ny , usa: wiley, 2005.
[5] w. m. p. van der aalst and k. m. van hee, workﬂow management:
models, methods, and systems . cambridge, ma, usa: mit press,
2004.
[ 6 ] w .m .p .v a nd e ra a l s t , process mining: discovery, conformance and
enhancement of business processes .n e wy o r k ,n y ,u s a :s p r i n g e r -
verlag, 2011.
[7] b. f. van dongen and w. m. p. van der aalst, “a meta model for process
mining data,” in proc. caise workshops (emoi-interop workshop) ,
vol. 2. 2005, pp. 309–320.
[8] c. w. günther, (2009). xes standard deﬁnition [onlilne]. available:
http://www.xes-standard.org
[9] f. daniel, s. dustdar, and k. barkaoui, “process mining manifesto,” in
bpm 2011 workshops , vol. 99. new york, ny , usa: springer-verlag,
2011, pp. 169–194.
[10] r. p. j. c. bose, w. m. p. van der aalst, i. žliobait˙ e, and m. pechenizkiy,
“handling concept drift in process mining,” in proc. int. caise , 2011,
pp. 391–405.
[11] j. carmona and r. gavaldà, “online techniques for dealing with concept
drift in process mining,” in proc. int. conf. ida , 2012, pp. 90–102.
[12] j. schlimmer and r. granger, “beyond incremental processing: tracking
concept drift,” in proc. 15th nat. conf. artif. intell. , vol. 1. 1986,
pp. 502–507.
[13] a. bifet and r. kirkby. (2011). data stream mining: a practical
approach , university of waikato, waikato, new zealand [online].
available: http://www.cs.waikato.ac.nz/~abifet/moa/streammining.pdf
[14] i. žliobait˙ e, “learning under concept drift: an overview,”
corr , vol. abs/1010.4784, 2010 [online]. available:
http://arxiv.org/abs/1010.4784
[15] j. gama, p. medas, g. castillo, and p. rodrigues, “learning with drift
detection,” in proc. sbia , 2004, pp. 286–295.
[16] a. bifet and r. gavaldà, “learning from time-changing data with
adaptive windowing,” in proc. 7th siam int. conf. data mining (sdm) ,
2007, pp. 443–448.
[17] g. j. ross, n. m. adams, d. k. tasoulis, and d. j. hand, “exponentially
weighted moving average chart s for detecting concept drift,” pattern
recognit. lett. , vol. 33, no. 2, pp. 191–198, 2012.
[18] k. nishida and k. yamauchi, “detecting concept drift using statistical
testing,” in proc. 10th int. conf. discovery sci. . 2007, pp. 264–269.
[19] c. alippi and m. roveri, “just-i n-time adaptive classiﬁers–part i:
detecting nonstationary changes,” ieee trans. neural netw. , vol. 19,
no. 7, pp. 1145–1153, jul. 2008.
[20] c. alippi, g. boracchi, and m. roveri, “just-in-time classiﬁers for
recurrent concepts,” ieee trans. neural netw. learn. syst. , vol. 24,
no. 4, pp. 620–634, apr. 2013.
[21] j. z. kolter and m. a. maloof, “dynamic weighted majority: an
ensemble method for drifting concepts,” j. mach. learn. res. ,v o l .8 ,
pp. 2755–2790, jan. 2007.
[22] r. elwell and r. polikar, “incremental learning of concept drift in
nonstationary environments,” ieee trans. neural netw. , vol. 22, no. 10,
pp. 1517–1531, oct. 2011.
[23] g. widmer and m. kubat, “learning in the presence of concept
drift and hidden contexts,” mach. learn. , vol. 23, no. 1, pp. 69–101,
apr. 1996.
[24] s. j. delany, p. cunningham, a. tsym bal, and l. coyle, “a case-based
technique for tracking concept drift in spam ﬁltering,” knowl. based
syst., vol. 18, nos. 4–5, pp. 187–195, aug. 2005.
[25] a. tsymbal, m. pechenizkiy, p. cunningham, and s. puuronen, “han-
dling local concept drift with dynamic integration of classiﬁers: domain
of antibiotic resistance in nosocomial infections,” in proc. 19th ieee
int. symp. cbms , nov. 2006, pp. 679–684.
[26] m. pechenizkiy, j. bakker, i. žliobait˙ e, a. ivannikov, and t. kärkkäinen,
“online mass ﬂow prediction in cfb boilers with explicit detec-
tion of sudden concept drift,” sigkdd explorations , vol. 11, no. 2,
pp. 109–116, 2009.
[27] e. s. page, “continuous inspection schemes,” biometrika , vol. 41,
nos. 1–2, pp. 100–115, 1954.
[28] n. mulyar, “patterns for process-aware information systems: an
approach based on colored petri nets, ” ph.d. dissertati on, dept. comput.
sci., univ. technol., eindh oven, the netherlands, 2009.
[29] b. weber, s. rinderle, and m. rei chert, “change patterns and change
support features in process-aw are information systems,” in proc. 19th
int., 2007, pp. 574–588.
[30] g. regev, p. soffer, and r. schmidt, “taxonomy of ﬂexibility in business
processes,” in proc. 7th workshop bpmds , 2006, pp. 1–4.[31] h. schonenberg, r. mans, n. russell, n. mulyar, and w. m. p. van der
aalst, “process ﬂexibility: a survey of contemporary approaches,” inproc. adv. enterprise eng. i , 2008, pp. 16–30.
[32] k. ploesser, j. c. recker, and m. rosemann, “towards a classiﬁcation
and lifecycle of business process change,” in proc. bpmds , vol. 8. 2008,
pp. 1–9.
[33] c. w. günther, s. rinderle-ma , m. reichert, and w. m. p. van der
aalst, “using process mining to learn from process changes in evolu-
tionary systems,” int. j. business process integr. manag. , vol. 3, no. 1,
pp. 61–78, 2008.
[34] m. van leeuwen and a. siebes, “streamkrimp: detecting change in
data streams,” in proc. mach. learn. knowl. discovery databases , 2008,
pp. 672–687.
[35] i. žliobait˙ e and m. pechenizkiy. (2010). handling con-
cept drift in information systems [online]. available:
http://sites.google.com/site/zliobaite/cd_applications_2010.pdf
[36] h. wang, w. fan, p. s. yu, and j. han, “mining concept-drifting data
streams using ensemble classiﬁers,” in proc. 9th acm sigkdd int.
conf. knowl. discovery data mining . 2003, pp. 226–235.
[37] d. brzezinski and j. stefanowski, “reacting to different types of concept
drift: the accuracy updated ensemble algorithm,” ieee trans. neural
n e t w .l e a r n .s y s t . , apr. 2013, doi: 10.1109/tnnls.2013.2251352.
[38] w. m. p. van der aalst, a. adriansyah, and b. dongen, “replay-
ing history on process models for conformance checking and perfor-mance analysis,” wires data mining knowl. discovery , vol. 2, no. 2,
pp. 182–192, 2012.
[39] m. hammer, beyond reengineering: how the process-centered orga-
nization is changing our work and our lives . new york, ny , usa:
harper business, 1996.
[40] l. l. minku, a. p. white, and x. yao, “the impact of diver-
sity on online ensemble learning in the presence of concept drift,”ieee trans. knowl. data eng. , vol. 22, no. 5, pp. 730–742,
may 2010.
[41] p. smyth and r. m. goodman, rule induction using information
theory . washington, dc, usa: aaas press, 1991, pp. 159–176.
[42] n. m. blachman, “the amount of information that ygives about x,”
ieee trans. inf. theory , vol. 14, no. 1, pp. 27–31, jan. 1968.
[43] d. sheskin, handbook of parametric and nonparametric statistical
procedures
. london, u.k.: chapman & hall/crc, 2004.
[44] i. k. fodor, “a survey of dimensionality reduction techniques,” in
proc. center appl. sci. comput., lawrence livermore nat. lab. , 2002,
pp. 1–24.
[45] i. guyon and a. elisseeff, “an int roduction to variable and feature
selection,” j. mach. learn. res. , vol. 3, pp. 1157–1182, mar. 2003.
[46] i. t. jolliffe, principal component analysis , 2nd ed., new york, ny ,
usa: springer-verlag, 2002.
[47] e. bingham and h. mannila, “random projection in dimensionality
reduction: applications to image and text data,” in proc. 7th acm
sigkdd int. conf. mining , 2001, pp. 245–250.
[48] w. m. p. van der aalst and a. h. m. ter hofstede, “yawl: yet another
workﬂow language,” inf. syst. , vol. 30, no. 4, pp. 245–275, 2005.
[49] w. m. p. van der aalst, “re-engineering knock-out processes,” decision
support syst. , vol. 30, no. 4, pp. 451–468, 2001.
[50] k. jensen and l. m. kristensen, colored petri nets: modeling and
validation of concurrent systems . new york, ny , usa: springer-
verlag, 2009.
[51] coselog, (2013). conﬁgurable services for local governments ,g e r -
many [online]. available: http://www.win.tue.nl/coselog
[52] w. m. p. van der aalst, “conﬁgurab le services in the cloud: supporting
variability while enabling cross-organizational process mining,” in on
the move to meaningful internet systems (otm 2010) , lncs 6426.
new york, ny , usa: springer-verlag, jan. 2010, pp. 8–25.
[53] w. m. p. van der aalst, “intra- and inter-organizational process mining:
discovering processes within and between organizations,” in proc.
pract. enterprise model. , 2011, pp. 1–11.
[54] j. c. a. m. buijs, b. f. van dongen, and w. m. p. van der aalst,
“towards cross-organizational proces s mining in collections of process
models and their executions,” in proc. int. workshop pmc , 2011,
pp. 1–14.
[55] j. j. c. l. v ogelaar, h. m. w. verbeek, and w. m. p. van der
aalst, “comparing business processes to determine the feasibility of
conﬁgurable models: a case study,” in proc. int. workshop pmc , 2011,
pp. 1–12.
[56] a. j. m. m. weijters and w. m. p. van der aalst, “rediscovering
workﬂow models from event-based data using little thumb,” integr.
comput. aided eng. , vol. 10, no. 2, pp. 151–162, 2003.this article has been accepted for inclusion in a future issue of this journal. content is final as presented, with the exception of pagination.
18 ieee transactions on neural networks and learning systems
[57] r. p. j. c. bose, w. m. p. van der aalst, i. žliobait˙ e, and m. pechenizkiy,
“dealing with concept drifts in process mining: a case study in a dutchmunicipality,” bpm center, univ. technol., singapore, tech. rep. bpm-13-13, 2013.
[58] w. m. p. van der aalst, n. lohmann, and m. l. rosa, “ensuring
correctness during process conﬁgur ation via partner synthesis,” inf. syst. ,
vol. 37, no. 6, pp. 574–592, 2012.
r. p. jagadeesh chandra bose received the ph.d.
(cum laude ) degree in process mining from technis-
che universiteit eindhoven, eindhoven, the nether-
lands.
he is a research scientist with xerox research
center india, bangalore , india. he has over eight
years of research experience in the industry, and
he has executed projects in the areas of softwareengineering, health care, business analytics, and
knowledge management. he has co-authored over
30 publications and ﬁve patent ﬁlings. his current
research interests include process mining, business process management,business intelligence (analytics), mach ine learning, data mining, and bioin-
formatics.
dr. bose has received various awards for excellence in academics.
wil m. p. van der aalst received the doctor hon-
oris causa degree from hasselt university, diepen-
beek, belgium, in 2012.
he is a full professor of information systems with
the technische universiteit eindhoven (tu/e), eind-
hoven, the netherlands. he is the academic super-
visor of the internationa l laboratory of process-
aware information systems, national research
university, higher school of economics, moscow,
russia. since 2003, he has h eld a part-time appoint-
ment with the queensland university of technology,
queensland, australia. his ideas have inﬂuenced researchers, software devel-
opers, and standardization committees working on process support. in 2013, he
was a distinguished university profe ssor at tu/e. his papers are highly cited
(he has an h-index of more than 103 according to google scholar, making him
the european computer scientist with th e highest h-index). he has published
more than 160 journal papers, 17 books (as author or editor), 300 refereedconference/workshop publications, and 50 book chapters. his current research
interests include workﬂow management, process mining, petri nets, business
process management, process modeling, and process analysis.
dr. van der aalst is a member of the royal holland society of sciences
and humanities (koninklijke hollandsche maatschappij der wetenschappen)
and the academy of europe (academia europaea).
indr˙ e žliobait˙ eis a research scientist with aalto
university, aalto, finland. her current researchinterests include predictive modeling from evolvingstreaming data, change detection, and predictive
analytics applications. for further information see
http://zliobaite.googlepages.com.
mykola pechenizkiy received the ph.d. degree
in computer science and information systems from
the university of jyvaskyla, jyvaskyla, finland, in
2005.
he is an assistant professor with the department
of computer science, eindhoven university of tech-
nology, eindhoven, the netherlands. he has co-
authored over 70 peer-reviewed publications and hasbeen organizing several workshops (hacdais at
ecml/pkdd in 2010, lemeds at aime in 2011),
conferences (ieee cbms in 2012, edm in 2011,
ieee cbms in 2008, and bnaic in 2009) and tutorials (at ecml/pkddin 2012, pakdd in 2011, ieee cbms in 2010, and ecml/pkdd in
2010). he has co-edited the handbook of educational data mining .h i s
current research interests include data mining and data-driven intelligence,and its application to various (adaptiv e) information systems serving industry,
commerce, medicine, and education.
dr. pechenizkiy has served as a guest editor of the special issues in
sigkdd explorations , elsevier’s dke and aiim , and springer’s evolving
systems journals . currently, he takes a leading role in nwo hacdais, stw
capa, eit ict labs stress at work, and nl agency codak.