explainable predictive decision mining for
operational support
gyunam park1, aaron k usters2, mara tews2, cameron pitsch2, jonathan
schneider2, and wil m. p. van der aalst1
1process and data science group (pads), rwth aachen university, germany
fgnpark,wvdaalst g@pads.rwth-aachen.de
2rwth aachen university, germany
faaron.kuesters,mara.tews,cameron.pitsch,lennart.schneider g@rwth-aachen.de
abstract. several decision points exist in business processes (e.g., whether
a purchase order needs a manager's approval or not), and dierent deci-
sions are made for dierent process instances based on their characteris-
tics (e.g., a purchase order higher than e500 needs a manager approval).
decision mining in process mining aims to describe/predict the routing
of a process instance at a decision point of the process. by predicting
the decision, one can take proactive actions to improve the process. for
instance, when a bottleneck is developing in one of the possible deci-
sions, one can predict the decision and bypass the bottleneck. however,
despite its huge potential for such operational support, existing tech-
niques for decision mining have focused largely on describing decisions
but not on predicting them, deploying decision trees to produce logical
expressions to explain the decision. in this work, we aim to enhance the
predictive capability of decision mining to enable proactive operational
support by deploying more advanced machine learning algorithms. our
proposed approach provides explanations of the predicted decisions us-
ing shap values to support the elicitation of proactive actions. we have
implemented a web application to support the proposed approach and
evaluated the approach using the implementation.
keywords: process mining 路decision mining 路machine learning 路op-
erational support 路proactive action
1 introduction
a process model represents the control-ow of business processes, explaining the
routing of process instances. it often contains decision points, e.g., xor-split
gateway in bpmn. the routing in such decision points depends on the data
attribute of the process instance. for instance, in a loan application process, the
assessment of a loan application depends on the amount of the loan, e.g., if the
amount is higher than e5000, it requires advanced assessment and, otherwise,
simple assessment .
decision mining in process mining aims to discover a decision model that
represents the routing in a decision point of a business process [8]. the discoveredarxiv:2210.16786v1  [cs.ai]  30 oct 20222 park et al.
decision model can be used for 1) describing how decisions have been made and
2) predicting how decisions will be made for future process instances. while
the focus has been on the former in the literature, the latter is essential to
enable proactive actions to actually improve business processes [13]. imagine we
have a bottleneck in advanced assessment due to, e.g., the lack of resources. by
predicting the decision of a future loan application, we can take proactive action
(e.g., suggesting to lower the loan amount to conduct simple assessment ), thus
facilitating the process.
to enable such operational support, a decision model needs to be both 1)
predictive (i.e., the model needs to provide reliable predictions on undesired/
decisions) and 2) descriptive (i.e., domain experts should be able to interpret
how the decision is made to elicit a proactive action). fig. 1 demonstrates these
requirements. fig. 1(a) shows a decision point in a loan application process, and
there is a bottleneck in advanced assessment . our goal is to accurately predict
that a loan application with the amount of e5500 and interest of 1 :5% needs
advanced assessment , which is undesired due to the bottleneck, and recommend
actions to avoid the bottleneck. fig. 1(b) shows four dierent scenarios. first, if
we predict a desired decision (i.e., predicting the simple assessment), no action
is required since the simple assessment has no operational issues. second, if we
predict an undesired prediction incorrectly (e.g., incorrectly predicting the ad-
vanced assessment), we recommend an inadequate action. third, if we predict the
undesired decision correctly but no explanations are provided, no action can be
elicited due to the lack of explanations. finally, if we predict the undesired deci-
sion, and the corresponding explanations are provided (e.g., the amount/interest
of the loan has a positive/negative eect on the probability of conducting the
advanced assessment, respectively), we can come up with relevant actions (e.g.,
lowering the amount or increasing the interest rate).
fig. 1: (a) decision point in a process model. (b) dierent scenarios showing
that decision mining needs to be predictive and descriptive to enable operational
support.
existing work has focused on the descriptive capability of decision models
by deploying highly interpretable machine learning algorithms such as decisionexplainable predictive decision mining 3
trees [8, 11, 15]. however, it leads to limited predictive capability due to the
limitation of decision trees, such as overtting and instability (i.e., adding a
new data point results in regeneration of the overall tree) [16]. in this work, we
aim to enhance the predictive capabilities of decision mining, while providing
explanations of predicted decisions. to this end, we estimate the decision model
by using machine learning algorithms such as support vector machines, random
forests, and neural networks. next, we produce explanations of the prediction of
the decision model by using shap values.
we have implemented the approach as a standalone web application. using
the implementation, we have evaluated the accuracy of predicted decisions using
real-life event logs. moreover, we have evaluated the reliability of explanations
of predicted decisions by conducting controlled experiments using simulation
models.
this paper is structured as follows. first, we discuss related work on decision
mining and explainability in sec. 2. next, we introduce process models and event
logs in sec. 3. in sec. 4, we provide our proposed approach. in sec. 5, we explain
the implementation of a web application based on the approach. sec. 6 evaluates
the approach based on the implementation using simulated and real-life event
logs. we conclude this paper in sec. 7.
2 related work
several approaches have been proposed to learn decision models from event logs.
rozinat et al. [15] suggest a technique based on petri nets. it discovers a petri
net from an event log, identies decision points, and employs classication tech-
niques to determine decision rules. de leoni et al. [8] extend [15] by dealing with
invisible transitions of a petri net and non-conforming process instances using
alignments . these methods assume that decision-making is deterministic and all
factors aecting decisions exist in event logs. to handle non-determinism and
incomplete information, mannhardt et al. [11] propose a technique to discover
overlapping decision rules. in [2], a framework is presented to derive decision
models using decision model and notation (dmn) and bpmn. all existing
approaches deploy decision trees due to their interpretability. to the best of
our knowledge, no advanced machine learning algorithms have been deployed to
enhance the predictive capabilities of decision models along with explanations.
although advanced machine learning approaches provide more accurate pre-
dictions compared to conventional white-box approaches, they lack explainability
due to their black-box nature. recently, various approaches have been proposed
to explain such black-box models. gilpin et al. [4] provide a systematic literature
survey to provide an overview of explanation approaches. the explanation ap-
proaches are categorized into global andlocal methods. first, global explanation
approaches aim to describe the average behavior of a machine learning model
by analyzing the whole data. such approaches include partial dependence plot
(pdp) [6], accumulated local eects (ale) plot [1], and global surrogate mod-
els [3]. next, local explanation approaches aim to explain individual predictions4 park et al.
by individually examining the instances. such approaches include individual
conditional expectation (ice) [5], local surrogate (lime) [14], and shapley
additive explanations (shap) [10]. in this work, we use shap to explain the
predictions produced by decision models due to its solid theoretical foundation
in game theory and the availability of global interpretations by combining local
interpretations [10].
3 preliminaries
given a set x, we denote the set of all multi-sets over xwithb(x).fxis
the function projected on x:dom(fx) =dom(f)\xandfx(x) =f(x) for
x2dom(fx).
3.1 process models
decision mining techniques are independent of the formalism representing pro-
cess models, e.g., bpmn, ywal, and uml-activity diagrams. in this work, we
use petri nets as the formalism to model the process.
first, a petri net is a directed bipartite graph of places and transitions. a
labeled petri net is a petri net with the transitions labeled.
denition 1 (labeled petri net). letuactbe the universe of activity names.
a labeled petri net is a tuple n=(p;t;f;l )withpthe set of places, tthe set of
transitions, p\t=;,f(pt)[(tp)the ow relation, and l2t6!uact
a labeling function.
fig. 2: an example of petri nets highlighted with decision points
fig. 2 shows a petri net, n1= (p1;t1;f1;l1), wherep1=fp1;:::;p 6g,
t1=ft1;:::;t 7g,f1=f(p1;t1);(t1;p2);:::g,l1(t1) = create purchase order ,
l1(t2) = request standard approval , etc.
the state of a petri net is dened by its marking. a marking mn2b(p) is
a multiset of places. for instance, mn1= [p1] represents a marking with a token
inp1. a transition tr2tisenabled in marking mnif its input places contain
at least one token. the enabled transition may reby removing one token from
each of the input places and producing one token in each of the output places.
for instance, t1 isenabled inmn1and red by leading to m0
n1= [p2].explainable predictive decision mining 5
table 1: an example of event logs
case id activity timestamp resource total-price vendor
po92 create purchase order 09:00 05.oct.2022 adams 1000 apple
po92 request standard order 11:00 07.oct.2022 pedro 1000 apple
po93 create purchase order 13:00 07.oct.2022 peter 1500 samsung
. . . . . . . . . . . . . . . . . .
denition 2 (decision points). letn=(p;t;f;l )be a labeled petri net. for
p2p,p=ft2tj(p;t)2fgdenotes it outgoing transitions. p2pis a
decision point ifjpj>1.
for instance, p2 is a decision point in n1sincep2=ft2;t3gandjp2j>1.
3.2 event logs
denition 3 (event logs). letuevent be the universe of events, uattrthe
universe of attribute names ( fcase;act;time;res guattr), and uvalthe uni-
verse of attribute values. an event log is a tuple l= (e;)witheuevent as
the set of events and 2e!(uattr9 u val)as the value assignments of the
events.
table 1 shows a part of an event log l1=(e1;1).e12e1represents the event
in the rst row, i.e., 1(e1)(case) =po92 ,1(e1)(act) =create purchase order ,
1(e1)(time) = 09:00 05.oct.2022 ,1(e1)(res) =adams ,1(e1)(total-price ) = 1000,
and1(e1)(vendor ) =apple .
4 explainable predictive decision mining
in this section, we introduce an approach to explainable predictive decision min-
ing. as shown in fig. 3, the proposed approach consists of two phases: oine
andonline phases. the former aims to derive decision models of decision points,
while the latter aims at predicting decisions for running process instances along
with explanations. in the oine phase, we compute situation tables based on
historical event logs and estimate decision models using the situation tables . in
the online phase, we predict decisions for ongoing process instances and explain
the decision.
4.1 oine phase
first, we compute situation tables from event logs. each record in a situation
table consists of features (e.g., total price of an order) and a decision in a decision
point (e.g., t2 at decision point p2 in fig. 2), describing how the decision has
been historically made (e.g., at decision point p2 in fig. 2, standard approval
(i.e.,t2) was performed when the total price of an order is e1000).6 park et al.
fig. 3: an overview of the proposed approach
denition 4 (situation table). letufeature be the universe of feature names
andufmap =ufeature 9 u valthe universe of feature mappings. let n=(p;t;f;l )
be a labeled petri net and p2pa decision point. sitp2ul!b(ufmapp)
maps event logs to situation tables (i.e., multi-sets of feature mappings and de-
cisions).sp=fsitp(l)jl2ulgdenotes the set of all possible situation tables
ofp.
the table in fig. 4(a) represents a situation table of p2 in fig. 2 derived from
the event log depicted in table 1. for instance, the rst row in fig. 4(a) describes
that request standard approval (t2) was executed when human resource adams
performed create purchase order (i.e., res-cpo ) for the order of e1000 (i.e., total-
price ) with apple (i.e., vendor ). formally, s1= (fmap 1;t2)2sitp2(l1) where
fmap 12ufmap such thatfmap 1=f(res-cpo;adams );(vendor;apple );(total-
price;1000)g. note that, s1corresponds to event e2in table 1 and fmap 1is
derived from all historical events of po92.
fig. 4: an example of the proposed approachexplainable predictive decision mining 7
a decision model provides the likelihood of each transition in a decision point
based on a given feature, e.g., when the total price of an order (i.e., feature)
ise1800, standard approval will be performed with the likelihood of 0 :2 and
manager approval with the likelihood of 0 :8.
denition 5 (decision model). letn=(p;t;f;l )be a labeled petri net and
p2pa decision point. let dmap p2p! [0;1]be a decision mapping that
maps decisions to likelihoods such that the sum of all likelihoods adds up to 1,
i.e.,p02pdmap p(p0) = 1 .dpdenotes the set of all possible decision mappings.
dm p2ufmap!dpis the set of all possible decision models of pthat map
feature mappings to decision mappings.
we estimate decision models based on situation tables.
denition 6 (estimating decision models). letn=(p;t;f;l )be a labeled
petri net and p2pa decision point. estimate p2sp!dm pis a function
estimating a decision model from a situation table.
the estimation function can be built using many machine learning algorithms
such as neural networks, support vector machines, random forests, etc.
4.2 online phase
using the decision model derived from the oine phase, we predict the decision
of a running process instance and explain the prediction. using the feature of a
running process instance depicted in fig. 4(b), a decision model may produce
the prediction shown in fig. 4(c), leading to the nal decision of request manager
approval that has the highest likelihood. next, we compute an explanation for the
decision (i.e., the eect of each feature on the prediction) as shown in fig. 4(d),
e.g., total-price has a positive eect of 0 :6 while vendor has a negative eect of
0:2. in other words, total-price increases the likelihood of predicting the decision
ofrequest manager approval by the magnitude of 0 :6 and vendor decreases it by
the magnitude of 0 :2, respectively.
in this work, we use shap values [10] to provide explanations of decisions.
shap values are based on shapley values. the concept of shapley values comes
from game theory . it denes two elements: a game and some players. in the
context of predictions, the game is to reproduce the outcome of the model, and
the players are the features used to learn the model. intuitively, shapley values
quantify the amount that each player contributes to the game, and shap values
quantify the contribution that each feature brings to the prediction made by the
model.
denition 7 (explaining decisions). letfmap2ufmap be a feature map-
ping andf=ff1;f2;:::;f i;:::g=dom(fmap )denote the domain of fmap .
letn=(p;t;f;l )be a labeled petri net, p2pa decision point, and dmpa8 park et al.
decision model. let t2pbe a target transition. the shap value of feature fi
for predicting tis dened as:
 t
fi=x
f0fnffigjf0j!(jfj jf0j 1)!
jfj!(dmp(fmap f0[ffig)(t) dmp(fmap f0)(t))
forfmap ,expdmp;t(fmap ) =f(f1; t
f1);(f2; t
f2);:::gis the explanation of pre-
dictingtusingdmp.
as shown in fig. 4(d), for feature mapping fmap0described in fig. 4(b),
the explanation of predicting t3 (i.e., request manager approval) using decision
modeldm0
p2isexpdm0
p2;t3(fmap0) =f(total-price;0:6);(vendor; 0:2)g. in other
words, total-price has a positive eect with the magnitude of 0 :6 on the decision
oft3 and vendor has a negative eect with the magnitude of 0 :2.
moreover, we can provide a global explanation of a decision model by aggre-
gating shap values of multiple running instances. for instance, by aggregating
all shap values of total-price for predicting t3, e.g., with the mean absolute
value, we can compute the global eect of total price to the prediction.
5 implementation
we have implemented a web application to support the explainable decision
mining with a dedicated user interface. source code and user manuals are avail-
able at https://github.com/aarkue/exdpn . the application comprises three
functional components as follows.
discovering process models. this component supports the discovery of pro-
cess models based on inductive miner [7]. the input is event data of the standard
xes. the discovered accepting petri net is visualized along with its decision
points.
decision mining. this component supports the computation of situation ta-
bles from event logs and the estimation of decision models from the computed
situation table. first, it computes situation tables with the following three types
of features:
{case features : case features are on a case-level and used for predicting all
decisions related to that case.
{event features : event features are specic to an event and used for predicting
decisions after the occurrence of the event.
{performance features : performance features are derived from the log. it in-
cludes elapsed time of a case (i.e., time duration since the case started) and
time since last event (i.e., time duration since the previous event occurred).
next, the estimation of decision models uses the following machine learning
algorithms: random forests ,xgboost ,support vector machines (svms) , and
neural networks .explainable predictive decision mining 9
table 2: f1 scores of applying dierent machine learning algorithms in dierent
decision points. the bold font shows the top two results in each decision point.
event logs bpi challenge 2012 (only oers) bpi challenge 2019 (ltered)
decision point p4 p6 p12 p14 p16 p19 p3 p4 p8 p11
algorithmsdecision tree 0.6888 0.7545 0.7955 0.9633 0.9612 0.9263 0.9555 0.9948 0.8135 1.0000
xgboost 0.7189 0.7897 0.8004 0.9697 0.9612 0.9407 0.9632 0.9948 0.8293 1.0000
support vector machine 0.7151 0.7799 0.8023 0.9701 0.9612 0.9414 0.9649 0.9950 0.8096 0.9997
neural network 0.725 0.8048 0.7955 0.9698 0.9607 0.9317 0.9583 0.9981 0.8191 0.9949
visualizing decisions and explanations this component visualizes the f1
score of dierent machine learning algorithms and suggests the best technique
based on the score. moreover, it visualizes the explanation of the decision both
at local and global levels. local explanations are visualized with force plot (cf.
fig. 5(a)), decision plot (cf. fig. 5(b)), and beeswarm plot (cf. fig. 5(c)), whereas
global explanations are visualized with bar plot (cf. fig. 5(d)), force plot (cf.
fig. 5(e)), and beeswarm plot (cf. fig. 5(f)). we refer readers to [9] for the
details of dierent plots.
6 evaluation
in this section, we evaluate the approach by conducting experiments using the
implementation. specically, we are interested in answering the following re-
search questions.
{rq1: does the advanced machine learning algorithm eciently predict the
decisions?
{rq2: does the approach provides reliable explanations for the predictions?
6.1 rq1: prediction accuracy
in order to answer rq1, we conduct experiments using real-life event logs: busi-
ness process intelligence challenge (bpic) 20123and bpic 20194. for each
event log, we rst discover a process model and determine decision points. then
we estimate dierent decision models for each decision point and compare the
performance of the decision models using 5-fold cross-validation. to measure the
performance of the decision model, we use f1 scores. each model is instantiated
with suitable, event-log-specic parameters, which have largely been obtained
from a parameter grid search on each decision point as well as manual test runs.
for decision tree algorithms, we apply pruning steps to avoid too many splits
that result in decision trees harder to interpret in practice due to their complex-
ity.
table 2 shows the f1 score of dierent machine learning algorithms in dier-
ent real-life event logs5. the top two scores for each decision point are highlighted
3doi:10.4121/uuid:3926db30-f712-4394-aebc-75976070e91f
4doi.org/10.4121/uuid:d06aff4b-79f0-45e6-8ec8-e19730c248f1
5the experimental results are reproducible in https://github.com/aarkue/exdpn/
tree/main/quantitative_analysis along with the corresponding process model.10 park et al.
fig. 5: local explanations : (a) force plot, (b) decision plot, and (c) beeswarm
plot explain how the model arrived at the decision of a running instance (i.e.,
request manager approval with the likelihood of 0 :98). for instance, (a) visualizes
the positive (red-colored) and negative (blue-colored) features with increasing
magnitudes. global explanations : (d) bar plot, (e) beeswarm plot, and (f)
force plot explain how the model arrived at the decision of all running instances
(both on request standard approval andrequest manager approval ). for instance,
(d) visualizes the mean absolute shap value for each feature on predicting
request standard approval (blue-colored bar) and request manager approval (red-
colored bar), showing that total-price has the highest impact on both predictions.
with bold fonts. xgboost shows good scores for all decision points except p14 in
bpic 2012 and p4 in bpic 2019. the scores for support vector machine belongexplainable predictive decision mining 11
to the top two scores for most of the decisions except p4 andp6 in bpic 2012
andp8 andp11 in bpic 2019, whereas the ones for neural network belong to
the top two scores in p4,p6 andp14 in bpic 2012 and p4 andp8 in bpic 2019.
decision tree shows the top two scores only for p16 in bpic 2012 and p11 in
bpic 2019.
6.2 rq2: reliability of explanations
to answer rq2, we design a simulation model to simulate a purchase-to-pay
(p2p) process using cpn tools [12]. the simulation model allows us to fully
dene the decision logic of decision points. based on the decision logic, we qual-
itatively evaluate if the generated explanation is reliable. fig. 6 shows the petri
net discovered using inductive miner [7] from an event log generated by the sim-
ulation model, with highlighted decision points. decision point (c) describes the
decision of whether the purchase order is held at customs or not. the decision
logic in the simulation model is as follows: if 1) a purchase order originates from
outside the eu and 2) the base price per item is higher than e50, the order is
held at customs.
fig. 6: petri net discovered from the simulated p2p event logs
the beeswarm plot in fig. 7(a) explains the decision at decision point (c).
the non-eu origin (high value of origin non eu ) has a strong positive impact
on the probability of being held at customs according to the decision model.
moreover, the existence of items in category odds and ends , which have low
base prices, has a negative impact on the probability, whereas the existence
of items in category electronics , which have high base prices, has a positive
impact on the probability. when the individual product names, categories, and
vendors are excluded (see fig. 7b), the four most impactful features that remain
are exactly the ones used in the logic of the underlying simulation model: the
eu or non-eu origin, the total price and the number of items in the order.
overall the decision logic as interpretable through the plots corresponds to the
underlying logic applied in the simulation model, showing that the explanation
obtained is reliable.
7 conclusions
in this paper, we proposed an approach to explainable predictive decision min-
ing. in the oine phase of the approach, we derive decision models for dierent
decision points. in the online phase, we predict decisions for running process12 park et al.
(a) beeswarm plot visualizing the impact of high or low feature values
on the model probability of being held at customs. the non-eu origin
(high value of origin non eu ) has a strong positive impact on the
probability of being held at customs.
(b) bar plot visualizing the mean absolute shap value of each se-
lected feature, per output class
fig. 7: qualitative analysis showing the explanation plots of decision point (c)
using a neural network model.
instances with explanations. we have implemented the approach as a web appli-
cation and evaluated the prediction accuracy using real-life event logs and the
reliability of explanations with a simulated business process.
this paper has several limitations. first, the explanation generated by the
proposed approach is less expressive than the logical expression generated by
traditional decision mining techniques. also, we abstract from the denition of
features that can be used to construct the situation tables, focusing on explaining
several possible features in the implementation. in future work, we plan to extendexplainable predictive decision mining 13
the approach with a taxonomy of features to be used for the comprehensive
construction of situation tables. moreover, we plan to connect the explainable
predictive insights to actual actions to improve the process.
acknowledgment
the authors would like to thank the alexander von humboldt (avh) stiftung
for funding this research.
references
1. apley, d.w., zhu, j.: visualizing the eects of predictor variables in
black box supervised learning models. corr abs/1612.08468 (2016).
https://doi.org/10.48550/arxiv.1612.08468, https://arxiv.org/abs/1612.
08468
2. bazhenova, e., weske, m.: deriving decision models from process models by en-
hanced decision mining. in: reichert, m., reijers, h.a. (eds.) business process
management bpm workshop 2015. lecture notes in business information pro-
cessing, vol. 256, pp. 444{457. springer (2015). https://doi.org/10.1007/978-3-319-
42887-1 36,https://doi.org/10.1007/978-3-319-42887-1_36
3. frosst, n., hinton, g.e.: distilling a neural network into a soft decision tree. corr
abs/1711.09784 (2017), http://arxiv.org/abs/1711.09784
4. gilpin, l.h., bau, d., yuan, b.z., bajwa, a., specter, m.a., kagal, l.: explain-
ing explanations: an approach to evaluating interpretability of machine learning.
corr abs/1806.00069 (2018), http://arxiv.org/abs/1806.00069
5. goldstein, a., kapelner, a., bleich, j., pitkin, e.: peeking inside the black
box: visualizing statistical learning with plots of individual conditional ex-
pectation. journal of computational and graphical statistics 24(1), 44{
65 (2015). https://doi.org/10.1080/10618600.2014.907095, https://doi.org/10.
1080/10618600.2014.907095
6. greenwell, b.m., boehmke, b.c., mccarthy, a.j.: a simple and eective model-
based variable importance measure. corr abs/1805.04755 (2018), http://
arxiv.org/abs/1805.04755
7. leemans, s.j.j., fahland, d., van der aalst, w.m.p.: discovering block-structured
process models from event logs - a constructive approach. in: colom, j.m., desel,
j. (eds.) petri nets 2013. lecture notes in computer science, vol. 7927, pp.
311{329. springer (2013). https://doi.org/10.1007/978-3-642-38697-8 17,https:
//doi.org/10.1007/978-3-642-38697-8_17
8. de leoni, m., van der aalst, w.m.p.: data-aware process mining: discover-
ing decisions in processes using alignments. in: shin, s.y., maldonado, j.c.
(eds.) 28th annual acm symposium on applied computing. pp. 1454{1461.
acm (2013). https://doi.org/10.1145/2480362.2480633, https://doi.org/10.
1145/2480362.2480633
9. lundberg, s.: shap library documentation. https://shap.readthedocs.io/en/
latest/index.html# , accessed: 05.aug.202214 park et al.
10. lundberg, s.m., lee, s.: a unied approach to interpreting model pre-
dictions. in: guyon, i., von luxburg, u., bengio, s., wallach, h.m., fer-
gus, r., vishwanathan, s.v.n., garnett, r. (eds.) advances in neural in-
formation processing systems 30: annual conference on neural informa-
tion processing systems 2017, december 4-9, 2017, long beach, ca, usa.
pp. 4765{4774 (2017), https://proceedings.neurips.cc/paper/2017/hash/
8a20a8621978632d76c43dfd28b67767-abstract.html
11. mannhardt, f., de leoni, m., reijers, h.a., van der aalst, w.m.p.: de-
cision mining revisited - discovering overlapping rules. in: nurcan, s., sof-
fer, p., bajec, m., eder, j. (eds.) advanced information systems engineer-
ing - 28th international conference, caise 2016, ljubljana, slovenia, june
13-17, 2016. proceedings. lecture notes in computer science, vol. 9694, pp.
377{392. springer (2016). https://doi.org/10.1007/978-3-319-39696-5 23,https:
//doi.org/10.1007/978-3-319-39696-5_23
12. park, g., van der aalst, w.m.p.: towards reliable business process simulation:
a framework to integrate erp systems. in: augusto, a., gill, a., nurcan, s.,
reinhartz-berger, i., schmidt, r., zdravkovic, j. (eds.) enterprise, business-
process and information systems modeling - 22nd international conference,
bpmds 2021, and 26th international conference, emmsad 2021, held at
caise 2021, melbourne, vic, australia, june 28-29, 2021, proceedings. lec-
ture notes in business information processing, vol. 421, pp. 112{127. springer
(2021). https://doi.org/10.1007/978-3-030-79186-5 8,https://doi.org/10.1007/
978-3-030-79186-5_8
13. park, g., van der aalst, w.m.p.: action-oriented process mining: bridg-
ing the gap between insights and actions. progress in articial intelligence
(2022). https://doi.org/10.1007/s13748-022-00281-7, https://link.springer.
com/10.1007/s13748-022-00281-7
14. ribeiro, m.t., singh, s., guestrin, c.: "why should i trust you?": ex-
plaining the predictions of any classier. in: krishnapuram, b., shah, m.,
smola, a.j., aggarwal, c.c., shen, d., rastogi, r. (eds.) proceedings of
the 22nd acm sigkdd international conference on knowledge discovery
and data mining, san francisco, ca, usa, august 13-17, 2016. pp. 1135{
1144. acm (2016). https://doi.org/10.1145/2939672.2939778, https://doi.org/
10.1145/2939672.2939778
15. rozinat, a., van der aalst, w.m.p.: decision mining in prom. in: dustdar, s.,
fiadeiro, j.l., sheth, a.p. (eds.) business process management, 4th interna-
tional conference, bpm 2006, vienna, austria, september 5-7, 2006, proceed-
ings. lecture notes in computer science, vol. 4102, pp. 420{425. springer (2006).
https://doi.org/10.1007/11841760 33,https://doi.org/10.1007/11841760_33
16. safavian, s.r., landgrebe, d.a.: a survey of decision tree classier
methodology. ieee trans. syst. man cybern. 21(3), 660{674 (1991).
https://doi.org/10.1109/21.97458, https://doi.org/10.1109/21.97458