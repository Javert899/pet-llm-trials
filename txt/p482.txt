j. filipe, j. cordeiro, and j. cardoso (eds.): iceis 2007, lnbip 12, pp. 3–15, 2008. 
© springer-verlag berlin heidelberg 2008 inter-enterprise system and application integration:  
a reality check 
jorge cardoso1, wil van der aalst2, christoph bussler3, amit sheth4, 
and kurt sandkuhl5 
1 sap research, dresden, germany 
2 eindhoven university of technology, the netherlands 
3 merced systems, inc., ca, u.s.a. 
4 kno.e.sis center, wright state university, ohio, u.s.a. 
5 jönköping university, sweden 
abstract.  this paper structures the summary of the panel held at the 9th 
international conference on enterprise information systems, funchal, madeira, 
12-16 june 2007 that addre ssed the following question: “are you still working 
on inter-enterprise system and application integration?” the panel aggregated 
distinguished experts from the areas of process management, workflow, web 
services, soa, and semantic web. 
keywords: inter-enterprise integration, business process management, workflow, 
web service, soa, semantic web. 
wil van der aalst 
eindhoven university of technology, the netherlands 
we are creating our own problems, e.g., current 
standardization efforts are only increasing complexity!  
the problem of building enterprise systems (and the glue between these systems) is 
the overwhelming complexity. to set up a contemporary middleware platform is a 
complex task which is further complicated if software from different vendors needs to 
work together. the fundamental idea of web services is sound and promising. 
however, the abundance of overlapping standards for web services composition is 
overwhelming. in fact, the collection of competing and complementary web services 
standards is creating a new tower of babel. standards are proposed without clear 
semantics and before a standard is adopted there are already new standards which 
build on it. the acronym wsah (web services acronym hell) coined in [1] nicely 
illustrates the problem. focus should be on a few good standards; otherwise we are 
creating our own problems. the "not invented here" syndrome reflects the 
unwillingness to adapt standards and products to best practices and sound theories. 
this phenomenon results in people intentionally differentiating things from one 4 j. cardoso et al. 
another rather than using solid, scientifically proven, foundations. for example, new 
process modeling languages are proposed on a daily basis by people unaware of 
foundational concepts such as bismulation, true concurrency, turing completeness, 
petri nets, etc. 
find out what is really going on  before (re)designing a system! 
reality is often very different from what is modeled or what people think. whatever 
representation is used (petri nets, bpmn, uml or any other modeling language), the 
model is an abstraction (i.e., things are left out) and may not reflect reality. the first 
observation (abstraction) is unavoidable and should be accepted as a fact of life. 
however, the second observation is more problematic and should be addressed urgently. 
as long as managers and system designer take a “powerpoint” reality as starting 
point, information systems will remain to have serious alignment problems. 
therefore, it is vital that more efforts are invested into finding out what is actually 
happening. if it is not possible to “catch” reality in a model, then it does not make any 
sense to develop or try to improve enterprise systems. process mining [4] can be a 
valuable tool here. the omnipresence of event logs is an important enabler of process 
mining, i.e., analysis of run-time behavior  is only possible if events are recorded. 
already today systems ranging from cross-organizational systems to embedded 
systems provide detailed event logs. 
do not specify more than strictly needed! 
both organizations and people are autonomous entities that in general behave in a 
reasonable way. however, many systems and standards do not acknowledge this. 
there is a tendency to over-specify things, i.e., to describe in a detailed and procedural 
way what should happen. a nice example is the role of bpel. whilst being a powerful 
language, bpel is of a procedural nature and not very different from classical 
workflow languages e.g., the languages used by systems such as staffware, cosa, 
sap workflow, and ibm websphere mq workflow. hence, it is not clear why 
organizations need to agree on the use of bpel. when an organization subcontracts 
part of it work to other organizations, it seems odd to require that the other parties need 
to enact specific bpel models for their internal processes. yet most of the languages 
proposed for orchestration are of a procedural nature, while it seems obvious that a 
more declarative language is needed [3]. thrust in people and organizations implies an 
under-specification rather than an over-specification of processes. 
let’s make fuzziness explicit! 
related to the above point is the gap between high-level modeling languages and 
executable languages. as an illustration, let us look at the sap reference model. of the 
more than 600 process models in the sap reference model, about 20 percent is incorrect 
in the sense that there are possible deadlocks,  livelocks, etc. these models intend to 
describe how the sap system works and how it should be used. however, the number  inter-enterprise system and applica tion integration: a reality check 5 
of errors shows that there is a complete disconnect between the actual software and 
these models. this nicely illustrates the general problem of going from “powerpoint 
diagrams” to executable models/software. one of the problems is that today’s languages 
are either informal or have some executable interpretation. therefore, the modeling 
process of going from an imprecise model to an executable model cannot be supported 
adequately. it would be good to have single language to specify both things that are 
precise and executable and things that are still vague and left open. making fuzziness 
explicit in models is important to avoid costly misinterpretations.  
christoph bussler 
merced systems, inc., ca, u.s.a. 
if you are still working on inter-enterpris e system and application integration, 
then you should re-evaluate and re-assess your research agenda, because … 
the world moved on 
one current development in the software industry is that the notion of ‘application’ is 
changing in the sense that an application (or software system) does not necessarily 
have to be licensed and locally installed at an organization any more for the sole 
purpose of this one organization. the notion of application service provider (asps), 
who installed a software system and made its interfaces available over the web, also 
changes as software vendors provide the hosting themselves, opening up a very 
different model of software as services (saas), see below. 
a second current development integrates existing web interfaces in new forms 
providing new functionality that has not been available before. the term ‘mash-up’ is 
used for this development and gains significant momentum at this point, see the 
discussion below. the wider development is captured in the term ‘web 2.0’ that clearly 
departs from the notion of simply providing the user interfaces for a single software 
system, but instead becomes the integration point for several types of functions from 
different software systems available remotely over the web infrastructure. 
from an academic research viewpoint th e topic of ‘integra tion’ (application 
integration or inter-enterprise integration) completely failed from the angle of a clear 
conceptual and working model that is agreed upon by the research community (and 
industry for that matter). unlike in the database research community with the 
relational database management system success, the research community around 
integration did never arrive at all to a sound foundation in terms of an appropriate 
conceptual model as basis for further research and industrial development. 
saas (software as a service) 
saas is very distinct from application hosting or making functionality available as 
web services. in a first characterization, saas is a specific engineering aspect for 
software systems that allows multiple tenants be present in the same installation of a 
software system. in fundamental terms, the software system is aware of several 6 j. cardoso et al. 
organizations that have their functionality and data implemented in a single 
installation of the software system. traditionally this meant that the functionality is 
the same across tenants, only their particular data is different. examples of this are 
www.ebay.com where each customer shares the same functionality, but their data 
(e.g. bids, offers, financial power, etc.) is different. in addition to end user 
functionality, middleware services are available in this mode, too, in the meanwhile, 
e.g. amazon s3 or amazon sqs by www.amazon.com. 
this multi-tenant awareness starts extending into the design-time domain where 
the software system configuration can be different for each tenant, but still in the 
same installation of the software system. an example is www.salesforce.com that 
allows customers (tenants) to modify the design-time configuration. so the same 
software system in a single installation supports tenant-specific modification of 
design-time data. 
however, the industry does not stop here. the notion of community is coming into 
the picture in different ways. one is the community of tenants. for example, 
www.xeequa.com allows tenants to form a community, i.e., they are aware of each other 
for mutual benefit. while all share the same functionality, they cooperate at the same 
time. xeequa pushes further by providing a clear model of ‘data ownership’ that goes 
beyond corporate boundaries following the insight that each person has a corporate life 
as well as a professional and private life (and data associated with those roles). 
a second way of community, the developer community, is cultivated by 
www.salesforce.com where the development of the software system functionality is 
not limited to their own employees any more, but opened up to any developer who 
wishes to contribute. the developer goes to www.salesforce.com to develop, test and 
offer to the tenants. this clearly shows that the classical distinction of develop – 
install –use starts changing in fundamental ways. 
in my mind, the community aspect will make all the difference, analogous to  
the effects that can be seen in other web applications like www.amazon.com or 
www.hotels.com where the community provides ratings or other web sites where the 
community starts adding meta-data for the community’s mutual benefit. 
web 2.0 
still outside the corporate software system world, but for sure coming into it sooner or 
later, the web 2.0 development addresses the integration of existing functionality 
available of the web. for example, www.trulia.com or www.zillow.com integrates 
various sources like real estate offerings, spatial maps and financial information into 
one web site. this combination is termed mash-up following the insight that the sum  
is greater then the individual parts. 
www.programmableweb.org is tracking mash-up developments and the number is 
constantly increasing, making this a very important ‘movement’. 
furthermore, the explicit notion of social networks like www.linkedin.com start to 
appear in this space as they can offer ne w type of functionality because of their 
explicit knowledge of social relationships. www.linkedin.com, for example, does not 
only have static forward links (i.e., who is related to me and whom can i reach?), but 
also dynamic backward links (i.e., who l ooked at my social network profile)?  inter-enterprise system and applica tion integration: a reality check 7 
the world really moved on 
in summary, the world really moved on from various viewpoints. in terms of integration 
this means that the entities that require integration changed in their nature quite a bit (as 
in fundamentally) requiring new thoughts and developments around it. the idea that an 
entity represents one organization is left behind completely as well as the notion that 
there is one location for integration for a given company or organization. 
of course, like all developments in it and computer science, it takes time for all 
software systems to follow the saas and web 2.0 model. and some of those software 
systems will never embark on this paradigm. however, the fact that this paradigm is 
picked up in all domains like sales, real estate, human resources, finance, and so on 
makes me believe that it will continue to grow and become main stream. 
meaning of ‘integration’ 
so, if your heart is still in the world of integration, which is not necessarily a bad 
place to be, you need to ask yourself, what does ‘inter-enterprise’ and ‘application’ 
integration mean in this changing world and how the notion of ‘integration’ will 
change going foward? and you need to ask yourself if maybe this time around it 
might be worth-while to put effort into a common conceptual model in the academic 
research community to achieve a similar success as the database research community 
achieved with relational database management systems. 
amit sheth 
kno.e.sis center, wright state university, ohio, u.s.a. 
new world order for interactions across enterprise information 
systems in the flat world 
as the world has become flat (“the world is flat” [5]), the dominance of agriculture 
and then of manufacturing has given way to the dominance of services. businesses have 
changed correspondingly and nowhere more than in their interdependence. a company 
may, for example, outsource not only the non-critical back office operations, the 
production of the components, or even a subassembly, but also the logistics of its entire 
supply chain, which is critical to its operations. increasing interdependence has also led 
to myriad ways a company’s operations, competitive-ness, and profitability are tied to 
those of its suppliers and partners. in terms of business models, many have changed 
from selling products to providing services, even when underlying materials and 
intellectual property are about the same. 
in spite of these drastic changes in businesses, entrenched legacy enterprise 
application systems have evolved slowly, whereas newly developed enterprise 
applications have leapt ahead. we feel that interactions among the applications have 
changed significantly and that the underlying reliance on and realization of processes 
has changed the most and will continue the do so. in 1999 (“processes driving the 8 j. cardoso et al. 
networked economy” [6]), we noted “ so far, most of the attention in information 
systems has gone to data. we believe that this attention will increasingly shift to 
information and knowledge on one hand and processes on the other. the first deals with 
service and product, the second deals with how to effectively support or render it. ”  
in the area of data and data interoperability, we often need to revisit the same 
challenges we addressed a long time ago. for example, recently we revisited work on 
data mapping [7] more than a decade old to address data mediation in web services 
[8]. and, interestingly, we found that while using sawsdl, the newly developed 
semantic web services standard, we were able to reuse the earlier work on data 
mapping with little or no fundamental advances. we can reduce unnecessary revising 
and rehashing of earlier work if we understand the four aspects or levels of 
interoperability: system, syntax, structure, and semantics [9]. although these levels 
have been well discussed (and we hope well understood) in the context of data and 
data interoperability, two difference can be noted: (a) data mediation in the context of 
more dynamic processes (such as dynamic trading processes or adaptive web 
processes referred to in this note) present new challenges not encountered above and 
require increasingly sophisticated use of semantics; and (b) these levels of 
interoperability also apply to processes and process interoperability issues. our view 
is that web services is not “old wine in new bottles.” clearly some of the old 
problems, such as those related to data mediation, resurface in the context of newer 
infrastructure for supporting interopera bility when adapting service oriented 
architecture and web services. however, as we argued in [10], low initial 
complexity, its use of xml, and support for an intrinsic loose coupling architecture, 
etc. provide just the right incremental advances in software componentry to make 
them practically useful, that has now resulted in wide adoption. 
in [6], we also outlined three types of inter-organizational workflows (processes)—
process portal, process vortex, and dynami c trading processes. for non-technical 
reasons there are few examples of process portals and process vortexes, but with the 
highly interdependent and dynamic nature of businesses and their interactions with 
global partners and suppliers, we see the increasing importance and relevance of and 
research in dynamic trading processes. this  has involved recognizing the events that 
affect a process [11] and how optimally to ad apt a process once an event relevant to it 
has been identified (“adaptive web processes” [12]).  
let us now turn our attention to the role of humans in enterprise information 
systems and inter-organizational processes. although automation and process 
technologies have reduced the role of humans in repetitive and mundane tasks, 
humans as well as organizations play integral and increasingly sophisticated roles in 
managing processes. consider a supply chain process that has technical capabilities to 
adapt to relevant events such as curren cy fluctuation or a fire at a supplier’s 
fabrication plant. in addition to the challenges of adapting to optimize cost and time 
factors, the business also needs to keep a keen eye on risks associated with different 
choices. this requires decision makers to be integral to the inter-organizational 
process. and for a process in service business, allocation of human resources needs an 
integral model of the organizational structures of both the enterprise and its partners. 
ibm has recently outlined the notion of services science, which emphasizes the need 
to model not only technical but also human and organizational aspects of systems 
(including enterprise information systems and processes) that support services.  inter-enterprise system and applica tion integration: a reality check 9 
in the context of services science, we have outlined a semantic services science 
(3s) model [13], which seeks to demonstrate the essential benefits of semantics to the 
broader vision of services science, with service descriptions that capture technical, 
human, organizational and business-value aspects. we asserted that ontology-based 
semantic modeling and descriptions can be us ed to energize services across the broad 
service spectrum. in this article, we demonstrate how the 3s approach could be used 
along three points in this spectrum: (1) semantic descriptions of standard web 
services with the help of sawsdl, semantic policies, and agreements; (2) semantic 
descriptions of lightweight web services using web 2.0 technologies (e.g., rest, 
ajax); and (3) ontology-based profiling of people and organizational aspects of the 
assets associated with the knowledge services. 
the use of semantics for data interoperability and integration was discussed in the 
1980s. we now see the emergence of an era in which the use of semantics will be 
much more pervasive, spanning interoperability related to middleware, data, services, 
and process within and across enterprises. this is coupled with advanced technical 
capabilities associated with semantic web and semantic web services, as well as a 
better understanding of how to apply both weaker forms of semantics (also called 
“little semantics”), incorporating folkonomies and limited agreements in social 
communities, and deep semantics encapsulated as domain ontologies involving 
domain knowledge and agreement across scientific and business communities that are 
captured in formal languages. 
kurt sandkuhl 
jönköping university, sweden 
it is an illusion to believe we will ever solve all interoperability 
problems!  
the main challenges when creating integration and interoperability between enterprise 
systems is to overcome heterogeneity. on all levels between enterprises, we see various 
and incompatible elements, including the it infrastructure, applications, business proc-
esses, or information and knowledge models. integration and interoperability require an 
understanding of objectives to reach and technical basis. 
despite all progress made during the last decades, integration and interoperability 
will continue to be challenges. it is an illusion to believe that we will ever solve all 
interoperability problems. some reasons for this are: 
• the providers of enterprise systems and it infrastructure components are market 
actors like all other “for profit” companies. these companies will continue 
developing innovative products. if they are commercially successful, others will 
offer similar solutions for the same problem, and – if commercially successful - 
create the next interoperability challenge. interoperability and integration are 
only a strategic issue for enterprise system developers, if their market position 
and competitiveness is improved. as long as the own products have unique 
selling points and functionality, why open them too early for interoperation?  10 j. cardoso et al. 
• standards only partially solve the problem. many official standards are based on 
de-facto industrial standards implemented much earlier than the official 
standardization takes place. furthermore, the knowledge about existing standards 
and their implementation is often insufficient. standards are like other products: 
only if they meet their “market window” they will be successful. 
• legacy systems increase complexity. old enterprise systems in many cases are 
highly optimized and highly productive. to replace these “legacy systems” with 
up-to-date solutions often can not be motivated, neither from an economic nor 
from a technical perspective. but inter-enterprise integration and interoperability 
has to include these legacy systems lead ing to increased complexity. and we are 
creating new legacy every day. today’s highly sophisticated soa systems will in 
15 years from know be considered legacy. 
understand the driving forces before integrating systems! 
when discussing about the battle of interoperability, how successful this has been in 
the past and whether existing technologi es are adequate for solving contemporary 
challenges, we have to agree on the perspective of the discussion. driving forces 
typically found in industries and public authorities are: 
 
• automation of routine processes 
• new laws and regulations requiring and integration of earlier separated applications 
• improvement of customer service 
• improvement of decision support on operative and management level 
• reduction of lead times and duration of business processes or production processes 
 
for all these areas, there are lots of examples for successful integration of systems and 
applications or for creating interoperability. understanding the driving force for 
integration and interoperability will help to reduce complexity and increase the 
probability for success. 
think in long-living infrastructures! 
what should we do differently when working on interoperability and integration in 
networked enterprises? any successful contribution to inter-enterprise system and 
application integration will be long-living (otherwise it cannot be considered 
successful) and has to be designed for this purpose. industry areas like banking, 
insurance, energy or automotive show that enterprise systems with an age of 20 years 
or more can still fulfill their purpose. a key feature of long-living systems is the 
design for maintainability, which often includes separation from business logic and 
implementation platform. let us not design interoperability and integration solutions 
just for a single technology. furthermore, inter-enterprise integration should be 
designed as infrastructures, not as solitary solutions for specific enterprises. 
infrastructures have to be scalable, offer a high availability and provide means for 
managing service levels, including performance management, security management 
and configuration management.  inter-enterprise system and applica tion integration: a reality check 11 
this was just the beginning! 
networking of systems and applications for inter-enterprise integration is just the 
beginning. several industrial areas work on integration of knowledge structures, both 
process knowledge and product knowledge. to develop a new product or service 
usually requires various competences including traditional service and engineering 
fields (electrical, mechanical, computer, material, etc.) and contributions from 
financial and service sectors. even multi-national enterprises often do not have all 
these competences in-house. the resulting need for cooperation leads in times of a 
global economy to collaboration and competition at the same time: in one project, a 
development partner might be a contributor to developing a new product or service, in 
another context this same partner might be allied with a competitor. 
the integration of all stakeholders into a flexible and dynamic organization cover-
ing the complete lifecycle of products or services and of the associated business 
services will create new challenges for inter-enterprise integration. 
jorge cardoso 
sap research, dresden, germany 
devise conceptual “n odes” instead of “leaves” solutions! 
given a problem, such as the inter-enterprise integration of systems and applications, 
the generation of a solution can be categori zed, contextualized and explained using a 
tree structure. let us assume that a tree structure can represent the solution space for a 
particular problem. the root node and the nodes represent conceptual solutions. on 
the other hand, leaves symbolize the actual implementation of a system to solve a 
given problem. nodes describe generic solutions that can be applied to solve recurring 
problems, within a defined context. a generic solution  means that a node does not 
define a specific solution. rather, it identifies the set of problems that can be solved 
with a specific conceptual approach. its influence is derived from the fact that it is an 
abstraction that can be re-used transversely in a large number of situations. nodes are 
useful to solve recurring problems when the problem is not unique, and are most 
useful when the problem occurs often. the defined context means that it is necessary 
to put bounds on a generic solution represented by nodes since there are no 
universally true solutions. it is necessary to understand the circumstances in which 
this generic solution is suitable. it is also important to elaborate on it to create specific 
designs that will be represented by leaves. we believe that sound and generic 
solutions have not been found yet to devise intra- and inter-eai systems since 
vendors and academia has been focused on “leaves” instead of focusing on “nodes.”  
current eai, wfm, and erp systems are “leaves”! 
having illustrated the relationships between generic and specific solutions we can 
analyze the development and adoption of inter-enterprise system and application inte-
gration. eai (enterprise application integration), workflow management (wfm),  
 12 j. cardoso et al. 
 
fig. 1.  top 10 eai vendors [1] 
and erp (enterprise resource planning) solutions have typically been developed as 
“leaves” implementations without first investing on the development of conceptual 
models for “nodes”. this means that the systems, languages and tools that were 
developed lacked conceptual and theore tical foundations. typically, no generic 
solutions to solve recurring problems within a defined context were developed. as a 
result, we are daily faced with an endless number of incompatible integration manage-
ment systems (e.g. ibm mqseries family, bea elink, sun forte fusion, tibco, 
vitria businessware, etc), a vast variety of languages to describe processes models 
(e.g. bpel, bpml, wsfl, xlang, xpdl, bpmn, etc), and a broad diversity of 
isolated non-interoperable tools specific to integration systems (tools for design, 
administration, simulation, analysis, planning, scheduling, etc). 
figure 1 shows the plethora of eai systems available in the market. each solution 
uses internal models and architectures, and very often the languages to define 
processes are proprietary. this situation gives rise to the worldwide promotion of 
islands of intra-enterprise integration solutions without supporting the inter-enterprise 
interoperability of systems. eai suffered and suffers from a lack of standardized 
practices during early implementation that lead to reduced outcomes and strong 
disappointments. 
is there any bright future for eai solutions? 
while the set of eai solutions available in the market suffers from a lack of strong 
foundations and conceptual models, the eai software license market is expected to 
reach $4.9 billion by  2012 [1]. this represents a growth of more than 300% in 7 
years, since in 2005 the market was evaluated in $1.4 billion. the driving force for 
this growth has been linked with the adoption of the internet as a channel to conduct 
business (i.e. e-commerce and b2b). therefore, while there are some concerns with 
respect to the soundness of the theoretical foundations of eai, wfms, and erp 
systems, from an academic perspective, it is clear that these systems will continue to 
find a strong acceptance in the industry.   inter-enterprise system and applica tion integration: a reality check 13 
eai solutions will eventually adopt and use semantics 
semantic inter-enterprise interoperability is the key for the implementation of the idea 
of a knowledge based economy where networks of enterprises (and sme – small to 
medium sized enterprises – in particular) can gain advantages from the peculiarities of 
the productive fabric (many small companies, highly specialized, closely connected 
with each other, highly flexible thanks to the diffusion of knowledge and very skilled 
people in the whole fabric). world-class competitiveness of enterprises strongly 
depends, in the future, on their ability to rapidly build dynamic networked enterprises. 
novel technologies for interoperability within and between enterprises need to 
emerge to radically solve a problem that has not been addressed by the research 
community before.  
as integration becomes multifaceted, more complex, and crosses organizations’ 
boundaries, there will be an increasing need to make sense of hundreds of data stores, 
tables and attributes. nowadays, the data managed by organizations is stored in 
various types of schemas and using different terminologies for data assets. as a result, 
the creation of a common terminology for information is fundamental for establishing 
a strategic integration infrastructure. let us consider the following example. intel 
corporation has 12 factories, assembly an d test facilities worldwide. to take 
advantage of the latest technological de velopments, intel processed electronically 
more than 60% of materials transactions and 85 % of customer orders. the critical 
goal for intel is to timely and accurately manage the production flow throughout the 
manufacturing network. in practice this is a hard task to achieve since the various 
information systems spread among the manufacturing network have strong semantic 
differences. for example, depending on the country, materials are categorized using 
different taxonomies. as a result, information systems have difficulties in 
communicating. these difficulties can be alleviated by using a semantic approach that 
we will be analyzing in the following sections. 
today, integration is a top priority for many european and worldwide enterprises 
and most organizations have already realized that the use of semantic web 
technologies is the best solution to support cross-organizational cooperation for sme 
that operate in dynamically changing work environments.  semantic web technologies 
are already viewed as a key technology to resolve the problems of interoperability and 
integration within the heterogeneous world of ubiquitously interconnected systems 
with respect to the nature of components, standards, data formats, protocols, etc. 
moreover, we also believe that semantic web technologies can facilitate not only the 
discovery of heterogeneous components and data integration, but also the communica-
tion, coordination and collaboration behavioral of employees and individuals. 
enterprise application and human integration 
the semantic web relies on the theoretical research done in the context of ontologies 
as a formal support for treating the semantic-sharing and interoperability problems. 
ontology-based human integration aims at reducing and eliminating terminological 
and conceptual confusion by defining a shared understanding, that is, a unifying 
framework enabling communication and cooperation amongst people in reaching 14 j. cardoso et al. 
better inter-enterprise organization. presently, one of the most important roles 
ontology plays in communication is that it provides unambiguous definitions for 
terms used in a software system, but semantic needs to be applied rapidly to human 
integration to enable communication, coordination, and cooperation. the use of 
ontologies for improving communication has already had been shown to work in 
practice. interesting examples of successful ontologies include the disease ontology1 
(a hierarchical and controlled vocabulary for human disease representation), the fao2 
(food and agriculture organization of the united nations) – which is committed to 
help information dissemination by providing consistent access to information for the 
community of people and organizations – and the open edi ontology3 which defines 
the ontology for data management and interchange between enterprises.  
references 
1. van der aalst, w.m.p.: don’t go with the flow: web services composition standards 
exposed. ieee intelligent systems 8(1), 72–76 (2003) 
2. van der aalst, w.m.p., dumas, m., ter hofstede, a.h.m.: web service composition 
languages: old wine in new bottles? in: chroust, g., hofer, c. (eds.) proceeding of the 
29th euromicro conference: new waves in system architecture, pp. 298–305. ieee 
computer society, los alamitos (2003) 
3. van der aalst, w.m.p., dumas, m., ter hofstede, a.h.m., russell, n., verbeek, h.m.w., 
wohed, p.: life after bpel? in: bravetti, m., kloul, l., zavattaro, g. (eds.) epew/ws-
em 2005. lncs, vol. 3670, pp. 35–50. springer, heidelberg (2005) 
4. van der aalst, w.m.p.: process mining and monitoring processes and services: workshop 
report. in: leymann, f., reisig, w., thatte, s.r., van der aalst, w.m.p. (eds.) the role of 
business processes in service oriented architectures, schloss dagstuhl, germany, july 
2006. dagstuhl seminar proceedings. internationales begegnungs- und forschungszentrum 
fuer informatik (ibfi), vol. 6291 (2006) 
5. friedman, t.: the world is flat: a brief history of the twenty-first century. douglan 
and mcintyre, ltd (2005) 
6. sheth, a., aalst, w., arpinar, i.: processes driving the networked economy. ieee 
concurrency 7(3), 18–31 (1999) 
7. kashyap, v., sheth, a.: schematic and semantic similarities between database objects: a 
context-based approach. very large data bases (vldb) journal 5(4), 276–304 (1996) 
8. nagarajan, m., verma, k., sheth, a., miller, j., lathem, j.: semantic interoperability of 
web services - challenges and experiences. in: proc. of the 4th ieee intl. conference on 
web services, chicago, il, september 2006, pp. 373–382 (2006) 
9. sheth, a.: changing focus on interoperability in information systems: from system, 
syntax, structure to semantics. in: goodchild, m.f., egenhofer, m.j., fegeas, r., 
kottman, c.a. (eds.) interoperating geographic information systems, pp. 5–30. kluwer 
academic publishers, dordrecht (1999) 
10. sheth, a., miller, j.a.: web services: technical evolution yet practical revolution? in: 
web services: been there, done that? ieee intelligent systems, trends & 
controversies, pp. 78–80 (january/february 2003) 
                                                           
1 http://diseaseontology.sourceforge.net 
2 http://www.fao.org/agris/aos/ 
3 http://www.jtc1sc32.org/, known as iso/iec jtc 1/sc 32  inter-enterprise system and applica tion integration: a reality check 15 
11. gomadam, k., ranabahu, a., ramaswamy, l., sheth, a., verma, k.: a semantic 
framework for identifying events in soa. in: intl conference on web services (icws) 
(2007) 
12. verma, k., sheth, a.: autonomic web processes. in: benatallah, b., casati, f., traverso, 
p. (eds.) icsoc 2005. lncs, vol. 3826, pp. 1–11. springer, heidelberg (2005) 
13. sheth, a., verma, k., gomadam, k.: semantics to energize the full services spectrum. 
communications of the acm (cacm) sp. issue on services science 49(7), 55–61 (2006) 
14. wintergreen research inc.,  http://www.wintergreenresearch.com/ 