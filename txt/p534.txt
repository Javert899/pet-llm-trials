context aware trace clustering: towards improving process mining
results
r. p. jagadeesh chandra bose¤ywil m.p. van der aalst¤
abstract
process mining refers to the extraction of process models
from event logs. real-life processes tend to be less struc-
tured and more °exible. traditional process mining algo-
rithms have problems dealing with such unstructured pro-
cesses and generate spaghetti-like process models that are
hard to comprehend. an approach to overcome this is to
cluster process instances (a process instance is manifested
as a trace and an event log corresponds to a multi-set of
traces) such that each of the resulting clusters correspond to
a coherent set of process instances that can be adequately
represented by a process model. in this paper, we propose a
context aware approach to trace clustering based on generic
edit distance. it is well known that the generic edit dis-
tance framework is highly sensitive to the costs of edit op-
erations. we de¯ne an automated approach to derive the
costs of edit operations. the method proposed in this paper
outperforms contemporary approaches to trace clustering in
process mining. we evaluate the goodness of the formed
clusters using established ¯tness and comprehensibility met-
rics de¯ned in the context of process mining. the proposed
approach is able to generate clusters such that the process
models mined from the clustered traces show a high degree
of ¯tness and comprehensibility when compared to contem-
porary approaches.
1 introduction
process mining techniques can deliver valuable, factual
insights into how processes are being executed in real
life. process mining refers to the extraction of process
models from event logs [1]. an event log corresponds to
a bag of process instances of a business process. a pro-
cess instance is manifested as a trace (a trace is de¯ned
as an ordered list of activities invoked by a process
instance from the beginning of its execution to the end).
real-life processes tend to be less structured and more
°exible. traditional process mining algorithms have
problems dealing with such unstructured processes and
¤department of mathematics and computer science, univer-
sity of technology, eindhoven, the netherlands
yphilips healthcare, veenpluis 4-6, 5684 pc best, the nether-
landsgenerate spaghetti-like process models that are hard
to comprehend. this is caused by the application of
discovery algorithms without preprocessing raw traces.
since traces are captured for each execution of the
system, there can be instances where the system is
subjected to similar execution patterns/behavior, and
instances where unrelated cases are executed. consid-
ering the set of traces in the event log all at once might
lead to ambiguities for the mining algorithms which
often result in spaghetti-like models. an approach to
overcome this is to cluster the traces such that each of
the resulting clusters corresponds to a coherent set of
cases that can be adequately represented by a process
model. figure 1 illustrates the signi¯cance of trace
clustering in process mining. the process model on the
top right of figure 1 is a process model mined from
the entire event log. the model is quite complex to
comprehend. the bottom rectangle of figure 1 depicts
the process models mined from clustered traces. it is
evident that clustering enables the comprehension of
process models by reducing the spaghetti-ness.
figure 1: signi¯cance of trace clustering in process
mining
the basic principle in clustering is to de¯ne a notion
of similarity or dissimilarity between traces and then
partition the event log into k-clusters (for some k¸2)such that all traces within a cluster ciare similar
in some sense, and traces belonging to two di®erent
clusters are dissimilar. the goodness of the formed
clusters is largely dependent on the notion of similarity
used. a poor choice of similarity metric can lead to
bad clusters. we de¯ne two notions of goodness from
a process mining perspective. process mining on traces
from good clusters should generate models that have a
(i) high degree of ¯tness and (ii) low degree of structural
complexity (less spaghetti like). fitness quanti¯es how
much of the observed behavior is captured in the model.
traditional approaches (to trace clustering) in the
literature were con¯ned to transforming the traces into
a vector space and using a pool of clustering tech-
niques (agglomerative hierarchical clustering, k-means
clustering etc) with di®erent distance metrics in the
vector space (euclidean distance, jaccard distance etc).
in this paper, we propose a new approach to trace
clustering based on generic edit-distance and show that
the proposed approach outperforms other approaches in
that it partitions the traces into clusters such that the
process models mined from those clusters show a high
degree of ¯tness and that the models are more compre-
hensible. edit-distance is sensitive to the cost function
(of edit operations). in this paper, we de¯ne a method
to automatically derive the cost function and show that
the cost function thus derived has semantic signi¯cance.
philips healthcare looks at process mining as a
tool to deliver a powerful set of solutions for providing
factual and appropriate insights into their product
usage, and believes that the insights gained would
enable them to build e±cient and customer-focused
product designs and maintenance processes. philips
healthcare collates logs from their medical systems
across the globe. these logs contain information about
user actions, system events etc. the number of such
log-recording systems in conjunction with the ¯ne
grained nature of logging makes the data available not
just huge, but massively huge. trace clustering assumes
utmost importance in dealing with such voluminous
data.
the rest of the paper is organized as follows. section
2 de¯nes the notations used in the paper. in section
3, we discuss various approaches to trace clustering by
highlighting the advantages and pitfalls of each. in
section 4, we present an algorithm to derive the cost
function for the generic edit distance framework. sec-
tion 5 presents the clustering approach and introduces
the metrics used to evaluate the goodness of clusters.
in section 6, we present and discuss the experimentalresults. related work is presented in section 7. finally,
section 8 concludes with remarks on future directions.
2 notations
letadenote the set of activities. jajis the number of
activities.
a+is the set of all non-empty ¯nite sequences of
activities from a. a trace, tis an element of a+.
the set of all n-length sequences over the alphabet a
is denoted by an. a trace of length nis denoted as tn
i.e.,tn2 an, andjtnj=n.
the ordered sequence of activities in tnis denoted
ast(1)t(2)t(3): : : t(n) where t(k) represents the
kthactivity in the trace. alternatively, for readability
purposes, we also denote the trace tnas an ordered
list of activities ( t(1); t(2); t(3); : : : ; t (n)).
tn¡1denotes the subsequence of tnwith the ¯rst n¡1
activities. in other words tn=tn¡1t(n).
a trace, t, without a superscript denotes an arbitrary
length trace, i.e., t2 a+.
an event log, l, corresponds to a multi-set (or bag) of
traces from a+.
as an example, let a=fa;b;cgbe the set of ac-
tivities; jaj= 3. t=abcabb is a trace of length 6.
t(1)= a,t(2)= b,t(3)= c,t(4)= a,t(5)= b,t(6)= b.
t(2;5) = bcab is a subsequence of tfrom positions 2
to 5. l=faba;aba;abba;baca;acc;cacgrepresents
an event log.
3 approaches to trace clustering: issues and
challenges
3.1 bag-of-activities approach one of the most
often used techniques for analyzing (clustering) traces is
to transform a trace into a vector, where each dimension
of the vector correspond to an activity [6], [7], [12]. the
set of all activities present in the event log de¯nes the
number of dimensions of the vector. for each trace,
the values of the vector correspond to the frequency
count of the activities in that trace. for example, the
traces abaac and badca correspond to the vectors [3,
1, 1, 0] and [2, 1, 1, 1] respectively; the dimensions of
the vector being [ a,b,c,d ]. similarity between traces
is then estimated using the standard distance metrics
(such as the euclidean distance) in the vector-space
model. this transformation, referred to as a bag-of-
activities transformation has a few drawbacks:
1.lack of context information: process execution is
characterized by a context. the bag-of-activities
representation does not capture the dynamics of
process execution. as an example, consider a
process model with a noti¯cation activity. thedi®erent instances of noti¯cation within a trace
might have di®erent connotations based on the
context in which it is invoked. for example, a
broad-cast noti¯cation, noti¯cation of information,
noti¯cation requesting a response.
2.order of execution: the bag-of-activities represen-
tation also loses the information on the order of
execution of events. any permutation of the bag
of activities of a given trace has the same vector
representation and thereby has a distance of 0 with
each other. however, in reality, a lot of these per-
mutations do not make any sense from a process
de¯nition point of view. for example, one cannot
write to a ¯le until the ¯le is opened . even in
cases where it makes sense, they might represent
two di®erent use-cases.
3.2 k-gram model one means of incorporating con-
text into the vector space model is to consider subse-
quences of activities. these subsequences capture the
order of execution as well. however, it is important to
note that the notion of context can be much more than
a mere order of execution of activities. henceforth, we
refer to a subsequence of kactivities as k-gram. for
the trace abacaab , the set of 2 ¡grams correspond to
fab,ba,ac,ca,aa gwhile the set of 3-grams correspond
tofaba,bac,aca,caa,aab g. one can transform a trace
into a vector in the k-gram model, which now incor-
porates certain context information. the clustering of
traces is then performed in the k¡gram space. how-
ever, it is to be noted that the size of this model in-
creases drastically as the size of the alphabet jajandk
increase. for a system with 100 activities and consid-
ering 3-grams, we end up with potentially 1003= 106
dimensions. in reality, one may not see all combina-
tions of 3-grams in the event log; thus the number of
dimensions would be less than 106. nonetheless, work-
ing in the k-gram space incurs a huge computational
overhead. in addition, selecting a suitable value for kis
non-trivial.
3.3 hamming distance while the vector-space
model falls under the statistical processing domain,
hamming distance and edit-distance [2] are two of the
most often used syntactic methods in text mining to
quantify the (dis-)similarity of two words/sequences.
hamming distance, de¯ned for two sequences of equal
length measures the count of character positions in
which the two sequences di®er. for the sequences
abacaab and abcaaba , the hamming distance is equal
to 4, since the two sequences di®er at positions 3 ;4;6
and 7. one can adopt hamming distance to event log
traces; instead of counting the character positions thatdi®er, one now needs to count the activities that di®er
at a position. this notion though useful in certain cases,
is not °exible enough for a majority of event traces due
to the following reasons:
i.hamming distance is not de¯ned for sequences of
di®erent lengths. in reality, event traces will have
di®erent lengths.
ii.even in cases where hamming distance is de¯ned,
two traces from the same process model can man-
ifest di®erently. interleaving of activities in two
traces are punished too strongly in hamming dis-
tance.
3.4 edit distance another fundamental mea-
sure of (dis-)similarity between two sequences is the
levenshtein distance, also called as edit distance.
levenshtein distance between two sequences is de¯ned
as the minimum number of edit operations needed to
transform one sequence into the other, where an edit
operation is an insertion, deletion or substitution of an
element. consider two sequences sandt2 a+.sand
tmay contain (a) symbols common to both of them,
(b) symbols present only in sand (c) symbols present
only in t. for example, consider the two sequences
s=teach andt=tricky ,jsj= 5 and jtj= 6. s
andthave the symbols tand cin common. a,eand
hare symbols present only in swhile i,r,kand y
occur only in t. a transformation of sequence sto
sequence twill be the set of editing operations applied
to one of the sequences iteratively, which transform s
intot. there are many possibilities in which one can
transform sintot. one can delete symbols that occur
only in sand insert symbols that occur only in tor
one can replace certain symbols in swith symbols in
t.
for two sequences sand t, the following edit
operations are considered on the alphabet a [ f¡g ,
where ¡denotes a gap. for a; b2 a, the pair
²(a; a) denotes a match of symbols between sand
tat some position s(i) and t(j). a match can be
considered as a substitution of a symbol with itself.
²(a;¡) denotes the deletion of ainsat some
position s(i)
²(¡; b) denotes the insertion of bins
²(a; b) denotes the replacement/substitution of ain
swith bat some position s(i) where a6=b
for the above example sequences sandt, the following
sequence of edit operations can transform sinto t:(t,t)(-,r)(e,-)(a,i)(c,c)(h,k),(-,y). the edit distance
framework works by assigning a cost or weight for each
of the edit operations de¯ned above. the advantage
of using edit distance is that it considers a trace in
totality thereby preserving the context and ordering.
more formally, the generic string edit distance
can be characterized by a triple <a;b; c >1consisting
of ¯nite alphabets aandband the primitive cost
function c:e! <+where e=ed[ei[edis the
set of primitive edit operations on the alphabets and
<+is the set of nonnegative real numbers. es=a £ b
is the set of substitutions, ed=a £ f¡g is the set of
deletions, and ei=f¡g£b is the set of insertions. the
distance between two strings smandtn,sm2 am,
tn2 bn(m¸1; n¸1), can be de¯ned as:
(3.1)
dc(sm; tn) =min8
><
>:c(s(m); t(n)) +dc(sm¡1; tn¡1);
c(s(m);¡) +dc(sm¡1; tn);
c(¡; t(n)) +dc(sm; tn¡1)
when either m= 0 or n= 0, only insertion/deletion
operations are de¯ned. we denote s0=t0=¡; thus
dc(sm;¡) =c(s(m);¡) +dc(sm¡1;¡); m¸1
dc(¡; tn) =c(¡; t(n)) +dc(¡; tn¡1); n¸1
dc(¡;¡) = 0;(3.2)
the levenshtein distance is a speci¯c case of the generic
edit distance . in the levenshtein distance, a unit cost
model is used for the edit operations. in other words,
under levenshtein distance, c(a;a) = 0, c(a;¡) =
c(¡;a) = 1, and c(a;b) = 1 for a6=b. consider two
strings s=abcac andt=acacad . the levenshtein
distance between sandtis 3. the sequence of edit
operations transforming stotcan be visualized as an
alignment between sandtand is depicted in figure 2.
s: a b c a c − − 
t: a − c a c a d
figure 2: sequence of edit operations transforming s to
t depicted as an alignment
levenshtein distance, though noteworthy for its simplic-
ity, does not ¯t in many application scenarios. consider
our case of event log traces, and the following scenarios
in diagnosing a patient using a cardiovascular medical
system:
²for the event traces t1= ( setphysician,
setpatienttype, startexamination,
1in most applications, a=baddexamination, stopexamination ) and
t2 = ( setpatienttype, setphysician,
setoperatorname, stopexamination,
addexamination ), the levenshtein distance
would be 5. figure 3 depicts two transformations
with levenshtein distance of 5. however it is
to be noted, from an application point of view,
the sequence of events in traces t1andt2can
be abstracted to presetting and examination
functionality. the set commands belong to
presetting while the rest to examination .
also (a) it really may not matter whether the
physician is set ¯rst or the patient (b) one
cannot stop an examination that is not started
and (c) all examination commands should be
enclosed between start andstop commands.
²now, consider another trace t3 =
(movedetectorfrontal ,angulatebeamfrontal ,
rotatebeamfrontal ,selectinjectorcontrol ).
the levenshtein distance between t1andt3is 5.
the levenshtein distance between t2andt3is
also 5. although t3represents a characteristically
distinct functionality when compared to t1and
t2, clustering based on the levenshtein distance is
likely to put all the three traces in a single cluster.
in other words, levenshtein distance does not consider
the functional validity of any edit operation. also, two
sequences of lengths n1andn2, irrespective of their
similarity, will always have a levenshtein distance of at
leastjn1¡n2j, where jnjdenotes the absolute value of
n. it is quite natural that event log traces would be of
di®erent length. the levenshtein distance applied as
is, would give a non-zero distance for two traces that
are functionally similar. for example, consider the two
traces abacd and abacacacd . these two traces are
similar in that they would have been generated from
the same process model where there is a loop construct
over the activities ac. ideally, one would like to put
these two traces in the same cluster. however, if we
apply levenshtein metric, we get a distance of 4. one
should consider the manifestations of process model
constructs to alleviate such problems.
in order to avoid edit operations that do not make sense
in a certain context, the cost function, c, needs to be
more robust. substitution of uncorrelated/constrasting
activities or insertion/deletion of activities not con-
¯rming to a context should be penalized heavily. on
the other hand, `like' events should be allowed to be
replaced/inserted at a minimal cost. however, deriving
such costs is nontrivial unless provided by a domain
expert. in the next section, we propose an approachsetphysician setpatienttype startexamination addexamination stopexamination
setpatienttype setphysician setoperatorname stopexamination addexaminationa.
setphysician setpatienttype startexamination addexamination stopexamination
setpatienttype setphysician setoperatorname stopexamination addexaminationb.figure 3: di®erent transformations with a levenshtein distance of 5
to automatically derive the edit operation costs from
event log traces and show that the derived costs have
statistical as well as semantic signi¯cance.
4 deriving substitution and indel costs
distance and similarity measures are interchangeable in
the sense that a small distance means high similarity,
and vice versa. for two sequences smandtn(m¸
1; n¸1), the edit distance (3.1) de¯ned in section 3.4
can be transformed to a similarity function de¯ned as
in (4.3).
(4.3)
sim(sm; tn) =max8
><
>:s(s(m); t(n)) +sim(sm¡1; tn¡1);
i(s(m);¡) +sim(sm¡1; tn);
i(¡; t(n)) +sim(sm; tn¡1)
s: (a £ b )! < de¯nes the substitution scores.
s(s(m); t(n)) de¯nes the score for substituting s(m)
with t(n).ide¯nes the indel (insertion/deletion)
scores. i(s(m);¡) de¯nes the score for deleting
s(m) while i(¡; t(n)) de¯nes the score for inserting
t(n). on similar lines of (4.3), one can transform
(3.2) for the base condition when either m= 0 or n= 0.
in this section, we derive the scores for substitu-
tion and insertion/deletion of symbols for similarity
rather than the costs for distance . before we discuss
the algorithm, let us ¯rst lay down the characteristics
that a substitution and indel scoring matrix should
hold:
1.substitution of uncorrelated activities should be
discouraged
2.substitution of contrasting activities should be pe-
nalized
3.insertion of activities out of context should be
discouraged
4.substitution of correlated/similar activities should
be encouraged in proportion to the degree of simi-
larity
the basic idea of substitution matrix derivation is to
compare the actual observed frequency of a pair of
activities sharing a particular context to their expected
frequency of co-occurrence if they occur independently.we use the set of 3-grams in the event log as a notion
of context. in other words, we need to estimate:
1.the probability of observing an activity in the set
of all contexts
2.the probability of observing a pair of activities that
can occur within the same context
4.1 substitution scores algorithm 1 presented
in this section generates the substitution scores. it
is to be noted that this algorithm tries to maximize
the score of two sequences based on the similarity. in
other words, it derives scores for substitution such that
sequences that are similar attains a high score and
sequences that are not similar gets a low score. the
edit-distance on the other hand assigns a low value for
similar sequences. we will later de¯ne a transformation
between the similarity score and the distance value.
let us discuss the fundamental steps of the algorithm
(steps 2 to 5) with an example. consider the event
log,l=faabcdbbcda ,dabcdabcbb ,bbbcdbbbccaa ,
aaadabbccc ,aaacdcdcbedbccbadbdebdc gover the
alphabet a=fa;b;c;d;eg. the set of all 3-grams
overlisg3=faaa,aab,abb,aac,aad,abc,bad,
bbb,bbc,bcd,bed,caa,cba,cbb,cda,cdb,dab,dbb,
dbc,dbd,ebd,. . .g. the corresponding frequencies
of the 3-grams is represented by the vector f3=
[2;1;1;1;1;3;1;2;4;4;1;1;1;1;2;2;3;2;1;1;1; : : :]. the
set of contexts of symbol a,xa=faa,ab,ac,ad,
bd,ca,dbg. similarly, the set of contexts for symbol
b,xb=fab,ac,bb,bc,ca,cb,db,dc,dd,edg.
x(a;b)=fab,ac,ca,dbg.x(a;b)signi¯es the set of all
contexts common to aandb. to calculate the count of
co-occurrence combinations (step 5 of algorithm 1), we
need to consider the frequency of 3-grams in the entire
event log. to calculate, cdb(a;b), we need to consider
the 3-grams with dbas the context for symbols aand
b. in other words, we need to consider the 3-grams dab
and dbb. now, we have 3 occurrences of daband 2
occurrences of dbbin the event log, l. each occurrence
of the activity acan have a co-occurrence with each
occurrence of bin the context dbas shown in figure
4(a). the count of co-occurrence combinations for this
case is 6. similarly, to calculate cdb(a;a), we need to
consider the 3-gram dab. there are 3 occurrences of
dabin the event log. each occurrence of the activitycommand 1 command 2 substitution score
blobjectshuttersstop stopstepimgfwd -25
blwedge2rotateclockwise blwedge2reset 24
blwedge2rotateclockwise blcloseshutters -4
startstepimgfwd stopstepimgfwd -30
addannotation showfullscreen 19
cathetereditbox switchtoanalysis 46
table 1: substitution scores for commands
command 1 command 2 substitution score
repair(simple)-start repair(complex)-start 5
repair(simple)-start repair(simple)-start 9
testrepair-complete archiverepair-complete -11
informuser-complete archiverepair-complete 0
table 2: substitution scores for a few activity pairs of the telephone repair process
ain the context dbcan co-occur with every other
occurrence of aother than itself as shown in figure
4(b). thus, the count of co-occurrence combinations
for this case is 3.
in other words, for the two symbols under consid-
eration in a given context, each occurrence of the
3-gram of one symbol in the given context can co-occur
with each occurrence of the 3-gram of the other symbol
in the same context. in general, if the estimation of co-
occurrence combinations is for `like' symbols, then the
count of such combinations cxy(a;a) =¡n
2¢
=n(n¡1)
2,
where nis the frequency of the 3-gram xay. the count
of co-occurrence combinations for `unlike' symbols
cxy(a;b) =ni:njwhere niandnjcorrespond to the
frequency of the 3-grams xayandxbyrespectively.
proceeding further, one can estimate the count of
co-occurrence combinations of two symbols over all
contexts thereby completing step 6 of the algorithm.
steps 7 and 8 of the algorithm normalize the counts
thus calculated for every pair of symbols. step 9
calculates the probability of occurrence of every symbol
in the alphabet while step 10 calculates the normalized
co-occurrence frequencies by chance (random). step
11 computes the ratio of the actual frequency divided
by the chance frequency with which the pair occurs.
such a ratio compares the probability of an event
occurring under two alternative hypotheses and is
called a likelihood or odds ratio. scores that are the
logarithm of odds ratios are called log-odds score.
we have applied the algorithm over a large set of event
traces (of real systems) over varying alphabet sizes
and analyzed the resulting substitution matrices. in
all the cases the algorithm mentioned above yielded
dab
dab
dab
dbb
dbb
(a) dab
dab
dab
(b)c   (a,b) = 6
dbc   (a,a) = 3
dbfigure 4: count of co-occurrence combinations
substitution scores having a high semantic signi¯cance.
we present one such study here where we have con-
sidered a set of 1372 event traces of a health care
system. the traces correspond to the commands of
clinical usage logged by the system. there were a total
of 213 commands in the event traces (alphabet size,
jaj= 213). table 1 lists the substitution scores for a
few command pairs. it can be seen here that the two
wedge related commands blwedge2rotateclockwise
and blwedge2reset assume a high score, signify-
ing their functional closeness. the command pair,
blwedge2rotateclockwise and blcloseshutters
belonging to two di®erent components of the system
viz., wedge and shutters assumes a negative score.
it is also important to notice that the scores are
assigned relatively in proportion to their degree of
closeness. consider the scores for the command pairs,
(blwedge2rototeclockwise ,blcloseshutters ) and
(blobjectshuttersstop ,stopstepimgfwd ). the
former command pair is assigned a relatively higher
score than the latter. as is obvious from the names,
the former pair though belonging to di®erent com-
ponents (wedge and shutters), still are used for the
same higher level functionality (viz., adjusting the
beam). however, the latter pair where one command
belongs to the shutter component and the other to an
image processing operation, being totally uncorrelatedalgorithm 1 algorithm to derive substitution scores
1:letabe the alphabet; x ;y;a;b2 a
2:letg3denote the set of all 3-grams present in
the event log and let f3denote their corresponding
frequencies.
3:de¯ne xato be the set of all contexts of symbol a.
a context of a symbol a is the subsequence xy such
that xay 2g3
4:de¯ne x(a;b)to be the set of contexts common to
symbols, a and b. i.e., x(a;b)=xa\ xb
5:de¯ne cxy(a;b) to be the count of co-occurrence
combinations (explained in the description) of sym-
bols, a and b in the given 3-gram context, xy 2
x(a;b).
6:de¯ne c(a;b) to be the count of co-occurrence
combinations of symbols a and b over all contexts
x(a;b)
c(a;b) =x
xy2x(a;b)cxy(a;b)
7:de¯ne ncto be the norm of the count of co-
occurrence combinations
nc=x
a;b2ac(a;b)
8:de¯ne matrix movera £ a to be
m(a;b) = [ c(a;b)=nc]
9:de¯ne pato be the probability of occurrence of
symbol a 2 a
pa=m(a;a) +x
b6=am(a;b);x
a2apa= 1
10:de¯ne matrix eto be the expected value of occur-
rence of pair of symbols
e(a;b) = [ p2
a] if a = b
= [2papb] otherwise
11:de¯ne the matrix of substitution scores sovera£a
to be the log-odds ratio
s(a;b) = log2µm(a;b)
e(a;b)¶
assumes a high negative score. another important
point to consider is the score for the command pair
(startstepimgfwd ,stopstepimgfwd ). these two
commands signify contrasting operations viz., start and
stop of an activity. these two contrasting commandsare assigned a high negative score of ¡30 discouraging
their substitution. remember that this is one of the
objectives that we started with.
as another example, let us consider the telephone
repair process depicted in prom tutorial2. the repair
process starts by registering a telephone device sent
by a customer. after registration, the telephone is
sent to the problem detection department where it is
analyzed and its defect is categorized. there are 10
di®erent categories of defects that the phones ¯xed by
this company can have. once the problem is identi¯ed,
the telephone is sent to the repair department and
a letter is sent to the customer to inform him/her
about the problem. the repair department has two
teams. one of the teams can ¯x simple defects and
the other team can repair complex defects. however,
some of the defect categories can be repaired by both
teams. once a repair employee ¯nishes working on a
phone, this device is sent to the quality assurance
department. there it is analyzed by an employee to
check if the defect was indeed ¯xed or not. if the
defect is not repaired, the telephone is again sent to the
repair department. if the telephone is indeed repaired,
the case is archived and the telephone is sent to the
customer. to save on throughput time, the company
only tries to ¯x a defect a limited number of times.
if the defect is not ¯xed, the case is archived anyway
and a brand new device is sent to the customer. in the
event log, there were a total of 12 activities for this
data set. table 2 depicts the substitution scores for a
few activity pairs of this log. it is to be noted that a
high positive value is assigned for activities of similar
functionality. the value is also relative to the degree of
similarity. for example the score for the activity pair
(repair(simple)start ,repair(simple)start ) is rel-
atively higher than for the pair ( repair(simple)start ,
repair(complex)start ). on the other hand, unre-
lated activities have a low/negative score.
one can consider not just 3-grams, but contexts
of larger length as well. the basic idea of substitution
matrix derivation still holds.
4.2 indel scores event traces from a process model
can have di®erent manifestations based on the use
case. the di®erences can be attributed to an execu-
tion of a di®erent path or functionality or optional
activities within a functionality. as an example,
2prom is an extensible framework that provides a comprehen-
sive set of tools/plugins for the discovery and analysis of process
models from event logs. see http://www.processmining.org for
more information and to download prom and the dataset.consider the sub-process `image processing', in the
process model of medical image acquisition. a lot
of activities pertaining to image processing (such as
zooming, ¯ltering, segmenting) would be provided
by the image processing component of the medical
system. depending on the type of patient and the
diagnosis prescribed, a subset of these functionalities
would be triggered. when we analyze event traces
from the medical system, we see traces with variation
in the usage of the image processing component. the
invocation or non-invocation of certain activities can
be thought of as insertion or deletion of activities in
the traces. for example, consider the two traces t1=
acbcabaa andt2=acbcabdaa . the di®erence between
the two traces is that in the second trace, t2, there is
an invocation of activity dbetween band a. one can
transform trace t1, to trace t2, by inserting dbetween
band a. alternatively, we can transform trace t2to
t1by deleting activity d. it is important to note that
insertions and deletions are complementary. therefore,
we will consider only insertions henceforth.
insertion of activities cannot take place at random. it
is natural to see insertion of activities pertaining to
a functionality between activities related to the same
or similar functionality than otherwise. even within
a functionality the presence/absence of an activity
largely depends on its neighbors. for example, it
is highly unlikely to see a image processing activity
between activities pertaining to beam positioning.
similarly, it is relatively highly likely to see an edge
detection activity between activities pertaining to
imagesegmentation than between those pertaining to
imageannotation . therefore, one should have di®erent
scores for insertion of activities based on the context.
we de¯ne two kinds of insertion operations: (i)
insertion of an activity to the right of an activity (ii)
insertion of an activity to the left of an activity. for
example, in abc, activity bcan be considered as an
insertion to the right of activity aor to the left of
activity c. we now de¯ne an approach to determine
the scores of insertion. we de¯ne two sets of scores
a.insertionrightgivenleft
b.insertionleftgivenright
insertionrightgivenleft( a/b) signi¯es the insertion of
activity ato the right of activity b(or insertion of
activity agiven that the left activity is b). similarly
insertionleftgivenright( a/c) signi¯es the insertion of
activity ato the left of activity c(or given that the
right activity is c).algorithm 2 algorithm to derive insertion scores
1:letabe the alphabet; x ;y;a;b2 a
2:letg3denote the set of all 3-grams present in
event log and let f3denote their corresponding
frequencies.
3:de¯ne xato be the set of all contexts of symbol a.
a context of a symbol a is the subsequence xy such
that xay 2g3
4:letcxy(a) be the count of occurrences of the 3-gram
xay2g3
5:for each symbol a ;x2 a, de¯ne
countrightgivenleft (a=x) =x
yjxy2xacxy(a)
6:de¯ne
norm (a) =x
x2acountrightgivenleft (a=x)
7:for all a 2 a, let padenote the probability of
occurrence of a.
8:de¯ne
normcountrightgivenleft (a=b) =
countrightgivenleft (a=b)=norm (a)
9:the insertion scores are de¯ned as the log-odds ratio
insrightgivenleft (a=b) =
log2µnormcountrightgivenleft (a=b)
papb¶
algorithm 2 generates the scores for the insertion
of activities to the right of a given activity i.e.,
insertionrightgivenleft. the insertion scores for
insertionleftgivenright can be derived in a similar
fashion.
table 3 lists a few insertion scores for the inser-
tion of command 2 to the right of command 1. it
is to be noted that related command pairs such as
(setpatientweight ,setpatienttype ), (setcontrast ,
setedgegain ) assume a high positive score. the latter
pair belonging to image processing functionality. it is
important to closely look at the score for the command
pair ( startstepimgrev ,startstepimgfwd ) assuming
a negative value. this signi¯es that it is discouraged
to start an imageforward operation immediately after
starting an imagereverse operation. the imagereverse
operation should be stopped ¯rst. this is re°ected
in the score for the command pair ( stopstepimgrev ,startstepimgfwd ).
command 1 command 2 insrightgiven
leftscore
setpatientweight setpatienttype 7
blopenshutters blcloseshutters 3
startsteprunfwd stopsteprunfwd 2
startstepimgrev startstepimgfwd -1
stopstepimgrev startstepimgfwd 1
setcontrast setedgegain 4
table 3: insrightgivenleft scores for commands
the algorithms de¯ned above derives scores for
substitution/indel operations such that similar traces
have a high score. one can compute the similarity be-
tween traces using these scores and take the reciprocal
of that as a measure of distance. in other words for two
traces sandt, the generic edit distance, d, between
them can be de¯ned as
d(s; t) =jsj+jtj
sim(s; t)
where the numerator denotes the normalization factor.
5 clustering event traces
we adopted the agglomerative clustering (or hierarchi-
cal clustering) technique with minimum variance crite-
ria [5] for our analysis. agglomerative clustering works
by initially placing each data item (here, an event trace)
into a di®erent cluster and iteratively combining clusters
that are closest until we obtain a single cluster. di®er-
ent criteria can be used in choosing the two clusters to
combine in an iteration. we use the minimum variance
criteria which tries to optimize the variance within a
cluster. a detailed description of this approach is be-
yond the scope of this paper and the interested reader
is referred to [3, 4].
5.1 evaluating the signi¯cance of clusters: a
process mining perspective statistical metrics such
as the average cluster density, silhouette width etc.,
have been proposed in the literature to evaluate the
goodness of the clusters. the underlying motive for
all these metrics is to prefer clusters that are compact.
compact clusters have a lot of signi¯cance in pattern
classi¯cation where the objective is to enable the discov-
ery of decision boundaries. the objective for clustering
event logs is to ease the discovery of process models by
grouping together traces that conform to similar execu-
tion patterns/behavior. to evaluate the signi¯cance of
the clusters formed, one can compare the process modelsthat are discovered from the traces within each cluster.
in this paper, we propose two hypotheses to evaluate
the goodness of clusters from a process mining point of
view. good clusters tend to cluster traces such that:
1.the process models mined show a high degree of
¯tness
2.the process models mined are less complex
the rationale behind these evaluation criteria is that if
the clusters formed are meaningful (all traces belonging
to related cases are in the same cluster and traces that
are unrelated are not), then the process models result-
ing from the traces in each cluster should be less com-
plex (more comprehensible and less spaghetti like). al-
gorithm 3 depicts the evaluation approach. algorithm
3 is run over various clustering criteria/techniques and
choice of cluster size.
algorithm 3 evaluating the signi¯cance of clusters
require: given an event log lconsisting of mtraces,
and a clustering algorithm c
ensure: partition the mtraces into n-clusters (for
some n¸2) using c
1:discover the process model pifor each cluster, ci,
1·i·n
2:evaluate the ¯tness of the process models pi
3:evaluate the complexity of the process models. the
number of control-°ows, and/xor joins/splits and
the size of the model de¯ned in terms of the nodes,
transitions and arcs signify the complexity of a
process model.
the following clustering techniques are studied:
²a1: bag-of-activities approach, euclidean distance,
agglomerative clustering
²a2: k-gram model, euclidean distance, agglomera-
tive clustering
²a3: levenshtein distance, agglomerative clustering
²a4: generic edit distance; substitution/indel
scores as derived in section 4, agglomerative clus-
tering
6 experimental results and discussion
we evaluate the above techniques using the telephone
repair process event log (described in section 4.1).
there were a total of 1104 process instances in this data
set. in addition to the whole data set, we have chosen
random subsets of this data set for analysis. subsets of
40%, 50%, 60%, 70%, 80%, 90% of instances have beencluster no a1 a2 a3 a4
i nifi cisi nifi cisi nifi cisi nifi cisi
1 47 .84 13 9 571.0 00 43 .91 10 7 571.0 00
2 89 .84 10 8120 .95 11 89 .84 10 8 341.0 00
3 240 .89 5 5 95 .86 12 9 74 .84 21 12 190 .91 12 9
4 31 .82 21 12 138 .89 12 8127 .88 5 5 52.91 87
5 39 .91 7 5 36 .95 11113 1.0 0 0113 1.0 00
table 4: fitness and complexity metrics of the process models from the four clustering techniques for a random
subset of 40% of the repair data set. the number of clusters is 5.
chosen randomly. for each such set of instances, we
have applied the above clustering techniques. we have
generated process models using the alpha++ mining
algorithm [8] (available in the prom framework) over
the traces in each cluster. the conformance checker
plugin in prom is used to measure the ¯tness of the
process models thus generated. further, we used the
petri-net complexity analysis plugin in prom over
the process models. the complexity analysis plugin
generates metrics such as the number of control-°ows,
and-joins, and-splits, xor-joins, xor-splits, arcs, places
and transitions in the process model. the larger
the value of these metrics, the more complex is the
model. the relationship between these metrics and
comprehensibility has been reported in [9] while their
relationship with defect/errors was reported in [10].
table 4 depicts the ¯tness and complexity metrics
of the process models mined from the traces clustered
using the four techniques on 40% of the repair example
data set. the data set has been partitioned into ¯ve
clusters. in table 4, nisigni¯es the number of instances
in cluster iwhile fisigni¯es the ¯tness of the process
model mined using the instances of cluster i.cisigni¯es
the number of control °ows in the process model
mined from instances of cluster iwhile sisigni¯es
the sum of and/xor joins/splits. it is interesting to
note that the generic edit distance based clustering
outperforms other techniques i.e., this technique is able
to cluster the traces more coherently. the coherency
is re°ected in the fact that three process models with
a ¯tness of 1.0 can be generated using this technique.
further, the comprehensibility of the process models
is signi¯cantly better since these models have less
control °ows and and/xor join/splits. clustering using
euclidean distance on k-grams (k is chosen to be 3) has
the next best performance. this boosts the argument
that incorporating context improves the goodness of
clusters. clustering using euclidean distance on the
bag-of-activities has the worst performance amongst
the four while the levenshtein distance based technique
performs on par with the bag-of-activities.we de¯ne two metrics viz., average ¯tness -favgand
weighted average ¯tness -wfavgas follows (here, nis
the number of clusters):
favg=1
nnx
i=1fi wfavg=nx
i=1(ni¤fi)=nx
i=1ni
weighted average ¯tness balances the ¯tness over
imbalanced clusters3. for example, consider the
scenario where 100 instances are partitioned into
four clusters with n1= 5, n2= 6, n3= 9, n4= 80
instances. assume that the process models mined
from the ¯rst three clusters has a ¯tness value of
1:0 while the model from the fourth cluster has a
¯tness value of 0 :8. the average ¯tness value would
be (1 :0 + 1 :0 + 1 :0 + 0 :8)=4 = :95. however, the
distribution of instances is skewed in the clusters and
the average ¯tness value does not re°ect the reality.
the weighted average ¯tness value for this partitioning
would be (5 ¤1:0 + 6¤1:0 + 9¤1:0 + 80 ¤0:8)=100 = :84,
a realistic summarization of the goodness of clusters.
table 5 illustrates the minimum, maximum and
average ¯tness of the process models mined from the
traces clustered using the four techniques on di®erent
subsets (varying between 40% and 100%) of the repair
example data set. each subset has been partitioned
into ¯ve clusters. it is to be noted that the generic
edit distance based technique performs consistently
superior over the other techniques. the k-gram based
approach which incorporates certain context is second
best while the bag-of-activities based technique has the
least ¯tness.
figure 5 depicts the average and weighted aver-
age ¯tness of the process models mined from the
traces clustered using the four techniques on di®erent
subsets of the telephone repair process log. it is to be
noted that the generic edit distance based clustering
3the partitioning of instances is skewed in that the number of
instances in some clusters are much less compared to othersdata set size a1 a2 a3 a4
% min avg max min avg max min avg max min avg max
40 .82 .86 .91 .85 .93 1.0 .84 .89 1.0 .91 .96 1.0
50 .82 .88 .92 .88 .92 .95 .84 .89 .95 .91 .96 1.0
60 .80 .83 .89 .84 .93 .95 .80 .84 .95 .80 .93 1.0
70 .82 .87 .91 .86 .91 .95 .80 .88 .95 .89 .96 1.0
80 .80 .83 .86 .80 .90 .95 .80 .84 .95 .83 .95 1.0
90 .82 .88 .92 .85 .93 1.0 .82 .88 .95 .87 .93 1.0
100 .82 .87 .92 .86 .92 .95 .80 .88 .95 .89 .96 1.0
table 5: the minimum, average and maximum ¯tness values of the process models from the four clustering
techniques for di®erent subsets of the repair dataset. the number of clusters is 5.
yields better clusters over others techniques on both
the metrics. figure 6 depicts the complexity viz.,
average control °ow and the total number of and/xor
join/splits in the process models mined from the traces
clustered using the four techniques on di®erent subsets
of the telephone repair process log. again it can be
observed that the context aware clustering techniques
such as the generic edit distance and k-gram approach
tend to generate process models that are less complex
compared to the bag-of-activities approach.
 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
 40  50  60  70  80  90 100
% of instancesa1
a2
a3
a4
(a) average fitness
 0.6 0.65 0.7 0.75 0.8 0.85 0.9 0.95 1
 40  50  60  70  80  90 100
% of instancesa1
a2
a3
a4
(b) weighted average fitness
figure 5: average and weighted average ¯tness of the
process models mined from the traces clustered using
the four techniques on di®erent subsets of the telephone
repair process log
the results presented in this section are for the scenario
where the data set is partitioned into 5 clusters. we
have varied the number of clusters into which the data
 2 4 6 8 10 12 14 16
 40  50  60  70  80  90  100
% of instancesa1
a2
a3
a4(a) average number of control °ows
 5 10 15 20 25 30 35 40 45 50
 40  50  60  70  80  90  100
% of instancesa1
a2
a3
a4
(b) total number of and/xor join/splits
figure 6: complexity of process models mined from the
traces clustered using the four techniques on di®erent
subsets of the telephone repair process log
set is partitioned into and in all the cases a similar
result was obtained.
in this study, we have used the alpha++ mining
algorithm to generate process models. however, other
mining algorithms that yield process models amenable
for analysis of the evaluation metrics de¯ned in this
paper can be used. similarly, one can use other
clustering techniques [4] instead of the agglomerative
hierarchical clustering.
6.1 computational complexity the vector space
approaches with euclidean distance has a linear time
complexity with respect to the number of features. for
distance between two traces, this amounts to o(jaj)ando(jajk) respectively for the bag-of-activities and
k-gram approaches. edit distance computation (both
levenshtein and generic edit distance) between two
traces takes quadratic time.
7 related work
data clustering is one of the most important ¯elds of
data mining and a lot of techniques exist in the litera-
ture [3], [4], [5]. there is a growing interest in process
mining and many case studies have been performed to
show the applicability of process mining e.g., [11]. the
signi¯cance of trace clustering to process mining has
been discussed in [6], [12]. greco et al. [6] used trace
clustering to partition the event log and this way dis-
covered more simple process models. they used the
vector space model over the activities and their transi-
tions to make clusters. transitions can be considered as
a speci¯c case of the k-gram model where the value of
kis 2. on similar lines, song et al. [7] have proposed
the idea of clustering traces by considering a combina-
tion of di®erent perspectives of the traces (such as ac-
tivities, transitions, data, performance etc) as the fea-
ture vector. for the activities and transition perspec-
tives, this approach can be thought of as a combination
of the bag-of-activities and the k-gram approach (with
k= 2). though this combined approach might yield
better results than either of the approaches in isolation,
it still su®ers from the pitfalls highlighted in section
3. the generic edit distance based approach proposed
in this paper is shown to outperform the vector-space
model on these two perspectives. further more, the
generic edit distance considers the entire trace in to-
tality thereby preserving the complete context of the
process instance. distances on other perspectives (such
as data, performance etc) can be seamlessly combined
with the generic edit distance just like in [7]. this helps
in further boosting the results of process mining algo-
rithms by leveraging the superior performance of the
generic edit distance. a comprehensive list of metrics
that in°uence the comprehensibility of process models
was reported in [9].
8 conclusions and future directions
in this paper, we have proposed a generic edit distance
based approach to trace clustering. in order to tackle
the sensitivity of the cost function (of edit operations)
in the generic edit distance framework, we proposed an
algorithm that automatically derives the cost of edit
operations. the costs derived using this approach are
shown to be e®ective. further, we have proposed a
process mining perspective to evaluate the goodness of
clusters. it was shown that the proposed clustering ap-
proach outperforms contemporary approaches to traceclustering in process mining. the alpha++ mining al-
gorithm and conformance checker have been used to
evaluate the goodness of clusters. however, there is a
bias associated with a mining algorithm over the class
of process models that it can generate and thereby the
evaluation metrics. so far, little research has been done
in this area. as future work, we would like to investi-
gate the in°uence (bias) of a mining algorithm on the
evaluation criteria.
acknowledgments the authors are grateful to philips
healthcare for funding the research in process mining.
references
[1]w.m.p. van der aalst, a.j.m.m. weijters, and l.
maruster, work°ow mining: discovering process mod-
els from event logs , ieee trans. knowl. data eng.,
16(9) (2004), pp. 1128-1142.
[2]e. s. ristad and p. n. yianilos, learning string-edit
distance , ieee trans. pami., 20-5 (1998), pp. 522-
532.
[3]a. k. jain, m. n. murty, and p. j. flynn, data
clustering: a review , acm computing surveys, 31-3
(1999), pp. 264-323.
[4]a. k. jain and r. c. dubes, algorithms for clustering
data, prentice-hall, inc., upper saddle river, nj,
usa, 1988.
[5]j.h. ward, hierarchical grouping to optimize an ob-
jective function , j. amer. stat. assoc., 58 (1963), pp.
236-244.
[6]g. greco, a. guzzo, l. pontieri, and d. sacca, dis-
covering expressive process models by clustering log
traces , ieee trans. knowl. data eng., (2006), pp.
1010-1027.
[7]m. song, c.w. gunther, and w.m.p. van der aalst
trace clustering in process mining , bpm workshops
(2008) (to appear)
[8]l. wen, w.m.p. van der aalst, j. wang, and j.
sun, mining process models with non-free choice
constructs , data min. knowl. discov., 15-2 (2007),
pp. 145-180.
[9]j. mendling, and m. strembeck, in°uence factors of
understanding business process models , bis (2008),
pp. 142-153.
[10]j. mendling, g. neumann, and w.m.p. van der aalst,
understanding the occurrence of errors in process
models based on metrics , otm conferences 1 (2007),
pp. 113-130.
[11]w.m.p. van der aalst, h.a. reijers, a.j.m.m. wei-
jters, b.f. van dongen, a.k. alves de medeiros, m.
song, and h.m.w. verbeek. business process mining:
an industrial application , info. sys., 32-5: (2007), pp.
713-732.
[12]a.k. alves de medeiros, a. guzzo, g. greco, w.m.p.
van der aalst, a.j.m.m. weijters, b.f. van dongen,
and d. sacca, process mining based on clustering: a
quest for precision , bpm workshops (2007), pp. 17-
29.