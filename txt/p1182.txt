group-based privacy preservation techniques
for process mining
majid raei
/envelopeand wil m.p. van der aalst
chair of process and data science, rwth aachen university, aachen, germany
abstract. process mining techniques help to improve processes us-
ing event data. such data are widely available in information systems.
however, they often contain highly sensitive information. for example,
healthcare information systems record event data that can be utilized
by process mining techniques to improve the treatment process, reduce
patient's waiting times, improve resource productivity, etc. however,
the recorded event data include highly sensitive information related to
treatment activities. responsible process mining should provide insights
about the underlying processes, yet, at the same time, it should not reveal
sensitive information. in this paper, we discuss the challenges regarding
directly applying existing well-known group-based privacy preservation
techniques, e.g., k-anonymity, l-diversity, etc, to event data. we provide
formal denitions of attack models and introduce an eective group-based
privacy preservation technique for process mining. our technique cov-
ers the main perspectives of process mining including control-ow ,time,
case, and organizational perspectives. the proposed technique provides
interpretable and adjustable parameters to handle dierent privacy as-
pects. we employ real-life event data and evaluate both data utility and
result utility to show the eectiveness of the privacy preservation tech-
nique. we also compare this approach with other group-based approaches
for privacy-preserving event data publishing.
keywords: responsible process mining ·privacy preservation ·result
utility ·data utility ·event data
1 introduction
process mining employs event data to discover, analyze, and improve the real
processes [1]. indeed, it provides fact-based insights into the actual processes
using event logs. there are many algorithms and techniques in the eld of pro-
cess mining. however, the three basic types of process mining are (1) process
discovery , where the goal is to learn real process models from event logs, (2)
conformance checking , where the aim is to nd commonalities and discordances
between a process model and an event log, and (3) process re-engineering (en-
hancement ), where the aim is to extend or improve a process model using dif-
ferent aspects of the available data.arxiv:2105.11983v1  [cs.db]  25 may 20212 majid raei and wil m.p. van der aalst
an event log is a collection of events where each event is described by its
attributes [1]. the typical attributes required for the main process mining algo-
rithms are case identier ,activity ,timestamp , and resource . the case identier
refers to the entity that the event belongs to, the activity refers to the activity
associated with the event, the timestamp is the time that the event occurred,
and the resource is the activity performer. in the human-centered processes, case
identiers refer to persons. for example, in a patient treatment process, the case
identiers refer to the patients whose data are recorded. moreover, the resource
attribute often refers to the persons performing activities, e.g., in the health-
care context, the resources refer to the doctors or nurses performing activities
for the patients. the event attributes are not limited to the above-mentioned
ones, and an event may also carry other case-related attributes, so-called case
attributes, e.g., age,salary ,disease , etc, which could be considered as sensitive
person-specic information. table 1 shows a sample event log.
orthogonal to the three mentioned types of process mining, dierent per-
spectives are also dened including control-ow ,organizational ,case, and time
perspective [1]. the control-ow perspective focuses on activities and their order,
which are often utilized by process discovery and conformance checking tech-
niques. the organizational perspective focuses on resources and their relations,
which are exploited by social network discovery techniques. the case perspective
is focused on case-related attributes, and the time perspective is concerned with
the time-related information, which can be used for performance and bottleneck
analyses .
with respect to the main attributes of events, two dierent perspectives for
privacy in process mining can be considered in the human-centered processes;
resource perspective and case perspective . the resource perspective focuses on
the privacy rights of the individuals performing activities, and the case perspec-
tiveconcerns the privacy rights of the individuals whose data are recorded and
analyzed. depending on the context, the relative importance of these perspec-
tives may dier. however, often the case perspective is more critical for privacy
than the resource perspective . for example, in the healthcare context, activity
performers could be publicly available. however, what happens for a specic
patient and her/his personal information should be kept private. in this paper,
we are focused on the case perspective . in principle, when event logs explicitly
or implicitly include personal data, privacy concerns appear which should be
taken into account according to regulations such as the european general data
protection regulation (gdpr) [40].
in this paper, we describe disclosure risks and linkage attacks against event
logs. the attack models are formally dened based on the available event at-
tributes. we discuss the challenges regarding directly applying group-based pri-
vacy preservation techniques, e.g., k-anonymity [35], l-diversity [21], etc, to event
logs. we extend the work described in [31], where the tlkc -privacy is intro-
duced as an eective group-based privacy preservation technique for process
mining. the tlkc -privacy exploits some restrictions regarding the availability
of background knowledge in the real world to deal with process mining-specicgroup-based privacy preservation techniques for process mining 3
process mining result (r) process mining result (r')original event 
log (el)
group -based privacy 
preservation techniques :
process mining 
techniques : control -flow perspective
 case perspective
 organizational perspective
 time perspectiveprivacy -aware 
event log (el')
 control -flow perspective
 case perspective
 organizational perspective
 time perspective
 k-anonymity
 l-diversity
 tlkc -privacy
 …process mining 
techniques :
 process discovery
 conformance 
checking
 performance analysis
 social network 
discovery
 ...privacy gain
data utilitybalancing 
privacy and 
utilitydisclosure risk 
analysisdisclosure risk 
analysis
privacy gain
result utilitybalancing 
privacy and 
utility process discovery
 conformance 
checking
 performance analysis
 social network 
discovery
 ...
result utility analysisdata utility analysis
fig. 1: the general overview of privacy-related activities in process mining. privacy
preservation techniques are applied to event logs to mitigate disclosure risks. the data
and result utility analyses are used to evaluate the eectiveness of the techniques where
the goal is to balance utility loss and privacy gain.
challenges. this technique is focused on control-ow ,time, and case perspec-
tives. tlkc -privacy generalizes several traditional privacy preservation tech-
niques, such as k-anonymity, condence bounding [41], ( ,k)-anonymity [42],
andl-diversity.
the extended privacy preservation technique covers all the main perspec-
tives of process mining including control-ow ,time,case, and organizational
perspectives. it empowers the adjustability of the proposed technique by adding
new parameters to adjust privacy guarantees and the loss of accuracy. more-
over, a new utility measure is dened to tackle the drawbacks of the current
approach. to evaluate the extended technique, we employ real-life event logs
and evaluate both data utility and result utility . we also compare the extended
tlkc -privacy with the main algorithm and other group-based approaches for
privacy-preserving event data publishing. our experiments show that the pro-
posed approach maintains high data and result utility, assuming realistic types
of background knowledge. figure 1 shows a general overview of privacy-related
activities in process mining which are discussed in this paper.4 majid raei and wil m.p. van der aalst
the rest of the paper is organized as follows. in section 2, we explain the
motivation and challenges. section 3 provides preliminaries on event logs and
dierent types of background knowledge. in section 4, we provide formal models
of the attacks. privacy preservation techniques are discussed in section 5. in
section 6, the experiments are presented. section 7 outlines related work, and
section 8 concludes the paper.
2 motivation and challenges
to motivate the necessity to deal with privacy issues in process mining, we de-
scribe the disclosure risks using an example in the health-care context. consider
table 1 as part of an event log recorded by an information system in a hospital.
note that each case has a sequence of events that are ordered based on the times-
tamps. this sequence of events is called a trace which is a mandatory attribute
for a case [1]. for example, case 1, which could be interpreted as patient 1, is
rst registered by employee 4, then visited by doctor 3, and at the end released
from the hospital by employee 6.
suppose that an adversary knows that a victim patient's data are in the event
log (as a case), with little information about some event attributes that belongs
to the patient, the adversary is able to connect the patient to the corresponding
case id , so-called case disclosure [29]. consequently, two types of sensitive person-
specic information are revealed: (1) the complete sequence of events belonging
to the case, and (2) sensitive case attributes. (1) and (2) are generally called
attribute disclosure . (1) is also called trace disclosure that is a specic type of
attribute disclosure [29]. for example, if the adversary knows that two blood tests
were performed for the victim patient, the only matching case is the case with id
2. this attack is called case linkage attack. after the case re-identication, the
sensitive case attributes are disclosed, e.g., the disease of patient 2 is infection .
this is called attribute linkage attack. moreover, the complete sequence of events
performed for patient 2 is disclosed which contains private information, e.g.,
the complete sequence of activities performed for the case, the resources who
performed the activities for the case, or the exact timestamp of doing a specic
activity for the case. we call this attack trace linkage which is a specic type of
attribute linkage attack.
note that the attribute linkage attack does not necessarily need to be launched
after the case linkage , i.e., if more than one case corresponds to the adversaries
knowledge while all the matching cases have the same value for the sensitive
case attribute(s) or the same sequence of event attributes (e.g., the same se-
quence of activities), the attribute linkage /trace linkage could happen without
a successful case linkage attack. for example, if the adversary knows that the
activity visit has been performed by the resource doctor 3 for a victim patient,
case 1 and case 6 match this background knowledge. however, they both have
the same sequence of activities and resources ( h(re;e 4);(vi;d 3);(rl;e 6)i).
consequently, the adversary realizes the complete sequence of activities and the
resources who performed the activities.group-based privacy preservation techniques for process mining 5
table 1: sample event log (each row represents an event).
case id activity timestamp resource agedisease
1 registration (re) 01.01.2019-08:30:00 employee 4 (e4) 22 flu
1 visit (vi) 01.01.2019-08:45:00 doctor 3 (d3) 22 flu
2 registration (re) 01.01.2019-08:46:00 employee 1 (e1) 30 infection
3 registration (re) 01.01.2019-08:50:00 employee 1 (e1) 32 infection
4 registration (re) 01.01.2019-08:55:00 employee 4 (e4) 29 poisoning
1 release (rl) 01.01.2019-08:58:00 employee 6 (e6) 22 flu
5 registration (re) 01.01.2019-09:00:00 employee 1 (e1) 35 cancer
2 hospitalization (ho) 01.01.2019-09:01:00 employee 3 (e3) 30 infection
6 registration (re) 01.01.2019-09:05:00 employee 4 (e4) 35 corona
4 visit (vi) 01.01.2019-09:10:00 doctor 2 (d2) 29 poisoning
5 visit (vi) 01.01.2019-09:20:00 doctor 2 (d2) 35 cancer
4 infusion (in) 01.01.2019-09:30:00 nurse 2 (n2) 29 poisoning
5 hospitalization (ho) 01.01.2019-09:55:00 employee 6 (e6) 35 cancer
3 hospitalization (ho) 01.01.2019-10:00:00 employee 3 (e3) 32 infection
2 blood test (bt) 01.01.2019-10:02:00 nurse 1 (n1) 30 infection
5 blood test (bt) 01.01.2019-10:10:00 nurse 2 (n2) 35 cancer
3 blood test (bt) 01.01.2019-10:15:00 nurse 1 (n1) 32 infection
6 visit (vi) 01.01.2019-10:20:00 doctor 3 (d3) 35 corona
4 release (rl) 01.01.2019-10:30:00 employee 6 (e6) 29 poisoning
6 release (rl) 01.01.2019-14:20:00 employee 6 (e6) 35 corona
2 blood test (bt) 01.02.2019-08:00:00 nurse 1 (n1) 30 infection
2 visit (vi) 01.02.2019-09:30:00 doctor 1 (d1) 30 infection
3 visit (vi) 01.02.2019-13:55:00 doctor 1 (d1) 32 infection
2 release (rl) 01.02.2019-14:00:00 employee 2 (e2) 30 infection
3 release (rl) 01.02.2019-14:15:00 employee 2 (e2) 32 infection
5 release (rl) 01.02.2019-16:00:00 employee 2 (e2) 35 cancer
several group-based privacy preservation techniques, such as k-anonymity
[35],l-diversity [21], and t-closeness [19], have been introduced to deal with sim-
ilar attacks in the context of relational databases. in such techniques, the data
attributes are classied into four main categories including; explicit identiers ,
quasi-identiers ,sensitive attributes , and non-sensitive attributes . the explicit
identiers are the attributes that can be used to uniquely identify the data
owner, e.g., national id. the quasi-identiers are a set of attributes that could
be exploited to uniquely identify the data owner, e.g., fage;gender;zipcode g.
the sensitive attributes consist of sensitive person-specic information, e.g., dis-
ease or salary, and the non-sensitive attributes contain all the attributes that
do not fall into the previous three categories [7]. assuming that explicit iden-
tiers suppressed or replaced with dummy identiers, the group-based privacy
preservation techniques aim to perturb potential linkages by generalizing the
records into equivalence classes, i.e., groups of records, having the same values
on the quasi-identier . these techniques are eective for anonymizing relational
data. however, they are not easily applicable to event data due to some specic
properties of event data.
in process mining, the explicit identiers (i.e., actual case identiers) do not
need to be stored and processed, and case identiers are often dummy identiers,
e.g., incremental ids. as described in the above-mentioned examples, a trace can
be considered as a quasi-identier and, at the same time, as a sensitive attribute .
in other words, a complete sequence of events belonging to a case, is sensitive
person-specic information, at the same time, part of a trace, i.e., only some of6 majid raei and wil m.p. van der aalst
the event attributes, can be exploited as a quasi-identier to launch case linkage
and/or attribute linkage attacks.
the quasi-identier role of traces in process mining causes signicant chal-
lenges for group-based privacy preservation techniques because of two specic
properties of event data: the high variability of traces and the typical pareto
distribution of traces . considering only activity as the main event attribute in
a trace, the variability of traces in an event log is high because of the following
reasons: (1) there could be tens of dierent activities which could happen in any
order, (2) one activity or a bunch of activities could happen repetitively, and (3)
traces could contain any non-zero number of activities, i.e., various lengths. note
that this variability becomes even higher when events contain more attributes,
e.g., resources. in an event log, trace variants are often distributed similarly
to the pareto distribution, i.e., few trace variants are frequent and many trace
variants are unique. enforcing group-based privacy-preserving approaches on
little-overlapping and high-dimensional space is a signicant challenge, and of-
ten valuable data needs to be suppressed in order to achieve desired privacy
requirements [6].
3 preliminaries
in this section, we provide formal denitions for event logs and background
knowledge. these formal models will be used in the remainder for describing the
attack scenarios and the approach.
3.1 event log
we rst introduce some basic notations. for a given set a,ais the set of
all nite sequences over a, andb(a) is the set of all multisets over the set
a. fora1;a22 b(a),a1a2if for alla2a,a1(a)a2(a). a nite
sequence over aof lengthnis a mapping 2f1;:::;ng!a, represented as
=ha1;a2;:::;aniwhereai=(i) for any 1in.jjdenotes the length
of the sequence. for 1;22a,1v2if1is a subsequence of 2, e.g.,
ha;b;c;xivhz;x;a;b;b;c;a;b;c;x i. for2a,fa2gis the set of elements in
, and [a2] is the multiset of elements in , e.g., [a2hx;y;z;x;yi] = [x2;y2;z].
forx= (a1;a2;:::;an)2a1a2:::an,ai(x) =aiis the projection of the
tuplexon the element from the domain ai, 1in.
denition 1 (process instance, trace). we denep=ces as
the universe of all process instances. cis the universe of case identiers. e=
art is the universe of main event attributes for process mining where ais
the universe of activities, ris the universe of resources, and tis the universe of
timestamps.sd 1[:::[dmis the universe of sensitive case attributes where
d1,...,dmare the universes of dierent case attributes, e.g., disease, salary, age,
etc. given a process instance p= (c;;s )2p,2eis called the trace attribute
of the case c.group-based privacy preservation techniques for process mining 7
denition 2 (event log). letp=ces be the universe of process
instances. an event log is elp such that if (c1;1;s1)2el,(c2;2;s2)2
el, andc1=c2, then1=2ands1=s2, i.e., all the case identiers are
unique. moreover, if p= (c;;s )2el, then6=hi.
denition 3 (perspective, projection). letp=ces be the uni-
verse of process instances. ps2fa;r;ar;at;rt;artg is
a perspective which can be used to project traces of an event log elp . for
=h(a1;r1;t1);:::;(an;rn;tn)i2e, such that there exists (c;;s )2el,ps()
is the projection of the trace on the given perspective, e.g., for ps=ar ,
ps() =h(a1;r1);:::;(an;rn)iis the projection of the trace on the activities and
resources. we denote ps=fa;r;ar;at;rt;artg as the
universe of perspectives.
denition 4 (set of activities/resources in an event log). letp=
ces be the universe of process instances, and elp be an event log.
ael=fa2aj9 (c;;s)2ela2a()gis the set of activities in the event log,
andrel=fr2rj9 (c;;s)2ela2r()gis the set of resources in the event
log.
denition 5 (set of traces/variants in an event log). letp=ces
be the universe of process instances, elp be an event log, and ps2ps be
a perspective. elps= [ps()j(c;;s )2el]is the multiset of traces in the
event log w.r.t. the given perspective. gelps=fps()j(c;;s )2elgis the set
of variants, i.e., unique traces, w.r.t. the given perspective, e.g., gelais the set
of unique traces w.r.t. the activities.
denition 6 (directly follows relations). letelp be an event log,
ps2fr;agbe a perspective, gelpsbe the set of variants and elpsbe the multiset
of traces in the event log elw.r.t. the given perspective ps.dfel
ps=f(x;y)2
pspsjx>el
psygis the set of directly follows relations w.r.t. the given perspec-
tive.x >el
psyi there exists a trace 2gelpsand1i<jj, s.t.,(i) =xand
(i+1) =y.jx>el
psyj=p
2gelpselps()jf1i<jjj(i)=x^(i+1)=ygjis
the number of times xis followed by yinel.
denition 7 (variant frequency). letp=ces be the universe of
process instances, and elp be an event log. given a perspective ps2ps ,
freqel
ps:gelps![0;1]is a function that retrieves the relative frequency of the
variants in the event log w.r.t. the given perspective. freqel
ps() =elps()=jelpsj
andp
2gelpsfreqel
ps() = 1 .
table 2 shows the process instance representation of the event log shown in
table 1, where timestamps are represented as \day-hour:minute". in this event
log,disease is the attribute which is considered as the sensitive one.8 majid raei and wil m.p. van der aalst
table 2: the process instance representation of the event log table 1 (each row is a
process instance where timestamps are represented as \day-hour:minute").
case id simple trace disease
1h(re,e4,01-08:30),(vi,d3,01-08:45),(rl,e6,01-08:58) iflu
2h(re,e1,01-08:46),(ho,e3,01-09:01),(bt,n1,01-10:02),
(bt,n1,02-08:00),(vi,d1,02-09:30),(rl,e2,02-14:00) ihiv
3h(re,e1,01-08:50),(ho,e3,01-10:00),(bt,n1,01-10:15),
(vi,d1,02-13:55),(rl,e2,02-14:15) iinfection
4h(re,e4,01-08:55),(vi,d2,01-09:10),(in,n2,01-09:30),
(rl,e6,01-10:30)ipoisoning
5h(re,e1,01-09:00),(vi,d2,01-09:20),(ho,e6,01-09:55),
(bt,n2,01-10:10),(rl,e2,02-16:00) icancer
6h(re,e4,01-09:05),(vi,d3,01-10:20),(rl,e6,01-14:20) icorona
3.2 background knowledge
regarding the quasi-identier role of traces, we consider four main types of
background knowledge including set,multiset (mult),sequence (seq), and relative
time dierence (rel). using setas the type of background knowledge, we assume
that an adversary knows a subset of some event attributes contained in the trace
attribute of a victim case. in the multiset type of background knowledge, the
assumption is that an adversary knows a subset of some event attributes included
in the trace attribute of a victim case as well as the frequency of the elements.
in the sequence type of background knowledge, we suppose that an adversary
knows a subsequence of some event attributes included in the trace attribute of
a victim case.
the exact timestamps of events in an event log impose a high risk regard-
ing the linkage attacks such that little time-related knowledge may easily single
out specic events, and consequently the case re-identication. for performance
analysis in process mining, we need to have the time-related information. how-
ever, the timestamps do not necessarily need to be the actual ones. therefore,
we make all the timestamps relative as dened in denition 8.
denition 8 (relative timestamps). let=h(a1;t1);(a2;t2);:::;(an;tn)i
be a trace including the time attribute, and t0be an initial timestamp.
relative () =h(a1;t0
1);(a2;t0
2);:::;(an;t0
n)iis the trace with relative timestamps
such thatt0
1=t0and for each 1<in,t0
i=ti t1+t0.
using relative timestamps does not eliminate time-based attacks, since the
time dierences are real and can be exploited by an adversary. relative time
dierence type of background knowledge is an extension for the sequence type,
where the assumption is that an adversary knows a subsequence of some event
attributes as well as the relative time dierences between the elements. figure 2
shows the classication of background knowledge based on the types and event
attributes. in the following, we provide formal denitions for dierent categories
of background knowledge based on the main event attributes, i.e., activity ,re-
source , and timestamp . moreover, one can see that there is a relation between
type,attribute , and perspective , i.e., a combination of type and attribute can begroup-based privacy preservation techniques for process mining 9
fig. 2: categorizing background knowledge based on the type and event attributes as
well as the corresponding perspectives, e.g., if type =relandatt=ar, the correspond-
ing perspective is ps=art .
mapped to a perspective. for example, if type =relandatt=ar, the cor-
responding perspective is ps=art , or iftype2fset;mult;seqgand
att=re, the corresponding perspective is ps=r.
denition 9 (background knowledge based on activities). letelbe
an event log, and aelbe the set of activities in the event log. bkset;ac (el) =
2ael,bkmult;ac (el) =b(ael), andbkseq;ac (el) =a
elare the sets of can-
didates of background knowledge based on the activity attribute of the events
for the set,multiset, and sequence types of background knowledge. for example,
fa;b;cg2bkset;ac (el),[a2;b]2bkmult;ac (el), andha;b;ci2bkseq;ac (el).
denition 10 (background knowledge based on resources). letel
be an event log, and relbe the set of activities in the event log. bkset;re (el) =
2rel,bkmult;re (el) =b(rel), andbkseq;re (el) =r
elare the sets of candi-
dates of background knowledge based on the resource attribute of the events for
the dierent types of background knowledge.
denition 11 (background knowledge based on activities&resources).
letelbe an event log, aelbe the set of activities in the event log, and relbe
the set of resources in the event log. bkset;ar (el) = 2aelrel,bkmult;ar (el) =
b(aelrel), andbkseq;ar (el) = (aelrel)are the sets of candidates of
background knowledge based on the activity and resource attribute of the events
for the various types of background knowledge.
denition 12 (background knowledge based on time dierences be-
tween relative timestamps). letelbe an event log, aelbe the set of ac-
tivities in the event log, relbe the set of resources in the event log, and tbe the10 majid raei and wil m.p. van der aalst
personal 
data
software systemevent logevents with dummy 
identifiersprocess 
instances 
data collectiondata holder ’s side
data publishingdata recipient ’s side
fig. 3: data collection and data publishing scenario.
universe of (relative) timestamps. bkrel;ac (el) = (aelt),bkrel;re (el) =
(relt), andbkrel;ar (el) = (aelrelt)are the sets of candidates
of background knowledge based on the relative time dierences.
note that in denition 12, other attributes are also present. however, our
focus is on time dierences between relative timestamps. therefore, we refer to
this category of background knowledge as time-based.
4 attack models
figure 3 shows our simple scenario of data collection and data publishing. with
respect to the types of data holder's models, introduced in [15], we consider a
trusted model . in the trusted data holder models, the data holder is trustworthy,
and on the data holder's side, only simple anonymization techniques need to be
applied, e.g., suppressing real identiers. however, the data recipient , i.e., a pro-
cess miner, is not trustworthy and may attempt to identify sensitive information
about record owners, i.e., cases. given a process instance p= (c;;s )2p, both
andsare considered as sensitive person-specic information, and part of the
tracecan be exploited as the quasi-identier to re-identify the owner of the
process instance, i.e., c, and/or to learn the sensitive information which belongs
to the data owner, i.e., and/ors.
in the following, we provide formal denitions and examples for the attack
scenarios based on the main event attributes, i.e., activity ,resource , and times-
tamp . note that the examples are based on the event log shown in table 2.
4.1 activity-based attacks
in the activity-based scenarios, we assume that the adversary's knowledge is
about the activities performed for a victim case. in the following, we provide
formal models based on the introduced types of background knowledge.
{ based on a set of activities (a1): in this scenario, we assume that the ad-
versary knows a subset of activities performed for a case, and this information
can lead to the case linkage and/or attribute linkage attacks. given elas angroup-based privacy preservation techniques for process mining 11
event log, we formalize this scenario by a function matchel
set;ac : 2ael!2el.
fora2bkset;ac (el),matchel
set;ac (a) =f(c;;s )2eljafa2a()gg.
for example, if the adversary knows that fvi;ingis a subset of activities
performed for a case, the only matching case is case 4. therefore, both the
sequence of events and the sensitive attribute are disclosed.
{ based on a multiset of activities (a2): in this scenario, we assume that
the adversary knows a sub-multiset of activities performed for a case, and
this information can result in the linkage attacks. given elas an event log,
we formalize this scenario as follows. matchel
mult;ac :b(ael)!2el. forb2
bkmult;ac (el),matchel
mult;ac (b) =f(c;;s )2eljb[a2a()]g. for
example, if the adversary knows that [ ho1;bt2] is a multiset of activities
performed for a case, the only matching case is case 2. consequently, the
complete sequence of events and the disease are disclosed.
{ based on a sequence of activities (a3): in this scenario, we assume
that the adversary knows a subsequence of activities performed for a case,
and this information can lead to the linkage attacks. given elas an event
log, we formalize this scenario by a function matchel
seq;ac :a
el!2el.
for2bkseq;ac (el),matchel
seq;ac () =f(c;0;s)2eljva(0)g.
for example, if the adversary knows that hre;vi;hoiis a subsequence of
activities performed for a case, case 5 is the only matching case.
4.2 resource-based attacks
in the resource-based scenarios, we assume that the adversary's knowledge is
about the resources who perform activities for a victim case. in the following,
we provide formal models based on the main types of background knowledge.
{ based on a set of resources (r1): in this scenario, we assume that the
adversary knows a subset of resources involved in performing activities for a
victim case, and this information can lead to the case linkage and/or attribute
linkage attacks. given elas an event log, we formalize this scenario as
follows.matchel
set;re : 2rel!2el. forr2bkset;re (el),matchel
set;re (r) =
f(c;;s )2eljrfr2r()gg. for example, if the adversary knows
thatfe1;d2gis a subset of resources involved in handling a victim case,
case 5 is the only matching case. therefore, both the sequence of events and
the sensitive attribute are disclosed.
{ based on a multiset of resources (r2): in this scenario, we assume
that the adversary knows a sub-multiset of resources involved in performing
activities for a victim case, and this information can lead to the linkage
attacks. given elas an event log, we formalize this scenario as follows.
matchel
mult;re :b(rel)!2el. fors2bkmult;re (el),matchel
mult;re (s) =
f(c;;s )2eljs[r2r()]g. for example, if the adversary knows that
[n12;e3] is a multiset of resources performed activities for a victim case,
the only matching case is case 2.
{ based on a sequence of resources (r3): in this scenario, we assume that
the adversary knows a subsequence of resources who performed activities for12 majid raei and wil m.p. van der aalst
a victim case, and this information can result in the linkage attacks. given
elas an event log, we formalize this scenario by a function matchel
seq;re :
r
el!2el. for2bkseq;re (el),matchel
seq;re () =f(c;0;s)2eljv
r(0)g. for example, if the adversary knows that he4;d2iis a subsequence
of resources who performed activities for a victim case, the only matching
case is case 4.
4.3 activity&resource-based attacks
in the activity&resource-based scenarios, we assume that the adversary's knowl-
edge is about activities and the corresponding resources who perform activities
for a victim case. in the following, we provide formal models based on the main
types of background knowledge.
{ based on a set of (activity,resource) pairs (ar1): in this scenario,
we assume that the adversary knows a subset of (activity,resource) pairs
included in the trace attribute of a victim case, and this information can
result in the case linkage and/or attribute linkage attacks. given elas an
event log, we formalize this scenario as follows. matchel
set;ar : 2aelrel!
2el. forar2bkset;ar (el),matchel
set;ar (ar) =f(c;;s )2eljar
f(a;r)2ar()gg. for example, if the adversary knows that f(ho;e 6)g
is a subset of (activity,resource) pairs contained in the trace attribute of
a victim case, case 5 is the only matching case, which result is the whole
sequence and sensitive attribute disclosure.
{ based on a multiset of (activity,resource) pairs (ar2): in this sce-
nario, we assume that the adversary knows a sub-multiset of (activity,resource)
pairs included in the trace attribute of a victim case. given elas an event
log, the scenario can be formalized as follows. matchel
mult;ar :b(ael
rel)!2el. forbs2bkmult;ar (el),matchel
mult;ar (bs) =f(c;;s )2
eljbs[(a;r)2ar()]g. for example, if the adversary knows that
[(bt;n 1)2] is a multiset of (activity,resource) pairs included in the trace
attribute of a victim case, the only matching case is case 2.
{ based on a sequence of (activity,resource) pairs (ar3): in this
scenario, we assume that the adversary knows a subsequence of (activ-
ity,resource) pairs included in the trace attribute of a victim case, and this
information can lead to the linkage attacks. given elas an event log, we
formalize this scenario by a function matchel
seq;ar : (aeleel)!2el.
for2bkseq;ar (el),matchel
seq;ar () =f(c;0;s)2eljvar(0)g.
for example, if the adversary knows that h(re;e 4);(vi;d 2)iis a (activ-
ity,resource) pairs included in the trace attribute of a victim case, case 4 is
the only matching case.
4.4 time-based attacks
as we discussed in subsection 3.2, after making the timestamps relative, the time
dierences are still real and can be exploited by an adversary. in the following, wegroup-based privacy preservation techniques for process mining 13
extend the attacks of the type sequence , i.e., a3, r3, ar3, with the time-related
information.
{ based on relative time dierences between activities (at): in this
scenario, we assume that the adversary knows a subsequence of activities and
also the time dierence between the activities. given elas an event log, the
scenario is formalized as follows. matchel
rel;ac : (aelt)!2el. for2
bkrel;ac (el),matchel
rel;ac () =f(c;0;s)2eljvrelative (at(0))g.
for example, if an adversary's knowledge is hho;vii, both case 2 and case
3 get matched. however, if the adversary further knows that for a victim
case, visit performed in the morning of the next day, the only matching case
is case 2.
{ based on relative time dierences between resources who per-
formed activities (rt): according to this scenario, the adversary knows
a subsequence of resources and the time dierence between the resources
involved in handling a case. given elas an event log, we formalize this sce-
nario by a function matchel
rel;re : (relt)!2el. for2bkrel;re (el),
matchel
rel;re () =f(c;0;s)2eljvrelative (rt(0))g. for example,
if an adversary's knowledge is he1;e3i, both case 2 and case 3 get matched.
however, if the adversary further knows that for the victim case, employee
3 performed hospitalization more than one hour after registration , case 3 is
the only matching case.
{ based on relative time dierences between (activity,resource) pairs
(art): in this scenario, the assumption is that the adversary knows a sub-
sequence of (activity,resource) pairs and the time dierence between these
pairs. given elas an event log, we formalize this scenario as follows.
matchel
rel;ar : (aelrel)!2el. for2bkrel;ar (el),matchel
rel;ar () =
f(c;0;s)2eljvrelative (0)g. for example, case 1 and case 6 have the
same sequence of (activity,resource) pairs. however, if the adversary knows
that for a victim case, it took almost four hours to get released by employee
6 after visiting by a doctor, the corresponding possible cases narrow down
to only one case, which is case 6.
5 privacy preservation techniques
traditional k-anonymity and its extended privacy preservation techniques as-
sume that an adversary could use all of the quasi-identier attributes as back-
ground knowledge to launch linkage attacks. according to the types of back-
ground knowledge introduced in section 3, this assumption means that the
background knowledge of an adversary is bkrel;ar which covers all the infor-
mation contained in a trace. in the following, we show the results of applying
two baseline methods with respect to the aforementioned assumption.14 majid raei and wil m.p. van der aalst
table 3: a simple event log where time dierence between relative timestamps are
represented by integer values.
case id trace disease
1h(re;e 4;1);(ho;e 3;4);(vi;d 1;5);(bt;n 1;7);(vi;d 1;8)icancer
2h(bt;n 1;7);(vi;d 1;8);(rl;e 2;9)i infection
3h(ho;e 3;4);(vi;d 1;5);(bt;n 1;7);(rl;e 2;9)i corona
4h(re;e 4;1);(vi;d 1;6);(vi;d 1;8);(rl;e 2;9)i infection
5h(ho; 4);(vi;d 1;8);(rl;e 2;9)i corona
6h(vi;d 1;6);(bt;n 1;7);(rl;e 2;9)i flu
7h(re;e 4;1);(bt;n 1;7);(vi;d 1;8);(rl;e 2;9)i flu
8h(re;e 4;1);(vi;d 1;6);(bt;n 1;7);(vi;d 1;8)i cancer
5.1 baseline methods
in this subsection, we introduce two baseline methods to apply k-anonymity
on event logs: baseline -1 and baseline -2.baseline -1 is a na ve k-anonymity
approach where we remove all the trace variants occurring less than ktimes.
baseline -2 maps each violating trace variant, i.e., the variant that does not fulll
the desired k-anonymity requirement, to the most similar non-violating subtrace
by removing events. in baseline -2, if there exists no non-violating subtrace, the
whole trace variant is removed.
suppose that table 3 is part of an event log recorded by an information
system in a hospital that needs to be published after applying k-anonymity. note
that for the sake of simplicity, the time dierences between relative timestamps
are represented by integers. since all the traces in this event log are unique if we
applyk-anonymity with any value greater than 1, using baseline -1, all the traces
are removed. if we apply baseline -2 wherek= 2 then the result is the event
log shown in table 4. one can see that for such a weak privacy requirement 12
events are removed. now, if we use k= 4, table 5 is the result where 18 events
are removed which is more than half of the events.
in [13], the pretsa method is introduced as a group-based privacy preser-
vation technique for process mining where the authors apply k-anonymity and t-
closeness on event data for privacy-aware process discovery. however, pretsa
focuses on the resource perspective of privacy while we focus on the case per-
spective . thepretsa method assumes a prex of activity sequences as the
background knowledge, and each violating trace is mapped to the most similar
non-violating trace. in [31], pretsa caseis introduced as a variant of pretsa
method where only the k-anonymity part is considered, and the focus is on the
table 4: the event log after applying 2-
anonymity to table 3 using baseline -2.
case id trace disease
1h(bt; n 1;7);(v i; d 1;8)i cancer
2h(bt; n 1;7);(v i; d 1;8);(rl; e 2;9)iinfection
3h(bt; n 1;7);(rl; e 2;9)i corona
4h(v i; d 1;8);(rl; e 2;9)i infection
5h(v i; d 1;8);(rl; e 2;9)i corona
6h(bt; n 1;7);(rl; e 2;9)i flu
7h(bt; n 1;7);(v i; d 1;8);(rl; e 2;9)iflu
8h(bt; n 1;7);(v i; d 1;8)i cancertable 5: the event log after applying 4-
anonymity to table 3 using baseline -2.
case id trace disease
1h(bt; n 1;7);(v i; d 1;8)icancer
2h(bt; n 1;7);(v i; d 1;8)iinfection
3h(rl; e 2;9)i corona
4h(rl; e 2;9)i infection
5h(rl; e 2;9)i corona
6h(rl; e 2;9)i flu
7h(bt; n 1;7);(v i; d 1;8)iflu
8h(bt; n 1;7);(v i; d 1;8)icancergroup-based privacy preservation techniques for process mining 15
privacy of cases rather than resources . therefore, pretsa caseis a specic type
ofbaseline -2 where the background knowledge is a specic type of bkseq;ac , i.e.,
a prex of activity sequences rather than any subsequence.
5.2 tlkc -privacy (extended)
as discussed in [31], it is almost impossible for an adversary to acquire all the
information of a target victim, and it requires non-trivial eort to gather each
piece of background knowledge. the tlkc -privacy exploits this limitation and
assumes that the adversary's background knowledge is bounded by at most l
values of the quasi-identier, i.e., the size or power of background knowledge.
based on the types of background knowledge illustrated in figure 2, the tlkc -
privacy considers all the types, i.e., set,multiset ,sequence , and relative . however,
it focuses on the activity attribute (ac) and timestamps which are included in
therelative type. in this paper, the technique is extended with the resource at-
tribute, i.e., merely resource (re) and activity along with resource (ar) are also
considered. in the following, we bound the power of the dierent types of back-
ground knowledge (denition 9-12) with las the maximal size of candidates.
denition 13 (bounded background knowledge). letel be an event
log,type2 fset;mult;seq;relgbe the type of background knowledge, att2
fac;re;argbe the event attribute of background knowledge, and l be the size
of background knowledge. bkl
type;att (el) =fcand2bktype;att (el)jjcandjlg
are the candidates of the background knowledge whose sizes are bounded by l.
in the tlkc -privacy,t2fseconds;minutes;hours;days grefers to the ac-
curacy of timestamps, e.g., t=minutes shows that the accuracy of timestamps
is limited at minutes level,lrefers to the power of background knowledge, k
refers to the kin thek-anonymity denition, and crefers to the bound of con-
dence regarding the sensitive attribute values in a matching set. we denote
el(t) as the event log with the accuracy of timestamps at the level t. the
general idea of tlkc -privacy is to ensure that the background knowledge of
sizelinel(t) is shared by at least kcases, and the condence of inferring
the sensitive value in sis not greater than c.
denition 14 ( tlkc -privacy). letelp be an event log, lbe the max-
imal size of background knowledge, t2fseconds;minutes;hours;days gbe the
accuracy of timestamps, type2 fset;mult;seq;relg, andatt2 fac;re;arg.
el(t)satisestlkc -privacy if and only if for any cand2bkl
type;att (el(t))
such thatmatchel(t)
type;att (cand)6=;:
{jmatchel(t)
type;att (cand)jk, wherek2n>0, and
{pr(sjcand) =jfp2matchel(t)
type;att (cand )js(p)=sgj
jmatchel(t)
type;att (cand )jcfor anys2s, where
0< c1is a real number as the condence threshold, and s(p)is the
projection of the process instance on the sensitive attribute value.16 majid raei and wil m.p. van der aalst
the tlkc -privacy provides a major relaxation from traditional k-anonymity
based on a reasonable assumption that the adversary has restricted knowledge. it
generalizes several privacy preservation techniques including k-anonymity, con-
dence bounding, ( ;k)-anonymity, and l-diversity. it also provides interpretable
parameters. note that the type and attribute of background knowledge implicitly
show the perspective (figure 2).
5.2.1 privacy measure in the subsection, we dene (minimal) violating
traces w.r.t. the privacy requirements of the tlkc -privacy.
denition 15 (violating trace). letel p be an event log, lbe the
maximal size of background knowledge, t2fseconds;minutes;hours;days gbe
the accuracy of timestamps, type2fset;mult;seq;relg,att2fac;re;arg,ps2
ps be the corresponding perspective w.r.t. the given type andatt, andv
ps(0)such that (c;0;s)2el(t).is a violating (sub)trace with respect to
thetlkc -privacy requirements if there exists a cand2bkl
type;att (el(t)):
{candv_candfe2g_cand[e2], and
{jmatchel(t)
type;att (cand)j<k orpr(sjcand)>c for somes2s.
an event log satises tlkc -privacy, if all violating traces w.r.t. the given
privacy requirement are removed. a na ve approach is to determine all violating
traces and remove them. however, this approach is inecient due to the numer-
ous number of violating traces, even for a weak privacy requirement. moreover,
as demonstrated in [31], tlkc -privacy is not monotonic w.r.t. l. in fact, the
anonymity threshold kis monotonic w.r.t. l, i.e., ifl0landc= 100%, an
event logelwhich satises tlkc -privacy must satisfy tl0kc-privacy. how-
ever, condence threshold cis not monotonic w.r.t. l, i.e., ifis non-violating
trace, its subtrace may or may not be non-violating. therefore, we have to make
sure that the conditions should hold for any l0l. to this end, in the follow-
ing, we dene the extended version of minimal violating traces w.r.t. the dierent
perspectives.
denition 16 (minimal violating trace). letelp be an event log, lbe
the maximal size of background knowledge, t2fseconds;minutes;hours;days g
be the accuracy of timestamps, type2fset;mult;seq;relg,att2fac;re;arg,
ps2 ps be the corresponding perspective w.r.t. the given type andatt, and
vps(0)such that (c;0;s)2el(t).is a minimal violating trace if is
a violating trace (definition 15)in theel, and every proper subtrace of is
not violating. we denote mvtel
psas the set of minimal violating traces in the
event logelw.r.t. the perspective ps.
every violating trace in an event log is either a minimal violating trace or it
contains a minimal violating trace. therefore, if an event log contains no minimal
violating trace, then it contains no violating trace. note that the set of minimal
violating traces in an event log is much smaller than the set of violating traces
in the event log which results in better eciency for removing violating traces.group-based privacy preservation techniques for process mining 17
5.2.2 utility measure in the tlkc -privacy, the maximal frequent traces
are dened as a measure for considering data utility, where traces contain activ-
ityand timestamp attributes. since we extend the tlkc -privacy preservation
technique to cover all the main perspectives of process mining, the utility mea-
sure also needs to be extended. in the following, we provide an extended version
of the utility measure considering the perspectives.
denition 17 (maximal frequent trace). letel be an event log, and
ps2ps be a perspective. for a given minimum support threshold , a non-
empty trace vps(0)such that (c;0;s)2elis maximal frequent in the el
ifis frequent, i.e., the frequency of is greater than or equal to , and no
supertrace of is frequent in the el. we denote mftel
psas the set of maximal
frequent traces in the event log elw.r.t. the perspective ps.
the goal of data utility is to preserve as many mft as possible w.r.t. the
given perspective. for example, in the control-ow perspective, i.e., ps=a, the
goal in to preserve the maximal frequent traces w.r.t. the activities. note that
in an event log, the set of maximal frequent traces is much smaller than the set
of frequent traces. moreover, any subtrace of a maximal frequent trace is also a
frequent trace, and once all the mfts are discovered, the support counts of any
frequent subtrace can be computed by scanning the data once.
5.2.3 balancing privacy and utility as discussed in the privacy measure
section, to provide the desired privacy requirements, all the minimal violating
traces need to be removed. however, this should be done w.r.t. the utility mea-
sure. according to denition 16, every proper subtrace of a minimal violating
trace is not violating. therefore, a minimal violating trace can be removed after
removing one event of the trace. this event needs to be chosen w.r.t. both util-
ity and privacy measures. to this end, a greedy function is dened to choose an
event to remove from the minimal violating traces such that it maximizes the
number of removed minimal violating traces, i.e., privacy gain, yet, at the same
time, minimizes the number of removed maximal frequent traces, i.e., utility loss.
denition 18 (score, privacy gain, utility loss). letel be an event
log,ps2ps be a perspective, and eventsps(el) =fe2ps()j(c;;s )2
elgbe the set of events in the event log w.r.t. the given perspective. scoreel
ps:
e9 r>0is a function which retrieves the score of the events in the event log
w.r.t. the perspective. for e2eventsps(el),scoreel
ps(e) =pgel
ps(e)=ulel
ps(e)+1.
pgel
ps(e)is the number of mvts containing the event e, i.e.,pgel
ps(e) =jfx2
mvtel
psje2xgjandulel
ps(e)is the number of mfts containing the event e,
i.e.,ulel
ps(e) =jfx2mftel
psje2xgj.
note that in the score (denition 18), 1 is added to the denominator to
avoid diving by zero (when edoes not belong to any mft). the event ewith the
highest score is called the winner event, denoted by ew. algorithm 1 summarizes
all the steps of tlkc -privacy. in the following, we show how the algorithm
works on the event log table 3.18 majid raei and wil m.p. van der aalst
algorithm 1: tlkc -privacy - extended w.r.t. the dierent perspec-
tives.
input: original event log el
input:t,l,k,c, and  (frequency threshold)
input: background knowledge type and attribute ( bktype;att ), sensitive attributes s
output: anonymized event log el0which satises the desired tlkc -privacy
requirements
1generatemftel
psandmvtel
ps;
2generatemfttree
ps andmvttree
ps as the prex trees for mftel
psandmvtel
ps;
3while there is node (event) in mvttree
psdo
4 select an event (node) ewthat has the highest score to suppress based on socre (e)el
ps;
5 delete all the mvts and mfts containing the event ewfrommvttree
ps andmfttree
ps;
6 updatesocre (e)el
psfor all the remaining events (nodes) in mvttree
ps;
7 addewto the suppression set supel;
8end
9foreache2supeldo
10 suppress all instances of efromel;
11end
12return suppressed elasel0;
suppose that table 3 shows a simple event log elwhere timestamps are
represented by integer values as hours. the rst line in algorithm 1 generates
the set of maximal frequent traces ( mftel
ps) and the set of minimal violating
traces (mvtel
ps) from the event log elwitht=hours ,l= 2,k= 2,
c= 50%,  = 25%, disease as the sensitive attribute s, andbkel
rel;ar as the
background knowledge, i.e., ps=art . figure 4 shows the mfttree
ps
andmvttree
psgenerated by line 2 in algorithm 1, where each root-to-leaf path
represents one trace, and each node represents an event in a trace with the
frequency of occurrence. table 6 shows the initial score of every event (node)
in themvttree
ps(scoreel
ps(e)). line 4 determines the winner event ewwhich is
(vi;d 1;5). line 5 deletes all the mvts and mfts containing the winner event
ew, i.e., subtree 2 and the path h(re;e 4;1);(vi;d 1;5)iof subtree 1 in the
mvttree
ps, and the pathh(ho;e 3;4);(vi;d 1;5);(bt;n 1;7)iof subtree 4 in
themfttree
psare removed and frequencies get updated. line 6 updates the scores
based on the new frequencies of events. table 7 shows the remaining events in
mvttree
pswith the updated scores. line 7 adds the winner event to a suppression
setsupel. lines 4-7 is repeated until there is no node in mvttree
ps. according
to table 7 the next winner event is ( re;e 4;1), and after deleting all the mvts
and mfts containing this event, mvttree
psis empty. therefore, at the end of
thewhile loop, the suppression set supel=f(vi;d 1;5);(re;e 4;1)g. the
foreach loop suppresses all the instances of the events, i.e., global suppression ,
in thesupelfrom theel, and the last line returns the suppressed elas the
anonymized event log el0which is shown in table 8.
compared to the table 4 and table 5 which are the results of applying
traditional k-anonymity using baseline -2, table 8 shows that tlkc -privacy
removes less events (only 6), for the stronger privacy requirements.group-based privacy preservation techniques for process mining 19
mft:9
(re,e4,1):3 (bt,n1,7):1
(vi,d1,8):1(vi,d1,6):1
(vi,d1,8):1(vi,d1,8):1 (bt,n1,7):1(vi,d1,6):2 (ho,e3,4):3
(rl,e2,9):1(vi,d1,8):1
(rl,e2,9):1(rl,e2,9):1 (bt,n1,7):1 (vi,d1,5):1 (rl,e2,9):1 (vi,d1,8):1
(bt,n1,7):11 2 3 4
(a)mfttree
ps
mvt :5
(re,e4,1):3 (vi,d1,5):2
(vi,d1,5):1 (ho,e3,4):1 (bt,n1,7):1 (rl,e2,9):1 (vi,d1,8):11 2
(b)mv ttree
ps
fig. 4: the mfttree
psandmv ttree
psgenerated for the event log table 3 with t=hours ,
l= 2,k= 2,c= 50%,  = 25%, s=disease , and bkel
rel;ar .
table 6: the initial scores for the events in fig. 4b.
(re;e 4;1)(ho;e 3;4)(vi;d 1;5)(bt;n 1;7)(vi;d 1;8)(rl;e 2;9)
pgel
ps(e) 3 1 3 1 1 1
ulel
ps(e)+1 4 4 2 5 6 5
scoreel
ps(e) 0.75 0.25 1.50 0.20 0.16 0.20
5.2.4 new utility measure and new score in this subsection, we rst
describe the shortcomings of the utility measure and the score introduced in [31]
(extended in denition 17 and denition 18), then we introduce a new utility
measure and a new score to overcome the drawbacks. according to denition 18,
the score is calculated based on the existence of events in the set of minimal vio-
lating traces and the set of maximal frequent traces. however, the sizes of these
sets, and consequently the included events, highly depends on the corresponding
parameters. the set of mvts is obtained based on t,l,k,c, andbktype;att ,
while the set of mfts is discovered based on  and the given perspective. there-
fore, some of the events included in the set of minimal violating traces may not
be included in the set of maximal frequent traces. consequently, the score of
the corresponding events is merely calculated based on the eect on the privacy
gain. when two or more events have the same score based on the privacy gain ,
the algorithm assumes an equal eect for the data utility aspect and randomly
choose one of the events, which is not a valid assumption.20 majid raei and wil m.p. van der aalst
table 7: the rst updated scores.
(re;e 4;1)(ho;e 3;4)(bt;n 1;7)
pgel
ps(e) 2 1 1
ulel
ps(e)+1 4 3 4
scoreel
ps(e) 0.5 0.33 0.25
table 8: the anonymized event log for table 3 with t=hours ,l= 2, k= 2,
c= 50%,  = 25%, s=disease , and bkel
rel;ar .
case id trace disease
1h(ho;e 3;4);(bt;n 1;7);(vi;d 1;8)icancer
2h(bt;n 1;7);(vi;d 1;8);(rl;e 2;9)iinfection
3h(ho;e 3;4);(bt;n 1;7);(rl;e 2;9)icorona
4h(vi;d 1;6);(vi;d 1;8);(rl;e 2;9)iinfection
5h(ho;e 3;4);(vi;d 1;8);(rl;e 2;9)icorona
6h(vi;d 1;6);(bt;n 1;7);(rl;e 2;9)iflu
7h(bt;n 1;7);(vi;d 1;8);(rl;e 2;9)iflu
8h(vi;d 1;6);(bt;n 1;7);(vi;d 1;8)icancer
another problem with the current score is that even when there are maximal
frequent traces where the event is included, the score does not dierentiate the
corresponding mfts based on their frequencies in the event log. for example,
suppose that for two events e1ande2in the minimal violating traces there are
two maximal frequent traces mft 1andmft 2such thate1is only included
inmft 1, i.e.,ul(e1) = 1, and e2is only included in mft 2, i.e.,ul(e2) =
1. hence, both events get the same score for the utility aspect. however, the
corresponding mfts may have completely dierent frequencies in the event
log which leads to a dierent impact on the utility. particularly, this issue is
highlighted when the frequency threshold () is rather low. for example, if
 = 50%, then frequency of mft 1andmft 2in the event log could dier up
to 50%. furthermore, the current score is not normalized, and it is not possible
for the user to adjust the eect of each aspect on the score. for example, one
may want to consider more eect for the data utility aspect compared to the
privacy gain aspect.
to overcome the above-mentioned shortcomings, we dene a new utility mea-
sure that is able to show the impact of every single event on the data utility.
we also dene a new score based on the new utility measure which provides
normalized scores, and the eect of each aspect is adjustable for users. in the
new utility measure (denition 19), we consider the relative frequency of the
variants, where the given perspective of the event is included, as the basis of the
utility.
denition 19 (new utility measure). letel be an event log, ps2ps
be a perspective, and eventsps(el) =fe2ps()j(c;;s )2elgbe the set
of events in the event log w.r.t. the given perspective. for e2eventsps(el),
nulel
ps(e) = 1 p
f2gelje2ps()gfreqel().
denition 20 (new score). letelbe an event log, ps2ps be a perspective,
eventsps(el) =fe2ps()j(c;;s )2elgbe the set of events in the event loggroup-based privacy preservation techniques for process mining 21
algorithm 2: tlkc -privacy - extended w.r.t. the dierent perspec-
tives, new score, and new utility measure.
input: original event log el
input:t,l,k,c
input: background knowledge type and attribute ( bktype;att ), sensitive attributes s
output: anonymized event log el0which satises the desired tlkc -privacy
requirements
1generatemvtel
psandmvttree
ps;
2while there is node (event) in mvttree
psdo
3 select an event (node) ewthat has the highest score to suppress based on
n-socre (e)el
ps;
4 delete all the mvts containing the event ewfrommvttree
ps;
5 updaten-socre (e)el
psfor all the remaining events (nodes) in mvttree
ps;
6 addewto the suppression set supel;
7end
8foreache2supeldo
9 suppress all instances of efromel;
10end
11return suppressed elasel0;
w.r.t. the given perspective, be the coecient of privacy gain (01),be
the coecient of utility loss (01), and+= 1.n-scoreel
ps:e9 r>0
is a function which retrieves the score of the events in the event log w.r.t. the
perspective. for e2eventsps(el),n-scoreel
ps(e) =rpgel
ps(e)+nulel
ps(e),
whererpgel
ps(e)is the relative value of the privacy gain, i.e., rpgel
ps(e) =
jfx2mvtel
psje2xgj=jmvtel
psj.
algorithm 2 shows the new algorithm based on the new utility measure and
new score, where maximal frequent traces are not used anymore, and the score
of events included in the minimal violating traces is calculated based on the new
score. note that in both algorithm 1 and algorithm 2 the perspective is derived
from the background knowledge type and attribute (figure 2).
6 experiments
in this section, we evaluate the extended tlkc -privacy by applying it to real-life
event logs. we explore the eect of applying the technique on both data util-
ityand result utility . the results are also compared with the baseline methods.
the result utility analysis evaluates the similarity of the specic results obtained
from the privacy-aware event log with the same type of results obtained from
the original event log, while the data utility analysis compares the privacy-aware
event log with the original event log. as discussed in [29], the result utility anal-
ysis is highly dependent on the underlying algorithm generating specic results,
and the data utility analysis provides a more general evaluation. we perform
the evaluation for the three main perspectives including control-ow ,organiza-
tional , and time perspectives. for the result utility analysis, in each perspective,
we focus on a specic type of results. for the control-ow perspective, we fo-
cus on process discovery , for the organizational perspective, we perform social22 majid raei and wil m.p. van der aalst
table 9: the general statistics of the event logs used in the experiments.
event log #cases #events#unique
activity#unique
resource#unique
(activity,resource)
sepsis-cases [22] 1050 15214 16 - -
bpic-2012-app [37] 13087 60849 10 61 301
bpic-2017-app [38] 31509 239595 10 144 927
network discovery , and for the time perspective, we perform bottleneck analysis .
the implementation as a python program is available on github.1
6.1 experimental setup
for the experiments, we employ two human-centered event logs, where the case
identiers refer to individuals: sepsis-cases, bpic-2012-app, and bpic-2017-
app. sepsis-cases [22] is a real-life event log containing events of sepsis cases
from a hospital. bpic-2012-app [37] is also a real-life event log about a loan
application process taken from a dutch nancial institute. bpic-2017-app also
pertains to a loan application process of a dutch nancial institute. table 9
shows the general statistics of these event logs. the sepsis-cases event log was
included in the experiments because it has some challenging features for privacy
preservation techniques, namely, 80% of traces are unique based on the activity
perspective which imposes signicant challenges for privacy-preserving process
discovery algorithms [31,13,23]. bpic-2017-app has similar properties w.r.t. the
resource perspective, i.e., 76% of traces are unique w.r.t. the resource perspec-
tive. note that sepsis-cases does not contain resource information and cannot
be used for the organizational perspective analysis. we employ bpic-2012-app
and bpic-2017-app for the organizational perspective. table 10 shows some
statistics about the variants with respect to dierent perspectives. for exam-
ple, as mentioned, in sepsis-cases, 80% of traces are unique from the activity
perspective, or in bpic-2017-app, 76% of traces are unique from the resource
perspective.
overall, we performed more than 1000 experiments for the four dierent
types of background knowledge and dierent perspectives. 200 dierent settings
are used based on the following values for the main parameters: l2f2;3;4;5;6g,
k2f20;30;40;50;60g,c2f0:2;0:3;0:4;0:5g, andt2fhours;minutesg. we
consider equal weights for the privacy gain and utility loss aspects of the score,
table 10: some statistics regarding the variants of the event logs used in the experi-
ments w.r.t. the dierent perspectives.
event log#variants
activity perspective#variants
resource perspective#variants
(activity,resource) perspective
sepsis-cases [22] 846 - -
bpic-2012-app [37] 17 2974 3872
bpic-2017-app [38] 102 24230 24471
1https://github.com/m4jidraei/tlkc-privacy-extgroup-based privacy preservation techniques for process mining 23
0.901
0.901
0.876
0.377
0.889
0.924
0.716
0.376
0.531
0.800
0.9030.567
0.567
0.383
0.683
0.416
0.359
0.413
0.882
1.000
0.650
0.5280.696
0.696
0.533
0.486
0.567
0.517
0.524
0.527
0.694
0.717
0.666
0.000.100.200.300.400.500.600.700.800.901.00fitness precision f1-score
(a) the measures with the weak setting.
0.858
0.853
0.625
0.336
0.854
0.851
0.444
0.235
0.000
0.640
0.9030.457
0.375
0.914
1.000
0.441
0.477
0.999
1.000
0.000
0.947
0.5280.596
0.521
0.742
0.503
0.582
0.611
0.615
0.381
0.000
0.764
0.666
0.000.100.200.300.400.500.600.700.800.901.00fitness precision f1-score (b) the measures with the strong setting.
fig. 5: the quality measures comparison between the four variants of tlkc and
tlkc -ext , the original results, and the baseline methods for sepsis-cases.
i.e.,= 0:5 and= 0:5. in sepsis-cases, \diagnose" and \age" are considered as
the sensitive case attribute. the numerical attributes are converted to categorical
attributes using boxplots such that all the values greater than the upper quartile
are categorized as high, the values less than the lower quartile are categorized
aslow, and the values in between are categorized as middle . note that the
condence value cshould not be greater than 0.5, i.e., there are at least two
dierent sensitive values for a victim case. to show and interpret the results of
experiments, we focus on specic strong andweak settings. we use t=minutes ,
l= 2,k= 20, andc= 0:5 as the weak setting, and t=minutes ,l= 6,
k= 60, andc= 0:2 as the strong setting. note that in the experiments, tlkc
refers to the algorithm presented in [31] which has been extended here w.r.t. the
dierent perspectives, i.e., algorithm 1, and tlkc -ext refers to algorithm 2.
6.2 control-ow perspective
in this subsection, we evaluate the eect of applying the extended tlkc -privacy
on the result utility anddata utility with respect to the control-ow perspective.
we perform the control-ow perspective analysis for both event logs.
6.2.1 result utility as mentioned, for the result utility analysis of the
control-ow perspective, we focus on process discovery . the main goal is to
nd out how accurately the discovered process model from a privacy-aware event
log capture the behavior of the original event log . to this end, we rst discover
a process model m0from the privacy-aware event log el0. then, for m0, we
calculate tness ,precision , and f1-score , as some model quality measures, w.r.t.
the original event log el.
fitness quanties the extent to which the discovered model can reproduce the
traces recorded in the event log [4]. precision quanties the fraction of the traces
allowed by the model which is not seen in the event log [5], and f1-score combines24 majid raei and wil m.p. van der aalst
0.989 0.986
0.872
0.1540.998 0.998 0.988
0.249
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relativedata utility
background knowledge typetlkc tlkc-ext
(a) the data utility with the weak setting.
0.909
0.701
0.298
0.1020.930
0.817
0.567
0.123
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relativedata utility
background knowledge typetlkc tlkc-ext (b) the data utility with the strong set-
ting.
fig. 6: the data utility comparison between tlkc and tlkc -ext which provide
the same privacy guarantees for the sepsis-cases event log.
the tness and precision f1-score =2precisionfitness=precision +fitness . for pro-
cess discovery, we use the inductive miner infrequent algorithm [16] with the
default parameters (noise threshold 0.2). figure 5 shows the results of experi-
ments for the quality measures. we consider four variants of our privacy preser-
vation technique based on the introduced types of background knowledge where
the attribute is activity , i.e.,bkset;at,bkmult;at ,bkseq;at , andbkrel;at. note that
applying privacy preservation techniques may improve some quality measures.
however, the aim is to provide as similar results as possible to the original ones
and not to improve the quality of discovered models. therefore, we include the
results from the original event log to compare the proximity of the values.
figure 5a and 5b show how the mentioned quality measures are aected
by applying our method with the weak and strong settings (for tlkc , we set
 = 0:5). we compare the measures with the results from the original pro-
cess model and the introduced baseline methods. if we only consider the quality
measures, baseline -2 should be marked as the best one, since it results in bet-
terf1-score values. however, the baseline methods remove more events from
the original event log. consequently, the corresponding privacy-aware event logs
contain signicantly less behavior compared to the original event log, and the re-
sulting models have high precision andf1-score . the result utility analyses show
that the extended version of the tlkc -privacy leads to the more similar results
to the original ones, specically for the setand multiset types of background
knowledge. however, the results obtained based on the relative type of back-
ground knowledge have a worse tness value which is not surprising regarding
the assumed background knowledge which is considerably strong, at the same
time, dicult to achieve in reality. note that the baseline methods do not pro-
tect event data against the attribute linkage attack and provide weaker privacy
guarantees.group-based privacy preservation techniques for process mining 25
0.995
0.995
0.995
0.852
0.995
0.995
0.995
0.566
0.000
0.990
0.9950.925
0.925
0.925
1.000
0.925
0.925
0.925
1.000
0.000
0.927
0.9250.959
0.959
0.959
0.920
0.959
0.959
0.959
0.723
0.000
0.957
0.959
0.000.100.200.300.400.500.600.700.800.901.00fitness precision f1-score
(a) the quality measures comparison be-
tween the four variants of tlkc andtlkc -
ext , the original results, and the baseline
methods.
1.000 1.000
0.4251.000
0.788
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relativedata utility
background knowledge type tlkc tlkc-ext(b) the data utility comparison be-
tween tlkc and tlkc -ext .
fig. 7: the data and result utility analyses for bpic-2012-app considering the strong
setting.
6.2.2 data utility for the data utility analysis, we utilize the earth mover's
distance , as proposed in [29]. the earth mover's distance describes the distance
between two distributions [34]. in an analogy, given two piles of earth, it de-
scribes the eort required to transform one pile into the other. assuming el
as the original event log, el0as a privacy-aware event log, and ps2ps as the
perspective of analysis. the data utility is calculated as follows: du(el;el0) =
1 minr2raul(r;elps;el0ps) whereul(r;elps;el0ps) is the distance between
the traces of two event logs projected on the given perspective. note that r2ra
is used as a reallocation function, and normalized edit distance (levenshtein) [18]
is used to calculate the distance between variants. it should also be noted that
for the control-ow ps=a.
figure 6 shows the results of data utility analysis where we compare tlkc
and tlkc -ext which provide the same privacy guarantees. as can be seen,
for the weak privacy setting, the data utility results are similar, and tlkc -
ext performs slightly better for the stronger types of background knowledge.
for the strong privacy setting, tlkc -ext performs considerably better for
themultiset and sequence types of background knowledge. comparing the data
utility analysis with the result utility analysis shows that the model quality
measures alone cannot precisely evaluate the eectiveness of the privacy preser-
vation techniques. for example, in the result utility analysis, for both weak and
strong setting, tlkc -ext results in an acceptable f1-score value. however,
the data utility analysis shows that the utility loss is indeed high for this type
of background knowledge.
as already mentioned, the sepsis-cases event log is a signicantly challenging
dataset for the privacy preservation techniques due to the high uniqueness of
variants. to show the eectiveness of our privacy preservation technique on other
event logs, we perform the same type of analyses for bpic-2012-app considering26 majid raei and wil m.p. van der aalst
only the strong setting. figure 7 shows that both data and result utility are high
even for the strong types of background knowledge.
6.3 organizational perspective
in this subsection, we evaluate the eect of applying the extended tlkc -privacy
on the result anddata utility of the organizational perspective. the experiments
of this perspective are done on bpic-2012-app which includes resource infor-
mation.
6.3.1 result utility for the result utility analysis of organizational perspec-
tive, we focus on the social network discovery techniques. there are dierent
methods for discovering social networks from event logs such as causality-based ,
joint activities ,joint cases , etc [3]. here, we focus on the handover technique
which is causality-based. this technique monitors for individual cases how work
moves from resource to resource, i.e., there is a handover relation from individ-
ualr1to individual r2, if there are two subsequent activities where the rst is
performed by r1and the second is performed by r2.
figure 8 shows the handover networks discovered from the original event
log and a privacy-aware event log when the relation threshold is 0, i.e., all the
handovers. the privacy-aware event log was obtained using the tlkc -ext
privacy preservation technique with the strong setting and setas the type of
background knowledge. as expected, the density of the network discovered from
the privacy-aware event log is less than the original handover network. however,
by focusing on some specic nodes, one can see that basic concepts are preserved.
for example, node 11339 in the original handover network has the following
set of input linksf11302;11003;11300;11121;11122;11180;10932;10861gand no
output link (excluding the self-loop), and in the network discovered from the
privacy-aware event log, only the input link from node 11121 is removed.
to quantify the similarity of social networks resulting from an original and
a privacy-aware event log, we use a set of measures similar to the quality mea-
sure of process models, i.e., tness ,precision , and f1-score . consider sn =
(rel;dfel
r) andsn0= (rel0;dfel0
r) as the handover social networks ob-
tained from an original event log and its corresponding privacy-aware event
log, respectively. since both tlkc and tlkc -ext provide privacy guaran-
tees by removing events, the vertices of sn0is a subset of vertices in sn, i.e.,
relrel0. however, the set of edges in sn0is not necessarily a subset of
edges insn, i.e.,sn0is not necessarily a subgraph of sn. the following equa-
tions are used to compute the tness (fsn) and the precision (psn) for handover
networks. the f1-score for handover networks ( f1sn) is the harmonic mean of
fsnandpsn.
fsn=x
(x;y)2dfel
r\dfel0
rjx >el0
ryj
x
(x;y)2dfel
rjx >el
ryjpsn=j(relrel)ndfel
r\(relrel)ndfel0
rj
j(relrel)ndfel
rjgroup-based privacy preservation techniques for process mining 27
(a) the original handover net-
work.
(b) the handover network discovered from
the privacy-aware event log.
(c) the relations of the resource 11339 in
the original handover network. the node
has 8 input links and no output link, ex-
cept the self-loop.
(d) the relations of the resource 11339 in
the handover network resulting from the
privacy-aware event log. the node has 7
input links and no output link, except the
self-loop.
fig. 8: the handover networks discovered from the original event log and a privacy-
aware event log for bpic-2012-app. the privacy-aware event log was obtained using
tlkc -ext with the strong setting and setas the type of background knowledge.28 majid raei and wil m.p. van der aalst
0.843
0.537 0.511
0.3361.000 1.000 1.000 1.000
0.915
0.699 0.676
0.503
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relative
background knowledge typef_sn p_sn f1_sn
(a) the handover social network com-
parison for the graphs obtained from the
bpic-2012-app event log.
0.983
0.783
0.3640.310.970 1.000 0.999 0.991
0.866
0.5340.473
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relative
background knowledge typef_sn p_sn f1_sn(b) the handover social network com-
parison for the graphs obtained from the
bpic-2017-app event log.
fig. 9: the social network comparison based on tness (fsn),precision (psn), and
f1-score (f1sn). the privacy preservation technique is tlkc -ext with the strong
setting.
figure 9 shows the similarity of handover social networks after applying the
tlkc -ext privacy model with the strong setting to bpic-2012-app and
bpic-2017-app. the precision is high for all the types of background knowl-
edge, i.e., the handover social networks obtained from the privacy-aware event
logs often do not contain edges that do not exist in the original network. the
tness decreases when the background knowledge becomes stronger, i.e., the
sn0s obtained based on stronger assumptions for the background knowledge
have fewer edges in common with the sn.
6.3.2 data utility for the data utility analysis of the organizational perspec-
tive, we utilize the earth mover's distance, similar to the data utility analysis
of the control-ow perspective. here, the perspective is resource, i.e., ps=r.
figure 10 shows the results for the data utility analysis for bpic-2012-app
considering dierent types of background knowledge using tlkc -ext as the
privacy preservation technique. as can be seen, the data utility reservation is
above 0.5 even for the strong types of background knowledge.
6.4 time perspective
we evaluate the eect on performance analyses by analyzing the bottlenecks
w.r.t. the mean duration of cases between activities. since the privacy preserva-
tion techniques may remove some activities, we cannot compare the bottlenecks
in the original process model with the bottlenecks in a process model discovered
from a privacy-aware event log. therefore, we rst project the original event
log on the activities existing in the privacy-aware event log. then, we discover
a performance-annotated directly follows graph dfg from the projected event
log and compare it with the performance-annotated directly follows graph dfg0group-based privacy preservation techniques for process mining 29
0.808
0.7010.655
0.595 0.695
0.6470.635
0.518
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relativedata utility
background knowledge typeweak setting strong setting
fig. 10: the data utility analysis of organizational perspective for bpic-2012-app with
the strong and weak settings considering dierent types of background knowledge, and
using tlkc -ext as the privacy preservation technique.
from the privacy-aware event log. a dfg is a graph where the nodes represent
activities and the arcs represent causalities. two activities a1anda2are con-
nected by an arrow when a1is frequently followed by a2[17].
figure 11 ( setand multiset as the types of background knowledge) and fig-
ure 12 ( sequence and relative as the types of background knowledge) show the
results for sepsis-cases using tlkc -ext with the strong setting.2as can be
seen, the bottlenecks in dfg anddfg0are the same for all the variants, except
for dfgs discovered using bkrel;ac , where the assumed background knowledge is
relative which is signicantly strong and our data utility analysis in section 6.2
demonstrated a low data utility preservation for sepsis-cases. note that the
mean duration of the cases are dierent in dfg anddfg0due to the relative
timestamps in the privacy-aware event logs.
we also evaluate the similarity of the directly follows graphs (dfgs) result-
ing from an original event log and its corresponding privacy-aware event log. let
dfg =(ael;dfel
a) anddfg0=(ael0;dfel0
a) be the directly follows graphs
obtained from an original and its corresponding privacy-aware event logs, re-
spectively. to compare these graphs, we follow the same approach taken for
quantifying the similarity of social networks. the tness (fdfg) and precision
(pdfg) for dfgs are calculated as follows:
fdfg=x
(x;y)2dfel
a\dfel0
ajx >el0
ayj
x
(x;y)2dfel
ajx >el
ayjpdfg=j(aelael)ndfel
a\(aelael)ndfel0
aj
j(aelael)ndfel
aj
the f1-score for dfgs (f1dfg) is the harmonic mean of fdfgandpdfg. fig-
ure 13 shows the similarity of dfgs after applying the tlkc -ext privacy
model with the strong setting for sepsis-cases, bpic-2012-app, and bpic-
2the results provided by disco (https://uxicon.com/disco/) with the sliders set
to the maximal number of activities and the minimal paths.30 majid raei and wil m.p. van der aalst
10.1 mins
15.1 hrs2.2 hrs
13.4 mins
6.3 hrs2.9 mins
13.1 hrs17.3 mins11.8 mins
12.5 minser registration
instant
leucocytes
instant
crp
instantlacticacid
instanter triage
instant
er sepsis triage
instant
iv liquid
instant
iv antibiotics
instant
(a)dfg0-bkset;ac
10.6 mins
26.3 hrs2.8 hrs
13.5 mins
7.2 hrs2.9 mins
14.2 hrs17.2 mins12.3 mins
12.5 minser registration
instant
leucocytes
instant
crp
instantlacticacid
instanter triage
instant
er sepsis triage
instant
iv liquid
instant
iv antibiotics
instant (b)dfg -bkset;ac
10.1 mins
17.7 hrs2.2 hrs
14.5 mins
5.1 hrs3.1 mins
12.7 hrs16.9 mins
95.4 mins11.8 mins
20.8 minser registration
instant
leucocytes
instant
crp
instantlacticacid
instanter triage
instant
er sepsis triage
instant
iv liquid
instant
iv antibiotics
instant (c)dfg0-bkmult;ac
10.6 mins
26.3 hrs2.8 hrs
13.5 mins
7.2 hrs2.9 mins
14.2 hrs17.2 mins12.3 mins
12.5 minser registration
instant
leucocytes
instant
crp
instantlacticacid
instanter triage
instant
er sepsis triage
instant
iv liquid
instant
iv antibiotics
instant (d)dfg -bkmult;ac
fig. 11: the performance-annotated dfgs from the projected event log ( dfg ) and
an anonymized event log ( dfg0) for sepsis-cases using tlkc -ext with the strong
setting and the specied types of background knowledge.
12.7 hrs11.9 mins
5.4 hrs
2 hrs 14.3 hrs
4.9 d26.1 minser registration
instant
leucocytes
instanter sepsis triage
instant
iv antibiotics
instantcrp
instant
release a
instant
(a)dfg0-bkseq;ac
41.8 mins
43.7 mins12.4 mins
35.8 mins 5.3 hrs
25.1 hrs
7.1 hrs 13.2 hrs
7.9 hrs53 hrser registration
instant
leucocytes
instant
crp
instanter sepsis triage
instant
iv antibiotics
instant
release a
instant (b)dfg -bkseq;ac
2.6 mins
18.9 secser registration
instant
er triage
instant
er sepsis triage
instant (c)dfg0-bkrel;ac
11.1 mins
10.9 mins92.7 mins
2.9 hrser registration
instant
er triage
instant
er sepsis triage
instant (d)dfg -bkrel;ac
fig. 12: the performance-annotated dfgs from the projected event log ( dfg ) and
an anonymized event log ( dfg0) for sepsis-cases using tlkc -ext with the strong
setting and the specied types of background knowledge.group-based privacy preservation techniques for process mining 31
0.8320.654
0.3817
0.02041.000 1.000 0.978 1.000
0.908
0.791
0.549
0.040.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relative
background knowledge typef_dfg p_dfg f1_dfg
(a) the dfg comparison for the graphs
obtained from the sepsis-cases event log.
0.4171.000 1.000 1.000 0.987 1 1 1
0.587
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relative
background knowledge typef_dfg p_dfg f1_dfg(b) the dfg comparison for the graphs
obtained from the bpic-2012-app event
log.
0.983
0.3641.000 1.0000.9581 0.991
0.528
0.00.10.20.30.40.50.60.70.80.91.0
set multiset sequence relative
background knowledge typef_dfg p_dfg f1_dfg
(c) the dfg comparison for the graphs
obtained from the bpic-2017-app event
log.
fig. 13: the dfg comparison based on tness (fd fg),precision (pd fg), and f1-score
(f1d fg). the privacy preservation technique is tlkc -ext with the strong setting.
2017-app. the precision is always high, i.e., the dfgs obtained from the privacy-
aware event logs often do not contain directly follows relations that do not exist
in the original dfg. for the sepsis-cases event log, the tness decreases when
the background knowledge becomes stronger, i.e., the dfg0s obtained based on
stronger assumptions for the background knowledge preserve fewer directly fol-
lows relations of the original dfg. the tness for the bpic event logs only drops
for the relative type of background knowledge which is considerably strong.
7 related work
in process mining, the research eld of condentiality and privacy is recently
receiving more attention. in this section, we list the work that has been done in
this research eld which is rapidly growing.
in [2], responsible process mining (rpm) is introduced as the sub-discipline
which focuses on possible negative side-eects of applying process mining where32 majid raei and wil m.p. van der aalst
fairness ,accuracy ,condentiality , and transparency (fact) are considered
as the concerns. in [24], the authors provide an overview of privacy challenges
in process mining in human-centered industrial environments. in [36], a method
to secure event logs for performing process discovery by the alpha algorithm is
proposed. in [10], the aim is to propose a solution which allows the outsourcing
of process mining while ensuring condentiality. in [25], the goal is to propose
a privacy-preserving system design for process mining, where a user-centered
view is considered to track personal data. in [32,33], a framework is proposed
which provides a generic scheme for condentiality in process mining. in [27], the
authors introduce a privacy-preserving method for discovering roles from event
logs. in [20], the authors consider a cross-organizational process discovery con-
text and share public process model fragments as safe intermediates. in [13], the
authors apply k-anonymity and t-closeness on event logs to preserve the privacy
ofresources . in [23,14], the notion of dierential privacy is employed to pre-
serve the privacy of event logs. in [31], the tlkc -privacy is introduced to cope
with high variability issues in event logs for applying group-based anonymiza-
tion techniques. in [8], a uniformization-based approach is proposed to preserve
individuals' privacy in process mining. in [11], a secure multi-party computation
solution is introduces for preserving privacy in an inter-organizational setting for
process discovery . in [26], the data privacy and utility requirements for health-
care event data are analyzed. in [30], the authors propose a privacy extension
for the xes standard3to manage privacy metadata. in [39], the authors pro-
pose a measure to evaluate the re-identication risk of event logs. also, in [29],
a general privacy quantication framework, and some measures are introduced
to evaluate the eectiveness of privacy preservation techniques. some tools are
also provided for applying the state-of-the-art privacy preservation techniques in
the led of process mining such as ppdp-pm [28], elpaas [9], and shareprom
[12].
8 conclusion
in this paper, we discussed the challenges regarding directly applying tradi-
tional group-based privacy preservation techniques to event logs. we discussed
thelinkage attacks and provided formal models of the possible attacks based on
the dierent types of background knowledge. we extended the tlkc -privacy
for process mining to cover all the main perspectives of process mining. the data
utility preservation aspect of the tlkc -privacy was improved by introducing a
new utility measure. moreover, a new score equation was proposed to generate
normalized scores for the events that need to be removed. the new equation
for the score also provides privacy gain and utility loss coecients that can be
adjusted by users. obviously, the extended version of the tlkc -privacy inherits
all the characteristics of the main approach. namely, it counteracts both the case
linkage and the attribute linkage attacks. it generalizes several privacy preserva-
3https://xes-standard.org/group-based privacy preservation techniques for process mining 33
tion techniques including k-anonymity, condence bounding, ( ,k)-anonymity,
andl-diversity. it also provides interpretable and tunable parameters.
similar to the main approach, we implemented four variants of the extended
version with respect to the four dierent types of background knowledge and
considering all the main perspectives. the eectiveness of dierent variants in
dierent perspectives was evaluated based on real-life event logs. both data and
result utility were analyzed to evaluate the eectiveness. overall more than 1000
experiments were performed for dierent types of background knowledge consid-
ering dierent perspectives, and the results were given for a weak and a strong
setting. our experiments showed that the extended tlkc -privacy performs bet-
ter than the previous version considering the data utility preservation aspect.
however, in the event logs with the high ratio of unique traces, when the assumed
type of background knowledge is very specic, e.g., relative , the group-based pri-
vacy preservation techniques may not be able to preserve the general data utility,
and this negative eect cannot be observed by only result utility analyses.
acknowledgment
funded under the excellence strategy of the federal government and the l ander.
we also thank the alexander von humboldt (avh) stiftung for supporting our
research.
references
1. van der aalst, w.m.p.: process mining - data science in action, second edition.
springer (2016). https://doi.org/10.1007/978-3-662-49851-4
2. van der aalst, w.m.p.: responsible data science: using event data in a "people
friendly" manner. in: hammoudi, s., maciaszek, l.a., missiko, m., camp, o.,
cordeiro, j. (eds.) enterprise information systems - 18th international confer-
ence, iceis 2016, rome, italy, april 25-28, 2016, revised selected papers. lec-
ture notes in business information processing, vol. 291, pp. 3{28. springer (2016).
https://doi.org/10.1007/978-3-319-62386-3 1
3. van der aalst, w.m.p., reijers, h.a., song, m.: discovering social networks from
event logs. computer supported cooperative work (cscw) 14(6), 549{593 (2005)
4. adriansyah, a., van dongen, b.f., van der aalst, w.m.p.: conformance checking
using cost-based tness analysis. in: proceedings of the 15th ieee international
enterprise distributed object computing conference, edoc. pp. 55{64 (2011)
5. adriansyah, a., munoz-gama, j., carmona, j., van dongen, b.f., van der aalst,
w.m.p.: measuring precision of modeled behavior. inf. syst. e-business manage-
ment 13(1), 37{67 (2015)
6. aggarwal, c.c.: on k-anonymity and the curse of dimensionality. in: b ohm, k.,
jensen, c.s., haas, l.m., kersten, m.l., larson, p., ooi, b.c. (eds.) proceedings of
the 31st international conference on very large data bases, trondheim, norway,
august 30 - september 2, 2005. pp. 901{909. acm (2005)
7. aggarwal, c.c., philip, s.y.: privacy-preserving data mining: models and algo-
rithms. springer science & business media (2008)34 majid raei and wil m.p. van der aalst
8. batista, e., solanas, a.: a uniformization-based approach to preserve individuals'
privacy during process mining analyses. peer-to-peer networking and applications
pp. 1{20 (2021)
9. bauer, m., fahrenkrog-petersen, s.a., koschmider, a., mannhardt, f., van der
aa, h., weidlich, m.: elpaas: event log privacy as a service. in: proceedings of
the dissertation award, doctoral consortium, and demonstration track at bpm
2019 (2019)
10. burattin, a., conti, m., turato, d.: toward an anonymous process mining. in:
future internet of things and cloud (ficloud), 2015 3rd international conference
on. pp. 58{63. ieee (2015)
11. elkoumy, g., fahrenkrog-petersen, s.a., dumas, m., laud, p., pankova, a., wei-
dlich, m.: secure multi-party computation for inter-organizational process min-
ing. in: nurcan, s., reinhartz-berger, i., soer, p., zdravkovic, j. (eds.) en-
terprise, business-process and information systems modeling - 21st interna-
tional conference, bpmds 2020, 25th international conference, emmsad 2020,
held at caise 2020, grenoble, france, june 8-9, 2020, proceedings. lecture
notes in business information processing, vol. 387, pp. 166{181. springer (2020).
https://doi.org/10.1007/978-3-030-49418-6 11
12. elkoumy, g., fahrenkrog-petersen, s.a., dumas, m., laud, p., pankova, a., wei-
dlich, m.: shareprom: a tool for privacy-preserving inter-organizational process
mining. in: proceedings of the best dissertation award, doctoral consortium,
and demonstration & resources track at bpm 2020 co-located with the 18th
international conference on business process management (bpm 2020), sevilla,
spain, september 13-18, 2020. ceur workshop proceedings, vol. 2673, pp. 72{76.
ceur-ws.org (2020)
13. fahrenkrog-petersen, s.a., van der aa, h., weidlich, m.: pretsa: event log
sanitization for privacy-aware process discovery. in: international conference on
process mining, icpm 2019, aachen, germany, june 24-26, 2019. pp. 1{8. ieee
(2019). https://doi.org/10.1109/icpm.2019.00012
14. fahrenkrog-petersen, s.a., van der aa, h., weidlich, m.: pripel: privacy-
preserving event log publishing including contextual information. in: fahland, d.,
ghidini, c., becker, j., dumas, m. (eds.) business process management - 18th
international conference, bpm 2020, seville, spain, september 13-18, 2020, pro-
ceedings. lecture notes in computer science, vol. 12168, pp. 111{128. springer
(2020). https://doi.org/10.1007/978-3-030-58666-9 7,https://doi.org/10.1007/
978-3-030-58666-9_7
15. gehrke, j.: models and methods for privacy-preserving data analysis and pub-
lishing. in: liu, l., reuter, a., whang, k., zhang, j. (eds.) proceedings
of the 22nd international conference on data engineering, icde 2006, 3-
8 april 2006, atlanta, ga, usa. p. 105. ieee computer society (2006).
https://doi.org/10.1109/icde.2006.100
16. leemans, s.j.j., fahland, d., van der aalst, w.m.p.: discovering block-structured
process models from event logs containing infrequent behaviour. in: business pro-
cess management workshops - bpm international workshops. pp. 66{78 (2013)
17. leemans, s.j., fahland, d., van der aalst, w.m.p.: scalable process discovery and
conformance checking. software & systems modeling 17(2), 599{631 (2018)
18. levenshtein, v.i.: binary codes capable of correcting deletions, insertions, and
reversals. in: soviet physics doklady. vol. 10, pp. 707{710 (1966)
19. li, n., li, t., venkatasubramanian, s.: t-closeness: privacy beyond k-anonymity
and l-diversity. in: chirkova, r., dogac, a., ozsu, m.t., sellis, t.k. (eds.) proceed-
ings of the 23rd international conference on data engineering, icde 2007, thegroup-based privacy preservation techniques for process mining 35
marmara hotel, istanbul, turkey, april 15-20, 2007. pp. 106{115. ieee computer
society (2007). https://doi.org/10.1109/icde.2007.367856
20. liu, c., duan, h., zeng, q., zhou, m., lu, f., cheng, j.: towards
comprehensive support for privacy preservation cross-organization busi-
ness process mining. ieee trans. serv. comput. 12(4), 639{653 (2019).
https://doi.org/10.1109/tsc.2016.2617331
21. machanavajjhala, a., gehrke, j., kifer, d., venkitasubramaniam, m.: l-diversity:
privacy beyond k-anonymity. in: 22nd international conference on data engineer-
ing (icde'06). pp. 24{24. ieee (2006)
22. mannhardt, f.: sepsis cases-event log. eindhoven university of technology (2016),
https://doi.org/10.4121/uuid:915d2bfb-7e84-49ad-a286-dc35f063a460
23. mannhardt, f., koschmider, a., baracaldo, n., weidlich, m., michael, j.: privacy-
preserving process mining - dierential privacy for event logs. bus. inf. syst. eng.
61(5), 595{614 (2019). https://doi.org/10.1007/s12599-019-00613-3
24. mannhardt, f., petersen, s.a., oliveira, m.f.: privacy challenges for process min-
ing in human-centered industrial environments. in: 14th international conference
on intelligent environments, ie 2018, roma, italy, june 25-28, 2018. pp. 64{71.
ieee (2018). https://doi.org/10.1109/ie.2018.00017
25. michael, j., koschmider, a., mannhardt, f., baracaldo, n., rumpe, b.: user-
centered and privacy-driven process mining system design for iot. in: cappiello,
c., ruiz, m. (eds.) information systems engineering in responsible information
systems - caise forum 2019, rome, italy, june 3-7, 2019, proceedings. lecture
notes in business information processing, vol. 350, pp. 194{206. springer (2019).
https://doi.org/10.1007/978-3-030-21297-1 17
26. pika, a., wynn, m.t., budiono, s., ter hofstede, a.h.m., van der aalst, w.m.p.,
reijers, h.a.: towards privacy-preserving process mining in healthcare. in:
francescomarino, c.d., dijkman, r.m., zdun, u. (eds.) business process manage-
ment workshops - bpm 2019 international workshops, vienna, austria, septem-
ber 1-6, 2019, revised selected papers. lecture notes in business information
processing, vol. 362, pp. 483{495. springer (2019). https://doi.org/10.1007/978-3-
030-37453-2 39
27. raei, m., van der aalst, w.m.p.: mining roles from event logs while preserv-
ing privacy. in: francescomarino, c.d., dijkman, r.m., zdun, u. (eds.) busi-
ness process management workshops - bpm 2019 international workshops, vi-
enna, austria, september 1-6, 2019, revised selected papers. lecture notes
in business information processing, vol. 362, pp. 676{689. springer (2019).
https://doi.org/10.1007/978-3-030-37453-2 54
28. raei, m., van der aalst, w.m.p.: practical aspect of privacy-preserving data
publishing in process mining. corr abs/2009.11542 (2020), https://arxiv.
org/abs/2009.11542
29. raei, m., van der aalst, w.m.p.: towards quantifying privacy in process min-
ing. in: international conference on process mining - icpm 2020 international
workshops, padua, italy, october 4-9, 2020 (2020)
30. raei, m., van der aalst, w.m.p.: privacy-preserving data publishing in process
mining. corr abs/2101.02627 (2021), https://arxiv.org/abs/2101.02627
31. raei, m., wagner, m., van der aalst, w.m.p.: tlkc-privacy model for
process mining. in: dalpiaz, f., zdravkovic, j., loucopoulos, p. (eds.) re-
search challenges in information science - 14th international conference, rcis
2020, limassol, cyprus, september 23-25, 2020, proceedings. lecture notes
in business information processing, vol. 385, pp. 398{416. springer (2020).
https://doi.org/10.1007/978-3-030-50316-1 2436 majid raei and wil m.p. van der aalst
32. raei, m., von waldthausen, l., van der aalst, w.m.p.: ensuring condentiality in
process mining. in: ceravolo, p., l opez, m.t.g., van keulen, m. (eds.) proceed-
ings of the 8th international symposium on data-driven process discovery and
analysis (simpda 2018), seville, spain, december 13-14, 2018. ceur workshop
proceedings, vol. 2270, pp. 3{17. ceur-ws.org (2018)
33. raei, m., von waldthausen, l., van der aalst, w.m.p.: supporting conden-
tiality in process mining using abstraction and encryption. in: ceravolo, p., van
keulen, m., l opez, m.t.g. (eds.) data-driven process discovery and analysis -
8th ifip wg 2.6 international symposium, simpda 2018, seville, spain, decem-
ber 13-14, 2018, and 9th international symposium, simpda 2019, bled, slovenia,
september 8, 2019, revised selected papers. lecture notes in business information
processing, vol. 379, pp. 101{123. springer (2019). https://doi.org/10.1007/978-3-
030-46633-6 6
34. r uschendorf, l.: the wasserstein distance and approximation theorems. probabil-
ity theory and related fields 70(1), 117{129 (1985)
35. sweeney, l.: k-anonymity: a model for protecting privacy. international journal
of uncertainty, fuzziness and knowledge-based systems 10(05), 557{570 (2002)
36. tillem, g., erkin, z., lagendijk, r.l.: privacy-preserving alpha algorithm for soft-
ware analysis. in: 37th wic symposium on information theory in the benelux/6th
wic/ieee sp (2016)
37. van dongen, b.f.: bpic 2012. eindhoven university of technology (2012).
https://doi.org/10.4121/uuid:3926db30-f712-4394-aebc-75976070e91f
38. van dongen, b.f.: bpic 2017. eindhoven university of technology (2017), https:
//doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b
39. von voigt, s.n., fahrenkrog-petersen, s.a., janssen, d., koschmider, a.,
tschorsch, f., mannhardt, f., landsiedel, o., weidlich, m.: quantifying the re-
identication risk of event logs for process mining - empiricial evaluation paper.
in: advanced information systems engineering, caise (2020)
40. voss, w.g.: european union data privacy law reform: general data protection
regulation, privacy shield, and the right to delisting. business lawyer 72(1) (2016)
41. wang, k., fung, b.c.m., yu, p.s.: handicapping attacker's condence: an
alternative to k-anonymization. knowl. inf. syst. 11(3), 345{368 (2007).
https://doi.org/10.1007/s10115-006-0035-5
42. wong, r.c., li, j., fu, a.w., wang, k.: (alpha, k)-anonymity: an enhanced
k-anonymity model for privacy preserving data publishing. in: eliassi-rad, t.,
ungar, l.h., craven, m., gunopulos, d. (eds.) proceedings of the twelfth
acm sigkdd international conference on knowledge discovery and data min-
ing, philadelphia, pa, usa, august 20-23, 2006. pp. 754{759. acm (2006).
https://doi.org/10.1145/1150402.1150499