process mining framework for
software processes
vladimir rubin1,2, christian w. g¨ unther1, wil m.p. van der aalst1,
ekkart kindler2, boudewijn f. van dongen1, and wilhelm sch¨ afer2
1eindhoven university of technology, eindhoven, the netherlands
{c.w.gunther,w.m.p.v.d.aalst,b.f.v.dongen }@tue.nl
2university of paderborn, paderborn, germany
{vroubine,kindler,wilhelm }@uni-paderborn.de
abstract. software development processes are often not explicitly mod-
elled and sometimes even chaotic. in order to keep track of the involved
documents and ﬁles, engineers use software conﬁguration management
(scm) systems. along the way, those systems collect and store informa-
tion on the software process itself. thus, scm information can be used
for constructing explicit process models, which is called software process
mining . in this paper we show that (1) a process mining framework can
be used for obtaining software process models as well as for analysing
and optimising them; (2) an algorithmic approach, which arose from our
research on software processes, is integrated in the framework.
1 introduction
software and information systems are still becoming more and more complex.
one of the distinguishing features of any engineering eﬀort is the fact that pro-
cess engineers create, change, update and revise all kinds of documents and ﬁles.
in order to cope with the vast amount of data, documents, and ﬁles, engineers
use product data management (pdm) systems or software conﬁguration man-
agement (scm) systems such as cvs or subversion. in addition to maintaining
the engineer’s documents, these systems collect and store information on the
process: who created, accessed, or changed which documents?, when was a
particular task completed?, etc.
the engineering processes themselves, however, are often not well-documented
and sometimes even chaotic: engineering processes tend to be far less structured
than production processes. in order to help engineers to identify, to better un-
derstand, to analyse, to optimise, and to execute their processes, the process
data stored in the scm systems can be used for extracting the underlying engi-
neering processes and for automatically constructing one or more explicit process
models . we call this software process mining .
process models and software process models cover diﬀerent aspects. here,
we consider the main aspects only: the control aspect captures the order in
which tasks are executed (i. e. the control-ﬂow), the information aspect cap-
tures the data, documents, and information needed and produced by a task,and the organisation aspect captures which persons in which role execute a task.
to mine diﬀerent aspects of software development processes – sometimes called
multi-perspective mining – we need diﬀerent algorithms. in order to make all
these algorithms available under a single user interface, we use the prom frame-
work [1]. prom provides a variety of algorithms and supports process mining in
the broadest sense. it can be used to discover processes, identify bottle-necks,
analyse social networks, verify business rules, etc. moreover, prom provides in-
terfaces to extract information from diﬀerent sources including scm systems
such as cvs and subversion.
the focus of this paper is on providing an overview of the application of pro-
cess mining to software processes. although we do not focus on the algorithms,
we discuss one process mining algorithm, which was speciﬁcally developed for
software processes and integrated in prom. moreover, we discuss in which other
ways prom can help software engineers in dealing with their processes.
2 related work
the capabilities of using software repositories for deriving information about
the software projects are being researched in the domain of mining software
repositories [2]. like in our approach, scm systems are used as sources of in-
formation. they are used for measuring the project activity and the amount of
produced failures, for detecting and predicting changes in the code, for providing
guidelines to newcomers to an open-source project, and for detecting the social
dependencies between the developers. in this area, scms are mostly used for
detecting dependencies on the code level, whereas we make an eﬀort at building
process models and analysing them. researchers and practitioners recognize the
beneﬁts of software process modelling with the aid of software repositories [3,
4]. nowadays, process improvement should be ruled by what was actually done
during the software development process and not by what is simply said about it.
the researchers from this domain examine bug reports for detecting defect life-
cycles, e-mails and scms for analysing the requirement engineering processes
and coordination processes between developers, their productivity and partici-
pation, etc. although this research direction deals with software processes and
their models, there is still a lack of algorithms for producing formal models.
since the mid-nineties several groups have been working on techniques for
process mining, i.e., discovering process models based on observed events. in [5],
an overview is given of the early work in this domain. the idea to apply process
mining in the context of workﬂow management systems was introduced in [6].
however, we argue that the ﬁrst papers really addressing the problem of process
mining appeared around 1995, when cook et al. [7, 8] started to analyse recorded
behaviour of processes in the context of software engineering, acknowledging the
fact that information was not complete and that a model was to be discovered
that reproduces at least the log under consideration, but it may allow for more
behaviour. more information on recent process mining research can be found at
http://www.processmining.org .document 
logsoftware 
process 
model practitionerprocess engineer, 
manager
websitesnews forums
e-mails
defect tracking systemsoftware repositories
-d i s c o v e r y
- improvement
software 
configuration
management system- monitoringprocess 
miningfig. 1. process-centered software engineering and process mining
3 process mining for software engineering environments
in this section, we ﬁrst explain the traditional process-centered software engi-
neering environments (psee). then, we present the ideas of the incremental
workﬂow mining approach.
3.1 incremental workﬂow mining approach
figure 1 gives an overview of the architecture of a traditional psee and rep-
resents how our incremental workﬂow mining approach is integrated to this
architecture: the environment consists of software repositories (scm system,
defect tracking system, etc...). the software product and the interaction among
practitioners are supported and maintained by the repositories. in the tradi-
tional schema, the process engineer (project manager or department) designs
the process model using his experience and existing approaches, like v-model,
rup, etc. then, the model is instantiated and practitioners follow it during the
product life cycle, indicated by the white arrows in fig. 1. there are the follow-
ing problems with this schema: the designed process model does not necessarily
reﬂect the actual way of work in the company, human possibilities in detect-
ing discrepancies between the process model and the actual process are limited,
practitioners are not involved in the design of the process model.
the main ideas of the incremental workﬂow mining approach were described
already in our previous work [9, 10]. in this approach we go the other direction,
it is shown with gray arrows in fig. 1: we take the audit trail information
(document log) of the scm system, which corresponds to the process instances
(particular executions of the process) and, using our process mining algorithms ,
derive the process model from it. then, the process model can be analysed,
veriﬁed and shown to the process engineer; he decides which changes should be
introduced to the process to optimise and to manage it in a better way. actually,
the mining approach can be used not only for discovery , but also for monitoring
andimproving real software processes using the data from software repositories
in general and scm systems in particular.
in software engineering environments, it is usually diﬃcult to introduce a
process management system (pms) directly from scratch. using our approachtable 1. document log
document date author
project1/models/design.mdl 01.01.05 14:30 designer
project1/src/code.java 01.01.05 15:00 developer
project1/tests/testplan.xml 05.01.05 10:00 qaengineer
project1/docs/review.pdf 07.01.05 11:00 manager
project2/models/design.mdl 01.02.05 11:00 designer
project2/tests/testplan.xml 15.02.05 17:00 qaengineer
project2/src/newcode.java 20.02.05 09:00 developer
project2/docs/review.pdf 28.02.05 18:45 designer
project3/models/design.mdl 01.03.05 11:00 designer
project3/models/veriﬁcation.xml 15.03.05 17:00 qaengineer
project3/src/gencode.java 20.03.05 09:00 designer
project3/review/areview.pdf 28.03.05 18:45 managertable 2. filtered log
document
des
code
test
rev
des
test
code
rev
des
ver
code
rev
in a batch mode , we gather the existing logs of several process instances and
automatically generate a model from them. our approach works also incremen-
tally, i.e. as soon as new data is added to the repositories, we reﬁne the overall
process model. following this approach, the role of the pms changes over time:
at the beginning, it is utilized only for storing the newly discovered models; af-
ter model improvements, the system can start advising the users and controlling
their work in the company. we call this gradual process support .
3.2 input information
in this section, we focus on the logs of scm systems and make our experiments
with them, but the approach and the algorithms are more general: they also
deal with the information derived from other software repositories.
in table 1, we present an example of the audit trail information from an
scm system. scm systems record the events corresponding to the commits of
documents . a sequence of these events constitutes a document log : it contains the
names of the committed documents, timestamps, and author names. document
logs with similar structure can be derived from all kinds of scm systems, such
ascvs,subversion ,sourcesafe ,clear case and others. when we analyse the
document logs, we have to identify the cases (process instances), identify the
document types, abstract from the details of the log, and ignore unnecessary
information. for many software projects, a case corresponds to a subproject or
a plug-in development, in our example it corresponds to a project development
(cases are separated with double lines in the tables). we detect the documents’
types by identifying similarities of their paths and names, see sect. 4.1 for details.
the same technique is used for abstracting from the log details and for ignoring
noise, i.e. ignoring exceptional or infrequent commits. however, the latter issues
are also resolved on the algorithm level, see sect. 4.2.4 process mining algorithms and tool support
in this section, we present the algorithms for multi-perspective software process
mining. in the area of process mining, there are diﬀerent algorithmic approaches,
which derive the control-ﬂow, the organization and the information models from
theevent logs . the events in these logs correspond to process activities produced
by some pms. in our application area, we have information about the commits
of documents which occur in scm systems, but generally can also occur in other
systems, like pdm. all the presented algorithms are integrated as plug-ins to
theprom tool [1], which is described at the end of this section.
4.1 abstraction on the log level
the document logs often contain either too many details or very speciﬁc docu-
ment names and paths, which are not relevant for the process mining algorithms.
thus, we need a technique to abstract from the concrete names and paths or
even to ignore some paths. we call this abstraction on the log level . the prom
tool contains a set of ﬁlters , which help us solving this problem.
here, we use the remap ﬁlter, which maps the names of documents from
the log to abstract names. regular expressions specify the paths that should be
mapped to abstract names. for example, if the path contains “/models/”, the
ﬁlename contains “design” and has extension “.mdl”, then it should be mapped
to “des”. table 2 shows the result of this ﬁlter applied to the log of table 1.
4.2 control-ﬂow mining
in this section, we describe the control-ﬂow mining algorithms. when dealing
with the control-ﬂow, the log can be represented as a set of sequences of docu-
ments (sequences are also called cases, traces or execution logs), see table 2.
generation and synthesis approach the approach presented in this section
is atwo-step approach : step 1 takes a document log and generates a transition
system (ts) from it; step 2 synthesises a petri net (pn) from the transition
system. the algorithmic details of the approach are discussed in [11]. one of the
main advantages of the approach is the capability to construct transition systems
and, then, to apply diﬀerent modiﬁcation strategies depending on the desired
degree of generalization; we call this “clever” transition system generation or
abstraction on the model level . despite the fact that transition systems are a
good speciﬁcation technique for making experiments, they are usually huge, since
they encode such constructs as concurrency or conﬂict in a sequential way. thus,
the algorithms developed within such a well-known area of petri net theory as
petri net synthesis and theory of regions [12] are used for transforming transition
systems to petri nets, which are more compact.
the transition system shown in fig. 2(a) with the solid arrows is constructed
from the log given in table 2. in this example, a state is deﬁned as a setof{}
{ des }
{ des, 
test }{ des,
code }
{des,test,code}
{des,test,code,rev}{ des,
ver }
{des,ver,code}
{des,ver,code,rev}des
test code
code test
revver
code
revverdestest
codever rev
destest
codever rev(a) (b)
(c)fig. 2. generated and synthesis approach: (a) transition systems (b),(c) petri nets
documents representing the complete history of a case at a point of time. for
example, for the ﬁrst case, there are such states as {},{des }, etc. there are
transitions between all the subsequent pairs of states, transitions are labelled
with the names of produced documents. using the petri net synthesis algorithms,
we generate a petri net from the given ts, see fig. 2(b). events of the ts
correspond to the transitions of the pn. this petri net has the same behaviour
as the ts; the concurrency of events test andcode , which is modeled
sequentially in the ts, is speciﬁed more compact in the pn.
but we can also modify the constructed ts using some strategy. for ex-
ample, the “extend strategy” adds transitions between two states, which were
created from diﬀerent traces but which can be subsequent because there is a
single document which can be produced to reach one state from the other.
as a result, we add one transition v er from state {des, code }to state
{des, v er, code }, it is shown with the dashed arrow in fig. 2(a). a petri net
corresponding to this ts is shown in fig. 2(c). this petri net is more general than
the ﬁrst one; it allows an additional trace, namely /angbracketleftdes, code, v er, rev /angbracketright.
the ﬁrst ideas of the generation and synthesis approach were presented in
our previous paper [13], then the algorithms were signiﬁcantly improved and
successfully implemented in the context of prom; the tool petrify [14] is used in
the synthesis phase. this approach overcomes many limitations of the traditional
process mining approaches; for example, it can deal with complicated process
constructs ,overﬁtting (generated model allows only for the exact behaviour seen
in the log) and underﬁtting (model overgeneralises the things seen in the log).
however, by now, this approach can hardly deal with noise (incorrectly logged
events and exceptions), since we do not consider the frequencies of cases in the
log; so, the other approaches that treat this problem, are presented in the next
section.
other approaches for control flow mining in the process mining domain
a number of algorithms for control ﬂow mining have been developed, whichhave diﬀerent characteristics from the previously introduced approach; all these
algorithms can be also applied for mining the software processes.
the alpha algorithm [15] can also derive a petri net model from an event
log, however it is based on analysing the immediate successor relation between
event types, i.e. documents. another algorithm, the multi-phase approach [16],
creates event-driven process chain (epc) models from a log, while it ﬁrst gen-
erates a model for each process instance and later aggregates these to a global
model. both the alpha and the multi-phase algorithms share the generation
and synthesis approach’s precision , i.e. the generated model accurately reﬂects
all ordering relations discovered in the log.
while sophisticated ﬁltering of logs can remove noise partially, there are
also process mining algorithms which are designed to be more robust in the
presence of noise. the heuristics miner [17] employs heuristics which, based on
the frequency of discovered ordering relations, attempts to discard exceptional
behaviour. another approach in this direction is the genetic miner [18]. it uses
genetic algorithms to develop the process model in an evolutionary manner,
which enables it to also discover e.g. long-term dependencies within a process.
4.3 mining other perspectives
our generation and synthesis approach deals with the control ﬂow, which is only
oneperspective addressed in process mining. such information as the timestamp
of an event or its originator (the person having triggered its occurrence) can be
used to derive high-level information about the process also in other perspectives.
resource perspective. the resource perspective looks at the set of people in-
volved in the process, and their relationships. the social network miner [19]
for example can generate the social network of the organization, which may
highlight diﬀerent relationships between the persons involved in the process,
such as handover of work ,subcontracting and others. the organizational miner
also addresses the resource perspective, attempting to cluster resources which
perform similar tasks into roles. this functionality can be very beneﬁcial in a
software development process, both for veriﬁcation and analysis of the organiza-
tional structure. mismatches between discovered and assigned roles can pinpoint
deﬁciencies in either the process deﬁnition or the organization itself.
performance perspective. mining algorithms addressing the performance per-
spective mainly make use of the timestamp attribute of events. from the combi-
nation of a (mined or predeﬁned) process model and a timed event log, they can
give detailed information about performance deﬁciencies, and their location in
the process model. if some project phase is identiﬁed as the point in the process
where most time is spent, we could assign more staﬀ to this task.
information perspective. theactivity miner [20] can derive high-level activ-
ities from a log by clustering similar sets of low-level events that are found to
occur together frequently. these high-level clusters, or patterns, are helpful for
unveiling hidden dependencies between documents, or for a re-structuring of the
document repository layout.4.4 process analysis and veriﬁcation
process mining is a tremendously helpful tool for managers and system admin-
istrators, who want to get an overview of how the process is executed, and for
monitoring progress. however, in many situations it is interesting whether ex-
ecution is correct . to answer this question, there exists a set of analysis and
veriﬁcation methods in the process mining domain. one of these techniques is
conformance checking [21], which takes a log and a process model, e.g. a petri
net, as input. the goal is to analyse the extent to which the process execution
corresponds to the given process model. also, conformance checking can point
out the parts of the process where the log does not comply.
another technique is ltl checking [22], which analyses the log for com-
pliance with speciﬁc constraints, where the latter are speciﬁed by means of
linear-temporal logic (ltl) formulas. in contrast to conformance checking, ltl
checking does not assume the existence of a fully deﬁned development process.
therefore, it can be used to successively introduce, and check for, corporate
guidelines or best development practices.
the prom framework also features techniques for process model analysis and
veriﬁcation in the absence of a log. advanced process model analysers, such as
woﬂan , can check e.g. a petri net model for deadlocks (i.e., potential situations
in which execution will be stuck), or verify that all process executions complete
properly with no enabled tasks left behind. process designers ﬁnd these auto-
mated tools valuable for ensuring that a deﬁned development process will not
run into problems which are hard to resolve later on.
4.5 prom and promimport tools
the ideas presented in this paper have been implemented in the context of
prom . prom serves as a testbed for our process mining research [1] and can be
downloaded from www.processmining.org. starting point for prom is the mxml
format. this is a vendor-independent format to store event logs. one mxml ﬁle
can store information about multiple processes. per process, events related to
particular process instances (cases) are stored. each event refers to an activity.
in the context of this paper, documents are mapped onto activities. events can
also have additional information such as the transaction type (start, complete,
etc.), the author, timestamps, and arbitrary data (attribute-value pairs).
thepromimport framework allows developers to quickly implement plug-ins
that can be used to extract information from a variety of systems and convert
it into the mxml format (cf. promimport.sourceforge.net). there are standard
import plug-ins for a wide variety of systems, e.g., workﬂow management sys-
tems like staﬀware, case handling systems like flower, erp components like
peoplesoft financials, simulation tools like aris and cpn tools, middleware
systems like websphere, bi tools like aris ppm, etc. moreover, it has been
used to develop many organization/system-speciﬁc conversions (e.g., hospitals,
banks, governments, etc.). the promimport framework can also be used to
extract event logs from such systems as subversion and cvs.once the logs are converted to mxml, prom can be used to extract a variety
of models from these logs. prom provides an environment to easily add plug-ins
that implement a speciﬁc mining approach. the most interesting plug-ins in the
context of this paper are the mining plug-ins. in addition to that, there are four
other types of plug-ins: export plug-ins implement some “save as” functionality
for some objects (such as graphs). for example, there are plug-ins to save epcs,
petri nets, spreadsheets, etc. import plug-ins implement an “open” functionality
for exported objects, e.g., load instance-epcs from aris ppm. analysis plug-ins
typically implement some property analysis on some mining result. for example,
for petri nets, there is a plug-in which constructs place invariants, transition
invariants, and a coverability graph. conversion plug-ins implement conversions
between diﬀerent data formats, e.g., from epcs to petri nets and from petri
nets to yawl and bpel. altogether, there are 140plug-ins for prom.
5 evaluation and applications
in order to evaluate our approach, we have chosen the argouml project, which
is an open-source uml modeling tool maintained by the subversion scm sys-
tem. since this data is freely available, it makes an excellent test case for us.
argouml has diﬀerent subprojects with the same ﬁle organization ; we have
chosen ﬁve subprojects which implement the argouml support for ﬁve diﬀer-
ent programming languages. we will use these ﬁve process instances to derive a
formal model of the control-ﬂow, to analyse the organization structure and the
performance of the process, and to do some analysis and veriﬁcation.
first, using the svn log utility provided by subversion, we generated logs
for all the ﬁve subprojects and imported them to prom. this log consisted of
about 400 commit events. the log contains project speciﬁc paths and diﬀer-
ent commits, which are not relevant for the software process. using the remap
ﬁlter, we replaced project speciﬁc paths with abstract names. following the ar-
gouml conventions, all the committed documents (ﬁles) containing “/src/” in
their paths and have “.java” as an extension were mapped to “src”, all the
“readme.*” ﬁles – to “readme”, all the ﬁles in “/tests/” – to “tests”, the
ﬁles in “/www/” – to “www”, “build.bat” – to “builder” and all the ﬁles,
which names start with “.” – to “config”; the other commits were ignored.
after executing the algorithms of the generation and synthesis approach, we
obtained the petri net shown in fig. 3. here, for the sake of readability, we show
a simpliﬁed petri net without loops – which was obtained by applying the “kill
loops” modiﬁcation strategy to the transition system and synthesizing a petri
net from there. thus, the petri net focuses on the start events, i.e. when source
code development was started, when testing was started. people use to start with
building web sites or editing readme ﬁles and builders, then they write code and
then, they test it, sometimes builder ﬁle is changed after writing code.
the petri net model of the development process can now be used for enhanced
analysis within the prom framework. figure 4 shows the result of a performance
analysis based on the mined model and the log. the states, i.e. places, havefig. 3. petri net for the argouml project
fig. 4. performance analysis
 fig. 5. conformance analysis
been colored according to the time which is spent in them while executing the
process. also, multiple arcs originating from the same place (i.e., choices) have
been annotated with the respective probability of that choice.
further, a conformance analysis can be performed using the petri net model
and the associated log. figure 5 shows the path coverage analysis of the confor-
mance checker. all activities that have been executed in a speciﬁc case (in our
example we chose the c++ language support) are decorated with a bold border,
and arcs are annotated with the frequency they have been followed in that case.
this example shows, that the c++ team did not create a readme ﬁle.
fig. 6. ltl analysis
 fig. 7. social networkone known software engineering concept is the “four eyes principle”, e.g.
developers working on the source code should not write tests as well. figure 6
shows the result of checking a corresponding ltl formula on the argouml log.
in the c++ support case, which is shown in fig. 6, both source code and tests
have been submitted by the developer “euluis”, thereby violating this principle.
for determining the social network of a development process, it is preferable
to use the original log, i.e. before it has been abstracted like explained in sec-
tion 4.1. the reason for that is, that it is also interesting when people collaborate
within a certain part of the project (e.g. writing source code), while one wants
to abstract from these activities on the control ﬂow level. figure 7 illustrates the
hand-over of work between argouml developers. it shows that some developers
are involved only in speciﬁc phases of the project (e.g. “bobtarling” appears to
work only at the end of projects), while others (e.g. “tfmorris”) have a more
central and connected position, meaning they perform tasks all over the pro-
cess. based on the nature of the project one may prefer diﬀerent collaboration
patterns, which can be checked conveniently in a mined social network like this.
6 conclusion
in this paper, we have discussed some new algorithms for mining software and
systems engineering processes from the information that is available in software
conﬁguration management systems. these algorithms are included in the prom
framework, which has interfaces to a variety of document management systems.
therefore, prom is now an eﬀective tool for software process mining.
for evaluation purposes, we have mined the software processes of a real
project: argouml. this shows that we can obtain the process models for real-
istic software projects. moreover, we have shown that prom could be used for
analysing and verifying some properties of these processes.
acknowledgements this research is supported by the technology foundation
stw, applied science division of nwo and the technology programme of the
dutch ministry of economic aﬀairs.
references
1. van dongen, b., medeiros, a., verbeek, h., weijters, a., van der aalst, w.: the
prom framework: a new era in process mining tool support. in ciardo, g.,
darondeau, p., eds.: application and theory of petri nets 2005. volume 3536.
(2005) 444–454
2. msr 2005 international workshop on mining software repositories. in: icse ’05:
proc. of the 27th international conference on software engineering, new york,
ny, usa, acm press (2005)
3. sandusky, r.j., gasser, l., ripoche, g.: bug report networks: varieties, strate-
gies, and impacts in a f/oss development community. in: msr 2004: interna-
tional workshop on mining software repositories. (2004)
4. iannacci, f.: coordination processes in open source software development: the
linux case study. http://opensource.mit.edu/papers/iannacci3.pdf (2005)5. van der aalst, w., van dongen, b., herbst, j., maruster, l., schimm, g., weijters,
a.: workﬂow mining: a survey of issues and approaches. data and knowledge
engineering 47(2003) 237–267
6. agrawal, r., gunopulos, d., leymann, f.: mining process models from work-
ﬂow logs. in: sixth international conference on extending database technology.
(1998) 469–483
7. cook, j., wolf, a.: discovering models of software processes from event-based
data. acm trans. on software engineering and methodology 7(1998) 215–249
8. cook, j., du, z., liu, c., wolf, a.: discovering models of behavior for concurrent
workﬂows. computers in industry 53(2004) 297–319
9. kindler, e., rubin, v., sch¨ afer, w.: incremental workﬂow mining based on doc-
ument versioning information. in li, m., boehm, b., osterweil, l.j., eds.: proc.
of the software process workshop 2005, beijing, china. volume 3840., springer
(2005) 287–301
10. kindler, e., rubin, v., sch¨ afer, w.: activity mining for discovering software pro-
cess models. in biel, b., book, m., gruhn, v., eds.: proc. of the software engi-
neering 2006 conference, leipzig, germany. volume p-79 of lni., gesellschaft f¨ ur
informatik (2006) 175–180
11. van der aalst, w., rubin, v., van dongen, b., kindler, e., g¨ unther, c.: process
mining: a two-step approach using transition systems and regions. bpm center
report bpm-06-30, bpm center, bpmcenter.org (2006)
12. cortadella, j., kishinevsky, m., lavagno, l., yakovlev, a.: deriving petri nets
from ﬁnite transition systems. ieee trans. on computers 47(1998) 859–882
13. kindler, e., rubin, v., sch¨ afer, w.: process mining and petri net synthesis. in
eder, j., dustdar, s., eds.: bpm 2006 workshops. volume 4103., springer (2006)
14. cortadella, j., kishinevsky, m., kondratyev, a., lavagno, l., yakovlev, a.: petrify:
a tool for manipulating concurrent speciﬁcations and synthesis of asynchronous
controllers. ieice trans. on information and systems e80-d (1997) 315–325
15. van der aalst, w., weijters, a., maruster, l.: workﬂow mining: discovering pro-
cess models from event logs. ieee trans. on knowledge and data engineering
16(2004) 1128–1142
16. van dongen, b., van der aalst, w.: multi-phase process mining: building instance
graphs. in atzeni, p., chu, w., lu, h., zhou, s., ling, t., eds.: international
conference on conceptual modeling (er 2004). volume 3288. (2004) 362–376
17. weijters, a., van der aalst, w.: rediscovering workﬂow models from event-based
data using little thumb. integrated computer-aided engineering 10(2003) 151–
162
18. van der aalst, w., medeiros, a., weijters, a.: genetic process mining. in ciardo,
g., darondeau, p., eds.: applications and theory of petri nets 2005. volume 3536.
(2005) 48–69
19. van der aalst, w., reijers, h., song, m.: discovering social networks from event
logs. computer supported cooperative work 14(2005) 549–593
20. g¨ unther, c., van der aalst, w.: mining activity clusters from low-level event
logs. beta working paper series, wp 165, eut, eindhoven (2006)
21. rozinat, a., van der aalst, w.: conformance testing: measuring the fit and
appropriateness of event logs and process models. in bussler et al., c., ed.:
bpm 2005 workshops. volume 3812. (2006) 163–176
22. van der aalst, w., beer, h., dongen, b.: process mining and veriﬁcation of
properties: an approach based on temporal logic. beta working paper series,
wp 136, eindhoven university of technology, eindhoven (2005)