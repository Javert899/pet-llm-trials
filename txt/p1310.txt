discovering directly-follows complete petri nets
from event data
wil m.p. van der aalst
process and data science (pads), rwth aachen university, germany
wvdaalst@pads.rwth-aachen.de www.vdaalst.com
abstract. process mining relies on the ability to discover high-quality process
models from event data describing only example behavior. process discovery is
challenging because event data only provide positive examples and process mod-
els may serve different purposes (performance analysis, compliance checking,
predictive analytics, etc.). this paper focuses on the discovery ofaccepting petri
netsunder the assumption that both the event log and process model are directly-
follows complete . based on novel insights, two new variants ( α1.1andα2.0) of
the well-known alpha algorithm ( α1.0) are proposed. these variants overcome
some of the limitations of the classical algorithm (e.g., dealing with short-loops
and non-unique start and ending activities) and shed light on the boundaries of
the “directly-follows completeness” assumption. these insights can be leveraged
to create new process discovery algorithms or improve existing ones.
keywords: process discovery · process models · petri nets
1 introduction
process mining is increasingly adopted by larger organizations to find and remove in-
efficiencies, bottlenecks, and compliance issues [1]. there are over 40 process min-
ing vendors (cf. www.processmining.org ) and more than half of the fortune-
500 corporations are already using process mining [16]. thousands of organizations
are extracting event data from systems such sap, salesforce, oracle, servicenow, and
workday to apply process mining. despite the widespread use of process mining, many
challenges remain, ranging from data extraction and scalability to discovering better
process models and providing better diagnostics.
although most process mining tools support the discovery of higher-level models
visualized in terms of bpmn (business process model and notation) (next to confor-
mance checking and predictive analytics), in practice process analysts and managers
mostly use the so-called directly-follows graphs (dfgs) to get initial insights. in a
dfg all activities and their frequencies are shown. the activities are connected through
directed edges that show how often one activity is followed by another activity within
the same case (i.e., process instance). these edges can also be annotated with dura-
tions (minimum, maximum, mean, etc.), because events have timestamps. the creation
of dfgs is simple and highly scalable. however, there are also many limitations (e.g.,
producing complex underfitting process models), as discussed in [2].2 wil van der aalst
a
t1c
db
f
et2
t4
t5t6t3
p1p2
p3p4
p5p6
fig. 1. accepting petri net an 1discovered for l1= [⟨a, c, e, f ⟩5,⟨a, e, c, f ⟩4,⟨a, b, c, e, f ⟩4,
⟨a, b, e, c, f ⟩3,⟨a, e, b, c, f ⟩3,⟨a, b, b, c, e, f ⟩3,⟨a, b, b, e, c, f ⟩2,⟨a, e, b, b, c, f ⟩2,⟨a, c, e, d, c,
e, f⟩2,⟨a, e, c, d, c, e, f ⟩2,⟨a, c, e, d, b, c, e, f ⟩2,⟨a, e, c, d, b, b, c, e, f ⟩2,⟨a, b, c, e, d, c, e, f ⟩,
⟨a, b, e, c, d, e, c, f ⟩,⟨a, e, b, c, d, c, e, f ⟩,⟨a, b, c, e, d, e, c, f ⟩,⟨a, b, c, e, d, c, e, d, c, e, d, b, e,
b, c, f ⟩,⟨a, c, e, d, c, e, d, e, c, f ⟩]using the new alpha algorithm.
to overcome the limitations of dfgs, dozens (if not hundreds) of process discovery
techniques have been developed. the core idea is very simple. the input (i.e., an event
log) can be viewed as a multiset of traces . each trace corresponds to a case, i.e., one
execution of the process for a patient, order, student, package, etc. a trace is represented
as a sequence of activities. since multiple cases may exhibit the same sequence, we need
to consider multisets. l1= [⟨a, c, e, f ⟩5,⟨a, e, c, f ⟩4, . . .]in the caption of figure 1
describes such an event log, e.g., there are five cases following the sequence ⟨a, c, e,
f⟩. note that in this compact representation, we abstract from timestamps, resources,
costs, etc. based on such input, we would like to produce models such as the accepting
petri net an 1shown in figure 1. an 1is able to produce all the traces in l1. note that
activity eis concurrent to bandcsuch that candeoccur the same number of times (at
least once) and bcan occur any number of times.
a
t1c
db
f
et2
t4
t5t6t3
p1p2
p3p4
p5p6
fig. 2. accepting petri net an′
1discovered for l1using the classical alpha algorithm.
the original alpha algorithm [1, 5] was the first algorithm able to discover concur-
rent process models from event logs. the algorithm assumes that the underlying pro-
cess can be represented as a free-choice structured workflow net without short loops.discovering directly-follows complete petri nets from event data 3
for this class of process models, the algorithm guarantees to return the correct process
model assuming a directly-follows complete event log [5]. for process models outside
this class, the results are unpredictable. the discovered model may be underfitting or
not sound. the limitations were already investigated in the original paper. one of the
problems is the inability to discover short loops. this is illustrated in figure 2, which
shows the process model when applying the original, over twenty year old, alpha algo-
rithm. the self-loop involving band the length-two loops involving dcause problems.
activities banddare disconnected and it is impossible to replay parts of the event log
l1. the alpha algorithm has more problems, some of which can be resolved by using
more information [24, 25]. however, these extensions are complex and impose more
assumptions.
ac
db
f
e
fig. 3. directly-follows graph (dfg) based on l1.
in this paper, we take a different route. we simply assume that the directly-follows
graph (dfg) is all the information we have. for event log l1, we assume that the dfg
in figure 3 is all we have. moreover, we look beyond the traditional subclasses of petri
nets. we do not assume workflow nets or the free-choice property. instead, we focus on
structural directly-follows complete accepting petri nets. the accepting petri net an 1
shown in figure 1 is an example of this class of models. therefore, we consider both
directly-follows complete event logs and structural directly-follows complete process
models. this provides novel insights and also leads to two new versions of the alpha
algorithm that are as compact and simple as the original algorithm, but more powerful.
the remainder of this paper is organized as follows. section 2 introduces event logs
and accepting petri nets. section 3 discusses different notions of directly-follows com-
pleteness and section 4 lists the typical subclasses of petri nets considered. section 5
presents an improved version of the original algorithm that drops the workflow net as-
sumption. section 6 changes the core part of the algorithm allowing for the discovery
of short loops. the paper ends with a discussion (section 7) and conclusion (section 8).
2 preliminaries
in this section, we introduce basic concepts, but assume that the reader is (somewhat)
familiar with the basics of petri nets and process mining. for completeness, we refer to
[1] for process mining and [13, 14] for an extensive introduction to petri nets.
in process mining, multisets and sequences play an important role. b(x) =x→n
is a multiset over x. for example, if x={a, b, c}, then [a3, b2, c]∈ b(x),[a4, b2]∈4 wil van der aalst
b(x),[a6]∈ b(x)are three multisets each consisting of six elements. x∗is the set
of sequences over x, e.g., σ=⟨a, b, a, b, c ⟩ ∈x∗. we use the standard operations on
multisets and sequences, e.g., {x∈σ}={a, b, c}and[x∈σ] = [a2, b2, c].
we start by introducing event logs . an event log is a collection of events typically
grouped in cases , ordered by time, and labeled by activity names . in its simplest form
each event has a case identifier, an activity name, and a timestamp. events can have
many more attributes, e.g., costs, resource, location, etc. there are also more sophisti-
cated event log notions, e.g., partially ordered events, events with explicit uncertainty,
and events that may refer to any number of objects of different types, see, for exam-
ple, the extensible event stream (xes, www.xes-standard.org ) standard and
object centric event log (ocel, www.ocel-standard.org ) standard. here, we
consider the most basic setting and only consider the ordering of activities within cases.
this implies that an event log can be described as a multiset of traces , where each
trace is a sequence of activities (also called a process variant ). an example trace is
σ=⟨a, b, a⟩. many cases can have the same trace. therefore, an event log is a multiset
of traces. e.g. l= [⟨a, b, a⟩12,⟨b, a, a⟩8]is an event log with 60 events describing the
traces of 20 cases distributed over two process variants.
definition 1 (event log). uactis the universe of activity names. a trace σ=⟨a1, a2,
. . . , a n⟩ ∈ u act∗is a sequence of activities. an event log l∈ b(uact∗)is a multiset of
traces.
in the caption of figure 1, there is another (larger) example of an event log l1= [⟨a,
c, e, f⟩5,⟨a, e, c, f ⟩4,⟨a, b, c, e, f ⟩4,⟨a, b, e, c, f ⟩3, . . .], e.g., there are five cases corre-
sponding to trace ⟨a, c, e, f ⟩, four cases corresponding to ⟨a, e, c, f ⟩, etc.
a
p1p3 p5p2 p4
bp6a t1t2
t3t4
fig. 4. an accepting petri net an 2= (n, m init, mfinal)withminit= [p1],mfinal= [p6], and
lang(an 2) = {⟨a, b, a ⟩,⟨b, a, a ⟩}.
we use accepting petri nets to model processes. figure 4 shows an example ac-
cepting petri net an 2allowing for two traces: ⟨a, b, a⟩and⟨b, a, a⟩. the petri net
has six places p={p1, p2, p3, p4, p5, p6}(represented by circles), four transitions
t={t1, t2, t3, t4}(represented by squares), and 10 arcs f={(p1, t1),(t1, p2), . . . ,
(t4, p6)}. transitions can be labeled, e.g., l(t2) =aandl(t3) =b.
definition 2 (labeled petri net). a labeled petri net is a tuple n= (p, t, f, l )with
pthe set of places, tthe set of transitions, p∩t=∅,f⊆(p×t)∪(t×p)the
flow relation, and l∈t̸→ u acta labeling function. •t={p∈p|(p, t)∈f}isdiscovering directly-follows complete petri nets from event data 5
the set of input places and t•={p∈p|(t, p)∈f}is the set of output places of a
transition t∈t. the same notation can be used for input and output transitions of a
place p∈p:•p={t∈t|(t, p)∈f}andp•={t∈t|(p, t)∈f}.
note that the labeling function may be partial and that multiple transitions may have
the same label. for an 2in figure 4, t1̸∈dom(l)andl(t2) = l(t4). it a transition t
has no label, i.e., t̸∈dom(l), we also write l(t) =τand say the transition is silent or
invisible . in figure 4, •p1 =∅,p1•={t1},•t1 ={p1},t1•={p2, p3}, etc. states
in petri nets are called markings that mark certain places with tokens (represented by
black dots). technically, a marking is a multiset of places m∈ b(p). an accepting
petri net has an initial marking minitand a final marking mfinal.
definition 3 (accepting petri net). an accepting petri net is a triplet an= (n,
minit, mfinal)where n= (p, t, f, l )is a labeled petri net, minit∈ b(p)is the
initial marking, and mfinal∈ b(p)is the final marking. uanis the set of accepting
petri nets.
inan 2depicted in figure 4, minit= [p1]is the initial marking, and mfinal=
[p6]. a transition is called enabled if each of the input places has a token. an enabled
transition may fire(i.e., occur), thereby consuming a token from each input place and
producing a token for each output place. for example, firing t1in the initial making
leads to marking [p2, p3]. there are 6 reachable markings starting from minit= [p1]:
[p1],[p2, p3],[p2, p5],[p3, p4],[p4, p5], and [p6].
definition 4 (reachable markings and enabled firing sequences). letan= (n,
minit, mfinal)∈ uanbe an accepting petri net with n= (p, t, f, l ).m1t→m2
denotes that in m1∈ b(p)transition t∈tis enabled and firing tresults in marking
m2∈ b(p).m1σ→mnwithσ=⟨t1, t2, . . . t n−1⟩ ∈t∗denotes that there are
markings m2, . . . m n−1∈ b(p)such that miti→mi+1for1≤i < n , i.e., there
is an enabled firing sequence σleading from m1tomn.efs(an) ={σ∈t∗|
∃m∈b(p)minitσ→m}is the set of enabled firing sequences. rmk(an) ={m∈
b(p)| ∃σ∈t∗minitσ→m}is the set of reachable markings.
definition 5 (liveness and boundedness). letan= (n, m init, mfinal)∈ uanbe
an accepting petri net with n= (p, t, f, l ).an is live if for any reachable marking
m∈rmk(an)and every transition t∈t, there exists a marking reachable from m
enabling t.anis bounded if rmk(an)is finite (i.e., there is a ksuch that no place can
have more than ktokens). an is safe if for any m∈rmk(an)andp∈p:m(p)≤1
(i.e., each place holds at most 1 token in any reachable marking).
accepting petri net an 1in figure 1 has six reachable markings and is safe, but
not live. an 2depicted in figure 4 also has six reachable markings and is safe, but not
live. adding a short-circuiting transition tscconnecting p6top1(i.e.,•tsc={p6}and
tsc•={p1}) in figures 1 and 4 makes both nets live.
definition 6 (complete firing sequences). letan= (n, m init, mfinal)∈ uanbe
an accepting petri net with n= (p, t, f, l ).cfs(an) ={σ∈t∗|minitσ→mfinal}
is the set of complete firing sequences of an, i.e., all firing sequences starting in the
initial marking minitand ending in the final marking mfinal.6 wil van der aalst
for the accepting petri net an 2in figure 4, cfs(an 2) ={⟨t1, t2, t3, t4⟩,⟨t1, t3,
t2, t4⟩}. the accepting petri net an 1in figure 1, allows for arbitrary long complete
firing sequences. hence, cfs(an 1) ={⟨t1, t3, t5, t6⟩,⟨t1, t2, t3, t5, t6⟩,⟨t1, t2, t5, t2,
t2, t3, t6⟩, . . .}has infinitely many elements.
firing a transition tcorresponds to executing activity l(t)ift∈dom(l). to map
complete firing sequences to traces, we apply labeling function lsuch that visible tran-
sitions are mapped onto activities and visible transitions are skipped. for an 2, i.e., the
accepting petri net in figure 4, and the two corresponding complete firing sequences
σ1=⟨t1, t2, t3, t4⟩andσ2=⟨t1, t3, t2, t4⟩:l(σ1) =⟨a, b, a⟩andl(σ2) =⟨b, a, a⟩.
note that firing t1cannot be observed and t2andt4are mapped onto the same activity
a.
definition 7 (traces of an accepting petri net). letan= (n, m init, mfinal)∈
uanbe an accepting petri net. lang(an) ={l(σ)|σ∈cfs(an)}are the traces
possible according to an.
for the accepting petri net an 2in figure 4, lang(an 2) ={⟨a, b, a⟩,⟨b, a, a⟩}.
the accepting petri net an 1in figure 1, allows for infinitely many traces: lang(an 1)
={⟨a, c, e, f ⟩,⟨a, b, c, e, f ⟩,⟨a, b, e, b, b, c, f ⟩, . . .}.
an accepting petri net is sound , if there are no dead transitions and, from any reach-
able state, it is possible to reach the final state.
definition 8 (soundness). letan = (n, m init, mfinal)∈ u anbe an accepting
petri net with n= (p, t, f, l ).anis sound if and only if (1) for any t∈tthere exists
aσ∈efs(an)such that t∈σ(i.e.,tis not dead), and (2) for any σ1∈efs(an)
there exists a σ2∈t∗such that σ1·σ2∈cfs(an)(i.e., from any reachable marking,
it is possible to reach the final state).
discovering a process model from a collection of example traces is one of the main
process mining tasks. ideally, the discovered process model is sound.
definition 9 (process discovery). a discovery algorithm disc∈ b(uact∗)→ u an
produces an accepting petri net for each event log.
many algorithms described in literature implement a discovery function disc∈
b(uact∗)→ u an, e.g., [4, 5, 9–11, 20, 17–19, 21, 24–27]. not all are explicitly discov-
ering accepting petri nets. however, also process trees can be converted into accepting
petri nets and if an explicit final marking is missing it can often be added.
definition 10 (conformance checking). letudiag be the universe of conformance
diagnostics. a conformance checking algorithm conf∈ b(uact∗)× uan→ u diag
produces conformance diagnostics given an event log and accepting petri net as input.
conformance checking is a topic in itself [1, 3, 12, 22]. therefore, we do not de-
tail the type of diagnostics udiag. most conformance measures are normalized to [0,1]
where values close to 0are bad and values close to 1are good.
conformance diagnostics may focus on (1) recall , also called (replay) fitness, which
aims to quantify the fraction of observed behavior that is allowed by the model, (2)discovering directly-follows complete petri nets from event data 7
precision , which aims to quantify the fraction of behavior allowed by the model that
was actually observed (i.e., avoids “underfitting” the event data), (3) generalization ,
which aims to quantify the probability that new unseen cases will fit the model (i.e.,
avoids “overfitting” the event data), and (4) simplicity , which refers to occam’s razor
and can be made operational by quantifying the complexity of the model (number of
nodes, number of arcs, understandability, etc.).
let’s try to operationalize recall and precision. recall is concerned with traces in
the event log not possible in the model, i.e., lnofit = [σ∈l|σ̸∈lang(an)].
precision is concerned with traces possible in the model, but not appearing in the event
log, i.e., lmiss={σ∈lang(an)|σ̸∈l}. however, this is not so simple. the event
log contains only example behavior (a sample) and any model with loops has infinitely
many traces. in such cases lmiss has infinitely many elements by definition. if the
model aims to describe the mainstream behavior, then lnofit may contain exceptional
behavior that was left out deliberately. moreover, traces may be partly fitting and one
often wants to strike a balance between precision (avoiding “underfitting” the sample
event data) and generalization (avoiding “overfitting” the sample event data).
these considerations make process mining different from many other model-learning
techniques such as synthesis, system identification, grammatical inference, regular in-
ference, automata learning [6–8, 15, 23]. the field of model learning can be structured
using three dimensions: (a) only positive examples versus positive and negative exam-
ples, (b) input data is complete (in some form) or not, (c) passive learning (just observa-
tions) versus active learning (interactions). process mining focuses on passive learning
using only positive examples with only weak completeness guarantees. this makes it
very difficult. for example, it is impossible to actively test hypotheses.
a detailed discussion of process discovery and conformance checking techniques
(including possible quality criteria) is outside the scope of this paper (see [1, 3, 12, 22]
for details).
3 directly-follows completeness
most process discovery algorithms heavily rely on the directly-follows relation , i.e.,
activities following each other directly, either in the event log or process model. the
goal is to find models that have the same directly-follows relation as seen in the event
log. the motivation to do this is simple. one cannot expect to see all possible traces in
an event log. the event log only contains a sample. however, it is reasonable to assume
that one can witness the complete directly-follows relation in the event log, i.e., if acan
be followed by bwe should see it at least once in the input data.
in the section, we define different directly-follows completeness notions, also con-
sidering the structure of the accepting petri net.
consider event log l1= [⟨a, c, e, f ⟩5,⟨a, e, c, f ⟩4,⟨a, b, c, e, f ⟩4,⟨a, b, e, c, f ⟩3,
⟨a, e, b, c, f ⟩3,⟨a, b, b, c, e, f ⟩3,⟨a, b, b, e, c, f ⟩2,⟨a, e, b, b, c, f ⟩2,⟨a, c, e, d, c, e, f ⟩2,⟨a,
e, c, d, c, e, f ⟩2,⟨a, c, e, d, b, c, e, f ⟩2,⟨a, e, c, d, b, b, c, e, f ⟩2,⟨a, b, c, e, d, c, e, f ⟩,⟨a, b,
e, c, d, e, c, f ⟩,⟨a, e, b, c, d, c, e, f ⟩,⟨a, b, c, e, d, e, c, f ⟩,⟨a, b, c, e, d, c, e, d, c, e, d, b, e, b,
c, f⟩,⟨a, c, e, d, c, e, d, e, c, f ⟩]and accepting petri net an 1shown in figure 1. assume
thatl1was obtained by repeatedly simulating the accepting petri net an 1. in this case,8 wil van der aalst
we have a known ground truth , because we want the discovery algorithm disc to dis-
cover an 1based on l1, i.e., disc(l1) =an 1. however, due to the two loops and
concurrency, there are many possible traces. the self-loop involving band the length-
two loops involving dallow for an arbitrary number of b’s,c’s,d’s, and e’s in a single
trace. hence, one cannot expect to observe all possible traces. in fact, this is impossi-
ble. one can try to increase the sample (i.e., the number traces in the event log), but the
foundational problem remains: we only have example traces. however, event log l1is
directly-follows complete with respect to model an 1. this is reflected by the directly-
follows graph (dfg) in figure 3. to explain directly-follows completeness, we first
define some core concepts.
definition 11 (adding artificial start and end activities). ▶̸∈ uactis an artificial
start activity, ■̸∈ u actis an artificial end activity, ˆuact=uact∪ {▶,■}. for any
σ∈ u act∗,ˆσ=⟨▶⟩ ·σ· ⟨■⟩. for any l∈ b(uact∗),ˆl= [ˆσ|σ∈l]. for any
s⊆ uact∗,ˆs={ˆσ|σ∈s}.
the “hat notation” adds artificial starts and ends to traces, languages, and event logs.
forl2= [⟨a, b, a⟩5,⟨b, a, a⟩4]:ˆl2= [⟨▶, a, b, a, ■⟩5,⟨▶, b, a, a, ■⟩4].
definition 12 (log-based directly-follows relation). letl∈ b(uact∗)be an event
log.
–act(l) = [σ(i)|σ∈l∧1≤i≤ |σ|]is the multiset of activities in the event log
(note that σ(i)is the i-th element in the sequence σ).
–df(l) = [( σ(i), σ(i+1))|σ∈ˆl∧1≤i <|σ|]is the multiset of directly-follows
relations in the event log (note that the artificial start activity ▶and end activity ■
have been added to the traces in ˆl).
–a1⇒la2if and only if (a1, a2)∈df(l),a1̸⇒la2if and only if (a1, a2)̸∈df(l),
anda1⇔la2if and only if a1⇒la2anda2⇒la1.
take again l2= [⟨a, b, a⟩5,⟨b, a, a⟩4]:act(l2) = [a18, b9],df(l2) = [(▶, a)5,(▶
, b)4,(a, a)4,(a, b)5,(b, a)9,(a,■)9]. hence, we can write ▶⇒l2a,b⇒l2a,b̸⇒l2b,
a⇒l2■, etc. similar relations can be obtained for process models as is defined next.
definition 13 (behavioral model-based directly-follows relation). letan= (n,
minit, mfinal)∈ u anbe an accepting petri net with s=lang(an)as possible
traces.
–actb(an) ={σ(i)|σ∈s∧1≤i≤ |σ|}is the set of activities possible
according to the model’s behavior.
–dfb(an) ={(σ(i), σ(i+1))|σ∈ˆs∧1≤i <|σ|}is the set of directly-follows
relations possible according to the model’s behavior.
–a1⇒b
ana2if and only if (a1, a2)∈dfb(an),a1̸⇒b
ana2if and only if (a1, a2)̸∈
dfb(an), and a1⇔b
ana2if and only if a1⇒b
ana2anda2⇒b
ana1.
for the accepting petri net an 2in figure 4, we find actb(an 2) ={a, b},dfb(an 2)
={(▶, a),(▶, b),(a, a),(a, b),(b, a),(a,■)}. hence, we can write ▶⇒b
an2a,b⇒b
an2
a,b̸⇒b
an2b,a⇒b
an2■, etc.discovering directly-follows complete petri nets from event data 9
next, we consider a novel concept that takes the structure of the accepting petri net
into account. for this, we only consider sound models where all transitions have a label
(no silent transitions). each place has a set of input and output transitions. these are in
astructural directly-follows relation. if t1∈ •pandt2∈p•, then we expect – based on
the structure – that activity l(t1)can be directly followed by activity l(t2). if multiple
places in the petri net can be enabled concurrently, the same is expected to hold for the
input transitions of one place and the output transitions of another concurrently marked
place.
definition 14 (structural model-based directly-follows relation). letan= (n,
minit, mfinal)∈ u anbe a sound accepting petri net with n= (p, t, f, l )and
dom(l) =t.
–acts(an) ={l(t)|t∈t}is the set of activities in the model (consider only
structure and not behavior).
–dfs(an) ={(l(t1), l(t2))| ∃m∈rmk (an)∃p1,p2∈mt1∈ •p1∧t2∈p2•} ∪ { (▶
, l(t))| ∃p∈minitt∈p•}∪{ (l(t),■)| ∃p∈mfinalt∈ •p}is the set of directly-follows
relations possible according to the model’s structure.
–a1⇒s
ana2if and only if (a1, a2)∈dfs(an),a1̸⇒s
ana2if and only if (a1, a2)̸∈
dfs(an), and a1⇔s
ana2if and only if a1⇒s
ana2anda2⇒s
ana1.
a
t1
t3 p1 p2 p5 p6c
t2d
t5b ep3
p4t4
fig. 5. accepting petri net an 3that is notstructural directly-follows complete.
acts(an) =actb(an)by definition for sound accepting fully labeled petri nets.
however, dfs(an)anddfb(an)do not need to be the same. consider for example
accepting petri net an 3in figure 5. dfs(an 3) ={(▶, a),(▶, b),(a, c),(a, d),(a, e),
(b, c),(b, d),(b, e),(c, d),(c, e),(d,■),(e,■)}, butdfb(an 3) ={(▶, a),(▶, b),(a, c),
(b, c),(c, d),(c, e),(d,■),(e,■)}, i.e., the relations corresponding to places p3andp4
are missing.
based on accepting petri net an 3in figure 5, we consider two related event logs:
l3= [⟨a, c, d⟩10,⟨b, c, e⟩10]andl′
3= [⟨a, c, d⟩5,⟨a, c, e⟩5,⟨b, c, d⟩5,⟨b, c, e⟩5]. event
logl3could have been generated by simulating an 3, butl′
3could not (e.g., ⟨a, c, e⟩
is not possible). however, both have the same directly-follows relations (shown in fig-
ure 6). both event logs are directly-follows complete for an 3.
definition 15 (directly-follows complete log). letl∈ b(uact∗)be an event log
andan= (n, m init, mfinal)∈ uanbe an accepting petri net. lis directly-follows
complete for an ifdf(l) =dfb(an).10 wil van der aalst
a
cd
b e
fig. 6. directly-follows graph based on the behavior of the accepting petri net in figure 5. note
that the long-term dependencies between aandd, andbandeare missing because these activities
never directly follow one another.
note that df(l3) =df(l′
3) =dfb(an 3) ={(▶, a),(▶, b),(a, c),(b, c),(c, d),
(c, e),(d,■),(e,■)}. hence, both event logs are directly-follows complete with respect
toan 3.
obviously, models like an 3are difficult to discover. region-based techniques are
able to find the places p3andp4, but are unusable for real-life data sets because they
produce complex overfitting process models and are not scalable. therefore, we are
interested in the class of structural directly-follows complete accepting petri nets.
definition 16 (structural directly-follows complete model). letan= (n, m init,
mfinal)∈ uanbe a sound accepting petri net with n= (p, t, f, l )anddom(l) =t.
an is structural directly-follows complete if dfs(an) =dfb(an).
note that definition 16 does not depend on a log. it is a model property. an 1
in figure 1 is structural directly-follows complete, an 3in figure 5 is not. figure 7
shows that the free-choice property and structural directly-follows completeness are
independent.
a
d
p1 p8
bf
gc
ep2
p3
p4p5
p6
p7a
d
p1 p6
be c
p2
p3p4
p5
(a) not free -choice , but directly -follows complete (b) free -choice , but not directly -follows complete
fig. 7. two accepting petri net: (a) an 4isnotfree-choice, but structural directly-follows com-
plete (e.g., dcan be directly followed by both fandg) and (b) an 5is free-choice, but not
structural directly-follows complete (despite p4, activity bis never directly followed by e).
4 subclasses of accepting petri nets relevant for process mining
properties such as soundness, liveness, and boundedness are behavioral properties.
structural directly-follows completeness is both structural and behavioral. in this sec-
tion, we list properties relevant for process mining that are structural.discovering directly-follows complete petri nets from event data 11
definition 17 (structural properties). letn= (p, t, f, l )be petri net.
–nis a state machine if for all t∈t:|•t| ≤1and|t•| ≤1.
–nis a marked graph if for all p∈p:|•p| ≤1and|p•| ≤1.
–nis free-choice if for all t1, t2∈twith•t1∩ •t2̸=∅:•t1=•t2.
–nis uniwired if for all t1, t2∈t:|t1• ∩ •t2| ≤1.
–nis join-free if for all p∈pandt∈p•:|•p| ≤1or|•t| ≤1.
–nis free of self-loops if for all t∈t:•t∩t• ̸=∅.
–nis free of length-two loops if for all t1, t2∈t:t1• ∩ •t2=∅ort2• ∩ •t1=∅.
–nis free of pt handles if for all p∈pandt∈tthere are no two elementary
paths from ptotsharing only pandt.
–nis free of tp handles if for all p∈pandt∈tthere are no two elementary
paths from ttopsharing only pandt.
–nis a workflow net if there is one source place p▶∈pand one sink place p■∈p
such that •p▶=p■•=∅and all nodes are on a path from p▶top■.
note that these properties consider only the net structure (i.e., the initial marking
and behavior are not considered). free-choice nets separate choice and synchroniza-
tion and most process discovery algorithms aim to produce free-choice nets (note that
process trees and basic bpmn models with xor and and gateways correspond to
free-choice nets). block-structured process models (e.g., process trees) are also free of
pt and tp handles. the basic alpha algorithm has difficulties dealing with self-loops,
length-two loops, and non-free-choice constructs. workflow nets have places explicitly
indicating the start and the end of the process.
in the remainder, we focus on regular accepting petri nets as our target model.
such nets have desirable properties such as safeness, soundness, and have no silent or
duplicate activities.
definition 18 (regular accepting petri nets). an= (n, m init, mfinal)∈ uanis
a regular accepting petri net if an is safe, sound, and lis bijective (i.e., a one-to-one
correspondence between transitions and activities).
the following theorem is a generalization of theorem 4.1 in [5].
theorem 1. letan= (n, m init, mfinal)∈ uanbe a regular accepting petri net.
for any two transitions t1, t2∈tsuch that t1• ∩ • t2=∅: ifl(t1)⇒b
anl(t2), then
l(t2)⇒b
anl(t1).
proof. for simplicity, we assume that lis the identity function (this can be achieved by
renaming transitions using bijection l). let a, b∈t,a• ∩ • b=∅, and a⇒b
anb. we
need to prove that b⇒b
ana. ifa=b, this holds trivially. hence, we assume a̸=b.
because a⇒b
anb, there is a trace σ1· ⟨a, b⟩ ·σ2∈lang(an). because a• ∩ • b=∅,
σ1· ⟨b⟩is enabled. if σ1· ⟨b, a⟩is not enabled, then bremoves a token from an input
place of awithout returning it (remember that an is safe). however, if aconsumes
the token first, then bcan no longer fire (leading to a contradiction), i.e., σ1· ⟨b, a⟩is
enabled. therefore, σ1· ⟨b, a⟩ ·σ2∈lang(an)andb⇒b
ana. ⊓ ⊔12 wil van der aalst
5 the α1.0andα1.1algorithms
the original alpha algorithm was developed over two decades ago [5]. we refer to the
original algorithm as α1.0. it was described in publications such as [1, 5] and during the
development of α1.0it was already proven that any structured workflow net (swn)
without self-loops can be “rediscovered”, i.e., a directly-follows complete event log
obtained by simulating swn contains enough information for the algorithm to discover
the swn again (modulo renaming of places). an swn is free-choice, join-free, has a
source and sink place, and no implicit places (cf. definition 17). as pointed out in [1, 5],
α1.0has many known limitations. the algorithm assumes that the event log is directly-
follows complete and that all behavior observed should be captured in the model (i.e.,
no noise and infrequent behavior). moreover, it has problems dealing with short loops
and processes that cannot be expressed as a workflow net.
over the last two decades, there have been many proposals to “repair” α1.0e.g.,
[24, 25]. however, these alternative approaches assume information that goes beyond
the directly-follows relation and most of them are much more complicated (with many
case distinctions). in this paper, we propose two variants of α1.0:α1.1andα2.0. these
are as simple as the original algorithm, but allow for the discovery of a larger class
of process models. in this section, we introduce α1.1which is close to α1.0and only
changes the initial and final parts of the process model to allow for non-workflow nets.
definition 19 ( α1.1algorithm). theα1.1algorithm implements a function discα1.1∈
b(uact∗)→ u anthat returns an accepting petri net discα1.1(l)for any event log
l∈ b(uact∗). leta=act(l)andˆa=a∪ {▶,■}.
1.cnd(l) ={(a1, a2)|a1⊆ˆa∧a1̸=∅ ∧ a2⊆ˆa∧a2̸=∅ ∧
(∀a1∈a1∀a2∈a2a1⇒la2∧a2̸⇒la1)∧(∀a1,a2∈a1a1̸⇒la2)∧(∀a1,a2∈a2a1̸⇒l
a2)}are the candidate places,
2.sel(l) ={(a1, a2)∈cnd(l)| ∀(a′
1,a′
2)∈cnd (l)a1⊆a′
1∧a2⊆a′
2=⇒
(a1, a2) = (a′
1, a′
2)}are the selected maximal places,
3.p={p(a1,a2)|(a1, a2)∈sel(l)}is the set of all places,
4.t={ta|a∈a}is the set of transitions,
5.f={(ta, p(a1,a2))|(a1, a2)∈sel(l)∧a∈a1∩a} ∪ { (p(a1,a2), ta)|
(a1, a2)∈sel(l)∧a∈a2∩a}is the set of arcs,
6.l={(ta, a)|a∈a}is the labeling function,
7.minit= [p(a1,a2)∈p|▶∈a1]is the initial marking, mfinal= [p(a1,a2)∈p|
■∈a2]is the final marking, and
8.discα1.1(l) = (( p, t, f, l ), minit, mfinal)is the discovered accepting petri net.
the first two steps are most important. set sel(l)defines the set of places in terms
of preceding and succeeding activities. steps 3–8 are mostly bookkeeping, i.e., all the
elements in sel(l)are mapped onto places with the corresponding connections. ▶
and■are placeholders for the start and end of the process and are not mapped onto
transitions, but define the initial and final marking.
figure 8 shows a simple example highlighting the difference between α1.0and
α1.1. for the event log l= [⟨a, b⟩10,⟨b, a⟩10], theα1.1algorithm specified in defi-
nition 19 generates the correct regular accepting petri net shown in figure 8(a). α1.0discovering directly-follows complete petri nets from event data 13
a
t1 p1 p3
b
t2 p2 p4a
t3
p5 p6b
t4
(a) (b) 
fig. 8. improvement over the original algorithm: (a) shows the correct model an 6obtained
byα1.1and (b) shows the incorrect model an′
6obtained by α1.0for the event log l=
[⟨a, b⟩10,⟨b, a⟩10].
tries to create a workflow net with only one initially marked place (cf. figure 8(b)).
the model in figure 8(b) is unable to replay any of the traces in the event log, whereas
the model in figure 8(a) is able to replay all and does not allow for unseen behav-
ior. the original algorithm does not allow for concurrent initial and final activities and
also does not allow for initial and final activities occurring at different positions. for
l= [⟨a, b⟩10,⟨b, a⟩10]:▶⇒la,▶⇒lb,a⇒lb,b⇒la,a⇒l■, andb⇒l■. hence,
cnd(l) =sel(l) ={({▶},{a}),({▶},{b}),({a},{■}),({b},{■})}. note that p1
corresponds to ({▶},{a}), etc.
at1
p1 p4b
t2 p2c
t3 p3e
d
t4t5 p6
p5
fig. 9.α1.0produces an incorrect model for l4= [⟨a, b, c ⟩10,⟨a, b, d, a, b, c ⟩5,⟨a, b, c, e, b, c ⟩5,
⟨a, b, d, a, b, c, e, b, c ⟩2,⟨a, b, c, e, b, d, a, b, c ⟩2]. note that none of the traces can be replayed.
another event log where α1.0fails and α1.1produces the desired model is l4=
[⟨a, b, c⟩10,⟨a, b, d, a, b, c ⟩5,⟨a, b, c, e, b, c ⟩5,⟨a, b, d, a, b, c, e, b, c ⟩2,⟨a, b, c, e, b, d, a, b,
c⟩2]for which ▶⇒la,a⇒lb,b⇒lc,b⇒ld,c⇒le,c⇒l■,d⇒la,
ande⇒lb.sel(l) ={({▶, d},{a}),({a, e},{b}),({b},{c, d}),({c},{e,■})}de-
scribes the four places, e.g., p({▶,d},{a})is initially marked, •p({▶,d},{a})={d}, and
p({▶,d},{a})•={a}. figure 9 shows the incorrect model produced by the α1.0algo-
rithm. figure 10 shows the correct model produced by the α1.1(and later α2.0) algo-
rithm. note that the latter model is able to replay all traces.14 wil van der aalst
a
t1 p1 p4b
t2 p2c
t3 p3e
d
t4t5
fig. 10. α1.1produces the desired model is l4.
6 the α2.0algorithm
theα1.1algorithm overcomes some of the limitations of the original α1.0algorithm,
but for “internal places” the characteristics are essentially the same and short-loops are
still a problem. for l1= [⟨a, c, e, f ⟩5, . . .]in figure 1, still the incorrect accepting petri
netan′
1(figure 2) is discovered due to the self-loop involving band the length-two
loop involving candd. the requirements used in cnd(l)(definition 19) are always
violated for short loops. for any (a1, a2)∈cnd(l): ifa⇒la, then acannot be part
ofa1andacannot be part of a2. for any loop of length 2 involving aandb, we have
a⇒lbandb⇒laand the condition ∀a1∈a1∀a2∈a2a1⇒la2∧a2̸⇒la1used in the
computation of cnd(l)is violated for places connecting aandb.
forl1, we have b⇒l1bdue to the self-loop involving b, andc⇒l1dandd⇒l1cdue
to the length-two loop involving candd. therefore, there cannot be a place connecting
bto itself or a place connecting ctodordtoc. this can be solved by changing only the
first step of the α1.1algorithm specified in definition 19.
definition 20 ( α2.0algorithm). theα2.0algorithm implements a function discα2.0∈
b(uact∗)→ u anthat only differs from discα1.1in the first step (computation of
cnd(l)). the rest is the same as in definition 19.
cnd2.0(l) ={(a1, a2)|a1⊆ˆa∧a2⊆ˆa∧ (1)
(∀a1∈a1∀a2∈a2a1⇒la2)∧ (2)
(∃a1∈a1\a2∃a2∈a2\a1a2̸⇒la1)∧ (3)
(∀a1∈a1∀a2∈a1\a2a1̸⇒la2)∧ (4)
(∀a1∈a2\a1∀a2∈a2a1̸⇒la2)} (5)
candidate places are again represented by pairs of sets of activities. (a1, a2)∈
cnd2.0(l)should still be such that elements of a1are in a directly-follows relation
with elements of a2. however, it is no longer required that the reverse never holds,
i.e., we no longer demand that ∀a1∈a1∀a2∈a2a2̸⇒la1. instead, we assume the weaker
requirement that ∃a1∈a1\a2∃a2∈a2\a1a2̸⇒la1. this implies that a1̸=∅anda2̸=∅.
note that a1∈a1\a2anda2∈a2\a1such that a2̸⇒la1ensures that there is
an activity a1producing a token for the place without removing it and an activity a2
consuming a token from the place without putting it back.discovering directly-follows complete petri nets from event data 15
consider the event log l= [⟨a, b, d⟩10,⟨a, b, c, b, d ⟩3,⟨a, b, c, b, c, b, d ⟩2,⟨a, b, c, b,
c, b, c, b, d ⟩]. theα2.0algorithm discovers the loop of length two and returns the correct
petri net. the model returned by α1.0andα1.1only allows for trace ⟨a, b, d⟩and leaves
cdisconnected from the rest.
theα2.0algorithm is also able to discover the regular accepting petri net an 1
shown in figure 1. note that α2.0inherits all the improvements of the α1.1algorithm.
actually, the algorithm is able to discover all structural directly-follows complete mod-
els in this paper. describing the exact conditions under which the α2.0algorithm is
able to rediscover the correct model based on a directly-follows complete event log is
outside the scope of the paper. however, the examples clearly show that the class of
correctly discovered process models is extended significantly.
theα1.1andα2.0algorithms have been implemented in prom by aaron k ¨usters.
(the reader can download the prom nightly build from www.promtools.org .)
experiments show that for most event logs more places can be discovered compared to
the original algorithm, i.e., there are fewer transitions without any connecting places.
since there is no guarantee that all places are fitting for arbitrary processes, a check has
been added to remove places that cannot replay a predefined percentage of cases.
7 discussion
theα2.0algorithm is able to rediscover accepting petri nets such as an 1in figure 1,
an 4in figure 7(a), an 6in figure 8(a) based on a directly-follows complete event
log. the α2.0algorithm is of course unable to discover models from event logs that are
not directly-follows complete . it fully depends on ⇒l, but this is a reasonable assump-
tion. what has not been observed cannot be discovered! the α2.0algorithm is also
unable to discover models that are not structural directly-follows complete . the notion
of structural directly-follows complete was introduced in this paper. accepting petri net
an 3in figure 5 is not structural directly-follows complete because a̸⇒ldandb̸⇒le
although there are places ( p3andp4) connecting these activities. accepting petri net
an 5in figure 7(b) is not structural directly-follows complete, because b̸⇒lewhile
there is a place ( p4) connecting btoe.
such problems are unavoidable when assuming directly-follows completeness. there-
fore, directly-follows-based algorithms like the α2.0algorithm need to be supported by
pre- and post-processing techniques. here, we discuss some examples.
an obvious preprocessing step is the filtering of activities and variants as described
in [2]. the approach is to first remove infrequent or chaotic activities and then order
the remaining variants by frequency (selecting the most frequent ones). note that most
event logs follow a pareto distribution, i.e., most of the behavior is explained by a
limited number of activities and variants.
an obvious postprocessing step it to remove places that do not fit. one can use
theα2.0algorithm and then check every place individually. this can be done very
efficiently. for a place p, one can first look at the sum of the absolute frequencies of the
activities represented by •pand compare this with the sum of the absolute frequencies
of the activities represented by p•. if there is a substantial mismatch, the place can be
discarded or repaired. it is also possible to project the event log onto activities •p∪p•16 wil van der aalst
and perform token-based replay or alignments. this can be done very efficiently for a
single place. it is possible to set a threshold to retain only the places that fit a minimum
percentage of traces. in general, process mining tools should avoid producing models
that have known problems.
a
t1c
db
f
et2
t4
t5t6t3
p1p2
p3p4
p5p6
fig. 11. accepting petri net an′
1having the same directly-follows relations as an 1, i.e.,
dfb(an 1) =dfb(an′
1).
it is also possible to improve discovery by exploiting the fact that we are interested
insafe accepting petri nets, i.e., there should not be two tokens in the same place for
a particular case. this can be exploited to rule out certain constructs and speed-up the
implementation of the algorithm and postprocessing.
it is important to note that there are processes that are behaviorally different, but
have the same directly-follows relation. figure 11 shows an accepting petri net an′
1
such that dfb(an 1) =dfb(an′
1), i.e., the corresponding dfgs are identical (the dfg
shown in figure 3) although the behaviors are different. this shows the weakness of any
algorithm relying on directly-follows relations only.
figure 12(a) maps the arcs of the dfg shown in figure 3 (based on event log l1)
onto the places of accepting petri net an 1in figure 1. figure 12(b) maps the same
arcs onto the places of accepting petri net an′
1in figure 11. note the difference in the
connections between dande. figure 12 nicely illustrates that bidirectional arcs either
correspond to concurrency or loops of length two. often it is clear whether bidirectional
arcs correspond to concurrency or loops of length two. however, this cannot always be
decided based on just the dfg as the example shows.
another possible refinement is to consider more elements of cnd2.0(l). we now
consider only the maximal elements when applying sel(l)to the candidates gener-
ated in the first step. however, if we can quickly check places on projected event
logs, it is possible to select the “largest one” of good quality. instead of replaying, we
can first check the total number of produced and consumed tokens for a place. given
(a1, a2)∈cnd2.0(l), we can comparep
σ∈lp
a∈a1|[a∈σ]|(tokens produced
for the candidate place) andp
σ∈lp
a∈a2|[a∈σ]|(tokens consumed from the can-
didate place). if these values are very different, we can discard candidate (a1, a2).
instead, we pick the maximal candidate not having obvious quality problems.
finally, there is the observation that regular accepting petri nets (cf. definition 18)
cannot produce arbitrary directly-follows relations ⇒b
an. there is no regular acceptingdiscovering directly-follows complete petri nets from event data 17
ac
db
f
ep4
p5p4
p5 p1 p6
p3p3p2
p2p2
p2
p2p2
(a) mapping of dfg arcs onto petri net places in accepting petri net an 1
ac
db
f
ep4
p5p4
p1 p6
p3p2
p2p2
p2
p2p2
(b) mapping of dfg arcs onto petri net places in accepting petri net an 1'
fig. 12. mapping the directly-follows graph (dfg) based on l1onto the places of an 1and
an′
1.
petri net an withdfb(an) ={(▶, a),(a, b),(a, c),(b, c),(c,■)}. this knowledge
can be used to replace problematic edges in the directly-follows relation by silent activ-
ities before applying the α2.0algorithm. in this example, one should replace (a, c)by
(a, τ)and(τ, c)and then the α2.0algorithm produces the desired result.
8 conclusion
discovering accepting petri nets from example data in such a way that the resulting
model is not overfitting or underfitting is extremely challenging. one cannot assume
that all possible behaviors are in the sample log. therefore, one needs to resort to as-
sumptions like directly-follows completeness. the original alpha algorithm ( α1.0) was
based on this assumption. in this paper, we tried to push the boundaries of what can
be discovered using this assumption and also introduced the new concept of structural
directly-follows completeness. the insights obtained led to two new variants of the
original α1.0algorithm: α1.1andα2.0. theα2.0can correctly discover short-loops and
non-workflow-net structures. combining these with the usual pre- and post-processing
steps (i.e., filtering and local checks) results in a discovery algorithm that is practically
usable. future work aims at extensive experimentation of the presented approach and
detecting/repairing structures in directly-follows relations that cannot stem from a pro-
cess corresponding to regular accepting petri net.
acknowledgment
funded by the alexander von humboldt (avh) stiftung and the deutsche forschungs-
gemeinschaft (dfg, german research foundation) under germany’s excellence strat-
egy – exc 2023 internet of production – 390621612.18 wil van der aalst
references
1. w.m.p. van der aalst. process mining: data science in action . springer-verlag, berlin,
2016.
2. w.m.p. van der aalst. a practitioner’s guide to process mining: limitations of the directly-
follows graph. in international conference on enterprise information systems (centeris
2019) , volume 164 of procedia computer science , pages 321–328. elsevier, 2019.
3. w.m.p. van der aalst, a. adriansyah, and b. van dongen. replaying history on process
models for conformance checking and performance analysis. wires data mining and
knowledge discovery , 2(2):182–192, 2012.
4. w.m.p. van der aalst, v . rubin, h.m.w. verbeek, b.f. van dongen, e. kindler, and c.w.
g¨unther. process mining: a two-step approach to balance between underfitting and over-
fitting. software and systems modeling , 9(1):87–111, 2010.
5. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workflow mining: discovering
process models from event logs. ieee transactions on knowledge and data engineering ,
16(9):1128–1142, 2004.
6. f. aarts, f. heidarian, h. kuppens, p. olsen, and f. vaandrager. automata learning through
counterexample guided abstraction refinement. in formal methods (fm 2012) , volume
7436 of lecture notes in computer science , pages 10–27. springer-verlag, berlin, 2012.
7. f. aarts, f. heidarian, and f. vaandrager. a theory of history dependent abstractions for
learning interface automata. in concur 2012 , volume 7454 of lecture notes in computer
science , pages 240–255. springer-verlag, berlin, 2012.
8. d. angluin and c.h. smith. inductive inference: theory and methods. computing surveys ,
15(3):237–269, 1983.
9. a. augusto, r. conforti, m. marlon, m. la rosa, and a. polyvyanyy. split miner: auto-
mated discovery of accurate and simple business process models from event logs. knowl-
edge information systems , 59(2):251–284, 2019.
10. r. bergenthum, j. desel, r. lorenz, and s. mauser. process mining based on regions of
languages. in g. alonso, p. dadam, and m. rosemann, editors, international conference
on business process management (bpm 2007) , volume 4714 of lecture notes in computer
science , pages 375–383. springer-verlag, berlin, 2007.
11. j. carmona, j. cortadella, and m. kishinevsky. a region-based algorithm for discovering
petri nets from event logs. in business process management (bpm 2008) , pages 358–373,
2008.
12. j. carmona, b. van dongen, a. solti, and m. weidlich. conformance checking: relating
processes and models . springer-verlag, berlin, 2018.
13. j. desel and j. esparza. free choice petri nets , volume 40 of cambridge tracts in theoret-
ical computer science . cambridge university press, cambridge, uk, 1995.
14. j. desel and w. reisig. place/transition nets. in w. reisig and g. rozenberg, editors,
lectures on petri nets i: basic models , volume 1491 of lecture notes in computer science ,
pages 122–173. springer-verlag, berlin, 1998.
15. a. ehrenfeucht and g. rozenberg. partial (set) 2-structures - part 1 and part 2. acta
informatica , 27(4):315–368, 1989.
16. m. kerremans, t. srivastava, and f.choudhary. gartner market guide for process mining,
research note g00737056. www.gartner.com , 2021.
17. s.j.j. leemans, d. fahland, and w.m.p. van der aalst. discovering block-structured process
models from event logs: a constructive approach. in j.m. colom and j. desel, editors,
applications and theory of petri nets 2013 , volume 7927 of lecture notes in computer
science , pages 311–329. springer-verlag, berlin, 2013.discovering directly-follows complete petri nets from event data 19
18. s.j.j. leemans, d. fahland, and w.m.p. van der aalst. discovering block-structured pro-
cess models from event logs containing infrequent behaviour. in n. lohmann, m. song,
and p. wohed, editors, business process management workshops, international workshop
on business process intelligence (bpi 2013) , volume 171 of lecture notes in business in-
formation processing , pages 66–78. springer-verlag, berlin, 2014.
19. s.j.j. leemans, d. fahland, and w.m.p. van der aalst. scalable process discovery and
conformance checking. software and systems modeling , 17(2):599–631, 2018.
20. l. mannel and w.m.p. van der aalst. finding complex process-structures by exploiting
the token-game. in s. donatelli and s. haar, editors, applications and theory of petri nets
2019 , volume 11522 of lecture notes in computer science , pages 258–278. springer-verlag,
berlin, 2019.
21. m. sol ´e and j. carmona. process mining from a basis of state regions. in j. lilius and
w. penczek, editors, applications and theory of petri nets 2010 , volume 6128 of lecture
notes in computer science , pages 226–245. springer-verlag, berlin, 2010.
22. a.f. syring, n. tax, and w.m.p. van der aalst. evaluating conformance measures in process
mining using conformance propositions. in m. koutny, l. pomello, and l.m. kristensen,
editors, transactions on petri nets and other models of concurrency (topnoc 14) , volume
11970 of lecture notes in computer science , pages 192–221. springer-verlag, berlin, 2019.
23. f. vaandrager. model learning. communications of the acm , 60(2):86–95, 2002.
24. l. wen, w.m.p. van der aalst, j. wang, and j. sun. mining process models with non-free-
choice constructs. data mining and knowledge discovery , 15(2):145–180, 2007.
25. l. wen, j. wang, w.m.p. van der aalst, b. huang, and j. sun. mining process models with
prime invisible tasks. data and knowledge engineering , 69(10):999–1021, 2010.
26. j.m.e.m. van der werf, b.f. van dongen, c.a.j. hurkens, and a. serebrenik. process dis-
covery using integer linear programming. fundamenta informaticae , 94:387–412, 2010.
27. s.j. van zelst, b.f. van dongen, w.m.p. van der aalst, and h.m.w verbeek. discovering
workflow nets using integer linear programming. computing , 100(5):529–556, 2018.