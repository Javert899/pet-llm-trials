viewing the internet of events through a
process lens
wil m.p. van der aalst
eindhoven university of technology, p.o. box 513, 5600 mb, eindhoven, the
netherlands
abstract. the spectacular growth of event data is rapidly changing the
business process management (bpm) discipline. it makes no sense to
focus on process modeling (including model-based analysis and model-
based process automation) without considering the torrents of factual
data in and between today's organizations. hence, there is a need to
connect bpm technology to the \internet of events" and make it more
evidence-based bpm. however, the volume (size of data), velocity (speed
of change), variety (multiple heterogeneous data sources), and veracity
(uncertainty) of event data complicate matters. mainstream analytics
approaches are unable to turn data in to insights, once things get more
involved. therefore, they tend to focus on isolated decision problems
rather than providing a more holistic view on the behavior of actors
within and outside the organization. fortunately, recent developments
in process mining make it possible to use process models as the \lens"
to look at (low) level event data. viewing the internet of events through
a \process lens" helps to understand and solve compliance and perfor-
mance related problems. in fact, we envision a new profession |the
process scientist| connecting traditional model-driven bpm with data-
centric approaches (data mining, statistics, and business intelligence).
process mining provides the process scientist with a powerful set of tools
and prepares bpm for a highly connected world where processes are
surrounded by devices emitting events.
1 introduction
organizations are competing on analytics and only organizations that intelli-
gently use the vast amounts of data available will survive. process-mining tech-
niques enable the analysis of a wide variety of processes using event data. for
example, event logs can be used to automatically learn a process model (e.g.,
a petri net or bpmn model). next to the automated discovery of the real un-
derlying process, there are process-mining techniques to analyze bottlenecks, to
uncover hidden ineciencies, to check compliance, to explain deviations, to pre-
dict performance, and to guide users towards \better" processes. dozens (if not
hundreds) of process-mining techniques are available and their value has been
proven in many case studies. see for example the twenty case studies on the
webpage of the ieee task force on process mining [7]. the growing number
of commercial process mining tools (disco, perceptive process mining, celonis2 wil m.p. van der aalst
process mining, qpr processanalyzer, software ag/aris ppm, fujitsu in-
terstage automated process discovery, etc.) further illustrates the uptake of
process mining. the recent massive open online course (mooc) on process
mining attracted over 41.500 participants [4].
process mining provides the interface between process models and event data.
on the one hand, conventional business process management (bpm) and work-
ow management (wfm) approaches and tools are mostly model-driven with lit-
tle consideration for event data. on the other hand, data mining (dm), business
intelligence (bi), and machine learning (ml) focus on data without considering
end-to-end process models. process mining aims to bridge the gap between bpm
and wfm on the one hand and dm, bi, and ml on the other hand. here, the
challenge is to turn torrents of event data (\big data") into valuable insights
related to process performance and compliance.
fig. 1. process models can be seen as the glasses through which one can see structure
in otherwise puzzling event data.
this paper does not focus on specic process mining algorithms. instead, it
focuses on the interplay between event data and process models. as illustrated
in figure 1, process models can be used to view event data in such a way that
actionable knowledge can be extracted. process models can be used to extractviewing the internet of events through a process lens 3
real value from event data. however, this is only possible if model and data are
aligned. this is where process mining plays a crucial role.
this paper coins the term \process lens" and demonstrates that processes
can indeed be used to interpret confounding event data.
2 internet of events
in [3] the term internet of events (ioe) was coined to refer to all event data avail-
able. as described in [6, 8], society shifted from being predominantly \analog"
to \digital" in just a few years. society, organizations, and people are \always
on". data is collected about anything ,at any time , and at any place .event data
are the most important source of information. events may take place inside a
machine (e.g., an x-ray machine or baggage handling system), inside an enter-
prise information system (e.g., a order placed by a customer), inside a hospital
(e.g., the analysis of a blood sample), inside a social network (e.g., exchang-
ing e-mails or twitter messages), inside a transportation system (e.g., checking
in, buying a ticket, or passing through a toll booth), etc. events may be \life
events", \machine events", or both.
internet of 
contentinternet of 
people
‚Äúsocial‚Äùinternet of 
thingsinternet of 
places
‚Äúcloud‚Äù ‚Äúmobility‚Äù
internet of events‚Äúbig 
data‚Äù
fig. 2. the internet of events (ioe) is based on the internet of content (ioc), the
internet of people (iop), the internet of things (iot), and the internet of locations
(iol).
figure 2 aims to characterize the types of events available for analysis. as
shown the internet of events (ioe) is composed of:4 wil m.p. van der aalst
{ the internet of content (ioc): all information created by humans to increase
knowledge on particular subjects. the ioc includes traditional web pages,
articles, encyclopedia like wikipedia, youtube, e-books, newsfeeds, etc.
{ the internet of people (iop): all data related to social interaction. the iop
includes e-mail, facebook, twitter, forums, linkedin, etc.
{ the internet of things (iot): all physical objects connected to the network.
the iot includes all things that have a unique id and a presence in an internet-
like structure. things may have an internet connection or tagged using radio-
frequency identication (rfid), near field communication (nfc), etc.
{ the internet of locations (iol): refers to all data that have a spatial dimen-
sion. with the uptake of mobile devices (e.g., smartphones) more and more
events have geospatial attributes.
obviously, the ioc, the iop, the iot, and the iol are partially overlapping. the
spectacular growth of ioe impacts bpm, e.g., process improvements will increas-
ingly be driven by analytics. at the same time, organizations have diculties
exploiting the data they have. therefore, we propose process models to be used
as lenses to view data that are otherwise confusing.
3 process lens
to use a process model as a \lens" to observe the data from a particular view-
point, it is not sucient to have a model and data. both (i.e. model and data)
need to be aligned. this can be achieved through process mining. based on the
event data, a model can be discovered that is automatically aligned with the
data. through conformance checking, it is possible to align normative models
with the data and highlight discrepancies between modeled behavior and ob-
served behavior.
a
startregisterb
update
record 
c
add 
customer
dec1
c2c3
c4c5 ship
goods 
handle 
paymentf
end archivetrace #
abdef 280
acdef 252
adbef 248
adcef 220
1000 10001000
1000472528
1000
1000
1000
100010001000
1000
fig. 3. a process model discovered for an event log with 1000 cases. the model is
expressed in terms of a petri net.viewing the internet of events through a process lens 5
to introduce the notion of process discovery, we consider figure 3, which
shows an event log and a discovered process model. the event log holds infor-
mation on 1000 cases: 280 cases followed the trace abdef , 252 followed the trace
acdef , etc. the activity names have been shortened to a single letter, e.g., a =
register . in fact, the event log in figure 3 is signicantly simplied by abstract-
ing away many aspects. normally, each event refers to a case and an activity .
an event also has a timestamp and may refer to the resources used, there may
betransactional information , and any number of attributes. in the example log
such information is missing. cases and events cannot be distinguished, but the
compact representation allows us to illustrate the basics of process mining. there
are 280 cases that followed the same sequence of activities: abdef . the event
log in figure 3 has 5000 events, e.g., 1000 aevents that always happen rst.
the discovered process model in figure 3 is expressed in terms of a petri net.
in the initial state shown, only the transition having activity label acan occur. a
transition (represented as a square) can occur if all input places (represented as
circles) have a token (represented by a black dot). if a transition occurs, tokens
are consumed from all input places and produced for all output places. after the
occurrence of ain figure 3, there are tokens in c1andc2. hence after aeither
(1)banddoccur or (2) canddoccur (in any order). then eoccurs, followed
byf. the end state is the state with a token in end. note that the process model
is able to replay all 1000 cases: they all start in the initial state and nish in
the desired end state. figure 3 also shows the number of times each place and
transition is visited, e.g., boccurs 528 times.
registeradd
customerupdate
record
handle 
paymentship goods
startendarchive
fig. 4. a bpmn model corresponding to the discovered petri net in figure 3.
the bpmn model in figure 4 has the same behavior as the petri net model
in figure 3. we would like to stress that the notation is less relevant here:
automatic translations are possible and \observed behavior does not have a
preference for a particular syntax" (although people like to believe dierently).
only things that can be related to event data matter!
process models can be discovered automatically or made by hand. in both
scenarios, it is possible to check conformance . this is illustrated in figure 5.
assume that sometimes dis skipped or both bandcoccur. hence, reality as
described in the event log deviates from the model. figure 5 shows some diagnos-
tics. conformance checking techniques will immediately reveal such deviations.6 wil m.p. van der aalst
a
startregisterb
update
record 
c
add 
customer
dec1
c2c3
c4c5 ship
goods 
handle 
paymentf
end archivetrace #
abdef 270
acdef 243
adbef 242
adcef 220
activity  d is skipped 18 
times although the payment 
activity is mandatory !acef 10
abef 8
abdcef 5
abcdef 2for 7 cases activities b and c 
are both executed although 
they are mutually exclusive !
fig. 5. the event log now has 25 cases that do not t into the normative process
model. by replaying the event log one can see that activity dis sometimes skipped and
activities bandcare both executed although the model does not allow for this.
note that the process model is used as the \lens" to show non-conforming be-
havior.
a
startregisterb
update
record 
c
add 
customer
dec1
c2c3
c4c5 ship
goods 
handle 
paymentf
end archive
fig. 6. by replaying the event log on a discovered process model, one can see where
the bottlenecks are in the process.
replay can also be used to show bottlenecks, see figure 6. note that the
process model is now used as the lens to show performance-related behavior.
it is also possible to replay streaming event data, i.e., align cases to the
model while they are still running. this can be used to show the \trac" in the
process, as illustrated by figure 7. there are three types of cases (representedviewing the internet of events through a process lens 7
a
startregisterb
update
record 
c
add 
customer
dec1
c2c3
c4c5 ship
goods 
handle 
paymentf
end archive
fig. 7. by mapping running cases onto the model, one can see the \trac jams" in
an organization.
using triangles, squares, and circles). in figure 7 one can see the congestion of
particular case types at any point in time.
a
startregisterb
update
record 
c
add 
customer
de
c1
c2c3
c4c5 ship
goods 
handle 
paymentf
end archivetrace #
abdef 205
acdef 180
adbef 170
adcef 160
abedf 150
acedf 135
fig. 8. due to concept drift, the model is changing. hence, the model needs to be
adapted continuously to avoid misleading diagnostics.
the event log in figure 8 describes the same process, but in a later period.
again 1000 cases are recorded, but now the shipment ( e) often occurs before the
payment ( d). this was not possible according to the original model. the petri
net shown in figure 8 shows the updated process model also allowing for this
new behavior.
the change from the process in figure 3 to the process in figure 8, illustrates
that the simple dashboards and reports provided by contemporary business
intelligence (bi) tools are inadequate. one needs to look into the process and8 wil m.p. van der aalst
cannot reduce reality to a few key performance indicators (kpis). suppose one
is interested in the delay between payments (activity d) and shipments (activity
e). this corresponds to the sojourn time of tokens in place c4in figure 3.
the process could have been instrumented to measure these delays. however,
after the drift these times can be negative. shipments (activity e) happen before
payments (activity d), and statistics can become very misleading. if activities
are skipped, similar problems occur. hence, it is vital to align event data with
an up-to-date process model. existing bi tools not supporting process mining,
cannot cope with such issues. to use a bi tool, an idealized process is assumed
and only high-level measurements are performed.
process mining provides a way to look into the process and view event data
in a process-centric manner. process models provide the lenses to make sense
of event data. the volume (size of data), velocity (speed of change), variety
(multiple heterogeneous data sources), and veracity (uncertainty) of event data
necessitates state-of-the-art techniques that are able to reliably and eciently
interpret recorded events.
4 process mining in the large
the reader is referred to [1] for an introduction to process mining. process min-
ing extends far beyond process discovery. the alignment of process models and
event data enables all kinds of analytics, e.g., decision point analysis, bottleneck
analysis, time prediction, resource recommendation, and compliance checking.
the spectacular growth of event data provides numerous opportunities for
process mining in any business. however, there are also challenges related to
\process mining in the large". fortunately, recent developments show that pro-
cess mining is quite scalable compared to classical data mining techniques. some
examples:
{ many process-mining techniques (but obviously not all) are linear in the size
of the event log. if the number of activities is limited, then the time need to
discover a process model corresponds to the time to traverse the data.
{ there are some discovery approaches that are more time consuming and com-
puting alignments (e.g., for conformance checking or performance analysis) is
known to be time consuming. fortunately, there are generic techniques [2] to
decompose large process mining into many smaller ones that can be solved
much faster.
{ there are many ways to distribute process-mining problems. next to the
process-mining specic approach in [2], many subproblems can be trivially
distributed using mapreduce approaches exploiting for example hadoop for
distributed storage and distributed processing.
{ events logs can be decomposed for performance and scalability reasons. how-
ever, it is often also useful to partition the log and then compare the results.
techniques and tools for comparative process mining are emerging and es-
sential for conducting process mining at a larger scale, e.g., for comparing
dierent departments, regions, customer groups, or periods.viewing the internet of events through a process lens 9
{ the notion of \process cubes" can be used for comparative process mining.
events are stored in the cells of a multidimensional database. this is closely
related to online analytical processing (olap) technologies that aim to an-
swer multi-dimensional analytical queries using operators such as slice, dice,
roll-up, and drill-down.
the above developments illustrate that process mining ts well with other de-
velopments in the context of big data.
5 towards a process scientist
hal varian, the chief economist at google said in 2009: \the sexy job in the
next 10 years will be statisticians. people think i'm joking, but who would've
guessed that computer engineers would've been the sexy job of the 1990s?".
the later article with the provocative title \data scientist: the sexiest job
of the 21st century" [5] generated lots of attention for this new profession.
indeed, just like computer science emerged from mathematics in the 70-ties
and 80-ties, data science is now emerging from computer science, statistics, and
management science. however, let's not forget about processes. as argued in this
paper, processes provide the lenses to look at event data from dierent angles.
the focus on data analysis is good, but should not frustrate process-orientation.
in the end, good processes are more important than information systems and
data analysis. the old phrase \it's the process stupid" is still valid. hence, we
advocate the need for process scientists that will drive process innovations while
exploiting the internet of events (ioe).
references
1. w.m.p. van der aalst. process mining: discovery, conformance and enhancement
of business processes . springer-verlag, berlin, 2011.
2. w.m.p. van der aalst. decomposing petri nets for process mining: a generic
approach. distributed and parallel databases , 31(4):471{507, 2013.
3. w.m.p. van der aalst. data scientist: the engineer of the future. in k. mertins,
f. benaben, r. poler, and j. bourrieres, editors, proceedings of the i-esa confer-
ence, volume 7 of enterprise interoperability , pages 13{28. springer-verlag, berlin,
2014.
4. w.m.p. van der aalst. process mining: data science in action. coursera course,
november 2014. https://www.coursera.org/course/procmin.
5. t.h. davenport and d.j. patil. data scientist: the sexiest job of the 21st century.
harvard business review , pages 70{76, october 2012.
6. m. hilbert and p. lopez. the world's technological capacity to store, communi-
cate, and compute information. science , 332(6025):60{65, 2011.
7. ieee task force on process mining. process mining case stud-
ies. http://www.win.tue.nl/ieeetfpm/doku.php?id=shared:process_mining_
case_studies , 2013.10 wil m.p. van der aalst
8. j. manyika, m. chui, b. brown, j. bughin, r. dobbs, c. roxburgh, and a. by-
ers. big data: the next frontier for innovation, competition, and productivity.
mckinsey global institute, 2011.