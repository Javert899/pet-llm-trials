business process comparison:
a methodology and case study
alifah syamsiyah1, alfredo bolt1, long cheng1, bart f.a. hompes1, r.p.
jagadeesh chandra bose2, boudewijn f. van dongen1, and wil m.p. van der
aalst1
1eindhoven university of technology, the netherlands
fa.syamsiyah, a.bolt, l.cheng, b.f.a.hompes,
b.f.v.dongen, w.m.p.v.d.aalst g@tue.nl
2xerox, india
jagadeesh.prabhakara@conduent.com
abstract. business processes often exhibit a high degree of variability.
process variants may manifest due to the dierences in the nature of
clients, heterogeneity in the type of cases, etc. through the use of pro-
cess mining techniques, one can benet from historical event data to ex-
tract non-trivial knowledge for improving business process performance.
although some research has been performed on supporting process com-
parison within the process mining context, applying process comparison
in practice is far from trivial. considering all comparable attributes, for
example, leads to an exponential number of possible comparisons. in this
paper we introduce a novel methodology for applying process compari-
son in practice. we successfully applied the methodology in a case study
within xerox services, where a forms handling process was analyzed and
actionable insights were obtained by comparing dierent process variants
using event data.
keywords: process comparison process mining business analytics.
1 introduction
modern information systems and devices collect and store large amounts of event
data. for instance, erp systems record business transaction events, and high-
tech systems such as x-ray machines record an abundance of events [10]. such
historical event data can be used to extract non-trivial knowledge and interesting
insights that can be used for further analysis. increasingly process mining tech-
niques are used to analyze such data [20]. process mining covers three types of
analysis [19]: process discovery automatically extracts a process model from an
event log; conformance checking measures how well the behavior recorded in an
event log ts a given process model and vice versa; and process enhancement is
concerned with extending or improving an existing a-priori process model using
event data.2 alifah syamsiyah et al.
in process mining, process characteristics such as waiting times, through-
put times, and utilization rates are typically of interest, and can be obtained
from real-life event data. many processes exhibit a high degree of variability.
there may be major dierences between processes and their variants, due to
an abundance of factors such as temporal changes, the geographical location of
the process execution, the involved resources and the overall context in which a
process is executed [1, 6]. in such scenarios, our research question is: how can
we conduct a comparative analysis of dierent processes and their variants in
real businesses? based on the results of the analysis, we should be able to nd
the dierences between multiple processes and also nd root causes for ine-
ciencies such as delays and long waiting times for the interpretation of process
behaviors. moreover, domain experts should also able to identify the precise
events that correspond to unusual behavior, and consequently devise concrete
measures to improve their business processes [17].
in this paper, we present a methodology for business process comparison. we
do so by presenting an overall methodology and an instantiation thereof in the
context of a large service delivery organization: xerox services. this organiza-
tion caters similar processes across several clients, hence process variants may
manifest due to the dierences in the nature of clients, heterogeneity in the type
of cases, etc. moreover, the organization's operational key performance indi-
cators (kpis) across these variants may widely vary. we show that, using our
method, we gain insights into the dierences between variants and we leverage
these insights on non-performing variants by means of process comparison.
the highlighted contributions of this paper are as follows:
{present a methodology for process comparison which focuses on the analy-
sis of multiple processes. this methodology considers multiple perspectives,
such as control ow, organizational, data, performance, etc.
{validate the methodology in a case study using real-life data.
the remainder of this paper is organized as follows. in section 2, we discuss
related work in process comparison and process mining methodologies. then, we
explain the proposed process comparison methodology in section 3 and apply
the methodology in a case study in section 4. section 5 concludes the paper.
2 related work
in recent years, the value of process mining techniques has been demonstrated
incase studies across dierent domains such as healthcare [11, 21, 25], industry
[12, 13, 15], insurance [17], and nance [7, 8]. however, few methodologies have
been proposed to carry out process mining projects in a structured manner. in
[2], the process diagnostics method (pdm) is proposed to quickly obtain a broad
overview of the process at hand, without the need for any domain knowledge.
as such, it can be used to steer a process mining project by providing initial
insights and analysis opportunities. for example, the method has been adopted
for the analysis of healthcare processes in [14]. in [19], the l* life-cycle model isbusiness process comparison: a methodology and case study 3
proposed as an approach for mining processes. l* covers many techniques, and
describes the life-cycles of a typical process mining project aiming to improve
processes. since pdm focuses on providing a broad overview using a limited
set of process mining techniques and because l* is aimed at the analysis of
structured processes, the authors of [23] proposed pm2: a process mining project
methodology . pm2is designed to support projects aiming to improve process
performance or compliance, and focuses on iterative analysis. its applicability
was shown by a case study conducted on data provided by ibm. like l*, pm2
covers a wide array of process mining techniques. contrary to l*, however, pm2
is suitable for the analysis of both structured and unstructured processes.
a common pitfall of the discussed process mining methodologies is that the
focus is on the analysis of a single process, as mentioned in [23]. as such, pro-
cess comparison remains an interesting but insuciently researched topic. the
comparison of processes based on event logs has been the focus of several papers
[1, 4, 5, 18]. however, most process comparison approaches take into consid-
eration only the control-ow aspect (i.e., presence, routing and frequency of
activities), while ignoring other dimensions.
given the increased interest in process comparison from perspectives other
than just control ow, and the lack of methodological support for applying pro-
cess comparison in a process mining project in practice, we propose the process
comparison methodology (pcm). in this work, dierent from existing process
mining methodologies, we introduce a novel methodology by considering multi-
ple aspects, such as the organizational aspect (i.e. the involved resources, roles,
and groups), the data aspect (attribute values), the performance aspect, etc. we
validate our methodology in a case study using real-life data provided by xerox
services. to the best of our knowledge, this is the rst work that methodologi-
cally considers business process comparison from multiple perspectives.
3 the process comparison methodology (pcm)
when comparing multiple processes, it is common that those processes have mu-
tual attributes for categorization. when process comparison methods are applied
to highlight the dierences between similar categorized processes, the results are
more detailed and representative than when comparing dissimilar or unrelated
processes. based on these underlying assumptions, in this section, we introduce
a methodology for process comparison which considers many perspectives. our
methodology comprises of ve main phases as depicted in figure 1.
first, the data pre-processing phase transforms raw data to standardized
event log formats such that existing process mining techniques can be applied.
next to the event logs, the so-called -attributes are selected. these attributes
are case-level attributes that identify the variants of interest. next, in the scop-
ing analysis phase, the interesting cases to be used for answering the analysis
questions are identied. in the third phase, comparable sub-logs are generated
by aggregating similar cases. fine-grained analysis of the generated sub-logs4 alifah syamsiyah et al.
1.¬†data¬†
preprocessing
xes¬†log¬†2.¬†scoping¬†
analysis
Œ±‚Äêattributes ¬†raw¬† data
4.¬†in‚Äêdepth¬†
comparison3.¬†identifying¬† comparable ¬†
sub‚Äêlogs5.¬†interpretation ¬†
and¬†validation
results
fig. 1. process comparison methodology (pcm)
takes place in the in-depth comparison phase. finally, the discovered results are
delivered to the process owners.
phase 1. in the data pre-processing phase, raw data is translated to stan-
dardized event log formats such that existing process mining techniques can be
applied. we have two main objectives for the data pre-processing phase: (1) re-
ne event data collected by information systems; and (2) create an event log and
identify a set of case attributes to be used in the comparison process.
typically, raw event data are collected by dierent information systems at
dierent levels of granularity. to conduct a meaningful analysis, we combine all
collected event data and merge them into a single collection of events. here,
standard data cleaning techniques can be used if the raw data contains noise.
from this event collection, an event log is devised. to get an event log from
an event collection, a notion of cases is introduced. a case refers to a time-
ordered sequence of events relating to the some underlying concept, for example
a purchase order or a single run of a machine, (i.e. events need to be correlated
to form traces of events). we follow the xes standard [24] as the format for the
generated event log, to make existing process mining techniques (implemented
in tools such as prom1) accessible in the following phases of our methodology.
finally, next to the case notion, attributes of interest are selected as the so-called
-attributes. in the further comparison, we consider the -attributes to denote
the process variant.
phase 2. once the event log and the -attributes are dened, we scope our
analysis. the goal of the scoping phase is to limit the number of comparisons
to be executed later. typically, scoping is done based on the -attributes, for
example by selecting the most frequent values of these attributes. however, in
general, the scoping decision must follow the business questions and the goal
of doing process comparison. as a result of scoping, a collection of sub-logs is
generated, again in the xes format.
phase 3. the next phase in the analysis is the identication of compara-
ble sub-logs. each of the sub-logs obtained during scoping refers to a variant of
the process under investigation. however, these variants are not always directly
1seehttp://processmining.org and http://promtools.orgbusiness process comparison: a methodology and case study 5
comparable. they may, for example, consist of disjoint sets of activities. there-
fore, in this phase, we select comparable variants (i.e. variants that have enough
commonalities).
the identication of comparable sub-logs can be done in several ways. for
example, we can use domain knowledge to manually select sub-logs to be com-
pared. alternatively, if domain knowledge is not available, clustering techniques
can be used to group sub-logs based on a quantiable similarity notion [16].
phase 4. after sets of comparable sub-logs are identied, we treat each set
as the starting point for the in-depth comparison phase. in this process, the sub-
logs in each set will be pairwise compared and the output of this phase will be
a collection of observed and interesting dierences between the input sub-logs.
for the in-depth comparison, the pairwise analysis of the sub-logs should
often not be limited to control ow only. instead, other aspects of processes,
such as performance characteristics, resource utilization and compliance aspects
should be considered. most importantly, the inuence of these aspects on each
other should be investigated. for example, cases in which dierent resources
were involved could have signicantly dierent durations, which might be an
actionable insight.
it should be noted that only the relevant and impactful dierences are of
interest to the process owner. for example, a dierence in case duration of several
seconds may be irrelevant in processes where the average case duration is in the
order of days, while in processes that generally last minutes this dierence can
be signicant.
phase 5. after completing the in-depth comparison for each cluster and
having identied relevant and impactful dierences, the relevant results will be
be reported to the process owner. we identify two activities for this phase:
1.presentation and interpretation. after the process mining analysis has been
performed, we obtain facts about the process. most of the time, these facts
are raw and disconnected with each other. therefore, to provide meaningful
information at the business level, an additional presentation and interpreta-
tion step is needed. the signicance of the results depends on how well the
analysis and interpretation step is executed.
2.validation. the results from the in-depth comparison have to be validated
with the process owner and participants in the process.
in the remainder of this paper, we show how this high-level methodology can
be executed in a concrete case study within xerox. we use publicly available
tools and techniques on proprietary data and we closely involved the xerox
stakeholders in the analysis.
4 xerox case study
this section discusses the application of pcm on a case study conducted within
xerox services. the study involved a real-life data set with millions of events.
first, we explain the data set in terms of its structure and its origin, and give a6 alifah syamsiyah et al.
1. data 
preprocessing
xes log 
2. scoping 
analysis
Œ±-attributes 
log Œ±1
log Œ±n:
cases in top n of 
attribute Œ± 
3a. discovery
log Œ±1
log Œ±n:
raw data
model Œ±1 
model Œ±n
3b. cross 
comparison
:
comparison matrix
log Œ±z
log Œ±ylog Œ±x4. in-depth 
comparison3c. clustering
5. interpretation 
and validation
process mining tool results
fig. 2. process comparison methodology applied to a xerox dataset
description of the process contained in it. then, we present the application of our
proposed methodology in detail. as demonstrated in figure 2, the instantiation
of each phase in our application corresponds to the ve phases in figure 1,
respectively. however, for the case study, the phase identifying comparable sub-
logs is rened into three smaller phases here: discovery ,cross comparison , and
clustering . this renement choice is one of many ways to identify comparable
sub-logs.
in our implementation, we used both prom (for steps 1 and 4 in figure 2)
and rapidprom (for steps 2, 3a, 3b, and 3c). the used rapidprom workow is
depicted in figure 3 and available at https://goo.gl/bcq1uo .
fig. 3. the rapidprom workow used for scoping analysis and identifying comparable
sub-logsbusiness process comparison: a methodology and case study 7
4.1 data set
we analyzed event logs pertaining to the transaction processing business unit
within xerox services. more specically, we analyzed the process pertaining to
the data entry back-oce operations of insurance claim forms. forms submitted
to the insurance providers need to be digitized before the claims can be pro-
cessed. business process outsourcing (bpo) organizations assist the insurance
providers in this process. forms received by the bpo organization are classied
and sorted depending on the type of form (e.g. hcfa, ub04, dental, etc.). more
ne-grained classications further rening each type are possible (e.g. hcfa
standard, hcfa careplus, etc.), thereby dening a taxonomy. dierent classes
in the taxonomy are divided into so-called batches, where each batch caters to
one type of insurance claim form (e.g. hcfa standard).
a transaction refers to the data entry operations of one instance of an in-
surance claim form. the organization handles data entry operations of millions
of such instances of insurance claim forms. in this paper, we only consider the
transactions of one month pertaining to one client, but the approach can be
applied to even larger data sets. furthermore, dierent attributes concerning
the execution of events such as involved resourced and properties of the forms
are recorded as well. the complete dataset used here contains information on
hundred transactions comprising 20 million events divided across 94 batches.
the organization is interested in analyzing the processes followed across dier-
ent batches and wants to obtain insights on their executions. in this paper, we
focus on the analysis of three batches, where two are similar but not identical
and the third batch is dierent from the other two.
4.2 data preprocessing
we transformed the raw event data obtained as csv le to a standard xes
log with the convert csv to xes plugin in prom. to make this transformation
meaningful and successful, we have done the following three main pre-processing
steps. (1) we enriched the set of attributes based on anticipated questions. since
we are interested in analyzing dierent batches (see subsection 4.1), we set the
attribute batchname as theattribute to be used in comparison process. (2)
we rened data into event level. each activity in the input log includes two
timestamps, indicating its start and end point, therefore we divide each activity
into two events based on that. (3) we removed uninteresting/uncompleted cases
from the log. based on statistics on the start and end activities for all cases,
we removed those case that have a start or end activity that does not appear
frequently enough. through this process, we removed 318,002 cases, and the
output xes log contains 936,720 cases and 31,660,750 events.
4.3 scoping analysis
we implemented our scoping analysis using rapidprom (as depicted in figure
4) to select the interesting batches (batches that are infrequent will not be con-
sidered in our analysis). for the generated xes log in the preprocessing phase,8 alifah syamsiyah et al.
fig. 4. scoping analysis to select the most frequent batches
we rst aggregated all the events based on their batchname values. then, we
ltered out the popular batches based on their occurrence frequency. there are
94 dierent batches in our log. we selected the 10 most frequent ones. their
corresponding batch identiers are 1, 4, 2, 11, 7, 18, 3, 58, 23, and 30 respec-
tively, each having between 424,560 and 8,684,476 cases. we divided the xes
log into 10 sub-logs according to the chosen batch names, and conducted our
process analysis using these sub-logs.
4.4 identifying comparable sub-logs
given a collection of sub-logs from the previous phase, the next step is to identify
subsets such that sub-logs within each subset share similar behavior (i.e. they are
comparable to each other). in the next phase, the sub-logs within one such subset
will be compared to obtain more rened comparison results. in this section, we
explain the dierent steps of the techniques we used to identify comparable
sub-logs. in figure 2, these steps refers to phases 3a, 3b, and 3c.
discovery. based on our goals, we compared the extracted batches based on
the analysis of their high-level process models. these models can be retrieved
by current process mining techniques. various process discovery algorithms such
as the alpha algorithm [20], ilp miner [22] and inductive miner [9] have been
proposed in the past years. considering the amount of events in our logs as well as
the quality of discovered processes (e.g., soundness and tness), we have chosen
the inductive miner. besides the fact that the inductive miner is the state-of-
the-art process discovery algorithm, other techniques are inclined to produce
models that are unable to replay the log well, create erroneous models, or have
excessive run times for event logs of this size. the output of this phase is a
collection of process models per sub-log.
cross comparison. in [3], buijs coined the term cross comparison and presents
the so-called comparison table, which has been evaluated in a case study using
event data from ve municipalities. a comparison table consists of three types of
metrics, namely process model metrics, event log metrics, and comparison met-
rics.process model metrics are metrics calculated using only the process model,
such as total number of nodes in the process model, cyclicity, or concurrency
in the process model. event log metrics are metrics calculated based on event
log, such as the total number of traces and events, average trace duration, etc.business process comparison: a methodology and case study 9
table 1. example cross-comparison table showing the cross comparison between logs
and models in dierent batches.
model 1model 2model 3...
log 10.64 0.37 0.25 ...
log 20.26 0.68 0.6 ...
log 30.25 0.69 0.61 ...
... ... ... ... ...
comparison metrics are used to compare modeled and observed behavior and
include metrics such as tness, precision, generality, and simplicity [19].
in this phase, we apply the tness comparison metric to the sub-logs and their
corresponding discovered models. we choose tness rather than the other metrics
due to the need of xerox services to have process models which allow for most of
the observed behavior. table 1 shows an excerpt of the cross comparison using
tness metric between logs and models in dierent batches. each row represents
a log of a particular batch n(logn), and each column represents a discovered
model from a particular batch m(model m). each cell contains the tness value
after replaying a log into a process model.
clustering. based on the cross-conformance checking results, we grouped the
sub-logs (i.e. batches) into clusters using k-means clustering. we chose this clus-
tering algorithm because of the information from domain expert that a batch
belongs to a single cluster and thus cluster overlap is not possible. concretely,
we used the rows of the cross-conformance matrix (table 1) as observations to
perform a k-means clustering. in our experiments, we used k = 3 clusters, and
we identify the clusters as follows: (1) cluster 0: batches 3, 4, 18, 23, (2) cluster
1: batches 1, 2, 7, 11, 52, (3) cluster 2: batch 30.
the resulting clusters contain groups of similar (i.e. comparable) batches.
comparative analysis can be performed within any of the clusters. note that
cluster 2 contains only one batch (batch 30). this can be caused by the fact that
batch 30 is very dierent from all other batches.
4.5 in-depth comparison
once clusters of comparable batches have been identied, we can proceed to
compare the batches in each cluster. to illustrate this, we apply two process
comparison techniques to the batches contained in cluster 0. the rst tech-
nique (as introduced in [1]) detects statistically signicant dierences between
two sub-logs in terms of control-ow and overall performance. the results of
this technique identify those parts of the process where dierences occur. how-
ever, they do not explain why such dierences manifest. the second technique
(as introduced in [6]) tackles this issue by analyzing, for each sub-log, the ef-
fect that dierent contexts (e.g. involved resources, data attributes, control-ow,
etc.) have on process performance, and whether that eect is statistically sig-
nicant. using these two techniques on the batches contained in cluster 0, we
could obtained valuable insights.10 alifah syamsiyah et al.
we rst applied the process comparison technique [1] to the four sub-logs of
cluster 0 to get a ranked list of pairs of sub-logs. after sorting the list based
on the percentage of control-ow dierences between the pairs of sub-logs, we
found that: batches 3 vs. 18 (38.04% control-ow dierence), batches 4 vs. 23
(42.03%), batches 3 vs. 23 (72.16%), batches 18 vs. 23 (73.40%), batches 3 vs.
4 (78.43%), and batches 4 vs. 18 (78.64%). this means that batches 4 and 18
are the most dissimilar pair within cluster 0, and batches 3 and 18 are the most
similar. in order to illustrate the in-depth comparison phase, in the remainder
of this section we will analyze the dierences between batches 4 and 18 and
between batches 3 and 18.
in figure 5, we provide an example of the control-ow dierences found
between batches 4 and 18. the dark-blue colored states are executed only in
batch 18, and never in batch 4. these states are related to optical character
recognition (ocr) in forms. moreover, an example of the performance dierences
found between batches 4 and 18 is also shown in figure 6. we can see that the
duration of the activity entry is statistically signicantly higher in batch 18
than in batch 4. this activity refers to manual entry of form content.
.
from¬†this¬†node,¬†the¬†left¬†branch¬†is¬†only¬†
executed¬†by¬†batch¬†18¬†(group¬†a),¬†while¬†
the¬†right¬†branch¬†is¬†only¬†executed¬†by¬†
batch¬†4¬†(group¬†b).
fig. 5. control-ow dierences between batch 18 (group a) and batch 4 (group b).
the activities toocr, images2humana, fromocr, fixafterocr are executed only
in batch 18.
to see whether there are any signicant dierences manifested in the behav-
ior of the similar batches 3 and 18, we also conducted another comparison using
the same technique. from figure 7, we can see a signicant dierence in the fre-
quency of execution of the process fragment, corresponding to the transformation
of data from xml to the x12 format, and the transmission and acknowledgmentbusiness process comparison: a methodology and case study 11
fig. 6. performance dierences between batch 18 (group a) and batch 4 (group b).
the average duration of the entry activity is 44 mins for batch 18 and 5 mins for batch
4.
of that data. this fragment is almost always executed in batch 18, it is executed
only in approximately 93% of the cases in batch 3. similarly, the cleanup ac-
tivity is executed in only 5% of the cases in batch 18 against 12% in batch 3.
from a performance point of view, we see that there is a signicant dierence
in the average duration of cases until the execution of the cleanup activity (22
days vs. 10 days). note that besides this dierence, for both batches, the stan-
dard deviation of the duration until cleanup is very high relative to the average
duration.
.
.
.activities¬†in¬†orange¬†
ovals¬†are¬†executed ¬†¬†
in¬†batch¬†18¬†(group¬†b)¬†
more¬†frequently ¬†
than¬†in¬†batch¬†3¬†
(group¬†a).
cleanup¬†activity¬†is¬†executed ¬†in¬†12.31%¬†of¬†the¬†
cases¬†in¬†batch¬†3¬†vs¬†5.3%¬†in¬†batch¬†18¬†
different¬†average ¬†case¬†duration¬†
(22¬†days¬†vs¬†10¬†days)
fig. 7. example of dierences found between batch 3 (group a) and batch 18 (group
b).
we analyzed the observed dierences between the three batches in more detail
using the context-aware performance analysis technique from [6]. this analysis
revealed that, for batch 18, signicant dierences exist between the resources
that execute the entry activity (in terms of the waiting time for the activity).
this observation is shown in figure 8. the waiting times range from several
hours to multiple days, and hence might be worth looking into. as explained,
the standard deviation for the case duration until the cleanup activity between12 alifah syamsiyah et al.
entry
involved resource5h0m00s11h0m00s17h0m00s23h0m00s1d5h0m00s1d11h0m00s1d17h0m00s1d23h0m00s2d5h0m00s2d11h0m00s2d17h0m00sactivity waiting timethe waiting time for 
entry when resource 
30208974 is involved 
is less than 5 hours.the waiting time for 
entry when resource 
30213628sp is 
involved is more than 
2 days.
fig. 8. the resources involved in the entry activity in batch 18 lead to dierent waiting
times.
batches 18 and 3 is quite high relative to the average duration. this observation
was analyzed in more detail as well. we found that the duration until cleanup
showed big dierences between the days in which the cleanup activity happened.
in some dates, the duration until cleanup took several days while in other dates,
it took multiple weeks. this is illustrated in figure 9.
4.6 delivering results
our results discussed above have been presented to and conrmed by a domain
expert. (1) the control-ow dierences in figure 5 are attributed to the fact that
the two batches deal with dierent types of forms. batch 18 deals with ub-04
forms, a claim form used by hospitals, nursing facilities, in-patient, and other
facility providers. these forms are lled by healthcare providers and they can
contain handwriting (e.g. disease codes, diagnosis, etc.), so ocr is needed. in
contrast, batch 4 deals with claim correspondence forms (i.e. reply forms from
the provider). these forms are typically digital. hence there is no need for ocr.
(2) the performance dierence in figure 6 is attributed to the fact that the
forms related to batch 4 (i.e. correspondence forms) are usually smaller than
the forms related to batch 18 (i.e. ub-04 forms), and have little content to be
cleanup
date0d23h0m00s2d23h0m00s4d23h0m00s6d23h0m00s8d23h0m00s10d23h0m00s12d23h0m00s14d23h0m00s16d23h0m00s18d23h0m00s20d23h0m00s22d23h0m00s24d23h0m00s26d23h0m00scase durationcases for which the 
cleanup activity was 
performed on 
october 19 took 
up to 23 hours.cases for which the 
cleanup activity was 
performed on 
november 2 took 
more than 20 days.
fig. 9. the duration until the cleanup activity in cases in batch 3 varies highly between
days.business process comparison: a methodology and case study 13
entered manually. hence, the average duration of entry activity in batch 4 is
lower. although these dierences between batch 18 and 4 are insightful, they are
not very surprising. similarly, the dierences in duration in the manual entry
of smaller vs. larger forms in terms of page and image count is to be expected
as well. however, the dierences in waiting times for dierent resources are
surprising and need to be investigated in order to avoid delays.
the dierences between batches 3 and 18 have also provided interesting ac-
tionable insights. both batches 3 and 18 correspond to a similar type of form
(ub-04) and are expected to have very similar behavior. the remarkable dif-
ferences in the frequencies in the process fragment are statistically signicant
and moreover unexpected by the domain expert, and hence need further inves-
tigation. the observed dierences in duration until the cleanup activity can be
explained by the fact that, in the analyzed process, a lot of (sub) batch pro-
cessing is involved, and as such, cases sometimes need to wait for other cases in
order to be processed.
5 conclusion
in this paper we have introduced a novel methodology for process comparison
within the process mining context, which aims at eciently examining the dier-
ences between multiple business processes and process variants. the proposed
methodology, called the process comparison methodology (pcm), considers
multiple perspectives during comparison, such as control ow, organizational,
data, and performance.
pcm consists of ve main phases. first, the data pre-processing phase trans-
forms raw data to standardized event log formats. secondly, the scoping analysis
phase creates sub-logs based on some case attributes values. next, the interesting
sub-logs to be used for answering analysis questions are identied. then, in the
identifying comparable sub-logs phase, similar sub-logs are aggregated to gener-
ate comparable sub-logs. in the in-depth comparison phase, ne-grained analysis
is conducted within comparable sub-logs. finally, the results are interpreted and
validated in the interpretation and validation phase and the discovered insights
and actions are delivered to the process owners.
the practical relevance of pcm is shown in a case study using real-life data
provided by xerox services. the process pertains to the data entry back-oce
operations of insurance claim forms. the organization is interested in analyz-
ing the processes followed across dierent batches. as there are 94 batches it
was unfeasible to compare each pair in detail. through the application of our
methodology, however, very meaningful results were obtained, conrmed by a
domain expert, and transformed into actionable insights such as studying the
root causes and contextual circumstances for the aberrant instances.
in the future, we would like to investigate more techniques related to the
comparison of business processes in order to further rene our methodology.
moreover, we would also like to study more relevant business questions through
our collaboration with xerox services.14 alifah syamsiyah et al.
bibliography
[1] a. bolt, m. de leoni, and w.m.p. van der aalst. a visual approach to
spot statistically-signicant dierences in event logs based on process
metrics. in caise , volume 9694, pages 151{166. springer, 2016.
[2] m. bozkaya, j. gabriels, and j.m.e.m. van der werf. process diagnostics:
a method based on process mining. in a. kusiak and s. lee, editors,
eknow 2009 , pages 22{27. ieee computer society, 2009.
[3] j.c.a.m. buijs. flexible evolutionary algorithms for mining structured
process models . phd thesis, tu eindhoven, 2014 (cit. on p. 179), 2014.
[4] j.c.a.m. buijs and h.a. reijers. comparing business process variants
using models and event logs. in bmmds/emmsad , pages 154{168,
2014.
[5] c. cordes, t. vogelgesang, and h. appelrath. a generic approach for
calculating and visualizing dierences between process models in multidi-
mensional process mining. in bpm workshops , volume 202, pages 383{394.
springer, 2015.
[6] bart f. a. hompes, joos c. a. m. buijs, and wil m. p. van der aalst. a
generic framework for context-aware process performance analysis. in on
the move to meaningful internet systems: otm 2016 conferences: con-
federated international conferences: coopis, c&tc, and odbase 2016,
rhodes, greece, october 24-28, 2016, proceedings , pages 300{317. springer
international publishing, 2016.
[7] m. jans, m. alles, and m.a. vasarhelyi. process mining of event logs in
internal auditing: a case study. in isais , 2012.
[8] m.j. jans, m. alles, and m.a. vasarhelyi. process mining of event logs in
auditing: opportunities and challenges. available at ssrn 2488737 , 2010.
[9] s.j.j. leemans, d. fahland, and w.m.p van der aalst. discovering block-
structured process models from event logs containing infrequent be-
haviour. in bpm , pages 66{78. springer, 2013.
[10] s.j.j leemans, d. fahland, and w.m.p. van der aalst. scalable process
discovery with guarantees. in bpmds/emmsad , pages 85{101, 2015.
[11] r.s. mans, h. schonenberg, m. song, w.m.p van der aalst, and p.j.m
bakker. application of process mining in healthcare - a case study in a
dutch hospital. in biostec , pages 425{438, 2008.
[12] z. paszkiewicz. process mining techniques in conformance testing of in-
ventory processes: an industrial application. in bis workshop , pages 302{
313, 2013.
[13] m. puchovsky, c. di ciccio, and j. mendling. a case study on the business
benets of automated process discovery. in simpda , pages 35{49, 2016.
[14] a. rebuge and d.r. ferreira. business process analysis in healthcare en-
vironments: a methodology based on process mining. inf. syst. , 37(2):99{
116, 2012.
[15] a. rozinat, i.s.m. de jong, c.w. g unther, and w.m.p. van der aalst.
process mining applied to the test process of wafer scanners in asml.
ieee trans. systems, man, and cybernetics, part c , 39(4):474{479, 2009.business process comparison: a methodology and case study 15
[16] m. song, c.w. g unther, and wil m. p. van der aalst. trace clustering in
process mining , pages 109{120. springer berlin heidelberg, berlin, heidel-
berg, 2009.
[17] s. suriadi, m.t. wynn, c. ouyang, a.h.m. ter hofstede, and n.j. van
dijk. understanding process behaviours in a large insurance company in
australia: a case study. in caise , pages 449{464. springer, 2013.
[18] n.r.t.p. van beest, m. dumas, l. garc a-ba~ nuelos, and m. la rosa. log
delta analysis: interpretable dierencing of business process event logs.
inbpm , pages 386{405, 2015.
[19] w.m.p. van der aalst. process mining - data science in action . springer,
2016.
[20] w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workow
mining: discovering process models from event logs. ieee , 16(9):1128{
1142, 2004.
[21] s. van der spoel, m. van keulen, and c. amrit. process prediction in noisy
data sets: a case study in a dutch hospital. in simpda , pages 60{83,
2012.
[22] j.m.e.m. van der werf, b.f. van dongen, c.a.j. hurkens, and a. sere-
brenik. process discovery using integer linear programming. fundam.
inform. , 94(3-4):387{412, 2009.
[23] m.l. van eck, x. lu, s.j.j. leemans, and w.m.p. van der aalst. pm2: a
process mining project methodology. in caise , pages 297{313. springer,
2015.
[24] h.m.w. verbeek, j.c.a.m. buijs, b.f. van dongen, and w.m.p. van
der aalst. xes, xesame, and prom 6. in caise forum , pages 60{75.
springer, 2010.
[25] z. zhou, y. wang, and l. li. process mining based modeling and analysis
of workows in clinical care - a case study in a chicago outpatient
clinic. in icnsc , pages 590{595. ieee, 2014.