single-entry single-exit decomposed conformance checking
jorge munoz-gamaa, josep carmonaa, wil m.p. van der aalstb,c
auniversitat politecnica de catalunya, barcelona (spain)
beindhoven university of technology, eindhoven (the netherlands)
cpais lab, higher school of economics, moscow (russia)
abstract
an exponential growth of event data can be witnessed across all industries. devices connected to the internet (‚Äúin-
ternet of things‚Äù), social interaction, mobile computing, and cloud computing provide new sources of event data and
this trend will continue. the omnipresence of large amounts of event data is an important enabler for process mining.
process mining techniques can be used to discover, monitor and improve real processes by extracting knowledge from
observed behavior. however, unprecedented volumes of event data also provide new challenges with which state-of-
the-art process mining techniques often cannot cope. this paper focuses on ‚Äúconformance checking in the large‚Äù and
presents a novel decomposition technique that partitions larger process models and event logs into smaller parts that
can be analyzed independently. the so-called single-entry single-exit (sese) decomposition not only helps to speed
up conformance checking, but also provides improved diagnostics. the analyst can zoom in on the problematic parts
of the process. importantly, the conditions under which the conformance of the whole can be assessed by verifying the
conformance of the sese parts are described, which enables the decomposition and distribution of large conformance
checking problems. all the techniques have been implemented in prom, and experimental results are provided.
keywords: process mining, conformance checking, decomposition, process diagnosis
1. introduction
in the last decade process mining emerged as a novel
discipline for addressing challenges related to business
process management (bpm) and ‚Äúbig data‚Äù [1]. in-
formation systems (and many other computer-supported
systems) record overwhelming amounts of event data.
these can be seen as the ‚Äúfootprints‚Äù left by the pro-
cess. for example, boeing jet engines may produce up
to 10 terabytes of operational information every 30 min-
utes, and walmart logs may store one million customer
transactions per hour [2].
event logs can be used to conduct three types of pro-
cess mining [1].the Ô¨Årst and most prominent is discov-
ery. a discovery technique takes an event log and pro-
duces a model without using a priori information. for
many organizations it is surprising that existing tech-
niques are indeed able to discover real processes based
only on example behaviors recorded in event logs. the
second type is conformance where an existing process
email addresses: jmunoz@lsi.upc.edu (jorge munoz-gama),
jcarmona@lsi.upc.edu (josep carmona),
w.m.p.v.d.aalst@tue.nl (wil m.p. van der aalst)model is compared with an event log of the same pro-
cess. conformance checking can be used to check if re-
ality, as recorded in the log, conforms to the model and
vice versa. the third type is enhancement where the
idea is to extend or improve an existing process model
using information about the actual process recorded in
an event log. whereas conformance checking measures
alignment between model and reality, this third type of
process mining aims to change or extend the a priori
model; for instance, using timestamps in the event log,
one can extend the model to show bottlenecks, service
levels, throughput times, and frequencies.
in conformance checking, the seminal work by roz-
inat et al. [3] was the Ô¨Årst in formalizing the problem
and enumerating the four dimensions to consider for de-
termining the adequacy of a model in describing a log:
Ô¨Åtness ,precision ,generalization andsimplicity . in this
paper, we will focus on evaluating Ô¨Åtness, that measures
the capability of a model in reproducing the traces of a
log. as modeling notation, we will focus on the petri net
formalism [4], although most of the conclusions of the
paper can be generalized to similar process formalisms
[5].
preprint submitted to information systems february 10, 2014in real-life situations, event logs often do not Ô¨Åt its
corresponding models, i.e., some log traces cannot be
fully reproduced in the model. these non-Ô¨Åtting sit-
uations should be communicated to the stakeholders,
in order to take decisions on the process object of
study. however, in reality process models can be non-
deterministic, which complicates the analysis. non-
determinism may arise when the model contains silent
orduplicate activities, which is often the case in prac-
tice. moreover, the presence of noise in the log (rare or
infrequent behavior that has been recorded in the log)
complicates even more the algorithmic detection of non-
Ô¨Åtting situations. due to this, the initial proposal from
rozinat et al. toreplay log traces in a model in order
to assess whether a trace can Ô¨Åt a model has been re-
cently reconsidered, giving rise to the notion of align-
ment . alignment techniques relate execution sequences
of the model and traces in the event log. the tech-
niques can cope with deviations and models with du-
plicate /invisible activities [6, 7, 8]. however, alignment
techniques are extremely challenging from a computa-
tional point of view. traces in the event log need to
be mapped on paths in the model. a model may have
inÔ¨Ånitely many paths and the traces may have an arbi-
trary amount of deviating events. hence, although the
algorithms have demonstrated to be of great value for
undertaking small or medium-sized problem instances
[1, 9], they are often unable to handle problems of in-
dustrial size. we believe that decomposition techniques
are an important means to tackle much large and more
complex process mining problems. therefore, this pa-
per addresses this problem through decomposition and
distribution .
there is a trivial way to decompose the conformance
checking problem. one can simply split the event log
into sublogs such that every trace appears in precisely
one of these sublogs. note that the conformance is still
checked on the whole model. linear speed-ups are pos-
sible using such a simple decomposition. however, the
real complexity is in the size of the model and the num-
ber of di erent activities in the event log. therefore, we
propose a di erent approach. instead of trying to assess
the conformance of the whole event log and the com-
plete petri net, conformance checking is only performed
for selected subprocesses (subnets of the initial petri net
and corresponding sublogs). subprocesses are identi-
Ô¨Åed as subnets of the petri net that have a single-entry
and a single-exit node ( sese ), thus representing an iso-
lated part of the model with a well-deÔ¨Åned interface to
the rest of the net. seses can be e ciently computed
and hierarchically represented in a tree-like manner into
the reÔ¨Åned process structured tree (rpst) [10].experiments (cf. sec.6) show a considerable reduc-
tion (orders of magnitude) in the time required to per-
form Ô¨Åtness checking . moreover the techniques pre-
sented in this paper allow for identifying those subnets
that have Ô¨Åtness problems, allowing the process owner
to focus on the problematic parts of a large model. im-
portantly, we have performed analytical comparisons of
the conformance problem when decomposition is con-
sidered or not, related to the size of the components
and the average length of the log traces. in terms of
complexity, those studies reveal a clear superiority of
the methods proposed in this paper, being more robust
for these important matters (size of the components and
length of log traces). remarkably, this signiÔ¨Åcant com-
plexity alleviation comes without any penalty on the ca-
pability of the method: by applying decomposition tech-
niques conformance checking of the whole can still be
assessed.
the sese decomposition is not only used for e -
ciency reasons. we also use it to provide diagnostics
that help the analyst in localizing conformance prob-
lems. we create a topological structure of seses in or-
der to detect the larger connected components that have
Ô¨Åtness problems. moreover, problematic parts can be
analyzed in isolation. finally, a hierarchical perspec-
tive of the conformance checking problem is presented,
which may open the door for zoom-in zoom-out anal-
ysis, and also focus the analysis of the hierarchy into
particular subprocesses that have common features.
this paper extends and generalizes two recent con-
ference papers [11, 12]. the extensions and generaliza-
tions can be summarized as follows. first, we present
a strategy to compute Ô¨Åtness by adapting a partition-
ing of the rpst in order to satisfy the valid decom-
position requirements from [13]. second, we have ex-
tended the decomposition approach of [12] in order to
deal with silent and duplicate activities. third, di erent
perspectives to the conformance problem are presented
which aim to provide more Ô¨Çexibility during analysis.
three alternatives to the traditional conformance check-
ing practice are proposed: (1) subprocess, (2) hierarchi-
cal and (3) Ô¨Åltered conformance checking. the Ô¨Åltered
conformance checking perspective is based on the initial
one presented in [11], but a new data perspective is pro-
posed in this paper. fourth, we have reimplemented the
initial architecture of [11, 12] in order to address prob-
lems encountered when analyzing large event logs. the
new implementation results in some cases in speed-ups
of orders of magnitude. fifth, we have extended consid-
erably the empirical evaluation from [11, 12], incorpo-
rating studies that relate the performance of the decom-
posed technique with respect to the log trace length and
2the size of the subprocesses.
the paper is structured as follows: sect. 2 intro-
duces preliminaries needed in the remainder. in sect. 3
the sese-decomposition is presented formally. sec-
tion 4 describes the high-level use of the rpst structure
for diagnostics of conformance checking problems, by
means of a topology of sese components. various ap-
plications of the decomposition technique are presented
in sect. 5. section 6 presents the experimental evalua-
tion of the techniques described in this paper. related
work is discussed in sect. 7. section 8 concludes the
paper.
2. preliminaries
2.1. mathematical preliminaries
deÔ¨Ånition 1 (multisets) given a set x, a multiset m of
x is a mapping m :x!n.b(x)denotes the set of all
multisets over x.
multisets can be represented in vector format, i.e.,
[x3;y;z2] is the multiset that has three occurrences of x,
one of yand two occurrences of z.m1m2ifm1(x)
m2(x) for all x2x. (domains are extended if needed.)
for example, [ y;z][x3;y;z2] and [ y2][x3;y;z2].
the di erence ( m1 m2) and union ( m1+m2) are de-
Ô¨Åned as usual. for example, [ x3;y;z2] [y;z]=[x3;z].
deÔ¨Ånition 2 (projection) let x be a set and q x
one of its subsets. qdenotes the projection of 2w
on q, e.g., aabc fa;cg=aac. the projection can also be
applied to multisets, e.g., [x3;y;z2]fx;yg=[x3;y].
2.2. petri nets and logs
for a deeper introduction of petri nets the reader is
refereed to [4].
deÔ¨Ånition 3 (petri net, workÔ¨Çow net) a petri net
is a tuple pn =(p;t;a), being p the set of places,
t the set of transitions, where p \t=;, and
a(pt)[(tp)the Ô¨Çow relation. for a node n
(place or transition) of a petri net, n (n) is the prede-
cessor (successor) set of n in a.
a workÔ¨Çow net wf-net =(p;t;a;start;end)is a par-
ticular type of petri net where the net has one source
place ‚Äô start‚Äô and one sink place ‚Äô end‚Äô, and all the other
nodes are in a path between them.
amarking in a petri net deÔ¨Ånes the global state,
which is distributed among its places. formally:deÔ¨Ånition 4 (marking, firability) let pn =(p;t;a)
be a petri net. a marking m is a multiset of places, i.e.,
m2b(p). a transition t2t is enabled in a marking
m itm.firing transition t in m results in a new
marking m0=m t+t, i.e., tokens are removed from
t and added to t. a marking m0isreachable from
m if there is a sequence of Ô¨Årings =t1t2:::tnthat
transforms m into m0, denoted by m [im0.
deÔ¨Ånition 5 (system net) a system net is a tuple sn =
(pn;mini;mÔ¨Ån), where pn is a petri net and m ini, m Ô¨Ån
deÔ¨Åne the initial and Ô¨Ånal marking of the net, respec-
tively.
a system net deÔ¨Ånes a set of sequences, each one
starting from the initial marking and ending in the Ô¨Ånal
marking.
deÔ¨Ånition 6 (full firing sequences, boundedness)
let sn =(pn;mini;mÔ¨Ån)be a system net. the set
fj(pn;mini)[i(pn;mÔ¨Ån)gdenotes all the full Ô¨Åring
sequences of sn. a petri net is said to be k-bounded
or simply bounded if all the possible markings in the set
of full Ô¨Åring sequences are bounded by k (e.g., no place
contains more than k tokens). when k is 1the petri net
is called safe.
an event log is a collection of traces, where a trace
may appear more than once. formally:
deÔ¨Ånition 7 (trace, event log) let tbe a trace . an
event log l2b(t)is a multiset of traces.
in this simple deÔ¨Ånition of an event log, an event
refers to just an activity. often event logs store addi-
tional information about events, e.g., resource, times-
tamp, or additional data elements. in this paper, we ab-
stract from such information. however, the results pre-
sented can easily be extended to event logs containing
additional information.
process discovery is concerned with learning a pro-
cess model (e.g., a petri net) from an event log. the fo-
cus of this paper is however on conformance checking,
i.e., comparing observed and modeled behavior. there
are four quality dimensions for comparing model and
log: (1) replay Ô¨Åtness , (2) simplicity , (3) precision , and
(4)generalization [1]. a model with good replay Ô¨Åt-
ness allows for most of the behavior seen in the event
log. a model has a perfect Ô¨Åtness if all traces in the log
can be replayed by the model from beginning to end.
thesimplest model that can explain the behavior seen
in the log is the best model. this principle is known
as occam‚Äôs razor. fitness and simplicity alone are not
3sucient to judge the quality of a discovered process
model. for example, it is very easy to construct an ex-
tremely simple petri net (‚ÄúÔ¨Çower model‚Äù) that is able to
replay all traces in an event log (but also any other event
log referring to the same set of activities). similarly, it
is undesirable to have a model that only allows for the
exact behavior seen in the event log. remember that
the log contains only example behavior and that many
traces that are possible may not have been seen yet. a
model is precise if it does not allow for ‚Äútoo much‚Äù be-
havior. clearly, the ‚ÄúÔ¨Çower model‚Äù lacks precision. a
model that is not precise is ‚ÄúunderÔ¨Åtting‚Äù[14]. underÔ¨Åt-
ting is the problem that the model over-generalizes the
example behavior in the log (i.e., the model allows for
behaviors very di erent from what was seen in the log).
at the same time, the model should generalize and not
restrict behavior to just the examples seen in the log.
a model that does not generalize is ‚ÄúoverÔ¨Åtting‚Äù [15].
overÔ¨Åtting is the problem that a very speciÔ¨Åc model is
generated whereas it is obvious that the log only holds
example behavior (i.e., the model explains the particu-
lar sample log, but there is a high probability that the
model is unable to explain the next batch of cases).
in the remainder, we will focus on replay Ô¨Åtness
which we will simply refer to as Ô¨Åtness . the follow-
ing deÔ¨Ånition states whether a trace or log Ô¨Åts the model
or not.
deÔ¨Ånition 8 (fitting trace) a trace2tÔ¨Åts sn =
(pn;mini;mÔ¨Ån)if(pn;mini)[i(pn;mÔ¨Ån), i.e.,corre-
sponds to a full Ô¨Åring sequence of sn. an event log
l2 b (t)Ô¨Åts sn if (pn;mini)[i(pn;mÔ¨Ån)for all
2l.
note that di erent metrics to quantify Ô¨Åtness are pos-
sible. for example, we can look at the percentage of
Ô¨Åtting traces. using alignments we can go one step fur-
ther and look at the event level. finally, although in
this paper we focus on Ô¨Åtness, other dimensions such
as precision [7, 8] and generalization [15] can be con-
sidered at the level of subnets. however, the computa-
tion of the overall precision and generalization in a de-
composed way will require revisiting both dimensions
because the current deÔ¨Ånitions are deÔ¨Åned globally and
cannot be reformulated in a decomposed manner easily.
2.3. sese and rpst
the intuitive idea behind the decomposition tech-
nique in the following section is to Ô¨Ånd subgraphs that
have a simple interface with respect to the rest of the
net. the following set of deÔ¨Ånitions formalize the ideaofsingle-entry single-exit (sese) subnet and the cor-
responding decomposition. the underlying theory dates
back to the seminal work of hopcroft and tarjan in the
seventies [16], but recent studies have made consider-
able progress into making the algorithms practical when
applied to process models [17]. we start deÔ¨Åning the
graph structure used for decomposing a process model:
deÔ¨Ånition 9 (workÔ¨Çow graph) given a petri net
pn=(p;t;a), we deÔ¨Åne its workÔ¨Çow graph simply as
the directed graph g =(v;e)where no distinctions are
made between places and transitions, i.e., v =p[t
and e =a.
in the remainder, the following context is assumed:
letgbe a workÔ¨Çow graph of a given wf-net, and let
gs=(vs;s) be a connected subgraph of gformed by
a set of edges sand the vertices vs= (s) induced by
s.1
deÔ¨Ånition 10 (subnet nodes [10]) a node x2vsisin-
terior with respect to g siit is connected only to nodes
in v s; otherwise x is a boundary node of g s. a bound-
ary node y of g sis an entry of g sino incoming edge
of y belongs to s or if all outgoing edges of y belong
to s . a boundary node y of g sis an exitof g sino
outgoing edge of y belongs to s or if all incoming edges
of y belong to s .
as next deÔ¨Ånition formalizes, a sese is a special
type of subgraph with a very restricted interface with
respect to the rest of the graph:
deÔ¨Ånition 11 (sese [10]) a set of edges se is a
sese (single-exit-single-entry) of graph g =(v;e)
igshas exactly two boundary nodes: one entry and
one exit. a sese is trivial if it is composed of a single
edge. s is a canonical sese of g if it does not partially
overlap with any other sese of g, i.e., given any other
sese s0of g, they are nested (s s0or s0s ) or
they are disjoint (s \s0=;). by deÔ¨Ånition, the source
of a wf-net is an entry to every fragment it belongs to
and the sink of the net is an exit from every fragment it
belongs to.
the decomposition based on canonical seses is a
well studied problem in the literature, and can be com-
puted in linear time. in [18], the authors proposed the
algorithm for constructing the reÔ¨Åned process structure
1(r)=s
(a;b)2rfa;bgis the set of elements referred to by relation
xab.
4(a) workflow net
(b) workflow graph and sese descompositiont1t2
t3t4t5
t6t7
p1p2
p3p4
p5p6 p7 p8
ab
cd
ef
gh
ijk
lm
no ps6
s7s3
s4
s5s s 2s s1s1s
s2s s3sjop a
s4s s5s s6s s7s
bdfhcegikm ln
(c) rpstfigure 1: a wf-net, its workÔ¨Çow graph and the rpst and sese decomposition.
tree (rpst) , i.e., a hierarchical structure containing all
the canonical seses of a model. in [10], the computa-
tion of the rpst is considerably simpliÔ¨Åed and gener-
alized by introducing a pre-processing step that reduces
the implementation e ort considerably.
deÔ¨Ånition 12 (rpst [10]) let g be the workÔ¨Çow
graph of a given wf-net.2thereÔ¨Åned process struc-
tured tree (rpst) of g is the tree composed by the set
of all its canonical seses, such that, the parent of a
canonical sese s is the smallest canonical sese that
contains s . the root of the tree is the entire graph, and
the leaves are the trivial seses. the set of all the nodes
of the tree is denoted as s.
in the remainder of the paper, we will refer to canoni-
cal seses resulting from the rpst decomposition sim-
ply as seses. also note that the seses are deÔ¨Åned as
a set of edges (i.e., s) over the workÔ¨Çow graph (not as
subgraphs, i.e., gs). however, for simplicity and when
the context is clear, we will use the term sese to refer
also to the subgraph induced by those edges. we will
denote as pns=(ps;ts;as) the petri net determined
by the sese s, i.e., pns=(p\(s);t\(s);a\s).
the nodes (either transitions or places) determined by
sare denoted as ns, i.e., ( p[t)\(s).
2.4. running example
conformance checking techniques investigate how
well an event log land a system net snÔ¨Åt together.
note that snmay have been discovered through pro-
cess mining or may have been made by hand. in any
2although the approach presented in this paper can be generalized
to graphs with several sources and sinks, for the sake of clarity in this
paper we restrict to the case with only one source and only one sink
[10].case, it is interesting to compare the observed example
behavior in lwith the potential behavior of sn.
as indicated before there are four quality dimensions
for comparing model and log (Ô¨Åtness, simplicity, preci-
sion, and generalization), but here we focus on Ô¨Åtness.
a model with good Ô¨Åtness allows for most of the be-
havior seen in the event log. we use the model shown
in fig. 2 to illustrate the notion of Ô¨Åtness and the role
of alignments when comparing modeled and observed
behavior.
the model in fig. 2 was inspired by a similar model
presented in [19] and represents the possible situations
to handle claims in a insurance company. in the follow-
ing, we will use the letters in each transition to refer to
the corresponding activity, e.g., arefers to the ‚Äúregister
claim‚Äù event.
consider the following event log
l1=[1=abdfgehmnpqs ;2=abijlmnpqnpqs ].
anoptimal alignment between a log trace and a model
is a pair of traces denoting what is the best way the log
trace can be reproduced by the model. for trace 1of
l1, the optimal alignment is:
abdfgehmnpqs
abdfgehmnpqs
the top row of each alignment corresponds to ‚Äúmoves
in the log‚Äù and the bottom row correspond to ‚Äúmoves in
the model‚Äù. if a move in the model cannot be mimicked
by a move in the log, then a ‚Äú ‚Äù (‚Äúno move‚Äù) appears
in the top row. the symmetric situation (a move in the
log that cannot be mimicked by a move in the model)
can also happen and is denoted analogously. any of the
two aforementioned situations reveal Ô¨Åtness problems
between the model and the log trace. when both log
and model can execute the same activity (in other words,
they move synchronously), it denotes a Ô¨Åtting step be-
tween log and model. since the optimal alignment for
5bde
f
gh
ij
klmn
op
q
s
raregister
claimdecide
high-lowstart high
check
start low
checkhigh insurance check
high medical history check
contract hospital
low insurance check
low medical history checkend high
check
end low
checkstart
notificationprepare
notification
notify
re-notification
need
register
notificationarchive
claim
re-process claimfigure 2: running example: claims in a insurance company.
trace1has only Ô¨Åtting steps, the trace is Ô¨Åtting. an
optimal alignment for trace 2is:
abij lmnp qnpqs
abijklmnpo npqs
this optimal alignment for trace 2has several Ô¨Åt-
ness problems represented by asynchronous moves of
log or model. for instance, when the claim is low,
the model considers it mandatory to check the medi-
cal history, while in reality this step did not happen,
which is manifested in the alignment above by an asyn-
chronous model move in the Ô¨Åfth position of the align-
ment: (;k). on the other hand, the notiÔ¨Åcation cannot
be registered if there are still pending notiÔ¨Åcations: the
asynchronous log move in the eleventh position of the
alignment ( q;) reveals this situation.
in general, costs can be assigned to the di erent types
of misalignments and global or individual Ô¨Åtness val-
ues can be deÔ¨Åned and computed [6]. for the example
above, and assuming that each misalignment has equal
cost (say 1), the Ô¨Åtness of the model with respect to the
log for trace 1is 1:0 (perfect Ô¨Åtness), while the Ô¨Åtness
for trace2is 0:9.
3. decomposing conformance checking using
seses
it is well known that checking conformance of large
logs and models is a challenging problem. the size
of log and model and the complexity of the underlying
process strongly inÔ¨Çuence the time needed to compute
Ô¨Åtness and to create optimal alignments. divide-and-
conquer strategies are a way to address this problem
[11, 12]. as indicated before, we do not just want to
partition the traces in the event log (providing a trivial
way to distribute conformance checking). the poten-
tial gains are much higher if also the model is decom-posed and traces are split into smaller ones. to decom-
pose conformance checking problems, the overall sys-
tem net snis broken down into a collection of subnets
fsn1;sn2;:::snngsuch that the union of these subnets
yields the original system net.
deÔ¨Ånition 13 (decomposition) let sn =(pn;mini;
mÔ¨Ån)be a system net where pn =(p;t;a). d =
fsn1;sn2;:::snngis a decomposition of sn if and only
if:
p=s
1inpi,
t=s
1inti,
a=s
1inaiwhere ai\aj=;for1i<jn.
note that each place or transition can be shared
among di erent subnets, while each arc resides in just
one subnet.
any decomposition that satisÔ¨Åes def. 13 may be con-
sidered for decomposing a conformance problem, e.g.,
subnets containing only one arc, or subnets randomly
grouping distant nodes on the net. however, given
that the ultimate goal of a decomposition is to be able
to diagnose, comprehend and understand conformance
problems, the use of meaningful decompositions is pre-
ferred. in [11] seses fragments were used to decom-
pose conformance: given the structure of a sese where
a unique single entry and a unique single exit exist,
a sese becomes an appropriate unit of decomposi-
tion. intuitively, each sese may represent a subpro-
cess within the main process (i.e., the interior nodes are
not connected with the rest of the net) , and the anal-
ysis of every sese can be performed independently.
the rpst of a net can then be used to select a possi-
ble set of seses forming a decomposition. as it shown
in prop. 1, any transverse cut over the rpst deÔ¨Ånes a
decomposition.
proposition 1 (sese decomposition) let sn =
6(wf-net;mini;mÔ¨Ån)be the system net of the workÔ¨Çow
net wf-net =(p;t;a;start;end). consider the rpst
decomposition of wf-net, where srepresents all the
seses in the rpst. we deÔ¨Åne a transverse-cut over
the rpst as a set of seses dssuch that any
path from the root to a leaf of rpst contains one
and only one sese in d. given a transverse-cut
d=fs1;s2;:::sng, let the decomposition d dbe de-
Ô¨Åned as d d=fsns1;sns2;:::snsng, where snsi=
(pnsi;minipsi;mÔ¨Ånpsi), i.e., the petri net determined
by the sese s i, and the projection of the initial and Ô¨Å-
nal markings on the places of the subnet. the decompo-
sition d dderived from the seses satisÔ¨Åes the deÔ¨Ånition
of decomposition given in def. 13
proof. by deÔ¨Ånition of rpst, the arcs of each sese
in the rpst are contained in one, and only one, of
its children (unless it is a trivial sese). therefore, any
transverse-cut set of seses contains all the arcs, where
each arc only appears in only one sese. 2
proposition 2 (a sese decomposition from rpst
exists) given any rpst, a decomposition always exists.
proof. given any rpst, the root (i.e., the whole net)
deÔ¨Ånes a decomposition. in addition, the set of all the
leaves (i.e., the trivial seses with only one arc) also
deÔ¨Ånes a decomposition. 2
as it is claimed in prop. 2, the overall net is, by def-
inition, a decomposition by itself. but it is obvious to
see that this trivial way of decomposition does not al-
leviate the initial conformance problem. on the other
hand, a decomposition formed only by trivial seses
will produce meaningless components, and at the same
time, the posterior analysis will have to deal with the
analysis overhead produced by the creation of the nu-
merous components. a decomposition which lays in
between the aforementioned extremes seems more in-
teresting from the practical point of view, i.e., to gen-
erate components large enough to become meaningful
subprocesses, but whose size can be handled in prac-
tice. hence, the algorithm proposed in alg. 1 can gen-
erate a decomposition which limits the maximum size
of each component to kin order to control the size and
complexity of individual components.
algorithm 1 shows how to compute a k-
decomposition, for any ksuch that 1k jaj
(wherejajstands for the number of arcs of the overall
net). the algorithm keeps a set of nodes that conform
the decomposition ( d) and a set of nodes to consider
(v). initially vcontains the root of the rpst, i.e.,
the overall net. then, the algorithm checks, for eachalgorithm 1 k-decomposition algorithm
procedure k-dec(rpst, k)
v=froot(rps t )g
d=;
while v,;do
v pop(v)
ifjv:arcs()jkthen d=d[fvg
elsev=v[fchildren (v)g
return d
node vto consider, if vsatisÔ¨Åes the kproperty, i.e., the
number of arcs of sese vis less or equal than k. if
this is the case, vis included in the decomposition. if
not, it discards vand includes the rpst children of v
into the nodes to consider. note that, given any rpst,
ak-decomposition always exists, i.e., in worst case, the
decomposition formed by all the leaves of the rpst
will satisfy the deÔ¨Ånition. the algorithm proposed has
linear complexity with respect to the size of the rpst,
and termination is guaranteed by the fact that the size
of the component is reduced in every iteration.
a sese is a component that only interfaces with the
rest of the net through the single entry and single exit
boundary nodes, which may be shared among di erent
components. the rest of nodes of a sese (i.e., the inte-
rior nodes) have no connection with other components.
given that the sese computation is performed over the
workÔ¨Çow graph (i.e., where there is no distinction be-
tween places and transitions), we distinguish two possi-
ble cases for the boundary nodes: transition boundary
andplace boundary .
the transition boundary case occurs when the node
determined to be the entry or the exit of a sese is a
transition. figure 3 shows an example of a transition
boundary. in the example, the overall net is decom-
posed into two subnets that correspond to the seses s1
ands2, being dthe boundary transition shared between
them.
as it is proven in [13], a transition boundary de-
composition represents no problem from a conformance
point of view, i.e., given a decomposition with only tran-
sition boundaries, a log trace Ô¨Åts the overall net if and
only if it Ô¨Åts all the subnets. the reason for that is
that when a transition is shared among subnets, the la-
bel of the transition is used to synchronize the subnets
that contain that transition on their boundaries, ensur-
ing that the decisions on model‚Äôs ability to reproduce
that label are done jointly. consider the decomposition
dd=fsns1;sns2gfrom the example of fig. 3, where
sns1=(pns1;[start ];[]) and sns2=(pns2;[];[end])
7(a) original model
(b) decompositionab
cs1
de
fgs2
ab
cs1
d
de
fgs2start
start
endend
(c) log tracesœÉ1abcddefg=
œÉ1s1abcdd=
œÉ1s2ddefg=
œÉ2abcefg=
œÉ2s1abc=
œÉ2s2efg=figure 3: example of decomposition with transition boundary.
are the systems nets derived from the seses s1ands2.
consider the trace 1=abcddefg shown in fig. 3c.
such trace does not Ô¨Åt the overall net due to the dou-
bled. the projection of that trace on sns1andsns2
results in1ts1=abcdd and1ts2=dde f g respec-
tively (cf. fig. 3c). note that, although 1ts2Ô¨Åtssns2
(onsns2, the preset of dis empty hence it can Ô¨Åre more
than once), 1ts1does not Ô¨Åt sns1. hence, the trace
1that does not Ô¨Åt the overall net, does not Ô¨Åt all the
subnets (at least there is one that is not Ô¨Åtting). a simi-
lar situation happens with the trace 2=abcefg (where
nodappears), i.e., trace 2does not Ô¨Åt the overall net,
hence2ts1does not Ô¨Åt sns1or2ts2does not Ô¨Åt
sns2. in the latter example, actually both do not Ô¨Åt.
ab
cd
ef
p
ab
cp
d
ef
ps1s2
s1
s2(a) original model
(b) decompositionstart
start
endend
(c) log tracesœÉ1abcdef=
œÉ1s1abc=
œÉ1s2def=
œÉ2abdecf=
œÉ2s1abc=
œÉ2s2def=
figure 4: example of decomposition with place boundary.
on the other hand, the case of place boundary is dif-
ferent. when the boundary (entry or exit) is a place, it is
shared among two or more subnets. however, the arcs
connected to the place (the ones in charge of produc-ing and consuming tokens) are split among the subnets.
this makes the place unable to synchronize, and there-
fore, it is impossible to analyze the di erent subnets
in isolation. the example in fig. 4 reÔ¨Çects this situa-
tion. the original net is decomposed into two subnets,
dd=fsns1;sns2g, corresponding with the seses s1
ands2, and being pthe boundary place shared by both
subnets. it can be seen that the arcs that produce to-
kens in pand the ones that consume tokens from pare
distributed into di erent subnets. consider now the log
traces1=abcdef and2=abdecf of fig. 4. while
1Ô¨Åts the overall net, 2does not. however, the pro-
jections of both traces on ts1andts2are the same (cf.
fig. 4). this problem materializes when we analyze the
subnets. firstly, given that any arc that produces tokens
inpis contained in pns1, we need to consider an initial
marking for sns2dierent than [] (otherwise, the sub-
net would be deadlocked initially). if we consider the
initial marking [ p],1ts2does not Ô¨Åts sns2. there-
fore the Ô¨Åtness correctness is not preserved, i.e., a trace
that Ô¨Åts the overall net like 1must Ô¨Åt all the subnets.
on the other hand, if we consider the initial marking
with two (or more) tokens on p(i.e., [ p2]),2ts2Ô¨Åts
sns2(similarly,2ts1Ô¨Åtssns1). however 2is a non-
Ô¨Åtting trace of the overall net, and consequently, it must
not Ô¨Åt all the subnets. therefore, when the decomposi-
tion contains place boundaries, the preservation of the
Ô¨Åtness correctness is not guaranteed.
in [13] the deÔ¨Ånition of decomposition is revisited to
propose the so called valid decomposition , i.e., a de-
composition that only shares transitions (but not places
nor arcs).
deÔ¨Ånition 14 (valid decomposition [13]) let sn =
(pn;mini;mÔ¨Ån)be a system net where pn =(p;t;a).
d=fsn1;sn2;:::snngis avalid decomposition of sn
if and only if:
t=s
1inti,
p=s
1inpiwhere pi\pj=;for1i<jn,
a=s
1inaiwhere ai\aj=;for1i<jn.
in [13, theorem 2] it is proven that all valid decom-
position preserves the Ô¨Åtting correctness, i.e., a log is
Ô¨Åtting a system net if and only if Ô¨Åts all the subnets.
as has been illustrated in the previous examples, a
decomposition based directly on seses is not necessar-
ily a valid decomposition, i.e., boundary places may be
shared among subnets. however, in the remainder of
this section an approach to transform a sese decom-
position into a valid decomposition is presented, which
tries to preserve the underlying semantics behind the
sese decomposition. this technique is called bridging ,
and consists of: (1) transforming each place boundary
8found into a transition boundary (i.e., boundary place
is removed) and (2) creating explicit subnets (called
bridges ) for each boundary place. the bridges contain
all the transitions connected with the boundary place,
and they are in charge of keeping the place synchro-
nized among subnets. in addition, the boundary places
together with the arcs connected to them are removed
from the original subnets. formally:
deÔ¨Ånition 15 (bridging a sese decomposition)
letd=fs1;:::sngbe sese decomposition of the
wf-net (p;t;a;start;end). let i d=fi1;:::; ingand
od=fo1;:::; ongbe the set of all entry and exit nodes
of the seses in d. b=fp1;:::; pkg=((ip[op)\
p)nfstart;endg=(ip\op)\p is the set of bound-
ary places, i.e., entry and exit nodes of the seses that
are places but not the source or sink place of the wf-
net wn. the decomposition after applying bridging
d0=fs0
1;:::s0
n;b1:::bkgofdis constructed as fol-
lows:
for all 1in: s0
i=f(x;y)2sijfx;yg\b=;g
(boundary places are removed from the seses).
for1jk: b j=f(x;y)2ajpj2fx;ygg
(bridges are added).
dd0=fsns0
1;:::sns0
n;snb1:::snbkgrepresents the
decomposition constructed from d0.
figure 5 illustrates the e ects of the bridging on the
example previously shown in fig. 4. in this case, the
boundary place p(and its arcs) are removed from s1
ands2, and a bridge b1is created. note that now, the
transitions connected to p(i.e., b,c,dande) are shared
(instead of p), keeping the synchronization among com-
ponents, and making dd0a valid decomposition.
proposition 3 shows that the decomposition derived
from applying sese decomposition and then bridging
results in a valid decomposition, according to def. 14.
proposition 3 (bridging results in valid decomposi-
tion)
letd0=fs0
1;:::s0
n;b1:::bkgbe obtained from a
sese decomposition after applying bridging. the de-
composition d d0=fsns0
1;:::sns0
n;snb1:::snbkgis a
valid decomposition according to def. 14.
proof. by construction, a sese decomposition only
shares transitions and places. after applying the bridg-
ing, all the shared places are removed, creating explicit
components with only one instance of these places. 2
ab
cd
ef
p
ab
cp
d
ef
p
ab
c
d
efb
cd
eps1 s2
s1
s2
s'1
s'2b1(a) original model
(c) decomposition and bridging(b) decompositionend
end
endstartstartstartfigure 5: example of decomposition with bridging.
moreover, given that the bridging produces a valid
decomposition, it also preserves the property that a trace
in the log Ô¨Åts the overall process model if and only
if each subtrace Ô¨Åts the corresponding process frag-
ment. hence, Ô¨Åtness checking can be decomposed using
seses and bridges.
proposition 4 (fitness checking can be decom-
posed) let l be a log and sn =(wf-net;mini;mÔ¨Ån)
be a system net where wf-net is a workÔ¨Çow net. let
dd0=fsn1;sn2;:::snngbe a valid decomposition re-
sulting of the application of the sese decomposition
and bridging over wf-net. let sni=(pni;mi
ini;mi
Ô¨Ån),
where pni=(pi;ti;ai).
a trace 2 l Ô¨Åts sn (i.e.,
(wf-net;mini)[i(wf-net;mÔ¨Ån)) if and only if
it Ô¨Åts all the parts, i.e., for all sni2dd0,
(pni;mi
ini)[tii(pni;mi
Ô¨Ån).
proof. special case of the more general theorem 2 in
[13]. if the overall trace Ô¨Åtss n, then each of the pro-
9h
lm
a
sn
p
ij
klbde
f
gh
q
r sop
qmn
o
b
ras'1d
i b1
b6 s'6b2
b3s'2
s'3s'4
b4
b5figure 6: components resulting from 15-decomposition and bridging for the running example of fig. 2.
jected traces tiÔ¨Åts the corresponding subnet. if this is
not the case, then at least there exist one projected trace
tithat does not Ô¨Åt. but this is impossible because, by
construction, each subnet is a relaxation of the behavior
of the overall net. if the projected traces tiÔ¨Åt the
corresponding subnets, then these traces can be stitched
back into a trace that Ô¨Åts s n. 2
going back to the running example of this paper
(fig. 2), fig. 6 shows the sese decomposition using
akof 15. let us show how the Ô¨Åtness problems are now
identiÔ¨Åed in a decomposed manner. for that, we will
use the trace 2=abijlmnpqnpqs from the log l1in
sect. 2.4. given 2and each one of the seses provided
in fig. 6, the only ones that reveal Ô¨Åtness anomalies are
s0
3,b4andb6(for the other components we can Ô¨Ånd
perfect alignments when projecting 2to the activities
of the component). the alignment for s0
3is:
ij l
ijkl
which reveals that the mandatory check of the medical
history is missing in the log. analogously, the align-
ment for b4is:
mn n
mnon
that identiÔ¨Åes the explicit need for notifying again the
client, an action missing in the log but required by the
model. finally, the alignment for b6:
qqs
 qs
reveals another Ô¨Åtness problem for trace 2: the system
has stored in the log an early registration of the notiÔ¨Å-
cation which was not meant at that point in time, since
later notiÔ¨Åcations were sent and according to the model,the registration is only expected to be done at the end of
the case.
using prop. 4, we can infer that the fact that some
components in the decomposition identify Ô¨Åtness prob-
lems implies that the whole model does not Ô¨Åt log l1.
3.1. decomposing with invisible /duplicates
so far, the approach presented in this paper was as-
suming that all the petri net transitions were associated
with a unique single activity, i.e., a transition could be
unambiguously identiÔ¨Åed by its label. in this section we
lift this assumption in order to consider invisible and du-
plicate transitions. an invisible transition is a transition
without activity associated, e.g., transitions included for
routing purposes. duplicate transitions are transitions
with the same activity associated. for example, con-
sider the net of fig.7, which is a slight variation of the
running example of fig. 2. this model contains an in-
visible transition (represented in black) used to skipthe
execution of contract hospital , i.e., now contract hos-
pital is optional. moreover, the new model does not
distinguishes between high insurance check andlow in-
surance check , but the same action insurance check is
modeled in two di erent parts of the model, i.e., is a
duplicate activity.
the deÔ¨Ånition of petri net presented in the preliminar-
ies is now adapted to include the possibility of invisible
and duplicate transitions.
deÔ¨Ånition 16 (labeled petri net) a labeled petri net
pn=(p;t;a;l)is a petri net (p;t;a)with labeling
function l2t9uawhereuais some universe of
activity labels. if a transition t <dom(l), it is called in-
visible. t v(pn)=dom(l)is the set of visible transitions
in pn. tu
v(pn)=ft2tv(pn)j8t02tv(pn)l(t)=l(t0))
t=t0gis the set of unique visible transitions in pn (i.e.,
there are no other transitions having the same visible
label).
10h
lm
a
sn
p
ie
klbde
f
gh
q
r sop
qmn
o
b
ras'1d
i b1
b6 s'4b2
b3s'2
s'3
b4
b5bde
f
gh
ie
klmn
op
q
s
raregister
claimdecide
high-lowstart high
check
start low
checkinsurance check
high medical history check
contract hospital
insurance check
low medical history checkend high
check
end low
checkstart
notificationprepare
notification
notify
re-notification
need
register
notificationarchive
claim
re-process claimfigure 7: variant of the running example of fig. 2 including invisible and duplicates (top), and its corresponding decomposition (bottom).
as it has been illustrated previously in this paper,
when a net is decomposed, the labels of the transitions
are used to synchronize and preserve the Ô¨Åtness prop-
erties. however, sharing invisible and duplicate tran-
sitions among subnets generates ambiguity invalidating
this synchronization. thus, the deÔ¨Ånition of valid de-
composition presented in def.14 is reÔ¨Åned to consider
invisible and duplicates, i.e., only unique visible transi-
tions can be shared among subnets.
deÔ¨Ånition 17 (valid decomposition with invisible
and duplicates[13]) let sn =(pn;mini;mÔ¨Ån)be
a system net where pn =(p;t;a;l). d =
fsn1;sn2;:::snngis avalid decomposition of sn if and
only if:
sni=(pni;mi
ini;mi
Ô¨Ån)is a system net with pni=
(pi;ti;ai;li)for all 1in,
li=ltifor all 1in,
pi\pj=;for1i<jn,
ti\tjtu
v(sn)for1i<jn, and
sn=s
1insni.
letsn=(pn;mini;mÔ¨Ån) with n=(p;t;a;l)
be a system net with valid decomposition d=fsn1;sn2;:::; snng. we can observe the following
properties:
- each place appears in precisely one of the subnets,
i.e., for any p2p:jf1injp2pigj=1,
- each invisible transition appears in precisely one of
the subnets, i.e., for any t2tntv(sn):jf1inj
t2tigj=1,
- visible transitions that do not have a unique label
(i.e., there are multiple transitions with the same la-
bel) appear in precisely one of the subnets, i.e., for
anyt2tv(sn)ntu
v(sn):jf1injt2tigj=1,
- visible transitions having a unique label may appear
in multiple subnets, i.e., for any t2tu
v(sn):jf1
injt2tigj1, and
- each edge appears in precisely one of the subnets,
i.e., for any ( x;y)2a:jf1inj(x;y)2aigj=1.
in order to instantiate a decomposition comply-
ing with this new deÔ¨Ånition of valid decomposition,
algorithm1 needs to be reÔ¨Åned (cf. alg. 2).
algorithm 2 checks if considering the children of a
sese swill violate the deÔ¨Ånition of valid decomposi-
tion in def.17. the three conditions need to be satisÔ¨Åed:
- transitions shared ( t) between any subset of seses
11algorithm 2 reÔ¨Åned k-decomposition algorithm
function k-dec(rpst, k)
v=froot(rps t )g
d=;
while v,;do
v pop(v)
ifjv:arcs()jkornotdecomposable (v)then
d=d[fvg
elsev=v[fchildren (v)g
return d
function decomposable (s)
fs1;:::sng children (s)
t shared transitions in fs1;:::sng
p shared places infs1;:::sng
tp transitions connected with p
ift\tu
v,tthen return false
else if tp\tu
v,tthen return false
else if same label in di erentfs1;:::sngthen
return false
else return true
fs1;:::sngmust be unique visible transitions ( tu
v).
- places shared ( p) between any subset of seses
fs1;:::sngwill be bridged according to def. 15.
therefore, transitions connected with the places
shared ( p) between any subset of fs1;:::sngmust be
unique visible transitions ( tu
v), in order to avoid be
duplicated boundary transitions after the bridging.
- transitions with the same label must belong to the
same vi.
the main di erence between the original k-
decomposition algorithm presented previously and alg.
2 is that the latter checks if considering the children
of sese vfor the decomposition dwill violate the
valid decomposition deÔ¨Ånition (def.17). this additional
checking makes the algorithm quadratic in the number
of edges, although our experiments show no noticeable
increase in computation time. notice that by deÔ¨Åni-
tion, if the children fs1;:::sngofvviolate the deÔ¨Ånition,
considering further descendants of vwill also violate
the deÔ¨Ånition. therefore, when the algorithm checks
that the sese must not be decomposed, it includes it
into the decomposition d. as a result, algorithm 2
does not guarantee the kproperty, i.e., some compo-
nents may have more than karcs. for instance, con-
sider the subnets resulting of a 15-decomposition and
bridging shown in fig.7. unlike fig.6, here when the
algorithm tries to decompose the sese s2, it detectsthan this will result in splitting the duplicate e, and thus
it must consider s2, even if the number of arcs of s2is
greater 153. notice that some worst case scenarios exist
for alg. 2: consider the example of fig.8. in this case,
the presence of invisible transitions in the model bound-
aries makes it impossible for the algorithm decompose
more that the root s1, and therefore, the resulting de-
composition will be the overall net. the e ect of those
cases can be alleviated by pre-processing the model and
the log before applying the decomposed conformance.
(a) workÔ¨Çow nett1 t7a bs2ss1 s1s
s2sb a
(b) rpst......
figure 8: example of worst case scenario for the k-decomposition
with invisible /duplicates.
4. topology of a decomposition
a valid decomposition is a collection of subnets that
may be related to each other through the sharing of tran-
sitions, i.e., two subnets are related if they share a transi-
tion. the topology of a valid decomposition is an undi-
rected graph where the vertices denote subnets and the
edges denote the sharing of transitions.
deÔ¨Ånition 18 (topology of a decomposition) let d =
fsn1;sn2;:::snngbe a valid decomposition, where
sni=(pni;mi
ini;mi
Ô¨Ån)and pni=(pi;ti;ai). the
topology of decomposition d is deÔ¨Åned as the undi-
rected graph t d=(d;c)such that two components
are connected if they share any transition, i.e., c =
ffsni;snjgj1i<jn^ti\tj,;g.
in the general deÔ¨Ånition of topology over a valid de-
composition the relations remain undirected, i.e., two
subnets sharing the same transition are connected by
an undirected edge. however, in the speciÔ¨Åc case of a
valid decomposition derived from seses, this deÔ¨Ånition
can be extended to include the concept of direction: the
transition being the exit of the sese is considered the
3notice that, after the bridging process, a fragment may lose its
sese structure, e.g., the entry and exit places of s2are removed when
it becomes s0
2due to the bridges b2andb3. in spite of this, the
decomposition obtained still satisÔ¨Åes def. 17. moreover, although the
entry or exit place has been removed explicitly from the graph, the
fragment still represents its corresponding subprocesses.
12(a) decomposition and bridging
(b) topological grapht4t5
t6 p6t9
p9t7
t8
(c) topology enhanced with fitness for the trace t1 t3 t4 t5 t7 t7 t9s12s
3sb1s5
s62bs8 s12s
3sb1s5
s62bs8'
'''
'' '
'' '
''t1
p1t1t2
t4p2 p4
t1
t3t4
p3 p5t5
p7t7
t6
p8t8t9
p10s1'2s'
3s'b1s5'
s6'2b
s8'figure 9: example of valid decomposition and its topology
source of the edge, while the entry is the target. bridges
can have multiple entry and exit nodes, but again we
can derive the direction connections among bridges and
seses.
deÔ¨Ånition 19 (topology of a sese decomposition)
letd=fs1;:::sngandd0=fs0
1;:::s0
n;b1;:::bkgbe
a sese decomposition before and after applying bridg-
ing. letfp1;:::; pkgbe the boundary places in d. let
dd0=fsns0
1;:::sns0
n;snb1:::snbkgrepresent the de-
composition constructed from d0. the topology of d d0
is deÔ¨Åned as the directed graph t dd0=(dd0;c)such
that c =f(sns0
i;sns0
j)j1i;jn^(y;x)2
si^(x;z)2sjg[f (sns0
i;snbj)j1in^1
jk^(y;pj)2sig[f(snbj;sns0
i)j1in^1
jk^(pj;y)2sig.
note that the topological graph has as vertices the
nets ind0, but some arcs of this graph (those regard-
ing connection to bridges) are deÔ¨Åned over the original
sese decomposition d, e.g., ( y;pj)2sirefers to an
arc in the original sese and is used to infer a directed
connection from sns0
itosnbj.
one of the features of the topology is to aid in the vi-
sualization of a valid decomposition. for example, let
us consider the valid decomposition in fig. 9 (a slight
modiÔ¨Åcation of the model in fig. 1). the decompo-
sition is the result of applying a 4-decomposition over
the model of fig. 9a (i.e., seses with at most 4 edges:
s0
1;s0
2;s0
3;s0
5;s0
6;s0
8) and followed by the bridging (re-
sulting in two bridges, b1andb2, corresponding withthe two boundary places p6andp9)4. the correspond-
ing topology is shown in fig. 9b.
besides simply showing the connections among sub-
nets, the topology can be enhanced with other informa-
tion about the components and their characteristics. for
instance, bridges can be denoted by circles having dot-
ted borders and seses can be denoted by circles hav-
ing solid borders. moreover, the size of the nodes in
the graph is directly related with the size of the corre-
sponding subnets, i.e., a subnet with many arcs is de-
picted using a larger circle compared to subnets with
fewer arcs. given the Ô¨Ånal goal of this paper (i.e.,
conformance analysis), a particular interesting case is
to enhance the topology with conformance informa-
tion. for example, consider the trace =t1t3t4t5t7t7t9.
when we check Ô¨Åtness in the subnets of decomposition
dd0=fsns0
1;:::sns0
8;snb1;snb2g, we detect the fol-
lowing Ô¨Åtness anomalies: in sns0
2,t4is Ô¨Åred without
Ô¨Åring t2; insns0
5,t7is executed twice, but this requires
the Ô¨Åring of t5also twice; Ô¨Ånally, in the bridge snb2,t7
is Ô¨Åred twice, but t9only once, leaving a token remain-
ing in p9. this information can be used to enhance the
topology of fig. 9b. as shown in fig. 9c the vertices
have problems can be depicted in gray (here s0
2,s0
5and
b2).
although the topology is an important aid for the pro-
cess diagnosis by itself, it can also guide further analy-
4note that the original trivial sese s4that corresponds to the arc
(t4;p6) has disappeared once the bridging has been done, i.e., the arc
is now in b1. the same happens for the original trivial sese s7
corresponding to the arc ( p9;t9).
13sis. for instance, the topological graph enhanced with
conformance information can be used to identify max-
imal process fragments with Ô¨Åtness problems . this al-
lows us to focus on the problematic parts of a model,
discarding the parts without any Ô¨Åtness problems. al-
gorithm 3 describes a procedure that is based on detect-
ing connected components ( cc) on the graph induced by
the non-Ô¨Åtting vertices. first, the topological graph ( td)
is Ô¨Åltered, leaving only non-Ô¨Åtting vertices ( v). then,
the weakly connected components ( cc) are detected:
1) a random node v1is chosen, 2) all nodes fv1;:::vng
weakly connected (i.e., connected vertices without con-
sidering the direction of the edges) with v1are computed
using a depth-Ô¨Åst search exploration and they constitute
a new connected component, and Ô¨Ånally 4) fv1;:::vng
are removed from the graph and the exploration of con-
nected components continues. for each connected com-
ponent, we project the elements of the original net they
refer to. note that this algorithm prioritizes the con-
nectivity among vertices resulting in weakly connected
components. however, alternative versions of the algo-
rithm yielding strongly connected components are pos-
sible. for instance, given the example of fig. 9c, two
connected components are found as shown in fig. 10:
one corresponding to sns0
2and the other to the union of
sns0
5andsnb2.
t5 t9
p6 p9 p7t7
t8t1 t4
p4 p2t2
s52b+2s'
'
figure 10: examples of non-Ô¨Åtting weakly connected components.
s4s2t1 t4
p4 p2t2 t5 t9
p6 p9 p7t7
t8 t8
s52b +b1+ + +'''
figure 11: example of a non-Ô¨Åtting subnet.
the topological graph enhanced with conformance
information can also be used to create one complete
subnet that includes all non-Ô¨Åtting subnets of the de-
composition, i.e., a connected set of vertices vcon-
taining all the non-Ô¨Åtting vertices vnf. algorithm 4 il-
lustrates the heuristic-based approach proposed, based
on the greedy expansion of the largest non-Ô¨Åtting con-
nected components, to compute the complete non-Ô¨Åtting
subnet. initially, vcontains the non-Ô¨Åtting vertices vnf,algorithm 3 non-fitting weakly connected compo-
nents algorithm
function nfwcc (td,v).vis non-Ô¨Åtting vertices
cc=;
remove from td:.graph induced by v
-all arcs c=fx;ygsuch that x;y<v
-all vertices z<v
while tdhas vertices do
v1 select random vertex on td
fv1;:::vng  get vertices weakly connected
with v1using depth-Ô¨Årst search
removefv1;:::vngfrom td
cc=cc[sn
1vi
return cc
andgdenotes the graph induced by v. the goal of the
algorithm is to have all the vertices in vconnected, i.e.
gbe connected. if this is not the case, the algorithm de-
tects the two largest connected components ( c1andc2)
ofg, and then computes the shortest path ( fv1:::vng)
between any vertex in c1and any vertex in c2. finally,
fv1:::vngare included to v, and it is checked again if
the induced graph gis connected. given the example
of fig. 9c, the net resulting (shown in fig. 11) contains
the union of the subnets sns0
2,sns0
4,snb1,sns0
5and
snb2.
algorithm 4 non-fitting subnet algorithm
function nfn(td,vnf).vnfis non-Ô¨Åtting vertices
v vnf
g graph induced by vontd
while gis not connected do
c1 get the 1 stlargest conn. comp. of g
c2 get the 2 ndlargest conn. comp. of g
fv1:::vng shortest path vertex( td;c1;c2)
v=v[fv1:::vng.
g graph induced by vontd
return petri net induced by v
in fig. 12, the topology for the running example is
presented as a screenshot of the tool associated with this
paper. in the Ô¨Ågure, the alignment for the problematic
component 4 ( s0
3in fig. 6) is also shown.
5. multi-level analysis and its applications
thus far the analysis of the conformance was al-
ways performed using a complete decomposition of the
14figure 12: screenshot of the topology for the running example.
model. however, for detailed process diagnosis it is im-
portant to also be able to do a more focused analysis.
this section presents three approaches to achieve this:
(1) stand-alone checking, (2) multi-level analysis, and
(3)Ô¨Åltering.
5.1. stand-alone checking
first we consider the problem of analyzing a selected
subprocess in isolation. clearly, assumptions on the
subprocess and its context must be deÔ¨Åned in order to
perform such an isolated conformance check. the con-
formance results obtained are strongly correlated with
the assumptions considered, and hence the analysis of
the model properties and domain knowledge becomes
an essential part, e.g., whether a place has a bound on
the number of tokens, or the number of activations of
the subprocess within a trace.
let us show an application of the stand-alone check-
ing for the typical case of well-structured process mod-
els, that can easily be modeled using the subclass of
safe workÔ¨Çow nets (for formal details see [11]). given a
sese sobtained from a decomposition, one can apply
the following steps to conduct a local diagnosis of s:
1.workÔ¨Çowing the sese: in order to have a clear
starting and ending point for the subprocess rep-
resented, re-deÔ¨Åne the net derived from s. in other
words, given a sese s, deÔ¨Åne the net derived from
sin terms of a workÔ¨Çow net (cf. def. 3), with a
starting place ( start) and a Ô¨Ånal place ( end). by
construction, a sese has both an entry ( i) and an
exit ( o) node. the start corresponds with iifiis a
place. however, when iis a transition, we deÔ¨Ånestart to be an artiÔ¨Åcial place and we connect it with
i. similarly for endando.
2.initial and final marking: given the workÔ¨Çow-
net from the previous step, determining a plausible
initial marking becomes straightforward, i.e., due
to the safeness assumption of safe workÔ¨Çow nets,
we consider a single token in the start in order to
enable the execution of the subprocess. similarly
for the Ô¨Ånal marking.
3.sese activations: the number of potential activa-
tions of a sese within a case must be determined.
in case it is always one, the sese is left as is.
however, in case it can be executed more than once
(e.g., the sese is inside some loop in the model),
the net in the previous step is short-circuited , using
a silent transition between endandstart. finally,
it can also happen that a sese may be not exe-
cuted in a trace. in this last case, a silent transition
between start andendavoiding the sese content
will be used. determining if a suprocess can be ex-
ecuted several times is a complex matter. in [11],
it is proposed the use of petri net structural theory
(minimal t-invariants [20]) as a best e ort strategy
for estimating repetitive behavior.
5.2. multi-level analysis
in this section we propose to combine the stand-alone
checking just presented with the rpst to achieve a
conformance analysis on a hierarchical manner. rpst
nodes enriched with conformance information enable
the analysis at di erent degrees of granularity and in-
dependence, similar to zooming in and out using on-
line maps. note that, by construction, the root of the
15rpst is the overall net. therefore, any hierarchical
analysis that involves the conformance checking of all
the rpst nodes will require checking conformance on
the original net (plus the checks of the rest of nodes),
i.e., the computation time for a exhaustive hierarchi-
cal analysis will always be, by deÔ¨Ånition, greater than
checking conformance on the overall net. for com-
plex and time-consuming cases, this problem can be al-
leviated by limiting the size of the nodes to check or
by using less expensive replay-based conformance tech-
niques like [3, 21]. the latter techniques use heuristics
in order to deal with unÔ¨Åtting situations.
5.3. filtering
the experiments presented in [11] suggest that there
are three main di erences between manual hierarchi-
cal decomposition and the one provided by the rpst-
based decomposition: (1) analysts prefer to discard
small components , (2) analysts prefer to not consider
similar components , and (3) analysts prefer to have a hi-
erarchy with a limited number of levels . additionally, in
this paper we point out a fourth di erence: (4) analysts
prefer to base hierarchies on other (non-control-Ô¨Çow)
perspectives . in the remainder of this section we pro-
pose Ô¨Åltering techniques to allow for rpst-based de-
compositions closer to hierarchical decompositions pre-
ferred by analysts.
-small components: small components of the rpst
can be removed by Ô¨Åltered using a minimal size
threshold.
-similarity: in order to reduce the redundancy of com-
ponents and the unnecessary growth of the hierarchy,
asimilarity metric between parent-child components
is deÔ¨Åned, together with a threshold that determines
the similarity frontier that will determine when two
components are considered essentially the same. the
proposed metric for estimating the similarity between
a node sand its single child s0is based on two fac-
tors: size and simplicity. the sizefactor is related
with the number of arcs of snot included on s0. the
more arcs shared by both components, the more simi-
lar they are. for instance, considering the component
s1of fig. 13a, all its arcs are included in s2except
two, i.e., s2is in essence s1. therefore, a detailed
conformance diagnosis over s1may be su cient for
understanding both subprocesses. the simplicity fac-
tor refers to the simplicity of part of the parent snot
included on the child s0. when such part deÔ¨Ånes a
simple behavior (e.g., the strictly sequential behavior
ofs3not included in s4, in fig. 13b), the analysis and
understanding of the parent may again be enough. on
(a) similar size among sesess2ss1
s3s4s
(b) high simplicity among sesesfigure 13: example of cases with high similarity between nested
seses.
the other hand, when the behavior not included in s0
contains complex control-Ô¨Çow constructs (e.g., mix-
tures of concurrency and choice) it may be more ad-
visable to analyze both subprocesses. an example
similarity metric is formalized as follows.
deÔ¨Ånition 20 (similarity metric) let s p=
(vp;fp)be an rpst node, and let s c=(vc;fc)
be its only child. let size deÔ¨Åne the di erence
on size between them, i.e., size =jfcj=jfpj. let
fo=fpnfcbe the set of non-intersecting arcs. let
f
obe the arcs in f othat have a source vertex with
only one outgoing edge, and a target vertex with only
one incoming edge, i.e., f
o=f(x;y)2foj(x;v)2
foj=1^ j(w;y)2foj=1g. let simplicity
deÔ¨Åne the simplicity of the non-intersecting arcs,
i.e., simplicity =jf
oj=jfoj. the similarity between
spand s cis the harmonic mean between size and
simplicity:
similarity =2sizesimplicity
size+simplicity
although the similarity evaluation is restricted to
nodes with only one child, our experimental results
show that the reduction achieved on the rpst may
be signiÔ¨Åcant (specially after applying a small nodes
Ô¨Åltering).
-multi-perspective Ô¨Åltering: the Ô¨Åltering presented
until now is based on only structural net properties,
not taking into account other perspectives (e.g., data,
costs, roles, departments). however, there may be
situations where we would like to focus the analysis
only on those subprocesses satisfying certain domain
conditions, e.g., an analyst may want to focus on the
subprocesses involving tasks executed in a particu-
lar department. therefore, we need to support Ô¨Ålter-
ing based on user-requirements and focus the analysis
16figure 14: a screenshot illustrating the Ô¨Åltering by similarity and small components (left), or together with multi-perspective (right).
on the subprocesses involving activities relevant from
the selected viewpoint. such Ô¨Åltering is not limited
to activities and may involve other perspectives (e.g.,
resources, actors, or costs), determining the activities
they are connected with, and using them for Ô¨Åltering.
this type of Ô¨Åltering was not considered in [11].
figure 14 illustrates some of the aforementioned
multi-level analysis with a log that includes informa-
tion on resources. the Ô¨Ågure is a screenshot of the
tool implementing the techniques of this paper. the
Ô¨Ågure shows two windows, representing the result of
applying two di erent Ô¨Ålters to a model for this log.
in the left-hand side of the main window, the Ô¨Åltered
rpst is shown. the parameters used for the Ô¨Åltering
are similarity 0 :8 and considering small components
to be less than 10. the rpst is enhanced with con-
formance information (white rpst nodes have no
conformance problems, and a gradient between green
and red on an rpst node identiÔ¨Åes the severity of
a conformance problem). by clicking in any of the
rpst nodes, the corresponding sese in the net is
highlighted. the user can analyse the replay or the
net used (cf. sect. 5.1) on the tab section in the top of
the Ô¨Ågure for each one of the rpst nodes. finally,
the tool provides the means to focus on particular
transitions of the model that involve some resources.
in the case of the example, the rpst of the left win-
dow is further Ô¨Åltered by only considering the transi-tions under the supervision of the user bob. this is
shown in the small right window.
6. implementation and experiments
in this section we provide experimental results
demonstrating that our decomposition approach pro-
vides signiÔ¨Åcant performance gains and improved diag-
nostics. moreover, we brieÔ¨Çy describe the decomposed
conformance package in prom used to conduct these
experiments.
implementation
the techniques presented in this paper have been
implemented within the prom 6 tool5, and have been
included in the package decomposed conformance .
the new implementation (unlike the one presented in
[11, 12]) is fully compliant with the divide &conquer
package ‚Äì a new initiative for a common frame-
work among all decomposed process mining techniques
within prom, such as [22, 23, 11, 12]. this modular
framework is based on common objects and encourages
and facilitates the reusability of plugins, both for discov-
ery and conformance. compared to the implementation
in [11, 12] the architecture changed dramatically. for
example, arrays of components are used, instead of the
5http://www.promtools.org/prom6/nightly
17020040060080010001200
pram6 prbm6 prcm6 prdm6 prem6 prfm6 prgm6time (s)  
new dc (25) new dc (50) old dc (50) non decomposedn/a n/a 
1667  1386  2743  n/a 
3566  figure 15: comparison of computation time among di erent approaches: the new decomposed conformance checking technique (two variants:
one which limits the maximum size of each component to k=25 and the other to k=50), the old decomposed conformance checking technique
[12], and the approach without decomposition.
sequential creation and processing of the components.
these changes in the implementation had a signiÔ¨Åcant
impact on the performance of the techniques. the de-
composed conformance package in prom supports all
of the decomposition and Ô¨Åltering approaches and the
advanced diagnostics described in this paper.
performance improvements
figure 15 illustrates the performance improvement
achieved by sese-based decomposition and the new
implementation in prom. for this Ô¨Årst analysis we
use the bpm2013 benchmark6that was also used in
[12]. the benchmark contains large models with dif-
ferent levels of Ô¨Åtness (ranging from perfectly Ô¨Åtting as
prbm 6, to models with Ô¨Åtness of 0 :57 ‚Äì like prcm 6),
according to the Ô¨Åtness metric in [6]. figure 15 com-
pares four approaches using seven model-log combina-
tions. the chart includes the results of the new decom-
posed conformance (dc), using a kto decompose of 25
and 50 respectively (cf. alg. 1). in this experiment (and
in the rest of section) we used a conformance based on
alignments for checking the conformance of each com-
ponent [6]. the comparison also includes the results of
the previous implementation (with kof 50) [11, 12], and
the non-decomposed results of [6] (using the same algo-
rithm and parameters as the decomposed approach).
the chart illustrates perfectly the vast di erence, in
computation time, between the approach presented and
the non-decomposed alternative. the non-decomposed
approach remains competitive for the less complex and
highly Ô¨Åtting models (e.g., pram 6 and prbm 6). be-
cause of the component creation overhead the non-
decomposed approach may even be faster for simple
and well-Ô¨Åtting models as noted in [12]. for example,
6http://dx.doi.org/10.4121/uuid:
44c32783-15d0-4dbd-af8a-78b97be3de49forpram 6 and prbm 6 the non-decomposed approach
is faster than the previous implementation presented in
[12]. this is no longer the case for the new decom-
posed implementation which is outperforming the ear-
lier approaches. in those cases where the complexity
and Ô¨Åtness is an issue, the di erence could reach two
orders of magnitude (e.g., from 15 to 3566 seconds in
prem 6). more importantly, the approach proposed in
this paper is able to tackle and provide conformance in-
formation for those cases ( prdm 6,prfm 6 and prgm 6)
where [6] is not able to provide a result within a pe-
riod of 12 hours. notice though, that the goal of both
approaches is slightly di erent: while [6] aims for a
global conformance, the decomposed approach aims for
an optimal conformance of each component. however,
a decomposed approach makes it possible to locate in
a smaller vicinity where the conformance problems are,
get a better understanding of the cause, and eventually
be able to provide and bound conformance properties
in a global manner [13, 11, 12]. the comparison also
shows the signiÔ¨Åcant speedup yield by the new imple-
mentation with respect to the one in [12], due to the new
architecture based on arrays of components.
conformance diagnosis
one of the main contributions presented in this pa-
per is a decomposed strategy to aid on the diagnosis
of conformance problems in large systems, pinpointing
which subprocesses are producing them. in order to il-
lustrate this contribution we provide the Ô¨Åtness results
per component for the running example and the bench-
mark bpm2013 (cf. fig. 16 and fig. 17).
we use a circumference to graphically depict the Ô¨Åt-
ness evaluation of a decomposition by means of a col-
ored gradient for each component. all components of
the decomposition are placed in di erent positions of
18figure 17: fitness results per components for benchmark bpm2013 .
s'1
b1
b2
s'2
s'3
b3 b4s'4b5b6s'6
figure 16: fitness visualization for the running example.
the circumference. let us use the running example of
this paper to illustrate the graphical visualization used.
for each component, a line from the center of the cir-
cumference indicates its Ô¨Åtness. if the line reaches the
perimeter, the Ô¨Åtness is 1 :0 (components s0
1,b1,b2,s0
2,
b3,s0
4,b5,s0
6), while the line for components with Ô¨Åt-
ness anomalies does not reach the perimeter. to show
intuitively the Ô¨Åtness, a color gradient is included in the
circumference: the Ô¨Åtness ranges from red (Ô¨Åtness prob-
lems close to 0 :0) down to green (perfect Ô¨Åtness of 1 :0).
the Ô¨Åtness diagnosis of each one of the models of
benchmark bpm2013 can be understood more easily: for
model pram 6, 7 components have Ô¨Åtness anomalies,
with diverse severity.7on the other hand, all compo-
nents in prbm 6 are perfectly Ô¨Åtting. this contrasts with
prcm 6, where Ô¨Åtness problems are clearly spread over
multiple components. the other of benchmark model-
log combinations have Ô¨Åtness anomalies in just a few
components. this supports the approach taken in this
paper. the diagnostics help to focus on the problematic
parts while at the same time provide performance gains.
performance vs comprehension
the previous experiment included two di erent sizes
for the decomposition: 25 and 50. this second set of ex-
periments is designed to determine the optimal decom-
position size for both perspectives: performance impact
7when no Ô¨Åtness anomalies exist, we do not explicitly label com-
ponents in the visualization.and comprehension of the conformance anomalies de-
tected. the benchmark used ( isbpm2013 ), has been
made publicly available within the 3tu.datacentrum ,
and can be referred and accessed through its doi8. the
isbpm2013 benchmark includes several models, and a
set of logs with di erent properties for each model. the
models have been generated by plg tool [24], and the
logs are the result of the log generator based on the re-
player from [21]. in this experiment we have checked
conformance for di erent values of k. note that, when
thekis the total number of arcs of the model, the de-
composed approach behaves as non-decomposed (i.e.,
there is only one component). figure 18 reÔ¨Çects the
computation time for two of the cases in the bench-
mark ( pr1908-m34-l3-noise andpr1151-m37-l3-noise ),
which summarizes the global tendency for all the mod-
els in the benchmark. the mark representing the mini-
mum time is slightly di erentiated.
the main conclusion one can reach from the experi-
ments is that, from a computational time point of view,
the smaller the better. this is perfectly reÔ¨Çected in
fig. 18. for small values of k(e.g., 1:::20), the re-
sults show a slight overhead because many components
need to be created. however the e ect of this overhead
is negligible in most of the cases. on the other hand,
when the k-decomposition starts to allow larger com-
ponents, the computation time abruptly increases. this
disruption on the computation time is produced by the
hierarchical nature of the rpst, e.g., a decomposition
kinstead of k+1 could lead the selection of nsubpro-
cesses of low complexity instead of the one subprocess
that includes all n. the results and insights based on
these new experiments di er from [12], where ‚Äìdue to
ineciencies of the previous implementation‚Äì the over-
head caused by the processing of components was sig-
niÔ¨Åcantly higher, making kof 200 faster than 50 in some
cases.
if components are excessively small (e.g., 1 :::10),
the semantic information they provide is rather trivial
8http://dx.doi.org/10.4121/uuid:
b8c59ccb-6e14-4fab-976d-dd76707bcb8a
190
10
20
30
40
50
0
20
40
60
80
time(s)
k
pr
-
1908
-
m34
-
l3
-
noise
i ( )
0
100
200
300
400
0
30
60
90
120
time(s)
k
pr
-
1151
-
m37
-
l3
-
noisefigure 18: comparison of computation time among di erent kvalues.
or insu cient. from a diagnostic point of view, the sub-
processes to be analyzed should be large enough to be
able to make meaningful conclusions. our empirical ex-
periments show that, decomposition with kbetween 20
and 40 could represent a good trade-o between com-
putation time and diagnostic quality.
trace length and grouping
a third set of experiments was conduced to study the
eect of the trace lengths on the proposed approach. we
aim to compare decomposed and non-decomposed con-
formance checking for di erent traces lengths. all logs
and models of this experiments are included in the is-
bpm2013 benchmark. for each model used in this ex-
periment, four logs were generated, each one with a dif-
ferent average length of the traces on it (e.g., pr1908-
m18-l1 has an average trace length of 18, while pr1908-
m41-l4 has average length of 41). each one of these
four logs has been generated from simulating the same
model and using the same parameters (except the length
of the traces), and all them are completely Ô¨Åtting. ad-
ditionally, we have created another four logs for each
model, with the same characteristics, but containingnoise (and hence being non-Ô¨Åtting). figure 19 shows
the results for two models: pr-1908 andpr-1151 , be-
ing the results similar for the rest of models-logs in the
benchmark. for each model, the chart contains the com-
putation times of each alternative: decomposed (using k
of 25) with noisy logs and Ô¨Åtting logs, and the results for
the same noisy and Ô¨Åtting logs using the original non-
decomposed approach.
0
20
40
60
80
100
16
21
26
31
36
41
time(s)
averagetracelength
dec(25)fit
dec(25)noise
non_decfit
non_decnoise
pr
-
1908
0
200
400
600
800
1000
11
21
31
41
51
time(s)
averagetracelength
dec(25)fit
dec(25)noise
non_decfit
non_decnoise
pr
-
1151
figure 19: comparison of computation time among di erent trace
length.
the Ô¨Årst conclusion that arises from the experiments
refers to the processes with noise ‚Äì the most plausi-
ble assumption in a real world scenario. figure 19
shows that, when the log has short traces, both decom-
posed and non-decomposed alignment checking per-
form good. however, once the length of the traces
grows (or simply traces of large models or with lot
of concurrency), it has a severe e ect on the non-
decomposed performance. this was to be expected, i.e.,
the more activities in a trace, the more di cult it is to
compute the alignment. on the other hand, the decom-
posed approach performs both fast and with a near-to
constant growth (and eventually constant at some point).
this is justiÔ¨Åed by the e ect of the decomposition on
the computation time (as has been shown in fig. 15),
but also due to the grouping (as explained below).
200 100 200135791113
nodes  levels  
rspt  
0 20 40135791113
nodes  levels  
small  
0 20 40135791113
nodes  levels  
similarity  figure 20: results of Ô¨Åltering by small ( <10) and merging by similarity ( >0:8) over the model prcm 6.
the current implementation of the align-based con-
formance checking includes the grouping optimization:
when the algorithm analyzes a trace, it Ô¨Årst checks if
it has already computed an alignment for an identical
trace. in this is the case, it re-uses the previously com-
puted alignment, thus reducing the time signiÔ¨Åcantly.
the e ect of this optimization for the non-decomposed
scenario depends on the case at hand, and it is strongly
related with the size and the behavior of the model.
however, in the decomposed scenario, the chances to
encounter this situation increase: the smaller is the com-
ponent (e.g., k=25), the fewer activities it contains,
and therefore, the more likely it is to Ô¨Ånd a trace al-
ready seen before (once the original trace has been pro-
jected onto the component). the e ects of the grouping
are perfectly reÔ¨Çected by the Ô¨Åtting cases of fig. 19:
the decomposed approach performs faster than the non-
decomposed alternative even in a Ô¨Åtting scenario. this
is remarkable because alignments can be created easily
in this case.
topology and filtering
the last set of experiments is designed to illustrate
the eects of some of the techniques proposed for pro-
cess diagnosis. in particular, the non-Ô¨Åtting subnet al-
gorithm (cf. alg. 4), and the techniques of Ô¨Åltering the
rpst based on small components and similarity (cf.
sect. 5.3). table 1 shows the application of the nfn
algorithm over the benchmark bpm2013 , with compo-
nents of size at most 50. for each model (containing
pplaces and ttransitions) the table provided the size
of the minimal net containing all the non-Ô¨Åtting compo-
nents, i.e., the number of places and transitions ( jpjand
jtj), and the number of vertices jvjused to create the
net. the table illustrates the beneÔ¨Åts of the proposed al-
gorithm to detect and isolate the Ô¨Åtness mismatches. in
case the Ô¨Åtness problems are spread all over the wholemodel, the resulting net is almost the original net (e.g.,
prcm 6). however, when the Ô¨Åtness problems are local,
the net that encloses all problem spots may be orders of
magnitude smaller than the original net, thus easing the
diagnosis.
table 1: results of nfnalgorithm.
dataset nfn
p tjvj j pj j tj
pram6 363 347 14 15 14
prcm6 317 317 113 315 317
prdm6 529 429 31 55 52
prem6 277 275 31 29 40
prfm6 362 299 7 27 25
prgm6 357 335 5 34 29
the Ô¨Ånal experiment performed illustrates the e ects
of the simpliÔ¨Åcation techniques over the rpst. figure
20 reÔ¨Çect the results for one of the models ( prcm 6).
the charts show the number of nodes of the original
rpst, after Ô¨Åltering small components ( <10) and then
merging by similarity ( >0:8). the number of nodes are
distributed by levels of depth in the rpst tree, i.e., the
distance with the root represented as the level 1. the
chart clearly reÔ¨Çects the di erence between the number
of components on the original rpst and the one after
removing the small components, i.e., most of the rpst
nodes are small. after removing small nodes the depth
of the rpst only decreases two levels (from 14 to 12).
on the other hand, when merging on similarity is ap-
plied over the Ô¨Åltered rpst, the number of nodes is not
reduced so drastically, but the number of levels of the
tree is (from 13 to 6), providing a hierarchical decom-
position with less redundancy and more aligned with the
human perception [11].
217. related work
for an introduction to process mining we refer to [1].
for an overview of best practices and challenges, we
refer to the process mining manifesto [25].
the seminal paper [3] established the basics of con-
formance checking, based on the use of model replay
to determine the Ô¨Åtness of a log trace. in the last
years, however, the use of alignment techniques has in-
creased [6]. in spite of its high complexity, alignment
techniques provide a robust analysis of Ô¨Åtness anoma-
lies, especially in the presence of non-determinism in
the model or noise in the logs. replay techniques have
been revisited recently in the scope of a general frame-
work for conformance checking based on the use of neg-
ative information [21].
decomposing large graphs into smaller fragments is a
topic widely studied in the literature. there exist plenty
of techniques with di erent goals for that task, e.g.,
minimizing the connectivity among fragments [26], or
obtaining fragments with a single entry and a single exit
[16, 10]. regarding decomposed conformance check-
ing, there have been recent contributions related to the
one presented in this paper. in [22] it is shown that
so-called ‚Äúpassages‚Äù can be used to decompose both
process discovery and conformance checking problems.
the aforementioned work is then generalized in [13],
where the minimal requirements for decomposing con-
formance in general are described. this paper uses
the results presented in [13] for the particular case of
seses. experimental results suggest that a sese-based
decomposition is faster than a decomposition based on
passages.
also related is the work on conformance checking of
proclets [27]. proclets can be used to deÔ¨Åne so-called
artifact centric processes, i.e., processes that are not
monolithic but that are composed of smaller interacting
processes (called proclets). in [27] it is shown that con-
formance checking can be done per proclet by project-
ing the event log onto a single proclet while considering
interface transitions in the surrounding proclets.
8. conclusions and future work
this paper presented a novel decomposition tech-
nique for handling large conformance instances and en-
abling the detailed and focused diagnosis of confor-
mance checking. by focusing the decomposition on
Ô¨Ånding subprocesses with a clear interface to the rest
of the process we achieve two goals: (1) conformance
checking can be done much faster and allows us toanalyze models /logs previously intractable and (2) im-
proved diagnostics. we were able to exploit existing
results for single-entry single-exit (sese) decompo-
sitions and apply these to the process mining domain.
the decomposition approach and related diagnostic
capabilities have been implemented in prom. extensive
experimental results demonstrate the advantages of our
approach and e ciency of the implementation. the use
of the decomposed paradigm reduces the computation
time of the original stand-alone conformance approach
due to a reduction of the state-space to explore, and the
eect of the grouping. moreover, innovative visualiza-
tions of the misalignments further support the diagno-
sis of the conformance problems. the technique can
deal with models of hundreds of nodes, representing a
disruptive step into enabling conformance checking for
industrial scenarios.
there are several research directions that can be tack-
led based on the results presented in this paper. first,
we aim to extend divide and conquer techniques with a
decomposed Ô¨Åtness metric that would serve as an esti-
mate for the real Ô¨Åtness value of the whole model. we
would also like to include other conformance metrics,
e.g., precision. note that this is far from trivial for met-
rics that correspond to global properties. we also aim
to extend the technique presented in this paper in or-
der to deal with other perspectives (e.g., data) available
in the event log. it appears to be possible to apply the
approach to process models having data conditions or
resource allocation rules. future work includes also the
study of new decomposition techniques that minimize
the bridging process, in order to preserve the strict sese
structure of the fragments as much as possible. finally,
we would like to use the insights provided in this paper
to develop sese-based discovery techniques.
acknowledgments
the authors would like to thank dr. artem
polyvyanyy for his comments, and seppe vanden
broucke for his help with the experiments. this work
has been partially supported by the ministerio de ed-
ucaci ¬¥on (ap2009-4959) and by the project tin-2007-
66523. this work was also supported by the basic
research program of the national research university
higher school of economics (hse) in moscow.
[1] w. m. p. van der aalst, process mining: discovery, confor-
mance and enhancement of business processes, springer, 2011.
[2] s. rogers, big data is scaling bi and analytics-data growth is
about to accelerate exponentially, information and management
- brookÔ¨Åeld 21 (5) (2011) 14.
22[3] a. rozinat, w. m. p. van der aalst, conformance checking of
processes based on monitoring real behavior, inf. syst. 33 (1)
(2008) 64‚Äì95.
[4] t. murata, petri nets: properties, analysis and applica-
tions., proceedings of the ieee 77 (4) (1989) 541‚Äì580.
doi:10.1109 /5.24143.
[5] w. m. p. van der aalst, a general divide and conquer approach
for process mining, in: m. ganzha, l. maciaszek, m. paprzy-
cki (eds.), federated conference on computer science and in-
formation systems (fedcsis 2013), ieee computer society,
2013, pp. 1‚Äì10.
[6] a. adriansyah, b. f. van dongen, w. m. p. van der aalst, con-
formance checking using cost-based Ô¨Åtness analysis, in: edoc,
ieee computer society, 2011, pp. 55‚Äì64.
[7] a. adriansyah, j. munoz-gama, j. carmona, b. f. van dongen,
w. m. p. van der aalst, alignment based precision checking,
in: m. l. rosa, p. so er (eds.), business process management
workshops, v ol. 132 of lecture notes in business information
processing, springer, 2012, pp. 137‚Äì149.
[8] a. adriansyah, j. munoz-gama, j. carmona, b. f. van dongen,
w. m. p. van der aalst, measuring precision of modeled behav-
ior, information systems and e-business management (2014) 1.
[9] ieee task force on process mining ‚Äì case studies , http:
//www.win.tue.nl/ieeetfpm/doku.php?id=shared:
process_mining_case_studies .
[10] a. polyvyanyy, j. vanhatalo, h. v ¬®olzer, simpliÔ¨Åed computa-
tion and generalization of the reÔ¨Åned process structure tree, in:
m. bravetti, t. bultan (eds.), ws-fm, v ol. 6551 of lecture
notes in computer science, springer, 2010, pp. 25‚Äì41.
[11] j. munoz-gama, j. carmona, w. m. p. van der aalst, hierar-
chical conformance checking of process models based on event
logs, in: colom and desel [28], pp. 291‚Äì310.
[12] j. munoz-gama, j. carmona, w. m. p. van der aalst, con-
formance checking in the large: partitioning and topology, in:
f. daniel, j. wang, b. weber (eds.), bpm, v ol. 8094 of lecture
notes in computer science, springer, 2013, pp. 130‚Äì145.
[13] w. m. p. van der aalst, decomposing petri nets for process
mining: a generic approach, distributed and parallel databases
31 (4) (2013) 471‚Äì507.
[14] j. munoz-gama, j. carmona, a fresh look at precision in pro-
cess conformance, in: r. hull, j. mendling, s. tai (eds.), bpm,
v ol. 6336 of lecture notes in computer science, springer,
2010, pp. 211‚Äì226.
[15] w. m. p. van der aalst, a. adriansyah, b. van dongen, re-
playing history on process models for conformance checking
and performance analysis, wires data mining and knowledge
discovery 2 (2) (2012) 182‚Äì192.
[16] j. e. hopcroft, r. e. tarjan, dividing a graph into triconnected
components, siam j. comput. 2 (3) (1973) 135‚Äì158.
[17] a. polyvyanyy, structuring process models, ph.d. thesis, uni-
versity of potsdam (2012).
[18] j. vanhatalo, h. v ¬®olzer, j. koehler, the reÔ¨Åned process structure
tree, data knowl. eng. 68 (9) (2009) 793‚Äì818.
[19] r. p. j. c. bose, w. m. p. van der aalst, i. zliobaite, m. pech-
enizkiy, handling concept drift in process mining, in: h. moura-
tidis, c. rolland (eds.), caise, v ol. 6741 of lecture notes in
computer science, springer, 2011, pp. 391‚Äì405.
[20] m. silva, e. teruel, j. m. colom, linear algebraic and linear
programming techniques for the analysis of place or transition
net systems, in: w. reisig, g. rozenberg (eds.), petri nets, v ol.
1491 of lecture notes in computer science, springer, 1996, pp.
309‚Äì373.
[21] s. k. l. m. vanden broucke, j. d. weerdt, j. v . b. bae-
sens, determining process model precision and generalization
with weighted artiÔ¨Åcial negative events, ieee transactions onknowledge and data engineering (accepted).
[22] w. m. p. van der aalst, decomposing process mining prob-
lems using passages, in: s. haddad, l. pomello (eds.), petri
nets, v ol. 7347 of lecture notes in computer science, springer,
2012, pp. 72‚Äì91.
[23] s. j. j. leemans, d. fahland, w. m. p. van der aalst, discov-
ering block-structured process models from event logs - a con-
structive approach, in: colom and desel [28], pp. 311‚Äì329.
[24] a. burattin, a. sperduti, plg: a framework for the generation
of business process models and their execution logs, in: m. zur
muehlen, j. su (eds.), business process management work-
shops, v ol. 66 of lecture notes in business information pro-
cessing, springer, 2010, pp. 214‚Äì219.
[25] ieee task force on process mining, process mining manifesto,
in: f. daniel, k. barkaoui, s. dustdar (eds.), business process
management workshops, v ol. 99 of lecture notes in business
information processing, springer, 2012, pp. 169‚Äì194.
[26] g. karypis, v . kumar, a fast and highly quality multilevel
scheme for partitioning irregular graphs, siam journal on sci-
entiÔ¨Åc computing 20 (1) (1999) 359‚Äì392.
[27] d. fahland, m. de leoni, b. f. van dongen, w. m. p. van der
aalst, conformance checking of interacting processes with
overlapping instances, in: s. rinderle-ma, f. toumani, k. wolf
(eds.), bpm, v ol. 6896 of lecture notes in computer science,
springer, 2011, pp. 345‚Äì361.
[28] j. m. colom, j. desel (eds.), application and theory of petri
nets and concurrency - 34th international conference, petri
nets 2013, milan, italy, june 24-28, 2013. proceedings, v ol.
7927 of lecture notes in computer science, springer, 2013.
23appendix a. benchmarks
table a.2: isbpm2013 andbpm2013 benchmarks ‚Äì logs
log cases activities length Ô¨Åtting
pr-1244-a59 l1 2000 59 17 yes
pr-1244-a59 l1noise 2000 59 17 no
pr-1244-a59 l2 2000 59 29 yes
pr-1244-a59 l2noise 2000 59 29 no
pr-1244-a59 l3 2000 59 41 yes
pr-1244-a59 l3noise 2000 59 41 no
pr-1244-a59 l4 2000 59 55 yes
pr-1244-a59 l4noise 2000 59 55 no
pr-1151-a48 l1 2000 48 12 yes
pr-1151-a48 l1noise 2000 48 12 no
pr-1151-a48 l2 2000 48 23 yes
pr-1151-a48 l2noise 2000 48 23 no
pr-1151-a48 l3 2000 48 37 yes
pr-1151-a48 l3noise 2000 48 37 no
pr-1151-a48 l4 2000 48 50 yes
pr-1151-a48 l4noise 2000 48 50 no
pr-1908-a32 l1 2000 32 18 yes
pr-1908-a32 l1noise 2000 32 18 no
pr-1908-a32 l2 2000 32 27 yes
pr-1908-a32 l2noise 2000 32 27 no
pr-1908-a32 l3 2000 32 34 yes
pr-1908-a32 l3noise 2000 32 34 no
pr-1908-a32 l4 2000 32 41 yes
pr-1908-a32 l4noise 2000 32 41 no
pr-1912-a57 l1 2000 57 15 yes
pr-1912-a57 l1noise 2000 57 15 no
pr-1912-a57 l2 2000 57 26 yes
pr-1912-a57 l2noise 2000 57 26 no
pr-1912-a57 l3 2000 57 39 yes
pr-1912-a57 l3noise 2000 57 39 no
pr-1912-a57 l4 2000 57 52 yes
pr-1912-a57 l4noise 2000 57 52 no
log cases tasks length Ô¨Åtting
pram6 1200 317 32 no
prbm6 1200 317 41 yes
prcm6 500 317 43 no
prdm6 1200 429 249 no
prem6 1200 275 99 no
prfm6 1200 299 241 no
prgm6 1200 335 143 notable a.3: isbpm2013 andbpm2013 benchmarks ‚Äì models
model p t a inv
pr-1244-a59 71 68 164 9
pr-1151-a48 55 56 130 8
pr-1908-a32 37 36 86 4
pr-1912-a57 64 57 142 5
model p t a
pram6 363 347 842
prbm6 317 317 748
prcm6 317 317 748
prdm6 529 429 1136
prem6 277 275 648
prfm6 362 299 768
prgm6 357 335 822
24