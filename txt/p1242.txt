preprint computing, 103(6):1085-1104, 2021
the impact of biased sampling of event logs on the
performance of process discovery
mohammadreza fani sani1 · sebastiaan j. van zelst1,2 ·
wil m. p. van der aalst1,2
received: 22 may 2020 / accepted: 18 january 2021
© the author(s) 2021
abstract
with process discovery algorithms, we discover process models based on event data, 
captured during the execution of business processes. the process discovery algorithms 
tend to use the whole event data. when dealing with large event data, it is no longer 
feasible to use standard hardware in a limited time. a straightforward approach to 
overcome this problem is to down-size the data utilizing a random sampling method. 
however, little research has been conducted on selecting the right sample, given the 
available time and characteristics of event data. this paper systematically evaluates 
various biased sampling methods and evaluates their performance on different datasets 
using four different discovery techniques. our experiments show that it is possible to 
considerably speed up discovery techniques using biased sampling without losing the 
resulting process model quality. furthermore, due to the implicit ﬁltering (removing 
outliers) obtained by applying the sampling technique, the model quality may even be 
improved.
keywords process mining · biased sampling · process discovery · event log 
preprocessing · performance enhancement
b mohammadreza fani sani
fanisani@pads.rwth-aachen.de
sebastiaan j. van zelst
s.j.v.zelst@pads.rwth-aachen.de
wil m. p . van der aalst
wvdaalst@pads.rwth-aachen.de
1process and data science chair, rwth aachen university, aachen, germany
2fraunhofer fit, birlinghoven castle, sankt augustin, germanym. fani sani et al.
1 introduction
process mining is a research discipline that provides both data-oriented and business
process oriented analysis at the same time. process discovery, one of the main branches
of process mining, aims to discover a process model that accurately describes the
underlying process captured within the event data [ 1]. in conformance checking, the
goal is to assess to what degree a given process model and event data conform to one
another. finally, process enhancement aims at improving or enhancing process mining
results, e.g., by reﬂecting bottleneck information directly onto a (given) process model.
the result of process discovery algorithms can be used by other process mining
branches like process simulation [ 2] and prediction [ 3]. currently, the main research
focus in process discovery is on quality issues of discovered process models. however,the ever-increasing size of the data handled by the process mining algorithms leads
to performance issues when applying the existing process discovery algorithms [ 4].
most process discovery algorithms ﬁrst build an internal data structure, based on thewhole event log, then an optional ﬁlter step is applied.
however, such an approach may be infeasible in big data settings, where the event
data are too large to process. moreover, some process mining tools impose constraints
on the size of event data, e.g., the number of events. also, in many cases, we do
not require the whole event log, and an approximation of the process can already bediscovered by only using a small fraction of the event data.
in real life, process discovery is often of an exploratory nature, that means some-
times we need to apply different process discovery algorithms with several parametersto generate different process models and select the most suitable process model. when
the discovery algorithms are used repeatedly, such an exploratory approach makes
sense only if performance is reasonable. thus, even a small performance improve-ment may accumulate to a signiﬁcant performance increase when applied several
times. furthermore, many process discovery algorithms are designed to generalize the
behavior observed in the event data. in other words, these algorithms are able to repro-duce process behavior extends beyond the example behavior used as input. therefore,
it may still be possible to discover the underlying process using a subset of event data.
this research studies the effectiveness of applying biased sampling on event data
in advance of invoking process discovery algorithms, instead of using all the avail-
able event data. in this regard, we present and investigate different biased sampling
strategies and analyze their ability to improve process discovery algorithm scalability.furthermore, the techniques presented allow us to select a user-speciﬁed fraction of
inclusion of the total available event data. utilizing the prom -based [ 5] extension
ofrapidminer [6], i.e., rapidprom , we study the usefulness of these sampling
approaches, using real event logs. the experimental results show that applying biased
sampling techniques reduces the required discovery time for all the evaluated discoveryalgorithms.
this paper extends the work in [ 7]. here, we formally deﬁne the proposed method
and explain it with more details. the proposed method is also applied on many realevent logs with state-of-the-art process discovery algorithms, i.e., inductive miner,
split miner and ilp miner. we return sampled event logs based on variants or traces.
finally, it is shown that using variant-based sampling, we are able to improve the per-
123the impact of biased sampling of event logs on the…
formance of process discovery procedure using different process discovery algorithms
and at the same time having high-quality process models.
the remainder of this paper is structured as follows. in sect. 2, we discuss related
work. section 3deﬁnes preliminary notation. we present different biased sampling
strategies in sect. 4. the evaluation and corresponding results are given in sect. 5.
finally, sect. 6concludes the paper and presents some directions for future work.
2 related work
most process model discovery algorithms, e.g., alpha miner [ 8] and the basic inductive
miner [ 9] were designed to depict as much as possible behaviors seen in the event log
into the process model. existence of high behavior variability in real event logs leads
this approach to result in complex and imprecise process models [ 10]. other process
discovery algorithms, e.g., split miner [ 11], the extended versions of inductive miner
[12], and ilp miner [ 13] were designed to capable of ﬁltering infrequent behavior
within their internal data structure, in advance of discovering a process model. theperformance of all these methods depends on different parameters, e.g., the number
of (unique) process instances, the number of unique activities, and the average length
of process instances in the given event log.
two main categories of methods are proposed in the literature to address this prob-
lem. in the ﬁrst category, outlier behaviors [ 10], uncertainty about the execution and
the order of activities [ 14], and missing data [ 15] are considered as the main reasons
of the behavioral variability in the process event log. therefore, they aim to detect
such behaviors and remove them from the event log and give the preprocessed event
logs to process discovery algorithms. however, in the second direction, the goal is toconsider the mainstream behavior in the event log in a fast way to be able to discover
a process model similar to the one that is discovered using the original event log. in
the following, we provide some works in each category.
there are different methods to detect and deal with outlier behavior in event logs. in
[10,16,17] the authors propose to remove outlier behavior that is detected in the event
log. however, in [ 18,19] the authors propose to apply automated ordering modiﬁcation
algorithms. moreover, [ 20] provides an interactive approach to repair noisy activity
labels. in addition, the authors in [ 21,22] propose to consider activities that could be
executed in different parts of the process that lead to less structure in the discovered
process model. in [ 23] an interactive ﬁltering toolkit is provided that let user choose
different ﬁltering methods in combination with several process discovery algorithms.filtering techniques effectively reduce the size of given process instances (i.e., traces)
used by process discovery algorithms. in this regard, these ﬁltering techniques have
non-linear time complexity that does not scale in the context of big data. however,sometimes the required time for applying these ﬁltering algorithms is longer than the
required time of discovering a process model from the original event log. also, these
ﬁltering techniques have no accurate control over the size of the reduced event log.
sampling methods reduce the number of process instances and increase the per-
formance of different process mining algorithms [ 24]. moreover, they can improve
the conﬁdentiality aspects of event logs [ 25]. in [ 26], the authors proposed a sam-
123m. fani sani et al.
pling approach based on parikh vector of traces to detect the behavior in the event
log. however, we can not use this sampling technique for process discovery purpose;
because the parikh vector does not store the sequences of activities that are criticalfor discovering process models. in [ 27], the authors recommend a random trace-based
sampling method to decrease the discovery time and memory footprint. this method
assumes that process instances have different behavior if they have different sets ofdirectly follows relations. however, using a unique set of directly follows relations
may show different types of process behavior. furthermore, [ 28] recommends a trace-
based sampling method speciﬁcally for the heuristic miner [ 29]. both [ 27] and [ 28]
have no control on the size of the ﬁnal sampled event data. also, they depend on the
deﬁned behavioral abstraction that may lead to the selection of almost all the process
instances.
moreover, as these methods are unbiased, we have non-deterministic results after
each sampling. in this paper, we will offer and analyze random and biased sampling
methods in which the size of the sampled event data is adjustable. therefore, we cancontrol the size and variability of process models at the same time.
3 preliminaries
in this section, we brieﬂy introduce basic process mining terminologies and notations
that ease the readability of the paper.
g i v e nas e t x, a multiset bover xis a function b:x→n≥0, i.e, it allows certain ele-
ments of xto appear multiple times. we show a multiset as b=[ek1
1,ek2
2,..., eknn], where
for 1≤i≤nwe have b(ei)=kiwith ki∈n>0.i fki=1, we do not show its superscript, and
if for some e∈xwe have b(e)=0, we omit it from the multiset notation. furthermore,
the empty multiset, i.e. b(e)=0,∀e∈xis written as []. moreover, b={e∈x|b(e)>0}
is the set of all elements that are presented in the multiset. the set of all possible mul-tisets over a set xis written as b(x).
let x
∗denote the set of all possible sequences over a set x. a ﬁnite sequence
σof length nover xis a function σ:{1,2,..., n}→x, alternatively written as
σ=/angbracketleft x1,x2,..., xn/angbracketrightwhere xi=σ(i)for 1≤i≤n. the empty sequence is writ-
ten as /epsilon1. the concatenation of sequences σandσ/primeis written as σ·σ/prime. function
hd:x∗×n≥0/notarrowrightx∗, returns the “head” of a sequence, i.e., given a sequence
σ∈x∗and k≤|σ|,hd(σ,k)=/angbracketleft x1,x2,..,xk/angbracketright, i.e., the sequence of the ﬁrst k
elements of σ. in case k=0, we have hd(σ,0)=/epsilon1, i.e., an empty sequence. sym-
metrically, tl:x∗×n≥0/notarrowrightx∗returns the “tail” of a sequence and is deﬁned as
tl(σ,k)=/angbracketleftxn−k+1,xn−k+2,..., xn/angbracketright, i.e., the sequence of the last kelements of σ,
with, again, tl(σ,0)=/epsilon1. sequence σ/primeis a subsequence of sequence σ, which we
denote as σ/prime∈σ, if and only if σ1,σ2∈x∗such that σ=σ1·σ/prime·σ2.l e tσ,σ/prime∈x∗.
we deﬁne the frequency of occurrence of σ/primeinσby fre q:x∗×x∗→n≥0
where fre q(σ/prime,σ)=|{1≤i≤|σ||σ/prime
1=σi,...,σ/prime
|σ/prime|=σi+|σ/prime|}|. for example, fre q(/angbracketleftb/angbracketright,
/angbracketlefta,b,b,c,d,e,f,h/angbracketright)=2 and fre q(/angbracketleftb,d/angbracketright,/angbracketlefta,b,d,c,e,g/angbracketright)=1, etc.
event logs describe sequences of executed business process activities, typically in
the context of some cases (or process instances), e.g., a customer or an order-id. the
123the impact of biased sampling of event logs on the…
execution of an activity in the context of a case is referred to as an event . a sequence of
events for a speciﬁc case is also referred to as a trace . thus, it is possible that multiple
traces describe the same sequence of activities, yet, since events are unique, each traceitself contains different events.
note that for many process mining purposes, e.g., process discovery and confor-
mance checking, the case and event attributes are not mandatory, and it is sufﬁcientto have a sequence of events for each case. we usually call this basic information
control-ﬂow information. in this regard, we show the trace that represents case 1 as
/angbracketlefta,b,c,d,e,f,h/angbracketright(using short-hand activity names), and for case 2 the trace is shown
as/angbracketlefta,b,g/angbracketright. in the context of this paper, we formally deﬁne event logs as a multiset
of sequences of activities. this assumption leads to ignoring the execution order of
different process instances, as it is not important for the process discovery purpose.
deﬁnition 1 (event log )l e t abe the universe of activities, and let a⊆abe a non-
empty set of activities. an event log is a multiset of sequences over a, i.e. l∈b(a
∗).
observe that each σ∈ldescribes a trace-variant whereas l(σ) describes how
many traces of the form σare presented within the event log.
by sampling an event log, we choose some of the process instances of it. sampling
could be done with/without replacement. if an object is selected once, it is not selectable
anymore in the sampling methods without replacement. here, we use sampling withoutreplacement. in other words, it is not possible to put an object more than once in the
sampled event log. in the following, we formally deﬁne sampled event logs.
deﬁnition 2 (sampled event log )l e t l⊆b(a
∗)be an event log. we deﬁne slas a
trace-based sampled event log of l,i f∀σ∈sl(0<sl(σ)≤l(σ)).slis a variant-based
sampled event log of lif for∀σ∈sl(1=sl(σ)≤l(σ)).
in other words, a variant-based sampled event log is a subset of trace-variants in l.
note that it is not possible to have a variant in a sampled event log that does not existin the original event log.
we could deﬁne different types of behavior in an event log. one behavior in an event
log is the directly follows relation between activities that can be deﬁned as follows.
deﬁnition 3 (directly follows relation )l e t a,b∈abe two activities and σ=
/angbracketleftσ
1,..,σ n/angbracketright∈a∗is a trace in the event log. a directly follows relation from atob
exists in trace σ, if there is i∈{1,..,n−1}such that σi=aandσi+1=band we denote
it by a>σb.
for example, in sequence /angbracketlefta,b,c/angbracketright, we have a directly follows relation from btoc.
an alternative behavior which has negative affects on the results of process dis-
covery algorithms is the occurrence of a low probable sub-pattern, i.e., a sequence
of activities, between pairs of frequent surrounding behavior, which we refer to it as
behavioral contexts [ 30].
deﬁnition 4 (behavioral context )l e t l∈b(a∗)be an event log. a behavioral context
cis a pair of non-empty sequences of activities, i.e., c∈a∗×a∗. furthermore, we
deﬁne the set of behavioral contexts present in l, i.e.,βl∈p(a∗×a∗),a s :
βl=/braceleftbig
(σl,σr)∈a∗×a∗:∃σ∈l,σ/prime∈a∗\/epsilon1/parenleftbig
σl·σ/prime·σr∈σ/parenrightbig/bracerightbig(1)
123m. fani sani et al.
for example, in trace σ=/angbracketlefta,b,c,d,e,f,h/angbracketright,/angbracketlefta,b/angbracketrightand/angbracketlefte/angbracketrightare two subsequences that
surround /angbracketleftc,d/angbracketright; hence, the pair (/angbracketlefta,b/angbracketright,/angbracketlefte/angbracketright)is a behavioral context. note that the
surrounded behavior could not be an empty sequence or /epsilon1. as we are more interested
in the contexts that frequently occur throughout the event log.
we inspect the probability of contextual sub-patterns, i.e., the behavior that is sur-
rounded by the frequent behavioral contexts. thus, we simply compute the empiricalconditional probability of a behavioral sequence, being surrounded by a certain con-
text.
deﬁnition 5 (conditional contextual probability )l e tσ
s,σl,σr∈a∗be three sequen-
ces of activities and let l∈b(a∗)be an event log. we deﬁne the conditional contextual
probability ofσs, w.r.t., σlandσrinl, i.e., representing the sample based estimate
of the conditional probability of σsbeing surrounded by σlandσrinl. function
γl:a∗×a∗×a∗→[0,1], is based on:
γl(σs,σl,σr)=/summationtext
σ∈l/parenleftbig
|σσl·σs·σr|/parenrightbig
/summationtext
σ∈l/parenleftbig/summationtext
σ/prime∈a∗\/epsilon1|σ/prime
σl·σ/prime·σr|/parenrightbig (2)
we alternatively write pl(σs|σl,σr)to represent γl(σs,σl,σr).
based on these probabilities, we are able to detect unstructured behavior in a trace.
4 sampling event data
in this section, we present different sampling strategies to increase the discovery
procedure’s performance. we propose to sample different behavioral elements of an
event log, e.g., events, directly follow relations, traces, and variants. by sampling
events, we can choose events from different parts of a process instance that may notshow the correct behavior of that process and leads to the inapplicability of it for
the process discovery purpose. sampling directly follows relations is useful for some
process discovery algorithms like alpha miner and a version of inductive miner. but,we need to modify these algorithms to accept a set of directly follows relations instead
of an event log as an input. also, such data structures do not apply to all process
discovery algorithms. thus, here we only consider trace and variant-based sampling.consequently, these sampling methods take an event log as input and return a subset of
traces or variants. the schematic of the sampling methods is illustrated in fig. 1.n o t e
that in some standard of storing event logs, e.g., xes [ 5], we do not have event logs in a
multiset view. therefore, we need to traverse the event log to ﬁnd out variants and their
frequency. afterward, in variant-based sampling, we choose one process-instance foreach of the selected variants, and consequently, the frequency of each sample is 1. in
trace-based sampling, the frequency of each unique sample is 1 ≤n
i≤mi.
for many process discovery algorithms such as ilp miner, the family of alpha
miners and inductive miner, it is enough to have unique variants to discover a cor-
responding process model. in other words, the frequency of variants is mostly just
used for post-processing algorithms like ﬁltering. therefore, here we mainly focus on
123the impact of biased sampling of event logs on the…
fig. 1 schematic overview of the sampling methods. we ﬁrst detect variants and afterward sample variants
or traces based on different criteria
variant-based sampling, but, all these methods easily can be extended to trace-based
sampling methods. moreover, we also just used control-ﬂow related information thatis available in all event logs, and this is consistent with the way.
we are able to consider three dimensions for sampling event logs. the ﬁrst one is
the number of process instances that are placed in the sampled event log, i.e., |s
l|.
in the worst case, it is the same as the original event log, i.e., we do not have any
reduction in size. we can set the size of the sampled event logs (i.e., the sample ratio)
as follows.
c=/braceleftbigg|sl|
|l|variant-based sampling
|sl|
|l|trace-based sampling(3)
note that, in the above equation, 0 <c≤1. the second dimension is the com-
pleteness of the sampled event log. if a sample event log contains few relations of theoriginal event log, process discovery algorithms are not able to discover an appropriate
process model from the sampled event log. however, including all the behavior in the
original event log in the sampled event log is also leads to complex and imprecise pro-
cess models. note that there is a difference between the size of event data and behavior
that it contains. therefore, we should put the most important behavior in the eventlog. the last dimension is the required sampling time as a preprocessing phase. some
preprocessing techniques require too much time to return the preprocessed event log
especially when we deal with large event logs. consequently, sampling an event login a shorter time is an advantage point of it.
we are able to sample behavioral elements in an event log randomly or by some
sampling biases. in the following, we will explain both of these methods.
4.1 random sampling
the ﬁrst method is to randomly sample c×|l|traces in the event log without replace-
ment and return these traces (i.e., trace-based sampling) or just unique trace-variants
among them (i.e., variant-based sampling). this method is fast because we do not needto traverse the original event log. however, it is possible that many of the sampled
traces have similar behavior, and we just return a few unique variants. moreover, we
may return variants that do not generalize the whole process.
123m. fani sani et al.
another approach ﬁrst ﬁnds all the unique variants in an event log, after that,
randomly select c×|l|variants from them. this approach is a bit slower, but it is
able to return more behaviors compared to the previous approach.
4.2 biased sampling strategies
in general, traversing event logs have a linear complexity considering the number of
process instances in the event log. it gives us a motivation that instead of randomly
sampling the variants, we are able to use more advanced strategies (biases) to sample
variants in the event log.
in biased sampling methods, we ﬁrst traverse the event log to ﬁnd unique trace-
variants in it; then, we rank the variants based on different strategies. the top n×|l|
variants with the highest rank will be selected to be placed in the sampled event log.
different ranking strategies can be used for this purpose that is discussed in follows.
4.2.1 frequency-based sampling
the ﬁrst ranking strategy is sampling variants based on their frequencies. this sam-
pling method gives more priority to a variant that has a higher occurrence frequencyin the event log. hence, we sort the variants based on their frequencies or l(σ) and
return the top c×|
l|of variants as a sampled event log.
this strategy was proposed beforehand to simplify the discovered process models
in some process mining tools. the advantage of this strategy is that we could grantee
a minimum replay ﬁtness of the future process model that will be discovered basedon the sampled event log. note that, in the random sampling strategy, the probability
of choosing a more frequent variant is also higher. however, in some event logs, the
majority of process instances have a unique trace-variant or variants with very lowfrequencies. so, to differentiate between them will be challenging, and using this
strategy is not efﬁcient anymore. therefore, a drawback of this strategy is that the
sampled event log may not contain many behaviors from the original event log.
4.2.2 length-based sampling
we can rank variants based on their length. in other words, we give a higher score to
a shorter variant or to a longer one. if we want to keep more behaviors in our sampled
event log, we need to choose traces with longer variants ﬁrst. however, if we are
interested in retaining the main-stream behaviors of the event log, usually it is better
to choose traces with shorter variants. thus, in this strategy, we sort variants based on
their length, i.e., |σ|, and choose the longest or the shortest ones ﬁrst.
using the longer strategy, we are able to leave out incomplete traces, that improves
the quality of resulted process models. however, if there are self-loops and other
longer loops in the event log, there is a high probability to consider many infrequentvariants with the same behavior for process discovery algorithms. for example, if we
use directly follows information, it does not matter if trace σhasa>
σaone time or
more.
123the impact of biased sampling of event logs on the…
on the other hand, we may keep variants with more simple behavior if we use the
shorter strategy; however, some incomplete process instances may be selected. note
that incomplete traces leads to having imprecise process models.
4.2.3 similarity-based sampling
if we aim to sample variants that contain general behavior of the whole event log, we
need to use the similarity-based sampling methods. using this approach, we ﬁrst ﬁnd
the general behaviors of the event log. we are able to use different behavior; however,
the simplest and the most critical behavior for process discovery is the directly follows
relation. therefore, we compute the occurrence probability of each directly followsrelation b
i=(a1,a2)(that a1,a2∈a) according to the following formula.
prob(bi)=num|σ∈l|a1>σa2|
|l|(4)
hence, we compute the probability of observing each directly follows relation biin
a variant. if prob(bi)is high (i.e., be higher than a deﬁned threshold tp), we expect
that the sampled variants should contain it. thus, any variant contains such a high
probable behavior (that here is a directly follows relations), will its ranking (by +1).
otherwise, if a variant does not contain a probable behavior, we decrease its rankingby giving a negative value (i.e., −1). contrariwise, if a variant contains a low probable
behavior (i.e., prob
bi≤1−tp), we decrease its ranking by 1. thus, we are searching
for variants that have very high probable behaviors and have less low probable behav-iors. note that, it is possible that some behaviors be neither high probable nor low
probable that we do nothing for such behaviors. note that we normalize the rankings
based on the length of variants. afterward, we sort the variants based on their rankingsand return the c×|
l|ones with the highest ranking.
the main advantage of this method is that it helps process discovery algorithms
to depict the main-stream behavior of the original event log in the process model.
however, it needs more time to compute a similarity score of all variants. especially,
if we use more advanced behavioral structures such as eventually follow relations, thiscomputation will be a limitation for this ranking strategy.
4.2.4 structured-based sampling
it is shown in [ 18] that unstructured behavior in event logs leads to imprecise and
complex process models. in this sampling strategy, we consider the presence of
unstructured behavior (i.e., based on deﬁnition 5) in each variant. in this regard,
we ﬁrst compute the occurrence probability of each sub-patten among its speciﬁc con-textual context (i.e., p
l(σs,σl,σr)). if this probability is below a given threshold, i.e.,
ts, we call it an odd structure or unstructured behavior. thus, for each unstructured
behavior in a variant, we deﬁne a penalty to it and decrease its ranking by −1. con-
sequently, a variant with higher odd structures receives more penalties, and it is not
appealing to be placed in the sampled event log. note that in this strategy, we do not
normalize the negative values based on the length of the variant.
123m. fani sani et al.
table 1 details of real event logs that are used in the experiment
event log activities# traces# v ariants# df relations#
bpic −2012 [ 31] 23 13,087 4336 138
bpic −2013 [ 32] 4 7554 1511 11
bpic −2017−all [ 33] 26 31,509 1593 178
bpic −2017−offer [ 33] 8 42,995 169 14
bpic −2018−control [ 34] 7 43,808 59 12
bpic −2018−inspection [ 34] 15 5485 3190 67
bpic −2018−reference [ 34] 6 43,802 515 15
hospital [35] 18 100,000 1020 143
road [36] 11 150,370 231 70
sepsis [37] 16 1050 846 115
4.2.5 hybrid sampling
in hybrid strategies, we combine two or three of other sampling strategies. in this
way, we expect to have the beneﬁts of different methods. to do so, we normalize various
ranking strategies to values between 0 and 1. then, we use a weighting average methodto aggregate normalized values. here, we combine the frequency and similarity-based
methods; however, other combinations are also possible.
in the next section, we show the inﬂuence of the sampling strategies on the perfor-
mance of process discovery procedure and quality of their results.
5 evaluation
we conduct some experiments to answer the following research questions:
–(q1) does sampling event logs improve the performance of different process
discovery algorithms?
–(q2) does variant-based sampling outperform trace-based sampling?
–(q3) is the quality of process models that are discovered using sampled event logs
similar to process models that are discovered from the original event logs?
–(q4) which sampling strategies are faster and result in high-quality process mod-
els?
–(q5) how does the sampling threshold affect the sampling and discovery time?
5.1 implementation
to apply the proposed sampling strategies, we implemented the sample variant plug-
in in the prom framework1[5]. in this implementation, we used static thresholds
1sample v ariant plug-in in the logfiltering package: https://svn.win.tue.nl/repos/prom/packages/
logfiltering .
123the impact of biased sampling of event logs on the…
for similarity and structured based sampling strategies. the user is able to specify
the desired percentage of the sampling traces/variants and the ranking strategy. the
plug-in takes an event log as an input and produces an event log contains top c×100
percentage of traces/variants as an output. in addition, to apply our proposed method
on various event logs with different parameters, we ported the sample variant plug-in
torapidprom [6] that is an extension of rapidminer that combines scientiﬁc
work-ﬂows with a range of ( prom -based) process mining algorithms.
5.2 experimental setup
information about ten real event logs that are used in the evaluation is given in table 1.
these event logs are accessible at https://data.4tu.nl/search?q=process%20mining&
contenttypes=collection . for process discovery, we used a family of alpha miner [ 8]
(i.e., the basic alpha miner, alpha++ and alpha#), inductive miner [ 12], ilp miner
[38], and split miner [ 11]. in cases whereas the event logs were sampled, we applied
process discovery algorithms just without their built-in ﬁltering mechanisms.
we sampled event logs with different variant and trace-based sampling strate-
gies, and cin[0.05,0.10,0.15,0.20]. each experiment was repeated ﬁve times and
the average values are shown in these ﬁgures. the y-axis represents the average
performance-improvements using a logarithmic scale.
5.3 experimental result
here, we show how experimental results address the mentioned research questions.
5.3.1 (q1 and q2)
to measure the performance improvement, we consider both the discovery time and
sampling time of event logs using the following formulas. higher values for these
measures shows the number of times we are faster using the sampling methods.
disco ver yt ime imp ro vement=disco ver yt ime who lelo g
disco ver yt ime sampledlog(5)
to ta ltime imp ro vement=disco ver yt ime who lelo g
disco ver yt ime sampledlog +samplingtime
(6)
figures 2and 3show the discovery time and total improvement when we sample
event logs with/without considering sampling time corresponding to eqs. 5and 6.i n
these ﬁgures, a higher value shows a higher improvement in the performance of process
discovery procedure. it is evident that by reducing the size of the event log, the processdiscovery time is reduced. therefore, the disco ver yt ime
imp ro vement for variant-
based sampling is signiﬁcantly higher than trace-based sampling. since the |sl|for
variant-based sampling is usually remarkably lower than trace-based one. for some
123m. fani sani et al.
fig. 2 process discovery performance improvement for different process discovery algorithms using variant
and trace-based sampling methods
fig. 3 total time improvement for discovering process using sampling methods
fig. 4 reduction in the number of directly follows relations by sampling event logs
event logs, process discovery is more than 10,000 times faster on the sampled event
log using variant-based sampling compared to using the whole event log. however,
for event logs such as sepsis , where most of the traces have unique control-follow
related behavior in the original event log, trace-based sampling methods are faster.
furthermore, by considering the sampling phase as a preprocessing step, we
are able to reduce the required time to discover a process model for most of the
event logs. v ariant-based methods need more time to perform the sampling becausethey need to discover variants among traces. however, they usually have a higher
improvement the total required time for discovering process (i.e.,
samplingtime +
disco ver yt ime sampledlog ).
123the impact of biased sampling of event logs on the…
fig. 5 the number of remained traces in the sampled event logs when we used variant and trace-based
sampling with c equals to 5 and 20. for event logs that have frequent variants the trace reduction is more
fig. 6 comparing the average of total discovery time of using variant sampling methods and event log
ﬁltering methods
sampling methods improve the performance of process discovery by ﬁrst reducing
the number of traces and also decreasing the behaviors in the event log. the required
time for process discovery algorithms depends on different factors. in ilp miner,
this time is mainly related to the number of activities and the number of uniquevariants in the event log that sampling can reduce both of them. however, in the
family of alpha miner and split miner, we ﬁrstly discover possible directly follow
relations and then create a process model from these relations. for these algorithms,we increase the performance of process discovery by reducing the number of possible
directly follow relations. in inductive miner, we iteratively divide the process to block
structured sub-processes. hence, in each step, we aim to divide the event log and ﬁndthe corresponding directly follow relation of the sub-event log. sampling reduces the
number of possible directly follow relations and the number of process instances in
the event log which leads to the performance improvement of process discovery usinginductive miner.
figure 4shows how many behaviors (here the directly follows) are reduced in the
sampled event logs. figure 5indicates the average number of traces in the sampled
event log using trace/event sampling. for most of the event logs, if we use variant-
based sampling, the size of the event logs (i.e., |l|) is reduced signiﬁcantly. also,
the number of remaining variants in sampled event logs is reduced to 5–20% of the
number of variants in the original event log (i.e., |
l|).
in fig. 6, we compared variant-based sampling methods and event log ﬁltering
methods on their ability to improve process discovery performance. in this experi-
ment, two automated event log ﬁltering methods are considered to be anomaly-free
automaton (afa) [ 16] and matrix filter (mf) [ 10]. for some even logs, because of
123m. fani sani et al.
fig. 7 analyzing the f-measure similarity of discovered process models with/without sampling using eq. 8.
for the cases with values higher than 1, the f-measure of discovered process models are higher when we
used the sampled event logs
fig. 8 the average sampling time for different sampling strategies. the random method is the fastest and
the structure method is the slowest sampling method
some technical problems, we could not ﬁlter the event log using the afa method.
results show that variant-based sampling reduces the total discovery time.
5.3.2 (q3)
here, we aim to analyze the quality of discovered process models from sampled event
logs. for this purpose, we use ﬁtness andprecision . fitness measures what percentage
of event log’s behaviors are also replayable by the process model. thus, a ﬁtness
value equals to 1, indicates all the behaviors in the event log, are described by theprocess model. precision measures to what extend behaviors that are described by
the process model are also presented in the event log. a low precision value means
that the process model allows for more behaviors compared to the event log. thereis a trade-off between these measures [ 39], sometimes, putting aside a small amount
of behavior causes a slight decrease in the ﬁtness value, whereas the precision value
increases dramatically. thus, we use the f-measures metric that combines both of
them.
f-measure =2×precision ×fitness
precision +fitness(7)
123the impact of biased sampling of event logs on the…
in fig. 7, we compared the quality of best process models that are discovered
with/without sampling according to the following formula.
f-measure similarity =f-measure sampledlog
f-measure who lelo g(8)
we used sampled event logs just for discovery purpose, and the original event logs were
used for computing the f-measure. for process models that are discovered without
sampling methods, we iterate the experiment with 100 different embedded ﬁltering
parameter(s) and considering their best f-measure (just for inductive miner and splitminer). we do not consider alpha miner algorithms, because they usually result in
unsound process models that we are not able to ﬁnd their corresponding f-measure.
note that, for some event logs (e.g., bpi- 2017-all), we could not compute the
f-measure of process models. an f-measure
similarity >1 means that sampling
methods increase the quality of the corresponding discovered process model (evencompared to the cases that we used process discovery algorithms with their ﬁltering
mechanism). note that, we did not use ﬁltering mechanisms of the process discovery
algorithm for sampled event logs. for some event logs, sampling methods can increasethe quality of discovered process models, speciﬁcally, if we use inductive miner.
it shows the weakness of process discovery algorithms in dealing with infrequent
behaviors [ 10].
by applying variant-based sampling methods, we will lose the frequency of variants.
as a result, some embedded ﬁltering mechanisms in process discovery algorithms
become unusable. however, the results of this experiment show that we can discoverprocess models with high quality from sampled event logs, even without these ﬁltering
methods. if for any reason we need to use frequency of variants, it is recommended to
apply trace-based sampling methods.
5.3.3 (q4)
here, we want to compare different variant biased sampling strategies. in fig. 8
the average of the sampling time (in milliseconds) for different variant-based sam-
pling strategies is shown. the random sampling is the fastest strategy as it does not
need to rank variants, and the structure-based sampling is the slowest one. after the
structure-based sampling, the similarity-based sampling and the hybrid sampling that
use directly follows relations are slower than other strategies. table 2compares the
quality of the process models that are discovered using these sampling methods. for
some combinations, we could not compute the f-measure in the speciﬁc time, and
their corresponding cell in the table is empty. results show that no unique samplingmethod results in process models with the highest possible f-measure for all process
discovery algorithms.
5.3.4 (q5)
finally, we analyzed the impact of the sampling threshold (i.e., c) on the sampling and
process discovery time. thus, we sampled road event log with cin[0.05,0.1,0.15,
123m. fani sani et al.table 2 the best f-measure of discovered process models using different process discovery algorithms and different variant-based sampling strategies
discovery event log frequency hybrid longer random shorter similar structure
ilp bpic_2012 0.77 0.77 0.44 0.69
bpic_2017_offer 0.70 0.99 0.98 0.93 0.93 0.99 0.99
bpic_2018_control 0.99 1.00 0.99 0.99 1.00 1.00 1.00
bpic_2018_reference 0.92 0.99 0.92 0.96 0.99 0.96 0.96
hospital 0.59 0.90 0.60 0.81 0.85 0.90 0.90
road 0.70 0.88 0.87 0.92 0.91 0.91 0.91
sepsis 0.44 0.80 0.43 0.81 0.51 0.46 0.46
inductive bpic_2012 0.73 0.77 0.75 0.77 0.73 0.66 0.66
bpic_2013 0.87 0.93 0.95 0.93 0.96 0.95 0.95
bpic_2017_offer 0.98 0.99 0.98 0.94 0.94 0.93 0.93
bpic_2018_control 1.00 1.00 0.97 1.00 0.97 1.00 1.00
bpic_2018_reference 0.96 1.00 0.93 0.96 0.96 0.99 0.99
hospital 0.90 0.81 0.90 0.90 0.90
road 0.92 0.93 0.92 0.92 0.93 0.94 0.94
sepsis 0.73 0.81 0.71 0.76 0.82 0.75 0.75
split bpic_2012 0.81 0.81 0.79 0.85 0.81 0.81 0.81
bpic_2013 0.96 0.96 0.96 0.96 0.96 0.96 0.96
bpic_2017_offer 1.00 0.99 0.98 0.93 0.93 0.96 0.96
bpic_2018_control 1.00 0.97 0.97 0.97 0.97 0.97 0.97
bpic_2018_reference 0.96 0.96 0.96 0.96
hospital 0.81
road 0.88 0.93 0.88 0.88
sepsis 0.75 0.75
123the impact of biased sampling of event logs on the…
fig. 9 the median of the sampling and discovery time for sampling road event log using different sampling
thresholds
0.2,0.3,0.5,0.8]and using the basic inductive miner for process discovery. this
experiment was repeated 10 times, and the median values are shown in fig. 9.w e
have not considered the hybrid method as its results are similar to frequency based forthis event log. in variant-based sampling, except for the random sampling, the sam-
pling time is independent of the sampling threshold. because in biased variant-based
sampling methods, most of the sampling time goes for ranking the variants. it is also asimilar case for trace-based samplings. structured-based sampling bias is the slowest
among the other biases. in variant-based sampling, the discovery time is dramatically
faster than traced-based sampling. among trace-based sampling methods, structuredand frequency-based strategies are faster than others.
the experimental results show that using biased sampling methods, we are able
to improve the performance of process discovery procedure and it is possible to havethis improvement when different process discovery algorithms are applied. as in most
of the cases, there will be fewer traces in the sampled event logs using variant-based
sampling methods, the improvement in the performance of process discovery is higherusing the variant-based approaches. moreover, results show that the process models
that are discovered using sampled event logs have similar quality compared to the
case that the original event logs are used (considering f-measure metric). there are
some cases that the sampling approach improves the quality of discovered models. in
addition, considering different sampling strategies, we could not ﬁnd a strategy thatalways results in the highest process model quality. however, the hybrid approach
results in process models with high quality on the used event logs. according to the
sampling time, the random strategy outperforms other ones and the structure strategyhas the lowest performance. finally, results indicate that the sampling threshold mainly
affects the discovery time when the trace-based approaches are used. also, results show
that sampling time is independent of the sampling threshold.
123m. fani sani et al.
6 conclusion
in this paper, we proposed several variant and trace-based sampling strategies to
increase the performance of the process discovery procedure. we recommend apply-
ing process discovery algorithms on the sampled event logs, especially when dealing
with large or complex event logs. we implemented different sampling strategies inprom and rapidprom. then, we applied them on many real event logs using different
process discovery algorithms. experimental results showed that sampling an event
log decreases the required time used by state-of-the-art process discovery algorithms.we found out that variant-based sampling approach results in considerably higher
process discovery performance improvement compared to the trace-based approach.
results showed that by applying sampling methods, we are able to discover acceptableapproximations of ﬁnal process models in a short time. moreover, results indicated
that, for some event logs, sampling methods can also improve the quality of discovered
process models according to the f-measure metric.
as future work, we aim to deﬁne more computationally affordable ranking
strategies. furthermore, we are interested in ﬁnding out the best sampling strategy
considering the process discovery quality and performance when dealing with differ-
ent event logs and process discovery algorithms.
acknowledgements we thank the alexander von humboldt (avh) stiftung for supporting this research.
funding open access funding enabled and organized by projekt deal.
open access this article is licensed under a creative commons attribution 4.0 international license, which
permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give
appropriate credit to the original author(s) and the source, provide a link to the creative commons licence,
and indicate if changes were made. the images or other third party material in this article are includedin the article’s creative commons licence, unless indicated otherwise in a credit line to the material. if
material is not included in the article’s creative commons licence and your intended use is not permitted
by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the
copyright holder. to view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/ .
references
1. van der aalst wmp (2016) process mining—data science in action, 2nd edn. springer, berlin
2. pourbafrani m, van zelst sj, van der aalst wmp (2020) supporting automatic system dynamics model
generation for simulation in the context of process mining. in: abramowicz w, klein g (eds) businessinformation systems. springer, cham, pp 249–263
3. park g, song m (2020) predicting performances in business processes using deep neural networks.
decis support syst 129:113191
4. van der aalst wmp et al (2011) process mining manifesto. in: business process management bpm
workshops, clermont-ferrand, france, pp 169–194
5. v erbeek hmw, buijs jcam, van dongen bf, van der aalst wmp (2010) xes, xesame, and prom 6. in
soffer p , proper e (eds) information systems evolution-caise forum 2010, hammamet, tunisia, june
7–9, 2010, selected extended papers. v olume 72 of lecture notes in business information processing.
springer, pp 60–75
6. van der aalst wmp , bolt a, van zelst s (2017) rapidprom: mine your processes and not just your
data. corr abs/1703.03740
123the impact of biased sampling of event logs on the…
7. fani sani m, van zelst sj, van der aalst wmp (2019) the impact of event log subset selection on the
performance of process discovery algorithms. in: new trends in databases and information systems,
adbis 2019 short papers, workshops bbigap , qauca, sembdm, simpda, m2p , madeisd, and
doctoral consortium, bled, slovenia, september 8–11, 2019, proceedings. v olume 1064 of communi-cations in computer and information science. springer, pp 391–404
8. van der aalst wm, weijters t, maruster l (2004) workﬂow mining: discovering process models from
event logs. ieee trans knowl data eng 16(9):1128–1142
9. leemans sjj, fahland d, van der aalst wmp (2013) discovering block-structured process models
from event logs—a constructive approach. in colom jm, desel j (eds) application and theory of petrinets and concurrency—34th international conference, petri nets 2013, milan, italy, june 24–28,
2013, proceedings. v olume 7927 of lecture notes in computer science. springer, pp 311–329
10. fani sani m, van zelst sj, van der aalst wmp (2017) improving process discovery results by ﬁltering
outliers using conditional behavioural probabilities. in: business process management workshops—
bpm 2017, barcelona, spain, september 10–11, 2017, revised papers. v olume 308 of lecture notes in
business information processing. springer, pp 216–229
11. augusto a, conforti r, dumas m, rosa ml, polyvyanyy a (2019) split miner: automated discovery
of accurate and simple business process models from event logs. knowl inf syst 59(2):251–284
12. leemans sjj, fahland d, van der aalst wmp (2013) discovering block-structured process models
from event logs containing infrequent behaviour. in lohmann n, song m, wohed p (eds) business
process management workshops-bpm 2013 international workshops, beijing, china, august 26, 2013,
revised papers. v olume 171 of lecture notes in business information processing. springer, pp 66–78
13. van zelst sj, van dongen bf, van der aalst wmp (2015) avoiding over-ﬁtting in ilp-based process
discovery. in motahari-nezhad hr, recker j, weidlich m (eds) business process management—13th
international conference, bpm 2015, innsbruck, austria, august 31–september 3, 2015, proceedings.
v olume 9253 of lecture notes in computer science. springer, pp 163–171
14. pegoraro m, uysal ms, van der aalst wmp (2019) discovering process models from uncertain event
data. in: business process management workshops-bpm 2019 international workshops, vienna, aus-tria, september 1–6, 2019, revised selected, pp 238–249
15. horita h, kurihashi y , miyamori n (2020) extraction of missing tendency using decision tree learning
in business process event log. data 5(3):82
16. conforti r, rosa ml, ter hofstede ahm (2017) filtering out infrequent behavior from business
process event logs. ieee trans knowl data eng 29(2):300–314
17. fani sani m, van zelst sj, van der aalst wmp (2018) applying sequence mining for outlier detection in
process mining. in: on the move to meaningful internet systems. otm 2018 conferences-confederated
international conferences: coopis, c&tc, and odbase 2018, v alletta, malta, october 22–26, 2018,proceedings, part ii. v olume 11230 of lecture notes in computer science. springer, pp 98–116
18. fani sani m, van zelst sj, van der aalst wmp (2018) repairing outlier behaviour in event logs using
contextual behaviour. inf syst arch 14:5:1-5:24
19. conforti r, la rosa m, ter hofstede ah, augusto a (2020) automatic repair of same-timestamp
errors in business process event logs. in: international conference on process mining, icpm 2020,padua, italy, october 4–9, 2020. ieee, pp 327–345
20. sadeghianasl s, ter hofstede ah, suriadi s, turkay s (2020) collaborative and interactive detection
and repair of activity labels in process event logs. in: international conference on process mining,
icpm 2020, padua, italy, october 4–9, 2020. ieee, pp 41–48
21. tax n, sidorova n, van der aalst wmp (2019) discovering more precise process models from event
logs by ﬁltering out chaotic activities. j intell inf syst 52(1):107–139
22. dees m, hompes b, van der aalst wm (2020) events put into context (epic). in: international confer-
ence on process mining, icpm 2020, padua, italy, october 4–9, 2020. ieee, pp 65–72
23. fani sani m, berti a, van zelst sj, van der aalst wmp (2019) filtering toolkit: interactively ﬁlter event
logs to improve the quality of discovered models. in: proceedings of the dissertation award, doctoral
consortium, and demonstration track at on business process management bpm 2019, vienna, austria,
september 1–6, 2019. v olume 2420 of ceur workshop proceedings. ceur-ws.org, pp 134–138
24. fani sani m, van zelst sj, van der aalst wmp (2020) conformance checking approximation using
subset selection and edit distance. in: advanced information systems engineering-32nd international
conference, caise 2020, grenoble, france, june 8–12, 2020, proceedings. v olume 12127 of lecture
notes in computer science. springer, pp 234–251
123m. fani sani et al.
25. raﬁei m, van der aalst wmp (2020) privacy-preserving data publishing in process mining. in: business
process management forum-bpm forum 2020, seville, spain, september 13–18, 2020, proceedings.
v olume 392 of lecture notes in business information processing. springer, pp 122–138
26. carmona j, cortadella j (2010) process mining meets abstract interpretation. in balcázar jl, bonchi f,
gionis a, sebag m (eds) machine learning and knowledge discovery in databases, european cconfer-
ence, ecml pkdd 2010, barcelona, spain, september 20–24, 2010, proceedings, part i. v olume
6321 of lecture notes in computer science. springer, pp 184–199
27. bauer m, senderovich a, gal a, grunske l, weidlich m (2018) how much event data is enough?
a statistical framework for process discovery. in krogstie j, reijers ha (eds) advanced informationsystems engineering-30th international conference, caise 2018, tallinn, estonia, june 11–15, 2018,
proceedings. v olume 10816 of lecture notes in computer science. springer, pp 239–256
28. berti a (2017) statistical sampling in process mining discovery. in: the 9th international conference
on information, process, and knowledge management, pp 41–43
29. weijters ajmm, ribeiro jts (2011) flexible heuristics miner (fhm). in: proceedings of the ieee
symposium on computational intelligence and data mining, cidm 2011, april 11–15, 2011, paris,
france. ieee, pp 310–317
30. fani sani m, van zelst sj, van der aalst wmp (2018) repairing outlier behaviour in event logs. in
abramowicz w, paschke a (eds) business information systems-21st international conference, bis
2018, berlin, germany, july 18–20, 2018, proceedings. v olume 320 of lecture notes in business infor-
mation processing. springer, pp 115–131
31. van dongen bf (2012) bpic 2012. eindhoven university of technology
32. ward steeman: bpic 2013. eindhoven university of technology (2013)33. van dongen bf (2017) bpic 2017. eindhoven university of technology
34. van dongen b, borchert f (2018) bpic 2018. eindhoven university of technology
35. mannhardt f (2017) hospital billing-event log. eindhoven university of technology. dataset 326–347
36. de leoni m, mannhardt f (2015) road trafﬁc ﬁne management process
37. mannhardt f (2016) sepsis cases-event log. eindhoven university of technology38. van zelst s, van dongen b, van der aalst wmp , v erbeek hmw (2017) discovering workﬂow nets
using integer linear programming. computing
39. weerdt jd, backer md, v anthienen j, baesens b (2011) a robust f-measure for evaluating discovered
process models. in: proceedings of the ieee symposium on computational intelligence and data mining,
cidm 2011, part of the ieee symposium series on computational intelligence 2011, april 11–15, 2011,
paris, france. ieee, pp 148–155
publisher’s note springer nature remains neutral with regard to jurisdictional claims in published maps
and institutional afﬁliations.
123