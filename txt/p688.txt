on the role of fitness, precision, generalization
and simplicity in process discovery
j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst
eindhoven university of technology, the netherlands
(j.c.a.m.buijs|b.f.v.dongen|w.m.p.v.d.aalst)@tue.nl
abstract. process discovery algorithms typically aim at discovering
process models from event logs that best describe the recorded behavior.
often, the quality of a process discovery algorithm is measured by quan-
tifying to what extent the resulting model can reproduce the behavior
in the log, i.e. replay tness. at the same time, there are many other
metrics that compare a model with recorded behavior in terms of the
precision of the model and the extent to which the model generalizes the
behavior in the log. furthermore, several metrics exist to measure the
complexity of a model irrespective of the log.
in this paper, we show that existing process discovery algorithm typ-
ically consider at most two out of the four main quality dimensions:
replay tness ,precision ,generalization and simplicity . moreover, exist-
ing approaches can not steer the discovery process based on user-dened
weights for the four quality dimensions.
this paper also presents the etm algorithm which allows the user to
seamlessly steer the discovery process based on preferences with respect
to the four quality dimensions. we show that all dimensions are im-
portant for process discovery. however, it only makes sense to consider
precision, generalization and simplicity if the replay tness is acceptable.
1 introduction
the goal of process mining is to automatically produce process models that
accurately describe processes by considering only an organization's records of its
operational processes. such records are typically captured in the form of event
logs, consisting of cases and events related to these cases.
over the last decade, many such process discovery techniques have been
developed, producing process models in various forms, such as petri nets, bpmn-
models, epcs, yawl-models etc. furthermore, many authors have compared
these techniques by focussing on the properties of the models produced, while
at the same time the applicability of various techniques have been compared in
case-studies.
figure 1 shows four quality dimensions generally used to discuss results of
process discovery techniques, namely:
replay tness. replay tness quanties the extent to which the discovered
model can accurately reproduce the cases recorded in the log. typical al-
gorithms guaranteeing perfect replay tness are region-based approaches [7,‚Äúable to replay event log‚Äù ‚Äúoccam‚Äôs razor‚Äù
‚Äúnot overfitting the log‚Äù ‚Äúnot underfitting the log‚Äùfig. 1: dierent quality dimensions for process model discovery [3]
21] and the multi-phase miner [10]. other techniques, such as the heuristics
miner [19] and some genetic algorithms [14] use replay tness as their guiding
principle when discovering a process model, but do not guarantee optimal
results.
simplicity. the complexity of a process model is captured by the simplicity
dimension. process discovery algorithms often result in spaghetti-like process
models [3], which are process models that are very hard to read. a class of
process discovery algorithms that strongly focusses on simplicity is the class
of-algorithms [3, 11, 20], derived from the original algorithm [5]. these
discovery techniques generally result in simple models, but with poor replay
tness and/or precision.
precision. it is trivial to discover a simple process model that can reproduce
the event log. such a model is generally referred to as the ower-model
[16] and is an extreme example of an undertting process model. a ower
model is able to produce any arbitrary nite sequence of events. therefore,
precision quanties the fraction of the behavior allowed by the model which
is not seen in the event log. the region-based algorithms mentioned before
[7, 21] are good examples of algorithms that guarantee optimal precision, i.e.
they guarantee to allow only minimally more behavior than seen in the log.
generalization. finally, generalization assesses the extent to which the re-
sulting model will be able to reproduce future behavior of the process. in
that sense, generalization can also be seen as a measure for the condence
on the precision. consider for example a very precise model that captures
each individual case in the log as a separate path in the model. if there are
many possible paths, it is unlikely that the next case will t. examples of
generalizing algorithms are the fuzzy miner [13] and the heuristics miner
[19].
the overview above shows that many process discovery algorithms focus on
one or two of the dimensions. however, none of these algorithms is able to guide
the result towards a particular dimension.
in this paper, we also present the etm algorithm, which is a genetic al-
gorithm able to optimize the process discovery result towards any of the four
dimensions. by making use of so-called process trees [8] this algorithm ensures
that the resulting model is a sound process model describing the observed log,
while at the same time, the model is optimal with respect to a weighted aver-
age over replay tness, simplicity, precision and generalization . using the etm
2algorithm, we can easily explore the eects of focussing on one dimension in
isolation and on combinations of these dimensions.
the remainder of this paper is structured as follows. in section 2, we present
our etm algorithm. furthermore, we present one metric for each of the four
quality dimensions and we present process trees as a convenient means of mod-
eling sound process models. in section 3, we then present a running example
which we use throughout the remainder of the paper. using this example, we
show the quality of various existing process discovery algorithms in terms of the
presented metrics. section 4 then shows the results of focussing on a subset of the
quality dimensions during process discovery. here, we use our etm algorithm to
show that such a narrow focus results in poor models. section 5 shows the result
when considering all dimensions. in section 6 we apply existing techniques and
our etm algorithm on several real life event logs. section 7 concludes the paper.
2 process trees and the etm algorithm
as stated in the introduction, we use the etm algorithm to see the eects of
(not) considering either of the four quality dimensions in process discovery. to
this end, we rst introduce process trees, which we use throughout the paper.
2.1 process trees
traditional languages like bpmn, petri nets, uml activity diagrams may be
convenient ways of representing process models. however, only a small fraction
of all possible models in these languages is sound , i.e. many models contain
deadlocks, livelocks and other anomalies. especially for the results presented in
this paper, where the focus is on measuring the quality of the resulting models,
it is essential that such unsound constructs are avoided. therefore, we choose to
useprocess trees to describe our models since all possible process trees represent
sound process models.
figure 2 shows the possible operators of a process tree and their translation
to a petri net. a process tree contains operator nodes and leaf nodes. operator
nodes specify the relation between its children. possible operators are sequence
(!), parallel execution ( ^), exclusive choice ( ), non-exclusive choice ( _) and
loop execution (	). the order of the children matters for the operators sequence
and loop. the order of the children of a sequence operator specify the order in
which they are executed (from left to right). for a loop, the left child is the `do'
part of the loop. after the execution of this `do' part the right child, the `redo'
part, might be executed. after this execution the `do' part is again enabled.
the loop in fig. 2 for instance is able to produce the traces hai,ha;b;ai,
ha;b;a;b;aiand so on.
although also making use of a tree structure, a slightly dierent approach is
taken by the rened process structure tree (rpst) [17]. the rpst approach
provides \a modular technique of workow graphs parsing to obtain ne-grained
fragments with a single entry and single exit node" [17]. the content of these
3a
b
ba
a
ba
bsequence
exclusive choice
loopparallellism
or choicea b
fig. 2: relation between process trees and block-structured petri nets.
fragments are graphs themselves and are not necessarily block-structured nor
sound. each operator in a process tree however results in a block structured
process part with a single entry and single exit node. however, each block in
a process tree can only contain a predened control ow construct, which are
shown in figure 2. therefore, workow graphs decomposed into an rpst can
be more expressive than a process tree but an rpst is not necessarily sound
while a process tree always is.
2.2 quality of process trees
to measure the quality of a process tree, we consider one metric for each of
the four quality dimensions. we based these metrics on existing work in each of
the four areas and we adopted them for process trees [1{3, 6, 9, 16]. we do not
present the precise formulae that compute the values of these metrics here, as
they do not matter for the results in this paper.
replay tness quanties the extent to which the model can reproduce the
traces recorded in the log. we use an alignment-based tness computation
dened in [6] to compute the tness of a process tree. basically, this tech-
nique aligns as many events as possible from the trace with activities in an
execution of the model (this results in a so-called alignment ). if necessary,
events are skipped, or activities are inserted without a corresponding event
present in the log. penalties are given for skipping and inserting activities.
the nal replay tness score is calculated as follows:
qrf= 1 cost for aligning model and event log
minimal cost to align arbitrary event log on model and vice versa
where the denominator is the minimal costs when no match between event
log and process model can take place (e.g. worst case scenario). this is used
to normalize the replay tness to a value between 0 and 1.
simplicity quanties the complexity of the model. simplicity is measured by
comparing the size of the tree with the number of activities in the log. this
4is based on the nding that the size of a process model is the main factor
for perceived complexity and introduction of errors in process models [15].
furthermore, since we internally use binary trees, the number of leaves of the
process tree has a direct inuence on the number of operator nodes. thus, if
each activity is represented exactly once in the tree, that tree is considered
to be as simple as possible. therefore, simplicity is calculated as follows:
qs= 1 #duplicate activities + #missing activities
#nodes in process tree + #event classes in event log
precision compares the state space of the tree execution while replaying the log.
our metric is inspired by [1] and counts so-called escaping edges, i.e. decisions
that are possible in the model, but never made in the log. if there are no
escaping edges, the precision is perfect. we obtain the part of the statespace
used from information provided by the replay tness, where we ignore events
that are in the log, but do not correspond to an activity according to the
alignment. in short, we calculate the precision as follows:
qp= 1 p
visited markings#visits#outgoing edges  #used edges
#outgoing edges
#total marking visits over all markings
generalization considers the frequency with which each node in the tree needs
to be visited if the model is to produce the given log. for this we use the
alignment provided by the replay tness. if a node is visited more often then
we are more certain that its behavior is (in)correct. if some parts of the tree
are very infrequently visited, generalization is bad. therefore, generalization
is calculated as follows:
qg= 1 p
nodes(p#executions) 1
#nodes in tree
the four metrics above are computed on a scale from 0 to 1, where 1 is
optimal. replay tness, simplicity and precision can reach 1 as optimal value.
generalization however can only reach 1 in the limit i.e., the more frequent the
nodes are visited, the closer the value gets to 1. the exibility required to nd a
process model that optimizes a weighted sum over the four metrics can eciently
be implemented using a genetic algorithm.
2.3 the etm algorithm
as discussed in section 1 we propose the use of a genetic algorithm for the
discovery of process models from event logs. evolutionary algorithms have been
applied to process mining discovery before in [4, 14]. our approach follows the
same high-level steps as most evolutionary algorithms [12], which are shown
in figure 3. the main improvements with respect to [4, 14] are the internal
representation and the tness calculations. by using a genetic algorithm for
process discovery we gain exibility: by changing the weights of dierent tness
factors we can guide the process discovery.
5by using process trees as our internal representation we only consider sound
process models . this drastically reduces the search space and therefore improves
the performance of the genetic algorithm. furthermore, we can apply standard
tree change operations on the process trees to evolve them further. finally, in our
tness calculation we consider all four quality dimensions for process models:
replay tness, precision, generalization and simplicity. the user can specify the
relative importance of each dimension beforehand . the etm algorithm (which
stands for evolutionary tree miner ) will then favor those candidates that have
the correct mix of the dierent quality dimensions.
in general, our genetic algorithm follows the process as shown in fig. 3.
the input of the algorithm is an event log describing observed behavior. in the
initial step a population of random process trees is generated where each activity
occurs exactly once in each tree. next the four quality dimensions are calculated
for each candidate in the population. using the weight given to each dimension
theoverall tness of the process tree is calculated. in the next step certain stop
criteria are tested such as nding a tree with the desired overall tness. if none of
the stop criteria are satised, the candidates in the population are changed and
the tness is again calculated. this is continued until at least one stop criterion
is satised and the ttest candidate is then returned.
our genetic algorithm has been implemented as a plug-in for the prom frame-
work [18]. we used this implementation for all experiments presented in the re-
mainder. the algorithm stops as soon as a perfect candidate was found, i.e. with
optimal tness, or after 1 :000 generations. in [8] we have shown that 1 :000 gener-
ations are typically enough to nd the optimal solution, especially for processes
with few activities. all other settings were selected according to the optimal
values presented in [8].
3 running example
throughout the paper, we use a running example, describing a simple loan appli-
cation process of a nancial institute, providing small consumer credit through
a webpage. when a potential customer lls in a form and submits the request
on the website, the process is started by activity awhich is sending an e-mail
to the applicant to conrm the receipt of the request. next, three activities are
executed in parallel. activity bis a check of the customer's credit history with a
result
fig. 3: the dierent phases of the genetic algorithm.
6table 1: the event log
trace # trace #
a b c d e g 6a d b c f g 1
a b c d f g 38 a d b c e g 1
a b d c e g 12 a d c b f g 4
a b d c f g 26 a c d b f g 2
a b c f g 8a c b f g 1
a c b e g 1
fig. 4: petri net of a loan application
process. ( a= send e-mail, b= check
credit, c= calculate capacity, d= check
system, e= accept, f= reject, g= send
e-mail)
registration agency. activity cis a computation of the customer's loan capacity
and activity dis a check whether the customer is already in the system. this
check is skipped if the customer lled in the application while being logged in
to the personal page, since then it is obsolete. after performing some computa-
tions, the customer is notied whether the loan was accepted (activity e, covering
about 20% of the cases) or rejected (activity f, covering about 80% of the cases).
finally, activity gis performed, notifying the applicant of the outcome.
a petri net of the loan application model is shown in figure 4 and the log
we obtained through simulation is shown in table 1.
3.1 results of process discovery algorithms
in order to validate that our small example provides enough of a challenge for
existing process discovery techniques, we applied several existing techniques,
many of which resulted in unsound process models. we translated the behavior
of each model to a process tree, in order to measure the quality of the result.
where applicable, we stayed as close as possible to the parallel behavior of the
original model. figures 5 to 11 show the results of the various algorithms.
figures 5 to 11 clearly indicate that, on our small example, only the -
algorithm was able to balance the four quality dimensions well. several algo-
rithms even produce an unsound result. moreover, the -algorithm was \lucky"
for this small example. in general, this algorithm produces models that are not
tting or not precise. therefore, in section 4, we rst investigate combining var-
ious dimensions and show that all of them have to be considered in order to
discover a sound, easy to understand process model, accurately describing the log
!
!
g
fe!
^
^
dcbaf: 0,992 p: 0,995
s: 1,000 g: 0,889
fig. 5: result of the algorithm [5] (sound)
7!
!
g
fe!
^
^

dcbaf: 1,000 p: 0,784
s: 0,933 g: 0,830
fig. 6: result of the ilp miner [21] (ensuring empty net after completion, sound)
!
^
!
!
g
fe^
cbda f: 0,992 p: 0,957
s: 1,000 g: 0,889
fig. 7: result of the language-based region theory [7] (the model is overly com-
plex and incomprehensible, but sound)
!
!
g
fe!
^
d^
cb^
cbaf: 1,000 p: 0,986
s: 0,875 g: 0,852
fig. 8: result of the heuristic miner [19] (unsound, tokens are left behind.)
!
!
g
fe!
_
_
dcbaf: 1,000 p: 0,830
s: 1,000 g: 0,889
fig. 9: result of the multi-phase miner [10] (model is guaranteed \relaxed sound"
and the tree reects this.)
!
g!
^
b
!
fec
!
e^
dc^
d!
fca f: 1,000 p: 0,922
s: 0,737 g: 0,790
fig. 10: result of the genetic miner [14] (unsound, tokens left behind.)
8!
!
g
fe!
^
^
dcbaf: 1,000 p: 0,893
s: 0,933 g: 0,830
fig. 11: result of the state-based region theory [21]
under consideration . next, in section 6, we show that only our etm algorithm
is able to balance all quality dimensions for real life event logs.
4 ignoring quality dimensions
the examples shown in gures 5 to 11 show that various existing process mining
techniques perform dierently on all four quality dimensions and they often
provide unsound models. in this section, we use the etm algorithm to discover
a process model on the given log, while varying which of the quality dimensions
should be considered. we show some optimal models that resulted from dierent
runs of the algorithm and discuss their properties.
4.1 considering only one quality dimension
fig. 12a shows an example process tree that was discovered when focussing solely
on the replay tness dimension. although the tree is able to replay the event log
perfectly, the tree allows for more behavior than is seen in the event log. since
adding parts to the process tree might improve replay tness, and removing
parts never does, the process tree will keep growing until perfect replay tness is
reached. this is bad for simplicity since activities will be duplicated (activities b
anddin fig. 12a) and certain parts of the tree will never be used (the rightmost
band the leftmost dare never used when replaying the event log).
in order to obtain trees that do not allow for behavior that is not observed
in the event log, we considered only the precision dimension in the genetic al-
gorithm. an example of such a tree is shown in fig. 12b, which has a perfect
precision because it can only generate the trace hc;b;ci. a process tree will
have perfect precision if each trace it can generate is used in an alignment. since
the tree of fig. 12b can only generate one trace, each alignment between event
log and the tree, will use this path of execution. however, the low replay tness
score indicates that the tree in fig. 12b has little to do with the behavior that
is recorded in the event log.
when only considering simplicity , we get trees such as the one in fig. 12c,
where each activity is included exactly once. however, the tree does not really
describe the observed process executions in the event log well, which is indicated
by the low scores on replay tness and precision.
9generalization measures the likeliness that a model contains future, not yet
observed behavior. when focussing solely on generalization, fig. 12d shows the
process tree that has the best generalization score. as mentioned before, general-
ization cannot reach 1, as this would require all possible behavior to be observed
innitely often. since generalization takes the number of node visits into ac-
count, the score is improved if nodes are visited more often, where the visits are
again measured on the closest matching execution of the model for each trace.
by placing	operators high in the tree, and activities fand bin the `redo'
part, the loops and the nodes in the `do' part are executed more often, hence
improving generalization.
4.2 always considering replay fitness
the discussion in the previous section showed that none of the quality dimensions
should be considered in isolation. furthermore, we validated the choice of many
existing process discovery techniques to put emphasis on replay tness, i.e. if the
replay tness is not good enough, the other quality dimensions add little value
as the discovered model does not describe the recorded behavior. on the other
hand, achieving a perfect replay tness is not always necessary or desired.
when focussing on replay tness and precision , the goal is to nd a process
model that describes all traces, and not much more, much like the region-based
algorithms the results of which are depicted in figure 6, 7 and 11. in general, a
model that contains an initial exclusive choice between all unique traces in the
log has perfect precision and replay tness. each choice is taken at least once
and each trace in the event log is a sequence in the process model. this always
results in a perfect replay tness. for our running example the process tree as
^
^
_
d^
b_
e

dc^
^
ab
fg
f: 1,000 p: 0,341
s: 0,737 g: 0,681
(a) only replay tness!
c!
bcf: 0,449 p: 1,000
s: 0,400 g: 0,797
(b) only precision

g^



ead
bcff: 0,504 p: 0,587
s: 1,000 g: 0,661
(c) only simplicity
b
f_
d_
agcf: 0,961 p: 0,394
s: 0,923 g: 0,916
(d) only generalization
fig. 12: process trees discovered when considering each of the quality dimensions
separately
10shown in fig. 13a also has has both a perfect replay tness and precision. each
part of the process tree is used to replay a trace in the event log and no behavior
that is not present in the event log can be produced by the process tree. however,
since the tree is fairly big, the simplicity score is low and more importantly, the
generalization is not very high either. this implies that, although this model is
very precise, it is not likely that it explains any future, unseen behavior.
next we consider replay tness and simplicity , the result of which is shown in
fig. 13b. when considering only replay tness, we obtained fairly large models,
while simplicity should keep the models compact. the process tree shown in
fig. 13b contains each activity exactly once and hence has perfect simplicity. at
the same time all traces in the event log can be replayed. however, the process
tree contains two ^, one	and three_nodes that allow for (far) more behavior
than is seen in the event log. this is reected in the low precision score in
combination with the high generalization.
the process tree that is found when focussing on the combination of replay
tness and generalization is shown in fig. 13c. the process tree shows many
similarities with the process tree found when solely considering generalization.
activity ehas been added to the `do' part of the 	to improve the replay tness.
however, it also reduces the generalization dimension since it is only executed
20 times. furthermore, the tree is still not very precise.
in contrast to the trees in section 4.1, the various process trees discussed in
this section mainly capture the behavior observed in the event log. however, they
either are overtting (i.e. they are too specic) or they are undertting (i.e. they
!
!
g
!
f!
cb
!
ef!
bc
!
!
fb^
dc!
ef^
!
cbdaf: 1,000 p: 1,000
s: 0,560 g: 0,657
(a) replay fitness and precision
^
b^
a
e_
f_
c_
dgf: 1,000 p: 0,387
s: 1,000 g: 0,892
(b) replay fitness and simplicity
_
bf_
e_
d_
_
agcf: 1,000 p: 0,214
s: 1,000 g: 0,906
(c) replay fitness and general-
ization
fig. 13: process trees discovered when considering replay tness and one of the
other quality dimensions
11are too generic). hence, considering replay tness in conjunction with only one
other dimension still does not yield satisfying results. therefore, in section 4.3,
we consider three out of four dimensions, while never ignoring replay tness.
4.3 ignoring one dimension
we just showed that replay tness, in conjunction with one of the other quality
dimensions, is insucient to judge the quality of a process model. however, most
process discovery algorithms steer on just two quality dimensions. hence we rst
consider 3-out-of-4 dimensions.
fig. 14 shows the three process trees that are discovered when ignoring one
of the quality dimensions, but always including replay tness. fig. 14a shows the
process tree found when ignoring precision. the resulting process tree is similar
to the one in fig. 13c, which was based on replay tness and generalization only.
the only dierence is that the parent of aandghas changed from _to. since
this only inuences precision, the other metrics have the same values and both
trees have the same overall tness when ignoring precision.
the process tree which is discovered when ignoring generalization is the same
a when simplicity is ignored and is shown in fig. 14b. this is due to the fact
that both simplicity and generalization are optimal in this tree. in other words,
when weighing all four dimensions equally, this tree is the best possible process
tree to describe the process.
interestingly, this tree is the same as the result of the -algorithm (fig. 5).
however, as mentioned earlier, the -algorithm is not very robust. this will also
be demonstrated in section 6 using real life event logs.
5 weighing dimensions
the process trees shown in fig. 14 have trouble replaying all traces from the
event log while maintaining a high precision. however, since process discovery is
mostly used to gain insights into the behavior recorded in the log, it is generally
required that the produced model represents the log as accurately as possible,
i.e. that both replay tness and precision are high. by giving more weight to

_
bf_
e_
_
agdcf: 1,000 p: 0,234
s: 1,000 g: 0,906
(a) no precision!
!
!
g
fe^
d^
bca
f: 0,992 p: 0,995
s: 1,000 g: 0,889
(b) no generalization or no simplic-
ity
fig. 14: considering 3 of the 4 quality dimensions
12replay tness, while still taking precision into account, our genetic algorithm
can accommodate this importance. fig. 15 shows the process tree resulting from
our algorithm when giving 10 times more weight to replay tness than the other
three quality dimensions. as a result the process tree is able to replay all traces
from the event log while still maintaining a high precision.
let us compare this process tree with the process tree of fig. 14b, which is
also the tree produced when all quality dimensions are weighted equally. it can
be seen that the price to pay for improving tness was a reduction in precision.
this can be explained by looking at the change made to the process model:
activity dis now in an_relation with activities bandc. replay tness is hereby
improved since the option to skip activity dis introduced. however, the process
tree now also allows for skipping the execution of both bandc. something which
is never observed in the event log.
furthermore, the process tree of figure 15 performs better than the model
we originally used for simulating the event log as can be seen in figure 16.
the original tree performs equal on replay tness but worse on the other three
quality dimensions. precision is worse because the state space of the original
model is bigger while less paths are used. simplicity is also worse because an
additionalnode is used in the original tree, hence the tree is two nodes bigger
than optimal. furthermore, since the node is only executed ten times, the
generalization reduces as well because the other nodes are executed more than
10 times, thus the average visits per node decreases.
6 experiments using real life event logs
in the previous sections we discussed the results of various existing process dis-
covery techniques on our running example. we also demonstrated that all four
quality dimensions should be considered when discovering a process model. in
this section we apply a selection of process discovery techniques, and our etm
algorithm, on 3 event logs from real information systems. using these event logs,
and the running example, we show that our etm is more robust than existing
process discovery techniques.
in this section we consider the following event logs:
f: 1,000 p: 0,923
s: 1,000 g: 0,889!
!
g!
fe_
d^
cba
fig. 15: process tree discovered when
replay tness is 10 times more impor-
tant than all other dimensionsf: 1,000 p: 0,893
s: 0,933 g: 0,830!
!
g!
fe^
^
bc
da
fig. 16: process tree of the model used
for simulation (translated manually
from figure 4)
13table 2: petri net properties of discovered models.
legend: s?: whether the model is sound ( x) or unsound ( 7);
#p: number of places; #t: number of transitions; #arcs: number of arcs
l0 l1 l2 l3
s?#p#t#arcs s?#p#t#arcs s?#p#t#arcs s?#p#t#arcs
-algorithmx97 20x36 4x36 4x66 10
ilp minerx77 19x46 9x26 11x46 9
heuristics 71212 30x1215 28x1216 3271011 23
genetic 7109 2171320 4271120 3671011 25
1. the event log l0is the event log as presented in table 1. l0 contains 100
traces, 590 events and 7 activities.
2.event log l1 contains 105 traces, 743 events in total, with 6 dierent
activities.
3.event log l2 contains 444 traces, 3 :269 events in total, with 6 dierent
activities.
4.event log l3 contains 274 traces, 1 :582 events in total, with 6 dierent
activities.
event logs l1, l2 and l3 are extracted from information systems of munici-
palities participating in the coselog1project. since some of the existing pro-
cess discovery techniques require a unique start and end activity, all event logs
have been ltered to contain only those traces that start with the most common
start activity and end with the most common end activity. furthermore, activity
names have been renamed to the letters a. . .f.
from the process discovery algorithms discussed in section 3.1 we selected
four well-known algorithms: the -algorithm [5], the ilp-miner [21], the heuris-
tics miner [19] and the genetic algorithm by alves de medeiros [14]. because we
do not have enough space to show all process models we show some important
characteristics of the resulting petri nets in table 2.
the-algorithm and ilp miner produce sound petri nets for each of the 4
input logs. the genetic miner however never produces a sound petri net and
the heuristics miner produces a sound solution for 2 out of the 4 event logs.
for each of the discovered petri nets we created process tree representations,
describing the same behavior. if a petri net was unsound, we interpreted the
sound behavior as closely as possible. for each of these process trees the evalua-
tion of each of the 4 metrics, and the overall average tness, is shown in table 3.
for event log l1 both the -algorithm and the ilp miner nd process models
that can replay all behavior. but, as is also indicated by the low precision, these
allow for far more behavior than observed in the event log. this is caused by
transitions without input places that can occur and arbitrary number of times.
1see http://www.win.tue.nl/coselog
14table 3: quality of process tree translations of several discovery algorithms
(italic results indicate unsound models, the best model is indicated in bold )
l0 l1 l2 l3
-algorithmf: 0,992 p: 0,995 f: 1,000 p: 0.510 f: 1.000 p: 0.468 f: 0.976 p: 0.532
s: 1,000 g: 0,889 s: 0.923 g: 0.842 s: 0.923 g: 0.885 s: 0.923 g: 0.866
overall: 0,969 overall: 0,819 overall: 0,819 overall: 0,824
ilp minerf: 1,000 p: 0,748 f: 1.000 p: 0.551 f: 1.000 p: 0.752 f: 1.000 p: 0.479
s: 0,933 g: 0,830 s: 0.857 g: 0.775 s: 0.923 g: 0.885 s: 0.857 g: 0.813
overall: 0,887 overall: 0,796 overall: 0,890 overall: 0,787
heuristicsf: 1,000 p: 0,986 f: 0.966 p: 0.859 f: 0.917 p: 0.974 f: 0.995 p: 1.000
s: 0,875 g: 0,852 s: 0.750 g: 0.746 s: 0.706 g: 0.716 s: 1.000 g: 0.939
overall: 0,928 overall 0,830 overall: 0,828 overall: 0,983
geneticf: 1,000 p: 0,922 f: 0,997 p: 0,808 f: 0.905 p: 0.808 f: 0.987 p: 0.875
s: 0,737 g: 0,790 s: 0,750 g: 0.707 s: 0,706 g: 0.717 s: 0.750 g: 0.591
overall: 0,862 overall: 0,815 overall: 0,784 overall: 0,801
etmf: 0,992 p: 0,995 f: 0,901 p: 0,989 f: 0,863 p: 0,982 f: 0,995 p: 1,000
s: 1,000 g: 0,889 s: 0,923 g: 0,894 s: 0,923 g: 0,947 s: 1,000 g: 0,939
overall: 0,969 overall: 0,927 overall: 0,929 overall: 0,983
the heuristics miner is able to nd a reasonably tting process model, although
it is also not very precise since it contains several loops. the genetic algorithm
nds a model similar to that of the heuristics miner, although it is unsound and
contains even more loops. the etm algorithm nds a process tree, which is
shown in figure 17a, that scores high on all dimensions. if we want to improve
replay tness even more we can make it 10 times more important as the other
quality dimensions. this results in the process tree as shown in figure 17b. with
an overall (unweighed) tness of 0 ;884 it is better than all process models found
by other algorithms while at the same time having a perfect replay tness.
event log l2 shows similar results: the -algorithm and the ilp miner are
able to nd process models that can replay all behavior but allow for far more be-
havior. the heuristics miner and genetic miner again found models with several
loops. the etm algorithm was able to nd a tree, which is shown in figure 18a,
that scores high on all dimensions but less so on replay tness. if we emphasize
replay tness 10 times more than the other dimensions, we get the process tree
as is shown in figure 18b. although replay tness improved signicantly, the
other dimensions, especially precision and simplicity, are reduced.
for event log l3 the observations for the last two event logs still hold. both
the-algorithm and the ilp miner provide tting process models that allow for
far more behavior. both the heuristics miner and the genetic algorithm result
15!
f!
!
e!

dd_
cbaf: 0,901 p: 0,989
s: 0,923 g: 0,894
(a) all dimensions weight 1!
f

e
d_
cabf: 0,996 p: 0,775
s: 0,923 g: 0,843
(b) replay fitness weight 10, rest 1
fig. 17: process trees discovered for l1
!
!
f

cb
!
edbaf: 0,863 p: 0,982
s: 0,923 g: 0,947
(a) all dimensions weight 1^

d!
b_
ec_
d_
ab_
c
b^
!
b^
f
ad
f: 0,964 p: 0,415
s: 0,571 g: 0,838
(b) replay tness weight 10, rest weight 1
fig. 18: process trees discovered for l2
in unsound models. however, the sound interpretation of the heuristics model
is the same as the sound process tree found by the etm algorithm. although
replay tness is almost perfect, we can let the etm algorithm discover a process
tree with real perfect replay tness. this requires making it 1000 times more
important than the others and results in a process tree that has perfect replay
tness but scores bad on precision. however, as we have seen before, this is a
common trade-o and the process tree is still more precise than the one found
by the ilp miner which also has a perfect replay tness.
!
f!
e!
_
dc!
baf: 0,995 p: 1,000
s: 1,000 g: 0,939
(a) all dimensions weight 1^
^
af^
_
_
bdcf_
ae
f: 1,000 p: 0,502
s: 0,857 g: 0,900
(b) replay tness weight 1000,
rest weight 1
fig. 19: process trees discovered for l3
16investigating the results shown in table 3 we see that on two occasions a
process model similar to the one found by the etm algorithm was found by
another algorithm. however, the -algorithm was not able to produce sensible
models for any of the three real life event logs. the heuristics miner once pro-
duced a process model of which the sound behavior matched the process tree
the etm algorithm discovered. however, our algorithm always produced sound
process models superior to the others. furthermore, the etm algorithm can be
steered to improve certain dimensions of the process model as desired.
7 conclusion
the quality of process discovery algorithms is generally measured using four di-
mensions, namely replay tness, precision, generalization and simplicity. many
existing process discovery algorithms focus on only two or three of these dimen-
sions and generally, they do not allow for any parameters indicating to what
extent they should focus on any of these dimensions.
in this paper, we presented the etm algorithm to discover process trees on
a log. this etm algorithm can be congured to optimize for a weighted average
over the four quality dimension, i.e. a model can be discovered that is optimal
given the weights given to each parameter. furthermore, the etm algorithm is
guaranteed to produce sound process models .
we used our etm algorithm to show that all four quality dimensions are
necessary when doing process discovery and that none of them should be left
out. however, the tness dimension, indicating to what extent the model can
reproduce the traces in the log, is more important than the other dimensions.
using both an illustrative example and three real life event logs we demon-
strated the need to consider all four quality dimensions. moreover, our algorithm
is able to balance all four dimensions is a seamless manner.
references
1. j. carmona b.f. van dongen w.m.p. van der aalst a. adriansyah, j. munoz-
gama. alignment based precision checking. bpm center report bpm-12-10,
bpmcenter.org, 20012.
2. wil van der aalst, arya adriansyah, and boudewijn van dongen. replaying his-
tory on process models for conformance checking and performance analysis. wiley
interdisciplinary reviews: data mining and knowledge discovery , 2(2):182{192,
2012.
3. w.m.p. van der aalst. process mining: discovery, conformance and enhancement
of business processes . springer-verlag, berlin, 2011.
4. w.m.p. van der aalst, a.k. alves de medeiros, and a.j.m.m. weijters. genetic
process mining. in applications and theory of petri nets 2005 .
5. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128{1142, 2004.
176. a. adriansyah, b. van dongen, and w.m.p. van der aalst. conformance checking
using cost-based fitness analysis. in ieee international enterprise computing
conference (edoc 2011) , pages 55{64. ieee computer society, 2011.
7. r. bergenthum, j. desel, r. lorenz, and s. mauser. process mining based on re-
gions of languages. in international conference on business process management
(bpm 2007) , 2007.
8. j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst. a genetic algorithm
for discovering process trees. in proceedings of the 2012 ieee world congress
on computational intelligence . ieee, 2012 (to appear).
9. t. calders, c. w. g unther, m. pechenizkiy, and a. rozinat. using minimum
description length for process mining. in proceedings of the 2009 acm symposium
on applied computing , sac '09, pages 1451{1455, new york, ny, usa, 2009.
acm.
10. b.f. van dongen. process mining and verication . phd thesis, eindhoven uni-
versity of technology, 2007.
11. b.f. van dongen, a.k. alves de medeiros, and l. wenn. process mining: overview
and outlook of petri net discovery algorithms. in k. jensen and w.m.p. van
der aalst, editors, transactions on petri nets and other models of concurrency
ii, volume 5460 of lecture notes in computer science , pages 225{242. springer-
verlag, berlin, 2009.
12. a.e. eiben and j.e. smith. introduction to evolutionary computing . springer
verlag, 2003.
13. c.w. g unther and w.m.p. van der aalst. fuzzy mining: adaptive process sim-
plication based on multi-perspective metrics. in g. alonso, p. dadam, and
m. rosemann, editors, international conference on business process management
(bpm 2007) , volume 4714 of lecture notes in computer science , pages 328{343.
springer-verlag, berlin, 2007.
14. a.k. alves de medeiros, a.j.m.m. weijters, and w.m.p. van der aalst. genetic
process mining: an experimental evaluation. data mining and knowledge dis-
covery , 14(2):245{304, 2007.
15. j. mendling, h.m.w. verbeek, b.f. van dongen, w.m.p. van der aalst, and
g. neumann. detection and prediction of errors in epcs of the sap reference
model. data and knowledge engineering , 64(1):312{329, 2008.
16. a. rozinat and w.m.p. van der aalst. conformance checking of processes based
on monitoring real behavior. information systems , 33(1):64{95, 2008.
17. j. vanhatalo, h. v olzer, and j. koehler. the rened process structure tree. data
and knowledge engineering , 68(9):793{818, 2009.
18. h.m.w. verbeek, j.c.a.m. buijs, b.f. van dongen, and w.m.p. van der aalst.
xes, xesame, and prom 6. in p. soer and e. proper, editors, information
systems evolution , volume 72 of lecture notes in business information processing ,
pages 60{75. springer-verlag, berlin, 2010.
19. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workow models
from event-based data using little thumb. integrated computer-aided engi-
neering , 10(2):151{162, 2003.
20. l. wen, w.m.p. van der aalst, j. wang, and j. sun. mining process models with
non-free-choice constructs. data mining and knowledge discovery , 15(2):145{
180, 2007.
21. j.m.e.m. van der werf, b.f. van dongen, c.a.j. hurkens, and a. serebrenik.
process discovery using integer linear programming. fundamenta informaticae ,
94:387{412, 2010.
18