business process reporting using process mining,
analytic workflows and process cubes
bolt iriondo, a.j.; de leoni, m.; van der aalst, w.m.p.; gorissen, p.j.b.
published in:
data-driven process discovery and analysis
doi:
10.1007/978-3-319-53435-0_2
published: 01/01/2017
document version
publisher’s pdf, also known as version of record (includes final page, issue and volume numbers)
please check the document version of this publication:
• a submitted manuscript is the author's version of the article upon submission and before peer-review. there can be important differences
between the submitted version and the official published version of record. people interested in the research are advised to contact the
author for the final version of the publication, or visit the doi to the publisher's website.
• the final author version and the galley proof are versions of the publication after peer review.
• the final published version features the final layout of the paper including the volume, issue and page numbers.
link to publication
citation for published version (apa):
bolt iriondo, a. j., de leoni, m., van der aalst, w. m. p., & gorissen, p. (2017). business process reporting
using process mining, analytic workflows and process cubes: a case study in education. in c. paolo, & r-m.
stefanie (eds.), data-driven process discovery and analysis: 5th ifip wg 2.6 international symposium,
simpda 2015, vienna, austria, december 9-11, 2015, revised selected papers (pp. 28-53). (lecture notes in
business information processing; vol. 244). dordrecht: springer. doi: 10.1007/978-3-319-53435-0_2
general rights
copyright and moral rights for the publications made accessible in the public portal are retained by the authors and/or other copyright owners
and it is a condition of accessing publications that users recognise and abide by the legal requirements associated with these rights.
            • users may download and print one copy of any publication from the public portal for the purpose of private study or research.
            • you may not further distribute the material or use it for any profit-making activity or commercial gain
            • you may freely distribute the url identifying the publication in the public portal ?
take down policy
if you believe that this document breaches copyright please contact us providing details, and we will remove access to the work immediately
and investigate your claim.
download date: 14. jan. 2018business process reporting using process
mining, analytic workﬂows and process cubes:
a case study in education
alfredo bolt1(b), massimiliano de leoni1, wil m.p. van der aalst1,
and pierre gorissen2
1eindhoven university of technology, eindhoven, the netherlands
{a.bolt,m.d.leoni,w.m.p.v.d.aalst }@tue.nl
2hogeschool van arnhem en nijmegen, nijmegen, the netherlands
pierre.gorissen@han.nl
abstract. business process intelligence (bpi) is an emerging topic that
has gained popularity in the last decade. it is driven by the need for
analysis techniques that allow businesses to understand and improvetheir processes. one of the most common applications of bpi is reporting ,
which consists on the structured generation of information (i.e., reports)
from raw data. in this article, state-of-the-art process mining techniques
are used to periodically produce automated reports that relate the actual
performance of students of a dutch university to their studying behav-ior. to avoid the tedious manual repetition of the same process mining
procedure for each course, we have designed a workﬂow calling various
process mining techniques using rapidprom. to ensure that the actualstudents’ behavior is related to their actual performance (i.e., grades
for courses), our analytic workﬂows approach leverages on process cubes ,
which enable the dataset to be sliced and diced based on courses and
grades. the article discusses how the approach has been operationalized
and what is the structure and concrete results of the reports that have
been automatically generated. two evaluations were performed with lec-turers using the real reports. during the second evaluation round, the
reports were restructured based on the feedback from the ﬁrst evaluation
round. also, we analyzed an example report to show the range of insightsthat they provide.
keywords: business process reporting
·analytic workﬂows ·process
mining ·process cubes ·education
1 introduction
business process reporting (bpr) refers to the provision of structured infor-
mation about processes in a regular basis, and its purpose is to support decision
makers. reports can be used to analyze and compare processes from many per-spectives (e.g., behavior, performance, costs, time). in order to be eﬀective, bpr
presents some challenges:
c/circlecopyrtifip international federation for information processing 2017
published by springer international publishing ag 2017. all rights reservedp. ceravolo and s. rinderle-ma (eds.): simpda 2015, lnbip 244, pp. 28–53, 2017.doi: 10.1007/978-3-319-53435-0
2business process reporting: a case study in education 29
1. it should provide insights using metric-based characteristics (e.g., bottlenecks,
throughput time, resource utilization) and behavioral characteristics (e.g.,deviations, frequent patterns) of processes.
2. it should be repeatable (i.e., not require great eﬀorts to repeat the analysis).
3. it should be able to analyze the data with diﬀerent granularity levels (i.e.,
analyze an organization as a whole or analyze its branches individually).
this paper shows through a case study how process mining ,analytic work-
ﬂows and process cubes can be concretely used for business process reporting,
addressing the three challenges mentioned above.
the case study presented in this paper refers to a business-process reporting
service at eindhoven university of technology. the service produces a report
each quartile (i.e., two-month academic period) for each course that is providedwith video lectures. the report is sent to the responsible lecturer and provides
insights about the relations between the students’ usage of video lectures and
their ﬁnal grades on the course, among other educational data analysis results.
process mining is a relatively young research discipline that is concerned with
discovering, monitoring and improving real processes by extracting knowledge
from event logs readily available in today’s systems [ 1]. hundreds of diﬀerent
process mining techniques have been proposed in literature. these are not lim-
ited to process-model discovery and the checking of conformance. also, other
perspectives (e.g., data) and operational support (e.g., predictions) are included.
process mining is supported by commercial software (e.g., disco
1, celonis2)a n d
academic software (e.g., prom3[2]) tools.
process mining allows the extraction of insights about the overall and inner
behavior contained in any given process (e.g., a student taking a course). these
insights can be collected and processed into reports. when thousands of diﬀerentreports need to be produced (e.g., one for each course), it can be tedious and
error-prone to manually repeat all the process-mining analyses to be incorpo-
rated in the reports. analytic workﬂows can be used to fully automate analyticexperiments such as the generation of an arbitrary number of reports. process
cubes can be used to scope and split the overall process data into the granularity
level expected by the analytic workﬂow. these scoped subsets of event data canbe distributed into cube cells. then, the event data contained in each cell can be
used as input for the analytic workﬂow (e.g., all the students that took a given
course on a given quartile).
the usefulness of the reports is evaluated with dozens of lecturers throughout
two evaluation rounds in diﬀerent academic periods. during the ﬁrst evaluation
round, an initial set of reports was sent to lecturers and feedback was collectedthrough an evaluation form. the feedback was used to restructure the report.
then, a set of restructured reports was sent to lecturers and a group of them were
interviewed to asses if the insights contained in the report were better perceived.
the results show that, indeed, this is the case.
1http://ﬂuxicon.com/disco .
2http://www.celonis.de/en .
3prom tools is free to download from http://www.promtools.org .30 a. bolt et al.
the remainder of this paper is organized as follows. section 2discusses related
work about educational data analysis and business process reporting. section 3
provides an overview of the case study and discusses the structure of the reports.
sections 4and5summarize the related work and main concepts related to ana-
lytic workﬂows and process cubes and illustrate how they are concretely appliedin this case study. sections 6and7discusses the reports sent and the results
of the two evaluation rounds with the lecturers. finally, sect. 8concludes the
paper.
2 related work
this section discusses the related work done around business process report-ing and educational data analysis. related work about analytic workﬂows and
process cubes is discussed in sects. 4and5respectively.
2.1 business process reporting
business process intelligence (bpi) is deﬁned by [ 3] as the application of business
intelligence (bi) techniques to business processes. however, behavioral proper-ties of processes (e.g., control-ﬂow) cannot be represented using traditional bi
tools. alternatively, castellanos et al. [ 4] provides a broader deﬁnition: bpi
exploits process information by providing the means for analyzing it to givecompanies a better understanding of how their business processes are actually
executed. it incorporates not only metric-based process analysis, but also process
discovery, monitoring and conformance checking techniques as possible ways tounderstand a process.
business process reporting can be deﬁned as the structured and periodical
production of reports containing analysis of process data obtained through bpitechniques.
business process management suites (e.g., sap, oracle) usually provide
process reporting capabilities. often, these process reporting capabilites are anadaptation of general-purpose reporting tools (e.g., crystal reports, oracle dis-
coverer) to process data [ 3]. these general-purpose reporting tools are unable to
analyze the data from a process perspective (e.g., discover a model).
most process mining tools (e.g., prom, disco) are able to analyze from a
process perspective, but they lack reporting and capabilities others, such ascelonis, oﬀer business process reporting capabilities. however, they are limited
to only a few process-perspective analysis components, and each report instance
has to be created manually. furthermore, the event data used as input for thereport can only be ﬁltered from the original event data; the granularity level
cannot be changed. also, most of these tools do not allow the comparison of
process variants (e.g., students with diﬀerent grades).
given the limitations described above, in this paper we used a combination of
process mining, analytic workﬂows and process cubes to provide fully automated
process-oriented reports.business process reporting: a case study in education 31
2.2 educational data analysis
the analysis of educational data and the extraction of insights from it is related
to two research communities: educational data mining and learning analytics .
educational data mining (edm) is an emerging interdisciplinary research
area that deals with the development of methods to explore data originating inan educational context. edm uses computational approaches to analyze educa-
tional data in order to study educational questions [ 5,6]. for example, knowledge
discovered by edm algorithms can be used not only to help teachers to managetheir classes, understand their students’ learning processes and reﬂect on their
own teaching methods, but also to support a learner’s reﬂections on the situation
and provide feedback to learners. an extensive survey on the state of the art ofedm is presented in [ 5].
learning analytics (la) is deﬁned by [ 7] as the measurement, collection,
analysis and reporting of data about learners and their contexts, for purposes of
understanding and optimising learning and the environments in which it occurs.
a c c o r d i n gt o[ 8], the diﬀerence between edm and la is that they approach
diﬀerent challenges driving analytics research. edm focuses on the technical
challenge (e.g., how can we extract value from these big sets of learning-related
data?), while la focuses on the educational challenge (e.g., how can we optimiseopportunities for online learning?). a discussion on the diﬀerences, similarities
and collaboration opportunities between these two research communities is pre-
sented in [ 9].
several process mining techniques (e.g., fuzzy miner [ 10]) have been applied
successfully in the context of edm [ 11] for analyzing study curriculums followed
by students. notably, the work introduced by [ 12] aims to obtaining better mod-
els (i.e., in terms of model quality ) for higher education processes by performing
data preprocessing and semantic log purging steps. however, most of these tech-
niques are not suitable for analyzing video lecture usage by students, given theinherent lack of structure of such processes.
in this paper, we will use existing and new process mining techniques to
obtain insights of student behavior from an educational point of view.
3 a case study in education
eindhoven university of technology provides video lectures for many courses forstudy purposes and to support students who are unable to attend face-to-facelectures for various reasons. student usage of video lectures and their course
grades are logged by the university’s it systems. the purpose of this case study
is to show how raw data extracted from the university’s it systems can betransformed into reports that show insights about students’ video lecture usage
and its relation with course grades by using process mining, process cubes and
analytic workﬂows. figure 1describes the overview of this case study.
the data used in this case study contains video lecture views ,course grades
and personal information of students of the university. each student and course
has a unique identiﬁer code (i.e., student id, course code ). the data reveals32 a. bolt et al.
fig. 1. overview of the case study: university data is transformed into reports by using
process mining, process cubes and analytic workﬂows.
enormous variability; e.g., thousands of students watch video lectures for thou-
sands of courses and every course has a diﬀerent set of video lectures, and they
have diﬀerent cultural and study backgrounds, which leads to diﬀerent behavior.therefore, we need to provide diﬀerent reports and, within a report, we need to
perform a comparative analysis of the students when varying the grade.
before describing our approach and the ingredients used, we sketch the report
we aim for. the report is composed of three sections: course information ,core
statistics and advanced analytics , as shown in fig. 1.
4the analysis results refer
to all students who registered for the course exam, independently whether ornot they participated in it.
4an example report, where student information has been anonymized, can be down-
loaded from https://www.dropbox.com/s/565zz94rdo6gg2r/report.zip?dl=0 .business process reporting: a case study in education 33
the course information section provides general information, such as the
course name, the academic year, the number of students, etc. the core statisticssection provides aggregate information about the students, such as their gen-
der, nationality, enrolled bachelor or master program, along with course grades
distribution and video lecture views. the advanced analytics section containsprocess-oriented diagnostics obtained through process mining techniques.
the next two sections show how the desired reports can be generated.
4 analytic workﬂows as a means to automate analysis
process mining experiments usually require analysts to perform many analysis
steps in a speciﬁc order. as mentioned in sect. 1, it is not unusual that the same
experiment has to be carried out multiple times. this is normally handled by
manually executing the analysis steps of the experiment, thus requiring largeperiods of time and resources and introducing the risk of human-induced errors.
current process mining tools are not designed to automatically repeat the
application of the same process-mining analyses on an arbitrary number of (subsets of) event logs. therefore, it is not possible to automatically generate any
arbitrary number of reports.
analytic workﬂows can be used to address this problem. they are deﬁned
by chaining analysis and data-processing steps, each of which consumes input
produced by previous steps and generates output for the next steps. ana-
lytic workﬂows are a specialization of scientiﬁc workﬂows tailored towards ana-
lytic purposes. scientiﬁc workﬂows have successfully been applied in many set-
tings [ 13,14]. the work presented in [ 15] illustrate the formalization and opera-
tionalization of a framework to support process-mining analytic workﬂows where
the steps are linked to the application of process-mining techniques.
in this paper, we combine process mining with analytic workﬂow systems,
which allow one to design, compose, execute, archive and share workﬂows that
represent some type of analysis or experiment. each activity/step of an analytic
workﬂow is one of the steps to conduct a non-trivial process-mining analysis, whichcan range from data ﬁltering and transformation to process discovery or confor-
mance checking. once an analytic workﬂow is conﬁgured, it can be executed with
diﬀerent process data as many times as needed without reconﬁguration.
in our case study, for automatically generating the course reports we used
rapidprom [ 15,16], which extends the rapidminer analytic workﬂow tool with
process mining techniques.
5
figure 2a illustrates the analytic workﬂow that is used to generate each
report. figure 2b shows the explosion of the “sequence models” section of the
analytic workﬂow.
the operators shown in fig. 2are used for diﬀerent purposes: multipliers
allow one to use the output of an operator as input for many operators. fil-
teroperators select a subset of events based on deﬁned criteria. process mining
5free version and installation instructions for rapidminer and the rapidprom exten-
sion are available at http://www.rapidprom.org or at the rapidminer marketplace .34 a. bolt et al.
fig. 2. implemented analytic workﬂow used to generate the reports. each instance of
a course can be automatically analyzed in this way resulting in the report described.
(color ﬁgure online)
operators are used to produce analysis results. for example, the operators high-
lighted in blue in fig. 2b produce a sequence model from each ﬁltered event
data.
the complete rapidprom implementation of the analytic workﬂow used in
this case study is available at https://www.dropbox.com/s/g9spsziyv55vsro/
single.zip?dl=0 . readers can execute this workﬂow in rapidminer to generatebusiness process reporting: a case study in education 35
a report using the sample event log available at https://www.dropbox.com/s/
r3gczshxqxh6a6d/sample.xes?dl=0 .6
5 process cubes as a means to select and scope event
data
processes are not static within moderns organizations but their instances con-
tinuously adapt to the dynamic context requirements of modern organizations.
therefore, an event log records executions of several process variants, whosebehavior depends on context information (e.g., diﬀerent courses that may con-
tain diﬀerent behavior). as a consequence, the event log needs to be split into
sub-logs (i.e., one for each variant), each containing all the events that belong tothat variant. the naive approach consists on manually ﬁltering the event data.
naturally, this approach is unpractical in scenarios where many diﬀerent process
variants exist.
process cubes [ 17] are used to overcome this issue: in a process cube, events
are organized into cells using diﬀerent dimensions. the idea is related to the
well-known notion of olap (online analytical processing) data cubes and theassociated operations, such as slice, dice, roll-up, and drill-down. by applying
the correct operations, each cell of the cube contains a sub-set of the event log
that complies with the homogeneity assumption mentioned above. this allowsone to isolate and analyze the diﬀerent variants of a process.
several approaches provide these capabilities, such as [ 18], which presents
an exploratory view on the application of olap operations over events. other
process-cube approaches have been applied in speciﬁc contexts [ 19,20]. the term
process cube was introduced and formalized in [ 17] with a working prototype
presented in [ 21], and later improved and implemented in [ 22].
5.1 basic concepts
a process cube is characterized by a set of dimensions , each of which is associated
with one or a group of event’s data properties. for each combination of values for
the diﬀerent dimensions, a cell exists in the process cube. hence, each process-cube cell contains the events that assign certain values to the data properties.
each cell of the process cube contains event data that can be used by process
mining techniques. please note that certain dimensions may be considered as
irrelevant and, therefore, they are ignored and are not visible in the cube. also,
some dimensions may be not readily available in the event data; however, theycan be derived from the existing dimensions. for example, the “year” and “day”
dimensions can be derived from the “timestamp” dimension.
the sliceoperation selects a subset of values of a dimension while removing
that dimension from the analysis. for example, if the “year” dimension is sliced
6when running the workﬂow, make sure that the read file operator points to the
sample event log and the “html output directory” parameter of the generate
report operator points to the desired output folder.36 a. bolt et al.
fig. 3. schematic examples of cube operations
f o ry e a r= {2012, 2013 }, only the events in those years are retained. also, the
“year” dimension is removed from the cube as shown in fig. 3a. the latter
implies that cells with diﬀerent values for the “year” dimension and the same
values for the other dimensions are merged.
the diceoperation is similar to the sliceoperation, with the diﬀerence that
the dicing dimension is retained. so, the dice operation is only removing cells
without merging any cells: the dicing dimension can still be used for furtherexploration of the event data, as shown in fig. 3a.
the roll up and drill down operations change the granularity level of a dimen-
sion. as shown in fig. 3b, if a dimension is rolled up, an attribute with a more
coarse-grained granularity will be used to create the cells of the cube, and if
a dimension is drilled down, an attribute with a more ﬁne-grained granularity
will be conversely used. for example, the “day” dimension can be rolled up to
“month”, and the “month” dimension can be drilled down to “day”.
5.2 application to the case study
for performing process cube operations over the university data we used the
process mining cube (pmc) tool introduced in [ 22]. as mentioned before, the
starting point is an event data set. this event data set has been obtained bydeﬁning and running opportune joins of tables of the database underlying the
video-lecture system of the university (see sect. 3). a fragment of the event data
set is shown in table 1.
using the event data, we created a process cube with the following dimen-
sions: student id, student gender, student nationality, student education
code, student education phase, course code, course department, activity,
activity type, grade, timestamp, quartile and academic year.
after slicing and dicing the cube, thousands of cells are produced: one
for each combination of values of the “course code”, “quartile” and “course
grade” dimensions. each cell corresponds to an event log that can be analyzed
using process mining techniques.business process reporting: a case study in education 37
table 1. a fragment of event data generated from the university’s system: each row
corresponds to an event.
ev.
idstudentid nat. ed.code coursecode activity quartile acad. year timestamp grade ···
1 1025 dutch bis 2ii05 lecture 1 1 2014–2015 03/09/2012 12:05 6 ···
2 1025 dutch bis 2ii05 lecture 2 1 2014–2015 10/09/2012 23:15 6 ···
3 1025 dutch bis 1cv00 lecture 10 3 2014–2015 02/03/2012 15:36 7 ···
4 2220 spanish inf 1cv00 lecture 1 3 2014–2015 20/03/2013 16:24 8 ···
5 1025 dutch bis 2ii05 exam 2 2014–2015 13/12/2012 12:00 6 ···
6 2220 spanish inf 1cv00 lecture 4 3 2014–2015 25/03/2013 11:12 8 ···
7 2220 spanish inf 1cv00 exam 3 2014–2015 04/04/2013 12:00 8 ···
······ ··· ··· ··· ··· ··· ··· ··· ··· ···
we applied our approach that combines process mining, analytic workﬂows
and process cubes to the case study presented in sect. 3in two evaluation
rounds. the following sections describe the work, reports, results and the feed-
back obtained on each round.
6 initial report
the ﬁrst evaluation round was conducted in august 2015 and it used the event
data corresponding to the academic year 2014–2015. the data used in this roundcontains 246.526 video lecture views and 110.056 course grades of8.122 stu-
dents, 8.437 video lectures and 1.750 courses. concretely, we automatically
generated a total of 8.750 course reports for 1750 courses given at the univer-
sity in each of the 5 quartiles (i.e., 4 normal quartiles + interim quartile) of
the academic year 2014–2015. for reliability of our analysis, we only selected
the reports of courses where, on average, each student watched at least 3 video
lectures. in total, 89 courses were selected and their reports were sent to the
corresponding lecturers.
section 6.1shows the ﬁrst report structure through an example of the reports
sent to lecturers in this evaluation round. it also provides a detailed analysis of
the ﬁndings that we could extract from the report for a particular course. alongwith the report, we also sent an evaluation form to the lecturers. the purpose of
the evaluation forms is to verify whether lecturers were able to correctly interpret
the analysis contained in the report. the results obtained in the ﬁrst evaluationround are discussed in sect. 6.2.
6.1 structure of the report
to illustrate the structure, contents and value of the reports, we selected an
example course: “introduction to modeling - from problems to numbers and
back” given in the third quartile of the academic year 2014–2015 by the inno-vation sciences department at the university. this course is compulsory for all38 a. bolt et al.
ﬁrst-year students from all programs at the university. in total, 1621 students
attended this course in the period considered. this course is developed in a“ﬂipped classroom” setting, where students watch online lectures containing the
course topics and related contents, and in the classroom, they engage these topics
in practical settings with the guidance of the instructor.
the video lectures provided for this course are mapped onto weeks (1 to 7).
within each week, video lectures are numbered to indicate the order in which
students should watch them (i.e., 1.1 correspond to the ﬁrst video lecture of theﬁrst week). as indicated by the course’s lecturer, the ﬁrst video lectures of each
week contain the course topics for that week, and the last video lectures of each
week contain complementary material (e.g., workshops, tutorials). the numberof video lectures provided for each week depends on the week’s topics and related
activities, hence, it varies.
students’s behavior can be analyzed from many perspectives. as mentioned
in sect. 2.2, several process mining techniques have been applied in the context
of educational data analysis [ 11].
initially, we applied traditional process model discovery techniques (e.g.,
fuzzy miner [ 10], ilp miner [ 23], inductive visual miner [ 24]) to the educa-
tional data. however, given the unstructured nature of this data (i.e., studentswatching video lectures), the produced models were very complex (i.e., spaghetti
orﬂower models) and did not provide clear insights. therefore, we opted for
other process mining techniques that could help us understand the behavior ofstudents:
figure 4(a) shows for each video lecture the number of students that watched
it. we can observe that the number of students that watch the video lecturesdecreases as the course develops: most students watched the video lectures cor-
responding to the ﬁrst week (i.e., 1.x) but less than half of them watched the
video lectures corresponding to the last week (i.e., 7.x). note that within eachweek, students tend to watch the ﬁrst video lectures (i.e., x.1, x.2) more than
the last ones (i.e., x.5, x.6). this was discussed with the course’s lecturer. it is
explained by the fact that, as mentioned before, the ﬁrst video lectures of each
week contain the topics, and the last ones contain complementary material.
figure 4(b) shows for each student group (i.e., grouped by their grade) the
level of conformance, averaged over all students in that group, of the real order
in which students watch video lectures, compared with the “natural” or logical
order, namely with watching them in sequence (i.e., from 1.1 to 7.4). the confor-mance level of each student is measured as the replay ﬁtness of the data over a
process model that contains only the “natural” sequential order. the replay ﬁt-
ness was calculated using conformance checking techniques [ 25]. we can observe
that students with higher grades have higher levels of conformance than students
with lower grades.
figure 4(c) shows the grade distribution for this course where each bar is
composed by two parts corresponding to the number of students who watched
at least one (red part) video lecture and the number of students who did not
(blue part). we can observe that the best students (i.e., with a grade of 8 orabove) use video lectures. on the other hand, we observe that watching videobusiness process reporting: a case study in education 39
fig. 4. analysis results contained in the report of the course 0leb0: (a) number of
students that watched each video lecture (b) conformance with the natural viewing
order by course grade (c) grades distribution for students who watched video lectures(in red) or did not (in blue) (color ﬁgure online)
lectures does not guarantee that the student will pass the course, as shown in
the columns of students that failed the course (i.e. grade ≤5).
figure 5shows dotted charts [ 26] highlighting the temporal distribution of
video-lecture watching for two student groups: (a) students that failed the course
with a grade of 5, and (b) students that passed the course with a grade of 6 or 7.each row corresponds to a student and each dot in a row represents that student
watching a video lecture or taking the exam. note that both charts show a gap
where very few video lectures were watched, which is highlighted in the pictures40 a. bolt et al.
fig. 5. dotted charts for students grouped by their course grades
through an oval. this gap coincides with the carnaval holidays. we can observe
that, in general, students that failed watched fewer video lectures. also notethat in fig. 5(a) the density of events heavily decreases after the mid-term exam
(highlighted through a vertical dashed line). this could be explained by students
being discouraged after a bad mid-term result. this phenomenon is also present
in (b), but not equally evident. we can also observe that most students tend to
constantly use video lectures. this is conﬁrmed by the low number of studentswith only a few associated events.
figure 6shows sequence analysis models that, given any ordered sequence of
activities, reﬂects the frequency of directly-follows relations
7as percentage anno-
tations and as the thickness of edges. the highest deviations from the ordered
sequence order are highlighted in colored edges (i.e., black edges correspond to
the natural order). this technique was tailored for the generation of reports andit is implemented using a customized rapidprom extension. when comparing
(a) students that passed the course with a grade of 6 or 7 with (b) students that
had a grade of 8 or 9, we can observe that both groups tend to make roughlythe same deviations. most of these deviations correspond to speciﬁc video lec-
tures being skipped. these skipped video lectures correspond in most cases to
complementary material. in general, one can observe that the thickness (i.e.,frequency) of the arcs denoting the “natural” order (i.e., black arcs) is higher
for (b), i.e., those with higher grades. note that at the beginning of each week
we can observe a recovery eﬀect (i.e., the frequencies of the natural order tend
to increase).
7the frequency of directly-follows relations is deﬁned for any pair of activities ( a, b )
as the ratio between the number of times that bis directly executed after aand
the total number of times that ais executed.business process reporting: a case study in education 41
table 2. summary of the classiﬁcation of statement evaluations performed by lecturers
statement
evaluationcorestatistics
sectionadvanced analytics section sub total total (%)
conformance temp. dist seq. analysis
correct 261 30 67 32 390 (89%) 61%
incorrect 28 5 8 6 47(11%)
unknown 95 61 69 58 283 39%
6.2 lecturers evaluation
in addition to the qualitative analysis for some courses like such as the course
analyzed in sect. 6.1, we have also asked lecturers for feedback through an eval-
uation form linked to each report.8the evaluation form provided 30 statements
about the analysis contained in the reports (e.g., “higher grades are associated
with a higher proportion of students watching video lectures”, “video lecture
views are evenly distributed throughout the course period”). lecturers evalu-
ated each statement on the basis of the conclusions that they could draw fromthe report. for each of the 30 statements, lecturers could decide if they agreed
or disagreed with the statement, or, alternatively, indicate that they could not
evaluate the statement (i.e., “i don’t know”).
in total, 24 of the 89 lecturers answered the evaluation form. out of the 720
(24×30) possible statement evaluations, 437 statements were answered with
“agree” or “disagree”. the remaining cases in which the statement could not beevaluated can be explained by three possible causes: the statement is unclear,
the analysis is not understandable, or the data shows no conclusive evidence.
in the case that a statement was evaluated with “agree” or “disagree”, we
compared the provided evaluation with our own interpretation of the same state-
ment for that report and classiﬁed the response as correct orincorrect .i nt h e
case that a statement was not evaluated, the response was classiﬁed as unknown .
table 2shows a summary of the response classiﬁcation for each section of
the report. in total, 89%of the statement evaluations were classiﬁed as correct .
this indicates that lecturers were capable to correctly interpret the analysis
provided in the reports. note that the conformance section had the highest rate
ofunknown classiﬁcations (63.5%). this could be related to understandability
issues of the analysis presented in that section.
the evaluation form also contained a few general questions. one of such ques-
tions was: “do you think this report satisﬁes its purpose, which is to provideinsights about student behavior?”, for which 7 lecturers answered “yes”, 4 lectur-
ers answered “no” and 13 lecturers answered “partially”. all the lecturers that
responded “partially” provided written feedback indicating the improvements
8the evaluation form is available at https://www.dropbox.com/s/09y4ypklt70y6d9/
form.zip?dl=0 .42 a. bolt et al.
fig. 6. sequence analysis for students grouped by their course grades (color ﬁgure
online)business process reporting: a case study in education 43
they would like to see in the report. some of the related comments received
were: “it would be very interesting to know if students: (a) did not attendthe lectures and did not watch the video lectures, (b) did not attend the
lectures, but did watch the video lectures instead, (c) did attend the lectures
and watch the video lectures too. this related to their grades”, “the reportitself gives too few insights/hides insights”, “it is nice to see how many students
use the video lectures. that information is ﬁne for me and all i need to know”,
and “i would appreciate a written explanation together with your diagrams,next time”. another question in the evaluation form was: “do you plan to intro-
duce changes in the course’s video lectures based on the insights provided by
this report?”, for which 4 lecturers answered “yes” and 20 answered “no”. theresults show that the analysis is generally perceived as useful, but that more
actionable information is needed, such as face-to-face lecture attendance. how-
ever, this information is currently not being recorded by the tu/e. the feedback
provided by lecturers was used to improve the report. these improvements are
discussed in the next section.
7 final report
we modiﬁed the reports based on the feedback obtained in the ﬁrst evaluationround. the detail of the changes is presented in sect. 7.1. to assess the quality
of the improved report, we conducted a second evaluation round, which was
conducted in march 2016 and it used the event data corresponding to the ﬁrst twoquartiles of the academic year 2015–2016. the data used in this round contains
89.936 video lecture views and 49.078 course grades of10.152 students, 2.718
video lectures and 1.104 courses. concretely, we automatically generated a total
of2.208 course reports for 1104 courses given at the university in each of the 2
ﬁrst quartiles of the academic year 2015–2016. for reliability of our analysis, we
only selected the reports of courses where, on average, each student watched atleast 3 video lectures. in total, 56 courses were selected and their reports were
sent to the corresponding lecturers.
section 7.1shows the changes introduced in the report based on the feedback
obtained from lecturers in the ﬁrst evaluation round. it also provides examples
of the ﬁndings that several lecturers could extract from the report. along with
the report, we also sent an evaluation form to the lecturers. the purpose of theevaluation forms is to verify whether lecturers were able to correctly interpret
the analysis contained in the improved report. unfortunately, in this evaluation
round no lecturer answered the evaluation form. therefore, we held face-to-
face meetings with four lecturers, where the results included in the report were
discussed. the insights obtained in these meetings are discussed in sect. 7.2.
7.1 changes in the report
according to the feedback obtained from lecturers (reported in table 2in
sect.6.2), the most problematic sections (i.e., highest rate of unknown classiﬁca-44 a. bolt et al.
tions) were the conformance (63.5% unknown ) and sequential analysis (60.4%
unknown ) sections of the report (described in sect. 6.1).
given this feedback and the fact that the interpretation of a speciﬁc replay
ﬁtness value can be misleading for non-process-mining-experts, the conformance
section was replaced for a section that describes the compliance of students with
the “natural” order of watching video lectures based on simpler calculations,
deﬁned as follows.
deﬁnition 1 (compliance score). for any given student, their compliance
score (cs) w.r.t. the natural order is calculated as cs=/summationtextn−1
i=1df(ai,a i+1)
count (ai),w h e r e
df(ai,a i+1)is the number of times that the student watched lecture ai+1directly
after ai,count( ai)is the number of times that the student watched the lecture ai
and nis the number of video lectures available for the course.
this new compliance score is easier to interpret: a value of x means that x
percent of the video lectures watched by the student were watched in the naturalorder.
figure 7shows an example of the new compliance section of the report. it
refers to the course “5ecc0 - electronic circuits 2” (more details will be given
later). figure 7(a) shows the average compliance scores according to the stu-
dent’s grades, while fig. 7(b) shows the distribution of students according to
their compliance scores.
regarding the sequence analysis section, we simpliﬁed the explanatory text
of this section in the report. however, this section presents inherent diﬃcul-ties associated to the analysis of process models: most lecturers are not familiar
with process models. previously, sequence models only referred to frequency
deviations. in this round, we decided to incorporate sequence models that showperformance information. in these sequence models, an arc indicates the time
between the start of the source activity (i.e., video lecture or exam) and the start
of the target activity. from these models, one can observe if a given lecture isbeing fully watched, or if students are skipping most of it after watching a few
minutes. figure 8shows an example of a sequence model annotated with per-
formance information. this model was obtained from one of the course reports(7u855 - research methods for the built environment) sent in this evaluation
round. from these models we can get interesting insights about the students’
behavior on this course. for example, in fig. 8(a) (i.e., students that obtained a
6 or a 7 in the exam) the arrow between lecture 01 and lecture 02 states that
students that watched lecture 02 directly after lecture 01 , started watching lec-
ture 02 14 s (in average) after started watching lecture 01 . however, in fig. 8(b)
(i.e., students that obtained a 8, 9 or 10 in the exam) this speciﬁc behavior is
not observed.
7.2 lecturers evaluation
as mentioned before, from the 56 reports sent to lecturers in this evaluation
round, we obtained no responses to the corresponding evaluation forms. there-
fore, we held face-to-face meetings with four lecturers from diﬀerent departmentsbusiness process reporting: a case study in education 45
fig. 7. new compliance section of the report for an example course (5ecc0 - electronic
circuits 2)
of the university to discuss the report in general, and to evaluate if the changes
introduced in this evaluation round did actually improve the understandability
of the report.
in the remainder of this section, we summarize the insights obtained by
lecturers when discussing the reports in the face-to-face meetings.
the ﬁrst lecturer we met was responsible for the course 1cv00 - determinis-
tic operations management, provided by the industrial engineering department.
in this course, lectures are grouped by topic (i.e., 2 lectures per topic) and topicsare independent from each other. figure 9(a) shows the distribution of students
according to their compliance scores for this course. in this chart, we can observe
that students have a very low compliance score in general, and it had no cor-relation with grades. the lecturer deﬁned this behavior as “expected” since the
course topics are independent. figure 9(b) shows the dotted chart containing all46 a. bolt et al.
fig. 8. sequence models annotated with performance information for students grouped
by their grade. the models were obtained from the report of course 7u855 - research
methods for the built environment.
the students of the course. here we can observe two peaks of video lecture usage
in weeks 4 and 7 (highlighted with vertical yellow lines), but without context
information, we cannot explain why they happened. the lecturer immediately
identiﬁed these two peaks as the two mid-term exams that are part of the course.
the interpretation given by the lecturer was that students were using the video
lectures to study for these exams. this behavior was expected by the lecturer,
but in the past he did not have the information to either conﬁrm or deny it.
the second lecturer was responsible for the course 4eb00 - thermodynamics,
provided by the mechanical engineering department. in this course, some topics
build on top of knowledge acquired in previous topics, but others are indepen-dent. figure 10(a) shows, for each lecture, the total number of views. we can
observe that lecture 02a and lecture 05a had the highest number of views. the
lecturer determined that this behavior was expected, since lecture 02a contained
most of the deﬁnitions and knowledge that students needed to “remember” frombusiness process reporting: a case study in education 47
fig. 9. analysis results included in the report of the course 1cv00. (color ﬁgure online)
previous courses. on the other hand, lecture 05a was related to entropy ,w h i c h
was the most diﬃcult topic of the course for students. figure 10(b) shows the
average student compliance with the “natural” order according to the student’s
grades. we can observe that there is a negative correlation between the com-pliance scores and the grades. according to the lecturer: “a possible explana-
tion of this could be that students with bad grades could have skipped face-
to-face lectures and then needed to watch all the video lectures, while goodstudents attended face-to-face lectures and only watched some video lectures if
they needed to clarify something”.
the third lecturer was responsible for the course 5ecc0 - electronic cir-
cuits 2, provided by the electrical engineering department. in this course, all
the topics were related, every topic built-up on the previous one. figure 7(a)
showed the average student compliance with the “natural” order according tothe student’s grades. we can observe a positive correlation between compliance
scores and grades. the lecturer was positively surprised by this ﬁnding, but he
considered that the correlation was not strong. figure 11shows a fragment of the
sequence model with frequency deviations for two diﬀerent groups of students of
the course (i.e., those with a grade lower than 5, and those with a grade equal to
6 or 7). we can observe in fig. 11(a) that lecture 01c is being skipped by 13%
of the students that watched the lecture 01b . this behavior does not occur for
students with higher grades (shown in fig. 11(b)). the lecturer then considered
this ﬁnding as “unexpected, but positive”, since lecture 01c consists of the basic
topics from the previous course (i.e., electronic circuits 1) and it was meant to
refresh student’s knowledge. according to the lecturer, the fact that studentsdid not need to watch it is positive.48 a. bolt et al.
fig. 10. analysis results included in the report of the course 4eb00. (color ﬁgure
online)
the fourth lecturer was responsible for the course 5xca0 - fundamentals
of electronics, provided by the electrical engineering department. this course
considers topics are relatively independent from each other. figure 12(a) shows,
for each lecture, the total number of views. it is interesting to notice that the
lecture 05a , the video lecture most watched by students (highlighted in red) is
aninstruction lecture (i.e., a lecture that consists of exercises instead of top-
ics). given this ﬁnding, the lecturer has expressed the intention of splitting that
video lecture, for the next executions of the course, into a series of 10-minute web
lectures comprehending all the diﬀerent types of exercises covered in the videolecture. figure 12(b) shows the student distribution over ranges of compliance
score. it is clear from the chart that most students have a very low compli-
ance score w.r.t. the “natural” viewing order. this was justiﬁed by the lecturerthrough the following statement: “the topics are relatively disconnected, and it
seems that most students would watch only speciﬁc lectures”.
the general comments that we received from lecturers are summarized as
follows. “it would be interesting to see the correlation with face-to-face lectures
to see if students use video lectures as a replacement or as a complement forbusiness process reporting: a case study in education 49
fig. 11. fragment of the sequence model with frequency deviations for all students. in
(a), lecture 1c is being skipped. these charts were included in the report of the course
5ecc0 - electronic circuits 2.
them”. “video lectures are very good for the middle students. good students do
not seem to need them as much”. “i should split the most visited video lectures
into a series of web lectures (i.e., 10 min recordings of speciﬁc topics) so i could
really know which topics are the most diﬃcult for the students”. “students tendto use exercise lectures much more intensively than the actual theory. they seem
to be exam-oriented, as they prepare mostly watching exercises”.
regarding the report itself, again we received suggestions to incorporate face-
to-face lecture attendance. as mentioned in sect. 6, it is very diﬃcult to record
face-to-face attendance of students for technical reasons. other lecturers sug-gested that we incorporate student feedback into the report. we certainly recog-
nize the potential that incorporating the students’ feedback on the report could
have in the insights that the lecturer can obtain from it. we plan to incorpo-rate this feedback and its potentially positive eﬀects in the reports for the next
quartile.50 a. bolt et al.
fig. 12. analysis results included in the report of the course 5xca0. (color ﬁgure
online)
8 conclusion
this paper has illustrated the beneﬁts of combining the complementary
approaches of process cubes and analytic workﬂows in the ﬁeld of process min-ing. in particular, the combination is beneﬁcial when process mining techniques
need to be applied on large, heterogenous event data of multidimensional nature.
to demonstrate such beneﬁts, we applied the combined approach in a large
scale case study where we provide reports for lecturers. these reports correlate
the grades of students with their behavior while watching the available video
lectures. we evaluated the usefulness of the reports in two evaluation rounds.the second evaluation round presented an improved report, which was modiﬁed
based on the feedback obtained in the ﬁrst evaluation round. unlike existing
learning analytics approaches, we focus on dynamic student behavior. also,
descriptive analytics would not achieve similar analysis results because they do
not consider the process perspective, such as the ordering of watching videolectures.business process reporting: a case study in education 51
educational data has been analyzed by some disciplines in order to
understand and improve the learning processes [ 5–9], even employing process
cubes [ 20]. however, these analyses were mostly focused on individual courses.
no research work has previously been conducted to allow large-scale process
mining analysis where reports are automatically generated for any number ofcourses. our approach has made it possible by integrating process mining with
analytic workﬂows, which have been devised for large-scale analysis, and process
cubes, which provide the capabilities needed to perform comparative analyses.
as future work, the report generation will be extended to massive open
online courses (moocs) given by eindhoven university of technology. this
type of courses are particularly interesting due to the fact that face-to-face lec-tures are not used: video lectures are the main channel used by students for
accessing the course topics. for example, over 100.000 people from all over the
world registered for the two executions of the mooc process mining: data sci-
ence in action .
9we also plan to apply this analysis to the courses provided by
the european data science academy (edsa).10
references
1. van der aalst, w.m.p.: process mining: discovery, conformance and enhancement
of business processes, 1st edn. springer, heidelberg (2011)
2. dongen, b.f., medeiros, a.k.a., verbeek, h.m.w., weijters, a.j.m.m., van der
aalst, w.m.p.: the prom framework: a new era in process mining tool support.in: ciardo, g., darondeau, p. (eds.) icatpn 2005. lncs, vol. 3536, pp. 444–454.
springer, heidelberg (2005). doi: 10.1007/11494744
25
3. grigori, d., casati, f., castellanos, m., dayal, u., sayal, m., shan, m.c.: busi-
ness process intelligence. comput. ind. 53(3), 321–343 (2004). process/workﬂow
mining
4. castellanos, m., alves de medeiros, a.k., mendling, j., weber, b., weijers,
a.j.m.m.: business process intelligence. in: cardoso, j., van der aalst, w.m.p.
(eds.) handbook of research on business process modeling, pp. 456–480. igiglobal, hershey, pa, usa (2009)
5. romero, c., ventura, s.: educational data mining: a review of the state of the art.
ieee trans. syst. man cybern. part c appl. rev. 40(6), 601–618 (2010)
6. gorissen, p.j.b.: facilitating the use of recorded lectures: analysing students’ inter-
actions to understand their navigational needs. ph.d. thesis, eindhoven university
of technology (2013)
7. siemens, g.: learning analytics: the emergence of a discipline. am. behav. sci.
57(10), 1380–1400 (2013)
8. ferguson, r.: learning analytics: drivers, developments and challenges. int. j.
technol. enhanced learn. 4(5–6), 304–317 (2012)
9. siemens, g., baker, r.s.j.d.: learning analytics and educational data mining:
towards communication and collaboration. in: proceedings of the 2nd international
conference on learning analytics and knowledge, lak 2012, pp. 252–254. acm,
new york (2012)
9http://www.coursera.org/course/procmin .
10http://edsa-project.eu .52 a. bolt et al.
10. g¨ unther, c.w., van der aalst, w.m.p.: fuzzy mining – adaptive process simpliﬁ-
cation based on multi-perspective metrics. in: alonso, g., dadam, p., rosemann,
m. (eds.) bpm 2007. lncs, vol. 4714, pp. 328–343. springer, heidelberg (2007).doi:10.1007/978-3-540-75183-0
24
11. trcka, n., pechenizkiy, m., van der aalst, w.m.p.: process mining from educational
data. in: handbook of educational data mining, pp. 123–142. crc press, london
(2010)
12. ly, l.t., indiono, c., mangler, j., rinderle-ma, s.: data transformation and
semantic log purging for process mining. in: ralyt´ e, j., franch, x., brinkkem-
per, s., wrycza, s. (eds.) caise 2012. lncs, vol. 7328, pp. 238–253. springer,
heidelberg (2012). doi: 10.1007/978-3-642-31095-9 16
13. jaeger, e., altintas, i., zhang, j., lud¨ ascher, b., pennington, d., michener, w.:
a scientiﬁc workﬂow approach to distributed geospatial data processing using webservices. in: proceedings of the 17th international conference on scientiﬁc and
statistical database management (ssdbm 2005), berkeley, ca, usa, pp. 87–90.
lawrence berkeley laboratory (2005)
14. turner, k., lambert, p.: workﬂows for quantitative data analysis in the social
sciences. int. j. softw. tools technol. transf. 17(3), 321–338 (2015)
15. bolt, a., de leoni, m., van der aalst, w.m.p.: scientiﬁc workﬂows for process min-
ing: building blocks, scenarios, and implementation. int. j. softw. tools technol.
transf. (2015). doi: 10.1007/s10009-015-0399-5
16. mans, r.s., van der aalst, w.m.p., verbeek, h.m.w.: supporting process min-
ing workﬂows with rapidprom. in: proceedings of the bpm demo sessions 2014colocated with the 12th international conference on business process manage-
ment (bpm). ceur workshop proceedings, vol. 1295, pp. 56–60. ceur-ws.org
(2014)
17. van der aalst, w.m.p.: process cubes: slicing, dicing, rolling up and drilling down
event data for process mining. in: song, m., wynn, m.t., liu, j. (eds.) ap-bpm 2013. lnbip, vol. 159, pp. 1–22. springer, heidelberg (2013). doi: 10.1007/
978-3-319-02922-1
1
18. ribeiro, j.t.s., weijters, a.j.m.m.: event cube: another perspective on business
processes. in: meersman, r., et al. (eds.) otm 2011. lncs, vol. 7044, pp. 274–283.springer, heidelberg (2011). doi: 10.1007/978-3-642-25109-2
18
19. vogelgesang, t., appelrath, h.j.: multidimensional process mining: a ﬂexible
analysis approach for health services research. in: proceedings of the joint
edbt/icdt 2013 workshops, edbt 2013, pp. 17–22. acm, new york (2013)
20. van der aalst, w.m.p., guo, s., gorissen, p.: comparative process mining in edu-
cation: an approach based on process cubes. in: ceravolo, p., accorsi, r., cudre-mauroux, p. (eds.) simpda 2013. lnbip, vol. 203, pp. 110–134. springer, hei-
delberg (2015). doi: 10.1007/978-3-662-46436-6
6
21. mamaliga, t.: realizing a process cube allowing for the comparison of event data.
master’s thesis, eindhoven university of technology, eindhoven, the netherlands(2013)
22. bolt, a., van der aalst, w.m.p.: multidimensional process mining using process
cubes. in: gaaloul, k., schmidt, r., nurcan, s., guerreiro, s., ma, q. (eds.) caise
2015. lnbip, vol. 214, pp. 102–116. springer, heidelberg (2015). doi: 10.1007/
978-3-319-19237-6
7
23. werf, j.m.e.m., dongen, b.f., hurkens, c.a.j., serebrenik, a.: process discovery
using integer linear programming. in: hee, k.m., valk, r. (eds.) petri nets
2008. lncs, vol. 5062, pp. 368–387. springer, heidelberg (2008). doi: 10.1007/
978-3-540-68746-7 24business process reporting: a case study in education 53
24. leemans, s.j.j., fahland, d., van der aalst, w.m.p.: exploring processes and
deviations. in: fournier, f., mendling, j. (eds.) bpm 2014. lnbip, vol. 202, pp.
304–316. springer, heidelberg (2015). doi: 10.1007/978-3-319-15895-2 26
25. van der aalst, w.m.p., adriansyah, a., van dongen, b.f.: replaying history on
process models for conformance checking and performance analysis. wiley inter-
disc. rev. data min. knowl. discovery 2(2), 182–192 (2012)
26. song, m., van der aalst, w.m.p.: supporting process mining by showing events at a
glance. in: proceedings of the 17th annual workshop on information technologies
and systems (wits), pp. 139–145 (2007)