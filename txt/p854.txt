a general process mining framework for correlating,
predicting and clustering dynamic behavior basedon event logs
massimiliano de leonia,n, wil m.p. van der aalsta, marcus deesb
adepartment of mathematics and computer science, eindhoven university of technology, eindhoven, the netherlands
buitvoeringsinstituut werknemersverzekeringen (uwv), the netherlands
article info
keywords:
process miningdecision and regression treesevent-log manipulationevent-log clusteringabstract
process mining can be viewed as the missing link between model-based process analysis
and data-oriented analysis techniques. lion's share of process mining research has been
focusing on process discovery (creating process models from raw data) and replaytechniques to check conformance and analyze bottlenecks. these techniques have helped
organizations to address compliance and performance problems. however, for a more
refined analysis, it is essential to correlate different process characteristics . for example, do
deviations from the normative process cause additional delays and costs? are rejected
cases handled differently in the initial phases of the process? what is the influence of a
doctor's experience on treatment process? these and other questions may involve processcharacteristics related to different perspectives (control-flow, data-flow, time, organiza-tion, cost, compliance, etc.). specific questions (e.g., predicting the remaining processing
time) have been investigated before, but a generic approach was missing thus far. the
proposed framework unifies a number of approaches for correlation analysis proposed inliterature, proposing a general solution that can perform those analyses and many more.
the approach has been implemented in prom and combines process and data mining
techniques. in this paper, we also demonstrate the applicability using a case studyconducted with the uwv (employee insurance agency), one of the largest “administrative
factories ”in the netherlands.
&2015 elsevier ltd. all rights reserved.
1. introduction
process aware information systems (paiss) are increas-
ingly used by organizations to support their businesses.
some of these systems are driven by process models, e.g.,
business process management (bpm) and workflow man-
agement (wfm) systems. however, in most paiss only an
implicit process notion exists. consider for example the
enterprise software sap and oracle that is widely used tomanage business operations and customer relations.
although these systems provide bpm/wfm functionality,
most processes are partly hard-coded in application soft-
ware and exist only in the minds of the people using the
software. this provides flexibility and simplifies imple-
mentation efforts, but also results in poor management
support. if there is no explicit process model that reflects
reality, it is impossible to reason about compliance and
performance in a precise and unified manner. manage-
ment dashboards provided by business intelligence (bi)software tend to oversimplify reality and do not use
explicit process models. fortunately, all these systems
record the execution of process instances in so-called
event logs . these logs thus capture information aboutcontents lists available at sciencedirect
journal homepage: www.elsevier.com/locate/infosysinformation systems
http://dx.doi.org/10.1016/j.is.2015.07.003
0306-4379/ &2015 elsevier ltd. all rights reserved.ncorresponding author.
e-mail addresses: m.d.leoni@tue.nl (m. de leoni),
w.m.p.v.d.aalst@tue.nl (w.m.p. van der aalst),marcus.dees@uwv.nl (m. dees).information systems ](]]]])]]]–]]]
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 iactivities performed. each event records the execution of
an activity instance by a given resource at a certain point
in time along with the output produced.
event logs are the key enabler for process mining , which
is capable of extracting, from event logs, in-depth insights
in process-related problems that contemporary enter-
prises face [1]. through the application of process mining,
organizations can discover the processes as they were
conducted in reality, check whether certain practices and
regulations were really followed and gain insight into
bottlenecks, resource utilization, and other performance-
related aspects of processes.
process mining often starts with process discovery ,i . e . ,
automatically learning process models based on raw event
data. once there is a process model (discovered or made by
hand), the events can be replayed on the model to check
conformance and to uncover bottlenecks in the process [1].
however, such analyses are often only the starting point for
providing initial insights. when discovering a bottleneck or
frequent deviation, one would like to understand why it
e x i s t s .t h i sr e q u i r e st h ec o r r e l a t i o no fd i f f e r e n t process
characteristics . these characteristics can be based on:
/c15the control-flow perspective (e.g., the next activity
going to be performed);
/c15thedata-flow perspective (e.g., the age of the patient or
the amount of glucose in a blood sample);
/c15thetime perspective (e.g., the activity duration or the
remaining time to the end of the process);
/c15theresource/organization perspective (e.g., the resource
going to perform a particular activity or the current
workload), or,
/c15if a normative process model exists, the conformance
perspective (e.g., the skipping of a mandatory activity
or executing two activities in the wrong order).
there are of course other perspectives possible (e.g., the
cost perspective), but these are often not process-specific
and can be easily encoded in the data-flow perspective. for
example, there may be data attributes capturing variable
and fixed costs of an activity.
these problems are specific instances of a more general
problem, which is concerned with relating any process or
event characteristic to other characteristics associated with
single events or the entire process . this paper proposes a
framework to solve the more general correlation problem
and provides a very powerful tool that unifies the numer-
ous ad hoc approaches described in literature. this is
achieved by providing (1) a broad and extendable set of
characteristics related to control-flow, data-flow, time,
resources, organizations and conformance, and (2) a gen-
eric framework where any characteristic (dependent vari-
able) can be explained in terms of correlations with any set
of other characteristics (independent variables). for
instance, the involvement of a particular resource or
routing decision can be related to the elapsed time, but
also the other way around: the elapsed time can be related
to resource behavior or routing.
the approach is fully supported by a new package that
has been added to the open-source process miningframework prom .1the evaluation of our approach is based
on two case studies involving uwv, a dutch governmental
institute in charge of supplying benefits. for the first case
study, the framework allows us to successfully answer
process-related questions related to causes of observed
problems within uwv (e.g., reclamations of customers).
for some problems, we could show surprising root causes.
for other problems, we could only show that some
suspected correlations were not present, thus providing
novel insights. a second case study was concerned with
discovering the process model that describes the uwv's
management of provisions of benefits for citizens who are
unemployed and unable to look for a job for a relatively
long period of time because of physical or mental illnesses.
analysis shows that there is a lot of variability in process
execution, which is strongly related to the length of the
benefit's provision. therefore, the discovery of one single
process led to unsatisfactory results as this variability
cannot be captured in a single process model. after
splitting the event log into clusters based on the distin-
guishing features discovered through our approach, the
results significantly improved.
it is important to note that our framework does not
enable analyses that previously were not possible. the
novelty of our framework is concerned with providing a
single environment where a broad range of process-
centric analyses can be performed much quicker without
requiring process analysts with a solid technical back-
ground. without the framework, for instance, process
analysts are confronted with database systems where they
need to perform tedious operations to import data from
external sources and, later, to carefully design complex sql
queries to perform joins and even self-joins that involve
different database tables and views.
the remainder of the paper is as follows. section 2
presents the overall framework proposed in this paper.
the section also discusses how the problem of relating
business process characteristics can be formulated and
solved as a data-mining problem. in particular, we leverage
of data-mining methods to construct a decision or regres-
sion tree. in the remainder, we refer them to as prediction
trees if there is no reason to make a distinction. our
framework relies on the availability of key process char-
acteristics. therefore, section 3 classifies and provides
examples of these characteristics, along with showing
how to extract them from raw event data. section 4
presents event-selection filters to determine the instances
of the learning problem. in section 5 the filters and the
process characteristics are used to provide an overview of
the wide range of questions that can be answered using
our framework. several well-studied problems turn out to
be specific instances of the more general problem con-
sidered in this paper. section 6 discusses the notion of
clustering parts of the log based on prediction trees.
section 7 illustrates the implementation of the framework
as well as two case studies that have benefitted from the
application of the framework. finally, section 8 positions
1see the featureprediction package available in prom 6.4 or newer,
downloadable from http://www.promtools.org .
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 2this work with respect to the state of the art and section 9
concludes the paper.
2. a framework for correlating, predicting and clustering
dynamic behavior based on event logs
this section introduces the framework reported on in
this paper. to facilitate the understandability of this frame-
work, section 2.1 first provides a general overview, fol-
lowed by section 2.2 which provides a formalization of the
framework. section 2.3 then shows how the problem of
performing an analysis use case can be transformed into a
data-mining problem.
2.1. overview
a high level overview of the framework proposed in
this paper is shown in fig. 1 . starting point is an event log .
for each process instance (i.e., case) there is a trace, i.e., a
sequence of events. events have different characteristics .
mandatory characteristics are activity and timestamp .
other standard characteristics are the resource used to
perform the activity, transactional information (start, com-
plete, suspend, resume, etc.), and costs . however, any other
characteristic can be associated to an activity (e.g., the age
of a patient or size of an order). characteristics are
attached to events as name-value pairs: ( name _of_charac-
teristic ,value ). as mentioned in section 1 and illustrated in
fig. 2 (a), these characteristics can focus on the control-flow
perspective, the data-flow perspective, the resource/organization perspective, the time perspective, and the
conformance perspective.
starting from the event log, a process analysis can
define a so-called analysis use case , which requires the
selection of a dependent characteristic, the independent
characteristics and an event filter to describe which events
to retain for the analysis.
sometimes, such analysis requires the incorporation of
characteristics that are not (yet) available in the event log.
these characteristics can be added by deriving their values
through computations over the event log or from external
information sources. this motivates the need of the second
step of our framework where the event log is manipulated
and enriched with additional characteristics. as an exam-
ple, the remaining time until case completion can be
added to the event characteristics by simply comparing
the time of the current event with the time of the last
event for the same case. another example is concerned
with adding the workload of a resource to any event
occurring at time tby scanning the event log and calculat-
ing the set of activity instances that are being executed by
or are queued for the resource at time t.2
event log
2. manipulate and 
enrich event log1. define analysis
use case
event loganalysis
use case
3. make 
analysisif analysis 
needs to be refined
analysis resultprocess 
model
context 
data...
additional objects
4. clustersub log 1
sub log n...
5. process 
discoverya
b
process 
modela1
a2
a ba3
c aa1
c d
fig. 1. the general framework proposed in this paper: based on an analysis use case the event log is preprocessed and used as input for classification. based
on the analysis result, the use case can be adapted to gather additional insights. the part in red (or gray if printed in gray scale) is optional. the resu lt of the
analysis use case provides a classification that can be used to split the event log into clusters: each tree's leaf becomes a different event log. each s ublog can
be used by different process mining techniques (including, but not only, process discovery).
2several definitions of workload are possible. here and later in the
paper, the workload of a resource rat time tis interpreted as the amount
of work that is assigned to rat time t[2]. this accounts for activities that r
is executing or that have been scheduled to rfor later performance. the
workload of a set of resources (e.g., within a department) is the sum ofthe workload of all resources in the set. other workload definitions arepossible as described in [2].
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 3fig. 2 (b) provides an overview of the sources of
information that can be used to add information to events.
event characteristics can derived over other events of the
same process instance, other instances of the same pro-
cess, instances of different processes but also over events
executed by the same resource or by resources belonging
to the same organization entity or to related organization
entities. all of the above classes of event characteristics are
solely based on the event log. however, event character-
istics can be extracted through cross correlations with
external data sources, as shown in fig. 1 . we may use a
process model (e.g., for conformance checking) or context
data (such as, the weather or stock market). for example,
we may compute conformance metrics like fitness or
precision and attach this to events. for instance, certainresources may be “meteoropathic ”: the level of their
performance is influenced by weather conditions. it is
worth analyzing whether, indeed, certain resources are
more efficient when the weather is better. if we augment
events with the weather conditions when they occurred,
we can use the augmented log and check whether the
efficiency of single resources is somehow related to the
weather condition. this can be done by using the activity
duration or resource workload as a dependent character-
istic and the weather as one of the independent ones. if
the characteristic occurs in the prediction tree, then there
is some correlation between efficiency and weather. some
event characteristics (like weather information) cannot be
derived from the event log. in general, the process context
is acknowledged by many authors to be a huge source of
valuable information to find correlations [3–5].
once the analysis use case is defined and the event log
is enriched, the analysis use case can be made. the
outcome of performing the analysis is the generation of a
decision or a regression tree, which aims to explain the
values of the dependent characteristic as a function of the
independent characteristics.
the analysis result obtained after the third step of the
framework can be used for multiple purposes. for
instance, the results can be used to derive which condi-
tions may have a negative impact on certain kpis; as an
example, when certain process participants or entirecompany's branches are involved in execution of a given
process, the customer's satisfaction is lower. as results,
corrective actions can be put in place to avoid those
conditions (e.g., the low-performing branches can be
closed or the unsatisfactory process participants can be
motivated, moved to different tasks or, as extreme solu-
tion, be fired). the results can also be used at run-time to
provide decision support. for instance, suppose that cer-
tain conditions yield low values for certain kpis. while
executing the process, participants can be suggested to
avoid certain decisions that have been observed to likely
lead to those conditions. however, the production of the
results is always done a posteriori using an event log that
records past executions of process instances. if new
process instances conclude, the result is not automaticallyupdated. conversely, the analysis needs to be repeated
from scratch.
in addition to the three steps mentioned earlier, the
general framework also envisions an optional fourth step
that enables the clustering of traces of event logs on the
basis of the correlation analysis results; see the red part (or
gray if printed in gray scale) in fig. 1 . in many settings, an
event-log clustering is an important preprocessing step for
process mining. by grouping similar log traces together, it
may be possible to construct partial process models that
are easier to understand. if the event log shows a lot of
behavioral variability, the process model discovered for all
traces together is too complex to comprehend; in those
cases, it makes sense to split the event log into clusters
and apply discovering techniques to the log clusters, thus
obtaining a simpler model for each cluster. this can be
combined with process cubes where event data are stored
in a multi-dimensional space [6]. prediction trees provide
a simple and visual way to perform such a clustering: each
leaf is associated with a number of event-log traces.
therefore, a cluster is constructed for each leaf.
2.2. formalization
as mentioned in section 2.1 , the main input of our
framework is an event log. an event can have any number
of attributes, here called characteristics. a trace is a
control-flow
data-flow
resource/
organization
time
conformancecontext perspectives
eventcase
resourceprocess
organizationevent 
belongs to 
a case
external context 
unrelated to process and 
organizations (e.g., 
weather)event was 
done by a 
resourceresource 
belongs to an 
organizationcase belongs 
to a process
fig. 2. overview of event characteristics. (a) perspectives to which event characteristics refer. (b) context of a selected event.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 4sequence of events and an event log is a collection of
traces.
definition 1 (events, traces and log ). let cand ube the
universe of characteristics and the universe of possible
values respectively. an event e is an assignment of values
to characteristics, i.e. eac↛u. in the remainder e¼c↛uis
the universe of events. a trace taenis a sequence of
events. let t¼enbe the universe of traces. an event log l
is a multi-set of traces, i.e. labðtþ.3
for each characteristic cac,typeðcþdudenotes the set
of possible values. we use a special value ?for any
characteristic cwhich an event eis not assigning a value
to, i.e. eðcþ¼ ? ifc=2domðeþ. this way eaecan be used as a
total function rather than a partial one. note that ?=2u.
typically, an event refers to an activity that is performed
within a certain case (i.e. process instance) by a resource at a
given timestamp. in our framework, these are treated as
ordinary event characteristics. we assume characteristics such
asactivity ,case,resource ,a n d timestamp but do not treat
them differently. no two events can have exactly the same
values for all characteristics. this is not a limitation, one can
always introduce an event identifier as an additional char-acteristic to ensure uniqueness.
our framework aims to support so-called analysis use
cases .
definition 2 (analysis use case ). an analysis use case is a
triple a¼ðc
r;cd;fþconsisting of
/c15a dependent characteristic crac⧹cd,
/c15a set cddc⧹fcrgof independent characteristics,
/c15an event-selection filter fde, which selects the events
that are retained for the analysis.
the definition of analysis use cases specializes standard
definitions of supervised learning [7]for the process-
mining case. the specialization consists in the fact that
the instances that are used for learning are a subset of the
events in an event log. as a consequence, the dependent
and independent characteristics are linked to the process
attributes that are recorded in the event log.
the result of performing an analysis use case is a
decision or a regression tree that relates the independent
characteristics (also called the predictor or explanatory
variables) to the dependent characteristic (also called the
response variable). fselects the events for which we
would like to make a prediction. sometimes we select all
events, sometimes only the last one in each case, and at
other times all events corresponding to a particular activ-
ity or resource. the events selected through fcorrespond
to the instances used to construct the decision or regres-
sion tree. if we would like to predict the remaining
processing time (the dependent characteristic), then weselect all events and may use independent characteristics
such as the resource that worked on it, the last activity, the
current workload, and the type of customer.as discussed in section 2.1 , many analysis use cases
require the presence of dependent and/or independent
characteristics that are not readily available in the event
log. similarly, using business domain knowledge, an ana-
lyst may want to verify a reasonable hypothesis of the
existence of a correlation to a given set of independent
characteristics, which may not be explicitly available in the
event log.
step 2 in fig. 1 aims to enrich the event log with
valuable information required for the analysis use cases
we are interested in. we provide a powerful framework to
manipulate event logs and obtain a new event log that
suits the specific analysis use case, e.g. events are enriched
with additional characteristics.
definition 3 (trace and log manipulation ). let tbe the
universe of traces and let labðtþbe an event log. a trace
manipulation is a function
δlat-tsuch that for any
tal:jtj¼jδlðtþj.
hence, given a trace tal,δlðtþyields a new trace of the
same length. a trace manipulation function can only add
event characteristics, without removing or adding events.
δlðtþnot only depends on tbut may also depend on
other traces in l. for example, to compute a resource's
workload, we need to look at all traces. δlðtþmay even
depend on any other contextual information (although this
is not formalized here). for example, we may consider
multiple processes or multiple organizations at the same
time and even include weather information.
by applying δlto all traces in l, we obtain a new log
l0¼½δlðtþ∣tal/c138. recall that, technically, a log is multiset of
traces.
after applying various log manipulations, we obtain an
enriched event log where an event may have any number
of event characteristics. then we apply the desired analysis
use case ðcr;cd;fþ. each selected event corresponds to an
instance of the supervised learning problem where the
dependent characteristic cris explained in terms of the
independent characteristics cd. many analysis use cases
require to only consider a subset of all log's events. for
example, if we aim at relating the total case duration to the
number of times a particular resource was involved in it,
we want to consider each case as a whole and, hence,
select the last event of the enriched event log. in this case
the number of instances used to learn a tree classifier is
same as the number of cases in the event log. if we would
like to analyze a decision in the process, then the number
of instances should equal the number of times the decision
is made. hence, fshould select the events corresponding
to the decision we are interested in.
the resulting tree produced by step 3 in fig. 1 may
provide valuable information regarding performance (e.g.,
t i m e ,c o s t s ,a n dq u a l i t y )a n dc o n f o r m a n c e .h o w e v e r ,a s fig. 1
shows it is also possible to use the analysis result to cluster
traces and create smaller event logs. these so-called sublogs
can be used for any type of process mining. for example, we
may compare process models l earned for the different
classes of traces identified in the decision tree.
in addition, it can be given as input to split the traces of
the event logs into groups in order to, e.g., construct partial3given any set x,bðxþdenotes the set of all possible multisets over x.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 5process models that are easier to understand. the trace
clustering can be defined as follows4:
definition 4 (trace clustering ). let tbe the universe of
traces. a trace clustering based on an analysis use case
a¼ðcr;cd;fþis a function λaabðtþ-bðbðtþþsuch that for
anylabðtþ:l+⨄l0aλaðlþl0and for any l0;l″aλaðlþ,i ftal0
and tal″, then l0¼l″.
function λaassociates a multiset of trace clusters to an
event log, where each cluster is again a multiset of traces
(i.e., a sublog). trace clustering cannot generate new traces
and a trace can only belong to one cluster.
note that λadoes not necessarily partition the traces in
the log, e.g., traces can be considered as outliers and,
hence, discarded from any of the clusters.
step 4 in fig. 1 provides the possibility to conduct
comparative process mining [6], i.e., comparing different
variants of the process, different groups of cases, or
different organizational units.
in the remainder of this paper, we provide further
information on how make the concepts discussed opera-
tional. note that the approach described using fig. 1 is very
generic and also fully implement, as extensively discussed
insection 7 .
2.3. use of tree-learning methods to perform analysis use
cases
the result of performing an analysis use case is a
prediction tree: decision or regression tree. decision and
regression trees classify instances (in our case the events
selected through f) by sorting them down in a tree from
the root to some leaf node. each non-leaf node specifies a
test of some attribute (in our case, an independent
characteristic) and each branch descending from that node
corresponds to a range of possible values for this attribute.each leaf node is associated with a value of a class attribute
(in our case, the dependent characteristic). a path from
root to a leaf represents a rule for classification or regres-
sion. there exist numerous algorithms to build a decision
or a regression tree starting from a training set [7]. every
algorithm for constructing a prediction tree takes three
input parameters: (1) a dependent variable (a.k.a. class
variable) c
r, (2) a set of independent variables cd, and (3) a
multi-set iabðeþof instances for constructing the tree.
the multi-set of instances iis constructed starting from
an event log l. given the multi-set eof all events in l, i.e.
e¼⨄tal⨄eate, the multi-set of instances for training is
computed as follows: i¼e∣f.5multi-set icontains every
instance that can be used to train and test the tree
classifier; instances that have been filtered out are dis-
carded. if cross-validation is employed, any instance is
going to be used for both training and testing. obviously, itis also possible to clearly split iin a train and test set. we
do not prevent any possibility from being used, as, for a
specific case, it may be worthwhile exploring both.
our framework is agnostic with respect to specific
algorithms used to construct prediction trees. however,
for a concrete implementation, we opted for the c4.5
algorithm to construct decision tree [7]and the reptree
algorithm to construct regression tree [8]. decision trees
require the dependent variable to be nominal. if not, the
domain of the class attribute needs to be discretized.
literature provides several ways to discretize dependent
variables. while any discretization technique can be
employed, our implementation provides two specific ones:
equal-width binning and equal-frequency binning [9].
3. extracting relevant process characteristics
this section focuses on step 2 in fig. 1 and provides an
overview of different manipulations to enrich the event
log such that the required dependent and independent
variables are present for building the desired decision or
regression tree.
remember that formally trace manipulation is a func-
tion δlat-ttransforming one trace into another while
possibly using the broader context shown in fig. 2 (b). the
trace manipulations described in this section always add
one new event characteristic to each case in the event log.
recall that for any tal:jtj¼jδlðtþj, i.e., no events are
added or removed.
the remainder of this section focuses on showing
examples of manipulation for the different perspectives
offig. 2 (a). the lists of manipulations are far from being
complete since the number of potential manipulations is
infinite. we limit ourself to discuss the manipulations that
are available in implementation at the time of writing.
however, the framework is generic: one can easily plug-in
new manipulations. in fact, also the implementation is
such that one can easily encode new manipulations, as it
will be discussed in section 7 .
in the remainder of section 3 , we also provide formal
definitions for some of the provided examples of the
manipulations. for this aim, we need to introduce some
helper functions and operators that are going to be used in
the definitions.
helper functions and operators : as mentioned in section
2.2,e a c he v e n t eis considered as unique. therefore, given an
event e, we can define functions prefix ðeþand postfix ðeþaen
that return the sequence of events that respectively precede
and follow event ein the same trace. events are aggregations
of process characteristics. given an event e,e(c)r e t u r n st h e
value of characteristic cfor event eif it exists. if no value exists,
the special value ?=2uis returned. given an event eand a
process characteristic as pair ðc;uþac/c2ðu[f ? g þ ,w ei n t r o -
duce the overriding operator e0¼e/c12ðc;uþaesuch that
e0ðcþ¼uand, for each c0ac⧹fcg,e0ðcþ¼eðcþ.w ea l s oi n t r o -
duce the trace concatenation operator /c8as follows: given
two traces t0¼〈e0
1;…;e0
n〉and t″¼〈e″
1;…;e″
m〉,t0/c8t″¼
〈e0
1;…;e0
n;e″
1;…;e0
m〉.g i v e nat r a c e taen, a characteristic
cacand a set of values udu,f u n c t i o n firstocc ðt;c;uþreturns
the first occurrence of any value uauin trace tfor4the union operator ⨄is defined over two multiset sets. given 2
multi-sets aand b,a⊎bis a multiset that contains all elements of aand b;
the cardinality of each element eaa⊎bis the sum of the cardinalities of e
inaand b.
5operator ∣fis the defined as follows: given a multi-set eand a set f,
e∣fcontains all elements that occur in both eand fand the cardinality of
each element eae∣fis equal to the cardinality of eine.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 6characteristic c. it can be recursively defined as follows:
firstocc ð〈〉;c;uþ¼ ?
firstocc ð〈e〉/c8t0;c;uþ
¼eðcþ ifeðcþau
firstocc ðt0;c;uþifeðcþ=2u(
s i m i l a r l y ,o n ec a nd e f i n et h el a s to c c u r r e n c e : last occ ð〈e1;…;
en〉;c;uþ¼firstocc ð〈en;…;e1〉;c;uþ
3.1. control-flow perspective
the control-flow perspective refers to the occurrence
and ordering of activities.
trace manipulation cfp1 x:number of executions of
activity xuntil the current event. this operation counts
the number of times xwas executed until the current
event in the trace. this event characteristic is added to all
traces. formally, given a trace t¼〈e1;…;en〉aen,
cfp1xðtþ¼ 〈e0
1;…;e0
n〉aenwhere, for 1 rirn,e0
i¼ei/c12
ðcfp1;nþwith n¼j fe″aprefix ðeþ∣e″ðactivity þ¼eðactivity þgj.
trace manipulation cfp2 x:first occurrence of any
activity in set aafter current event. this operation
augments every event ewith the name of the activity that
belongs to set xand firstly occurs in the trace after e.i f
there is no next event or no activity in xthat occurs in the
trace after e, special value ?is used. set xcan be
technically empty but it would be meaningless: any event
would be always augmented with the ?value. if set x
contains all activities to which log's events refer, the event
is augmented with the name of the activity that follows e
in the trace, or ?if such an event is the last in the trace.
formally, given a trace t¼〈e1;…;en〉aen,cfp2xðtþ¼ 〈e0
1;…;
e0
n〉aenwhere, for 1 rirn,e0
i¼ei/c12ðcfp2;uþwith
u¼firstocc ðpostfix ðeþ;activity ;xþ
trace manipulation cfp3 :previous activity in the
trace. this operation determines the activity directly
preceding the current event in the same case (i.e. the
same log trace). if there is no previous event, a ?value is
used. formally, given a trace t¼〈e1;…;en〉aen,cfp3ðtþ¼
〈e0
1;…;e0
n〉aenwhere e0
1¼e1/c12ðcfp3;?þand, for 1 oirn,
e0
i¼ei/c12ðcfp3;ei/c01ðactivity þþ.
trace manipulation cfp4 :current activity. this
operation determines the current event's activity name.
strictly speaking no manipulation is needed since this is
already an event attribute. nevertheless, we list it to be
able to refer to it later.
one can think of many other control-flow trace manip-
ulation, e.g., counting the number of times a given activity
is followed by another activity.
3.2. data-flow perspective
next we consider the data-flow perspective. here we
focus on the data attributes attached to events, these may
refer to the event itself or to properties of the case the
event belongs to. let us recall that uindicates that
universe of possible values which a characteristic can
take on.trace manipulation dfp1 c:latest recorded value of
characteristic cbefore current event. this operation deter-
m i n e st h el a t e s tv a l u eo fs o m ea t t r i b u t e cnot considering the
current event. note that, when enriching a certain event e,
there may be multiple events before ein the same trace that
assign a value to c. then, we consider the latest of these
events. if the attribute was not present in any of the preceding
events, a ?value is returned. as before all events are
preserved in the trace; this characteristic is added to each
event. formally, given a trace t¼〈e1;…;en〉aen,dfp1cðtþ¼
〈e0
1;…;e0
n〉aenwhere, for 1 rirn,e0
i¼ei/c12ðdfp1c;uþwith
u¼lastocc ðprefix ðeþ;c;uþ.
trace manipulation dfp2 c:latest recorded value of
characteristic cuntil current event. this operation
determines the latest value of calso considering the
current event. if the current event has attribute c, then
the corresponding value is the latest value. if not, the
previous events for the same case are considered. for-
mally, given a trace t¼〈e1;…;en〉aen,dfp2cðtþ¼ 〈e0
1;…;
e0
n〉aenwhere, for 1 rirn,e0
i¼ei/c12ðdfp2c;uþwith
u¼lastocc ðprefix ðeþ/c8 〈e〉;c;uþ.
trace manipulation dfp3 c:average value of charac-
teristic cuntil the current event. this operation aug-
ments an event ewith the average of the values assigned
to characteristic cbyeand by those events that are
preceding ein the trace. formally, given a trace
t¼〈e1;…;en〉aen,dfp3cðtþ¼ 〈e0
1;…;e0
n〉aenwhere, for
1rirn,e0
i¼ei/c12ðdfp3c;uþwith u¼avge″aprefix ðeþ/c8 〈e〉eðcþ.6
trace manipulation dfp4 c:maximum value of char-
acteristic cuntil the current event. this operation
augments an event ewith the maximum value assigned
to characteristic cbyeand by those events that are
preceding ein the trace. formally, given a trace
t¼〈e1;…;en〉aen,dfp4cðtþ¼ 〈e0
1;…;e0
n〉aenwhere, for
1rirn,e0
i¼ei/c12ðdfp4c;uþwith u¼max e″aprefix ðeþ/c8 〈e〉eðcþ
(footnote 6).
trace manipulation dfp5 c:minimum value of char-
acteristic cuntil the current event. this operation
augments an event ewith the minimum value assigned
to characteristic cbyeand by those events that are
preceding ein the trace. formally, given a trace
t¼〈e1;…;en〉aen,dfp5cðtþ¼ 〈e0
1;…;e0
n〉aenwhere, for
1rirn,e0
i¼ei/c12ðdfp5c;uþwith u¼min e″aprefix ðeþ/c8 〈e〉eðcþ
(footnote 6).
trace manipulation dfp6 c:sum of value of charac-
teristic cuntil the current event. this operation aug-
ments an event ewith the sum of the values assigned to
characteristic cbyeand by those events that are preceding
ein the trace. formally, given a trace t¼〈e1;…;en〉aen,
dfp6cðtþ¼ 〈e0
1;…;e0
n〉aenwhere, for 1 rirn,e0
i¼ei/c12
ðdfp6c;uþwith u¼p
e″aprefix ðeþ/c8 〈e〉eðcþ(footnote 6).
note that, of course, manipulations dfp3c;…;dfp6care
only applicable if cis numerical, such as a timestamp, a
cost or the customer's age.
6to keep the notation simple, we assume here that functions avg,
min and max and the sum operatorpautomatically exclude all
occurrences of value ?. also, when the functions and the operator are
applied over an empty set, they return ?.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 73.3. resource and organization perspective
the resource and organization perspective focusses on
the resource executing the event or corresponding activity
instance. resources may be grouped in different organiza-
tional entities (groups, roles, positions, departments, etc.).
for the manipulations listed below we do not provide a
formal introduction because it would not add much to the
textual description, unless the workload calculations are
explained in detail, which is out of the scope of this paper.
to compute the total workload or that of a single resource,
we employ the approach discussed in [2].
trace manipulation rop1 :workload per resource.
events may be related to resources. by scanning the event
log one can get an indication of the amount of work
performed in a particular period. moreover, one can also
see waiting work items that are later executed by a
particular resource. the resource's workload at the time
the event occurs can be attached to the event.
trace manipulation rop2 :total workload. the pre-
vious event characteristic is related to the particular
resource performing the event. however, we can also take
the sum over all running or queuing work items. for
example, we can simply count the number of activities
in-between a start and complete event.
trace manipulation rop3 :current resource. this
operation determines the current event's resource (if
any). strictly speaking no manipulation is needed, because
it is already part of the event. however, we list it to be able
to refer to it later.
trace manipulation rop4 :current role. this opera-
tion determines the role of the current event. this can be
already part of the event; in that case, no manipulation is
needed. if not, it can be derived by cross-correlatingorganizational information, stored, e.g., in a database,
and the current resource.
many other resource-related event characteristics are
possible: many ways exist to measure workload, utiliza-
tion, queue lengths, response times, and other
performance-related properties. information may be
derived from a single process or multiple processes.
3.4. time perspective
the time perspective refers to various types of dura-
tions (service times, flow times, waiting times, etc.) in
processes. clearly the resource/organization perspective
and the time perspective are closely related.
some of the manipulations for the resource/organiza-
tion perspective have already exploited transactional infor-
mation in the event log. for example, to measure the
number of running activity instances, we need to correlate
the start events and the complete events. schedule, start,
complete, suspend, resume, etc. are examples of possible
transaction types [1]. each event has such a transaction
type (default is complete ). an activity instance corresponds
to a set of events. for one activity instance there may be a
schedule event, a start event, a suspend event, a resume
event, and finally a complete event. the duration of an
activity instance is the time between the start event and
thecomplete event.trace manipulation tip1:activity duration. the char-
acteristic adds information on activity instance durations
to complete events. we can measure the duration of an
activity instance by subtracting the timestamp of the start
event from that of the complete event, under the assump-
tion that never more than one instance of the given
activity is concurrently being executed.7formally,
t¼〈e1;…;en〉aen,tip1ðtþ¼ 〈e0
1;…;e0
n〉aenwhere, for
1rirn:
/c15ifeiðtransition þa“complete ”, then e0
i¼ei;
/c15if eiðtransition þ¼ “complete ”, then e0
i¼ei/c12
tip1;eiðtimestamp þ/c0ejðtimestamp þ/c0/c1such that joi
and ejðactivity þ¼eiðactivity þand, for all jokoi,
ekðactivity þaeiðactivity þ.
note that start or complete events may be missing and
that correlation may be non-trivial [1]. hence, there are
multiple ways to measure activity durations in these cases.
we support the approach in [2]where the start time is
approximated as follows: it either the time of completion
of the previous activity within the same process instance
or the time of completion of the previous activity by the
same resource (possibly in a different process instance)
depending on which one comes latest. this is based on the
assumption that the resource could have started to work
on the activity if the previous activity completed and the
resource was not working on other activities. the full
formalization is beyond the scope of this paper.
trace manipulation tip2:time elapsed since the
start of the case. each non-empty case has a first event.
the timestamp of this event marks the start of the case.
events corresponding to the same case also have a time-
stamp. the difference between both corresponds to the
elapsed since the start of the case. this information is
added to all events. formally, given a trace t¼〈e1;…;
en〉aen,tip2ðtþ¼ 〈e0
1;…;e0
n〉aenwhere, for 1 rirn,
e0
i¼ei/c12ðtip2;eiðtimestamp þ/c0e1ðtimestamp þþ.
trace manipulation tip3:remaining time until the
end of case. each non-empty case has a last event. the
timestamp of this event marks the end of the case. events
corresponding to the same case also have a timestamp.
the difference between both corresponds to the remaining
flow time. this information is added to all events. for-
mally, given a trace t¼〈e1;…;en〉aen,tip3ðtþ¼ 〈e0
1;…;
e0
n〉aenwhere, for 1 rirn, e0
i¼ei/c12ðtip3;
enðtimestamp þþ/c0eiðtimestamp þþ.
trace manipulation tip4:case duration. this event
characteristic measures the difference between the last
event and first event of the case the current event belongs
to. formally, given a trace t¼〈e1;…;en〉aen,tip4ðtþ¼
〈e0
1;…;e0
n〉aenwhere, for 1 rirn,e0
i¼ei/c12ðtip4;
enðtimestamp þþ/c0e1ðtimestamp þþ.
trace manipulation tip5:current timestamp. this
information corresponds to the event's timestamp. strictly
7experience shows this assumption holds in the large majority of
processes due to the fact that information systems rarely support thepossibility of concurrently starting multiple instances of the same activitywithin the same process instance.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 8speaking no manipulation is needed since this is already
an event attribute. nevertheless, we list it to be able to
refer to it later.
other time-related event characteristics are also possi-
ble. for example, if schedule events are present, one can
measure waiting times and attach this information to
events.
3.5. conformance perspective
the time perspective is important for performance-
related questions. however, process mining also includes
conformance-related questions in the context of compli-
ance management, auditing, security, etc. to be able to
answer conformance-related questions we need to have a
specification of the desired behavior. this may be a
complete process model or just a set of simple rules. here
we consider two forms of specified normative behavior:
(1) a process model (typically a petri net) and (2) a
constraint expressed in terms of ltl (linear temporal
logic). the ltl-based checking is based on the technique
described in [10]. the others rely on the prom implemen-
tation of the techniques discussed in [11], which are
concerned with finding an alignment of traces in the log
with the control flow of process models. an extension of
the technique is provided in [12] where the other per-
spectives are also considered. note that these are just
examples, any evaluation of the observed behavior with
respect to the normative behavior can be used (including
declarative languages like declare).
to understand such trace manipulations, it is important
to understand the seminal notion of alignments [11].t o
establish an alignment between process model and event
log we need to relate “moves ”in the log to “moves ”in the
model. however, it may be the case that some of the
moves in the log cannot be mimicked by the model andvice versa. basically, there are three kinds of moves after
alignment:
/c15ðe;⪢þis a “move on log ”, i.e., in reality an event e
occurred that could not be related to a move of
the model,
/c15ð⪢;aþis a “move on model ”, i.e., in the process model
activity aneeds to be executed, but in reality there was
no related event that actually occurred, and
/c15(e,a)i sa “synchronous move ”if in reality an event e
occurred that corresponds to an activity aexecuted in
the model and vice versa.
in an optimal alignment the number of synchronous
moves is maximized and the number of moves on log
and moves on model is minimized. the optimal alignment
of a trace wrt a given model is also used to compute the
fitness of a trace. fitness is measured as a value between 0
and 1; value 1 indicates perfect fitness, which means that
the alignment only contains synchronous moves (thus, no
deviations). as the percentage of moves on log and model
over all moves increases, the fitness value decreases. value
0 indicates a very poor fitness. interested readers are
referred to [12,13].trace manipulation cop1 p:trace fitness. given a
process model p, it augments each event with the value
of fitness of the trace to which the event belongs
trace manipulation cop2 p,a:number of not allowed
executions of activity athus far. using process model p
an optimal alignment is created per trace. this trace
manipulation augments each event ewith an integer
characteristic that denotes the number of “moves on
log”. it counts the number of times something happened
in reality before ein the corresponding trace that was not
possible or allowed according to the process model p[11].
trace manipulation cop3 p,a:number of missing
executions of activity athus far. this trace manipulation
augments each event with the number of “moves on
model ”. it counts the number of times something had to
happen in model pbefore ein the corresponding trace
although it did not happen in reality [11].
trace manipulation cop4 p,a:number of correct
executions of activity athus far. this trace manipulation
augments each event the number of “synchronous moves ”,
i.e., the number of times that, before ein the correspond-
ing trace, an event actually occurred when it was expected
according to the model p[11].
trace manipulation cop5 f:satisfaction of formula f
considering the whole trace. this trace manipulation
augments each event with an additional boolean charac-
teristic and assigns a true value if and only if formula fis
satisfied. up to this date, formula fcan be defined through
ltl and checked using the ltl checker discussed in [10].
3.6. trace manipulation: a concrete example
the trace manipulations described thus far have all
been implemented in prom (see the featureprediction
package). note that the set of manipulations is not fixed
and can be extended. also note that any context informa-
tion can be used to enrich the event log with further
information, i.e., it is not limited to the perspectives in
fig. 2 (a) and may include truly external things like
weather or traffic information.
table 1 illustrates the application of two trace manip-
ulation functions to a fragment of an event log. as a result,
two event characteristics have been added to each event;
characteristic nextactivityintrace is nominal whereas elap-
sedtime is numerical. this shows that the log manipula-
tions are applied to create both nominal and numerical
characteristics. let us denote the set of all activity names
seen in the event log with xl, i.e. xl¼{preoperative
screening, laparoscopic gastrectomy, nursing, first hospital
admission }. trace manipulation first occurrence of any
activity in set x lafter current event ðcfp2xlþwas used to
add the next activity to each event. note that the last event
of each case has value ?because there is no next activity.
trace manipulation time elapsed since the start of the case
(tip2) adds durations. note that the last event of each case
now has a characteristic capturing the case's flow time.
4. event selection ﬁlter
as described in definition 2 an analysis use case is a
triplet ðcr;cd;fþ. the trace manipulations discussed in
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 9section 3 can be used to create the dependent character-
istic crand the independent characteristics cd. in this
section we elaborate on the choices for the event-
selection filter fdethat selects the events that are
retained for the analysis. recall that each of the remaining
events corresponds to an instance of the learning problem
that aims to explain crin terms of cd.
recall that we assume that events are uniquely identi-
fiable, i.e., no two events have identical attributes. there
are two extremes: we can retain all events or just one
event per case. however, we can also retain selectedevents, e.g., all complete events.
event filter ef1:keep all events. no events are
removed and all are kept. formally, ef1¼e.
event filter ef2:keep first event only. per case only
the first event is retained. given a trace t〈e
1;e2;…en〉, only
e1is kept and the rest is removed. formally,
ef2¼feae:prefix ðeþ¼ 〈〉g.
event filter ef3:keep last event only. per case only
the last event is retained. given a trace t〈e1;e2;…en〉, only
enis kept and the rest is removed. formally,
ef3¼feae:postfix ðeþ¼ 〈〉g.
event filter ef4:keep all complete events. only
events that have as transaction type complete are retained.
all other events (e.g., start events) are removed. formally,
ef4¼feae:eðtransition þ¼“complete ”g.
event filter ef5:keep all start events. only events
that have as transaction type start are retained. formally,
ef5¼feae:eðtransition þ¼″start″g.
event filter ef6 a:keep all events corresponding to
activity a. only events that correspond to activity aare
retained. formally, ef6a¼feae:eðactivity þ¼ag.
event filter ef7 r:keep all events corresponding to
resource r. only events that were performed by resource r
are retained. formally, ef7r¼feae:eðresource þ¼rg.
event filter ef8 f:keep all events satisfying a given
formula f. fis a user-provided boolean expression defined
over the set cof names of process characteristics. fcanmake use of relational operators o;4;¼and logical
operators, namely conjunction ð4þ, disjunction ð3þ, and
negation ð:þ. this filter retains all events for which f
evaluate to true. this generalizes filters ef4;…;ef7. for
instance, filter ef4¼ef8transition ¼″complete″. filter ef1is also
a specialization: ef1¼ef8true
it is also possible to combine a set of filters f1;…;fn
where, for all 1 rirn,fide. the combined filter bfis
equal to ⋂ian:1rirnfi. for instance, if one wants to keep
allcomplete events corresponding to activity a, the filter is
ef4\ef6a.
the event-selection filter fselects the instances used to
learn the desired tree. some analysis use cases require to
have one instance per case. table 2 shows the application
of event filter keep last event only (ef3) totable 1 .
5. overview of process-related questions that can be
answered
literature proposes several research works to correlate
specific process characteristics to each other. this section
aims to illustrate that those works propose ad hoc solu-
tions for a more general problem: finding any type of
correlation among arbitrary process characteristics at any
level (event, case, process, resource, etc.). our framework
attempts to solve the more general problem. in this way,
we can certainly perform the same correlation analyses as
those research works. however, by applying the appro-
priate trace manipulations and event-filter functions
described earlier and by choosing the correct dependent
and independent characteristics, we can provide an
answer to many more correlation analyses.
tables 3 and4illustrate concrete analysis use cases that
allows for performing the same correlation analyses as in
many earlier research works. this illustrates that it is
possible to unify existing approaches. for the sake of
simplifying the definition of the analysis use cases, we
assume that all trace manipulations described in section 3table 1
fragment of a hospital's event log with four traces. let us denote the set of all activity names seen in the event log with xl. the gray columns have been
added after applying two trace manipulations: first occurrence of any activity in set x lafter current event ðcfp2aexþand time elapsed since the start of the
case (tip2).nextactivityintrace andelapsedtime are the names of the characteristics that are added as a result of these manipulations.
case timestamp activity resource cost nextactivityintrace elapsedtime
1 1-12-2011:11.00 preoperative screening giuseppe 350 laparoscopic gastrectomy 0 days
1 2-12-2011:15.00 laparoscopic gastrectomy simon 500 nursing 1.16 days
1 2-12-2011:16.00 nursing clare 250 laparoscopic gastrectomy 1.20 days
1 3-12-2011:13.00 laparoscopic gastrectomy paul 500 nursing 2.08 days1 3-12-2011:15.00 nursing andrew 250 first hospital admission 2.16 days1 4-12-2011:9.00 first hospital admission victor 90 ? 3.92 days
2 7-12-2011:10.00 first hospital admission jane 90 laparoscopic gastrectomy 0 days2 8-12-2011:13.00 laparoscopic gastrectomy giulia 500 nursing 1.08 days2 9-12-2011:16.00 nursing paul 250 ? 2.16
3 6-12-2011:14.00 first hospital admission gianluca 90 preoperative screening 0 days
3 8-12-2011:13.00 preoperative screening robert 350 preoperative screening 1.96 days
3 10-12-2011:16.00 preoperative screening giuseppe 350 laparoscopic gastrectomy 4.08 days3 13-12-2011:11.00 laparoscopic gastrectomy simon 500 first hospital admission 6.88 days3 13-12-2011:16.00 first hospital admission jane 90 ? 7.02 days
4 7-12-2011:15.00 first hospital admission carol 90 preoperative screening 0 days4 9-12-2011:7.00 preoperative screening susanne 350 laparoscopic gastrectomy 0.66 days4 13-12-2011:11.00 laparoscopic gastrectomy simon 500 nursing 5.84 days4 13-12-2011:13.00 nursing clare 250 nursing 5.92 days
4 13-12-2011:19.00 nursing vivianne 250 ? 6.16 days
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 10are applied. of course, in practice, one only needs to apply
the sub-set of log manipulations that generate character-
istics that are used in the definition of the analysis use
case.
letcavail be the set of characteristics available in the
original event log l, which are not obtained through trace
manipulations. every event of a log always contains the
activity name; hence, the activity characteristic is always
incavail. let xldenote the set of all values observed for the
activity characteristic in an event log l.
6. trace clustering based on analysis use cases
as already discussed, the performance of an analysis
use case produces a decision or a regression tree. these
trees can be used to cluster event logs. our clustering
algorithm requires that each trace is associated with one
single event; for instance, this is guaranteed by the event
filters ef2and ef3insection 4 . as discussed in section 2.3 ,
each event becomes a training/test instance for learning
decision or regression trees. therefore, each trace is linked
to one single instance that is exactly associated with oneleaf of the tree. our basic idea for clustering is that all log
traces associated with the same leaf are grouped within
the same cluster; therefore, there are as many clusters as
the number of leaves in the decision tree.
for the sake of explanation, let us consider the second
analysis use case in table 3 :“prediction of the outcomes of
the executions of process instances ”and assume variable
outcome is numerical. the tree that results from this
analysis use case can be used to cluster traces according
to the outcome's value. therefore, each cluster groups
traces that record executions of process instances with
similar outcomes. however, traces with similar outcomes
may still be in different clusters if they have with different
values for other process characteristics. this happens
when the tree contains two different leaves with similar
values for the outcome variable.
the significant intervals of values of process character-
istics that determine the cluster to which to add a given
instance are not known in advance; conversely, they are
computed as a result of the construction of the tree. if they
were known in advance, one can easily define clusters by
adding traces to cluster according to the values of such atable 2
the retained events after applying event filter keep last event only (ef3) to the event log shown in table 1 .
case timestamp activity resource cost nextactivityintrace elapsedtime
1 4-12-2011:9.00 case victor 90 ? 3.92 days
2 9-12-2011:16.00 case paul 250 ? 2.16 days
3 13-12-2011:16.00 case jane 90 ? 7.02 days
4 13-12-2011:19.00 case vivianne 250 ? 6.16 days
table 3
three analysis use cases that illustrate how our framework works to unify existing approaches to correlate specific process characteristics.
#1.analysis use case ðcop5f;fcfp4;rop3;8cacavaldfp1cg;ef1þ:run-time predictions of violations of formula f. the aim of this use case is to
predict, given the current status of the process instances, the next activities to work on to maximize the chances of achieving a given business
goal expressed using some ltl formula f. the selected dependent characteristic is cop5f(“satisfaction of formula fconsidering the prefix trace
until current event e”), the selected independent characteristics are cfp4 (“current activity ”),rop3 (“current resource ”), and dfp1c(“latest
recorded value of characteristic cbefore current event ”) for all recorded characteristics c. the selected event-selection filter is ef1(“keep all
events ”). in [14], an ad hoc solution is proposed for this problem where formulas are expressed in ltl
#2.analysis use case ðdfp2outcome ;f8cacavail⧹foutcome gdfp2cg;ef3þ:prediction of the outcomes of the executions of process instances, which is
stored as characteristic outcome . the goal of this use case is to predict the outcome of a case. predictions are computed using a set of complete
process instances that are recorded in the event log. the last event of each trace is associated with a characteristic outcome , which may be
numerical or nominal (including boolean) depending on the specific setting. the prediction is done at the case level: one instance for learning iscreated for each trace in the event log. the dependent characteristic is dfp2
outcome (“latest recorded value of characteristic outcome after
current event ”) for a specific outcome or interest. the selected independent characteristics are dfp2cfor all event characteristics cexcept
outcome . the chosen event-selection filter is ef3(“keep last event only ”). in [15], an ad hoc solution is proposed for this problem. in fact this
analysis use case is very close to traditional data mining where the case is considered as a whole rather than rooming in on the individual eventsand behavior. conforti et al. also proposes an ad hoc solution to predict whether or not an process instance is going to complete with a fault. ifcompleted with a fault, its magnitude is also predicted [16]. in this case, the outcome is a numerical value that ranges between 0 and 1, whereas 0
indicates no fault and 1 the highest level of fault
#3.analysis use case ðcfpa
x;f8cacavaildfp2cg;ef4\ef6xþ:mining of conditions at a decision point that determine the activity to execute within
a set x /c26xlafter execution of an activity xaxl. this analysis use case aims to determine the conditions that enable the execution of one of
multiple activities when the execution flow reaches a decision point. using the bpmn notation, a decision point is represented through theexclusive choice construct. an example of decision point analysis is shown in fig. 3 using the bpmn notation, where we aim to discover which
conditions enable a,borcfor execution. for the analysis use case, we retain every event of type complete (i.e. filter ef4is applied) that is referring
to executions of activity
x(i.e.ef6x). for our example, x¼z, which is the activity before the decision point. these conditions are defined over the
process variables, which are the characteristics cavailpresent in the original event log. therefore, characteristic dfp2c(“latest recorded value of
characteristic cuntil current event ”) is used as an independent characteristic for all cacavail. the dependent characteristic is cfpa x(“first
occurrence of any activity in set xafter current event ”) where xis the set of activities that are at the decision point; for our example, x¼fa;b;cg.
in[17], an ad hoc solution is proposed for this problem
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 11variable. however, even in the case, traces with similar
values for the dependent characteristic but very different
values for other relevant characteristics would be grouped
in the same cluster, which, hence, would still contain
traces with heterogenous behavior.
when using any classifier, it is extremely common to
have outliers, which in our framework translates to having
traces to be filtered out and included in no cluster.
according to our clustering criteria, one trace can
belong to one cluster only. in the following, we discuss
whether the trace should be retained in its own cluster or
filtered out.
this depends on whether the result of performing an
analysis use case is a decision or regression tree. let cand
ube the universe of characteristics and the universe of
possible values, respectively; also e¼c↛uis the universe
of events.
decision tree: let us suppose to have a decision tree for a
dependent characteristic cac. this decision tree
is learned from a set iabðeþof instances, each of
which is associated with one different trace. letus suppose to have a log trace that corresponds
to an instance iai. according to the decision
tree, this instance is classified as belonging to a
tree leaf lwith value vfor characteristic c. trace t
is retained in the cluster for lifiðcþ¼v, i.e. it is
correctly classified.
regression tree: let us suppose to have a regression tree
trfor a dependent characteristic c. this decision
tree is learned from a multi-set iof instances.
let us suppose to have a log trace tthat corre-
sponds to an instance iai. according to regres-
sion tree tr,iðcþshould be vexp
tr;i;car. however,
differences can occur; therefore, we introduce
the mean absolute percentage error (mape) ofinstance iwhen predicting through regression
tree tras follows:
mape
tr;i;ci;cðþ ¼ 100%iðcþ/c0vexp
tr;i;c
iðcþ/c12/c12/c12/c12/c12/c12/c12/c12/c12/c12ð1þ
the trace associated with an instance iis
retained if mape
tr;i;cði;cþox%where xis a cut-
off threshold that is defined by the process
analyst. clearly, a larger value for xfilters out
fewer instances. if x¼0, only instances with
exactly the same value for the dependent char-
acteristic are retained. as said, this extreme is
undesirable: it would probably remove most of
traces, since it is unlikely to have exactly the
same value for the dependent characteristic.
in sum, our approach has the advantage of dynamically
computing the intervals of the dependent characteristic
that determine the clusters to which instances are added.
furthermore, it can determine whether single traces are
outliers and, thus, should be excluded from further analysis.
when employing regression trees, the determination of the
value to assign to the cut-off threshold is not always easy.
section 7.1 discusses an example where it has been
crucial to discard a number of traces from a clustertable 4
additional analysis use cases that further illustrate how our framework research works unify existing approaches to correlate specific processcharacteristics.
#4. analysis use case ðrop3;f8
cacavaildfp1c;…g;ef6xþ:prediction of the executor of a certain activity x. the goal is to discover the conditions that
determine which resource is going to work on a given activity xduring the process execution. the dependent characteristic is rop3 (“current
resource ”). the set of independent characteristics contain a characteristic dfp2c(“latest recorded value of characteristic cbefore current event ”)
for each cacavail, at least. however, potentially any characteristic obtained through trace manipulation can be used to predict the executor; this
explains the presence of “…”in the definition of the set of independent characteristics. since the analysis use case is restricted to a single activity,
the selected event-selection filter is ef6x(“keep all events corresponding to activity x”)
#5. analysis use case ðtip3;f8xaxlcfp1x;8cacavaildfp2c;…g;ef1þ:prediction of the remaining time to the end of the process instance . the goal is,
given a running process instance, to predict how long it would take for that instance to conclude. all the events are used to train the tree-based
classifier and, hence, the event filter is ef1(“keep all events ”). the analysis use case aims to predict the remaining time; hence, the dependent
characteristic is tip3 (“remaining time until the end of case ”). as far as concerning the independent characteristics, any characteristics that can
be obtained through trace manipulation may be suitable; this explains the presence of “…”in the definition of the set of independent
characteristics. certainly, the following characteristics should be included: dfp2c(“latest recorded value of characteristic cuntil current event ”)
for each cacavailas well as cfp1x(“the number of executions of activity xuntil the current event ”) for each activity xobserved in the event log (i.
e. for all xaxl). it is similar to [18] when a multi-set abstraction is used; additionally, the current values of process variables are also taken into
account
za
b
c
y
fig. 3. example of decision point analysis. our framework can find the
conditions that determine which activity is enabled at a decision point. inthis figure, the decision point is highlighted through a circle: the analysisaims to discover the disjoined conditions that enable the three activities:a,band c.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 12because they were considered as noise. the example also
shows how, sometimes, one wants to discard an entire
cluster, as each of the comprised traces is, in fact, noise.
7. implementation and evaluation
the general framework discussed above is implemen-
ted as a plug-in of prom, an open-source “pluggable ”
framework for the implementation of process mining tools
in a standardized environment (see http://www.prom
tools.org ). the prom framework is based on the concept
of packages each of which is an aggregation of several
plug-ins that are conceptually related. our new plug-in is
available in a new package named featureprediction , which
is available in prom version 6.4.
the main input object of our plug-in is an event log,
whereas the output is a decision or a regression tree. the
construction of decision and regression trees relies on the
implementations of algorithms c4.5 and reptree developed
in the weka toolkit.8as mentioned before, our framework
envisions the possibility to au gment/manipulate the event
logs with additional features. on this concern, the tool iseasily extensible: a new log manipulation can be easily
plugged in by (1) implementing 3 methods in a java class
that inherits from an abstract class and (2) programmatically
adding it to a given java set of available log manipulations.
this section illustrates how our framework can be used to
help uwv. uwv (employee insurance agency) is an auton-
omous administrative authority to implement employee
insurances and provide labor market and data services.
within uwv, several processes are carried on to provide
different types of social benefits for residents in the nether-
lands. this paper analyzes two of their processes.
the first process is concerned with providing support
for dutch residents when they develop disabilities whilst
entitled to unemployment benefits; later on, we refer to
this process as illness-management process . uwv provides
illness benefits for these ill people, hereafter referred to as
customers, and provides customized paths for them to
return to work. the customer is supported and assessed by
a team that consists of a reintegration supervisor, an
occupational health expert and a doctor. they cooperate
to assess the remaining labor capacity of the employee
during the illness. if the person is not completely recov-
ered after two years, the employee can apply for the work
and income according to labor capacity act (wia).
the second process is about ensuring that benefits are
provided quickly and correctly when a dutch resident
ceases a work contract and cannot immediately find a
new employment; later, we refer to this as unemployment
process . an instance of this process starts when a person,
hereafter referred to as customer, applies. subsequently,
checks are performed to verify the entitlement conditions.
if the checks are positive, the instance is being executed
for the entire period in which the customer receives themonetary benefits, which are paid in monthly install-
ments. entitled customers receive as many monthly
installments as the number of years for which they wereworking. therefore, an instance can potentially be exe-
cuted for more than one year.
uwv is facing various undesired executions of these
two processes. for the unemployment process, uwv is
interested in discovering the root-causes of a variety of
problems identified by uwv's management; for the
illness-management process, uwv is interested to gain
an insight about how process instances are actually being
carried out.
for the illness-management process , uwv is interested to
discover if there is any correlation between the character-
istics of the process instances and the duration of their
execution. the reason is that uwv is trying to reduce the
duration of the execution of long instances with the
purpose of speeding up the reintegration of the customers
into the job market. in section 7.1 , we illustrate one analysis
use case that aims to discover the causes that determine
whether a process execution is longer or shorter. in addi-
tion, we show that it is useful to cluster the event log
according to this analysis use case. without clustering the
event log, we discover a single process model that does not
provide insights into how process instances are carried out:
the resulting model is too imprecise as it would allow for
too much behavior. conversely, by splitting the event log
into clusters according to the case duration, we can discover
insightful process models.
for the unemployment process , during the entire period,
customers must comply with certain duties, otherwise a
customer is sanctioned and a reclamation is opened. when
a reclamation occurs, this directly impacts the customer,
who will receive lower benefits than expected or has to
return part of the benefits. it also has negative impact from
uwv's viewpoint, as this tends to consume lots of
resources and time. therefore, uwv is interested to knowthe root causes of opening reclamations to reduce their
number. if the root causes are known, uwv can predict
when a reclamation is likely going to be opened and,
hence, it can enact appropriate actions to prevent it
beforehand. section 7.2 discusses a number of analysis
use cases that aim to predict when reclamations are likely
to happen.
7.1. discovery of the illness management process
for the illness management process , uwv is interested
to discover how process instances are being carried out. in
order to answer this question through the application of
process mining, we used an event log lcontaining 1000
traces.
fig. 4
shows the bpmn process model that has been
discovered from the event log with 1000 traces, men-
tioned above. in particular, we employ the so-called
“inductive miner ”[19] using a noise threshold of 30%.
the inductive miner generates a petri net, which has
subsequently been converted into a bpmn model [20].
the resulting model contains a loop that internally com-
prises an exclusive choice between 19 activities. this
means that these 19 activities can occur an arbitrary
number of times in any order, interleaved with few
additional activities. therefore, the model is clearly8http://weka.sourceforge.net/
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 13unsatisfactory because it is not sufficiently precise: an
excessively large variety of behavior is possible.9
this result is due to the fact that the miner tries to
discover one single process model out of an event log that
records heterogenous process behavior. in these situations,
as mentioned above, it is advisable to split the event log in
clusters, each comprising traces with similar behavior, and
to discover one model per cluster.
uwv had the opinion that the behavioral heterogeneity
can be tackled by splitting the event log based on the
process-instance duration. if instances of the same dura-
tion have similar behavior, then this can lead to discover a
set of more precise process models. for this purpose, we
defined and performed an analysis use case where:dependent characteristic: case duration ( tip4).
independent characteristics: the number of executions of
each activity xobserved in the log ( dfp2x) and
the latest value observed for each characteristic c
presented in log.
filter: the last event of each trace ( ef3): each process
instance needs to be considered as a whole.
since the case duration is a numerical value, we opted
for generating a regression tree.
7.1.1. visual interface
fig. 5 illustrates a screenshot of the tool where we show the
regression tree that provides an answer for the analysis use
case in question. before continuing to report on the application
of our framework, it is worthwhile to quickly discuss on how
regression and decision trees are visualized in the tool.
in particular, each internal node refers to a different process
characteristic, which concerns with one of the five process
perspectives considered in section 3 : control-flow, data-flow,
resource, time and conformance. compared with the imple-
mentation reported in [21], the nodes of the trees are now
filled in with a color. the color of an internal node depends on
the perspective of the referred process characteristics. for
fig. 4. discovery of the bpmn process model for the ill-management process when using every trace in log.
9there are various ways to quantify the notion of precision. here, we
employ the notion presented in [11,1]. a model is precise if it does not
allow for “too much ”behavior. a model that is not precise is “under-
fitting ”. underfitting is the problem that the model allows for behavior
unrelated to example behavior seen in the log. intuitively, precision is the
ratio between the amount of behavior observed in the event log and
allowed by the model and the total amount of behavior allowed by themodel. precision is 1 if all modeled behavior was actually observed in theevent log. values close to 0 suggest that the model is underfitting.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 14instance, looking at fig. 5 , one can observe that the internal
nodes about the number of executions of activities are colored
purple (control-flow perspective), whereas the internal nodereferring to the timestamp of the process-instance completion
is colored blue (time perspective). leaves are filled in with a
color that varies from white to black if a leaf is associated with
t h el o w e s to rh i g h e s tv a l u ef o rt h ed e p e n d e n tc h a r a c t e r i s t i c ,i t
is colored white or black, respectively. the color shades from
white till black, going through different intensities of yellow,
red and brown, as the value associated with the leaf increases.
when using a regression tree, each leaf is labeled with the
average value of the instances associated with the leaf, followed
in brackets by the number of instances for that leaf and the
absolute error averaged over all instances associated with that
leaf (in milliseconds).
before concluding, it is good to stress that end users can
click on any tree node and save the associated instances in a
file in attribute-relation file format (arff )
10to be externally
loaded in data-mining tools, such as weka, to employ
different data-mining techniques.
7.1.2. log cluster
the tree in fig. 5 contains five leaves and, hence, five
clusters are going to be created. however, one clusterneeds to be filtered out because it contains traces that have
clearly issues, as discussed in the following. the tree
illustrates the relation between the duration of processinstances and the number of the executions of two
activities, namely 26e_week_herijkingmoment (in english:
26th week recalibration time) and 78e_week_herijking-moment (in english: 78th week recalibration time). as the
names suggest, these activities are executed when the
customer is being handled since 26 and 78 weeks, respec-
tively.
11. therefore, it is normal that, if those are executed,
the duration of process instances is respectively longer
than 26 or 78 weeks (around 0.5 and 1.5 years).
from the discussion above, it is clear that, if activity
78e_week_herijkingmoment is executed, activity
26e_week_herijkingmoment should also be in the log
trace. nonetheless, in 10% of the process instances, activity
26e_week_herijkingmoment is not performed whereas
activity 78e_week_herijkingmoment is executed. this
clearly shows that a number of process instances have
some issues because the assessment after 26 weeks was
skipped, even though it is mandatory according to the
internal uwv's procedures. this means that this entire
cluster should be discarded as it only contains outlier log
traces.
we conclude this discussion by observing that, when both
26e_week_herijkingmoment and 78e_week_herijkingmoment
fig. 5. a screenshot of the implementation for prom. the screenshot shows the regression tree that correlates several process characteristics with the
duration of process instances. (for interpretation of the references to colors in this figure caption, the reader is referred to the web version of thi s paper.)
10http://weka.wikispaces.com/arff11in particular, these activities concern reassessments of customers
to establish the causes why they have not been reintegrated into the job
market yet and determine whether they will be ever reintegrated. in fact,
if the illness results to remain permanent, it is possible that the customercannot restart his/her previous employment and, hence, uwv helpsfinding a new job that suits the new physical situation.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 15are performed, the process-in stance duration depends on when
the instance concluded. process instances that conclude before
december 2013 run for a shorter time than those concluded
after that date: 541 versus 683 days. therefore, it is worth
splitting the cluster of the traces containing executions of both
activities according to the time of process-instance completion.
in the remainder of section 7.1 , we illustrate how the
set of models that can be discovered from these clusters
allow stakeholders to gain more insight into the process
structure.
7.1.3. discovery of models from log clusters
the first cluster refers to those traces where activities
26e_week_herijkingmoment and 78e_week_herijkingmo-
ment were never executed and the process-instance dura-
tion was around 83.04 days 760%. this cluster contains
179 traces, which were used to discover a process model
through the inductive miner, using the same noise thresh-
old as previously, followed by the bpmn conversion. the
resulting model is depicted in fig. 6 ; compared with the
model in fig. 4 , the model is much more desirable. first,
the model is precise: it does not contain a large exclusive
choice. second, it does not contain arbitrary loops allowing
for arbitrary executions of activities: each activity can be
executed at most once.
it is worthy observing that, even though fig. 5 shows
that 482 traces are such that 26e_week_herijkingmoment
and 78e_week_herijkingmoment were never executed, the
corresponding cluster only contains 179 traces. this indi-
cates that the choice of only retaining traces with an error
less than 60% has caused around 62% of the traces to befiltered out. although this may seem to not be a good
choice, it can be easily motivated. many of the traces that
have been filtered out contain less than 5 events, whichmight indicate that those are incomplete cases.
one might raise objections concerning the fact that, if
only 179 out of 1000 traces are retained, less behavior is
observed in the event log and, thus, it is natural to obtain
more precise models. however, this does not apply to this
case study as discussed below. first, we sampled 200
random traces four times, thus generating 4 event logs.
afterwards, we mined 4 process models: all models were
very imprecise, similar to the model in fig. 4 and definitely
different from fig. 6 .
fig. 7 illustrates the process model discovered for the
long cases, where activities 26e_week_herijkingmoment
and 78e_week_herijkingmoment were both executed at
least once, the timestamp when the case concluded was
before 10 december 2013 and the process-instance dura-
tion was around 541.75 days 760%. the log cluster con-
tained around 100 traces. the model is highly precise: no
exclusive choice is presented among several alternative
activities. the inclusion of the timestamp as independent
characteristic in the analysis use case is very important to
discover a precise model. if we exclude the timestamp, we
create one single cluster for each trace in which both
26e_week_herijkingmoment and 78e_week_herijkingmo-
ment occur, unrespectfully when each trace concludes. the
discovered model is similar to the model in fig. 4 and,
hence, insufficiently precise. this clearly illustrates that
during 2013, the structure of the process and the order
with which activities are performed has gone through a
radical change. in other words, using the consolidated
process-mining terminology, the process has experienced
a so-called concept drift . this is also confirmed by the
uwv, which was aware of a concept drift at beginning of
2014, even though it did not expect to observe so radical
changes.
fig. 6. discovery of the bpmn process model using the clustering of the traces where activities 26e_week_herijkingmoment and 78e_week_herijkingmo-
ment were never executed and the process-instance duration was around 83.04 days 760%. the model is significantly more precise than the model
discovered when all traces are considered together.
fig. 7. discovery of the bpmn process model using the clustering of the traces where activities 26e_week_herijkingmoment and 78e_week_herijkingmo-
ment were both executed at least once, the timestamp when the case concluded was before 10 december 2013 and the process-instance duration wasaround 541.75 days 760%. the model is again quite well structured and precise: there are no exclusive choices among several alternatives.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 16space limitations prevent us from showing the model
derived from the cases where activity 26e_week_herij-
kingmoment was executed at least once, activity
78e_week_herijkingmoment was never executed and the
process-instance duration was around 304.75 days 760%.
as mentioned above, we excluded from the analysis the
cluster of the traces where activity 26e_week_herijking-
moment was never executed whereas activity 78e_week_-
herijkingmoment was at least once. those traces show
undesirable behavior: the customer assessment did not
occur during the 26th week, even though the uwv's
procedure prescribes it.
7.2. analysis of the unemployment process
this section is looking at the process to deal with
requests of unemployment benefits. as mentioned at the
beginning of this section, uwv wants to investigate what
factors yield reclamations to occur with the aim of pre-
venting them from happening. in order to discover the
root causes, uwv formulated four questions:
q1 are customer characteristics linked to the occurrence
of reclamations? and if so, which characteristics are
most prominent?
q2 are characteristics concerned with how process
instances are executed linked to the occurrence of
reclamations? and if any, which characteristics
matter most?
q3 if the prescribed process flow is not followed, will this
influence whether or not a reclamation occurs?
q4 when an instance of the unemployment-benefit pay-
ment process is being handled, is there any character-
istic that may trigger whether a reclamation is going
to occur?
table 5 enumerates some of the analysis use cases that
have been performed to answer the questions above. the
analyses have been performed using a uwv's event log
containing 2232 process instances and 77 551 events. the
remainder of this section details how the analysis use
cases have been used to answer the four questions above.
the use cases u1,u2,u3use the number of executions
ofreclamation as dependent characteristic. for those
analysis use cases, we opted to use decision trees and
discretize the number of executions. this is because uwv
is interested to clearly distinguish cases in which no
reclamation occurs versus those in which reclamations
occur. the number of executions of reclamation is discre-
tized as two values: ( 0.0,0.0) and ( 0.0,5.0) . when the
number of executions of reclamation is 0, this is shown as
(0.0,0.0 ); conversely, any value greater than 0 for the
number of executions is discretized as ( 0.0,5.0 ). we
used the same discretization for u1,u2,u3.
question q1 : to answer this question, we performed
the use case u1intable 5 . the results of performing this
analysis are represented through the decision tree in fig. 8 .
in particular, the screenshot refers to our implementation
in prom. the implementation allows the end user to
configure a number of parameters, such as the level ofdecision-tree pruning, the minimum number of instances
per leaf or the discretization method. in this way, the user
can try several configurations, thus, e.g., balancing
between over- and under-fitting. in particular, the screen-
shot refers to the configuration in which the minimum
number of instances per leaf is set to 100.
looking at the tree in fig. 8 , some business rules seem
to be derived. for instance, if the customer is a recurrent
customer ( ww _ind_herleving 40), a reclamation
occurs, i.e. the leaf is labeled as ( 0.0,5.0) .12if this
correlation really held, it would be quite unexpected:
recurrent customers tend to disregard their duties. none-
theless, the label is also annotated with 318.0/126.0 ,
which indicates that a reclamation is not opened for 126
out of the 318 recurrent customers (39%). though not very
strong, a correlation seems to exist between being recur-
rent customers and incurring in reclamations. further
investigation is certainly needed; perhaps, additional cus-
tomer's characteristics might be needed to better discri-
minate, but they are currently not present in the event log
used for analysis.
question q2 : firstly, we performed the analysis use case
u2. we obtained a decision tree that showed correlations
between the number of reclamations and certain character-
istics that are judged as trivial by uwv. for instance, there
was a correlation of the number of reclamations with (1) the
method of payment of the benefit installments to customers
and (2) the number of executions of activity call contact door
hh deskundige , which is executed to push customers to
perform their duties. being these correlations considered
trivial by uwv, the respective characteristics should be left
out of the analysis. so, we excluded these characteristics from
the set of independent characteristics and repeated the
analysis. we refined the analysis use case multiple times byremoving more and more independent characteristics. after 9
iterations, we performed an analysis use case that led to
satisfactory results. the results of performing this analysis are
represented through the decision tree in fig. 9 ,w h i c h
classifies 77% of the instances correctly.
this tree illustrates interesting correlation rules. recla-
mations are usually not opened in those process instances
in which (1) uwv never informs (or has to inform) a
customer about changes in his/her benefits (the number of
executions of brief uitkering gewijzigd ww is 0), (2) uwv's
employees do not hand over work to each other (the
number of executions of brief interne memo is 0) and (3)
either of the following conditions holds:
/c15no letter is sent to the customers (the number ofexecutions of brief van uwv aan klant is 0);
/c15at least one letter is sent but uwv never calls the
customer (the number of executions of call telefoonno-
titie is equal to 0) and, also, the number of months for
which the customer is entitled to receive a benefit is
more than 12.
12customers are recurrent if they apply for monetary benefits
multiple times because they find multiple temporary jobs and, hence,they become unemployed multiple times.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 17table 5
additional analysis use cases that illustrate how our framework works to unify existing approaches to correlate specific process characteristics.
u1. analysis use case ðcfp1reclamation ;f8customercharacteristicsc dfp1cg;ef2þ:are customer characteristics linked to the occurrence of reclamations? we
aim to correlate the number of executions of activity reclamation to the customer characteristics. customer characteristics are a subset of the
entire set of characteristics available in the original log, i.e. before applying any trace manipulation. for this analysis use case, we aim to analyz e
each trace as a whole and, hence, we use event filter ef2 to only retain the last event of each trace. the dependent characteristic is cfp1reclamation
(“the number of executions of activity reclamation ”) and the set of independent characteristics includes dfp1c(“latest recorded value of
characteristic cuntil current event ”) for each customer characteristic cof the original event log
u2. analysis use case ðcfp1reclamation ;f8process characteristics c dfp1c;tip2;8activity x different from reclamation cfp1x;g;ef2þ:are characteristics concerned with
how process instances are executed linked to the occurrence of reclamation? we aim to correlate the number of executions of activity
reclamation to the number of executions of every activity, process-related characteristics, the elapsed time, i.e. the time since process instances
are started. process-related characteristics are a subset of the entire set of characteristics available in the original log, i.e. before applying a ny trace
manipulation. they differ from the customer characteristics because they are related to the outcome of the management of the provision ofunemployment benefits. for this analysis use case, we aim to analyze each trace as a whole and, hence, use event filter ef2to only retain the last
event of each trace. the dependent characteristic is cfp1
reclamation (“the number of executions of activity reclamation ”) and the set of
independent characteristics includes dfp1c(“latest recorded value of characteristic cuntil current event ”) for each process-related
characteristic cof the original event log, tip2 (“elapsed time since the start of the case ”) and cfp1x(“number of executions of activity x”) for each
process activity x
u3. analysis use case ðcfp1reclamation ;fcop1p;8activity x different from″reclamation″cop2p;x;cop3p;x;cop4p;xg;ef2þ:if the prescribed process flow is not
followed, will this influence whether or not a reclamation occurs? we aim to correlate the number of executions of activity reclamation to the
trace fitness, the number of non-allowed, missing and correct executions of any other activity. for this analysis use case, a process model pis
provided. since we again aim to analyze each trace as a whole, we use event filter ef2to only retain the last event of each trace. the dependent
characteristic is cfp1reclamation (“the number of executions of activity reclamation ”) and the set of independent characteristics include the fitness
of each trace wrt model p(manipulation cop1p) as well as, for each activity xdifferent from reclamation ,cop2p;x(“number of not allowed
executions of activity xthus far ”),cop3p;x(“number of missing executions of activity xthus far ”) and cop4p;x(“number of correct executions of
activity xthus far ”)
u4. analysis use case ðcfp2all;ftip2;8process characteristics c dfp 1c;8activity x different from″call contact door hh deskundige″cfp1x;g;ef4þwhen an instance of the
unemployment process is handled, is there any characteristic that may trigger whether a reclamation is going to occur next? we aim to
predict when a reclamation is going to occur as the next activity during the execution of a process instance. for this purpose, we predict whichactivity is going to follow for any process activity and, then, we focus on the paths leading to predicting that the following activity is, indeed,
reclamation . for this analysis use case, differently from the others in the table, we use any complete event; thus, the event filter is ef4(“keep all
complete events ”). the dependent characteristic is cfp2
all, indicating the first occurrence of any activity after the current event, i.e. the next
activity in the trace. the set of independent characteristics includes tip2 (“time elapsed since the start of the case ”as well as dfp1c(“latest
recorded value of characteristic cuntil current event ”) for each process-related characteristic cand cfp1x(“number of executions of activity x”)
for each process activity xdifferent from call contact door hh deskundige
fig. 8. a screenshot of the framework's implementation in prom that shows the decision tree used to answer question q1.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 18from this analysis, we can conclude that uwv should
reduce the hand-over of work. moreover, it should pay
more attention to customers when their situation changes,
e.g. they find a new job. when customers find a job, they
start having a monetary income, again. the problem seems
to be related to the customers who often do not provide
information about the new job on time. in these cases,
their benefits are not stopped or reduced when they
should. consequently, a reclamation needs to be opened
because these customers need to return the amount that
was overpaid to them. conversely, if a customer has
already received benefits for 12 months, it is unlikely that
a reclamation is going to occur. this can be motivated quite
clearly and it is again related to the presence of changes ofthe customer's job situation. if benefits are received for
more than 12 months, the customer has not found a job in
the latest 12 months and, thus, it is probably going to be
hard for him to find one. so, uwv does not have to pay
much attention to customers entitled to long benefits
when they aim to limit the number of reclamations.
question q3 : the answer to this question is given by
performing the analysis use case u3intable 5 . this use
case relies on a process model that describes the normal
execution flow. this model was designed by hand, using
knowledge of the uwv domain. the results of performing
u3are represented by the decision tree in fig. 10 . analyz-
ing the decision tree, a correlation is clear between trace
fitness and the number of reclamations. 610 out of the 826
process executions (nearly 70%) with fitness higher than
0.89 do not comprise any reclamation. therefore, it seems
crucial for uwv to make the best to follow the normal
flow, although this is often made difficult by a hasty
behavior of customers. this rule seems quite reliable and
is also confirmed by the fact that 70% of the executions
with fitness lower than 0.83 incur in reclamations.
the decision tree contains an intermediate node
labeled mreal for ikf van klant aan uwv . this character-
istic refers to the number of missing executions of
activity ikf van klant aan uwv . this activity is executed
in a process instance every time that uwv receives a
declaration form from the customer. uwv requests
customers to send a form every month to declare
whether or not their condition has changed in the last
month, e.g. they found a job. the decision tree states
that, when an execution deviates moderately, i.e. thefitness is roughly between 0.83 and 0.89, a reclamation is
still unlikely being opened if the customer forgets to
send the declaration form for at most 3 months (not
necessarily in a row). note that, since traces are quite
long, considering how fitne ss is computed, a difference
of 0.06 in fitness can be quite remarkable. this rule is
quite reliable since it holds in 79% of cases. therefore, it
is worthwhile for uwv to enact appropriate actions
(such as calling by phone) to increase the chances that
customers send the declaration form every month.
question q4 : the answer to this question is given by
performing the analysis use case u4intable 5 . we built a
decision tree for this use case by limiting the minimal
number of instances per leaf to 50. we are interested in
tree paths that lead to reclamation as next activity in the
trace. unfortunately, the f-measure for reclamation was
very low (0.349), which indicates that it is not possible to
reliably estimate if a reclamation is going to occur at acertain moment of the execution of a process instance .w e
also tried to reduce the limit of the minimum number of
instances per leaf. unfortunately, the resulting decision
tree was not valuable since it overfitted the instance sets:
the majority of the leaves were associated to less than 1%
of the total number of instances. conversely, the decision
tree with 50 as minimum number of instances per leaf
could be useful to predict when a payment is sent out to a
customer: the f score for the payment activity is nearly
0.735. unfortunately, finding this correlation does not
answer question q4.
7.3. final remarks
as mentioned in section 1 , we do not claim that our
framework is able to perform analyses that previously
were not possible. for some types of analysis use cases,dedicated solutions were provided and, for other types of
analysis use cases, the analyst had to manually go through
several transformation and selection steps. the novelty of
our framework that we provide a single environment
where analyses can be performed much quicker and do
not require process analysts to have solid technical
background.
in the remainder of this section, we illustrate the
complexity and time consumption of performing analysis
use cases without the framework. for this aim, we
fig. 9. the decision tree used to answer question q2.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 19consider question q1 introduced in section 7.2 , whose
corresponding analysis use case is in table 5 . for simpli-
city, let us suppose that the event log is stored in a
database table event _table of a certain database. each
table's row is a different log's event. this table containscolumns cid,timestamp ,activity , which represent
the identifier of the case (i.e., of the process instance),
the event's timestamp and the activity name, respectively.
in addition to that, each additional process attribute is
characterized by a respective column attr _1,…,attr _n.
in order to perform the analysis use case, we aim to write a
sql query that returns a tabular result that can be
exported in a csv file and loaded in data-mining tools.
table 6 shows the corresponding sql query; in particular,
to increase the readability, we introduce two sql functions
that compute the number of occurrences of activity
reclamation in a process instance with identifier cid and
the latest value written for a certain process attribute attr
for a process instance with identifier cid.
space limitations prevent us from detailing how the
sql query and the helper functions are structured. how-
ever, we believe that this shows how long, error-prone and
time-consuming the task of manually defining such sql
queries is for each analysis use case. furthermore, process
analysts are required to possess a large knowledge of sql,
which is not always true. if we replaced sql and databases
with alternative languages, the complexity would be
certainly comparable. here we have showcased an analysis
use case for q1 that is relatively simple if compared with
other analysis use cases discussed in this paper. for
instance, without our framework the analysis use casefor q3 would require to write complex codes or scripts to
import the conformance results.
conversely, using our framework and our correspond-
ing prom implementation, the task of defining analysis use
cases is simple while remaining relatively generic. this canbe done in a matter of minutes by simply selecting the
opportune dependent and independent characteristics
from a provided list. the complexity would only be raised
if one needed to incorporate new log-manipulation
functions.
8. related work
this paper has clearly shown that the study of process
characteristics and how they influence each other is of
crucial importance when an organization aims to improve
and redesign its own processes. many authors have pro-
posed techniques to relate specific characteristics in an ad
ad-hoc manner. for example, several approaches have
been proposed to predict the remaining processing time
of a case depending on characteristics of the partial trace
executed [22,18,23]. other approaches are only targeted to
correlating certain predefined characteristics to the pro-
cess outcome [15,24,16], process service time [25] or the
violations of business rules [14]. senderovich et al. [26]
leverages on queue theory to correlate service time to the
arrival of new activities to perform; the main drawback is
that the approach can be only applied to single activities
and assumes a certain arrival distribution.
the general framework proposed in this paper is in line
with typical methodologies to discover knowledge,
intended as a set of interesting and nontrivial patterns,
fig. 10. the decision tree used to answer question q3.
table 6
create of the set of learning instances using sql in place of our framework.
create function numreclamation (@cid)
as (select count(*) from event _table as et where et.cid ¼@cid and et.activity ¼’reclamation’)
create function latestvalue (@cid,@attr) as (
select @attr from event _table as et1 where et1.cid ¼@cid and et2.@attr is not null
and 0 ¼(select count(*) from event _table as et2 where et2.cid ¼et1.cid and et2.@attr is not null
and et2.timestamp 4et1.timestamp ))
select et1.*,numreclamation(et.cid),latestvalue(et.cid,attr _1),…,latestvalue(et.cid,attr _n)
from event _table et1 where et.timestamp ¼(select max(timestamp) from event _table et2 where et2.cid ¼et.cid)
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 20from data sets with some degree of certainty. in [27],
fayyad et al. propose a methodology and guidelines to
execute the process of knowledge discovery. a number of
abstract steps are proposed: selection, pre-processing,
transformation, data mining and interpretation. the simi-
larity between these steps and those proposed by our
framework is quite evident. the selection and pre-
processing steps match the definition of the analysis use
case, whereas the transformation step coincides with the
manipulation of event logs as discussed in section 3 .
finally, the data mining step in the methodology of fayyad
et al. corresponds to the actual construction of decision
and regression trees to provide answers to analysis use
cases. while our framework shares commonalities with
the methodology of fayyad et al., several major differences
exist. it is not in the scope of the methodology of fayyad
et al. to provide a concrete framework and operationaliza-
tion that allow non-experts to easily conduct a process-
related analysis.
furthermore, our paper adapts the methodology of
fayyad et al. for the domain of process mining. the funda-
mental difference between data and process mining is that
process mining is concerned with processes. as extensively
discussed, processes take several perspectives into account.
therefore, these perspectives n eed to be elected as first-class
citizens to obtain reliable correlations. the outcomes, the
time for executing a certain activity or any other character-
istic in a process instance may depend on several factors that
are outside the activity in question. for instance, resource
and group workloads, delays, deadlines, the customer type
(e.g., silver, gold or platinum) or the number of undergone
c h e c k sm a yh a v es t r o n gi n f l u e n c e .f a c t o r sc a nb ee v e n
outside the specific process instance; namely, these factors
are part of the external context around which the activity isbeing executed. without taking them into consideration, the
correlation is certainly weaker. therefore, each event cannot
be considered in isolation but should consider the other
events and, even, aspects outside the process in question.
somehow, data mining tends to take events, i.e. the learning
instances, in isolation. this also motivates the importance of
augmenting and manipulating the event log.
in addition to decision and regression trees, many other
machine-learning techniques exist and some have already
been applied in bpm, such as bayesian networks [28],c a s e -
based reasoning [29],m a r k o vm o d e l s [23],n a i v eb a y e s
classifiers and support vector machines [30].t h e s ea r e
certainly valuable but they are only able to make correlations
for single instances of interest or to return significant exam-
ples of relevant instances. conversely, we aim to aggregate
knowledge extracted from the event logs and return it as
decision rules. association rules [3]could have been an
alternative, but decision and regression trees have the advan-
tage of clearly highlighting the characteristics that are most
discriminating. also, linear regression [7]could be applied;
however, this could only be applied when dependent and
independent characteristics are numerical, thus excluding
many valuable process charact eristics. moreover, we believe
that linear formulas would not be understood by non-expert
users as much as decision or regression trees would. last but
not least, stochastic analysis has been used to predict the
remaining service time [31]; the approach requires to have aprocess model and it is not clear how it can be generalized to
any process characteristics.
there is also a body of work that is concerned with
providing intuitive visual representations of root causes of
problems or undesirable events, such as cause –effect or
why-why diagrams (see, e.g., [32, pp. 190 –198] ). we
envision these intuitive visualizations as complementary
to our framework and visualization. furthermore, before
drawing such diagrams, one needs to gain the necessary
insights, which our framework facilitates to obtain.
this paper extends the framework initially proposed in
[21] to allow grouping the traces of an event log into
clusters. literature proposes a large number of approaches
to address this topic, e.g.
[33–38]. all existing approaches
share the same idea: similar traces are grouped together
and placed in the same cluster; the difference among these
approaches resides on the use of different notions of trace
similarity. however, existing approaches propose a prede-
termined repertoire of similarity's notion, whereas this
paper proposes an approach to trace clustering that is based
on a configurable notion of trace similarity. we believe that
there is no concept of trace similarity that is generally
applicable in every situations; in fact, the similarity among
traces depends on the specific process domain. further-
more, the predetermined repertoire is mostly based on the
control-flow perspective (e.g. the order with which activ-
ities are performed). conversely, our framework enables to
define the similarity concept as a function of characteristics
related to several perspectives: the duration of the process-
instance execution, the workload of the process participants
when the instance was carried out, the execution's com-
pliance and many others.
in addition to using different concepts of trace similar-
ity, existing approaches also use different clustering tech-niques, such as agglomerative hierarchical clustering, k-
means or dbscan [7]. when using these techniques for
trace clustering, process analysts do not have a clear
insight into the process characteristics that are common
among all traces within the same cluster. conversely,
decision or regression trees clearly highlight the charac-
teristics that discriminate. this means that, when using it
for trace clustering, it becomes clear why a certain log
trace belongs to a given cluster and not to another.
9. conclusion
process mining can be viewed as the missing link
between model-based process analysis and data-oriented
analysis techniques. lion's share of process mining
research has been focusing on process discovery (creating
process models from raw data) and replay techniques to
check conformance and analyze bottlenecks. it is crucial
that certain phenomena can be explained, e.g., “why are
these cases delayed at this point? ”,“why do these devia-
tions take place? ”,“what kind of cases are more costly due
to following this undesirable route? ”, and “why is the
distribution of work so unbalanced ”. these and other
questions may involve process characteristics related to
different perspectives (control-flow, data-flow, time, orga-
nization, cost, compliance, etc.). specific questions (e.g.,
predicting the remaining processing time) have been
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 21investigated before, a generic framework for correlating
business process characteristics was missing. in this paper,
we presented such a framework and its implementation in
prom. by defining an analysis use case composed of three
elements (one dependent characteristic, multiple indepen-
dent characteristics and a filter), we can create a classifica-
tion or regression problem. the results of performing an
analysis use case is a decision or a regression tree that
describes the dependent characteristic in terms of the
independent characteristics. as discussed, the resulting
decision or regression tree can also be used to split event
logs into clusters of traces with similar behavior. cluster-
ing is a necessary action when the event log shows such a
heterogenous behavior that many process-mining techni-
ques, such as for process discovery, cannot return insight-
ful results. the advance of the proposed clustering
technique is that the notion of trace similarity is configur-
able according to the specific application domain and can
leverage on many process perspectives, instead of only the
control-flow perspective.
the approach has been evaluated using a case study
within the uwv, one of the largest “administrative fac-
tories ”in the netherlands. the evaluation has demon-
strated the usefulness of performing correlation analyses
to gain insight into processes as well as of clustering event
logs according to the results of performing analysis
use cases.
acknowledgments
the work of dr. de leoni has received funding from the
european community's seventh framework program fp7
under grant agreement num. 603993 (core).
references
[1]w.m.p. van der aalst, process mining: discovery, conformance and
enhancement of business processes, 1st edition, springer publishing
company, incorporated, 2011 .
[2] j. nakatumba, resource-aware business process management: ana-
lysis and support (ph.d. thesis), eindhoven university of technology,
isbn: 978-90-386-3472-2, 2014.
[3] a. dohmen, j. moormann, identifying drivers of inefficiency in
business processes: a dea and data mining perspective, in: enter-
prise, business-process and information systems modeling, lnbip,
vol. 50, springer, berlin, heidelberg, 2010, pp. 120 –132.
[4] l. zeng, c. lingenfelder, h. lei, h. chang, event-driven quality of
service prediction, in: proceedings of the 8th international con-
ference of service-oriented computing (icsoc 2008), lecture notesin computer science, vol. 5364, springer, berlin, heidelberg, 2008,
pp. 147 –161.
[5]w.m.p. van der aalst, s. dustdar, process mining put into context,
ieee internet comput. 16 (1) (2012) 82 –86.
[6] w.m.p. van der aalst, process cubes: slicing, dicing, rolling up and
drilling down event data for process mining, in: m. song, m. wynn,
j. liu (eds.), asia pacific conference on business process manage-
ment (ap-bpm 2013), lnbip, vol. 159, springer-verlag, beijing, china,
2013, pp. 1 –22.
[7]t.m. mitchell, machine learning, 1st edition, mcgraw-hill, inc., new
york, ny, usa, 1997 .
[8] i.h. witten, e. frank, data mining: practical machine learning tools
and techniques, 2nd edition, morgan kaufmann series in data
management systems, 3rd edition, morgan kaufmann publishers
inc., san francisco, ca, usa, 2011.
[9] j. dougherty, r. kohavi, m. sahami, supervised and unsupervised
discretization of continuous features, in: proceedings of the twelfthinternational conference on machine learning (icml'95), morgan
kaufmann, tahoe city, california, usa, 1995, pp. 194 –202.
[10] w.m.p. van der aalst, h.t. beer, b.f. van dongen, process mining and
verification of properties: an approach based on temporal logic, in:conference on the move to meaningful internet systems 2005:coopis, doa, and odbase, lecture notes in computer science, vol.
3760, springer, berlin, heidelberg, 2005, pp. 130 –147.
[11] w.m.p. van der aalst, a. adriansyah, b.v. dongen, replaying history
on process models for conformance checking and performanceanalysis, wires data min. knowl. discov. 2 (2) (2012) 182 –192.
[12] m. de leoni, w.m.p. van der aalst, aligning event logs and process
models for multi-perspective conformance checking: an approachbased on integer linear programming, in: proceedings of the 11th
international conference on business process management
(bpm'13), lecture notes in computer science, vol. 8094, springer-verlag, beijing, china, 2013, pp. 113 –129.
[13] m. de leoni, f.m. maggi, w.m.p. van der aalst, an alignment-based
framework to check the conformance of declarative process models
and to preprocess event-log data, inf. syst. 47 (2015) 258 –277.
[14] f.m. maggi, c.d. francescomarino, m. dumas, c. ghidini, predictive
monitoring of business processes, in: proceedings of the 26th
international conference on advanced information systems engi-neering (caise 2014), lecture notes in computer science, vol. 8484,2014, pp. 457 –472.
[15] j. ghattas, p. soffer, m. peleg, improving business process decision
making based on past experience, decis. support syst. 59 (2014)93–107.
[16] r. conforti, m. de leoni, m. la rosa, w.m.p. van der aalst, supporting
risk-informed decisions during business process execution, in:
proceedings of the 25th international conference on advancedinformation systems engineering (caise'13), lecture notes in com-puter science, vol. 7908, springer-verlag, valencia, spain, 2013,
pp. 116 –132.
[17] a. rozinat, w.m.p. van der aalst, decision mining in prom, in:
proceedings of the 4th international conference on business process
management (bpm'06), lecture notes in computer science,
springer-verlag, vienna, austria, 2006, pp. 420 –425.
[18] w.m.p. van der aalst, m.h. schonenberg, m. song, time prediction
based on process mining, inf. syst. 36 (2) (2011) 450 –475.
[19] s.j. leemans, d. fahland, w.m.p. van der aalst, discovering block-
structured process models from incomplete event logs, in: proceed-
ings of the 35th international conference on application and theoryof petri nets and concurrency (petri net 2014), vol. 8489, springer
international publishing, tunis, tunisia, 2014, pp. 91 –110.
[20] a. kalenkova, m. de leoni, w.m.p. van der aalst, discovering,
analyzing and enhancing bpmn models using prom, in: proceedings
of the demo sessions of the 12th international conference on
business process management (bpm 2014), ceur workshop pro-ceedings, vol. 1295, ceur-ws.org, 2014, p. 36.
[21] m. de leoni, w.m. van der aalst, m. dees, a general framework for
correlating business process characteristics, in: proceedings of the
11th business process management (bpm'14), lecture notes incomputer science, vol. 8659, springer international publishing,eindhoven, the netherlands, 2014, pp. 250 –266.
[22] f. folino, m. guarascio, l. pontieri, discovering context-aware
models for predicting business process performances, in: on themove to meaningful internet systems: otm 2012, lecture notes incomputer science, vol. 7565, springer, berlin, heidelberg, 2012,
pp. 287 –304.
[23] g. lakshmanan, d. shamsi, y. doganata, m. unuvar, r. khalaf, a
markov prediction model for data-driven semi-structured business
processes, knowl. inf. syst. (2013) 1 –30.
[24] a. kim, j. obregon, j.-y. jung, constructing decision trees from
process logs for performer recommendation, in: proceedings of2013 business process management workshops, lnbip, vol. 171,
springer, beijing, china, 2014, pp. 224 –236.
[25] a. senderovich, m. weidlich, a. gal, a. mandelbaum, mining
resource scheduling protocols, in: proceedings of the 11th business
process management (bpm'14), lecture notes in computer science,
vol. 8659, springer international publishing, eindhoven, the nether-lands, 2014, pp. 200 –216.
[26] a. senderovich, m. weidlich, a. gal, a. mandelbaum, queue mining
–predicting delays in service processes, in: proceedings of caise,
lecture notes in computer science, vol. 7565, springer, thessaloniki,greece, 2014, pp. 42 –57.
[27] u.m. fayyad, g. piatetsky-shapiro, p. smyth, from data mining to
knowledge discovery: an overview, in: u.m. fayyad, g. piatetsky-shapiro, p. smyth, r. uthurusamy (eds.), advances in knowledge
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 22discovery and data mining, american association for artificial
intelligence, 1996, pp. 37 –54.
[28] r.a. sutrisnowati, h. bae, j. park, b.-h. ha, learning bayesian
network from event logs using mutual information test, in: pro-
ceedings of the 6th international conference on service-oriented
computing and applications (soca 2013), 2013, pp. 356 –360.
[29] a. aamodt, e. plaza, case-based reasoning: foundational issues,
methodological variations, and system approaches, ai commun. 7
(1) (1994) 39 –59.
[30] m. polato, a. sperduti, a. burattin, m. de leoni, data-aware remain-
ing time prediction of business process instances, in: proceedings of
the 2014 international joint conference on neural networks (ijcnn),
2014.
[31] a. rogge-solti, m. weske, prediction of remaining service execution
time using stochastic petri nets with arbitrary firing delays, in:
proceedings of icsoc, lecture notes in computer science, vol. 8274,
springer, berlin, germany, 2013.
[32] m. dumas, m. la rosa, j. mendling, h.a. reijers, fundamentals of
business process management, springer, berlin, heidelberg, 2013 .
[33] c.c. ekanayake, m. dumas, l. garca-bauelos, m. la rosa, slice, mine
and dice: complexity-aware automated discovery of businessprocess models, in: proceedings of the 10th business process
management (bpm'13), lecture notes in computer science, vol.
8094, springer, berlin, heidelberg, 2013, pp. 49 –64.
[34] r.p.j.c. bose, process mining in the large: preprocessing, discovery,
and diagnostics (ph.d. thesis), eindhoven university of technology,
eindhoven, 2012.
[35] g.m. veiga, d.r. ferreira, understanding spaghetti models with
sequence clustering for prom, in: business process management
workshops, lecture notes in business information processing, vol.43, springer, berlin, heidelberg, 2010, pp. 92 –103.
[36] g. greco, a. guzzo, l. pontieri, mining taxonomies of process
models, data knowl. eng. 67 (1) (2008) 74 –102.
[37] j. de weerdt, s. vanden broucke, j. vanthienen, b. baesens, active
trace clustering for improved process discovery, ieee trans. knowl.data eng. 25 (12) (2013) 2708 –2720 .
[38] m. sole, j. carmona, a high-level strategy for c-net discovery, in:
proceedings of the 12th international conference on application of
concurrency to system design (acsd), 2012, pp. 102 –111.
please cite this article as: m. de leoni, et al., a general process mining framework for correlating, predicting and
clustering dynamic behavior based on event logs, information systems (2015), http://dx.doi.org/10.1016/j.is.2015.07.003 im. de leoni et al. / information systems ](]]]])]]]–]]] 23