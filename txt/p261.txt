a meta model for process mining data
b.f. van dongen and w.m.p. van der aalst⋆
department of technology management, eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands.
{b.f.v.dongen,w.m.p.v.d.aalst }@tue.nl
abstract. modern process-aware information systems store detailed in-
formation about processes as they are being executed. this kind of infor-
mation can be used for very diﬀerent purposes. the term process mining
refers to the techniques and tools to extract knowledge (e.g., in the form
of models) from this. several key players in this area have developed so-
phisticated process mining tools, such as aris ppm and the hp businesscockpit, that are capable of using the information available to generate
meaningful insights.
what most of these commercial process mining tools have in common
is that installation and maintenance of the systems requires enormous
eﬀort, and deep knowledge of the underlying information system. more-
over, information systems log events in diﬀerent ways. therefore, theinterface between process-aware information systems and process min-
ing tools is far from trivial. it is vital to correctly map and interpret event
logs recorded by the underlying information systems. therefore, we pro-
pose a meta model for event logs. we give the requirements for the data
that should be available, both informally and formally. furthermore, weback our meta model up with an xml format called mxml and a tool-
ing framework that is capable of reading mxml ﬁles. although, the
approach presented in this paper is very pragmatic, it can be seen as aﬁrst step towards and ontological analysis of process mining data.
1 introduction
under the umbrella of buzzwords such as “business activity monitoring” (bam)
and “business process intelligence” (bpi) both academic (e.g., emit, littlethumb, inwolve, process miner, and minson) and commercial tools (e.g.,
aris ppm, hp bpi, and ilog jviews) have been developed. the goal of
these tools is to extract knowledge from event logs (e.g., event logs in an erpsystem or audit trails in a wfm system), i.e., to do process mining .
the research domain process mining is relatively new. a complete overview
of recent process mining research is beyond the scope of this paper. therefore,we limit ourselves to a brief introduction to this topic and refer to [2, 3] and the
http://www.processmining.org web page for a more complete overview.
the goal of process mining is to extract information about processes from
event logs. it assumes that it is possible to record events such that (i) each
⋆this work is supported by the interop network of excellence - contract no.:
ist-508 011 (http://www.interop-noe.org)event refers to an activity (i.e., a well-deﬁned step in the process), (ii) each event
refers to a case(i.e., a process instance), and (iii) events are totally ordered.
furthermore, all kinds of system-speciﬁc data elements can be present in these
event logs. this immediately shows one of the biggest challenges faced in the
process mining research. each information system has its own internal datastructure, and its own language to describe the internal structure. when trying
to use event logs from diﬀerent system to do process mining, we need to be
able to present the logs in a standardized way, i.e., there is a need for a gooddescription of such a log. furthermore, for each information system, a mapping
has to be provided onto that description. in other words, we need a meta model
for process mining. in this paper, we take a ﬁrst step towards such a processmining meta model.
few of the meta models described in literature (e.g., [12]) focus on process
mining. the work of zur muehlen [9] is closest to the results reported in thispaper. however, our work is more pragmatic and driven by concrete tools and
systems. the application of prom, our process mining platform, provides us with
insights that are valuable for people using bam, bpi, and other process miningtools.
in practice, the mapping of event logs from one system to the standard format
is a non-trivial task. it requires the mapping of one meta model onto another.
it can be seen as a form of ontological analysis in the spirit of [4, 6, 11]. insteadof the bunge-wand-weber ontology, we use a meta model that can be seen
as a starting point for an ontology for process mining. similar to the work in
[4, 6, 11], “ontological goodness” and “ontological weaknesses” of process-awareinformation systems with respect to event logs can be analyzed by comparing
the diﬀerent meta models.
the remainder of this paper is organized as follows. in section 2, we intro-
duce process-aware information systems and we provide a high-level classiﬁcation
thereof. then, in section 3, we introduce an xml format (mxml) for storing
event logs. in section 4, we introduce the process mining framework that canwork with mxml ﬁles. in section 5, we show an example of a mapping be-
tween the the meta model of a widely-used information system (staﬀware) to
our meta model, and we show how this can be translated to a mapping of the logto mxml. in this section, we also provide an ontological analysis of the logging
facilities of staﬀware. section 6, we touch some of the issues related to these
mappings for other information systems. finally, we discuss related work andconclude the paper.
2 process-aware information systems
process-aware information systems are widely used in practice (cf. erp, wfm,crm, pdm systems). at the basis of most of these systems lays a process modelof some kind. however, the way systems enforce the handling of cases is diﬀerent
for all systems. on the one hand there are systems that enforce a given process
description to all users, while some other systems only provide an easy way ofhandling access to ﬁles. as a result of this, information systems are used in
very diverse organizations and with all kinds of expectations. even though eachsystem has its individual advantages and disadvantages, these systems can be
divided in several groups. in figure 1, we give four types of information systems,
and position them with respect to the structure of the process that is dealt withand whether they are data or process driven. in figure 2, we give the trade-oﬀs
that are made for each of these four types of systems with respect to ﬂexibility,
support, performance and design eﬀort.
explicitly
structured
implicitly
structured
ad-hoc
structured
unstructured
data-driven process-drivenad-hoc workflow
groupwareproduction
workflow
case handling
fig. 1. pais spectrumad-hoc
workflowgroupwareproduction
workflowcase
handlinglowhigh
flexibilitysupport
design
effortperformance
fig. 2. pais tradeoﬀs
production workﬂow systems such as for example staﬀware are typically used
in organizations where processes are highly standardized, and volumes are big
(i.e. a lot of cases are to be dealt with in parallel). these systems not only handle
data, but enforce a certain process deﬁnition to be followed by the letter. case
handling systems such as flower on the other hand, are typically used in envi-
ronments where people have a good understanding of the complete process. thisallows these so-called “knowledge workers” to handle cases with more ﬂexibility.
in the end however, the case handling system keeps structure in both the data
involved and the steps required. ad-hoc workﬂow systems such as inconcertallow for the users to deviate completely from given processes. processes deﬁ-
nitions are still provided, but not enforced on an execution level. they merely
serve as reference models. the ﬁnal category of systems, i.e. groupware is themost ﬂexible one. systems such as lotus notes provide a structured way to store
and retrieve data, but no processes are deﬁned at all.
due to the fact that each information system serves a diﬀerent purpose, and
that they are used in very diﬀerent organizations, it is obvious that there is a
diﬀerence in the internal data warehousing of those systems. in this paper, we areinterested in the event logs that can be generated by process-aware information
systems. since the information in an event log highly depends on the internal
data representation of each individual system, it is safe to assume that eachsystem provides information in its own way. therefore, we need to provide a
standard for the information we need and mappings from each system to this
standard. for this, we introduce mxml.3 xml mining format mxml
as we stated in the introduction, there is a minimal amount of information that
needs to be present in order to do process mining. in this section, we ﬁrst give
some requirements with respect to this information. from these requirements,we derive a meta model in terms of a uml class diagram. then, we introduce a
formal xml deﬁnition for event logs, called mxml , to support this meta model.
we conclude the section with an example of an mxml ﬁle.
3.1 requirements
all process-aware information systems have one thing in common, namely the
process speciﬁcation. for groupware systems, such a speciﬁcation is nothing more
than a unstructured set of possible activities, while for production workﬂows this
speciﬁcation is extremely detailed. for process mining, log ﬁles of such systems
are needed as a starting point. first we give the requirements for the informationneeded.
to make the distinction between events that took place, and logged events, we
will refer to the latter by audit trail entries from here on. when events are logged
in some information system, we need them to meet the following requirementsin order to be useful in the context of process mining:
1. each audit trail entry should be an event that happened at a given point
in time. it should not refer to a period of time. for example, starting towork on some work-item in a workﬂow system would be an event, as well
as ﬁnishing the work-item. the process of working on the work-item itself is
not.
2. each audit trail entry should refer to one activity only, and activities should
be uniquely identiﬁable.
3. each audit trail entry should contain a description of the event that hap-
pened with respect to the activity. for example, the activity was started or
completed.
4. each audit trail entry should refer to a speciﬁc process instance (case).
we need to know, for example, for which invoice the payment activity was
started.
5. each process instance should belong to a speciﬁc process.
using the requirements given above, we are able to make a meta model of
the information that should be provided for process mining.
3.2 mining meta model
from the requirements given in the previous section, we derive the uml class
diagram of figure 3. note that we use the term “workﬂow model element”
instead of activity, and “workﬂow log” instead of event log. this is done for
historic reasons.workflowmodelelement+activity : workflowmodelelement
+description : string+timestamp : date+person : originator+...audittrailentry
1*process processinstance workflowlog
* 1..* 1 0..*
1
1..*1
1..*
fig. 3. mining data meta model.reassign
schedule assign
start
resume
suspend
autoskip completemanualskip
ate_abort
pi_abortwithdraw
fig. 4. transactional model.
as we stated in the requirements, each audit trail entry contains a description
of the event that generated it. in order to be able to talk about these events in a
standardized way, we developed a transactional model that shows the events thatwe assume can appear in a log. this model is based on analyzing the diﬀerent
types of logs in real-life systems (e.g., staﬀware, sap, flower, etc.) figure 4
shows this transactional model.
when an activity (or workﬂow model element) is created, it is either “sched-
uled” or skipped automatically (“autoskip”). scheduling an activity means that
the control over that activity is put into the information system. the informationsystem can now “assign” this activity to a certain person or group of persons. it
is possible to “reassign” an assigned activity to another person or group of per-
sons. this can be done by the system, or by a user. a user can “start” workingon an activity that was assigned to him, or some user can decide to “withdraw”
the activity or skip it manually (“manualskip”), which can even happen before
the activity was assigned. the main diﬀerence between a withdrawal and a man-
ual skip is the fact that after the manual skip the activity has been executed
correctly, while after a withdrawal it is not. the user that started an activitycan “suspend” and “resume” the activity several times, but in the end he or
she either has to “complete” or abort (“ate
abort”) it. note the activity can get
aborted (“pi abort”) during its entire life cycle. since we cannot claim that we
have captured all possible behavior of all systems, we will have to allow for user
deﬁned events in the mxml format.
3.3 xml structure
using the meta model of figure 3, we can easily derive an xml format for
storing event logs. in figure 5 a schema deﬁnition is given for the format that
is used by our process mining framework prom.
most of the elements in the xml schema can be found in the meta model
and they speak for themselves. there are however two exceptions. first, there is
the “data” element. this element allows for storing arbitrary textual data, andcontains a list of “attribute” elements. on every level, it can be used to store
information about the environment in which the log was created. second, there
is the “source” element. this element can be used to store information aboutthe information system this log originated from. it can in itself contain a data
element, to store information about the information system. it can for example
be used to store conﬁguration settings.fig. 5. xml mining format.
3.4 example
we conclude the section about the mxml format with an example of an xml
log ﬁle. this example log is the ﬁrst part of a translation of a staﬀware log to
the mxml format (without the standard headers). in section 5, we introduce
this translation in more detail. it shows two audit trail entries in a complaints
handling process.
<source program="staffware">
<data>
<attribute name="version">7.0</attribute>
</data>
</source><process id="main_process">
<data>
<attribute name="description">complaints handling</attribute>
</data>
<processinstance id="case 1">
<audittrailentry>
<workflowmodelelement>case start</workflowmodelelement><eventtype unknowntype="case_event">unknown</eventtype><timestamp>2002-04-16t11:06:00.000+01:00</timestamp>
</audittrailentry><audittrailentry>
<workflowmodelelement>register complaint</workflowmodelelement>
<eventtype>schedule</eventtype><timestamp>2002-04-16t11:16:00.000+01:00</timestamp><originator>jvluin@staffw</originator>
</audittrailentry>
table 1. ap a r to fa nm x m lﬁ l e .
4p r o m
deﬁning an xml format such as mxml would not make sense unless it is backed
up by a good tool. for this, the prom framework [5] has been developed. theprom framework is a “pluggable” environment for process mining. it allows for
interaction between a large number of so-called plug-ins. a plug-in is basically
the implementation of an algorithm that is of some use in the process mining
area, where the implementation agrees with the framework. when dealing with
log ﬁles, the framework requires them to be in the mxml format.
1
1for more information about prom, we refer to http://www.processmining.org.the prom framework can read log ﬁles in the mxml format. through the
import plug-ins a wide variety of models can be loaded ranging from a petri net to
ltl formulas. the mining plug-ins do the actual mining and the result is stored
as aframe . these frames can be used for visualization, e.g., displaying a petri
net [10], an epc [8] or a social network [1], or further analysis or conversion.theanalysis plug-ins take a mining result and analyze it, e.g., calculating a
place invariant for a resulting petri net. the conversion plug-ins take a mining
result and transform it into another format, e.g., transforming an epc into apetri net.
using the prom framework, we have seen promising results with respect to
the applicability of process mining in real business environments. in the nextsection, we present a small case study thereof.
5 case: staﬀware logs to mxml
in this section, we show that it is possible to actually extract mxml log ﬁlesfrom commercial systems, since this greatly improves the practical applicability
of the prom framework. as a case study, we show that this is possible for a
commercial workﬂow system called tibco staﬀware process suite (in short
staﬀware). through this example, we show why we call our model from figure 3
ameta-model. we consider the data model used by staﬀware as an instantiation
of the meta-model. then, the staﬀware log ﬁle should be seen as an instantiation
of the staﬀware data model. by studying the mapping between the staﬀware
data model and our meta-model in section 5.2 we give a translation from thestaﬀware log ﬁle to the mxml ﬁle.
5.1 a staﬀware log ﬁle
in table 2, we show an example of a staﬀware log ﬁle. it consists of one complete
case of a complaint handling process and a second, incomplete case of the sameprocess.
case 1
diractive description event user yyyy/mm/dd hh:mm---------------------------------------------------------------------
start jvluin@staffw 2002/04/16 11:06
register complaint processed to jvluin@staffw 2002/04/16 11:16register complaint released by jvluin@staffw 2002/04/16 11:26evaluate complaint processed to jvluin@staffw 2002/04/16 11:36evaluate complaint released by jvluin@staffw 2002/04/16 11:46
terminated 2002/04/16 11:56
case 2diractive description event user yyyy/mm/dd hh:mm
---------------------------------------------------------------------
start jvluin@staffw 2002/04/16 12:36
register complaint processed to jvluin@staffw 2002/04/16 12:46register complaint expired jvluin@staffw 2002/04/17 13:07register complaint withdrawn jvluin@staffw 2002/04/17 13:07
table 2.
as t a ﬀ w a r el o gﬁ l e .5.2 mapping staﬀware to mxml
in order to map staﬀware logs to mxml, we ﬁst need to map the internal data
model of staﬀware onto our model from figure 3. in figure 6, we show the
staﬀware data model, and we show how the mapping should be done.
workflowmodelelement
1*process processinstance workflowlog
* 1..* 1 0..*
1
1..*1
1..*
+activity : workflowmodelelement
+description : string+timestamp : date
+person : originator+...audittrailentry
step
+diractivedescription : string+event : string
+timestamp : string+user : stringlineoftext
0..1 *procedure audittrail audit
1 0..*
1
1..*
+name : stringmanualstep automaticstep*1
1*
fig. 6. mapping meta models.
when this mapping is available, it is almost trivial to map log ﬁles to mxml.
each audit in staﬀware, contains the logs of only one procedure (or process) ofwhich each audit trail is described separately. these audit trails can easily be
mapped onto “process instances”. each line of text in the audit ﬁle of table 2
contains four columns. the ﬁrst column can be mapped onto the “workﬂowmodel element”, since they refer to manual steps of which the process is com-
posed. the third and fourth column are obviously mapped onto the “originator”
and “timestamp” respectively. in table 3, we show the mapping for the eventsthat can appear in the second column of table 2 and what to do with the begin-
ning of a case and the end of a case, i.e. the “start” and “terminated” events
respectively. the beginning and end of a case are special situations, since theyare lines of text without an associated manual step. therefore, we have to create
virtual manual steps.
staﬀware event prom workﬂowmodelelement prom eventtype
start “case start” unknown: case event
processed to as in 2nd column schedule
released by as in 2nd column complete
expired as in 2nd column unknown: expire
withdrawn as in 2nd column withdrawn
terminated “case end” unknown: case event
table 3. the staﬀware mapping.
5.3 ontological analysis
in the spirit of [4, 6, 11] we can conduct an ontological analysis of the staﬀware
logging capabilities. first, we check for ontological incompleteness , also named
construct deﬁcit , which exists “unless there is at least one grammatical con-
struct for each ontological construct” [4, 6, 11]. staﬀware is quite complete. themost important construct deﬁcit is the absence of an event type comparable to
“start” (e.g., a worker that picks up a work-item). as a result it is impossibleto distinguish “waiting” and “service” times. second, we check for ontological
clarity . this is determined by the extent to which the grammar does not ex-
hibit one or more of the following deﬁciencies: (1) construct overload exists in
a grammar if one grammatical construct represents more than one ontological
construct, (2) construct redundancy exists if more than one grammatical con-
struct represents the same ontological construct, (3) construct excess exists in
a grammar when a grammatical construct is present that does not map to any
ontological construct [4, 6, 11]. the fact that staﬀware uses a start (end) event
to record the creation (completion) of a case can be seen as construct overload.there is no construct redundancy nor construct excess. so overall, the ontolog-
ical analysis is quite positive. for staﬀware such an analysis may seem trivial.
however, for systems that support a completely diﬀerent way of logging, the
ontological analysis is less straightforward.
5.4 meeting the requirements
in section 3.1, we gave ﬁve requirements for log ﬁles in order for them to be
useful for process mining. in this section, we discuss whether these requirements
are met for staﬀware, taking the mapping we established and the ontological
analysis into account.
1. each audit trail entry refers to a speciﬁc point in time. in the staﬀware log,
each line is an audit trail entry and since each line has a timestamp, this
requirement is met.
2. each audit trail entry refers to one activity. in the staﬀware log, the activities
are described by the ﬁrst column. however, there are two problems. first
of all, the start and termination of a case does not have an activity-name.
second, we cannot conclude that the activity names are unique. in fact it ispossible to have multiple activities in the deﬁnition of a staﬀware process
with the same label. to still meet this requirement, we assume the start and
end of a case to belong to a ﬁctive manual step. furthermore, we just assume
that activities are uniquely identiﬁed by their labels.
3. the second column contains a reference to the event that actually happened,
so this requirement is met.
4. the audit trail entries are sorted per case, so this requirement is met.5. the cases all belong to the same process, since a staﬀware log ﬁle always
contains at most one procedure. therefore, the last requirement is met as
well.
in this section we have shown that it is possible to make mappings from log
ﬁles of commercial systems to mxml. due to space limitations, we cannot show
the complete result of the translation. however, table 1 shows a part of the
converted log ﬁle.6 known issues
in section 5, we have shown that it is possible to map staﬀware logs onto mxml.
it may be clear that our goal is to come up with such mappings for as manyinformation systems as possible. so far, we have discovered that for most pro-
duction workﬂow system, making these mappings is almost trivial. however, for
systems that are more data driven than process driven, these mappings become
extremely diﬃcult. for example, information systems like sap r/3 and peo-
plesoft are capable of logging almost anything on a database level. however, ithas proven to be impossible to discover the case (process instance) to which an
event belongs from the event log.
obviously, the internal data structures of complex information systems like
sap and peoplesoft have to be able to link database transactions to cases. how-
ever, usually, the way these are linked is implementation and release speciﬁc,
which makes it almost impossible to derive generic results. on an implementation-
speciﬁc level however, we have seen promising results in both sap and people-soft.
another issue that needs to be addressed is the situation where not one sys-
tem is providing the event logs, but logs are taken from multiple legacy systems.
this of course requires even more bookkeeping and makes it even harder to re-
store relations between events, cases, etc. however, data warehousing techniquesmay ease the burden.
7 related work
the mxml format presented in this paper is not the only attempt to give
a formalization of data models for event logging. several papers focus on the
use of meta models in the context of process-aware information systems [9, 12].
most of these meta models however focus on the functionality of these systems
rather than their ability to record event logs. the ontological analysis of diﬀerentlanguages has been the topic of many papers. for example, in [4, 6, 11] the bunge-
wand-weber ontology is used to compare diﬀerent languages. again such an
analysis focuses on the core functionality rather than logging facilities.
we would like to discuss two related approaches in more detail. the ﬁrst is
an attempt by the workﬂow management coalition (wfmc) to standardizethe communication between workﬂow engines and administration and monitor-
ing tools. the second is the tool aris ppm (process performance monitor),
developed by ids scheer.
7.1 interface 5 of the wfmc reference model
in the area of workﬂow management, the workﬂow management coalition has
developed a reference model for communication between the core of a workﬂow
system, i.e. the workﬂow engine, and several supporting tools. for this, ﬁve
interfaces have been developed, of which interface 5 is of most interest to us.it is deﬁned as the interface for communication between the workﬂow engine
and administration and monitoring tools. unfortunately, a good standard forthis interface has never been developed. a meta model for this interface was
proposed recently in section 4, page 175 of [9]. this model, however, shows how
information in a log ﬁle relates to objects created at runtime and objects createdat build time, but it is too high level to be used as a starting point for process
mining.
7.2 ppm
a well known tool in the area of process performance monitoring, is aris ppm
(process performance monitor) [7] developed by ids scheer. aris ppm allows
for the visualization, aggregation, and analysis of process instances expressed in
terms of instance epcs (i-epcs). an instance epc describes the control-ﬂow of
a case and it provides a graphical representation describing the causal relations
between events within the case. in case of parallelism, there may be diﬀerenttraces having the same instance epc. note that in the presence of parallelism,
two subsequent events do not have to be causally related. aris ppm exploits
the advantages of having instance epcs rather than traces to provide additionalmanagement information, i.e., instances can be visualized and aggregated in
various ways.
typically, aris ppm communicates with systems like staﬀware and sap
r/3 using a number of custom-made adapters. these adapters, unfortunately,can only create instance epcs if the actual process is known. as a result, it
is very time consuming to build adapters. moreover, the approaches used only
work in environments where there are explicit process models available.
8 conclusion
in this paper, we introduced a standard for storing event logs generated byprocess-aware information systems. for this, we provide requirements, a data
model and an xml format called mxml. furthermore, we have shown an ex-
ample of a mapping from an event log of a commercial workﬂow system tomxml. in section 4, we introduced the process mining framework prom. this
framework accepts event logs in the mxml format and it enables researchers to
implement new process mining techniques and beneﬁt from each others ideas,without having to care about the information system the event logs were gen-
erated by. furthermore, by mapping event logs from commercial information
systems to mxml, the applicability of process mining in business environmentsgreatly improves. however, to establish mappings from the log formats of diﬀer-
ent information systems to the mxml format, an in-depth evaluation of a large
enough number of these systems is needed.acknowledgements and relation to interop
we thank interop for supporting this work that has been conducted in the
context of the interop work package “domain ontologies for interoperabil-ity”. more speciﬁcally, the paper touches the issue of how to deal with multi-
ple data-models (and accompanying ontologies) of logs of information systems,
which ﬁts into subtask 2 of the work package. furthermore, especially the map-
ping presented deals with issues stated in subtask 3 of the work package, i.e.
semantic mapping of ontologies and data models. since the work is inspired by apractical problem, it can be used as a starting point for further work in subtask 4,
i.e., the investigation of the eﬀectiveness of the use of ontologies for interoper-
ability. as indicated, an evaluation of a more systems (flower, filenet, ibmwebsphere, etc.) is planned in the context of this subtask.
references
1. w.m.p. van der aalst and m. song. mining social networks: uncovering interac-
tion patterns in business processes. in j. desel, b. pernici, and m. weske, editors,international conference on business process management (bpm 2004) ,v o l u m e
3080 of lecture notes in computer science , pages 244–260. springer-verlag, berlin,
2004.
2. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
3. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining ,s p e c i a l
issue of computers in industry, volume 53, number 3. elsevier science publishers,amsterdam, 2004.
4. i. davies, p. green, s. milton, and m. rosemann. analyzing and comparing
ontologies with meta-models. in j. krogs, t. halpin, and k. siau, editors, infor-
mation modeling methods and methodologies , pages 1–16. idea group, 2005.
5. b.f. van dongen, a.j.m.m. weijters a.k.a. de medeiros, h.m.w. verbeek, and
w.m.p. van der aalst. the prom framework: a new era in process mining tool
support. in accepted tool presentation at atpn 2005 , 2005.
6. p. green and m. rosemann. integrated process modeling: an ontological evalu-
ation. information systems , 25(3):73–87, 2000.
7. ids scheer. aris process performance manager (aris ppm): measure, ana-
lyze and optimize your business process performance (whitepaper). ids scheer,
saarbruecken, gemany, http://www.ids-scheer.com, 2002.
8. g. keller and t. teufel. sap r/3 process oriented implementation . addison-
wesley, reading ma, 1998.
9. m. zur muehlen. workﬂow-based process controlling: foundation, design and
application of workﬂow-driven process information systems . logos, berlin, 2004.
10. w. reisig and g. rozenberg, editors. lectures on petri nets i: basic models ,
volume 1491 of lecture notes in computer science . springer-verlag, berlin, 1998.
11. m. rosemann and p. green. developing a meta model for the bunge-wand-weber
ontological constructs. information systems , 27(2):75–91, 2002.
12. m. rosemann and m. zur muehlen. evaluation of workﬂow management systems
- a meta model approach. australian journal of information systems , 6(1):103–
116, 1998.