the prom framework:
a new era in process mining tool support
b.f. van dongen, a.k.a. de medeiros, h.m.w. verbeek, a.j.m.m. weijters,
and w.m.p. van der aalst
department of technology management, eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands.
b.f.v.dongen@tue.nl
abstract. under the umbrella of buzzwords such as “business activity
monitoring” (bam) and “business process intelligence” (bpi) both aca-
demic (e.g., emit, little thumb, inwolve, process miner, and minson)
and commercial tools (e.g., aris ppm, hp bpi, and ilog jviews) havebeen developed. the goal of these tools is to extract knowledge from event
logs (e.g., transaction logs in an erp system or audit trails in a wfm sys-
tem), i.e., to do process mining . unfortunately, tools use diﬀerent formats
for reading/storing log ﬁles and present their results in diﬀerent ways.
this makes it diﬃcult to use diﬀerent tools on the same data sets and to
compare the mining results. furthermore, some of these tools implementconcepts that can be very useful in the other tools but it is often diﬃcult
to combine tools. as a result, researchers working on new process min-
ing techniques are forced to build a mining infrastructure from scratch ortest their techniques in an isolated way, disconnected from any practical
applications. to overcome these kind of problems, we have developed the
prom framework, i.e., an “plugable” environment for process mining. theframework is ﬂexible with respect to the input and output format, and
is also open enough to allow for the easy reuse of code during the imple-
mentation of new process mining ideas. this paper introduces the promframework and gives an overview of the plug-ins that have been developed.
1 introduction
the research domain process mining is relatively new. a complete overview of
recent process mining research is beyond the scope of this paper. therefore, we
limit ourselves to a brief introduction to this topic and refer to [3, 4] and thehttp://www.processmining.org web page for a more complete overview.
the goal of process mining is to extract information about processes from
transaction logs. it assumes that it is possible to record events such that (i) eachevent refers to an activity (i.e., a well-deﬁned step in the process), (ii) each event
refers to a case(i.e., a process instance), (iii) each event can have a performer
a l s or e f e r r e dt oa s originator (the actor executing or initiating the activity), and
(iv) events have a timestamp and are totally ordered. table 1 shows an example
of a log involving 19 events, 5 activities, and 6 originators. in addition to the
information shown in this table, some event logs contain more information on thecase itself, i.e., data elements referring to properties of the case. for example, the
case handling system flower logs every modiﬁcation of some data element.
case id activity id originator case id activity id originator
case 1 activity a john case 5 activity a sue
case 2 activity a john case 4 activity c carol
case 3 activity a sue case 1 activity d pete
case 3 activity b carol case 3 activity c sue
case 1 activity b mike case 3 activity d pete
case 1 activity c john case 4 activity b sue
case 2 activity c mike case 5 activity e clare
case 4 activity a sue case 5 activity d clare
case 2 activity b john case 4 activity d pete
case 2 activity d pete
table 1. an event log (audit trail).
event logs such as the one shown in table 1 are used as the starting point
for mining. we distinguish three diﬀerent perspectives: (1) the process perspec-
tive, (2) the organizational perspective and (3) the case perspective. the process
perspective focuses on the control-ﬂow, i.e., the ordering of activities. the goal of
mining this perspective is to ﬁnd a good characterization of all possible paths,
e.g., expressed in terms of a petri net [14] or event-driven process chain (epc)[11, 12]. the organizational perspective focuses on the originator ﬁeld, i.e., which
performers are involved and how are they related. the goal is to either structure
the organization by classifying people in terms of roles and organizational unitsor to show relation between individual performers (i.e., build a social network [2]
and references there ). the case perspective focuses on properties of cases. cases
can be characterized by their path in the process or by the originators working ona case. however, cases can also be characterized by the values of the correspond-
ing data elements. for example, if a case represents a replenishment order, it is
interesting to know the supplier or the number of products ordered.
orthogonal to the three perspectives (process, organization, and case), the
result of a mining eﬀort may refer to logical issues and/or performance issues. for
example, process mining can focus on the logical structure of the process model
(e.g., the petri net shown in figure 1(a)) or on performance issues such as ﬂow
time. for mining the organizational perspectives, the emphasis can be on the rolesor the social network (cf. figure 1(b) and (c)) or on the utilization of performers
or execution frequencies.
after developing ad hoc tools for the mining of the process perspective (e.g.,
emit [1] and little thumb [16]) and other ad hoc tools (e.g., minson [2]) for the
other mining perspectives we started the design of a ﬂexible framework in which
diﬀerent algorithms for each of the perspectives can be plugged in.
2 architecture
as indicated in the introduction, the basis for all process mining techniques isaprocess log . such a log is a ﬁle generated by some information system, withaand
-splitb
cand
-join
d
e
(a) the control-flow structure expressed in terms of a petri net.
(b) the organizational structure expressed in
terms of a activity-role-performer diagram.john sue mike carol pete clarerole x role y role zjohn sue
mike
carol peteclare
(c) a sociogram based on transfer of work.
fig. 1. some mining results for the process perspective (a) and organizational (b and c)
perspective based on the event log shown in table 1.
information about the execution of a process. since each information system has
its own format for storing log ﬁles, we have developed a generic xml formatfor the prom framework to store a log in. this format was based on a thorough
comparison of the input needs of various existing (ad-hoc) process mining tools
and the information typically contained in an audit trail or transaction log of
some complex information system (e.g., an erp or a wfm system).
another important feature of the prom framework is that it allows for inter-
action between a large number of so-called plug-ins. a plug-in is basically theimplementation of an algorithm that is of some use in the process mining area,
where the implementation agrees with the framework. such plug-ins can be added
to the entire framework with relative ease: once the plug-in is ready it can be
added to the framework by adding its name to some ini-ﬁle. note that there is
no need to modify the prom framework (e.g., recompiling the code) when addingnew plug-ins, i.e., it is a truly “plugable” environment.
in figure 2, we show an overview of the framework that we developed. it
explains the relations between the framework, the process log format, and the
plug-ins. as the ﬁgure shows, the prom framework can read ﬁles in the xml
format through the log ﬁlter component. this component is able to deal with
large data-set and ﬁlter them before the actual mining starts. through the import
plug-ins a wide variety of models can be loaded ranging from a petri net to ltl
formulas. the mining plug-ins do the actual mining and the result is stored as a
frame . these frames can be used for visualization, e.g., displaying a petri net [14],
an epc [12] or a social network [2], or further analysis or conversion. the analysis
plug-ins take a mining result an analyze it, e.g., calculating a place invariant for a
resulting petri net. the conversion plug-ins take a mining result and transform
it into another format, e.g., transforming an epc into a petri net or vice versa.
in the remainder of this section, we describe both the process log format and the
plug-ins.user
interface
+
user
interactionstaffware
flowersap
inconcert
...heuristic net
aris graph format
(aris aml format)pnml
tpn
...
mining
pluginimport
pluginexport
plugin
analysis
pluginconversion
pluginheuristic net pnml
aris graph format tpn
netminer file agna filearis ppm instances dot
comma seperated values …
...
log filter
visualisation
enginexml log
result
frame
fig. 2. overview of the prom framework
2.1 process log format
figure 3 visualizes the xml schema that speciﬁes the process log format. the root
element is a workﬂowlog element. (the name “workﬂow log” is chosen for back-
wards compatibility and we prefer to talk about process log.) the workﬂowlog
element contains (in the given order) an optional dataelement, an optional source
element, and a number of process elements. a dataelement allows for storing ar-
bitrary textual data, and contains a list of attribute elements. a source element
can be used to store information about the information system this log originated
from. a process element refers to a speciﬁc process in an information system. since
most information systems typically control several processes, multiple process el-
ements may exist in a log ﬁle. a processinstance is an instance of the process, i.e.,
ac a s e .a n audittrailentry may refer to an activity ( workﬂowmodelelement ), an
eventtype ( eventtype ), a timestamp ( timestamp ), and a person that executed the
activity ( originator ).
as will be clear from what was mentioned earlier, a log ﬁle typically contains
information about events that took place in a system. such events typically referto a case and a speciﬁc activity within that case. examples of such events are:
–the activity send message is now ready to be executed.
–the activity wait for incoming transmission has not been started for three
weeks.
–the case with id 203453 was aborted.
in order to be able to talk about these events in a standard way, we developed
a transactional model that shows the events that we assume can appear in afig. 3. format of a process log
log. again this model is based on analyzing the diﬀerent types of logs in real-life
systems (e.g., staﬀware, sap, flower, etc.) figure 4 shows the transactional
model.
reassign
schedule assign
start
resume
suspend
autoskip completemanualskip
ate_abort
pi_abortwithdraw
fig. 4. transactional model for activities
when an activity is created, it is either schedule d or skipped automatically
(autoskip ). scheduling an activity means that the control over that activity is put
into the information system. the information system can now assign this activity
to a certain person or group of persons. it is possible to reassign an assigned
activity to another person or group of persons. this can be done by the system,or by a user. a user can startworking on an activity that was assigned to him, or
some user can decide to withdraw the activity or skip it manually ( manualskip ),
which can even happen before the activity was assigned. the main diﬀerencebetween a withdrawal and a manual skip is the fact that after the manual skip
the activity has been executed correctly, while after a withdrawal it is not. the
user that started an activity can suspend and resume the activity several times,but in the end s/he either has to complete or abort ( ateabort) it. note the activity
can get aborted ( piabort) during its entire life cycle.
we do not claim that we have captured all possible behavior of all systems.
however, we have veriﬁed our transactional model against several commercial
systems and they all seem to ﬁt nicely. nonetheless, in the xml format, we allow
for other event types to be deﬁned on the ﬂy.
2.2 plug-ins
in this section, we provide an overview of the plug-ins as currently implemented
in the context of the prom framework. as shown in figure 2 there are ﬁve kinds
of plug-ins:
mining plug-ins which implement some mining algorithm, e.g., mining algo-
rithms that construct a petri net based on some event log.
export plug-ins which implement some “save as” functionality for some objects
(such as graphs). for example, there are plug-ins to save epcs, petri nets(e.g., in pnml format [7]), spreadsheets, etc.
import plug-ins which implement an “open” functionality for exported objects,
e.g., load instance-epcs from aris ppm.
analysis plug-ins which typically implement some property analysis on some
mining result. for example, for petri nets there is a plug-in which constructs
place invariants, transition invariants, and a coverability graph. however,there are also analysis plug-ins to compare a log and a model (i.e., confor-
mance testing) or a log and an ltl formula.
conversion plug-ins which implement conversions between diﬀerent data for-
mats, e.g., from epcs to petri nets.
the current version of the framework contains a large set of plug-ins. a detailed
description of these plug-ins is beyond the scope of this paper. currently, thereare nine export plug-ins, four import plug-ins, seven analysis plug-ins, and three
conversion plug-ins. therefore, we only mention some of the available mining plug-
ins. for each of the three perspectives which were mentioned in the introduction,
there are diﬀerent mining plug-ins.
for the process perspective, four plug-ins are available:
α-algorithm which implements the α-algorithm [5] and its extensions as devel-
oped by the authors. the α-algorithm constructs a petri net which models
the process recorded in the log.
tshinghua- αalgorithm which uses timestamps in the log ﬁles to construct a
petri net. it is related to the αalgorithm, but uses a diﬀerent approach. it
is interesting to note that this mining plug-in was the ﬁrst plug-in developedby researchers outside of our research group. researchers from tshinghua
university in china (jianmin wang and wen lijie) were able to develop and
integrate this plug-in without any help or changes to the framework.genetic algorithm which uses genetic algorithms to tackle possible noise in the
log ﬁle. its output format is a heuristics net (which can be converted into anepc or a petri net).
multi-phase mining which implements a series of process mining algorithms
that use instance graphs (comparable to runs) as an intermediate format.the two-phase approach resembles the aggregation process in aris ppm.
for the organizational perspective, one plug-in is available:
social network miner which uses the log ﬁle to determine a social network of
people [2]. it requires the log ﬁle to contain the originator element.
finally, for the case perspective, also one plug-in is available:case data extraction which can be used for interfacing with a number of stan-
dard knowledge discovering tools , e.g., viscovery and spss answertree.
sometimes a collection of plug-ins is needed to achieve the desired function-
ality. an example is the ltl-checker which checks whether logs satisﬁes some
linear temporal logic (ltl) formula. for example, the ltl-checker can be used
to check the “four eyes” principle, i.e., two activities within the same case shouldnot be executed by the same person to avoid possible fraud. the ltl-checker com-
bines a mining plug-in (to get the log), an import plug-in (to load the ﬁle with
predeﬁned ltl formulas), and an analysis plug-in (to do the actual checking).
3 user interface
since the prom framework contains a large number of plug-ins, it is impossibleto discuss them all in detail. therefore, we only present some screenshots of afew plug-ins that we applied to the example of table 1. in figure 5, we show the
result of applying the α-mining plug-in to the example. the default settings of
the plug-in were used, and the result is a petri net that is behaviorally equivalentto the one presented in figure 1. in figure 6, we show the result of the social
network mining plug-in. we used the handover of work setting, considering only
direct succession, to generate this ﬁgure. comparing it to figure 1(c) shows thatthe result is an isomorphic graph (i.e. the result is the same).
petri nets are not the only modelling language supported by the framework.
instead, we also have built-in support for epcs (event-driven process chains).
in figure 7, we show the result of the multi-phase mining plug-in. the result is
an aggregated epc describing the behavior of all cases. note that it allows formore behavior than the petri net, since the connectors are of the type logical or .
in figure 8 we show the user interface of the analysis plug-in that can be used
for the veriﬁcation of epcs.
in this section, we showed some screenshots to provide an overview of the
framework. we would like to stress that we only showed a few plug-ins of the many
that are available. we would also like to point out that most plug-ins allow for userinteraction. the latter it important because process mining is often an interactive
process where human interpretation is important and additional knowledge can
be used to improve the mining result.fig. 5. theα-mining plug-in
 fig. 6. the social network mining plug-in
4 related work
process mining can be seen as a tool in the context of business activity monitoring
(bam) and business (process) intelligence (bpi). in [9] a bpi toolset on top ofhp’s process manager is described. the bpi tools set includes a so-called “bpi
process mining engine”. however, this engine does not provide any techniques as
discussed before. instead it uses generic mining tools such as sas enterprise miner
for the generation of decision trees relating attributes of cases to information about
execution paths (e.g., duration). in [13] the pisa tool is described which can beused to extract performance metrics from workﬂow logs. similar diagnostics are
provided by the aris process performance manager (ppm) [11]. the later tool is
commercially available and a customized version of ppm is the staﬀware processmonitor (spm) [15] which is tailored towards mining staﬀware logs.
1
fig. 7. the discovered epc
 fig. 8. analyzing the epc for correctness
1note that the prom framework interfaces with staﬀware, spm, aris toolset, and
aris ppm.given the many papers on mining the process perspective it is not possible to
give a complete overview. instead we refer to [3, 5]. historically, cook et al. [8]and agrawal et al. [6] started to work on the problem addressed in this paper.
herbst et al. [10] took an alternative approach which allows for dealing with
duplicate activities. the authors of this paper have been involved in diﬀerentvariants of the so-called α-algorithm [1, 5, 16]. each of the approaches has its pros
and its cons. most approaches that are able to discover concurrency have problems
dealing with issues such as duplicate activities, hidden activities, non-free-choiceconstructs, noise, and incompleteness.
the prom framework subsumes process mining tools like emit [1], little
thumb [16] and minson [2]. most of these tools had their own format to storelog ﬁles in, and had their own limitations. the tool emit for example was un-
able to deal with log ﬁles of more than 1000 cases. to be able to use all these
tools together in an interactive way, we developed the prom framework, which
can be seen as a successor of all these tools. the framework allows researchers to
seamlessly combine their own algorithms with algorithms from other people. fur-thermore, using the framework allows you to interface with many existing tools,
both commercial and public. these tools include: the aris toolset, aris ppm,
woﬂan, the petri net kernel, netminer, agna, dot, viscovery, etc.
5 conclusion
the prom framework integrates the functionality of several existing process min-ing tools and provides many additional process mining plug-ins. the prom frame-
work supports multiple formats and multiple languages, e.g., petri nets, epcs,
social networks, etc. the plug-ins can be used in several ways and combined to beapplied in real-life situations. we encourage developers and researchers to use the
prom framework for implementing new ideas. it is easy to add a new plug-in. for
adding new plug-ins it suﬃces to add a few lines to the conﬁguration ﬁles and no
changes to the code are necessary, i.e., new mining plug-ins can be added without
re-compiling the source code. experiences with adding the thingua alpha-plugin
and the social network miner show that this is indeed rather straightforward.
6 acknowledgements
the authors would like to thank all people that have been involved in the de-
velopment and implementation of the prom framework. in particular we would
like to thank minseok song, jianmin wang and wen lijie for their contributions.furthermore, we would like to thank ids scheer for providing us with aris ppm
and the aris toolset. last, but certainly not least, we would like to thank peter
van den brand for doing the major part of the implementation work for us.
references
1. w.m.p. van der aalst and b.f. van dongen. discovering workﬂow performance
models from timed logs. in y. han, s. tai, and d. wikarski, editors, internationalconference on engineering and deployment of cooperative information systems
(edcis 2002) , volume 2480 of lecture notes in computer science , pages 45–63.
springer-verlag, berlin, 2002.
2. w.m.p. van der aalst and m. song. mining social networks: uncovering interaction
patterns in business processes. in j. desel, b. pernici, and m. weske, editors,
international conference on business process management (bpm 2004) , volume
3080 of lecture notes in computer science , pages 244–260. springer-verlag, berlin,
2004.
3. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
4. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining ,s p e c i a l
issue of computers in industry, volume 53, number 3. elsevier science publishers,
amsterdam, 2004.
5. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128–1142, 2004.
6. r. agrawal, d. gunopulos, and f. leymann. mining process models from workﬂow
logs. in sixth international conference on extending database technology ,p a g e s
469–483, 1998.
7. j. billington and et. al. the petri net markup language: concepts, technology,
and tools. in w.m.p. van der aalst and e. best, editors, application and theory of
petri nets 2003 , volume 2679 of lecture notes in computer science , pages 483–506.
springer-verlag, berlin, 2003.
8. j.e. cook and a.l. wolf. discovering models of software processes from
event-based data. acm transactions on software engineering and methodology ,
7(3):215–249, 1998.
9. d. grigori, f. casati, u. dayal, and m.c. shan. improving business process qual-
ity through exception understanding, prediction, and prevention. in p. apers,
p. atzeni, s. ceri, s. paraboschi, k. ramamohanarao, and r. snodgrass, editors,
proceedings of 27th international conference on very large data bases (vldb’01) ,
pages 159–168. morgan kaufmann, 2001.
10. j. herbst. a machine learning approach to workﬂow management. in proceedings
11th european conference on machine learning , volume 1810 of lecture notes in
computer science , pages 183–194. springer-verlag, berlin, 2000.
11. ids scheer. aris process performance manager (aris ppm): measure, analyze
and optimize your business process performance (whitepaper). ids scheer, saar-
bruecken, gemany, http://www.ids-scheer.com, 2002.
12. g. keller and t. teufel. sap r/3 process oriented implementation . addison-
wesley, reading ma, 1998.
13. m. zur m¨ uhlen and m. rosemann. workﬂow-based process monitoring and con-
trolling - technical and organizational issues. in r. sprague, editor, proceedings
of the 33rd hawaii international conference on system science (hicss-33) , pages
1–10. ieee computer society press, los alamitos, california, 2000.
14. w. reisig and g. rozenberg, editors. lectures on petri nets i: basic models ,v o l u m e
1491 of lecture notes in computer science . springer-verlag, berlin, 1998.
15. staﬀware. staﬀware process monitor (spm). http://www.staﬀware.com, 2002.
16. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models from
event-based data using little thumb. integrated computer-aided engineering ,
10(2):151–162, 2003.