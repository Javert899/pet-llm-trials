article type: focus article
replaying history on process models for
conformance checking and performance
analysis
wil van der aalst, arya adriansyah, and boudewijn van dongen
department of mathematics and computer science, technische universiteit
eindhoven, the netherlands.
keywords
process mining, conformance checking, automated process discovery, petri
nets, business intelligence
abstract
process mining techniques use event data to discover process models, to
check the conformance of predeÔ¨Åned process models, and to extend such
models with information about bottlenecks, decisions, and resource usage.
these techniques are driven by observed events rather than hand-made mod-
els. event logs are used to learn and enrich process models. by replaying
history on the model, it is possible to establish a precise relationship between
events and model elements . this relationship can be used to check confor-
mance and to analyze performance. for example, it is possible to diagnose
deviations from the modeled behavior. the severity of each deviation can be
quantiÔ¨Åed. moreover, the relationship established during replay and the times-
tamps in the event log can be combined to show bottlenecks. these examples
illustrate the importance of maintaining a proper alignment between event log
and process model. therefore, we elaborate on the realization of such align-
ments and their application to conformance checking and performance analy-
sis.
introduction
process mining is an emerging research discipline that sits between computational in-
telligence and data mining on the one hand, and process modeling and analysis on the
other hand [1]. starting point for process mining is an event log . all process mining
techniques assume that it is possible to sequentially record events such that each event
refers to an activity (i.e., a well-deÔ¨Åned step in the process) and is related to a particular
case (i.e., a process instance). event logs may store additional information such as the
resource (i.e., person or device) executing or initiating an activity, the timestamp of
an event, or data elements recorded with an event (e.g., the size of an order). event
1logs can be used to discover, monitor and improve processes based on facts rather than
Ô¨Åction. there are three main types of process mining:
discovery : take an event log and produce a model without using any other a-
priori information. there are dozens of techniques to extract a process model
from raw event data. for example, the classical algorithm is able to discover
a petri net by identifying basic process patterns in an event log [4]. for many
organizations it is surprising to see that existing techniques are indeed able to dis-
cover real processes based on merely example executions recorded in event logs.
process discovery is often used as a starting point for other types of analysis.
conformance : an existing process model is compared with an event log of the
same process. the comparison shows where the real process deviates from the
modeled process. moreover, it is possible to quantify the level of conformance
and differences can be diagnosed. conformance checking can be used to check
if reality, as recorded in the log, conforms to the model and vice versa. there
are various applications for this (compliance checking, auditing, six sigma, etc.)
[25].
enhancement : take an event log and process model and extend or improve the
model using the observed events. whereas conformance checking measures the
alignment between model and reality, this third type of process mining aims at
changing or extending the a-priori model. for instance, by using timestamps
in the event log one can extend the model to show bottlenecks, service levels,
throughput times, and frequencies [1].
process mining provides a bridge between data mining (including computational intel-
ligence, machine learning, and knowledge discovery) and model-driven process man-
agement (process modeling, business process management, simulation, and veriÔ¨Åca-
tion). data mining techniques [16] tend to search for relatively simple patterns in large
datasets. these patterns may be association rules, decision trees, clusters, frequent
sequences, etc. however, patterns discovered through traditional data mining tech-
niques do not describe end-to-end processes involving concurrency, resource sharing,
etc. model-driven process management techniques [31] focus on such end-to-end pro-
cesses but do not use event data, i.e., models are typically made by hand and are not
related to the actual observed behavior. only in recent years it has become possible to
bridge this gap [1].
over the last decade, event data have become readily available and process mining
techniques have matured. moreover, managements trends related to process improve-
ment, e.g., six sigma, tqm (total quality management), cpi (continuous process
improvement), and cpm (corporate performance management) can beneÔ¨Åt from pro-
cess mining [1, 18]. whereas these managements trends aim at improving operational
performance, e.g., reducing Ô¨Çow time and defects, organizations are also putting more
emphasis on corporate governance, risk, and compliance. major corporate and ac-
counting scandals including those affecting enron, tyco, adelphia, peregrine, and
worldcom have fueled interest in more rigorous auditing practices. legislations such
2as the sarbanes-oxley act (sox) of 2002 and the basel ii accord of 2004 were en-
acted in response to such scandals. the recent Ô¨Ånancial crisis also underscores the
importance of verifying that organizations operate ‚Äúwithin their boundaries‚Äù. process
mining techniques offer a means to more rigorously check compliance and ascertain the
validity and reliability of information about an organization‚Äôs core processes [1, 18].
the right-hand side of fig. 1 shows an abstraction of an event log containing 1391
cases, i.e., instances of some reimbursement process. each case is represented by a
trace of events and each event corresponds to an activity executed for a speciÔ¨Åc case.
for example, fig. 1 shows that there are 455 process instances having a trace acdeh .
activities are represented by a single character: a=register request ,b=examine
thoroughly ,c=examine casually ,d=check ticket ,e=decide ,f=reinitiate re-
quest ,g=pay compensation , andh=reject request . hence, trace acdeh models a
reimbursement request that was rejected after a registration, examination, check, and
decision step. 455 cases followed this path consisting of Ô¨Åve steps, i.e., the Ô¨Årst line
in the table corresponds to 4555 = 2275 events. the whole log consists of 7539
events.
the event log in fig. 1 only shows activity names. as mentioned before, events may
have much more properties. for example, the aevent of one of the 455 cases following
acdeh may refer to the name of the customer, the employee registering the request, the
timestamp, etc. although the activity name is just one of many potential attributes of
an event, we use the more compact representation shown in fig. 1 for clarity.
thealgorithm [4] mentioned earlier constructs process model m1from the event log
shown in fig. 1. the model is represented as a petri net and shows that all cases start
witha(register request) and end with g(pay compensation) or h(reject request). the
examination (i.e., borc) is concurrent with the checking of the ticket ( d). subsequently,
a decision is made ( e) with three possible outcomes. one of these three outcomes is
the reinitiation of the request ( f) which triggers a new examination and check. model
m1describes the observed behavior well, e.g., m1is able to replay all 1381 cases in
the event log.
figure 1 shows three additional models. these models also aim to describe the pro-
cess that produced the event log. model m2is only able to replay the 455 cases that
followedacdeh and none of the 936 other cases Ô¨Åts completely. model m3is able to
replay the whole log (i.e., all 1391 cases), but also allows for traces dissimilar to the
observed behavior, e.g., traces such as aeeeeeh are possible according to m3. model
m4simply enumerates all 21 traces observed. this model is too complex and is also
‚ÄúoverÔ¨Åtting‚Äù the observed behavior, i.e., unseen but likely behavior is excluded.
the four process models may have been discovered using a process discovery algo-
rithm or may also have been made by hand. in either case, it is interesting to check
conformance of model and log. assuming that m1is the model that best Ô¨Åts reality as
observed in the event log, we can use the relation between m1and the 7539 events in
the log as the starting point for all kinds of analysis. for example, when events have
timestamps, we can replay the log and add performance related information to m1. for
example, all places (circles) in m1can be annotated with the observed average waiting
time extracted from the event log.
3a
start register 
requestbexamine 
thoroughly
cexamine 
casuallydcheck
ticket
decidepay 
compensation
reject 
requestreinitiate 
request eg
hfenda
startregister 
requestc
examine 
casuallyd
check
ticketdecide reject 
requeste h
end
m3 : fitness = +, precision = -, generalization = +, simplicity = +m2 : fitness = -, precision = +, generalization = -, simplicity = +a
start register 
requestb
examine 
thoroughly
c
examine 
casually
d
check ticketdecidepay 
compensation
reject 
request
reinitiate 
requesteg
h
fend
m1 : fitness = +, precision = +, generalization = +, simplicity = +
a
start register 
requestc
examine 
casuallyd
check
ticketdecide reject 
requeste h
end
m4 : fitness = +, precision = +, generalization = -, simplicity = -a
register 
requestd
examine 
casuallyc
check
ticketdecide reject 
requeste ha c
examine 
casuallyd
check
ticketdecidee ga d
examine 
casuallyc
check
ticketdecidee g
register 
requestregister 
requestpay 
compensation
pay 
compensation
a
register 
requestb d
check
ticketdecide reject 
requeste ha
register 
requestd b
check
ticketdecide reject 
requeste ha b d
check
ticketdecidee g
register 
requestpay 
compensationexamine 
thoroughly
examine 
thoroughly
examine 
thoroughly‚Ä¶ (all 21 variants seen in the log)acdeh
abdeg
adceh
abdeh
acdeg
adceg
adbeh
acdefdbeh
adbeg
acdefbdeh
acdefbdeg
acdefdbeg
adcefcdeh
adcefdbeh
adcefbdeg
acdefbdefdbeg
adcefdbeg
adcefbdefbdeg
adcefdbefbdeh
adbefbdefdbeg
adcefdbefcdefdbeg455
191
177
144
111
82
56
47
38
33
14
11
9
8
5
3
2
2
1
1
1#trace
1391event logfigure 1: one event log l(right) and four process models m1,m2,m3, andm4(left).
4aligning event log and process model
conformance checking and performance analysis require an alignment of event log
and process model, i.e., events in the event log need to be related to model elements
and vice versa. such an alignment shows how the event log can be replayed on the
process model. this is far from trivial as the log may deviate from the model and not
all activities may have been modeled or recorded. to discuss these complications we
need to introduce some notations.
the event log in fig. 1 contains 1391 cases. each case is described by a trace, i.e., a
sequence of activity names. different cases may have the same trace. therefore, an
event log is a multiset of traces (rather than a set). aldenotes the set of activities that
may be recorded in the log. 2a
lis atrace , i.e., a sequence of events. l2i b(a
l)
is an event log , i.e., a multiset of traces. for example, l= [acdeh;acdeh;abdeg ]is an
event log with three cases, two of which follow the same trace.
each of the four process models in fig. 1 is represented as a petri net. other representa-
tions frequently used are uml activity diagrams, bpmn (business process modeling
notation), epcs (event-driven process chains) models, yawl models, etc. [17, 31]. it
is essential that such models are able to represent common process patterns in a com-
pact and intuitive manner. for example, process models should be able to represent
concurrency (e.g., in m1checking and examination activities can be done in parallel).
however, in this article we abstract from the actual process notation and focus on the
behavior described by the model. therefore, we can use basic transition systems as a
placeholder for more advanced modeling languages (petri nets, uml, bpmn, epcs,
etc.).
aprocess model m= (s;si;sf;am;t)is a transition system over a set of activities
amwith statess, initial states sis, Ô¨Ånal states sfs, and transitions t
sams. the set of activities in the model ammay differ from the set of activities
in the event log al. the transition system starts in a state in siand moves from one
state to another according to the transition relation t, e.g., (s1;a;s 2)2tmeans that
in states1the transition system can move to state s2while producing an event labeled
a. eventually, a Ô¨Ånal state in sfshould be reached in order to complete.
(m)a
mis the set of all full execution sequences , i.e., possible traces starting in a
state insiand ending in a state in sf. consider for example m= (fs1;s2;s3;s4g;
fs1g;fs4g;fa;b;c;dg;f(s1;a;s 2);(s2;b;s 3);(s3;c;s 2);(s2;d;s 4)g).(m) =fad;
abcd;abcbcd;abcbcbcd;::: g. all modeling languages with executable semantics can
be described in this way.
an important assumption of the approach presented in this article is that the relation-
ship between activities in the model and events in the event log is known, i.e., both
events and activities carry labels. this way it is possible to relate events to activities.
however, as we will show later, there may be multiple activities carrying the same label
and there may be a partial match between an event and activity (deÔ¨Åned by a so-called
distance function ).
5to establish an alignment between process model and event log we need to relate
‚Äúmoves‚Äù in the log to ‚Äúmoves‚Äù in the model. however, it may be the case that some of
the moves in the log cannot be mimicked by the model and vice versa. we explicitly
denote ‚Äúno move‚Äù by ?. for convenience, we introduce the set a?
l=al[f?g where
x2alrefers to ‚Äúmove xin log‚Äù and?refers to ‚Äúno move in log‚Äù. similarly, we use
a?
m=am[f?g wherey2amrefers to ‚Äúmove yin model‚Äù and?refers to ‚Äúno
move in model‚Äù.
one step in an alignment is represented by a pair (x;y)2a?
la?
msuch that
(x;y)is amove in log ifx2alandy=?,
(x;y)is amove in model ifx=?andy2am,
(x;y)is amove in both ifx2alandy2am,
(x;y)is an illegal move x=?andy=?.
alm=f(x;y)2a?
la?
mjx2al_y2amgis the set of all legal moves .
letl2lbe a trace in event log land letm2(m)be a full execution sequence
of modelm. an alignment oflandmis a sequence 2almsuch that the
projection on the Ô¨Årst element (ignoring ?) yieldsland the projection on the second
element (again ignoring ?) yieldsm. two examples of alignments:
1=acdeh
acdehand2=ab?deg?
a?cde?h
note that we represent the moves vertically, e.g., the Ô¨Årst move of 1is(a;a)indicating
that both the log and the model make an amove.1is an alignment of l=acdeh and
m=acdeh .2is an alignment of l=abdeg andm=acdeh . two additional
alignments for l=abdeg andm=acdeh :
3=ab?de??g
?acd?eh?and4=a?bdeg?
a?cde?h
note that in3there is Ô¨Årst a ‚Äúmove in log‚Äù (a;?)followed by a ‚Äúmove in both‚Äù (b;a).
clearly, this is not an optimal alignment because there is no need to just move in the
log and then to move both without agreement on the step to be made: the log makes
abmove whereas the model makes an amove.4is not a correct alignment because
it contains an illegal move (?;?)(see second position). after removing the illegal
move, we obtain a proper alignment.
1shows the ideal situation where model and log can mimic each other perfectly. such
an alignment is not possible for l=abdeg andm=acdeh . instead, one needs
to resort to alignments such as 2and3. of these two alignments 2is preferable
because3contains more moves in only the log or model, and 3has a ‚Äúmove in both‚Äù
(x;y)withx6=y(second position).
to qualify the quality of an alignment we introduce a distance function on legal moves:
2alm!i n. the distance function associates costs to moves in an alignment:
6ifx2alandy=?, then(x;y)is the cost of ‚Äúmove xin log‚Äù,
ifx=?andy2am, then(x;y)is the cost of ‚Äúmove yin model‚Äù, and
ifx2alandy2am, then(x;y)is the cost of ‚Äúmove xin log and move yin
model‚Äù (typically (x;y) = 0 ifx=y).
distance function can be generalized to alignments by taking the sum of the costs of
all individual moves: () =p
(x;y)2(x;y).1
we deÔ¨Åne a standard distance function s. forx2alandy2am:s(x;?) = 1 ,
s(?;y) = 1 ,s(x;y) = 0 ifx=y, ands(x;y) =1ifx6=y. only moves
where log and model agree on the activity have no associated costs. moves in just the
log or model have cost 1. sassociates high costs to moves where both log and model
make a move but disagree on the activity. in ‚Äú s(x;y) =1‚Äù,1should be read as a
number large enough to discard the alignment (see below). using the standard distance
functions:s(1) =s(a;a) +s(c;c) +s(d;d) +s(e;e) +s(h;h) = 0 ,
s(2) = 4 (four moves in just the log or model), and s(3) =1(because of move
(b;a)).
various cost functions can be deÔ¨Åned. for example, the weights of activities may vary.
skipping a payment may have a much higher cost than skipping some minor check.
the cost function can also be used to compare activities which are not identical but
similar, e.g., in the example we may deÔ¨Åne (b;c) =(c;b) = 0:8because both b
andcexamine the request and are exchangeable to some degree. it is also possible
that the model has multiple activities which have the same observable effect. for ex-
ample, in a petri net there may be multiple transitions (e.g., t1andt2) corresponding
to some activity x:(x;t1) =(x;t2) = 0 . in fact, it is often desirable to give all
transitions a unique name. this way any m2(m)corresponds to a unique path
in the model. in the remainder, we assume the standard distance function sunless
mentioned otherwise.
thus far we considered a speciÔ¨Åc full execution sequence in the model. however, our
goal is to relate traces in the model to the best matching full execution sequence in the
model. therefore, we deÔ¨Åne the notion of an optimal alignment . letl2lbe a trace
in event log land letmbe a model.  l;m=f2almj9m2(m)is an
aligment of landmg. an alignment 2 l;misoptimal for log trace l2l
and modelmif for any02 l;m:(0)().
for an event log land process model m, we deÔ¨Ånem2al!alm: a mapping
that assigns any l2lto an optimal alignment, i.e., m(l)2 l;mandm(l)
is optimal. it is easy to see that such a mapping exists (but there may be multiple).
consider for example m2andl=acdefdbeh , i.e., the trace that occurred 47 times
in the log of fig. 1. mapping m2may produce the following optimal alignment:
m2(l) =acdefdbeh
acd????eh
1note that summation is generalized to sequences and multisets, i.e.,p
x2aabf(x) =p
x2[a;a;b ]f(x) = 2 f(a) +f(b).
7note that the alignment deÔ¨Ånes a path in the model from an initial state to a Ô¨Ånal state
(in this case acdeh ).m(l)2(m)is the projection on the second element of
m(l)(ignoring?). hence,m2al!amsuch thatm(l)gives the best
matching full execution sequence for tracelin modelm. consider for example m1
andl=abefbh , i.e. a trace that cannot be generated by the petri net in fig. 1. given
standard distance function sthere is just one choice:
m1(l) =ab?efb??h
abdefbdeh
hence,m1(l) =abdefbdeh is the best matching sequence with cost s(m1(l)) =
3.
in general, there may be many other alignments having the same cost. however, func-
tionmprovides an ‚Äúoracle‚Äù that, given an log trace l, produces onebest match-
ing full execution sequence m(l). it is always possible to create such a function
based on some predeÔ¨Åned distance function. in [6, 5] various approaches are given
to create optimal alignment with respect to some predeÔ¨Åned distance function. these
approaches are based on the aalgorithm, i.e., an algorithm originally invented to Ô¨Ånd
the shortest path between two nodes in a directed graph. the aalgorithm can be
adapted to Ô¨Ånd an optimal alignment between model and log. in this article we do not
elaborate on the aalgorithm. in principle, any optimization approach can be used to
computem(l). here we focus on the result that after alignment any trace in the
event log can be replayed on model (even if the trace does not Ô¨Åt perfectly).
conformance checking
for conformance checking we use the ‚Äúoracle‚Äù mthat relates traces in the event log
to paths in the model. in this section, we consider the standard four quality dimen-
sions for comparing model and log: (a) Ô¨Åtness , (b) simplicity , (c) precision , and (d)
generalization [1].
fitness: can the model generate the observed behavior?
a model with good Ô¨Åtness allows for most of the behavior seen in the event log. a
model has a perfect Ô¨Åtness if all traces in the log can be replayed by the model from
beginning to end. to quantify Ô¨Åtness, we can directly apply the distance function 
on the optimal alignments provided by the ‚Äúoracle‚Äù m. the total alignment cost for
event logland modelmis
fcost(l;m ) =x
l2l(m(l))
consider for example event log land the four models shown in fig. 1. fcost(l;m 1) =
0,fcost(l;m 2) = 2884 ,fcost(l;m 3) = 0 , and fcost(l;m 4) = 0 . this shows that
8m1,m3, andm4are able to replay the log without any problems. the total alignment
cost for model m2is 2884. this sum is caused by the moves in just the model or just
the log, for all cases different from acdeh .
often, we would like to express Ô¨Åtness as a number between 0(very poor Ô¨Åtness)
and1(perfect Ô¨Åtness). there are several ways to normalize the alignment costs.
one approach is to divide fcost(l;m )by the maximal possible cost. let us as-
sume that for x2alandy2am:(x;y) =1ifx6=y, i.e., we only al-
low a move on both model and log (x;y)ifx=y. in this case, the worst-case
scenario is that there are just moves in the log and moves in the model (and never
both) in the optimal alignment. movel(l) =p
l2lp
x2l(x;?)is the total
cost of moving through the whole log without ever moving together with the model.
movem(m) = minm2(m)p
y2m(?;y)is the total cost of making moves on
model only. note that we consider the ‚Äúleast expensive path‚Äù because an optimal align-
ment will try to minimize costs. this results in the following deÔ¨Ånition of Ô¨Åtness:
tness (l;m ) = 1 fcost(l;m )
movel(l) +jljmovem(m)
tness (l;m 1) = 1 ,tness (l;m 2) = 0:8,tness (l;m 3) = 1 , and tness (l;m 4) =
1. the Ô¨Åtness value for model m2is 0.8. this may seem high as just 455 of 1391 cases
Ô¨Åt completely (i.e., less than 33% of the process instances can be replayed from begin-
ning to end). however, note that all cases start with aand execute at least one dande.
moreover, the majority of cases ends with h. this explains the high Ô¨Åtness value.
note that there are alternative ways to normalize the alignment cost to produce a Ô¨Åtness
value, e.g., a Ô¨Åtness value only considering moves on log.
precision: avoid underÔ¨Åtting
modelm3in fig. 1 has a Ô¨Åtness of 1 although the model clearly allows for behavior
very different from the behavior seen in the event log. a model is precise if it does not
allow for ‚Äútoo much‚Äù behavior. a model that is not precise is ‚ÄúunderÔ¨Åtting‚Äù. underÔ¨Åt-
ting is the problem that the models such as m3over-generalize the example behavior
seen in the log.
in [25] two so-called ‚Äúappropriateness notions‚Äù are deÔ¨Åned (behavioral appropriateness
and structural appropriateness). the goal is to discover situations where ‚Äútoo‚Äù many
transitions are enabled. for example, after the execution of ainm3, seven activities
(b,c,d,e,f,gandh) are continuously enabled until completion. however, based on
the event log it appears that in most situations just one to three activities are enabled
rather than seven.
in [23] a so-called preÔ¨Åx automaton is constructed to see where the process model
allows for more behavior than actually observed in the event log. this approach is
further improved in [22, 24].
9the approach proposed in this paper is very different from [25]. instead, we propose
an approach similar to [22], i.e., using a preÔ¨Åx automaton combined with an alignment
between model and log. before doing so, we revisit our notion of event logs.
event logldoes not need to Ô¨Åt model m. however, we can construct a modiÔ¨Åed event
logl0= [m()j2l]. in the remainder, we only use such preprocessed logs, i.e.,
from now on we only consider event logs after alignment . note that this implies that
given a logland modelm: (a)al=amand (b)2limplies2(m).
moreover, we assume any model mto be deterministic , i.e., given some execution se-
quence2(m)there is only one corresponding path in the model. this also holds
for preÔ¨Åxes of . modelm4in fig. 1 does not meet this requirement unless we relabel
the transitions. for any state in a deterministic model, there cannot be two enabled
transitions with the same label. note that any model can be made deterministic: sim-
ply rename competing transitions with the same label and adapt the distance function
accordingly.
to simplify our deÔ¨Ånition of precision, we view an event log as a collection of unique
eventse. consider the Ô¨Årst activity of trace acdeh in the event log of fig. 1. there are
455 distinct events corresponding to initial activity ainacdeh . for the example log,
econtains 7539 events. the activity associated to e2e isact(e)and the timestamp
ofeistime(e). in addition, we deÔ¨Åne the following functions given e2e and some
modelm= (s;si;sf;am;t):
statem(e)2sis the state inmjust before the occurrence of e. note that it is
possible to derive this state because we consider a preprocessed log with Ô¨Åtness
1 and a deterministic model.
contextl(e)2amis the activity preÔ¨Åx of the process instance just before the
occurrence of e, i.e., the sequence of all activities that happened before event e.
we call this preÔ¨Åx the context ofe.
enm(e)amis the set of activities enabled in statem(e), i.e., enm(e) =
fa2amj9s2s(statem(e);a;s)2tg. note that act(e)2enm(e).
enl(e)amis the set of activities that were executed in the same con-
text, i.e., enl(e) =fact(e0)je02 e ^ contextl(e0) = contextl(e)g.
enl(e)enm(e)because we consider a preprocessed log with Ô¨Åtness 1 and
a deterministic model (the same preÔ¨Åx always leads to the same state).
sim(e)e is the set of all events that happened in the same state as the state
just before executing e, i.e., sim(e) =fe02e j statem(e0) = statem(e)g.
note thate2sim(e).
di(e) =fact(e0)je02sim(e)gamare the different activities that were
executed in the same state as the state just before executing e.
each evente2e implicitly refers to a point in the event log just before executing e.
for such a point we can count the number of enabled activities in the model enm(e)
10and the number of observed activities actually executed in a similar context enl(e).
this can be used to deÔ¨Åne the following precision notion:
precision (l;m ) =1
jejx
e2ejenl(e)j
jenm(e)j
if all behavior allowed by the model is actually observed, then precision (l;m ) = 1 .
by taking the average over all events, we automatically take frequencies into account.
if the model has an activity that is enabled on a frequent path but the activity is never
executed, then this is more severe than an unused activity enabled along an infrequent
path.
for our running example we compute: precision (l;m 1) = 0:97,precision (l;m 2) =
1,precision (l;m 3) = 0:41, and precision (l;m 4) = 1 . this clearly shows that
modelm3is underÔ¨Åtting.
generalization: avoid overÔ¨Åtting
modelm4simply encodes the event log and does not generalize. in general, a process
model should not restrict behavior to just the examples seen in the log. a model that
does not generalize is ‚ÄúoverÔ¨Åtting‚Äù. overÔ¨Åtting is the problem that a very speciÔ¨Åc
model is generated whereas it is obvious that the log only holds example behavior (i.e.,
the model explains the particular sample log, but it is unlikely that another sample log
of the same process can be explained well by the current model).
it is difÔ¨Åcult to reason about generalization because this refers to unseen examples.
however, we can use an approach similar to the one used for the quantiÔ¨Åcation of
precision. again we consider all points in the event log where event e2e is about
to happen. given an event ewe can Ô¨Ånd all events e0that occurred in the same state
in modelm. every event can be seen as an observation of an activity in some state s.
suppose that state sis visitedntimes and that wis the number of different activities
observed in this state. suppose that nis very large and wis very small, then it is
unlikely that a new event visiting this state will correspond to an activity not seen
before in this state. however, if nandware of the same order of magnitude, then it
is more likely that a new event visiting state swill correspond to an activity not seen
before in this state. using this idea we deÔ¨Åne generalization as follows:
generalization (l;m ) = 1 1
jejx
e2epnew (jdi(e)j;jsim(e)j)
pnew (w;n)is the estimated probability that a next visit to state s=statem(e)will
reveal a new path not seen before: w=jdi(e)jis the number of unique activities
observed leaving state sandn=jsim(e)jis the number of times swas visited by the
event log. we use an estimator inspired by [7]: pnew (w;n) =w(w+1)
n(n 1)ifnw+2and
pnew (w;n) = 1 otherwise. this estimate can be derived under the bayesian assump-
tion that there is an unknown number of possible activities in state sand that probability
11distribution over these activities follows a multinomial distribution. this results in the
posterior transition probability pnew (w;n)ifnw+ 2 [7]. fornw+ 1, the
bayesian analysis proposed in [7] does not provide a transition probability. in this case
there are too few repetitions to properly estimate the posterior transition probability.
forn=w+ 1,w(w+1)
n(n 1)= 1. forn=w,w(w+1)
n(n 1)>1(or undeÔ¨Åned). therefore, we
assume the transition probability to be 1 if nw+ 1. this is a reasonable assump-
tion (especially for larger n): if most observations are unique, it is likely that the next
observation will also be unique.
generalization (l;m )is close to 0 if it is very likely that new events will exhibit
behavior not seen before. generalization (l;m )is close to 1 if it is very unlikely that
the next event will reveal new behavior.
for our running example, generalization (l;m 1) = 1:0,generalization (l;m 2) =
1:0,generalization (l;m 3) = 1:0, and generalization (l;m 4) = 0:99. the high
values form1,m2, andm3correspond to the intuitive notion of generalization. the
next trace to be observed is likely to Ô¨Åt into these models. however, the value for
m4may be higher than expected. the reason is that generalization takes the aver-
age over all events, and most events occur (by deÔ¨Ånition) in the highly frequent traces.
for example, there are 455 process instances having a trace acdeh . for all interme-
diate states there is only one possible next activity ( w= 1) whereas these states are
visited 455 times ( n= 455 ). hence pnew (w;n) =1(1+1)
455(455 1)0for all events
having such a trace resulting in a very high precision value. the effect becomes clear
if we assume that each of the 21 possible traces occurs only once. let us call this log
ls. then generalization (ls;m 1) = 0:99349 ,generalization (ls;m 2) = 0:99524 ,
generalization (ls;m 3) = 0:99750 , and generalization (ls;m 4) = 0:11547 . for
this smaller log, it becomes clear that m4is indeed less general (i.e., more overÔ¨Åtting).
alternatively, we can also deÔ¨Åne the notion of generalization at the state level rather
than the event level:
generalizations(l;m ) = 1 1
jsjx
s2spnew (jdi(s)j;jsim(s)j)
now functions di andsim are deÔ¨Åned for states rather than events. for s2s:
sim(s) =fe2ej statem(e) =sge is the set of all events that happened in state
sanddi(s) =fact(e)je2sim(s)gamare the different activities that were
executed in state s. this metric will punish the parts of the model that are low-frequent
but overÔ¨Åtting much harder. hence, this metric results in an even lower generalization
value form4.
when evaluating a process discovery algorithm , one can also use an alternative ap-
proach. first, construct the model mfor the whole event log l. suppose thatjlj=k
and that the cases are numbered: 1;2;:::;k . createkevents logs by removing pre-
cisely one process instance: l1;l2;:::;lk. event log liislwithout the events
corresponding to case i. next, construct a model mifor each of the event logs li.
letlbe the number of models mithat can replay case isuccessfully. the fraction
l=kis an alternative metric for generalization. if l=kis close to 0, then the model is
12overÔ¨Åtting. if l=kis close to 1, the model is able to generalize well. also other forms
of cross validation (e.g., k-fold cross-validation) can be used to quantify the degree of
generalization.
simplicity: occam‚Äôs razor
the fourth quality dimension is related to occam‚Äôs razor which states that ‚Äúone should
not increase, beyond what is necessary, the number of entities required to explain any-
thing‚Äù. following this principle, we look for the ‚Äúsimplest process model‚Äù that can
explain what is observed in the event log. model m1in fig. 1 is simple compared to
m4. this makes m4a less suitable model.
there are various techniques to quantify model complexity. the complexity of the
model could be deÔ¨Åned by the number of nodes and arcs in the underlying graph. also
more sophisticated metrics can be used, e.g., metrics that take the ‚Äústructuredness‚Äù or
‚Äúentropy‚Äù of the model into account. a detailed discussion of these complexity metrics
is outside the scope of this article. we refer to [21] for pointers to over twenty metrics
described in literature.
performance analysis
after aligning event log and model, all kinds of analysis techniques based on ‚Äúreplay‚Äù
come into reach. these replay techniques may use additional attributes and are not
restricted to activity names. as mentioned earlier, events may have timestamps and
refer to resources, customers, organizational units, cost rates, etc. timestamps can be
used to compute Ô¨Çow times, waiting times, service times, synchronization times, etc.
consider two subsequent events e1ande2with act(e1) =a,act(e2) =b,time(e1) =
23-11-2011:15.56 , and time(e2) =23-11-2011:16.20 . ifbis causally de-
pendent on a, we record a time of 24 minutes in-between aandb. by repeatedly
measuring such time differences during replay, we can compute the average time that
elapses in-between aandb.
such detailed analysis is only possible after successfully aligning model and log. a
process model annotated with time information can be used to diagnose performance
problems. moreover, the learned temporal behavior can be used for predictions (‚Äúwhat
is the remaining Ô¨Çow time for this running case?‚Äù) and recommendations (‚Äúwhich
action minimizes the expected overall costs?‚Äù). see [1] for more details and concrete
examples.
related work
this article describes a collection of process mining algorithms aiming at conformance
checking and performance analysis. see [1] for an introduction to process mining. we
13refer to the recently released process mining manifesto [18] for the main challenges in
process mining.
cook et al. [9, 8] were among the Ô¨Årst to quantify the relationship between event logs
and process model. they compare event streams of the model with event steams gen-
erated from the event log.
several authors proposing process discovery algorithms also provide a quality metric
(often related to Ô¨Åtness). for example, in [20] the authors deÔ¨Åne a Ô¨Åtness function for
searching for the optimal model using a genetic approach. in [26] a ‚Äúprocess mining
evaluation framework‚Äù for benchmarking process discovery algorithms is proposed.
the Ô¨Årst comprehensive approach to conformance analysis was proposed in [25] by
rozinat and van der aalst. two different types of metrics are proposed: (a) Ô¨Åtness
metrics , i.e., the extent to which the log traces can be associated with valid execution
paths speciÔ¨Åed by the process model, and (b) appropriateness metrics , i.e., the degree
of accuracy in which the process model describes the observed behavior, combined
with the degree of clarity in which it is represented. fitness in [25] is measured by ‚Äúre-
playing the event log‚Äù and counting the number of missing and remaining tokens. this
typically results in rather high Ô¨Åtness values as also pointed out in [6, 28]. in [25] four
appropriateness metrics are deÔ¨Åned. simple behavioral appropriateness looks at the
average number of enabled transitions. if most transitions are continuously enabled,
the model is likely to lack precision (i.e., underÔ¨Åtting). advanced behavioral appropri-
ateness compares the ‚Äúfootprint‚Äù of the log (follows and precedes relationships) to the
‚Äúfootprint‚Äù of the model. simple structural appropriateness andadvanced structural
appropriateness quantify the complexity of the model. note that the appropriateness
metrics in [25] cover the simplicity, precision, and generalization dimensions discussed
in this article.
one of the drawbacks of the approach in [25] and most other approaches that ‚Äúplay
the token game‚Äù, is that Ô¨Åtness is typically overestimated. when a model and log do
not Ô¨Åt well together, replay will overload the process model with superÔ¨Çuous tokens.
as a result, the model will allow for too much behavior. approaches such as the
one in [25] also have problems when the model has ‚Äúinvisible activities‚Äù (silent steps
that are not recorded in the event log) or ‚Äúduplicate activities‚Äù (multiple transitions
bearing the same label). to deal with such phenomena state-space exploration and
heuristics are needed to replay the event log. in fact, most conformance techniques
give up after the Ô¨Årst non-Ô¨Åtting event or simply ‚Äúguess‚Äù the corresponding path in the
model. therefore, adriansyah et al. formulated conformance checking problems as an
optimization problem [6, 5]. this is the approach we also use in this article.
the lion‚Äôs share of attention in conformance checking has been devoted to checking
Ô¨Åtness. besides the four appropriateness notions in [25], munoz-gama et al. quantiÔ¨Åed
additional precision notions [22, 23, 24]. in this paper, we use an approach similar to
the one reported in [22]. unlike [23, 24], this approach is robust in case of non-Ô¨Åtting
traces.
it is difÔ¨Åcult to use classical quality notions such as precision andrecall for process
mining. the main reason is that event logs only contain positive examples, i.e., one
14can see what ‚Äúdid happen‚Äù but not what ‚Äúcould not happen‚Äù. therefore, some authors
suggest inserting artiÔ¨Åcially generated ‚Äúnegative events‚Äù [12, 29]. goedertier et al.
proposed such events for both process discovery and conformance checking [12]. de
weerdt et al. deÔ¨Åned a so-called f-measure based on artiÔ¨Åcially generated negative
events [29]. the authors of the latter paper also conducted a comparative analysis
of several conformance metrics [28]. however, their study did not consider the more
advanced alignment-based approaches discussed in this article.
in [15] a so-called completeness metric and soundness metric are deÔ¨Åned. these met-
rics compare the traces of the model with the traces in the log. this approach suffers
from several drawbacks. first of all, only complete traces are compared. second, it is
assumed that the model‚Äôs behavior can be enumerated. finally, it is assumed that the
log contains all possible traces.
in [11], the techniques presented in [6, 5] are generalized to artifact-centric processes
(the so-called proclets). the conformance notions in [11] also take interactions be-
tween process instances into account.
several approaches create so-called behavioral footprints to compare event log and
model [1]. the key idea is that a footprint can be based on observed behavior and
modeled behavior as described in [1]. another example of such a footprint is the so-
called ‚Äúbehavioral proÔ¨Åle‚Äù [30]. the problem of this approach is that it cannot handle
loops properly (unlike [1, 25]).
all techniques discussed thus far, compare model and log. there are also many com-
pliance approaches that compare a model and another model or a model and a set of
rules [10, 13, 14, 19]. these approaches are very different to the techniques discussed
in this paper as they do not take the actual observed behavior into account.
as indicated in this article, alignments can also be used for performance analysis as
most event logs contain timestamps [1]. replaying event logs with timestamps allows
for bottleneck analysis and prediction as demonstrated in [2, 3].
conclusion
process mining can be seen as the ‚Äúmissing link‚Äù between data mining and traditional
model-driven bpm. although process discovery received the lion‚Äôs share of attention,
the alignment between event log and model is at least as important. an alignment
makes it possible to replay the event log on the model. this can be used for perfor-
mance analysis and conformance checking. as demonstrated, it is possible to decou-
ple analysis and Ô¨Årst establish an optimal alignment before measuring conformance or
identifying bottlenecks.
many of the ideas presented in this article have been implemented in prom , an open-
source process mining platform offering a wide variety of techniques for process dis-
covery, conformance checking, and model enhancement [1, 27]. from a computational
point of view it is challenging to compute an optimal alignment [6, 5]. hence, future
15work should aim at more efÔ¨Åcient algorithms. moreover, it will be fruitful to explore
the full application potential of replay (beyond conformance checking and performance
analysis).
references
[1] w.m.p . van der aalst. process mining: discovery, conformance and enhance-
ment of business processes . springer-verlag, berlin, 2011.
[2] w.m.p . van der aalst, m. pesic, and m. song. beyond process mining: from
the past to present and future. in b. pernici, editor, advanced information
systems engineering, proceedings of the 22nd international conference on
advanced information systems engineering (caise‚Äô10) , volume 6051 of lec-
ture notes in computer science , pages 38‚Äì52. springer-verlag, berlin, 2010.
[3] w.m.p . van der aalst, m.h. schonenberg, and m. song. time prediction based
on process mining. information systems , 36(2):450‚Äì475, 2011.
[4] w.m.p . van der aalst, a.j.m.m. weijters, and l. maruster. workÔ¨Çow mining:
discovering process models from event logs. ieee transactions on knowl-
edge and data engineering , 16(9):1128‚Äì1142, 2004.
[5] a. adriansyah, b. van dongen, and w.m.p . van der aalst. conformance check-
ing using cost-based fitness analysis. in ieee international enterprise com-
puting conference (edoc 2011) . ieee computer society, 2011.
[6] a. adriansyah, b.f . van dongen, and w.m.p . van der aalst. towards robust
conformance checking. in m. zur muehlen and j. su, editors, bpm 2010 work-
shops, proceedings of the sixth workshop on business process intelligence
(bpi2010) , volume 66 of lecture notes in business information processing ,
pages 122‚Äì133. springer-verlag, berlin, 2011.
[7] c. boender and a. rinnooy kan. a bayesian analysis of the number of cells
of a multinomial distribution. the statistician , 32(1-2):240‚Äì248, 1983.
[8] j.e. cook, c. he, and c. ma. measuring behavioral correspondence to a
timed concurrent model. in proceedings of the 2001 international conference
on software mainenance , pages 332‚Äì341, 2001.
[9] j.e. cook and a.l. wolf. software process validation: quantitatively mea-
suring the correspondence of a process to a model. acm transactions on
software engineering and methodology , 8(2):147‚Äì176, 1999.
[10] a. elgammal, o. turetken, w. van den heuvel, and m. papazoglou. root-
cause analysis of design-time compliance violations on the basis of property
patterns. in p . maglio, m. weske, j. y ang, and m. fantinato, editors, proceed-
ings of service-oriented computing (icsoc 2010) , volume 6470 of lecture
notes in computer science , pages 17‚Äì31. springer-verlag, berlin, 2010.
16[11] d. fahland, m. de leoni, b.f . van dongen, and w.m.p . van der aalst. con-
formance checking of interacting processes with overlapping instances. in
s. rinderle, f . toumani, and k. wolf, editors, business process management
(bpm 2011) , volume 6896 of lecture notes in computer science , pages 345‚Äì
361. springer-verlag, berlin, 2011.
[12] s. goedertier, d. martens, j. vanthienen, and b. baesens. robust process
discovery with artiÔ¨Åcial negative events. journal of machine learning re-
search , 10:1305‚Äì1340, 2009.
[13] g. governatori, j. hoffmann, s. sadiq, and i. weber. detecting regulatory
compliance for business process models through semantic annotations. in
4th international workshop on business process design , 2008.
[14] g. governatori, z. milosevic, and s. sadiq. compliance checking between
business processes and business contracts. in 10th international enter-
prise distributed object computing conference (edoc 2006) , pages 221‚Äì232.
ieee computing society, 2006.
[15] g. greco, a. guzzo, l. pontieri, and d. sacc `a. discovering expressive pro-
cess models by clustering log traces. ieee transaction on knowledge and
data engineering , 18(8):1010‚Äì1027, 2006.
[16] d. hand, h. mannila, and p . smyth. principles of data mining . mit press,
cambridge, ma, 2001.
[17] a.h.m. ter hofstede, w.m.p . van der aalst, m. adams, and n. russell. modern
business process automation: yawl and its support environment . springer-
verlag, berlin, 2010.
[18] ieee task force on process mining. process mining manifesto. in bpm
workshops , volume 99 of lecture notes in business information processing .
springer-verlag, berlin, 2011.
[19] n. lohmann. compliance by design for artifact-centric business processes.
in s. rinderle, f . toumani, and k. wolf, editors, business process manage-
ment (bpm 2011) , volume 6896 of lecture notes in computer science , pages
99‚Äì115. springer-verlag, berlin, 2011.
[20] a.k. alves de medeiros, a.j.m.m. weijters, and w.m.p . van der aalst. genetic
process mining: an experimental evaluation. data mining and knowledge
discovery , 14(2):245‚Äì304, 2007.
[21] j. mendling, g. neumann, and w.m.p . van der aalst. understanding the
occurrence of errors in process models based on metrics. in f . curbera,
f . leymann, and m. weske, editors, proceedings of the otm conference
on cooperative information systems (coopis 2007) , volume 4803 of lecture
notes in computer science , pages 113‚Äì130. springer-verlag, berlin, 2007.
17[22] j. munoz-gama, a. adriansyah, j. carmona, b.f . van dongen, and w.m.p . van
der aalst. alignment based precision checking in process mining. eindhoven
university of technology, eindhoven, 2011.
[23] j. munoz-gama and j. carmona. a fresh look at precision in process con-
formance. in r. hull, j. mendling, and s. tai, editors, business process man-
agement (bpm 2010) , volume 6336 of lecture notes in computer science ,
pages 211‚Äì226. springer-verlag, berlin, 2010.
[24] j. munoz-gama and j. carmona. enhancing precision in process con-
formance: stability, conÔ¨Ådence and severity. in n. chawla, i. king, and
a. sperduti, editors, ieee symposium on computational intelligence and data
mining (cidm 2011) , paris, france, april 2011. ieee.
[25] a. rozinat and w.m.p . van der aalst. conformance checking of processes
based on monitoring real behavior. information systems , 33(1):64‚Äì95, 2008.
[26] a. rozinat, a.k. alves de medeiros, c.w. g ¬®unther, a.j.m.m. weijters, and
w.m.p . van der aalst. the need for a process mining evaluation framework in
research and practice. in a. ter hofstede, b. benatallah, and h.y . paik, edi-
tors, bpm 2007 international workshops (bpi, bpd, cbp , prohealth, refmod,
semantics4ws) , volume 4928 of lecture notes in computer science , pages
84‚Äì89. springer-verlag, berlin, 2008.
[27] h.m.w. verbeek, j.c.a.m. buijs, b.f . van dongen, and w.m.p . van der aalst.
prom 6: the process mining toolkit. in m. la rosa, editor, proc. of bpm
demonstration track 2010 , volume 615 of ceur workshop proceedings ,
pages 34‚Äì39, 2010.
[28] j. de weerdt, m. de backer, j. vanthienen, and b. baesens. a critical evalu-
ation of model-log metrics in process discovery. in m. zur muehlen and j. su,
editors, bpm 2010 workshops, proceedings of the sixth workshop on busi-
ness process intelligence (bpi2010) , volume 66 of lecture notes in business
information processing , pages 158‚Äì169. springer-verlag, berlin, 2011.
[29] j. de weerdt, m. de backer, j. vanthienen, and b. baesens. a robust f-
measure for evaluating discovered process models. in n. chawla, i. king,
and a. sperduti, editors, ieee symposium on computational intelligence and
data mining (cidm 2011) , pages 148‚Äì155, paris, france, april 2011. ieee.
[30] m. weidlich, a. polyvyanyy, n. desai, j. mendling, and m. weske. process
compliance measurement based on behavioral proÔ¨Åles. information systems ,
36(7):1009‚Äì1025, 2011.
[31] m. weske. business process management: concepts, languages, architec-
tures . springer-verlag, berlin, 2007.
18