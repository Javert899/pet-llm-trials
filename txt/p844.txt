exploiting process cubes, analytic workﬂows and
process mining for business process reporting: a case
study in education
alfredo bolt1, massimiliano de leoni1, wil m. p. van der aalst1, and
pierre gorissen2
1eindhoven university of technology, eindhoven, the netherlands
{a.bolt,m.d.leoni,w.m.p.v.d.aalst}@tue.nl
2hogeschool van arnhem en nijmegen, nijmegen, the netherlands
pierre.gorissen@han.nl
summary. business process intelligence (bpi) is an emerging topic that has
gained popularity in the last decade. it is driven by the need for analysis tech-
niques that allow businesses to understand and improve their processes. one of
the most common applications of bpi is reporting, which consists on the struc-
tured generation of information (i.e., reports) from raw data. in this article, state-
of-the-art process mining techniques are used to periodically produce automated
reports that relate the actual performance of students of eindhoven university of
technology to their studying behavior. to avoid the tedious manual repetition of
the same process mining procedure for each course, we have designed a work-
ﬂow calling various process mining techniques using rapidprom. to ensure that
the actual students’ behavior is related to their actual performance (i.e., grades
for courses), our analytic workﬂows approach leverages on process cubes, which
enable the dataset to be sliced anddiced based on courses and grades. the article
discusses how the approach has been operationalized and what is the structure
and concrete results of the reports that have been automatically generated. the
reports were sent to lecturers and feedback was collected through an evaluation
form. also, we analyzed an example report to show the range of insights that they
provide.
key words: business process reporting, analytic workﬂows, process mining, pro-
cess cubes, education.
1 introduction
business process reporting (bpr) refers to the provision of structured information
about processes in a regular basis, and its purpose is to support decision makers. re-
ports can be used to analyze and compare processes from many perspectives (e.g., per-
formance, costs, time). in education, for example, it is interesting to study student’s
grades in a course over different years, and how these grades are related to the students’
behavior. in order to be effective, bpr presents some challenges:
1. it should provide insights about the typical behavioral characteristics (e.g., through-
put time or resource utilization) and highlights the issues (e.g., bottlenecks).
332. it should be repeatable (i.e., not require great efforts to repeat the analysis).
3. it should be able to drill down into the process data and compare the different
groups and process variants to highlight dissimilarities.
this paper discusses how to address the three challenges mentioned above by combin-
ingprocess mining, analytic workﬂows andprocess cubes.
process mining is a relatively young research discipline that is concerned with dis-
covering, monitoring and improving real processes by extracting knowledge from event
logs readily available in today’s systems [1]. this allows the extraction of insights about
the overall and inner behavior contained in any given process. hundreds of different
process mining techniques have been proposed in literature. these are not limited to
process-model discovery and the checking of conformance. also, other perspectives
(e.g., data) and operational support (e.g., predictions) are included. process mining is
supported by commercial and academic software tools, such as disco and prom [2].1
when dozens of different reports need to be produced, it can be tedious and error-
prone to repeat all the process-mining analyses to be incorporated in the reports. process
mining tools such as prom are not designed to automatically repeat the application of
the same process-mining analyses on an arbitrary number of (sub sets of) event logs.
therefore, it is not possible to automatically generate any arbitrary number of reports.
here we combine process mining with analytic workﬂow systems, which allow one
to design, compose, execute, archive and share workﬂows that represent some type of
analysis or experiment. each activity/step of an analytic workﬂow is one of the steps
to conduct a non-trivial process-mining analysis, which can ange from data ﬁltering
and transformation to process discovery or conformance checking. once an analytic
workﬂow is conﬁgured, it can be executed as many times as needed without the recon-
ﬁguration. analytic workﬂows are specialization of scientiﬁc workﬂows tailored to-
wards analytic purposes. scientiﬁc workﬂows have successfully been applied in many
settings [3, 4]. bolt et al. [5] illustrate the formalization and operationalization of a
framework to support process-mining analytic workﬂows where the steps are linked to
the application of process-mining techniques.
business process reports are usually intended to provide a comparative analysis of
the differences observed in the different variants of process executions (e.g., executions
for gold versus silver customers). therefore, the data needs to be split into sub sets,
where the same analysis needs to be repeated for each set (e.g., the process discovery)
and the multiple results need to be compared (e.g., the discovered models need to be
compared for differences). process cubes [6, 7] are used to overcome this issue: in a
process cube, events are organized into cells using different dimensions. the idea is
related to the well-known notion of olap (online analytical processing) data cubes
and the associated operations, such as slice, dice, roll-up, and drill-down. by applying
the correct operations, each cell of the cube contains a sub-set of the event log that
complies with the homogeneity assumption mentioned above.
this paper shows through a case study how these three ingredients (process mining,
process cubes and analytic workﬂows) can be mixed for business process reporting.
the case study presented in this paper is about a business-process reporting service at
eindhoven university of technology (tu/e). the service produces a report each year
1prom tools is free to download from http://www.promtools.org
34for each course that is provided with video lectures. the report is sent to the responsible
lecture and provides insights about the relations between the use of students of the
video lectures and their ﬁnal grades on the course. the usefulness of the reports are
evaluated with dozens of lecturers. while the involved lecturers suggested a number
of improvements, they also clearly acknowledged the added value of those reports to
understand the usefulness of watching video lectures.
the remainder of this paper is organized as follows. section 2 provides an overview
of the case study and discusses the structure of the desired reports. sections 3 and 4
summarize the main concepts related to process cubes and analytic workﬂows and il-
lustrates how they are concretely applied in this case study. section 5 illustrates the
resulting report for one of the courses as well as it discusses the results of the evalua-
tion with the lecturers. finally, section 6 concludes the paper.
2 a case study in education
eindhoven university of technology (tu/e) provides video lectures for many courses
to support students who are unable to attend face-to-face lectures for various reasons.
student usage of video lectures and their course grades are logged by the tu/e systems.
the purpose of this case study is to show how raw data extracted from tu/e systems
can be transformed into reports that show insights about students’ video lecture usage
and its relation with course grades by using process mining, process cubes and analytic
workﬂows. figure 1 describes the overview of this case study.
the data used in this case study contains 246.526 video lecture views and110.056
course grades of8.122 students, 8.437 video lectures and 1.750 courses at tu/e for
the academic year 2014-2015. each student and course has a unique identiﬁer code
(i.e., student id, course code). the data reveals enormous variability; e.g., thousands of
students watch video lectures for thousands of courses and every course has a different
set of video lectures, and they have different cultural and study backgrounds, which
leads to different behavior. therefore, we need to provide different reports and, within
a report, we need to perform a comparative analysis of the students when varying the
grade.
before describing our approach and the ingredients used, we sketch the report we
aim for. the report is composed of three sections: course information, core statistics
andadvanced analytics, as shown in figure 1.2the analysis results refer to all students
who registered for the course exam, independently whether or not they participated in
it.
the course information section provides general information, such as the course
name, the academic year, the number of students, etc. the core statistics section pro-
vides aggregate information about the students, such as their gender, nationality, en-
rolled bachelor or master program, along with course grades distribution and video
2an example report, where student information has been anonymized, can be downloaded
from http://www.win.tue.nl/~abolt/userfiles/downloads/reports/
sample.zip
35fig. 1: overview of the case study: tu/e data is transformed into reports by using
process mining, process cubes and analytic workﬂows.
lecture views. the advanced analytics section contains more detailed diagnostics ob-
tained through process mining techniques. it is divided in three parts and leverages on
process mining techniques:
– the level of compliance wrt. the natural way of watching the video lectures, which
is watching all video lectures sequentially before participating in the exam. this is
achieved by integrating the process cube and the conformance-checking technique
presented in [8]. an example result is shown in figure 2a.
– dotted charts [9] highlighting the temporal distribution of video-lecture watching.
each row indicates a different student and the x axis is the time dimension. each
row contains a dot for each event referring to the respective student. the dot are dis-
tributed along the x axis according to the time when the event occurred. an example
chart is shown in figure 2b.
– process models that show the most frequent patterns and deviations of watching
video lectures by students. an example of a model that shows the most frequent
36fig. 2: examples of results obtained using process mining techniques: (a) conformance
checker, (b) dotted chart, (c) sequence analysis.
order followed by students to watch video lectures is shown in figure 2c. in these
models, edge thickness represents relative frequency. the edges that correspond to
the “natural” order are colored black. from the edges that do not correspond to the
“natural” order, only 10 edges are shown: those with the highest relative frequency.
in order to avoid confusion by the overlapping of the edges, we used different colors
for each of these edges.
the next two sections show how the desired reports can be generated using our
tools, followed by an evaluation of the approach.
3 process cubes as a means to select and compare
this section discusses the basic concepts of process cubes and illustrates how they have
been applied in the generation of the reports.
3.1 basic concepts
processes are not static within moderns organizations but their instances continuously
adapt to the dynamic context requirements of modern organizations. therefore, an event
37(a) slice and dice
(b) roll up and drill down
fig. 3: schematic examples of cube operations
log records executions of several process variants, whose behavior depends on the con-
text. as a consequence, the event log needs to be split to obtaining sub-logs, each of
which records the events pertaining a certain variant. this is commonly handled by
manually ﬁltering the event data. however, this approach is unpractical in scenarios if
many different process variations exist.
the process cubes approach [10, 6] provides the capabilities needed to perform
multidimensional analysis over event data so it can be split and events can be grouped
according to their data values. this allows one to isolate and analyze the different pro-
cess variations of a process given the available data.
process cubes are inspired by the idea of structuring and scoping the event data
through classical olap operations (i.e., slice, dice, roll up, drill down). however, be-
cause we are dealing with events we cannot use standard olap tools. see [10, 6] for
details.
a process cube is characterized by a set of dimensions, each of which is associated
with one or a group of event’s data properties. for each combination of values for
the different dimensions, a cell exists in the process cube. hence, each process-cube
cell contains the events that assign certain values to the data properties. each cell of
the process cube contains event data that can be used by process mining techniques
as illustrated by figure 2. please note that certain dimensions may be considered as
irrelevant and, therefore, they are ignored and are not visible in the cube. also, some
dimensions may be not readily available in the event data; however, they can be derived
from the existing dimensions. for example, the “year” and “day” dimensions can be
derived from the “timestamp” dimension.
theslice operation selects a subset of values of a dimension while removing that
dimension from the analysis. for example, if the “year” dimension is sliced for year =
{2012, 2013}, only the events in those years are retained. also, the “year” dimension
is removed from the cube as shown in figure 3a. the latter implies that cells with
different values for the “year” dimension and the same values for the other dimensions
are merged.
the dice operation is similar to the slice operation, with the difference that the
dicing dimension is retained. so, the dice operation is only removing cells without
38merging any cells: the dicing dimension can still be used for further exploration of the
event data, as shown in figure 3a.
theroll up anddrill down operations change the granularity level of a dimension.
as shown in figure 3b, if a dimension is rolled up, an attribute with a more coarse-
grained granularity will be used to create the cells of the cube, and if a dimension
is drilled down, an attribute with a more ﬁne-grained granularity will be conversely
used. for example, the “day” dimension can be rolled up to “month”, and the “month”
dimension can be drilled down to “day”.
3.2 application to the case study
for performing process cube operations over the tu/e data we used the process mining
cube (pmc) tool introduced in [6]. as mentioned before, the starting point is an event
data set. this set has been obtained by deﬁning and running opportune joins of tables of
the database underlying the video-lecture system of tu/e (see section 2). a fragment
of the event data set is shown in table 1.
table 1: a fragment of event data generated from tu/e system: each row corresponds
to an event.
event id student id nationality education code course code activity quartile academic year timestamp course grade ...
1 1025 dutch bis 2ii05 lecture 1 1 2014-2015 03/09/2012 12:05 6 ...
2 1025 dutch bis 2ii05 lecture 2 1 2014-2015 10/09/2012 23:15 6 ...
3 1025 dutch bis 1cv00 lecture 10 3 2014-2015 02/03/2012 15:36 7 ...
4 2220 spanish inf 1cv00 lecture 1 3 2014-2015 20/03/2013 16:24 8 ...
5 1025 dutch bis 2ii05 exam 2 2014-2015 13/12/2012 12:00 6 ...
6 2220 spanish inf 1cv00 lecture 4 3 2014-2015 25/03/2013 11:12 8 ...
7 2220 spanish inf 1cv00 exam 3 2014-2015 04/04/2013 12:00 8 ...
... ... ... ... ... ... ... ... ... ... ...
using the event data, we created a process cube with the following dimensions: stu-
dent id, student gender, student nationality, student education code, student educa-
tion phase, course code, course department, activity, activity type, grade, times-
tamp, quartile and academic year.
after slicing anddicing the cube, it contained 87.500 cells: one for each combina-
tion of values of the “course code”, “quartile” and “course grade” dimensions. each
cell corresponds to an event log that can be analyzed using process mining techniques.
4 analytic workﬂows as a means to automate analysis
process mining experiments usually require analysts to perform many analysis steps in
a speciﬁc order. as mentioned in section 1, it is not unusual that the same experiment
has to be carried out multiple times. this is normally handled by manually executing
the analysis steps of the experiment, thus requiring large periods of time and resources
and introducing the risk of human-induced errors.
analytic workﬂows can be used to address this problem. they are deﬁned by chain-
ing analysis and data-processing steps, each of which consumes input produced by pre-
vious steps and generates output for the next steps. the analytic workﬂows can be
39(a) advanced analytics section sub-workﬂow
(b) explosion of the “sequence models” sub-workﬂow
fig. 4: implemented analytic workﬂow used to generate the reports. each instance of a
course can be autimatically analyzed in this way resulting in the report described.
applied to any situation where the same analysis needs to be repeated again and again.
the application of analytic workﬂows to process mining analysis is discussed in [5].
for automatically generating the reports we used rapidprom [11, 5], which extends
the rapidminer analytic workﬂow tool with process mining techniques.3
figure 4a illustrates the analytic workﬂow that is used to generate each report. fig-
ure 4b shows the explosion of the “sequence models” section of the analytic workﬂow.
the operators shown in figure 4 are used for different purposes: multipliers allow
one to use the output of an operator as input for many operators. filter operators select a
subset of events based on deﬁned criteria. process mining operators are used to produce
3free version and installation instructions for rapidminer and the rapidprom extension are
available at http://www.rapidprom.org or at the rapidminer marketplace.
40analysis results. for example, the operators highlighted in blue in figure 4b produce a
sequence model from each ﬁltered event data.
the complete rapidprom implementation of the analytic workﬂow used in this
case study is available at http://www.win.tue.nl/~abolt/userfiles/
downloads/reports/report.rmp. readers can execute this workﬂow in rapid-
miner to generate a report using the sample event log available at http://www.win.
tue.nl/~abolt/userfiles/downloads/reports/sample.xes.4
5 evaluation
we applied our approach that combines analytic workﬂows and process cubes to the
case study presented in section 2. concretely, we generated 8.750 course reports for
1750 courses given at tu/e in each of the 5 quartiles (i.e., 4 normal quartiles + in-
terim quartile) of the academic year 2014-2015. for reliability of our analysis, we only
considered those courses where, on average, each student watched at least 3 video lec-
tures. in total, 89 courses were selected. for each one of these courses, an automatically
generated report was sent to the corresponding lecturer.
section 5.1 provides a detailed analysis of the ﬁndings that we could extract from
the report for a particular course. along with the report, we also sent an evaluation form
to the lecturers. the purpose of the evaluation forms is to verify whether lecturers were
able to correctly interpret the analysis contained in the report. the results are discussed
in section 5.2.
5.1 report for an example course
to illustrate the contents and value of the report, we selected an example course: “intro-
duction to modeling - from problems to numbers and back” given in the third quartile
of the academic year 2014-2015 by the innovation sciences department at tu/e. this
course is compulsory for all ﬁrst-year students from all programs at tu/e. in total,
1621 students attended this course in the period considered. this course is developed
in a “ﬂipped classroom” setting, where students watch online lectures containing the
course topics and related contents, and in the classroom, they engage these topics in
practical settings with the guidance of the instructor.
the video lectures provided for this course are mapped onto weeks (1 to 7). within
each week, video lectures are numbered to indicate the order in which students should
watch them (i.e., 1.1 correspond to the ﬁrst video lecture of the ﬁrst week). as indicated
by the course’s lecturer, the ﬁrst video lectures of each week contain the course topics
for that week, and the last video lectures of each week contain complementary mate-
rial (e.g., workshops, tutorials). the number of video lectures provided for each week
depends on the week’s topics and related activities, hence, it varies.
4when running the workﬂow, make sure that the read file operator points to the sample event
log and the "html output directory" parameter of the generate report operator points to the
desired output folder.
41fig. 5: analysis results contained in the report of the course 0leb0:
(a) number of students that watched each video lecture
(b) compliance with the natural viewing order by course grade
(c) grades distribution for students who watched video lectures (in red) or did
not (in blue)
figure 5.a shows for each video lecture the number of students that watched it. we
can observe that the number of students that watch the video lectures decreases as the
course develops: most students watched the video lectures corresponding to the ﬁrst
week (i.e., 1.x) but less than half of them watched the video lectures corresponding
to the last week (i.e., 7.x). note that within each week, students tend to watch the ﬁrst
video lectures (i.e., x.1, x.2) more than the last ones (i.e., x.5, x.6). this was discussed
with the course’s lecturer. it is explained by the fact that, as mentioned before, the ﬁrst
video lectures of each week contain the topics, and the last ones contain complementary
material.
figure 5.b shows for each student group (i.e., grouped by their grade) the level of
compliance, averaged over all students in that group, of the real order in which stu-
dents watch video lectures, compared with the “natural” or logical order, namely with
watching them in sequence (i.e., from 1.1 to 7.4). the compliance level of each student
is measured on a scale from 0 to 1, where 1 indicates that the student has watched all
video lectures in the logical order and 0 indicates that no video lectures were viewed in
42(a) grade = 5 (failed)
 (b) grade = 6 or 7 (passed)
fig. 6: dotted charts for students grouped by their course grades
the logical order or, even, not watched at all. we can observe that students with higher
grades have higher levels of compliance than students with lower grades.
figure 5.c shows the grade distribution for this course where each bar is composed
by two parts corresponding to the number of students who watched at least one (red
part) video lecture and the number of students who did not (blue part). we can observe
that the best students (i.e., with a grade of 8 or above) use video lectures. on the other
hand, we observe that watching video lectures does not guarantee that the student will
pass the course, as shown in the columns of students that failed the course (i.e. grade
5).
figure 6 shows dotted chart analysis described in section 2 for two student groups:
(a) students that failed the course with a grade of 5, and (b) students that passed the
course with a grade of 6 or 7. each row corresponds to a student and each dot in a
row represents that student watching a video lecture or taking the exam. note that both
charts show a gap where very few video lectures were watched, which is highlighted
in the pictures through an oval. this gap coincides with the dutch carnaval holidays.
we can observe that, in general, students that failed watched fewer video lectures. also
note that in fig. 6.a the density of events heavily decreases after the mid-term exam
(highlighted through a vertical dashed line). this could be explained by students being
discouraged after a bad mid-term result. this phenomenon is also present in (b), but not
equally evident. we can also observe that most students tend to constantly use video
lectures. this is conﬁrmed by the low number of students with only a few associated
events.
figure 7 shows sequence analysis models that, given any ordered sequence of ac-
tivities, reﬂects the frequency of directly-follows relations5as percentage annotations
5the frequency of directly-follows relations is deﬁned for any pair of activities (a; b )as the
ratio between the number of times that bis directly executed after aand the total number of
times that ais executed.
43(a) grade = 6 or 7
 (b) grade = 8 or 9
fig. 7: sequence analysis for students grouped by their course grades
and as the thickness of edges. the highest deviations from the ordered sequence or-
der are highlighted in colored edges (i.e., black edges correspond to the natural order).
this technique was tailored for the generation of reports and it is implemented using a
customized rapidprom extension. when comparing (a) students that passed the course
with a grade of 6 or 7 with (b) students that had a grade of 8 or 9, we can observe
that both groups tend to make roughly the same deviations. most of these deviations
correspond to speciﬁc video lectures being skipped. these skipped video lectures cor-
respond in most cases to complementary material. in general, one can observe that the
thickness (i.e., frequency) of the arcs denoting the “natural” order (i.e., black arcs) is
higher for (b), i.e., those with higher grades. note that at the beginning of each week we
can observe a recovery effect (i.e., the frequencies of the natural order tend to increase).
5.2 summarized report feedback
in addition to the qualitative analysis for some courses like such as the course analyzed
in section 5.1, we have also asked lecturers for feedback through an evaluation form
linked to each report.6the evaluation form provided 30 statements about the analysis
contained in the reports (e.g., “higher grades are associated with a higher proportion of
students watching video lectures”, “video lecture views are evenly distributed through-
out the course period”). lecturers evaluated each statement on the basis of the con-
6the evaluation form is available at http://www.win.tue.nl/~abolt/userfiles/
downloads/reports/form.pdf
44table 2: summary of the classiﬁcation of statement evaluations performed by lecturers
statement core statistics advanced analytics sectionsub total total (%)evaluation section compliance temp. dist. seq. analysis
correct 261 30 67 32 390(89%)61%incorrect 28 5 8 6 47(11%)
unknown 95 61 69 58 283 39%
clusions that they could draw from the report. for each of the 30 statements, lecturers
could decide if they agreed or disagreed with the statement, or, alternatively, indicate
that they could not evaluate the statement (i.e., “i don’t know”).
in total, 24 of the 89 lecturers answered the evaluation form. out of the 720 (24
x 30) possible statement evaluations, 437 statements were answered with “agree” or
“disagree”. the remaining cases in which the statement could not be evaluated can be
explained by three possible causes: the statement is unclear, the analysis is not under-
standable, or the data shows no conclusive evidence.
in the case that a statement was evaluated with “agree” or “disagree”, we compared
the provided evaluation with our own interpretation of the same statement for that report
and classiﬁed the response as correct orincorrect. in the case that a statement was not
evaluated, the respose was classiﬁed as unknown.
table 2 shows a summary of the response classiﬁcation for each section of the re-
port. in total, 89% of the statement evaluations were classiﬁed as correct. this indi-
cates that lecturers were capable to correctly interpret the analysis provided in the re-
ports. note that the compliance section had the highest rate of unknown classiﬁcations
(63.5%). this could be related to understandability issues of the analysis presented in
that section.
the evaluation form also contained a few general questions. one of such questions
was: “do you think this report satisﬁes its purpose, which is to provide insights about
student behavior?”, for which 7 lecturers answered “yes”, 4 lecturers answered “no”
and 13 lecturers answered “partially”. all the lecturers that responded “partially” pro-
vided written feedback indicating the improvements they would like to see in the report.
some of the related comments received were: “it would be very interesting to know if
students: a) did not attend the lectures and did not watch the video lectures, b) did
not attend the lectures, but did watch the video lectures instead, c) did attend the lec-
tures and watch the video lectures too. this related to their grades”, “the report itself
gives too few insights/hides insights”, “it is nice to see how many students use the video
lectures. that information is ﬁne for me and all i need to know”, and “i would appre-
ciate a written explanation together with your diagrams, next time”. another question
in the evaluation form was: “do you plan to introduce changes in the course’s video
lectures based on the insights provided by this report?”, for which 4 lecturers answered
“yes” and 20 answered “no”. the results show that the analysis is generally perceived
as useful, but that more actionable information is needed, such as face-to-face lecture
attendance. however, this information is currently not being recorded by the tu/e. the
feedback provided by lecturers will be used to improve the report. this has only been
made possible by process mining with process cubes and analytic workﬂows
456 conclusion
this paper has illustrated the beneﬁts of combining the complementary approaches of
process cubes and analytic workﬂows in the ﬁeld of process mining. in particular, the
combination is beneﬁcial when process mining techniques need to be applied on large,
heterogenous event data of multidimensional nature.
to demonstrate such beneﬁts, we applied the combined approach in a large scale
case study where we provide reports for lecturers. these reports correlate the grades of
students with their behavior while watching the available video lectures. unlike existing
learning analytics approaches, we focus on dynamic student behavior. also, descrip-
tive analytics would not achieve similar analysis results because they do not consider
the process perspective, such as the ordering of watching video lectures.
educational data has been analyzed by some disciplines in order to understand and
improve the learning processes [12, 13, 14, 15, 16], even employing process cubes [17].
however, these analyses were mostly focused on individual courses. no research work
has previously been conducted to allow large-scale process mining analysis where re-
ports are automatically generated for any number of courses. our approach has made
it possible by integrating process mining with analytic workﬂows, which have been de-
vised for large-scale analysis, and process cubes, which provide the capabilities needed
to perform comparative analyses.
the report will be enhanced in order to incorporate the feedback obtained from
lecturers through the evaluation and from now on they will be sent periodically four
times per year (i.e., after each quartile a report is automatically generated for each
course given).
the report generation will also be extended to massive open online courses
(moocs) given by the tu/e. this type of courses are particularly interesting due to
the fact that face-to-face lectures are not used: video lectures are the main channel used
by students for accessing the course topics. for example, over 100.000 people from all
over the world registered for the two executions of the mooc process mining: data
science in action.7we also plan to apply this analysis to the courses provided by the
european data science academy (edsa).8
references
1. van der aalst, w.m.p.: process mining: discovery, conformance and enhancement of busi-
ness processes. 1st edn. springer-verlag berlin heidelberg (2011)
2. van dongen, b.f., de medeiros, a.k.a., verbeek, h.m.w., weijters, a.j.m.m., van der
aalst, w.m.p.: the prom framework: a new era in process mining tool support. in: ap-
plications and theory of petri nets. v olume 3536 of lecture notes in computer science.
springer berlin heidelberg (2005) 444–454
3. jaeger, e., altintas, i., zhang, j., ludäscher, b., pennington, d., michener, w.: a scientiﬁc
workﬂow approach to distributed geospatial data processing using web services. in: proceed-
ings of the 17th international conference on scientiﬁc and statistical database management
(ssdbm’2005), berkeley, ca, us, lawrence berkeley laboratory (2005) 87–90
7http://www.coursera.org/course/procmin
8http://edsa-project.eu
464. turner, k., lambert, p.: workﬂows for quantitative data analysis in the social sciences.
international journal on software tools for technology transfer 17(3) (2015) 321–338
5. bolt, a., de leoni, m., van der aalst, w.m.p.: scientiﬁc workﬂows for process mining:
building blocks, scenarios, and implementation. international journal on software tools for
technology transfer (2015) . to appear. doi: 10.1007/s10009–015–0399–5
6. bolt, a., van der aalst, w.m.p.: multidimensional process mining using process cubes. in:
enterprise, business-process and information systems modeling. v olume 214 of lecture
notes in business information processing. springer international publishing (2015) 102–
116
7. cordes, c., v ogelgesang, t., appelrath, h.j.: a generic approach for calculating and visual-
izing differences between process models in multidimensional process mining. in: business
process management workshops. v olume 202 of lecture notes in business information
processing. springer international publishing (2015) 383–394
8. van der aalst, w.m.p., adriansyah, a., van dongen, b.f.: replaying history on process mod-
els for conformance checking and performance analysis. wiley interdisciplinary reviews:
data mining and knowledge discovery 2(2) (2012) 182–192
9. song, m., van der aalst, w.m.p.: supporting process mining by showing events at a glance.
in: proceedings of the 17th annual workshop on information technologies and systems
(wits). (2007) 139–145
10. van der aalst, w.m.p.: process cubes: slicing, dicing, rolling up and drilling down event data
for process mining. in: proceedings of the first asia paciﬁc conference on business process
management. v olume 159 of lecture notes in business information processing., springer
international publishing (2013) 1–22
11. mans, r.s., van der aalst, w.m.p., verbeek, h.m.w.: supporting process mining workﬂows
with rapidprom. in: proceedings of the bpm demo sessions 2014 co-located with the 12th
international conference on business process management (bpm). v olume 1295 of ceur
workshop proceedings., ceur-ws.org (2014) 56–60
12. siemens, g.: learning analytics: the emergence of a discipline. american behavioral
scientist 57(10) (2013) 1380–1400
13. siemens, g., baker, r.s.j.d.: learning analytics and educational data mining: towards com-
munication and collaboration. in: proceedings of the 2nd international conference on learn-
ing analytics and knowledge. lak ’12, new york, ny , usa, acm (2012) 252–254
14. romero, c., ventura, s.: educational data mining: a review of the state of the art. ieee
transactions on systems, man, and cybernetics (part c: applications and reviews) 40(6)
(nov 2010) 601–618
15. romero, c., ventura, s., pechenizkiy, m., baker, r.: handbook of educational data mining.
chapman & hall/crc data mining and knowledge discovery series. crc press (2010)
16. gorissen, p.j.b.: facilitating the use of recorded lectures: analysing students’ interactions to
understand their navigational needs. phd thesis, eindhoven university of technology (2013)
17. van der aalst, w.m.p., guo, s., gorissen, p.j.b.: comparative process mining in education:
an approach based on process cubes. in: proceedings of the 4th international symposium
on data-driven process discovery and analysis. v olume 203 of lecture notes in business
information processing., springer berlin heidelberg (2015) 110–134
47