workow simulation for operational decision
support using design, historic and state
information
a. rozinat1, m. t. wynn2, w. m. p. van der aalst1;2, a. h. m. ter hofstede2,
and c. j. fidge2
1information systems group, eindhoven university of technology,
p.o. box 513, nl-5600 mb, eindhoven, the netherlands.
fa.rozinat,w.m.p.v.d.aalst g@tue.nl
2business process management group, queensland university of technology,
gpo box 2434, brisbane qld 4001, australia.
fm.wynn,a.terhofstede,c.fidge g@qut.edu.au
abstract. simulation is widely used as a tool for analyzing business
processes but is mostly focused on examining rather abstract steady-state
situations. such analyses are helpful for the initial design of a business
process but are less suitable for operational decision making and contin-
uous improvement. here we describe a simulation system for operational
decision support in the context of workow management. to do this we
exploit not only the workow's design , but also logged data describing
the system's observed historic behavior, and information extracted about
the current state of the workow. making use of actual data capturing
the current state and historic information allows our simulations to ac-
curately predict potential near-future behaviors for dierent scenarios.
the approach is supported by a practical toolset which combines and ex-
tends the workow management system yawl and the process mining
framework prom.
keywords : workow management, process mining, short-term simulation.
1 introduction
business process simulation is a powerful tool for process analysis and improve-
ment. one of the main challenges is to create simulation models that accurately
reect the real-world process of interest. moreover, we do not want to use simu-
lation just for answering strategic questions but also for tactical and even oper-
ational decision making. to achieve this, dierent sources of simulation-relevant
information need to be leveraged. in this paper, we present a new way of creating
a simulation model for a business process supported by a workow management
system, in which we integrate design, historic, and state information.
figure 1 illustrates our approach. we consider the setting of a workow
system that supports some real-world process based on a workow and orga-
nizational model . note that the workow and organizational models have beenworkflow & 
organizational
modelevent
logs
workflow
system
recordssupports /
controls
current state informationmodels
simulation
modelspecifies 
configures
simulation 
logs
simulationengine
recordssimulates
models
historic informationdesign information
analyzesimulated process real-world process
specifies 
configuresfig. 1. overview of our integrated workow management (right) and simulation (left)
system
designed before enactment and are used for the conguration of the workow sys-
tem. during the enactment of the process, the performed activities are recorded
inevent logs . an event log records events related to the oering, start, and
completion of work items, e.g., an event may be `mary completes the approval
activity for insurance claim xy160598 at 16.05 on monday 21-1-2008'.
the right-hand side of figure 1 is concerned with enactment using a workow
system while the left-hand side focuses on analysis using simulation. in order to
link enactment and simulation we propose to use three types of information read-
ily available in workow systems to create and initialize the simulation model.
{design information. the workow system has been congured based on an
explicit process model describing control and data ows. moreover, the work-
ow system uses organizational data, e.g., information about users, roles,
groups, etc.
{historic information. the workow system records all events that take place
in `event logs' from which the complete history of the process can be recon-
structed. by analyzing historic data, probability distributions for workow
events and their timing can be extracted.
{state information. at any point in time, the workow process is in a partic-
ular state. the current state of each process instance is known and can be
used to initialize the simulation model. note that this current state informa-
tion includes the control-ow state (i.e., `tokens' in the process model), case
data, and resource data (e.g., resource availability).
by merging the above information into a simulation model, it is possible to
construct an accurate model based on observed behavior rather than a manually-
2constructed model which approximates the workow's anticipated behavior. more-
over, the state information supports a `fast forward' capability, in which simula-
tion can be used to explore dierent scenarios with respect to their eect in the
near future . in this way, simulation can be used for operational decision making .
based on this approach, the system design in figure 1 allows dierent simu-
lation experiments to be conducted. for the `as-is' situation, the simulated and
real-world processes should overlap as much as possible, i.e., the two process
`clouds' in figure 1 coincide. for the `to-be' situation, the observed dierences
between the simulated and real-world processes can be explored and quantied.
in our implementation we ensure that the simulation logs have the same format
as the event logs recorded by the workow system. in this way we can use the
same tools to analyze both simulated and real-world processes.
to do this, we need state-of-the art process mining techniques to analyze the
simulation and event logs and to generate the simulation model. to demonstrate
the applicability of our approach, we have implemented the system shown in fig-
ure 1 using prom [1] and yawl [2]. yawl is used as the workow management
system and has been extended to provide high-quality design, historic, and state
information. the process mining framework prom has been extended to merge
the three types of information into a single simulation model. moreover, prom
is also used to analyze and compare the logs in various ways.
the paper is organized as follows. related work is reviewed in section 2.
section 3 describes the approach proposed. section 4 presents a running example,
which is then used in section 5 to explain the implementation realized using
yawl and prom. section 6 concludes the paper by discussing the three main
innovations presented in this paper.
2 related work
our work combines aspects of workow management, simulation, and process
mining. some of the most relevant contributions from these broad areas are
reviewed below.
prominent literature on workow management [6, 13, 19] focuses on enact-
ment, and research on workow analysis usually focuses on verication, rather
than simulation. conversely, publications on simulation typically concentrate on
statistical aspects [11, 16, 12] or on a specic simulation language [10]. several
authors have used simulation or queuing techniques to address business process
redesign questions [4, 5, 14], and most mature workow management systems
provide a simulation component [7, 8]. however, none of these systems uses his-
toric and state information to learn from the past and to enable operational
decision making. we are not aware of any toolset that is able to extract the
current state from an operational workow management system and use this as
the starting point for transient analysis.
in earlier work we rst introduced the notion of using historic and state in-
formation to construct and calibrate simulation models [15, 20], and used protos,
exspect, and cosa to realize the concept of short-term simulation [15]. how-
3ever, this research did not produce a practical publicly available implementation
and did not use process mining techniques.
process mining aims at the analysis of event logs [3]. it is typically used to
construct a static model that is presented to the user to reect on the process.
previously we showed that process mining can be used to generate simulation
models [17], but design and state information were not used in that work.
3 approach
a crucial element of the approach in figure 1 is that the design ,historic and
state information provided by the workow system are used as the basis for
simulation. table 1 describes this information in more detail.
table 1. process characteristics and the data sources from which they are obtained
design information historic information state information
(obtained from the workow
and organization model
used to congure the
workow system)(extracted from event logs
containing information on
the actual execution of
cases)(based on information
about cases currently being
enacted using the workow
system)
control and data ow
(activities and causalities)data value range
distributionsprogress state of cases
(state markers)
organizational model
(roles, resources, etc.)execution time
distributionsdata values for running
cases
initial data values case arrival rate busy resources
roles per task availability patterns of
resourcesrun times for cases
the design information is static, i.e., this is the specication of the process
and supporting organization that is provided at design time. this information
is used to create the structure of the simulation model. the historic and state
information are dynamic, i.e., each event adds to the history of the process
and changes the current state. historic information is aggregated and is used
to set parameters in the simulation model. for instance, the arrival rate and
processing times are derived by aggregating historic data, e.g., the (weighted)
average over the last 100 cases is used to t a probability distribution. typically,
these simulation parameters are not very sensitive to individual changes. for
example, the average processing time typically changes only gradually over a
long period. the current state, however, is highly sensitive to change. individual
events directly inuence the current state and must be directly incorporated into
the initial state of the simulation. therefore, design information can be treated
as static, while historic information evolves gradually, and state information is
highly dynamic.
to realize the approach illustrated in figure 1 we need to merge design,
historic and state information into a single simulation model. the design infor-
4mation is used to construct the structure of the simulation model. the historic
information is used to set parameters of the model (e.g., t distributions). the
state information is used to initialize the simulation model. following this, tradi-
tional simulation techniques can be used. for example, using a random generator
and replication, an arbitrary number of independent simulation experiments can
be conducted. then statistical methods can be employed to estimate dierent
performance indicators and compute condence intervals for these estimates.
by modifying the simulation model, various `what-if' scenarios can be investi-
gated. for example, one can add or remove resources, skip activities, etc. and see
what the eect is. because the simulation experiments for these scenarios start
from the current state of the actual system, they provide a kind of `fast-forward
button' showing what will happen in the near future, to support operational de-
cision making. for instance, based on the predicted system behavior, a manager
may decide to hire more personnel or stop accepting new cases.
importantly, the simulations yield simulation logs in the same format as the
event logs. this allows process mining techniques to be used to view the real-
world processes and the simulated processes in a unied way. moreover, both
can be compared to highlight deviations, etc.
4 running example
consider the credit card application process expressed as a yawl workow
model in figure 2. the process starts when an applicant submits an application.
upon receiving an application, a credit clerk checks whether it is complete. if
not, the clerk requests additional information and waits until this information is
received before proceeding. for a complete application, the clerk performs further
checks to validate the applicant's income and credit history. dierent checks are
performed depending on whether the requested loan is large (e.g. greater than
$500) or small. the validated application is then passed on to a manager to
decide whether to accept or reject the application. in the case of acceptance, the
applicant is notied of the decision and a credit card is produced and delivered to
the applicant. for a rejected application, the applicant is notied of the decision
and the process ends.
fig. 2. a credit application process modeled in yawl
5here we assume that this example workow has been running for a while. in
yawl but also any other workow system the following runtime statistics can
be gathered about the long-term behavior of this process.
{ case arrival rate: 100 applications per week
{ throughput time: 4 working days on average
with respect to resources, there are eight members of sta available, which
include three capable of acting as `managers' and seven capable of acting as
`clerks'. (one person can have more than one role.)
further assume that due to a successful christmas promotion advertised in
november, the number of credit card applications per week has temporarily
doubled to 200. the promotion period is now over and we expect the rate to
decrease to 100 applications per week again. however, as a result of the increased
interest, the system now has a backlog of 150 applications in various stages of
processing, some of which have been in the system for more than a week. since
it is essential that most applications are processed before the holiday season,
which begins in a fortnight from now (the `time horizon' of interest), manage-
ment would like to perform simulation experiments from the current state (`fast
forward') to determine whether or not the backlog can be cleared in time.
5 realization through yawl and prom
we now use the example introduced in section 4 to describe our proof-of-concept
implementation supporting the approach depicted in figure 1. the realization
is based on the yawl workow environment [2] and the process mining frame-
work prom [1]. we focus on the new capabilities that have been added to these
systems, and briey explain the main steps that need to be performed3.
5.1 extracting simulation-relevant information
the information contained in the workow specication is supplemented with
historical data obtained from the event logs and data from the organizational
model database. this was achieved by implementing two new functions in the
workow engine to export historical data from the logs for a particular speci-
cation and to export the organizational model (i.e., information about roles and
resources).
in the yawl workow system, event logs are created whenever an activity
is enabled, started, completed or cancelled, together with the time when this
event occurred and with the actor who was involved. logs are also kept for data
values that have been entered and used throughout the system. therefore, we
can retrieve historical data about process instances that have nished execution.
3a detailed description of how to generate a simulation model including operational
decision support is provided in our technical report [18]. the example les and the
prom framework can be downloaded from http://www.processmining.org.
6in this work we assume that the simulation experiments are being carried out on
`as-is' process models for which historical data is available. a function has been
created which extracts the historical data for a specication from the workow
engine and exports audit trail entries in the mining xml (mxml) log format.
some sample data for the credit application example is shown in figure 3(a).
this historical data is used for mining information about case arrival rates and
distribution functions for the data values used in future simulation experiments.
<process>
       <processinstance id="5">              <audittrailentry>                  <data>
                      <attribute name="loanamt">550</attribute>
                  </data>                  <workflowmodelelement>
              receive_application_3
                  </workflowmodelelement>                  <eventtype>complete</eventtype>                  <timestamp>
              2008-02-29t15:20:01.050+01:00
                  </timestamp>                  <originator>moew</originator>
              </audittrailentry>
...
       </processinstance>
...
</process>
(a) a log entry for the completion of ac-
tivity `receive application' carried out by
resource moew with loan amount $550
<orgmodel>       
       <orgentity>      <entityid>1</entityid>       <entityname>manager</entityname> 
      <entitytype>role</entitytype> 
       </orgentity>       <orgentity>      <entityid>2</entityid>       <entityname>clerk</entityname>       <entitytype>role</entitytype>        </orgentity>    ...       <resource>    <resourceid>pa-529f00b8-0339</resourceid> 
      <resourcename>jonesa</resourcename> 
      <hasentity>2</hasentity>        </resource>
...
</orgmodel>(b) an excerpt from an organizational
model with roles and resources, where re-
source jonesa has role `clerk'
fig. 3. part of an organizational model and historical data extracted from the workow
engine
similarly, the yawl workow system gives access to the organizational
model through a function which extracts all available role and resource data
in an organization and exports this information in the xml format required
by prom. some sample data with the roles of clerk and manager are shown in
figure 3(b). this information is used to identify available roles and resources
that are relevant for a given specication.
5.2 generating the simulation model
from the (1) extracted workow specication, (2) the newly extracted organi-
zational model, and (3) the event log le, we can now generate a simulation
model that reects the process as it is currently enacted. the direct usage of
design information avoids mistakes that are likely to be introduced when models
are constructed manually, and the automated extraction of data from event logs
allows the calibration of the model based on actually observed parameters.
to generate the model, four basic steps need to be performed within prom
(a sample screenshot is shown for each phase in figures 4 and 5):
71. the yawl model, the organizational model, and the event log need to be
imported from yawl and analyzed.
2. simulation-relevant information from the organizational model and log anal-
ysis needs to be integrated into the yawl model.
3. the integrated yawl model must be converted into a petri net model (be-
cause our simulation tool is based on coloured petri nets).
4. finally, the integrated and converted model can be exported as a coloured
petri net (cpn) model for simulation.
(a) data is imported from dierent sources. here the organizational model
import is shown
(b) the organizational model and the information obtained from the log
analysis are integrated into the imported yawl model
fig. 4. phase 1 : the workow and organizational model are imported and integrated
with the information obtained from event log analysis
8(a) the integrated yawl model is translated into a petri net while pre-
serving all the simulation-relevant information
(b) after importing, merging, and converting the data, a simulation model
including current state support can be generated
fig. 5. phase 2 : to enable the export to cpn tools, the yawl model is rst converted
into a petri net. then, a cpn model of the process is generated
we can then use the cpn tools system [9] to simulate the generated model.
however, to produce useful results we do not want to start from an empty initial
state. instead we load the current state of the actual yawl system into the
cpn tools for simulation.
5.3 loading the current state
to carry out simulation experiments for operational decision making purposes
(the `fast forward' approach), it is essential to include the current state of the
9workow system. this allows us to make use of the data values for the current
cases as well as the status of the work items for current cases within the sim-
ulation experiments. a new function has been created to extract current state
information of a running workow from the yawl system and to export this
information as a cpn tools input le (see figure 6).
fun getinitialcasedata() = [(41, {loanamt = 1500,completeapp = false,decideapp = false}),
(40, {loanamt = 0,completeapp = false,decideapp = false}),
(39, {loanamt = 500,completeapp = false,decideapp = false})];
fun getnextcaseid() = 42;fun getinitialtokensexeplace(pname:string) = case pname of 
"task_check_for_completeness_4`e"=>[(41,"-154","jonesa")] | _ => empty;
fun getinitialtokens(pname:string) = case pname of 
"process`cond_c2_15"=>[(39,"-43200")] | "overview`start"=>[(40,"-155")] | _ => empty;
fun getbusyresources() = ["jonesa"];
fun getcurrenttimestamp() = ‚Äú1205203218‚Äù;fun gettimeunit() = ‚Äúsec‚Äù;
fig. 6. cpn tools input le with initial state information. several cases are in dierent
states in the system. for example, application no. 41 is currently being checked by
jonesa for completeness, and has a run time of 154 secs, i.e., ca. 2.57 mins
the following information is obtained about the current state and is intro-
duced as the initial state of a simulation run.
{ all the running cases of a given workow and their marking.
{ all the data values associated with each case.
{ information about enabled work items.
{ information about executing work items and the resources used.
{ the date and time at which the current state le is generated.
when the empty initial state le of the generated simulation model is replaced
with the le depicted in figure 6, tokens are created in the cpn model that
reect the current system status (see figure 7). for example, among the three
case data tokens is the data associated with application no. 41. the resource
jonesa is currently performing a check activity on this case and hence, it does
not appear in the list of free resources.
we now follow the scenario described in section 4 for simulation experiments,
i.e., due to a promotion 150 cases are in the system. we load the state le
containing these 150 cases into the model and perform simulation experiments
for the coming two weeks. we also add more resources to the model and observe
how this inuences the backlog and the throughput times for processing credit
card applications within this time horizon.
5.4 analyzing the simulation logs
we simulate the process from the generated cpn model for four dierent sce-
narios:
10fig. 7. the generated cpn model after loading the current state le
1. an empty initial state. (`empty' in figure 8)
2. after loading the current state le with the 150 applications that are cur-
rently in the system and no modications to the model, i.e., the `as-is' situ-
ation. (`as is' in figure 8)
3. after loading the current state le but adding four extra resources (two
having the role `manager' and three having the role `clerk'), i.e., a possible
`to-be' situation to help clear the backlog more quickly. (`to be a' in figure 8)
4. after loading the current state le and adding eight extra resources (four
having the role `manager' and six having the role `clerk'). (`to be b' in
figure 8)
we can see the dierence among these four scenarios in figure 8, which de-
picts the development of the number of cases (i.e., applications) in the workow
system over the coming two weeks for an example simulation run per scenario.
in the case of scenario 1 the simulation starts with having 0 credit card appli-
cations in the system. this does neither reect the normal situation nor does
it capture our current backlog of cases. only after a while, does this simulation
represent the normal behavior of the credit card application process (i.e., with
ca. 100 applications arriving per week). the other three scenarios load a dened
initial state, which contains the 150 applications that we assume to be currently
in the system. furthermore, one can observe that in the scenarios where we add
extra resources to the process, the case load decreases more quickly to a normal
level than without further intervention. however, the scenario `to be b' does
not seem to perform much better than the scenario `to be a' although twice as
many resources have been added. this way, we can assess the eect of possible
11 0 20 40 60 80 100 120 140 160 180
 0 5000 10000 15000 20000 25000no. of applications in the system
time horizon: two weeks (in seconds)number of applications that are in the system for four different scenarios1)2)3)4)'as is''to be a''to be b''empty'fig. 8. number of applications in the simulated process for the dierent scenarios.
while the scenario with the empty state has initially 0 applications, the other scenarios
are initialized by loading 150 applications from the current state le
 5000 5500 6000 6500 7000 7500 8000 8500 9000
 0 1 2 3 4 5confidence interval
simulation scenarios95 % confidence intervals average throughput time in minfor the four simulation scenarios (50 replications each)confidence intervals'as is'5.88 days'to be a'4.91 days'empty'3.86 days'to be b'4.72 days
fig. 9. simulation run showing the 95% condence intervals of the throughput times
for the dierent simulation scenarios. the length of the condence interval indicates
the degree of variation
measures to address the problem at hand, i.e., we can compare dierent `what-if'
scenarios in terms of their estimated real eects.
cpn tools has powerful simulation capabilities, which we can leverage. for
example, it is possible to automatically replicate simulation experiments to en-
able statistical analyses, such as calculating condence intervals for specic pro-
cess characteristics. for instance, figure 9 depicts the 95% condence intervals
12of the average case throughput times based on 50 replicated simulations for each
of the four simulation scenarios. one can observe that the estimated through-
put time for the `empty' scenario (i.e., based on the usual situation) is ca. 4
days, while the expected throughput time for the `as is' scenario (i.e., actually
expected based on the current backlog situation) is almost 6 days.
fig. 10. the generated simulation logs can be analyzed with the same tool set as the
initial workow logs
while cpn tools already provides powerful logging facilities and even gener-
ates gnuplot scripts that can be used to plot certain properties of the simulated
process, we also generate mxml event log fragments during simulation, similar
to the one shown in figure 3(a) for the workow log. these fragments can then
be combined using the cpn tools lter of the prom import framework, which
facilitates the conversion of event logs from various systems into the mxml
format that is read by prom.
the ability to use the same toolset for analyzing the simulation logs and
analyzing the actual workow logs constitutes a big advantage because the sim-
ulation analysis results can be more easily related to the initial properties of
the process. in particular, since we support the loading of current cases into
the initial state at the beginning of the simulation, we can easily combine the
real process execution log (`up to now') and the simulation log (which simulates
the future `from now on') and look at the process in a unied manner (with the
possibility of tracking both the history and the future of particular cases that
are in the system at this point in time).
13figure 10 shows a screenshot of prom while analyzing the simulation logs
generated by cpn tools. various plug-ins can be used to gain more insight
into the simulated process. for example, in figure 10 the log dashboard (top
left), the basic statistics plug-in (bottom left), the performance analysis plug-
in (bottom right), and the ltl checker (top right) are shown. the former
two provide a general overview about the cases and activities in the process,
whereas the performance analysis plug-in nds bottlenecks (e.g., in figure 10 a
bottleneck for starting the activity `make decision' is highlighted), and the ltl
checker can be used to verify specic properties of interest (e.g., \how many
cases could be processed until they are in the stage where a decision can be made
in under 3 days?").
6 discussion
in this paper we presented an innovative way to link workow systems, simu-
lation, and process mining. by combining these ingredients it becomes possible
to analyze and improve business processes in a consistent way. the approach
is feasible, as demonstrated by our implementation using yawl and prom. to
conclude, we would like to discuss the three main challenges that have been
addressed in this research.
6.1 faithful simulation models
although the principle of simulation is easy to grasp, it takes time and expertise
to build a good simulation model. in practice, simulation models are often awed
because of incorrect input data and a na ve representation of reality. in most
simulation models it is assumed that resources are completely dedicated to the
simulated processes and are eager to start working on newly arriving cases. in
reality this is not the case and as a result the simulation model fails to capture
the behavior of resources accurately. moreover, in manually constructed models
steps in the processes are often forgotten. hence simulation models are usually
too optimistic and describe a behavior quite dierent from reality. to compensate
for this, articial delays are added to the model to calibrate it and as a result
its predictive value and trustworthiness are limited. in the context of workow
systems, this can be partly circumvented by using the workow design (the
process as it is enforced by the system) and historic data. the approach presented
in this paper allows for a direct coupling of the real process and the simulation
model. however, the generated cpn models in this paper can be improved by a
better modeling of resource behavior. moreover, the process mining techniques
that extract characteristic properties of resources need to be improved to create
truly faithful simulation models.
6.2 short-term simulation
although most workow management systems oer a simulation component,
simulation is rarely used for operational decision making and process improve-
14ment. one of the reasons is the inability of traditional tools to capture the real
process (see above). however, another, perhaps more important, reason is that
existing simulation tools aim at strategic decisions. existing simulation models
start in an arbitrary initial state (without any cases in the pipeline) and then
simulate the process for a long period to make statements about the steady-state
behavior. however, this steady-state behavior does not exist (the environment
of the process changes continuously) and is thus considered irrelevant by the
manager. moreover, the really interesting questions are related to the near fu-
ture. therefore, the `fast-forward button' provided by short-term simulation is a
more useful option . because of the use of the current state and historic data,
the predictions are more valuable, i.e., of higher quality and easier to interpret
and apply. the approach and toolset presented in this paper allow for short-
term simulation. in the current implementation the coupling between yawl
and prom is not well-integrated, e.g., the translation of insights from simulation
to concrete actions in the workow system can be improved. further research is
needed to provide a seamless, but generic, integration.
6.3 viewing real and simulated processes in a unied manner
both simulation tools and management information systems (e.g., bi tools)
present information about processes. it is remarkable that, although both are
typically used to analyze the same process, the results are presented in com-
pletely dierent ways using completely dierent tools. this may be explained
by the fact that for a simulated process dierent data is available than for the
real-world process. however, the emergence of process mining techniques allows
for a unication of both views . process mining can be used to extract much more
detailed and dynamic data from processes than traditional data warehousing and
business intelligence tools. moreover, it is easy to extend simulation tools with
the ability to record event data similar to the real-life process. hence, process
mining can be used to view both simulated and real processes. as a result, it is
easier to both compare and to interpret `what-if' scenarios.
acknowledgements . this research was supported by the iop program of the
dutch ministry of economic aairs and by australian research council grant
dp0773012. the authors would like to especially thank michael adams, eric
verbeek, ronny mans, and also christian g unther, minseok song, lindsay brad-
ford, and chun ouyang for their valuable support in implementing the approach
for yawl and prom. we also would like to thank marlon dumas for sharing
his valuable insights during the many discussions we had about this topic.
references
1. w.m.p. van der aalst, b.f. van dongen, c.w. g unther, r.s. mans, a.k. alves
de medeiros, a. rozinat, v. rubin, m. song, h.m.w. verbeek, and a.j.m.m.
weijters. prom 4.0: comprehensive support for real process analysis. in j. kleijn
15and a. yakovlev, editors, application and theory of petri nets and other models of
concurrency (icatpn 2007) , volume 4546 of lecture notes in computer science ,
pages 484{494. springer-verlag, berlin, 2007.
2. w.m.p. van der aalst and a.h.m. ter hofstede. yawl: yet another workow
language. information systems , 30(4):245{275, 2005.
3. w.m.p. van der aalst, h.a. reijers, a.j.m.m. weijters, b.f. van dongen, a.k.
alves de medeiros, m. song, and h.m.w. verbeek. business process mining: an
industrial application. information systems , 32(5):713{732, 2007.
4. r. ardhaldjian and m. fahner. using simulation in the business process reengi-
neering eort. industrial engineering , pages 60{61, july 1994.
5. j.a. buzacott. commonalities in reengineered business processes: models and
issues. management science , 42(5):768{782, 1996.
6. m. dumas, w.m.p. van der aalst, and a.h.m. ter hofstede. process-aware infor-
mation systems: bridging people and software through process technology . wiley
& sons, 2005.
7. c. hall and p. harmon. a detailed analysis of enterprise architecture, process
modeling, and simulation tools. technical report 2.0, bptrends, september 2006.
8. m. jansen-vullers and m. netjes. business process simulation { a tool survey.
inworkshop and tutorial on practical use of coloured petri nets and the cpn
tools , aarhus, denmark, october 2006.
9. k. jensen, l.m. kristensen, and l. wells. coloured petri nets and cpn tools
for modelling and validation of concurrent systems. international journal on
software tools for technology transfer , 9(3-4):213{254, 2007.
10. d.w. kelton, r. sadowski, and d. sturrock. simulation with arena . mcgraw-hill,
new york, 2003.
11. j. kleijnen and w. van groenendaal. simulation: a statistical perspective . john
wiley and sons, new york, 1992.
12. m. laugna and j. marklund. business process modeling, simulation, and design .
prentice hall, upper saddle river, new jersey, 2005.
13. f. leymann and d. roller. production workow: concepts and techniques .
prentice-hall ptr, upper saddle river, new jersey, usa, 1999.
14. h. reijers. design and control of workow processes: business process manage-
ment for the service industry , volume 2617 of lecture notes in computer science .
springer-verlag, berlin, 2003.
15. h.a. reijers and w.m.p. van der aalst. short-term simulation: bridging the gap
between operational control and strategic decision making. in m.h. hamza,
editor, proceedings of the iasted international conference on modelling and
simulation , pages 417{421. iasted/acta press, anaheim, usa, 1999.
16. s.m. ross. a course in simulation . macmillan, new york, 1990.
17. a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering col-
ored petri nets from event logs. international journal on software tools for
technology transfer , 10(1):57{74, 2008.
18. a. rozinat, m. wynn, w.m.p. van der aalst, a.h.m. ter hofstede, and c. fidge.
workow simulation for operational decision support using yawl and prom.
bpm center report bpm-08-04, bpmcenter.org, 2008.
19. mathias weske. business process management: concepts, languages, architec-
tures . springer-verlag, berlin, heidelberg, 2007.
20. m.t. wynn, m. dumas, c.j. fidge, a.h.m. ter hofstede, and w.m.p. van der
aalst. business process simulation for operational decision support. in a.h.m.
ter hofstede, b. benatallah, and h.-y. paik, editors, bpm 2007 workshops , volume
4928 of lecture notes in computer science , pages 66{77. springer-verlag, 2008.
16