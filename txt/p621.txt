product-based work°ow support
irene vanderfeestena;¤hajo a. reijersa
wil m.p. van der aalsta
atechnische universiteit eindhoven, department of industrial engineering and
innovation sciences, po box 513, nl-5600 mb eindhoven, the netherlands
abstract
despite the industrial need for the improvement of information-intensive business
processes, few scienti¯cally grounded approaches exist to support such initiatives.
in this paper, we propose a new approach that builds on concepts that are part of a
product-oriented view on process optimization. essentially, this approach allows end
users to °exibly decide on the best possible way to create an informational product
within the limits that are imposed by regulations and logical dependencies. we
argue that this provides various bene¯ts in comparison to earlier work. to support
the end user in making sensible decisions, we describe two alternative approaches
to provide her with recommendations to this end. we formalize these alternatives
and discuss their relative strengths and weaknesses. the feasibility of the overall
approach, which we refer to as product-based work°ow support, is demonstrated
by a work°ow system realized using prom and declare.
key words: business process modelling, work°ow management, product data
model.
1 introduction
contemporary management concepts like \operational excellence", \lean man-
agement", and \business process redesign" all stress the importance of smoothly
running business processes. it seems a natural angle to consider processes {
complete chains of operations that are needed to produce certain products or
?this research is supported by the technology foundation stw, applied science
division of nwo and the technology programme of the dutch ministry of economic
a®airs.
¤corresponding author. tel. 0031 40 247 4366, fax. 0031 40 243 2612
email address: i.t.p.vanderfeesten@tue.nl (irene vanderfeesten).
preprint submitted to elsevier april 23, 2010services { to make organizations perform better. unsurprisingly, market anal-
yses consistently identify the improvement of business processes as the top
business priority for cio's [20,21,22].
given the importance of business processes and their tight relation to organi-
zational performance, it may come as a surprise that few scienti¯c approaches
are available that address the issue of how to actually design a process or, as
in many processes are already in place, how to redesign one. the best-known
references are situated in the domain of the popular management literature,
e.g. [11,14,17]. understandably, it is often said that process design is \more
art than science" [42,43].
one of the notable exceptions is product-based work°ow design (pbwd)
[35]. pbwd has been developed in close cooperation between academic and
industrial parties to arrive at a method for process redesign that is repeatable,
objective, and e®ective. the focus is on the design of processes that deliver
informational products, the so-called work°ow processes . since its conception,
pbwd has been adopted by various consultancy and service companies to
improve the performance of various business processes in the services domain
[33,34].
highly characteristic for pbwd is that it aims ¯rst and foremost at developing
a deep understanding of the characteristics of the informational product that
is to be delivered, e.g. a particular type of decision, proposal, permit, etc.,
which is laid down in a product data model . this is subsequently used by the
designer to determine the best process structure to create and deliver that
product. given that, in general, there are alternative ways to produce an
informational product, pbwd discloses the various opportunities to produce
a product a desirable way.
at this stage, considerable experience has been gained with the application of
pbwd in practice. aside from the tangible business bene¯ts that pbwd has
delivered, it has become apparent that the \product" notion is an extremely
viable concept to reason about work°ow processes. the shift of attention to
what is the desired outcome of a work°ow process without directly discussing
how this is achieved leads to an interaction with stakeholders that quickly
converges. this sharply contrasts with the problems that are often associated
with process improvement projects, such as the confusion about what actions
in the current process are really necessary and which ones are merely motivated
by tradition [14,39]. interestingly, ibm's recent artifact-centric approach takes
a similar indirect route, by ¯rst considering the objects that are manipulated
in a process before the focus moves to the actual process design [6].
at the same time, it must be acknowledged that the translation of the product
data model to a favorable work°ow is a critical step. in the ¯rst applications of
2pbwd this derivation was done manually [34, p.256-273]. since this is time-
consuming and error-prone, we have been developing it tools to support the
administration of a product data model, as well as algorithms that automat-
ically generate work°ow designs on the basis of a product data model [44].
still, business users ¯nd it di±cult to consider and compare all the options
that are available for the ¯nal work°ow design. after all, in general, there are
many of such options. some options may work well for some cases and not for
others. moreover, many potential work°ow variants may only di®er in subtle
ways.
this paper presents an entirely new outlook on the use of the product data
model. instead of aiming at the derivation of a work°ow design that is in gen-
eral the best possible way to generate an informational product, the product
data model itself is proposed as the vehicle to steer a work°ow's execution.
in other words, the need to translate a product data model into a work°ow
design disappears. instead, a business user determines on a case-by-case basis
the best possible way to create an informational product in accordance with
the relevant product data model. this approach addresses the di±culty for
business users to compare many alternative work°ow designs, while it still re-
lies on the product data model with its attractive properties. in addition, this
approach allows for a highly dynamic and case-speci¯c execution of work°ows,
as will be illustrated in the remainder of this paper.
the proposed approach builds on two pillars. on the one hand, we exploit
the wide industrial proliferation of \process-aware" or \process-oriented" in-
formation systems [13,24]. we will assume the existence of this type of system
to support the proposed approach and, along the way, show the feasibility of
this idea in the form of a prototype work°ow system. on the other hand, the
o®ered solution rests on the idea that it is easier for a business user to deter-
mine what is the best possible action in the context of processing a single case
than to do that for the general case. to guide the business user in this respect,
we present two alternative approaches to provide her with recommendations:
one that is optimal in relation to a dominant performance criterion but rather
computing-intensive, and another that is lightweight and based on heuristics.
our contribution can be summarized as follows. we present a rigorous ap-
proach for business process improvement, which addresses the need for guid-
ance in this respect from practice. the innovative aspect is that we do not aim
at the design of an underlying, generic process but instead provide a business
user with direct support for delivering individual informational products. to
do so, we build on the successful notions from product-based work°ow design
(pbwd), in particular the product data model, to arrive at a method that
we coin \product-based work°ow support" (pbws). while the product data
model speci¯es the elements to assemble a particular product, a process-aware
information system recommends a business user on how to use these to deliver
3the product in the best possible way.
the structure of this paper is as follows. section 2 contains background infor-
mation, a running example and the motivation for product-based work°ow
support. next, sections 3 and 4 present the two main, alternative realizations
of the envisioned support. a comparison of these di®erent approaches is given
in section 5, followed by a description of a work°ow system (based on prom
and declare) to support the overall approach in section 6. finally, the
paper ends with related work and conclusions.
2 background and motivation
this section provides information that is essential as background for the re-
mainder of the paper. in particular, the product data model will be explained,
which will be illustrated by an example. also, we will motivate the idea of
product-based work°ow support.
2.1 work°ow products
the product of a work°ow process is an informational product, e.g. a decision
on an insurance claim, the allocation of a subsidy, the approval of a loan. based
on the input data provided by the client or retrieved from other systems, the
process constructs the end product step-by-step. in each step new information
is produced based on the speci¯c data present for the case.
in this paper, we use a ¯nancial work°ow process as a running example. the
work°ow process deals with the calculation of the maximum amount of mort-
gage a bank is willing to loan to a client. the bank has three alternative ways
to decide on the maximum mortgage. first of all, if the client has a negative
registration in the central register for credits (e.g. the client has a history of
non-payment), the bank may directly reject this person for a mortgage (lead-
ing to a maximum amount of zero). the central credit register keeps track of
all loans a person has and helps providers of loans in their assessment of the
creditworthiness of such a person.
secondly, if the client has previously requested a mortgage o®er and the term
of validity of this o®er is not expired yet, this may determine the amount
of mortgage. typically, the percentage of interest changes over time and a
mortgage o®er is valid for some months. in case the interest has increased
since the previous o®er, the valid o®er might be better than a new one which
is based on the higher interest percentage.
4a maximum mortgage 
b percentage of interest 
c annual budget to be spent on 
the mortgage 
d term of mortgage 
e previous offer (within the period 
of validity of the offer)
f percentage of income to be 
spent on the mortgage 
g gross income per year 
h credit registration figure 1. the pdm of the maximum mortgage calculation.
finally, if the credit register shows a positive credit history, the bank needs
more information on the client's situation (e.g. gross income, type of mort-
gage) in order to decide on the maximum mortgage. to a certain extent, a
bank de¯nes its own internal rules and policies to decide on how much risk a
mortgage applicant is to their business if they allow a mortgage. therefore,
each bank uses a percentage of the gross income of the client to calculate how
much money the client is allowed to spend on the house. with this rule a bank
ensures that the client can a®ord the cost of food and recurring expenses and
that the probability is high that he will meet the monthly payment liabilities
with the bank. however, this percentage is not ¯xed and can vary based on
the bank's current situation as well as the client's.
in this example the maximum amount of mortgage is the end product of
the work°ow process, this is the piece of information that is \produced". a
graphical representation of the structure of this work°ow product is given in
figure 1 and is explained below.
2.2 the product data model
the structure of a work°ow product is modeled by a product data model
(pdm) . the pdm is described by a tree-like structure similar to a bill of
material [25]. the information that is processed in the work°ow process is
described by the so-called data elements of the pdm. for each speci¯c case a
data element can have a di®erent value . data elements are depicted as circles
in the pdm, as can be seen in the example of figure 1.
the actions that are taken on the data element values are called operations
and are represented by arcs. each operation can have zero or more input
5data elements and produces exactly one output data element . the arcs are
`knotted' together when a value for all data elements is needed to execute the
particular operation. compare for instance the arcs from b,c, and dleading
toaon the one hand, and the arc leading from etoaon the other hand in
figure 1. in the latter case, only one data element value is needed to determine
the outcome of the process, while in the case of b,c, and dall three data
element values are needed to produce a. an operation is said to be executable
when a value for all of its input elements is available.
several operations can have the same output element while having a di®erent
set of input elements. such a situation represents alternative ways to produce
a value for that output element. for example, a value for the end product a
in figure 1, can be determined in three alternative ways: (i) based on a value
fore, (ii) based on a value for h, and (iii) based on values for b,c, and d.
the top element of the pdm, i.e. the end product, is called the root of the
pdm. the leaf elements are the elements that are provided as inputs to the
process. they are produced by operations with no input elements (e.g. the
operations with output elements b,d,e,f,g, and h). the operations
producing values for the leaf elements are denoted as leaf operations or input
operations. an operation can be identi¯ed by a tuple consisting of the output
element and a set of input elements, e.g. ( a;fb; c; d g) for the operation
producing a value for abased on data elements b,c, and d. throughout
this paper operations are also referred to by identi¯ers, such as op01.
the construction of a pdm is a manual task. however, the information needed
to construct a pdm can be obtained from e.g. rules and regulations, work
instructions, forms, textual product descriptions, jurisprudence, information
systems and the knowledge on the work°ow product that is present with stake-
holders.
figure 1 expresses the pdm for the mortgage example. it shows that the
maximum mortgage (element ain figure 1) is dependent either on a previous
mortgage o®er ( e), or on the registration in the central credit register ( h),
or on the combination of the percentage of interest ( b), the annual budget to
be spent on the mortgage ( c), and the term of the mortgage ( d). the annual
budget ( c) is determined from the gross income of the client per year ( g), the
credit registration ( h), and the percentage of the income the client is allowed
to spend on paying the mortgage ( f).
2.3 motivation
according to the pbwd method, the pdm is used as the basis for designing
a process that on the one hand respects the dependencies between the various
6data elements and on the other provides an attractive \walk through" along
the various operations that need to take place [35]. it is important to stress
that with pbwd such a process is proposed as a generally attractive way to
deal with all thinkable instances of the product that the pdm relates to.
both for the derivation of a general process (in accordance with pbwd) and
for product-based work°ow support (as proposed in this paper) the availabil-
ity of various alternatives to achieve a particular outcome is exploited. opera-
tions that create new values for data elements can take on di®erent forms, e.g.
an automatic calculation, an assessment by a human, or a rule-based decision,
but all will consume time and money. in general, an operation can have a
number of attributes associated to it that describe the characteristics of the
operation in more detail:
²execution cost : the cost associated with executing the operation (given by
a probability distribution and its parameters).
²processing time : the time that is needed to complete the operation (given
by a probability distribution and its parameters).
²execution conditions : conditions on the value of the input data elements
that restrict the execution of the operation. if the condition is not satis¯ed,
the operation is not executable even if a value for all of its input data
elements is available.
²failure probability : the probability that the operation is not performed suc-
cessfully, i.e. the probability that the output data element is not produced.
²resource class : the resource class or role that is required to perform the
operation.
if we again consider our example, it could occur, for instance, that the cost
of executing alternative operations di®ers. the involved bank has to pay for
receiving a copy of the client's registration in the credit register. thus, the
cost for this operation are higher than the cost for e.g. determining the gross
income, since the information on income is provided by the client. the same
holds for the processing time of these operations: since an external party is
consulted, it may take more time to retrieve the credit registration than to
ask the client for his gross income.
to illustrate the notion of product-based work°ow support, we will present
with figure 2 a step-by-step execution of the operations that occur in a
pdm1. suppose that the values for the leaf elements b,d,f,g, and h
(i.e. the interest percentage, term of mortgage, percentage of income to be
paid in rent) are available at the start of the process for one particular case
1for reasons of simplicity we abstract here from the execution conditions on the
operations. moreover, in figure 2 we assume that all leaf operations have already
executed in the initial state, i.e. a value is available for the output data elements of
all successfully executed leaf operations.
7op01
op02op03 op04
op05 op06 op07
op08 op09 op10(a) the pdm for the mortgage exam-
ple.
(b) the values for some of the leaf data
elements ( b; d; f; g; h ) are available
(indicated by bold circles). through-
out this paper, we refer to this situa-
tion as the initial state .
op02 op03 
(c) executable operations in the ¯rst
step: op02 and op03.
op02 (d) the value for data element cis
produced by operation op02.
op01 
op03 
(e) executable operations in step two:
op01 and op03.
op01 (f) the value for the end product ( a)
is determined by executing operation
op01.
figure 2. the step-by-step execution of the pdm for the mortgage example. bold
circles represent available data element values for the case under consideration; bold
arrows indicate executable operations.
8table 1
operations and their attributes for the mortgage example.
output input cost time prob. conditions
op01 a b, c, d 5.0 1.0 0.05 -
op02 c f, g, h 5.0 4.0 0.05 -
op03 a h 9.0 3.0 0.05 value(h) = `negative'
op04 a e 2.0 2.0 0.00 -
op05 b - 0.0 0.0 0.00 -
op06 d - 0.0 0.0 0.00 -
op07 e - 1.0 1.0 0.50 -
op08 f - 0.0 0.0 0.00 -
op09 g - 0.0 2.0 0.00 -
op10 h - 3.0 10.0 0.15 -
(see figure 2(b))2. the operations that are now enabled for execution for
this speci¯c case are op02 and op03, since a value for all of their input el-
ements is available (figure 2(c)). operation op01 is not executable because
a value for data element cis not available yet and op04 is not executable
since there is no value for epresent. now, we have to choose between the two
executable operations ( op02,op03). suppose we select op02. then, a value
for data element cis produced (figure 2(d)). the executable operations are
calculated again, i.e. op01 and op03, and one of these two operations is to be
selected next. suppose we select op01 (figure 2(f)). then, the value for the
end product ais determined and the process ends.
the example illustrates that more than one operation may be executable at
a certain point in time. for example, in the ¯rst step of this example we
could have chosen for op03 instead of op02. this would have led to the
end product ( a) immediately, but it generally also could have resulted in a
di®erent execution of the process with e.g. di®erent total cost, throughput
time, etc. for example, suppose the execution cost and processing time for
the operations of the mortgage example are given in table 1. if we focus on
the cost of execution it seems best to choose op02 since the execution cost
forop02 is lower than the execution cost for op03 (5.0 vs 9.0). however, if
we consider the processing times for the operations, the selection of op03 as a
next step would perhaps be a better decision (4.0 for op02 vs 3.0 for op03). it
2note that for this case not all leaf operations have been executed successfully.
because the execution of op07 has failed, there is no value for data element e
available.
9would be extremely valuable if at any point during the execution of operations
these insights would be available.
the idea of product-based work°ow support can now be described as follows.
an end user is supported on a case-by-case basis with recommendations on the
most suitable way to carry out the available operations in a pdm. a recom-
mendation takes into account what type of performance is pursued for each
case and how the various alternative executions di®er from each other with re-
spect to that performance criterion. note that the general process model that
is most suitable to deal with the average case, as prescribed by the pbwd
method, becomes super°uous when using product-based work°ow support.
as an alternative, the end user is guided through the operations of the pdm
in a way that is both °exible and performative.
in the remainder, we deal with the question how to determine proper recom-
mendations, i.e. how to select in each possible situation from a set of executable
operations the best operation to proceed with. it should be stressed that we
de¯ne `best' in the context of a single case, i.e. the performance goal (e.g.
total cost, total processing time) of the case in isolation is optimized. two
main solution approaches for selecting candidate operations are presented in
the next two sections.
3 global decision strategies
the ¯rst solution approach aims at creating guaranteed optimal walkthroughs
of the pdm by using global decision strategies. a global decision strategy takes
into account the e®ect of the current decision on future decisions, i.e. the over-
all performance of the case. for example, in the ¯rst step of the mortgage case
choosing op02 enables op01 in the next step and determines an alternative
path to the path containing only op03 to produce the end product a. this
e®ect is considered when determining a recommendation for the current situ-
ation. a global decision strategy takes the complete, alternative paths to the
end product into account to optimize the overall performance of the case.
the technique we use to determine a walkthrough of the pdm using a global
perspective is based on the theory of markov decision processes (mdps)
[31,41]. an mdp extends the notion of a markov chain with decisions. markov
chains are mathematical models of stochastic processes, i.e. systems that
evolve over time [41]. they are widely used in e.g. operations research, bi-
ology, and computer science. in an mdp several decisions can be taken in
each state of the markov chain. the state transitions in the markov chain are
given by the transition matrix and are dependent on these decisions. each
decision has associated costs, which depend on the state of the system. the
10goal of an mdp is to ¯nd a strategy that speci¯es which decision to take in
each state, so as to minimize the overall cost [41]. note that an important
characteristic of a markov chain is that it is memoryless , i.e. the probability
of being in a certain state at time n+ 1, is only dependent on the state at
time nand not on earlier states ( < n).
the execution of a pdm can be described as a memoryless stochastic process
with decisions. we now present the formulation of an mdp based on the pdm
to elaborate on this mapping.
3.1 formulation of the markov decision process
an mdp is de¯ned by a number of components: (i) the state space, (ii) the
time space, (iii) the decision space, (iv) the transition function, and (v) the
cost functions. to show that the decision problem in the execution of a pdm
can be translated into an mdp, we describe for each component of the mdp
the corresponding part in a pdm. a simple example, based on the mortgage
process, is used to clarify this mapping.
state space - the state space ( s) describes the states the process can be
in. the states of the execution of a pdm can be described by the opera-
tions that have been executed (either successfully or unsuccessfully) together
with the data elements for which a value is available. a state in the state
space is therefore represented by a tuple consisting of three sets: (i) the suc-
cessfully executed operations, (ii) the unsuccessfully executed operations, and
(iii) the data elements for which a value is available3. in figure 3(b), for
example, the state in the mortgage example in which a value for each of
the leaf elements b,d,f,g, and his available (cf. figure 2(b)) is de-
noted by ( fop05; op06; op08; op09; op10g;fop07g;fb; d; f; g; h g). thus,
sµ p(o)£ p(o)£ p(d). the state space of the mdp is ¯nite, since the
number of operations is ¯nite and we assume that each operation can only be
executed once, either successfully or unsuccessfully.
time space - the time space describes the time points at which a decision is
taken and at which a state transition occurs (also called decision epochs ). the
times used in our mdp are discrete and can be represented by the number of
executed operations ( t=f0;1;2;3; :::;jojg), i.e., time is indicated by t2t
indicating the number of executed operations. the times are not necessarily
equidistant, but since there is a ¯nite number of operations in a product data
3note that the set of available data elements in a state actually gives redundant
information, since the set of available data elements can also be determined based
on the set of successfully executed operations. however, this information is added
for reasons of clarity and understandability of the examples.
11{} 
{} 
{} (a) the state in which no data element
values are available yet, cf. the initial
state shown in figure 2(b).
{op05,op06,op08,op09,op10}
{op07}
{b,d,f,g,h}(b) the state in which the values for
data elements b,d,f,g, and hare
available, cf. figure 2(b).
figure 3. a state in the state space is described by three sets: (i) the operations that
have been executed successfully so far, (ii) the operations that have been executed
unsuccessfully, and (iii) the data elements for which a value is available.
model and we assume no concurrency, the time space is bounded by this
number, i.e. the mdp problem has a ¯nite time horizon.
decision space - in each state a number of decisions can be made. for the
execution of a pdm these decisions are described by the set of operations
that are executable in the current state of execution (i.e. those operations of
which the input elements are available and that have not yet been executed)4.
moreover, if there are no executable operations for a certain state there is only
one decision possible, i.e. to stop. thus, the decision space ais equal to the
set of operations plus the decision to stop, i.e. a= (o[fstopg). furthermore,
the decision space in a particular state aiis a subset of ( o[fstopg). note that
the decision space in a certain state is time-independent, i.e. given a state, at
any point in time, the same decisions can be made.
transition probabilities - the transition probabilities are given by a matrix
pthat describes the probabilities that the system moves from the current state
to any of the other states in the system. these transition probabilities are
dependent on the decision that was made. for our application, a decision ain
state ican lead to two new states: j1(for a successful execution of the operation
given in decision a) and j2(for a failed execution of the operation given in
decision a), each with their own probabilities. the two transition probabilities
under decision aalways add up to 1. for example, recall the execution of the
mortgage example in figure 2. if we start in the state with available values for
data elements b,d,f,g, and h, there are two decisions which can be taken,
i.e.fop02; op03g µ o. each of these two operations can either fail or be
successfully executed. this leads to four new states (figure 4). the transition
probabilities correspond to the probabilities of failure or successful execution
of an operation (see table 1):
4throughout this paper we abstract from concrete values of data elements and
conditions based on these values. incorporating data is possible if the number of
possible values is small. if many values are possible, the state space will be too large
to allow for any form of analysis.
12{op05,op06,op08,op09,op10}
{op07}
{b,d,f,g,h}
{op03,op05,op06,op08,op09,op10}
{op07}
{a,b,d,f,g,h}{op05,op06,op08,op09,op10}
{op03,op07}
{b,d,f,g,h}{op05,op06,op08,op09,op10}
{op02,op07}
{b,d,f,g,h}{op02,op05,op06,op08,op09,op10}
{op07}
{b,c,d,f,g,h}op02 op02 op03 op03 
{op02,op05,op06,op08,op09,op10}
{op01,op07}
{b,c,d,f,g,h}{op01,op02,op05,op06,op08,op09,op10}
{op07}
{a,b,c,d,f,g,h}{op02,op05,op06,op08,op09,op10}
{op03,op07}
{b,c,d,f,g,h}{op02,op03,op05,op06,op08,op09,op10}
{op07}
{a,b,c,d,f,g,h}op01 op01 op03 op03 
{op03,op05,op06,op08,op09,op10}
{op02,op07}
{a,b,d,f,g,h}op03 op03 
{op05,op06,op08,op09,op10}
{op02, op03,op07}
{b,d,f,g,h}op02 op02 
{op02,op03,op05,op06,op08,op09,op10}
{op01,op07}
{a,b,c,d,f,g,h}{op02,op05,op06,op08,op09,op10}
{op01,op03,op07}
{b,c,d,f,g,h}op03 op03 
{op01,op02,op05,op06,op08,op09,op10}
{op03,op07}
{a,b,c,d,f,g,h}{op02,op05,op06,op08,op09,op10}
{op01,op03,op07}
{b,c,d,f,g,h}op01 op01 1
2 3 4 5
8 9 10 11 7 6
12 13 14 15 stop stop 
stop stop stop 
stop stop stop stop 
figure 4. the state space of the mortgage example. note that there are eight end states: f2;6;8;10;11;12;13;14;15g.
13p1;3(op02) = 0.95 p1;2(op03) = 0.95
p1;5(op02) = 0.05 p1;4(op03) = 0.05
thus, the probability of moving from state 1 to state 3 under decision op02
is 0.95.
immediate and final cost - the immediate cost of a transition from
state ito state junder decision aare the cost of executing operation a.
in our model there are no costs associated to residing in a state, i.e., costs
are associated to decisions. depending on the performance objective of the
process, e.g. minimization of cost or processing time, the immediate cost are
de¯ned as the cost or the processing time of the operation. suppose we want
to minimize the execution cost of the process, then the immediate cost in state
1 are (see table 1):
cop02(1) = 5.0 cop03(1) = 9.0
the ¯nal cost incurred at time joj, when no decisions can be made anymore,
in state iare zero, i.e. q(i) = 0.
by using the mapping presented above, the process of executing a pdm can
be translated to a time-homogenous mdp with a ¯nite horizon. note that
this mapping of a pdm to an mdp results in a markov chain with some
special properties. first of all, the state space is ¯nite , i.e. there is a ¯nite
number of states. secondly, each operation can be executed at most once.
thus, each decision can also be taken at most once during any execution.
moreover, at each point in time an operation is selected until there are no
executable operations anymore. the only decision that can be made then is
to stop and the system stays in the same state. these end states are absorbing
states. the markov chain is a transient chain since each closed class has exactly
one absorbing state. besides the absorbing end states there are no cycles in
the markov chain, i.e. it is not possible to return to a state that was previously
visited.
we have used a small part of the mortgage example to illustrate the map-
ping from a pdm to an mdp (see figure 4). below, this example is used to
demonstrate how a stationary markov decision rule ( f) is determined for the
complete mortgage example.
3.2 the mortgage example as an mdp
in this section, the mdp problem for the mortgage example is explained as an
illustration. the initial situation (see figure 2(b)) in which there is already a
14state 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
1 0.0 0.95 0.95 0.05 0.05 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
2 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
3 0.0 0.0 0.0 0.0 0.0 0.95 0.05 0.95 0.05 0.0 0.0 0.0 0.0 0.0 0.0
4 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.95 0.05 0.0 0.0 0.0 0.0 0.0
5 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.05 0.95 0.0 0.0 0.0 0.0
6 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
7 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.95 0.05 0.0 0.0
8 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
9 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.95 0.05
10 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0
11 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0
12 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0
13 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0
14 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0
15 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0
table 2. transition probabilities for the state space of the mortgage example in figure 4. the transition probabilities correspond to the
failure probabilities in table 1.
15value for data elements b,d,f,g, and his used again because in this case
the decision space is rather small. therefore, the state space for this mdp
problem stays small and readable. the state space is depicted in figure 4 and
describes all possible execution steps from the initial state. the decision space
per state can also be derived from the ¯gure, e.g. in state 3 two alternatives
exist: op01 and op03. because the execution of both operations can either be
successful or unsuccessful, state 3 has four outgoing arcs to four new states.
if operation op01 is executed successfully, the system moves from state 3 to
state 6. confronted with an unsuccessful execution of op01, the system moves
to state 7. similarly, upon execution of op03 the system moves to state 8
or 9. the probabilities for these transitions are summarized in table 2. for
this example we focus on minimizing the total cost for a case. the cost for
executing an operation can be found in table 1.
the optimal decision strategy for this mdp can be calculated using a value
iteration algorithm [41]. the algorithm is de¯ned as follows:
de¯nition 3.1 letv0(i) :=q(i), and vt(i); t= 1;2; :::be recursively given by
vt(i) := min
a2ai[ca(i) +x
j2spi;j(a)¢vt¡1(j) ]:
then, any decision rule ftdetermined by
ft(i) = arg min
a2ai[ca(i) +x
j2spi;j(a)¢vt¡1(j) ]
gives the optimal decision for each state in the state space and achieves the
minimal cost over tperiods to the time horizon.
the value iteration algorithm uses backward induction to step-by-step derive
the decision rules. first, the cost at the time horizon (see figure 5) are deter-
mined. the time horizon is the point in time at which the process ends and
no decisions can be made anymore. then, a decision rule ( f1) is calculated for
the last decision step in the process, i.e. the situation in which one decision
can be made ( t= 1). this calculation is based on the expected cost at t= 0.
subsequently, the decision rules for t= 2;3; :::can be determined. below, the
¯rst steps of this algorithm are elaborated for our mdp. vt(i) denotes the
total expected cost at decision epoch tand state i. the cost at decision epoch
t= 0 are equal to the ¯nal cost, i.e.
v0(i) = 0 ;8i2s:
next, the values for t= 1 can be calculated based on all v0(i) values. for
instance, two decisions can be made in state 3: op01 and op03. the expected
cost for choosing op01 are dependent on the immediate cost for choosing op01
in state 3, and the expected cost and transition probabilities for the states the
161 0 9 8 7 6 5 4 3 2
8 9 0 1 2 3 4 5 6 7time (n)  
number of decisions 
to be taken (t) total cost t ime horizon 
(n = 9) 
abcde f ghi
decision 
points figure 5. this ¯gure describes a time line of an mdp with a ¯nite time horizon.
the process ends at time n= 9. this point is either represented by the time, i.e.
n= 9, or by the number of decision epochs to the end of the process, i.e. t= 0.
process can move to under decision op01:
cop01+p3;6(op01)¢v0(6)+ p3;7(op01)¢v0(7) = 5 :0+0:95¢0:0+0:05¢0:0 = 5 :0:
similarly, the expected cost in state 3 for decision op03 can be calculated:
cop03+p1;2(op03)¢v0(2)+ p1;4(op03)¢v0(4) = 9 :0+0:95¢0:0+0:05¢0:0 = 9 :0:
since decision op01 has the lowest expected total cost it is the best decision.
thus, if the process is in state 3 and there is only one decision to be taken
until the end of the process, the best decision is op01, i.e. f1(3) = op01, with
expected total cost of 5 :0, i.e. v1(3) = 5 :0. the same way the expected cost
and best decisions for all other states at time t= 1 can be calculated. tables 3
and 4 show that if there is only one time period left, it is best to choose op02
in state 1 since v1(1) has the minimal value of 5.0 (vs. 9.0) for its argument
op02. also, op02 should be chosen in state 4 ( v1(4) = 5 :0 for op02), etc. in
states 2, 6, 8, 10, 11, 12, 13, 14, and 15 the only decision that can be made is
to stop since these states are end states in the state space. thus, the decision
rulef1(for time t= 1) is:
f1=f(1; op02);(2;stop) ;(3; op01);(4; op02);(5; op03);(6;stop) ;
(7; op03);(8;stop) ;(9; op01);(10;stop) ;(11;stop) ;(12;stop) ;
(13;stop) ;(14;stop) ;(15;stop)g:
17in a similar way, the values and decision rules for all time points can be
calculated. the details can be found in tables 3 and 4. the tables show that
the decision rules become stationary for su±ciently large t(i.e.t¸3 for
this case), since the markov chain does not contain any cycles other than the
absorbing end states. this results in the following global decision strategy:
f=f(1; op03);(2;stop) ;(3; op01);(4; op02);(5; op03);(6;stop) ;
(7; op03);(8;stop) ;(9; op01);(10;stop) ;(11;stop) ;(12;stop) ;
(13;stop) ;(14;stop) ;(15;stop))g:
note that the best decision for the ¯rst state (describing the initial situation)
has changed from op02 at t= 1 to op03 at t¸2. thus, by looking at the
complete state space and decision space, the algorithm calculates a global
strategy that gives the best decision for each state in the mdp.
3.3 computability of the decision strategy
in the previous section we have elaborated on the computation of a decision
strategy for a small example with a small state space. as we mentioned before,
the state space of our mdp problem is ¯nite. nevertheless, the state space
can become extremely large. for instance, if we use an initial situation in the
mortgage example in which none of the operations have been executed yet
and no value is available for any of the data elements, i.e. the initial state
with ( fg;fg;fg) of figure 6(a), the state space contains 2218 states and, as
such, is much larger than in our example of figure 4 with 15 states. this
is because the six leaf operations can be executed in an arbitrary order. all
possible combinations are then explicitly represented in the state space.
generally, an upper bound for the size of the state space can be given in
terms of the number of operations of the pdm. each operation can be either
(i) successfully executed, (ii) unsuccessfully executed (failed), or (iii) not yet
executed. thus, there are 3jojpossible combinations of operations, which is
an upper bound for the size of the state space. however, most state spaces
will be smaller since not all combinations of executed operations are possible.
for instance, the state space for the mortgage example will never contain the
state ( fop02,op07 gfop09gfc,gg), since op02 can never be executed before
both op08 and op10 are executed.
we have experimented calculating the state space for one of the industry cases
in which pbwd was applied. the pdm of the uwv-case (described in [34])
contains 45 data elements and 50 operations, which is signi¯cantly larger than
our running example but still reasonably small for a practical case. during
18table 3
the minimal cost values obtained by the value iteration algorithm, i.e. vt(i). note
that the values become stable, i.e. they do not change anymore, for t¸3.
t=i 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0
1 5.0 0.0 5.0 5.0 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
2 9.25 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
3 9.49 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
4 9.49 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
5 9.49 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
6 9.49 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
7 9.49 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
8 9.49 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
9 9.49 0.0 9.25 9.75 9.0 0.0 9.0 0.0 5.0 0.0 0.0 0.0 0.0 0.0 0.0
table 4
the rows in this table denote the decision strategy ( ft) for each point in time ( t).
t=i 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
1 op02 - op01 op02 op03 - op03 - op01 - - - - - -
2 op03 - op01 op02 op03 - op03 - op01 - - - - - -
3 op03 - op01 op02 op03 - op03 - op01 - - - - - -
4 op03 - op01 op02 op03 - op03 - op01 - - - - - -
5 op03 - op01 op02 op03 - op03 - op01 - - - - - -
6 op03 - op01 op02 op03 - op03 - op01 - - - - - -
7 op03 - op01 op02 op03 - op03 - op01 - - - - - -
8 op03 - op01 op02 op03 - op03 - op01 - - - - - -
9 op03 - op01 op02 op03 - op03 - op01 - - - - - -
10 op03 - op01 op02 op03 - op03 - op01 - - - - - -
our experiments we experienced that a normal pc5was not able to process
the complete state space of this case. therefore, we tried to limit the amount
of states in the state space based on a number of restrictions described in [44].
one of the main design objectives for the redesign project of the case was
a minimum number of contacts with the client (see [34]). this requirement
was realized in the design by requesting all input information from the client
at once at the start of the case. therefore, the restriction of using an initial
state in which all leaf operations have been (successfully) executed is not
unrealistic. calculating the ¯rst 300.000 states of the state space with only
this restriction took more than 60 days and we failed to gain the complete state
5a normal pc at the time of writing this paper is e.g. an intel pentium 4 with a
3.8ghz processor and 3gb of ram.
19space. furthermore, it also seemed realistic to assume that all operations are
executed successfully, since the failure probabilities for the operations in the
pdm are typically very low. with these two restrictions, the state space for
the social bene¯ts case was calculated in 2.5 days. the state space contained
66.581 states. based on this partial state space a decision strategy can be
computed. however, this decision strategy may not be optimal because of the
assumptions that were made to limit the state space.
the experiments show that it is theoretically possible to ¯nd globally opti-
mal recommendations for executing the pdm, but for real-life applications
it may be intractable to ¯nd the optimal solution. typically, pdms may be
even larger than the one for the uwv-case, e.g. containing hundreds of data
elements. therefore, the mdp may become unsolvable in practice. note that
the selection of the next operation needs to be done at real time and repeated
after every step. hence, a more pragmatical way of determining recommenda-
tions would be desirable. as a second solution approach, we now describe a
number of local decision strategies that focus on the selection of the candidate
operation for execution within the set of executable operations.
4 local decision strategies
the issue of unsolvable mdps due to large state spaces also exists in other
application areas of mdp theory. in the ¯eld of production planning, simpler
heuristics have been developed that perform well and approximate the optimal
solution of the decision problem. these heuristics aim for a local instead of
a global optimization. they do not consider the e®ects of a decision on the
next steps in the execution, but merely look at the currently available set of
possible decisions and take the best one out of it. for instance, in the initial
situation of figure 6(b), two operations are executable. when deciding on
the next operation to be executed only those two operations are considered
without looking at the further, possible e®ects of the choice for one of the
two. based on the characteristics of the two operations the best performing
one with respect to the selected criterion is selected.
based on production planning heuristics we have developed some local decision
strategies for the direct execution of a pdm. we have drawn inspiration from
sequencing and scheduling rules in the ¯eld of logistics and production plan-
ning [26,40]. short-range production planning is a method to decide, a priori,
which resource is going to perform which jobs in which order for production
systems with a shop structure (i.e. °ow shop, job shop, or open shop) [40].
production planning problems are usually too large to be solved mathemati-
cally and researchers therefore have developed pragmatic ways (e.g. heuristics)
that approximate the desired solution to a scheduling problem. many di®erent
20strategies or rules exist to schedule jobs that have to be performed by a ma-
chine [26,40]. well-known strategies are, for instance, first come first served
(fcfs) or earliest due date (edd) [40]. the following decision strategies
can be applied to our selection problem of ¯nding the next operation in the
execution of a pdm:
²random - the operation is randomly selected from the set of executable
operations (cf. [26]).
²lowest cost - the operation with the lowest cost is selected.
²shortest processing time - the operation with the shortest duration is chosen
(cf. spt de¯ned in [26]).
²lowest failure probability - the operation with the lowest probability of not
being performed successfully is chosen.
²shortest distance to root element - the operation with the shortest distance
to the root element (measured in the total number of operations) is selected.
the distance of an operation to the root element is the `shortest path' from
this operation to an operation that produces the root element. the distance
to the root element can be measured as the total number of operations to
the root element (cf. fopnr de¯ned in [26]).
²shortest remaining processing time - the operation with the shortest re-
maining processing time is chosen. the shortest remaining processing time
is another form of the distance to the root element. in this case the pro-
cessing times of the operations on the path to the root element are added
up (cf. sr de¯ned in [26]).
if, for example, a lowest cost strategy was used for decision making on the
initial situation of the mortgage example in figure 6(b) then op02 would
have been selected since the cost for op02 are lower than the cost for op03
(i.e. 5.0 vs. 9.0). if a shortest processing time strategy was used op03 would
have been selected and with a shortest distance to root element strategy also
op03 would have been chosen.
the above strategies present ways to select the next step based on a single
strategy, i.e. only one performance goal is considered. a more advanced way
to use these simple selection strategies is by combining them. with a single
strategy there may be several candidates available for selection with the same
value for the performance goal. to distinguish between the operations that all
have an optimal value based on the ¯rst strategy, one can use another strategy
to complement the ¯rst one. for instance, if the lowest cost strategy leads to
three operations with the same minimal execution cost, another strategy (e.g.
lowest failure probability) may be used to rank these three operations and ¯nd
the best one among the three. additionally, weighted criteria can be used. for
instance, if the processing time and the execution cost are equally important
for the selection of an operation, the selection strategy can be based on an
equal weight (0.5 vs 0.5) for both performance criteria.
21(a) total cost: 5.0 + 5.0 = 10.0.
 (b) total cost: 9.0.
figure 6. two di®erent execution paths leading to the end product of the pdm.
the cost of executing an operation are presented in table 1
using the strategies presented above, the selection of the next candidate for
execution is optimized locally (i.e. within the set of currently executable op-
erations); the e®ect of the selected operation on future steps is not taken into
account6. such a local optimization may lead to a less desirable situation if
we consider the overall performance of the case. consider, for instance, the
execution steps for the mortgage example with respect to the total execution
cost. the ¯rst execution sequence contains op02 followed by op01. the total
cost of this execution are: 5 :0 + 5 :0 = 10 :0. the total cost of the alternative
execution path containing only op03 are 9 :0. so, the cost of the second exe-
cution path are lower. selecting the best candidate based on the lowest cost
selection strategy in this case does not lead to the best overall decision for the
case considering the total cost of execution (see figure 6). however, many of
these pragmatic heuristics are proven to reach a near-optimal solution [26,32].
to assess our approaches, a comparison between some local strategies and the
global decision strategy is made in the next section.
5 evaluation
in this section, we evaluate the two proposed approaches based on the mort-
gage example. in order to assess the performance of the global and local de-
cision strategies, we compare their results using two performance criteria. we
6note that this is comparable to a situation in the mdp in which there is only
one decision left to the end of the process, i.e. t= 1
22consider a situation in which the goal is to minimize cost as well as a situation
in which the processing time is minimized.
for the global decision strategy, an expected value of each of these performance
criteria can be calculated based on the mdp (see also de¯nition 3.1). since
the mortgage example is small enough we are able to compute a complete
state space7and decision strategy for the mdp derived from the pdm. to
do so, we used the prototype work°ow system presented in section 6.
the performance of the local decision strategies is measured through simula-
tion. in this simulation study, we have executed several simulation runs per
local decision strategy. a simulation run corresponds to one complete execu-
tion of the pdm of the mortgage example. for each execution the total execu-
tion cost and total processing time were determined. per strategy we collected
300 samples (i.e. n= 300) and constructed 90%-con¯dence intervals [23]. in
the next section, the simulation model is explained ¯rst. next, the simulation
results are compared to the results of the global selection strategies.
5.1 simulation model
the simulation model for executing a pdm describes the functional design
of a tool supporting the direct execution of a pdm based on a local decision
strategy. the simulation model is represented by a colored petri net (cpn,
[16]) and has developed using cpn tools [10]. the model takes care of a
correct step-by-step execution of the pdm as was illustrated in figure 2. this
means that the functional design ensures that only executable operations are
executed, that no duplicate data element values are produced, and that only
one operation at a time is performed. it does not deal with performance and
the selection of the best operation for the next step. the structure of the
model is generic since the model does not need to be changed for a di®erent
pdm or a di®erent selection strategy. the pdm is added to the model as a
variable and the selection strategy as a function. this section describes the
cpn model on a high level. for more details we refer to [44,45].
the main level of the cpn model is depicted in figure 7. it contains eight
places and three transitions. all three transitions are sub processes in which
the actions to be taken are described in detail. for a detailed description of
these subprocesses we refer to [44,45]. the main execution stream in the model
is indicated by thick lines: first the executable operations are determined.
then one of the executable operations is selected based on the local decision
strategy that was chosen. the selected operation is executed. if the execution
7we take the initial situation in which no input data element values are available,
i.e. (fg;fg;fg).
23op01, op04, op07 
op02, op03 
b,d,f,g,h 
4 13 figure 7. the main level of the simulation model, represented by a colored petri
net (cpn). the main execution stream of the simulation model is indicated by
thick lines. also, the initial situation of figure 2(b) is depicted by tokens in the
model.
of the operation was successful, the data element and its value are stored in
the place available data elements and the execution cost and execution time
for this operation are added to the total cost and duration of the process. if
the execution was not successful, only cost and duration are increased; no data
element is added to the set of available data elements . next, the executable
operations can be executed again and this procedure is repeated until the end
product is produced or no executable operations remain.
5.2 comparison of decision strategies
the results of the simulation study are shown in figure 8. the ¯rst diagram
shows the results for the cost performance criterion. con¯dence intervals of the
total cost resulting from executions under a lowest cost and a random strategy
are given. according to the simulation results, the lowest cost strategy has a
246789101112
7.54 
lowest cost strategy random strategy 8.11 8.67 
7.55 10.71 11.22 
10.21 total cost (a) total cost
89101112131415
shortest processing time str. random strategy 9.75 13.94 
8.58 10.37 
9.13 14.40 
13.48 total processing time 
(b) total processing time
figure 8. some results of the simulation study.
mean of 8 :11. the 90%-con¯dence interval has a lower bound 7 :55 and an
upper bound of 8 :67. the total cost under a random strategy has a mean
of 10:71 (between 10 :21 and 11 :22 according to the 90%-con¯dence interval).
since these con¯dence intervals do not overlap, we may conclude that a lowest
cost strategy leads to lower total cost than a random selection strategy. besides
the comparison of the local strategies we can also compare the outcome of the
local strategies to the optimal solution resulting from the mdp. the total
expected cost for executing the pdm of the mortgage example are 7 :54 (see
horizonal line in figure 8(a)). figure 8 shows that a lowest cost strategy closely
approaches the optimal solution when a minimal cost strategy is selected in
the mdp.
25the second diagram depicts the results for the processing time performance
criterion. the con¯dence intervals for the total processing time under a short-
est processing time strategy and under a random strategy are given. the total
processing time under a shortest processing time strategy has a mean of 9 :75,
a lower limit of 9 :13 and an upper limit of 10 :37. the random strategy has
a mean of 13 :94, a lower limit of 13 :48 and an upper limit of 14 :40. clearly,
the shortest processing time strategy performs better than a random strat-
egy to minimize the total processing time. the results of the local decision
strategies can again be compared to the expected processing time achieved by
the global decision strategy obtained by the mdp: 8.58 (see horizonal line in
figure 8(b)). the shortest processing time strategy approaches the optimal
solution compared to a minimal processing time decision strategy in the mdp.
we conclude from this simulation study that (i) using a heuristic (e.g. a lowest
cost strategy to minimize cost) leads to better results than random selection
of operations, and (ii) the outcomes of the heuristics closely approximate the
optimal solution calculated by an mdp.
6 system support
in this section we describe the work°ow system that we have developed for
product-based work°ow support. it allows for the direct execution of a pdm
by guiding the user through all steps to the end product. the system presents
execution recommendations to the user based on the selected decision strategy
and the current state of a case. section 6.1 explains the architecture of our
work°ow system. next, it is explained how the global and local strategies are
supported by this system.
6.1 architecture
our approach builds on prom and declare.8prom [2,12] was initiated as
a framework for process mining , but in recent years it has evolved into a broad
and powerful process analysis tool supporting all kinds of analyses related to
business processes [12]. prom as a plug-able architecture. prom 5.2 has 286
plug-ins, each realizing a particular type of functionality, e.g., the ®miner
plug-in is able to discover a process model from event logs and the confor-
mance checker plug-in is able to measure the quality of a model in relation to
an event log. declare is a work°ow management system [27,28,29]. de-
8prom can be downloaded from www.processmining.org . declare can be
downloaded from http://www.win.tue.nl/declare/ .
26pdm pdm 
recommendation  
service framework worklist prom declare
recommendation 
query 
declare process modelfigure 9. an overview of the architecture of the work°ow system based on prom
and declare.
clare is based on a declarative approach to business process modeling and
execution and therefore provides more °exibility than conventional work°ow
management systems do. while the mainstream work°ow management sys-
tems use a procedural approach where every activity needs to be triggered,
declare starts from the viewpoint that \anything is allowed unless explic-
itly forbidden".
to realize a work°ow system for product-based work°ow support, we use
declare as-is and added several plug-ins to prom. declare is used to
o®er work to end users and could be replaced by another work°ow system.
however, we selected declare because it is easy to specify work°ow models
that do not impose any control-°ow constraints, i.e., from the viewpoint of the
process any sequence of activities is possible (unless explicitly forbidden). an-
other reason for selecting declare is the connection to prom which allows
to combine prom's analysis and reasoning capabilities with the °exibility of
declare. declare does not know about data and dependencies between
data elements, i.e., the pdm is only known to prom. prom uses a so-called
recommendation service , the pdm, and knowledge about the history of cases,
to inform declare about recommended operations. such a recommenda-
tion service (that is driven by a pdm and the availability of data) replaces
the conventional control-°ow oriented work°ow engine. two recommendations
services have been realized using prom's plug-able architecture: one using the
global mdp approach and one using local decision strategies.
an overview of the architecture of our system is shown in figure 9. as a ¯rst
step in the use of the pdm-based work°ow system, a pdm is loaded into
the prom framework and exported to a declare model. this declare
model solely contains the operations of the pdm as activities and their input
and output data elements. thus, no control °ow is added to the declare
27model, i.e. the declare activities are not related to each other in any
way. then, the prom pdm recommendation service is started and a strategy
is selected by the user. actual cases can be handled after the declare
model has been loaded into the declare framework and the declare
worklist has been started. the declare framework communicates with the
prom recommendation service by sending queries . such a query contains the
current state of the case in terms of executed activities and available data
element values. based on this information, the pdm recommendation service
calculates which operation is the best candidate to be executed for the case
with respect to the selected decision strategy. the result of this calculation
is sent back to the declare framework as a recommendation . finally, this
recommendation is shown to the user in the worklist of declare. the user
may then follow up on the recommendation and execute the recommended
operation. when the operation is executed a new query is sent to the prom
recommendation service.
two di®erent implementations of the pdm recommendation service have been
developed. the ¯rst one is based on the global decision strategies introduced
in section 3. the second implementation uses the local decision strategies as
described in section 4 to generate recommendations for a query. both imple-
mentations are described in more detail in the next sections.
6.2 global decision strategies
in case a global decision strategy based on an mdp is chosen for generat-
ing recommendations, the user ¯rst has to calculate the state space and the
optimal decision strategy in prom (see figure 10). next, the recommenda-
tion service in prom can be started. also, the declare framework and
the declare worklist are started. the user ¯lls out the values for the leaf
data elements. suppose we take the same initial situation for the mortgage
example as before (i.e. values for b,d,f,g, and hare available and eis
not available), then a query containing the set of executable operations (i.e.
op02; op03) and a set of available data elements and their values is sent to
prom. prom determines a recommendation based on the calculated global
decision strategy (i.e. op03 under a minimize cost strategy) and sends it to
declare. in the declare worklist, the recommendations are presented
(see figure 11). the ¯rst one is the recommended activity according to the
calculated strategy. the others are second best options. each recommendation
also has a ¯eld called `rationale' in which the total expected cost or processing
time to ¯nish the process is shown.
28figure 10. on the right hand side, this screenshot of prom shows the complete
state space that was computed for the mortgage example. in the lower left corner
the user can select the performance objective to be optimized (e.g. minimize cost,
or minimize processing time) via a drop-down menu. next, the decision strategy is
calculated.
figure 11. two recommended activities are shown for the process which is in the
state where all leaf operations have been executed and the values for data elements
b,d,f,g, and hare available. based on the global decision strategy calculated
by using the mdp, op03 is recommended as the next operation to be executed (cf.
vn(3) and fn(3), for n¸2, in table 3 and 4). note that all executable operations
are ranked with respect to the performance objective: the second best next step is
op02. other operations are not executable.
296.3 local decision strategies
in the pdm recommendation service based on local decision strategies, the
user can immediately select one of the strategies introduced in section 4 via
a drop-down menu. once the strategy has been selected, the recommendation
service can be started. the execution of the process based on these recommen-
dations is similar to the execution based on the global strategies described
above. given the state of the case, the recommendation service determines
which operations are executable and which one of these is the best choice con-
sidering the selected local decision strategy. a list of all executable operations
is presented with the best next step listed ¯rst. the user may decide whether
or not to follow the recommendation and execute a next step. in any case, the
recommendation service will again calculate a recommendation for the new
state of the process until the end product is produced.
a detailed description of a pdm execution example using the prototype with
a local decision strategy can be found in [44]. note that it is possible to
change a local decision strategy during the execution of a case. this is useful,
for example, if a company decides to switch from a low cost strategy to a
strategy focusing on a short throughput time to be able to deal with extra
case arrivals as quickly as possible. in contrast to this, changing a global
strategy during the execution of a case is not allowed, since this would force
the system to recalculate the complete strategy. recalculation may take some
time and therefore is not acceptable at run-time.
7 related work
most of the work°ow approaches described in literature and supported by
commercial systems and academic prototypes assume a procedural approach
[3]. although there are huge di®erences in the expressiveness and the suitabil-
ity of procedural languages ranging from yawl and bpmn to bpel and
adept, the starting point of all these languages is the modeling of control-
°ow dependencies among tasks. few alternative approaches have been pro-
posed. for example, the declare system supports a more declarative style
of modeling grounded in ltl [27,28,29]. however, also declare focuses
on control-°ow dependencies among tasks. this paper proposes to start from
data and dependencies between data elements. the pdm has a similar role
as the bill-of-material (bpm) in production planning. this relation has been
explored in the nineties [1,30]. however, no concrete work°ow support was
provided so far. in our earlier work [1,34,35,44] we showed that in some cases
the pdm can be converted into procedural model. however, as indicated in
this paper this has the drawback that logical dependencies and performance
30related concerns get mixed and it becomes impossible to dynamically change
the strategy.
also related is the work on case handling as it is supported by systems such
as bpm jone [5]. in the case handling paradigm the availability of data also
plays a dominant role. however, hard-coded control-°ow dependencies need
to be added to steer the user. the case handling paradigm is one of many
approaches aiming at providing °exibility in work°ows. clearly, the direct
execution of a pdm also o®ers °exibility. however, most of the literature
focusing on work°ow °exibility assumes a procedural language and changes of
the underlying model. see for [46,37] for related work and typical °exibility
mechanisms.
recently, there has been revival of approaches that balance data and process
aspects, cf. the artifact-centric approach [7] and the proclets approach [4].
however, these approaches do not use the data dependencies as a way to
replace control-°ow.
most related to our work is the work by kress and seese on executable product
models [18,19]. this approach is based on our de¯nition of a pdm [1,34,35]
and the authors also propose to directly execute the pdm. kress and seese
combine this with multi-agent systems, reinforcement learning, and genetic
algorithms. the core idea is to learn how to best execute the pdm to reach
particular goals.
the work°ow solution presented in this paper combines declare [28] and
prom [2,12]. the core idea is that a recommendation service in prom provides
guidance to users of the declare system. such a recommendation-based
approach was proposed in [38] and our current system is using this idea. how-
ever, the recommendation approach presented in [38] is not using a pdm.
instead a model is learned and it is assumed that all logical dependencies and
other constraints are handled outside of the recommendation service. hence,
this approach is not data driven and serves as an add-on rather than as a
full-°edged work°ow engine. the recommendation approach presented in [38]
is closely linked to recommender systems [8,9,36]. recommender systems are
widely used in other domains such as information ¯ltering. they are used to
recommend items (¯lms, television, video on demand, music, books, news, im-
ages, web pages, products, etc.) that are likely to be of interest to the user.
these systems typically do not consider a process, i.e., the creation of a prod-
uct using a sequence operations. the broader area of web mining, i.e., the
application of data mining techniques to discover patterns by observing users
of the web [15], has the same characteristic. therefore, these techniques can-
not be applied to work°ow management. moreover, these approaches aim at
analysis rather than execution support involving data and processes.
318 conclusion
this paper presented a new approach to work°ow execution on the basis
of a product description, named the product data model (pdm). instead
of aiming at the derivation of a work°ow design that is in general the best
possible way to generate an informational product, the pdm itself is proposed
as the vehicle to steer a work°ow's execution. based on data element values
readily available for a speci¯c case on the one hand and a selected strategy
on the other hand, this approach recommends the next step that should be
performed for the case. there is a clear separation of concerns at work here:
the product data model is based on functional requirements while the selected
strategy focuses on performance (e.g. minimizing costs or time). therefore, the
execution of one case can be still dynamic and °exible, i.e. changing strategies
along the execution.
we have introduced two types of strategies to calculate the recommendations:
(i) a global decision strategy, which takes into account the e®ect of the current
decision that is made on future decisions, and (ii) a number of local decision
strategies, which only look at the set of directly available, executable steps.
the ¯rst approach is computationally demanding and may be infeasible for
large decision problems, but presents the overall best decision for a case. the
second approach is much faster and more °exible, but may result in sub-
optimal solutions. we have assessed the performance of several strategies by
a simulation study, showing that the local decision strategies indeed reach a
near-optimal solution to the global decision strategy. finally, the feasibility of
the presented ideas is shown by the description of a fully operational prototype
that supports the approach presented in this paper.
a limitation to this work is that the di®erent decision strategies presented
in this paper all focus on improving performance while considering a case in
isolation. the best decisions are de¯ned in terms of the performance objective
on the case level, e.g. the minimization of throughput time or cost for a single
case. optimization on the process level with respect to e.g. the utilization of
the process, or the optimal distribution of work among resources, is not con-
sidered yet. kress et al. [18,19] propose an approach to optimize the whole
process with an agent based system. however, they do not consider the per-
formance of a single case. moreover, the presented decision strategies are not
yet able to deal with parallel execution of operations. concurrency would lead
to di±culties with di®erent values for the same data element. in general, data
updates are an issue for the use of pdms and other data-driven approaches.
note that current data-driven work°ow management systems, e.g. the case-
handling system flower, prevent parallel executions for the same case by
blocking the whole case as soon as someone is working on it.
32for future work we plan to cooperate with our industrial partners to incorpo-
rate the direct execution of a pdm and the decision strategies in a commercial
tool. the availability of such a tool will certainly enhance the practical appli-
cability of the ideas, which will be useful to further evaluate the approach in
practice.
acknowledgements
we would like to thank maja pesic for her work on declare. moreover, we
thank the many people working on prom. their work enabled us to realize
the work°ow solution presented in this paper.
references
[1]w.m.p. van der aalst. on the automatic generation of work°ow processes
based on product structures. computers in industry , 39:97{111, 1999.
[2]w.m.p. van der aalst, b.f. van dongen, c.w. gä unther, r.s. mans, a.k. alves
de medeiros, a. rozinat, v. rubin, m. song, h.m.w. verbeek, and a.j.m.m.
weijters. prom 4.0: comprehensive support for real process analysis. in
j. kleijn and a. yakovlev, editors, application and theory of petri nets and
other models of concurrency (icatpn 2007) , volume 4546 of lecture notes
in computer science , pages 484{494. springer-verlag, berlin, 2007.
[3]w.m.p. van der aalst, a.h.m. ter hofstede, b. kiepuszewski, and a.p. barros.
work°ow patterns. distributed and parallel databases , 14(1):5{51, 2003.
[4]w.m.p. van der aalst, r.s. mans, and n.c. russell. work°ow support
using proclets: divide, interact, and conquer. ieee bulletin of the technical
committee on data engineering , 32(3):16{22, 2009.
[5]w.m.p. van der aalst, m. weske, and d. grä unbauer. case handling: a new
paradigm for business process support. data and knowledge engineering ,
53(2):129{162, 2005.
[6]k. bhattacharya, c. gerede, r. hull, r. liu, and j. su. towards formal analysis
of artifact-centric business process models. lecture notes in computer science ,
4714:288, 2007.
[7]k. bhattacharya, c. gerede, r. hull, r. liu, and j. su. towards formal
analysis of artifact-centric business process models. in g. alonso, p. dadam,
and m. rosemann, editors, international conference on business process
management (bpm 2007) , volume 4714 of lecture notes in computer science ,
pages 288{304. springer-verlag, berlin, 2007.
33[8]r. burke. the wasabi personal shopper: a case-based recommender system.
inproceedings of the 11th conference on innovative applications of arti¯cial
intelligence , pages 844 { 849. american association for arti¯cial intelligence,
1999.
[9]r. burke. a case-based reasoning approach to collaborative filtering. in
e. blanzieri and l. portinale, editors, proceedings of the 5th european workshop
on advances in case-based reasoning (ewcbr 2000) , volume 1898 of lecture
notes in computer science , pages 370{379. springer-verlag, berlin, 2000.
[10]cpn tools home page. http://wiki.daimi.au.dk/cpntools/cpntools.wiki.
[11]t.h. davenport. process innovation : reengineering work through information
technology . harvard business school press, boston, 1993.
[12]b.f. van dongen, a.k. alves de medeiros, h.m.w. verbeek, a.j.m.m. weijters,
and w.m.p. van der aalst. the prom framework: a new era in process mining
tool support. in g. ciardo and p. darondeau, editors, application and theory
of petri nets 2005 , volume 3536 of lecture notes in computer science , pages
444{454. springer-verlag, berlin, 2005.
[13]m. dumas, w.m.p. van der aalst, and a.h.m. ter hofstede. process-
aware information systems: bridging people and software through process
technology . wiley & sons, 2005.
[14]m. hammer and j. champy. reengineering the corporation . nicolas brealey
publishing, london, 1993.
[15]p. hofgesang. online mining of web usage data: an overview. in web
mining applications in e-commerce and e-services , volume 172 of studies in
computational intelligence , pages 1{24. springer-verlag, berlin, 2009.
[16]k. jensen. coloured petri nets. basic concepts, analysis methods and practical
use. volume 1, basic concepts . monographs in theoretical computer science.
springer-verlag, berlin, 1997.
[17]h.j. johansson, p. mchugh, a.j. pendlebury, and w.a. wheeler. business
process reengineering: breakpoint strategies for market dominance . wiley &
sons, 1993.
[18]m. kress, j. melcher, and d. seese. introducing executable product models for
the service industry. in proceedings of the 40th hawaii international conference
on system sciences (hicss '07) , pages 1{10. ieee computer society, 2007.
[19]m. kress and d. seese. executable product models - the intelligent way.
inproceedings of the ieee international conference on systems, man and
cybernetics (isic '07) , pages 1987 { 1992, 2007.
[20]m. mcdonald, m. blosch, t. ja®arian, l. mok, and s. stevens. growing it's
contribution: the 2006 cio agenda. gartner january , 2006.
[21]m. mcdonald and t. nunno. creating enterprise leverage: the 2007 cio
agenda. gartner january , 2007.
34[22]m. mcdonald, t. nunno, and d. aron. making the di®erence: the 2008 cio
agenda. gartner january , 2008.
[23]d.c. montgomery and g.c. runger. applied statistics and probability for
engineers . john wiley and sons, new york, 1999.
[24]b. mutschler, m. reichert, and j. bumiller. unleashing the e®ectiveness of
process-oriented information systems: problem analysis, critical success factors
and implications. ieee transactions on systems, man, and cybernetics (part
c), 38(3):280{291, 2008.
[25]j.a. orlicky. structuring the bill of materials for mrp. production and
inventory management , pages 19{42, dec 1972.
[26]s.s. panwalkar and w. iskander. a survey of scheduling rules. operations
research , 25:45{61, 1977.
[27]m. pesic and w.m.p. van der aalst. a declarative approach for flexible
business processes. in j. eder and s. dustdar, editors, business process
management workshops, workshop on dynamic process management (dpm
2006) , volume 4103 of lecture notes in computer science , pages 169{180,
berlin, 2006. springer-verlag.
[28]m. pesic, m.h. schonenberg, and w.m.p. van der aalst. declare: full
support for loosely-structured processes. in proceedings of the 11th ieee
international enterprise distributed object computing conference (edoc
2007) , pages 287{300. ieee computer society, 2007.
[29]m. pesic, m.h. schonenberg, n. sidorova, and w.m.p. van der aalst.
constraint-based work°ow models: change made easy. in r. meersman and
z. tari, editor, on the move to meaningful internet systems 2007: otm 2007
confederated international conferences, part i. , volume 4803 of lecture notes
in computer science , pages 77{94, 2007.
[30]e.a.h. platier. a logistical view on business processes: bpr and wfm
concepts . phd thesis, eindhoven university of technology, eindhoven, 1996.
(in dutch).
[31]m.l. puterman. markov decision processes . wiley, new york, 1994.
[32]r. ramasesh. dynamic job shop scheduling: a survey of simulation research.
omega international journal of management science , 18(1):43{57, 1990.
[33]h.a. reijers. product-based design of business processes applied within the
¯nancial services. journal of research and practice in information technology ,
34(2):110{122, 2002.
[34]h.a. reijers. design and control of work°ow processes: business process
management for the service industry , volume 2617 of lecture notes in
computer science . springer-verlag, berlin, 2003.
[35]h.a. reijers, s. limam mansar, and w.m.p. van der aalst. product-based
work°ow design. journal of management information systems , 20(1):229{262,
2003.
35[36]p. resnick and h.r. varian. recommender systems. communication of the
acm , 40(3):56{58, 1997.
[37]h. schonenberg, r. mans, n. russell, n. mulyar, and w.m.p. van der aalst.
process flexibility: a survey of contemporary approaches. in j. dietz,
a. albani, and j. barjis, editors, advances in enterprise engineering i ,
volume 10 of lecture notes in business information processing , pages 16{30.
springer-verlag, berlin, 2008.
[38]h. schonenberg, b. weber, b.f. van dongen, and w.m.p. van der aalst.
supporting flexible processes through log-based recommendations. in
m. dumas, m. reichert, and m.-c. shan, editors, proceedings of the 6th
international conference on business process management (bpm 2008) ,
volume 5240 of lecture notes in computer science , pages 51{66. springer-
verlag, berlin, 2008.
[39]a. sharp and p. mcdermott. work°ow modeling: tools for process
improvement and application development . artech house, 2nd edition, 2009.
[40]e.a. silver, d.f. pyke, and r. peterson. inventory management and production
planning and scheduling . john wiley and sons, hoboken, nj, 1998.
[41]h.c. tijms. a first course in stochastic models . wiley, chichester, england,
2003.
[42]p. trkman. the critical success factors of business process management.
international journal of information management , 2009.
[43]m. vakola and y. rezgui. critique of existing business process re-engineering
methodologies. business process management journal , 6(3):238{50, 2000.
[44]i. vanderfeesten. product-based design and support of work°ow processes .
phd thesis, eindhoven university of technology, eindhoven, the netherlands,
2009.
[45]i. vanderfeesten, w.m.p. van der aalst, and h.a. reijers. modeling a product-
based work°ow system in cpn tools. in k. jensen, editor, proceedings of the
sixth workshop on the practical use of coloured petri nets and cpn tools
(cpn 2005) , volume 576 of daimi , pages 99{118, aarhus, denmark, october
2005. university of aarhus.
[46]b. weber, m. reichert, and s. rinderle-ma. change patterns and
change support features: enhancing flexibility in process-aware information
systems. data and knowledge engineering , 66(3):438{466, 2008.
36