worklets: a service-oriented implementation of
dynamic flexibility in work°ows
michael adams1, arthur h. m. ter hofstede1, david edmond1,
and wil m. p. van der aalst1;2
1business process management group
queensland university of technology, brisbane, australia
fm3.adams,a.terhofstede,d.edmond g@qut.edu.au
2department of technology management
eindhoven university of technology, eindhoven, the netherlands
w.m.p.v.d.aalst@tm.tue.nl
abstract. this paper presents the realisation, using a service oriented
architecture, of an approach for dynamic °exibility and evolution in
work°ows through the support of °exible work practices, based not on
proprietary frameworks, but on accepted ideas of how people actually
work. a set of principles have been derived from a sound theoretical base
and applied to the development of worklets , an extensible repertoire of
self-contained sub-processes aligned to each task, from which a dynamic
runtime selection is made depending on the context of the particular
work instance.
1 introduction
work°ow management systems are used to con¯gure and control structured
business processes from which well-de¯ned work°ow models and instances can
be derived [1, 2]. however, the proprietary process de¯nition frameworks im-
posed make it di±cult to support (i) dynamic evolution (i.e. modifying process
de¯nitions during execution) following unexpected or developmental change in
the business processes being modelled [3]; and (ii) deviations from the prescribed
process model at runtime [4{6].
without support for dynamic evolution, the occurrence of a process deviation
requires either suspension of execution while the deviation is handled manually,
or an entire process abort. however, since most processes are long and complex,
neither manual intervention nor process termination are satisfactory solutions
[7]. manual handling incurs an added penalty: the corrective actions undertaken
are not added to `organisational memory' [8, 9], and so natural process evolution
is not incorporated into future iterations of the process. other evolution issues
include problems of migration, synchronisation and version control [4, 10].
these limitations mean a large subset of business processes do not easily
map to the rigid modelling structures provided [11], due to the lack of °exibility
inherent in a framework that, by de¯nition, imposes rigidity. process models are
`system-centric', or straight-jacketed [12] into the supplied framework, rather2 adams et. al.
than truly re°ecting the way work is actually performed [13]. as a result, users
are forced to work outside of the system, and/or constantly revise the static
process model, in order to successfully support their activities, thereby negating
the e±ciency gains sought by implementing a work°ow solution in the ¯rst place.
since the mid-nineties many researchers have worked on problems related to
work°ow change (cf. section 7). this paper is based on and extends the approach
proposed in [14]. it introduces a realisation of `worklets' , an extensible reper-
toire of self-contained sub-processes and associated selection rules, grounded in
a formal set of work practice principles called activity theory , to support the
modelling, analysis and enactment of business processes. this approach directly
provides for dynamic change and process evolution without having to resort to
o®-system intervention and/or system downtime. it has been implemented as a
discrete service for the well-known, open-source work°ow environment yawl
[15, 16] using a service oriented architecture (soa), and as such its applica-
bility is not limited to that environment. also, being open-source, it is freely
available for use and extension.
the paper is organised as follows: section 2 provides a brief overview of
activity theory and lists relevant principles derived from it by the authors,
then introduces the worklet paradigm. section 3 describes the implementation
of the discrete worklet service. section 4 details the worklet service architecture.
section 5 discusses process de¯nition methods, while section 6 describes how
the worklet approach utilises ripple down rules (rdr) to achieve contextual,
dynamic selection of worklets at runtime. section 7 discusses related work, and
¯nally section 8 outlines future directions and concludes the paper.
2 achieving flexibility through worklets
work°ow management systems provide support for business processes that are
generally predictable and repetitive. however, the prescriptive, assembly-line
frameworks imposed by work°ow systems limit the ability to model and enact
°exible work practices where deviations are a normal part of every work activ-
ity [12, 17]. for these environments, formal representations of business processes
may be said to provide merely a contingency around which tasks can be formu-
lated dynamically [18], rather than a prescriptive blueprint that must be strictly
adhered to.
rather than continue to try to force business processes into in°exible frame-
works (with limited success), a more adaptable approach is needed that is based
on accepted ideas of how people actually work.
a powerful set of descriptive and clarifying principles that describe how work
is conceived, performed and re°ected upon is activity theory , which focusses
on understanding human activity and work practices, incorporating notions of
intentionality, history, mediation, collaboration and development [19]. (a full
exploration of activity theory can be found in [20, 21]). in [22], the current
authors undertook a detailed study of activity theory and derived from it adynamic flexibility using worklets 3
set of principles that describe the nature of participation in organisational work
practices. brie°y, the relevant principles are:
1.activities (i.e. work processes) are hierarchical (consist of one or more ac-
tions), communal (involve a community of participants working towards a
common objective), contextual (conditions and circumstances deeply a®ect
the way the objective is achieved), dynamic (evolve asynchronously), and
mediated (by tools, rules and divisions of labour).
2.actions (i.e. tasks) are undertaken and understood contextually. a repertoire
of applicable actions is maintained and made available for each action of an
activity; the activity is performed by making contextual choices from the
repertoire of each action in turn.
3.a work plan is not a prescription of work to be performed, but merely a
guide which may be modi¯ed during execution depending on context.
4.deviations from a plan will naturally occur with every execution, giving rise
to learning experiences which can then be incorporated into future instanti-
ations of the plan.
consideration of these derived principles have led to the conception, develop-
ment and implementation of a °exible work°ow support system that:
{regards the process model as a guide to an activity's objective, rather than
a prescription for it;
{provides a repertoire (or catalogue) of applicable actions to be made available
for each task at each execution of a process model;
{provides for choices to be made dynamically from the repertoire at runtime
by considering the speci¯c context of the executing instance; and
{allows the repertoire of actions to be dynamically extended at runtime, thus
incorporating unexpected process deviations, not only for the current in-
stance, but for other current and future instantiations of the process model,
leading to natural process evolution.
thus, each task of a process instance may be linked to an extensible repertoire
of actions, one of which will be contextually chosen at runtime to carry out the
task. in this work, we present these repertoire-member actions as \worklets" .
in e®ect, a worklet is a small, self-contained, complete work°ow process which
handles one speci¯c task (action) in a larger, composite process (activity)1. a
top-level or parent process model is developed that captures the entire work°ow
at a macro level. from that manager process, worklets are contextually selected
and invoked from the repertoire of each task when the task instance becomes
enabled during execution.
in addition, new worklets for handling a task may be added to the repertoire
at any time (even during process execution) as di®erent approaches to com-
pleting a task are developed, derived from the context of each process instance.
1in activity theory terms, a worklet may represent one action within an activity, or
may represent an entire activity.4 adams et. al.
importantly, the new worklet becomes part of the process model for all current
and future instantiations, avoiding issues of version control. in this way, the
process model undergoes a dynamic natural evolution.
3 the worklet custom service for yawl
the worklet dynamic process selection service has been implemented as a
yawl custom service [15, 16]. the yawl environment was chosen as the im-
plementation platform since it provides a very powerful and expressive work°ow
language based on the work°ow patterns identi¯ed in [23], together with a for-
mal semantics. it also provides a work°ow enactment engine, and an editor for
process model creation, that support the control °ow, data and (basic) resource
perspectives. the yawl environment is open-source and has a service-oriented
architecture, allowing the worklet paradigm to be developed as a service inde-
pendent to the core engine. thus the deployment of the worklet service is in no
way limited to the yawl environment, but may be ported to other environ-
ments by making the necessary amendments to the service interface. as such,
this implementation may also be seen as a case study in service-oriented com-
puting whereby dynamic °exibility in work°ows, orthogonal to the underlying
work°ow language, is provided.
custom yawl services interact with the yawl engine through xml/http
messages via certain interface endpoints, some located on the yawl engine side
and others on the service side. speci¯cally, custom services may elect to be no-
ti¯ed by the engine when certain events occur in the life-cycle of nominated
process instantiations (i.e. when a workitem becomes enabled, when a workitem
is cancelled, when a case completes). on receiving a workitem-enabled event, the
custom service may elect to `check-out' the workitem from the engine. on doing
so, the engine marks the workitem as executing and e®ectively passes operational
control for the workitem to the custom service. when the custom service has
¯nished processing the workitem it will check it back in to the engine, at which
point the engine will mark the workitem as completed , and proceed with the
process execution.
the worklet service utilises these interactions by dynamically substituting an
enabled workitem in a yawl process with a contextually selected worklet { a
discrete yawl process that acts as a sub-net for the workitem and so handles
one speci¯c task in a larger, composite process activity.
anextensible repertoire (or catalogue) of worklets is maintained for each
nominated task in a parent work°ow process . each time the service is invoked
for an enabled workitem, a choice is made from the repertoire based on the
data attributes and values associated with the workitem, using a set of rules to
determine the most appropriate substitution (see section 6). the workitem is
checked out of the yawl engine, the input variables of the original workitem
are mapped to the net-level input variables of the selected worklet, and then
the worklet is launched in the engine as a separate case. when the worklet has
completed, its net-level output variables are mapped back to the output variablesdynamic flexibility using worklets 5
of the original workitem, which is then checked back into the engine, allowing
the original (parent) process to continue.
the worklet executed for a task is run as a separate case in the yawl engine,
so that, from an engine perspective, the worklet and its parent are two distinct,
unrelated cases. the worklet service tracks the relationships, data mappings and
synchronisations between cases, and creates a process log that may be combined
with the engine's process logs via case identi¯ers to provide a complete opera-
tional history of each process.
worklets may be associated with either an atomic task, or a multiple-instance
atomic task. any number of worklets can form the repertoire of an individual
task, and any number of tasks in a particular speci¯cation can be associated
with the worklet service. a worklet may be a member of one or more reper-
toires { that is, it may be re-used for several distinct tasks within and across
process speci¯cations. in the case of multiple-instance tasks, a separate worklet
is launched for each child workitem. because each child workitem may contain
di®erent data, the worklets that substitute for them are individually selected,
and so may all be di®erent.
the repertoire of worklets for a task can be added to at any time, as can
the rules base used for the selection process, including while the parent process
is executing. thus the service provides for dynamic ad-hoc change and process
evolution, without having to resort to o®-system intervention and/or system
downtime, or requiring modi¯cation of the original process speci¯cation.
4 worklet service architecture
  
yawl 
engine 
 a 
b  
worklet 
service 
  
 
 rdrs  
logs  
 
yawl 
worklist 
 /computers1  
rdr  
editor 
  
yawl 
editor 
 worklet 
specs 
user 
fig. 1. external architecture of the worklet service
figure 1 shows the external architecture of the worklet service. as men-
tioned previously, the service has been implemented as a custom yawl service6 adams et. al.
[16]. the yawl engine provides a number of interfaces, two of which are used
by the worklet service. interface a provides endpoints for process de¯nition,
administration and monitoring; interface b provides endpoints for client and in-
voked applications and work°ow interoperability [16]. the worklet service uses
interface a to upload worklet speci¯cations into the engine, and interface b
for connecting to the engine, to start and cancel case instances, and to check
workitems in and out of the engine after interrogating their associated data.
the disk entities `worklet specs', `rdrs' and `logs' in figure 1 comprise
theworklet repository . the service uses the repository to store rule sets and load
them for enabled workitems; to store worklet speci¯cations for uploading to the
engine; and to store generated process and audit logs. the yawl editor is used
to create new worklet speci¯cations, and may be invoked from the rdr (ripple
down rules) editor. the rdr editor is used to create new or augment existing
rule sets, making use of certain selection logs to do so, and may communicate
with the worklet service via a jsp/servlet interface to override worklet selections
following rule set additions (see section 6).
 
 
 
 
 
 
 
 
 
 
 
 
workletselector  
 
wsgateway 
  
rdrset  
 
rdrtree 
 
 
rdrnode 
  
checkedoutitem 
 
 
checkedoutchilditem  
 
conditionevaluator  
 worklet 
service 
to yawl 
engine 
to rules 
editor 1 * 1 
1 1 
1 
* * 
* * 
fig. 2. internal architecture of the worklet service
figure 2 shows a representation of the internal architecture of the worklet
service. the workletselector object handles all interactions with the yawl
engine, and administrates the service. for each workitem that it checks out
of the engine, it creates a checkedoutitem object. in yawl, each workitem
is a `parent' of one or more child items { one if it is an atomic task, or a
number of child items in the case of a multiple instance atomic task. thus,dynamic flexibility using worklets 7
the role of each checkedoutitem object is to create and manage one or more
checkedoutchilditems , which hold information about worklet selection, data
associated with the workitem and the results of rules searches.
the workletselector, for each workitem that is checked out from the engine,
also loads from ¯le the set of rules pertaining to the speci¯cation of which the
workitem is a member into an rdrset object. at any time, there may be a
number of rdrsets loaded into the service, one for each speci¯cation for which
a workitem has been checked out. each rdrset manages one or more rdrtree
objects, each tree representing the rule tree for a particular task within the
speci¯cation, of which this workitem is an instance. in turn, each rdrtree owns
a number of rdrnode objects, which contain the actual rules, conclusions and
other data for each node of the rule tree.
when a rule tree is evaluated against the data set of a workitem, each of the
associated nodes of that tree has its condition evaluated by the conditionevalu-
ator object, which returns the boolean result to the node, allowing it to traverse
to its true or false branch as necessary. finally, the wsgateway object provides
communications via a jsp/servlet interface between the service and the rules
editor (see section 6 for more details).
5 process de¯nition
fundamentally, a worklet is nothing more than a work°ow speci¯cation that has
been designed to perform one part of a larger, parent speci¯cation. however,
it di®ers from a decomposition or sub-net in that it is dynamically assigned to
perform a particular task at runtime, while sub-nets are statically assigned at
design time. so, rather than being forced to de¯ne all possible branches in a
speci¯cation, the worklet service allows the de¯nition of a much simpler speci¯-
cation that will evolve dynamically as more worklets are added to the repertoire
for particular tasks within it.
figure 3 shows a simple example speci¯cation (in the yawl editor) for
a casualty treatment process. note that this process speci¯cation has been
intentionally simpli¯ed to demonstrate the operation of the worklet service; while
it is not intended to portray a realistic process, it is desirable to not camou°age
the subject of this paper by using a more complex process speci¯cation.
in this process, the treat task is to be substituted at runtime with the ap-
propriate worklet based on the patient data collected in the admit andtriage
tasks. that is, depending on each patient's actual physical data and reported
symptoms, we would like to run the worklet that best treats the patient's con-
dition.
each task in a process speci¯cation may be °agged to notify the worklet
service when it becomes enabled. in this example, only the treat task is °agged
so; the other tasks are handled directly by the yawl environment. so, when
a casualty treatment process is executed, the yawl engine will notify the
worklet service when the treat task becomes enabled. the worklet service will8 adams et. al.
 
 
fig. 3. parent `casualty treatment' process
then examine the data of the task and use it to determine which worklet to
execute as a substitute for the task.
a worklet speci¯cation is a standard yawl process speci¯cation, and as
such is created in the yawl editor in the usual manner. figure 4 shows a very
simple example worklet to be substituted for the treat top-level task when a
patient complains of a fever.
in itself, there is nothing special about the treat fever speci¯cation in figure
4. even though it will be considered by the worklet service as a member of
the worklet repertoire and may thus be considered a \worklet", it also remains
a standard yawl speci¯cation and as such may be executed directly by the
yawl engine without any reference to the worklet service, if desired.
 
fig. 4. the `treat fever' worklet process
the association of tasks with the worklet service is not restricted to top-level
speci¯cations. worklet speci¯cations also may contain tasks that are associated
with the worklet service and so may have worklets substituted for them, so that
a hierarchy of executing worklets may sometimes exist. it is also possible to
recursively de¯ne worklet substitutions - that is, a worklet may contain a task
that, while certain conditions hold true, is substituted by another instance of
the same worklet speci¯cation that contains the task.
any number of worklets can be created for a particular task. for the casualty
treatment example, there are currently ¯ve worklets in the repertoire for thedynamic flexibility using worklets 9
treat task, one for each of the ¯ve conditions that a patient may present with
in the triage task: fever, rash, fracture, wound and abdominal pain. in this
example, which worklet is chosen for the treat task depends on which of the ¯ve
is given a value of true in the triage task.
6 context and worklet selection
the consideration of context plays a crucial role in many diverse domains, in-
cluding philosophy, pragmatics, semantics, cognitive psychology and arti¯cial
intelligence [24]. in order to realise the worklet approach, the situated contex-
tual factors relevant to each case instance were required to be quanti¯ed and
recorded [25] so that the appropriate worklet can be `intelligently' selected from
the repertoire at runtime.
the types of contextual data that may be recorded and applied to a busi-
ness case may be categorised as follows (examples are drawn from the casualty
treatment process):
{generic (case independent): data attributes that can be considered likely
to occur within any process (of course, the data values change from case to
case). such data would include descriptors such as created when, created by,
times invoked, last invoked, current status; and role or agent descriptors such
as experience, skills, rank, history with this process and/or task and so on.
process execution states and process log data also belong to this category.
{case dependent with a-priori knowledge: that set of data that are
known to be pertinent to a particular case when it is instantiated. generally,
this data set re°ects the data variables of a particular process instance.
examples are: patient name and id, blood pressure readings, height, weight,
symptoms and so on; deadlines both approaching and expired; and diagnoses,
treatments and prescribed medications.
{case dependent with no a-priori knowledge: that set of data that
only becomes known when the case is active and deviations from the known
process occur. examples in this category may include complications that
arise in a patient's condition after triage, allergies to certain medications
and so on.
each worklet is a representation of a particular situated action, the runtime
selection of which relies on the relevant context of each case instance, derived
from case data. the worklet selection process is achieved through the use of rip-
ple down rules (rdr), which comprise a hierarchical set of rules with associated
exceptions, ¯rst devised by compton and jansen [26].
the fundamental feature of rdr is that it avoids the di±culties inherent in
attempting to compile, a-priori , a systematic understanding, organisation and
assembly of all knowledge in a particular domain. instead, it allows for general
rules to be de¯ned ¯rst with re¯nements added later as the need arises [27].
an rdr knowledge base is a collection of simple rules of the form \if condi-
tionthen conclusion " (together with other associated descriptors), conceptually10 adams et. al.
arranged in a binary tree structure. each rule node may have a false (`or')
branch and/or a true (`exception') branch to another rule node, except for the
root node, which contains a default rule and can have a true branch only. if a
rule is satis¯ed, the true branch is taken and the subsequent rule is evaluated;
if it is not satis¯ed, the false branch is taken and its rule evaluated [28]. when
a terminal node is reached, if its rule is satis¯ed, then its conclusion is taken; if
its rule is not satis¯ed, then the conclusion of the last rule satis¯ed on the path
to that node is taken. this tree traversal provides implied locality - a rule on an
exception branch is tested for applicability only if its parent (next-general) rule
is also applicable.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 0 
true 
default 
1 
fever = true 
treatfever 
2 
wound = true 
treatwound 
3 
abdominalpain = true 
treatabpain 
4 
fracture = true 
treatfracture 7 
pregnant = true 
treatlabour 
5 
rash = true 
treatrash 
6 
heartrate >= 190 
treathighheartrate condition not satisfied condition satisfied condition 
conclusion 
fig. 5. conceptual structure of a ripple down rule ( casualty treatment ex-
ample)
a work°ow process speci¯cation may contain a number of tasks, one or more
of which may be associated with the worklet service. for each speci¯cation thatdynamic flexibility using worklets 11
contains a worklet-enabled task, the worklet service maintains a corresponding
set of ripple down rules that determine which worklet will be selected as a sub-
stitute for the task at runtime, based on the current case data of that particular
instance. each worklet-enabled task in a speci¯cation has its own discrete rule
set. the rule set or sets for each speci¯cation are stored as xml data in a disk
¯le that has the same name as the speci¯cation, except with an \.xrs" extension
(xml rule set). all rule set ¯les are stored in the worklet repository.
occasionally, the worklet started as a substitute for a particular workitem,
while the correct choice based on the current rule set, is considered by a user
to be an inappropriate choice for a particular case. for example, if a patient in
a casualty treatment case presents with a rash anda heart rate of 190, while
the current rule set correctly returns the treatrash worklet, it may be more
desirable to treat the racing heart rate before the rash is attended to. in such
a case, when the worklet service begins an instance of the treatrash process, a
user may reject it by advising an administrator (via a button on their worklist)
of the inappropriate choice. thus the administrator would need to add a new
rule to the rule set so that cases that have such data (both now and in the
future) will be handled correctly.
if the worklet returned is found to be unsuitable for a particular case instance,
a new rule is formulated that de¯nes the contextual circumstances of the instance
and is added as a new leaf node using the following algorithm:
{if the worklet returned was the conclusion of a satis¯ed terminal rule, then
the new rule is added as a local exception node via a new true branch from
the terminal node.
{if the worklet returned was the conclusion of a non-terminal, ancestor node
(that is, the condition of the terminal rule was not satis¯ed), then the new
rule node is added via a new false branch from the unsatis¯ed terminal node.
in essence, each added exception rule is a re¯nement of its parent rule. this
method of de¯ning new rules allows the construction and maintenance of the
kb by \sub-domain" experts (i.e. those who understand and carry out the work
they are responsible for) without regard to any engineering or programming
assistance or skill [29].
each rule node also incorporates a set of case descriptors that describe the
actual case that was the catalyst for the creation of its rule. this case is referred
to as the `cornerstone case'. the descriptors of the cornerstone case refer to
essential attributes of a case, in this example, the sex, heart rate, age, weight
and so on of a patient. the condition for the new rule is determined by comparing
the descriptors of the current case to those of the cornerstone case of the returned
worklet and identifying a sub-set of di®erences. not all di®erences will be relevant
{ to de¯ne a new rule it is only necessary to determine the factor or factors
that make it necessary to handle the current case in a di®erent fashion to the
cornerstone case. the identi¯ed di®erences are expressed as attribute-value pairs,
using the normal conditional operators. the current case descriptors become the
cornerstone case for the newly formulated rule; its condition is formed by the12 adams et. al.
identi¯ed attribute-values and represents the context of the case instance that
caused the addition of the rule.
a separate rules editor tool has been developed to allow for the easy addition
of new rules and associated worklets to existing rule sets, and the creation of
new rule sets.
each time the worklet service selects a worklet to execute as a substitute
for a speci¯cation instance's workitem, a ¯le is created that contains certain
descriptive data about the selection process. these ¯les are stored in the worklet
repository, again in xml format. thus to add a new rule to the existing rule
set after an inappropriate selection, the particular selection ¯le for the case that
was the catalyst for the rule addition is ¯rst loaded into the rules editor.
figure 6 shows the add new rule screen of the rules editor with a selection
¯le loaded. the cornerstone case panel shows the case data that existed for the
creation of the original rule for the treatrash selection. the current case panel
shows the case data for the current case - that is, the case that is the catalyst
for the addition of the new rule. the new rule node panel is where the details
of the new rule are added. notice that the ids of the parent node and the new
node are shown as read only - the rules editor takes care of where in the rule
tree the new rule node is to be placed, and whether it is to be added as a true
child or false child node, using the algorithm described above.
 
 
 
fig. 6. rules editor (add new rule screen)dynamic flexibility using worklets 13
in this example, there are many data values that di®er between the two case
data sets shown in figure 6, such as patientid, name, sex, blood pressure
readings, height, weight and age. however, the only di®ering data item of
relevance here is heartrate - that is the only data item that, in this case, makes
the selection of the treatrash worklet inappropriate. selecting the heartrate
line in the list of current case data items will insert it to the condition ¯eld,
where it may be modi¯ed as necessary. in this case, the new rule would become,
as an example, \heartrate ¸190".
it is not necessary to de¯ne a conjunctive rule such as \rash = true and
heartrate ¸190", since this new rule will be added as an exception to the
true branch of the treatrash node. by doing so, it will only be evaluated if the
condition of its parent, "rash = true", ¯rst evaluates to true. therefore, any
rule nodes added to the true branch of a parent node become exception rules,
and thus re¯nements, of the parent rule.
after de¯ning a condition for the new rule, the name of the worklet to be
executed when this condition evaluates to true must be entered in the worklet
¯eld of the editor (refer figure 6). this input is a drop-down list that contains
the name of all the worklets currently in the worklet repository. an appropriate
worklet for this rule may be chosen from the list, or, if none are suitable, a new
worklet speci¯cation may be created.
after a new rule is added, the editor provides an administrator with the
choice to replace the previously started (inappropriate) worklet instance with
an instance of the worklet de¯ned in the new rule. if the administrator chooses
to replace the worklet, the rules editor contacts the worklet service via http
and requests the change. the service responds with a dialog similar to figure 7.
 
 
 
fig. 7. example dialog showing a successful dynamic replacement
7 related work
since the mid-nineties much research has been done on issues related to °exibility
and change in work°ow management systems (cf. the classi¯cation into ad-hoc,
administrative, and production work°ows in [30]). while it is not the intention
of this paper to provide a complete overview of the work done in this area,14 adams et. al.
reference is made here to a number of quite di®erent approaches to providing
dynamic °exibility in work°ows.
generally, commercial work°ow management systems provide various levels
of support for the decomposition of tasks and sub-processing. however, each
of the products require the model to be fully de¯ned before it can be instan-
tiated, and changes must be incorporated by modifying the model statically.
sta®ware provides `re-usable process segments' that can be inserted into any
process. sap r/3 allows for the de¯nition of `blocks' that can be inserted into
other `blocks', thus providing some support for encapsulation and reuse. cosa
supports parent-sibling processes, where data can be passed to/from a process to
a sub-process. mq work°ow allows sub-processes to be de¯ned and called stat-
ically from within a process. clearly, all of these static forms of decomposition
do not o®er support for dynamic °exibility.
among the non-commercial systems, adept [31] supports modi¯cation of
a process during execution (i.e. add, delete and change the sequence of tasks)
both at the type (dynamic evolution) and instance levels (ad-hoc changes). such
changes are made to a traditional monolithic model and must be achieved via
manual intervention. the wasa [32] system provides some support for dynamic
change, mainly focusing on scienti¯c applications. it allows an administrator
to modify a (monolithic) speci¯cation and then restart a task, but then only
at the instance level. a catalog of `skeleton' patterns that can be instantiated
or specialised at design time is supported by the werde system [5]. again,
there is no scope for specialisation changes to be made at runtime. agentwork
[33] provides the ability to modify process instances by dropping and adding
individual tasks based on events and eca rules. however, the rules do not o®er
the °exibility or extensibility of ripple down rules, and changes are limited
to individual tasks, rather than the process-for-task substitution provided by
the worklet service. also, the possibility exists for con°icting rules to generate
incompatible actions, which requires manual intervention and resolution.
it should be noted that only a small number of academic prototypes have had
any impact on the frameworks o®ered by commercial systems [34]. nevertheless,
there are some interesting commercial products that o®er innovative features
with respect to °exibility. caramba [35] supports virtual teams in their ad hoc
and collaborative processes by enabling links between artifacts (for example,
documents and database objects), business processes (activities), and resources
(persons, roles, etc.). flower supports the concept of case-handling; the pro-
cess model only describes the preferred way of doing things and a variety of
mechanisms are o®ered to allow users to deviate in a controlled manner [1].
the implementation discussed in this paper di®ers considerably from the
above approaches. worklets dynamically linked together by extensible ripple
down rules provide an alternative method for the provision of dynamic °exibil-
ity. an approach with some similarities to worklets is is the process orchestrator ,
an optional component of sta®ware [36], which provides for the dynamic alloca-
tion of sub-processes at runtime. it requires a construct called a \dynamic event"
to be explicitly modelled that will execute a number of sub-processes listed in andynamic flexibility using worklets 15
`array' when execution reaches that event. which sub-processes execute depend
on prede¯ned data conditionals matching the current case. unlike the worklet
approach, the listed sub-processes are statically de¯ned, as are the conditionals {
there is no scope for dynamically re¯ning conditionals, nor adding sub-processes
at runtime.
8 conclusion and future work
work°ow management systems impose a certain rigidity on process de¯nition
and enactment because they use frameworks based on assembly line metaphors
rather than on ways work is actually planned and carried out. an analysis of
activity theory provided principles of work practices that were used as a tem-
plate on which a work°ow service has been built that better supports °exibility
and dynamic evolution. by capturing contextual data, a repertoire of actions is
constructed that allow for contextual choices to be made from the repertoire at
runtime to e±ciently carry out work tasks. these actions, or worklets, directly
provide for process evolution and °exibility, and mirror accepted work practices.
the worklet implementation presents several key bene¯ts, including:
{a process modeller can describe the standard activities and actions for a
work°ow process, and any deviations, using the same methodology;
{it allows re-use of existing process components and aids in the development
of fault tolerant work°ows using pre-existing building blocks [37];
{its modularity simpli¯es the logic and veri¯cation of the standard model,
since individual worklets are less complex to build and therefore easier to
verify than monolithic models;
{it provides for a variety of work°ow views of di®ering granularity, which
o®ers ease of comprehensibility for all stakeholders;
{it allows for gradual and ongoing evolution of the model, so that global
modi¯cation each time a business practice changes or a deviation occurs is
unnecessary; and
{in the occurrence of an unexpected event, the process modeller needs sim-
ply to choose an existing worklet or build a new one for that event, which
can be automatically added to the repertoire for current and future use as
necessary, thus avoiding manifold complexities including downtime, model
restructuring, versioning problems and so on.
this implementation used the open-source, service-oriented architecture of
yawl to develop a service for dynamic °exibility independent to the core en-
gine. thus, the implementation may be viewed as a successful case study in
service-oriented computing. it is the ¯rst instalment of a comprehensive ap-
proach to dynamic work°ow and is intended to be extended in the near future
to also provide support for dynamic handling of process exceptions using the
same service paradigm. one of the more interesting things to be investigated
and incorporated is the application of process mining techniques to the various
logs collected by the worklet service; a better understanding of when and why16 adams et. al.
people tend to \deviate" from a work plan is essential for providing better tool
support.
all system ¯les, source code and documentation for yawl and the worklet
service, including the examples discussed in this paper, may be downloaded via
www.yawl-system.com .
references
1.w.m.p. van der aalst, mathias weske, and dolf grä unbauer. case handling: a new
paradigm for business process support. data & knowledge engineering , 53(2):129{
162, 2005.
2.gregor joeris. de¯ning °exible work°ow execution behaviors. in peter dadam and
manfred reichert, editors, enterprise-wide and cross-enterprise work°ow man-
agement: concepts, systems, applications , volume 24 of ceur workshop proceed-
ings, paderborn, germany, october 1999.
3.alex borgida and takahiro murata. tolerating exceptions in work°ows: a uni-
¯ed framework for data and processes. in proceedings of the international joint
conference on work activities, coordination and collaboration (wacc'99) , pages
59{68, san francisco, ca, february 1999. acm press.
4.s. rinderle, m. reichert, and p. dadam. correctness criteria for dynamic changes
in work°ow systems: a survey. data and knowledge engineering , 50(1):9{34, 2004.
5.fabio casati. a discussion on approaches to handling exceptions in work°ows. in
cscw workshop on adaptive work°ow systems , seattle, usa, november 1998.
6.c.a. ellis, k. keddara, and g. rozenberg. dynamic change within work°ow
systems. in n. comstock, c. ellis, r. kling, j. mylopoulos, and s. kaplan, editors,
proceedings of the conference on organizational computing systems , pages 10{21,
milpitas, california, august 1995. acm sigois, acm press, new york.
7.claus hagen and gustavo alonso. exception handling in work°ow management
systems. ieee transactions on software engineering , 26(10):943{958, october
2000.
8.mark s. ackerman and christine halverson. considering an organization's mem-
ory. in proceedings of the acm 1998 conference on computer supported cooper-
ative work , pages 39{48. acm press, 1998.
9.peter a. k. larkin and edward gould. activity theory applied to the corpo-
rate memory loss problem. in l. svennson, u. snis, c. sorensen, h. fagerlind,
t. lindroth, m. magnusson, and c. ostlund, editors, proceedings of iris 23 lab-
oratorium for interaction technology , university of trollhattan uddevalla, 2000.
10.w.m.p. van der aalst. exterminating the dynamic change bug: a concrete ap-
proach to support work°ow change. information systems frontiers , 3(3):297{317,
2001.
11.jakob e. bardram. i love the system - i just don't use it! in proceedings of the
1997 international conference on supporting group work (group'97) , phoenix,
arizona, 1997.
12.w.m.p. van der aalst and p.j.s. berens. beyond work°ow management: product-
driven case handling. in s. ellis, t. rodden, and i. zigurs, editors, international
acm siggroup conference on supporting group work , pages 42{51, new york,
2001. acm press.
13.i. bider. masking °exibility behind rigidity: notes on how much °exibility people
are willing to cope with. in j. castro and e. teniente, editors, proceedings of the
caise'05 workshops , volume 1, pages 7{18, porto, portugal, 2005. feup edicoes.dynamic flexibility using worklets 17
14.michael adams, arthur h. m. ter hofstede, david edmond, and wil m.p. van der
aalst. facilitating °exibility and dynamic exception handling in work°ows through
worklets. in orlando bello, johann eder, oscar pastor, and jo~ ao falc~ ao e cunha,
editors, proceedings of the caise'05 forum , pages 45{50, porto, portugal, june
2005. feup edicoes.
15.w.m.p. van der aalst and a.h.m. ter hofstede. yawl: yet another work°ow
language. information systems , 30(4):245{275, 2005.
16.w.m.p. van der aalst, l. aldred, m. dumas, and a.h.m. ter hofstede. design
and implementation of the yawl system. in a. persson and j. stirna, editors,
proceedings of the 16th international conference on advanced information sys-
tems engineering (caise 04) , volume 3084 of lncs , pages 142{159, riga, latvia,
june 2004. springer verlag.
17.diane m. strong and steven m. miller. exceptions and exception handling in
computerized information processes. acm transactions on information systems ,
13(2):206{233, 1995.
18.jakob e. bardram. plans as situated action: an activity theory approach to
work°ow systems. in proceedings of the 1997 european conference on computer
supported cooperative work (ecscw'97) , pages 17{32, lancaster u.k., 1997.
19.bonnie a. nardi. activity theory and human-computer interaction , pages 7{16.
in nardi [21], 1996.
20.y. engestrom. learning by expanding: an activity-theoretical approach to de-
velopmental research . orienta-konsultit, helsinki, 1987.
21.bonnie a. nardi, editor. context and consciousness: activity theory and human-
computer interaction . mit press, cambridge, massachusetts, 1996.
22.michael adams, david edmond, and arthur h.m. ter hofstede. the application of
activity theory to dynamic work°ow adaptation issues. in proceedings of the 2003
paci¯c asia conference on information systems (pacis 2003) , pages 1836{1852,
adelaide, australia, july 2003.
23.w.m.p. van der aalst, a.h.m. ter hofstede, b. kiepuszewski, and a.p. barros.
work°ow patterns. distributed and parallel databases , 14(3):5{51, july 2003.
24.paolo bouquet, chiara ghidini, fausto giunchiglia, and enrico blanzieri. the-
ories and uses of context in knowledge representation and reasoning. journal of
pragmatics , 35(3), 2003.
25.debbie richards. combining cases and rules to provide contextualised knowledge
based systems. in modeling and using context, third international and interdis-
ciplinary conference, context 2001 , volume 2116 of lecture notes in arti¯cal
intelligence , pages 465{469, dundee, uk, july 2001. springer-verlag, berlin.
26.p. compton and b. jansen. knowledge in context: a strategy for expert system
maintenance. in j.siekmann, editor, proceedings of the 2nd australian joint arti¯-
cial intelligence conference , volume 406 of lecture notes in arti¯cial intelligence ,
pages 292{306, adelaide, australia, november 1988. springer-verlag.
27.tobias sche®er. algebraic foundation and improved methods of induction of ripple
down rules. in procceedings of the paci¯c rim workshop on knowledge acquisi-
tion, sydney, australia, 1996.
28.b. drake and g. beydoun. predicate logic-based incremental knowledge acqui-
sition. in p. compton, a. ho®mann, h. motoda, and t. yamaguchi, editors,
proceedings of the sixth paci¯c international knowledge acquisition workshop ,
pages 71{88, sydney, december 2000.
29.byeong ho kang, phil preston, and paul compton. simulated expert evaluation
of multiple classi¯cation ripple down rules. in proceedings of the 11th workshop on18 adams et. al.
knowledge acquisition, modeling and management , ban®, alberta, canada, april
1998.
30.dimitrios georgakopoulos, mark hornick, and amit sheth. an overview of work-
°ow management: from process modelling to work°ow automation infrastructure.
indistributed and parallel databases , volume 3, pages 119{153. kluwer academic
publishers, boston, 1995.
31.clemens hensinger, manfred reichert, thomas bauer, thomas strzeletz, and pe-
ter dadam. adept workflow - advanced work°ow technology for the e±cient sup-
port of adaptive, enterprise-wide processes. in conference on extending database
technology , konstanz, germany, march 2000.
32.g. vossen and m. weske. the wasa approach to work°ow management for
scienti¯c applications. in a. dogac, l. kalinichenko, m.t. ozsu, and a. sheth,
editors, work°ow management systems and interoperability , volume 164 of asi
nato series, series f: computer and systems sciences , pages 145{164. springer,
1999.
33.robert muller, ulrike greiner, and erhard rahm. agentwork: a work°ow sys-
tem supporting rule-based work°ow adaptation. data & knowledge engineering ,
51(2):223{256, november 2004.
34.michael zur muehlen. work°ow-based process controlling. foundation, design,
and implementation of work°ow-driven process information systems , volume 6 of
advances in information systems and management science . logos, berlin, 2004.
35.s. dustdar. caramba - a process-aware collaboration system supporting ad hoc
and collaborative processes in virtual teams. distributed and parallel databases ,
15(1):45{66, 2004.
36.michael george® and jon pyke. dynamic process orchestration. white
paper, sta®ware plc http://is.tm.tue.nl/bpm2003/download/wp%20dynamic%
20proce%ss%20orchestration%20v1.pdf , march 2003.
37.claus hagen and gustavo alonso. flexible exception handling in process support
systems. technical report no. 290, eth zurich, 1998.