process mining in case handling systems
christian w. g¨ unther and wil m.p. van der aalst
department of technology management, eindhoven university of technology
p.o. box 513, nl-5600 mb, eindhoven, the netherlands
{c.w.gunther, w.m.p.v.d.aalst }@tm.tue.nl
abstract. process mining has proven to be a valuable tool for tracking
down problems or ineﬃciencies within a variety of business processes, us-
ing information from event logs. compared to traditional process-aware
information systems (e.g. workﬂow management systems), case handling
systems allow for much more ﬂexibility by adding all kinds of implicit
controls. in this paper we reason about what information can be ex-
tracted from a case handling system and how this is accomplished. fur-
ther, we investigate how this data can be exploited, in order to achieve
greater insight into how business processes are handled within such a
ﬂexible environment.
1 introduction
while checking, monitoring and supervising industrial production processes is
quite straightforward, i.e. one only has to physically follow the product through
its production stages, this does not hold for informational processes in the same
way. of course the basic procedure is being prescribed by the designed process
model, but in case of problems emerging during enactment workers tend to
bypass the system and work “behind its back”. on the one hand, this makes it
hard to spot problems located in the process model itself, as they are eﬀectively
evaded by experienced workforce, while on the other hand other problems arising
from these very actions can no longer be traced back to the process model and
lead to mysterious and unforeseen behavior. these are situations where process
mining proves to be a valuable tool in unveiling properties of process enactment
that would otherwise remain hidden within the system. the general idea of
process mining is to examine event logs (i.e. process execution logs also known
as transaction logs or audit trails) created by some process-aware information
system and analyze them in various aspects. the goal of this analysis is to aid
in discovering problems or ineﬃcient behavior and in subsequently tracing these
back to deﬁciencies located in the process model or the organization itself.
workﬂow management (wfm) systems are a nice example of a technology
used to construct process-aware information systems. while production work-
ﬂow technology is becoming increasingly widespread, both concerning “stand-
alone” installations of full-ﬂedged wfm systems like staﬀware, ibm mqseries
workﬂow or cosa and the inclusion of wfm components in e.g. erp (en-
terprise resource planning) systems like sap r/3, peoplesoft and oracle, it is2
burdened with a set of fundamental problems that cause a fair deal of ineﬃ-
ciencies in practical use and hinder further proliferation of this paradigm. the
tightly prescribed process model leads to an inherent lack of ﬂexibility [3, 5, 11,
16, 20, 21, 24, 27, 29, 32] which makes wfm systems a serious roadblock when it
comes to changing business processes. as has been argued in [10] the process ori-
ented legacy of workﬂow management systems, focusing on causal relationships
between tasks as its primary driver, leads to four crucial problems. one that is
deeply rooted in the wfm paradigm is the partitioning of work in order to make
it distributable, while this work is usually performed at a far more ﬁne-grained
level by the employees involved. further, the way wfm systems distribute work
is closely intertwined with authorization, i.e. workers are always presented with
all activities they are allowed to perform. this can be a problem especially for
high-ranking employees whose role implies a large set of sub-roles, such that
the really important tasks that only they can perform drown within a mass of
other, less demanding tasks. another downside is the phenomenon of context
tunneling , i.e. workers are more or less isolated within their currently handled
activity and have no overview about the case as a whole. this leads to errors
and ineﬃciencies that could otherwise be evaded easily. however, the problem
that is most responsible for the inﬂexibility of traditional workﬂow management
is its strongly push-oriented nature of routing, prescribing what to do instead of
leaving the choice to the users.
to address these problems the case handling paradigm , introduced in [2, 10]
and implemented in successful tools such as flower (pallas athena, [14, 13]),
promises remedy. the basic idea is to base progress within the process model
on the availability of deﬁned data elements. further novelties enable users to
substantially deviate from the predeﬁned process model, as these no longer de-
scribe what is allowed but rather what is not, granting a maximal degree of
freedom and nearly unlimited navigation within the process. in such an envi-
ronment where one execution of a process model may look completely diﬀerent
to another one, depending on the case itself and who is working on it, process
mining can be expected to yield even more interesting insights into an organiza-
tion and its processes. concerning the process perspective it is no longer bound
to rediscovering the original process model but can rather be used to see how
process-aware workers organize their tasks, discover their otherwise tacit best
practices, and thus make them persistent. one further opportunity is to make
use of the more data-centered approach of case handling systems by taking into
account information associated with data elements in the mining process. in
this way a far more detailed understanding can be gained concerning how data
is created and transformed during a speciﬁc business process.
this paper investigates opportunities, challenges and new methods that may
arise from applying process mining techniques to case handling systems, or their
enactment logs. the following sections give a short introduction into the case
handling paradigm and the technique of process mining. section 4 introduces
diﬀerent types of logs that can be extracted from a case handling system, after
which concrete tools are introduced in section 5. in the subsequent section the3
design of a generic converter and envisioned process mining techniques for case
handling systems are discussed.
2 case handling
while production workﬂow, emphasizing the routing between atomic activities,
is strongly process-oriented, the case handling paradigm focuses mainly on the
case itself. the case is the primary object to be manufactured, e.g. the outcome
of a lawsuit or the response to a customer request. in this case, single activities
diminish in importance in favor of the larger context. they are no longer consid-
ered atomic steps that have to be performed in an “all or nothing” manner, but
rather make up the logical partitions of work between which a transition from
one worker to another is possible.
like in traditional wfm there exists a set of precedence relations between
single activities making up a process, using well-known patterns [4] for that.
however the primary driver for progress is no longer the event of explicitly ﬁn-
ishing activities but the availability of values for data objects. while production
workﬂow clearly separates the process from associated data, case handling inte-
grates both far more closely, using produced data not only for routing decisions
but also for determining which parts of the process have already been accom-
plished. with case handling, each task has associated to it data objects for three
distinct purposes, while the ﬁrst association is between a task and all data ob-
jects that are accessible while performing it. furthermore, all data objects that
aremandatory for a task have to be set (i.e. bound to a value) before the task
itself is considered to be accomplished by the system. finally, every data object
can have a random number of tasks to which it is restricted , meaning that it
can only be altered while performing one of these tasks. the mandatory and
restricted properties are independent from each other, however reason dictates
to have the last (in the sense of a causal chain) task featuring a data object as
restricted also declared as mandatory (to make sure it will be provided). user-
interactive tasks are connected to a form , each providing access to a selection
of data objects. note that one form can be associated to multiple tasks; on the
other hand it is also possible to associate a form to the case itself, so that it can
be accessed at any point in time.
in order to introduce the case handling principle, we use a small abstract
example. figure 1 shows a very simple case type . the concept of a case type is the
case handling analogy to a workﬂow process deﬁnition: three tasks a,bandc
are making up the process, sequentially chained by causal relationships denoted
by connecting arrows. their mandatory relationships to the three data objects
x,yandzbelow are denoted by (curved) lines connecting activities (middle) to
data elements (bottom). similarly, activities are associated with the forms m
andn(top). as it can be seen in the illustration, tasks aandbshare the same
formm, which provides access to data objects xandy. if a properly authorized
worker now starts handling task a, the associated form mwill open and he
will start providing values for the presented data objects. in a traditional wfm4
fig. 1. simpliﬁed example case type
system activity awould not be ﬁnished before form mis closed. however, a case
handling system regards aas ﬁnished as soon as a value for xhas been provided
(and conﬁrmed appropriately), automatically enabling task bin the background.
if the worker would now close form m, another employee could pick up the case
where he left it, starting task b, which would provide the same form mwithx
having a value ﬁlled in (that could now be changed again). another possibility
is, however, that the ﬁrst worker keeps on handling the form, providing also
a value for y. this would correspondingly trigger the auto-completion of task
b(as all associated mandatory data elements, in this case only y, have been
provided) and activate task c. note that if a worker closes a form after ﬁlling
out only parts of the mandatory data ﬁelds of a task, despite the task not being
considered ﬁnished data already entered is not lost but will be presented to the
person continuing work on that task.
such a closely intertwined relationship between data and process obviously
abandons their, often unnatural, separation so rigidly pursued in traditional
workﬂow management. with the status of case data objects being the primary
determinant of case status, this concept overcomes a great deal of the problems
described in the introduction:
– work can now be organized by those performing it with a far higher degree
of freedom. activities can either be performed only partly, without losing
intermediary results, or multiple related activities can be handled in one go,
surpassing the considerably weakened border between single tasks.
– the phenomenon of context tunneling can be remedied e.g. by providing
overview forms directly associated to the case. every authorized worker can
consult such form at any point in time, ensuring he is aware of the context
where necessary.
– routing is no longer solely determined by the process model. case types can
be designed in such a way that multiple activities become enabled concur-
rently, providing diﬀerent ways of achieving one goal. it is up to the user to
decide which way to go, with the system “cleaning up behind”, i.e. disabling
or auto-completing tasks that have not been chosen.5
in addition to the execute role, specifying the subset of resources allowed to
handle a speciﬁc task, the case handling principle introduces two further roles
crucial for operation. the skip role allows workers to bypass a selected task,
which could be interpreted as an exception . when one thinks of real business pro-
cesses an exception, like skipping an activity that deals with thoroughly checking
the history of a client before granting a mortgage for well-known and trusted
clients, is likely to occur quite frequently. the ability to grant the skip role to a
senior worker renders the necessity for implementing such bypass obsolete, thus
greatly simplifying the whole case type. it has to be noted that in order to skip a
task all preceding tasks that have not been completed yet have to be skipped (or
completed) beforehand. traditional workﬂow deﬁnitions use loops for repeating
parts of the process, e.g. because they have not yielded an expected result. in
a case handling system, such construct has been made obsolete as well by the
introduction of a redo role, enabling its bearer to deliberately roll the case’s
state back and make a task undone. in doing so, the values provided for data
objects during this task are not discarded but merely marked as unconﬁrmed , so
that they serve as kind of template when re-executing the aﬀected task. similar
to skipping, before a task can be redone all subsequent tasks that have already
been completed need to be rolled back as well. roles in a case handling system
arecase speciﬁc , i.e. having assigned the role “manager” for a case type adoes
not imply that one can play the same role for another case type b. they can be
speciﬁed in form of a role graph , where single role nodes are connected to each
other by arcs, symbolizing is-arelationships; i.e. being authorized to play a role
also implies the authorization to play all roles connected as child nodes.
intertwining authorization with distribution of activities has been one of
the major ﬂaws in contemporary wfm systems, because “what one can do”
(authorization) does not need to coincide with “what one should do” (work
distribution). in a case handling system, the classical in-tray , i.e. a list of all
activities the user is authorized to perform and that he can choose from, has
been replaced by a sophisticated query mechanism . this tool can be used to
look for a speciﬁc case, based on certain features (e.g. case data, or enactment
meta-data like the start date of a case instance). moreover it can be used to create
predeﬁned queries tailored to each worker (or, group of workers). a manager is
no longer constantly ﬂooded with all possible activities that he can perform, but
only those which require a certain role, or e.g. case instances of an order where
the combined value exceeds $1000. obviously the query mechanism can also be
used to perfectly imitate a classic in-tray, be it required.
as a reference implementation of the case handling concept, we will use
flower [14]. flower of pallas athena is one of the most successful software
tools to create process-aware information systems on the dutch market. there
it is competing with classical workﬂow products such as staﬀware, filenet,
and cosa. besides flower there are few other case handling tools. related
products are e.c.h.o. (electronic case-handling for oﬃces), a predecessor of
flower, the staﬀware case handler [31] and the cosa activity manager [30],6
both based on the generic solution of bpi [15], vectus [25, 26], and the open-
source system con:cern (http://con-cern.org/).
3 process mining
the goal of process mining is to extract information about processes from trans-
action logs [7]. one reason for this is to discover patterns in the way people
work and processes unfold, or one may want to check whether things are really
executed the way it was prescribed. the results of process mining may be used
to align the information system, organization and processes in a better way.
also, a careful analysis of the way things really are, may assist in improving
the eﬃciency, eﬀectivity and quality of business processes. any redesign eﬀort
based on incorrect assumptions of the current process is like an accident waiting
to happen. this section introduces the concept of process mining with classi-
cal process-aware information systems in mind. in section 4 we shift to case
handling systems.
traditional process mining techniques assume that it is possible to record
events such that (i) each event refers to an activity (i.e. a well-deﬁned step in
the process), (ii) each event refers to a case (i.e. a process instance), (iii) each
event can have a performer also referred to as originator (the person executing
or initiating the activity), and (iv) events have a timestamp and are totally
ordered. table 1 shows an example of a log involving 19 events, 5 activities, and
6 originators.1in addition to the information shown in this table, some event
logs contain more information on the case itself, i.e. data elements referring to
properties of the case. for example, the case handling system flower logs every
modiﬁcation of some data element.
event logs such as the one shown in table 1 are used as the starting point
for mining. we distinguish three diﬀerent perspectives: (1) the process perspec-
tive, (2) the organizational perspective and (3) the case perspective. the process
perspective focuses on the control-ﬂow, i.e. the ordering of activities. the goal of
mining this perspective is to ﬁnd a good characterization of all possible paths,
e.g. expressed in terms of a petri net or event-driven process chain (epc). the
organizational perspective focuses on the originator ﬁeld, i.e. which performers
are involved and how are they related. the goal is to either structure the or-
ganization by classifying people in terms of roles and organizational units or to
show relations between individual performers (i.e. build a social network). the
case perspective focuses on properties of cases, i.e. the values of the correspond-
ing data elements. for example, if a case represents a replenishment order it is
interesting to know the supplier or the number of products ordered.
1note that in table 1 we abstract from event types , i.e. we consider activities to be
atomic. in real logs events typically correspond to the start or completion of an ac-
tivity. this way it is possible to measure the duration of activities and to explicitly
detect parallelism. moreover, there are other event types related to failures, schedul-
ing, delegations, etc. for simplicity we abstract from this in this paper. however, in
our process mining tools we take event types into account.7
case id activity id originator timestamp
case 1 activity a john 9-3-2004:15.01
case 2 activity a john 9-3-2004:15.12
case 3 activity a sue 9-3-2004:16.03
case 3 activity b carol 9-3-2004:16.07
case 1 activity b mike 9-3-2004:18.25
case 1 activity c john 10-3-2004:9.23
case 2 activity c mike 10-3-2004:10.34
case 4 activity a sue 10-3-2004:10.35
case 2 activity b john 10-3-2004:12.34
case 2 activity d pete 10-3-2004:12.50
case 5 activity a sue 10-3-2004:13.05
case 4 activity c carol 11-3-2004:10.12
case 1 activity d pete 11-3-2004:10.14
case 3 activity c sue 11-3-2004:10.44
case 3 activity d pete 11-3-2004:11.03
case 4 activity b sue 11-3-2004:11.18
case 5 activity e clare 11-3-2004:12.22
case 5 activity d clare 11-3-2004:14.34
case 4 activity d pete 11-3-2004:15.56
table 1. an event log
fig. 2. some mining results for the process perspective (a) and organizational (b and
c) perspective based on the event log shown in table 18
the process perspective is concerned with the “how?” question, the orga-
nizational perspective is concerned with the “who?” question, and the case
perspective is concerned with the “what?” question. to illustrate the ﬁrst two
consider figure 2. the log shown in table 1 contains information about ﬁve cases
(i.e. process instances). the log shows that for four cases (1, 2, 3, and 4) the
activities a, b, c, and d have been executed. for the ﬁfth case only three activ-
ities are executed: activities a, e, and d. each case starts with the execution of
a and ends with the execution of d. if activity b is executed, then also activity
c is executed. however, for some cases activity c is executed before activity b.
based on the information shown in table 1 and by making some assumptions
about the completeness of the log (i.e. assuming that the cases are representative
and a suﬃciently large subset of possible behaviors is observed), we can deduce
the process model shown in figure 2(a). the model is represented in terms of a
petri net [18]. note that for this example we assume that two activities are in
parallel if they appear in any order. by distinguishing between start events and
complete events for activities it is possible to explicitly detect parallelism.
as table 1 shows the performers of activities, we can use this information to
discover the organizational structure. for every activity, there is a distinctive set
of persons that have performed it. rather than extending figure 2(a) with this
information, we can also use it to discover organizational structures. comparing
the sets of persons that have executed each activity can yield the underlying
roles of the process model, in this example we can discover three roles x, y,
and z. for example, for the execution of a role x is required and john and
sue have this role. the resulting “activity-role-performer diagram” is shown in
figure 2(b). the three “discovered” roles link activities to performers. for ﬁve
cases these choices may seem arbitrary but for larger data sets such inferences
capture the dominant roles in an organization.
the event log can be used to derive a sociogram based on the transfer of
work from one individual to another as is shown for the example in figure 2(c).
here the focus is not on the relation between the process and individuals but
on relations among (groups of) individuals. each node represents one of the six
performers and each arc represents that there has been a transfer of work from
one individual to another, i.e. whether for the same case an activity executed
by a is directly followed by an activity executed by b. for example, both in
case 1 and 2 there is a transfer from john to mike. figure 2(c) does not show
frequencies. however, for analysis purposes these frequencies can be added. the
arc from john to mike would then have weight 2. typically, we do not use
absolute frequencies but weighted frequencies to get relative values between 0
and 1.
the case perspective looks at the case as a whole and tries to establish
relations between the various properties of a case (i.e., the “what?” question).
focusing on the case perspective is most interesting when also data elements
are logged but these are not listed in table 1, and therefore this perspective is
not addressed in figure 2. note that some of the properties may refer to the
activities being executed, the performers working on the case, and the values of9
various data elements linked to the case. using clustering algorithms it would
for example be possible to show a positive correlation between the size of an
order or its handling time and the involvement of speciﬁc people.
orthogonal to the three perspectives (process, organization, and case), the
result of a mining eﬀort may refer to logical issues and/or performance issues.
for example, process mining can focus on the logical structure of the process
model (e.g. the petri net shown in figure 2(a)) or on performance issues such as
ﬂow time. for mining the organizational perspectives, the emphasis can be on
the roles or the social network (cf. figure 2(b) and (c)) or on the utilization of
performers or execution frequencies.
to address the three perspectives and the logical and performance issues we
have developed a set of tools including emit, thumb, and minson sharing a
common xml format. recently, these tools have been merged into the prom
framework (see http://www.processmining.org for more details).
4 extracting logs from a case handling system
in order to analyze business processes using process mining techniques it is essen-
tial to retrieve suitable event logs from the system in question. a case handling
system logs, like workﬂow management systems, the occurrence of activities
(i.e. executed tasks). however, further it also provides detailed log information
about events referring to any modiﬁcation of a deﬁned data object included in
the case. in the remainder of this section we discuss the information extractable
from case handling system logs.
4.1 activity logs
a case handling system keeps much closer track of the events related to activi-
ties than many traditional wfmss, virtually logging every state change in the
life-cycle of activities. whenever an activity becomes enabled, someone starts
or stops working on it, or it is ﬁnished, a log entry with the appropriate infor-
mation is created. of course events like skipping or redoing an activity also get
recorded in the logs. this detailed logging allows for a far more comprehensible
understanding of what happened during process enactment, the actual workﬂow
can be concisely traced back to user interactions.
4.2 data logs
following its paradigm of more closely intertwining the data and control ﬂow
aspect of business processes, case handling systems do not only log events related
to activities but also manipulation of case data elements. if these events are
considered as activities within a regular process it is possible to mine a process
model from such a data log, featuring a ﬁne-grained model of data access events
as tasks.10
data logs may also be exploited by performing statistical analysis techniques
on them, thereby exposing typical access patterns or general characteristics of
data usage within the handling of a certain case type. speciﬁc access patterns can
also be used as indicators for inadequately designed processes (e.g. if rolling back
a certain task is not an exception but rather the rule). moreover, it is possible
to use data as a starting point for process design. as suggested by the product
based workﬂow design (pbwd) approach [28, 1], one can structure information
in a hierarchical structure similar to the bill of material used in manufacturing.
it is worthwhile to emphasize that, besides case handling systems, many systems
log updates on data elements. consider for example a product data management
(pdm) system like windchill (http://www.ptc.com/), logging the status of every
design artifact (e.g. a technical drawing). erp systems like sap r/3 also use
the concept of document ﬂows to record events at the business level, i.e. not the
process but some document is the key concept when logging events.
4.3 uniﬁed logs
to unleash the full potential of process mining in case handling systems it is
necessary to also take into account its characteristics of handling control ﬂow
and data in a uniﬁed manner, namely by analyzing those in a respectively com-
bined fashion. since activities can also be perceived as abstractions of bulk data
processing and modiﬁcation rather than ﬁne-grained data updates, the data per-
spective and the process perspective reside on diﬀerent levels of abstraction. in
combining logs from both perspectives, care has to be taken in order to not
distort the contained information. the order of events within the uniﬁed log
can be derived from the events’ timestamps. whenever two events from diﬀerent
layers are in conﬂict, the semantic implications should be taken into account to
resolve it (e.g. starting work on an activity is naturally preceding the consequent
setting of a data object). it is also important to mark each event, so that it can
later be identiﬁed to either stem from the activity or data log. only then can
interrelations between both perspectives be extracted in a meaningful way.
5 flower and prom
after introducing the concepts of process mining and case handling, and explor-
ing their relationships, we consider two concrete software systems: flower as
an example of a case handling product and prom as an example of a process
mining tool.
case handling as a paradigm of business process management is relatively
novel, thus it is not surprising that no large number of actual case handling
system implementations can be found in practice. for our research we are at
the moment focusing on the commercial case handling system flower, which
is introduced in the next section.
process mining is closely linked to tools advertised through buzzwords such
as business activity monitoring (bam) and business process intelligence (bpi).11
however, most of the commercial tools focus on simple performance indicators
such as ﬂow times and frequencies. a notable exception is aris ppm [22] of ids
scheer. compared to commercial tools, the functionality of prom is far superior
when it comes to process mining. therefore, we focus our attention on bridging
the gap between flower and prom. note that prom can export its results to
aris ppm for alternative (i.e. more traditional) ways of analysis.
5.1 flower
flower is a commercial case handling system manufactured by the dutch com-
pany pallas athena. it implements the case handling paradigm very close to its
theoretical foundations, rendering it a highly relevant object of research in this
ﬁeld.
fig. 3. screenshot of the flower process designer
the flower process designer, shown in figure 3, features a vast set of
control ﬂow constructs that can largely be mapped on the well-known control
ﬂow patterns [4]. for the sake of performing process mining, flower requires the
process designer to explicitly activate the recording of management information
for both tasks and data elements at design time.
5.2 prom
in order to foster development in the process mining domain and to achieve a
maximal degree of interoperability between previously existing and newly devel-
oped methods and programs a common xml based format2for storing process
logs has been established [7]. to further proceed on this path to combine ef-
forts the prom framework has been developed, providing a common base for the
development of techniques related to the ﬁeld of process mining.
2see www.processmining.org.12
the key property of the prom framework is its highly modular architecture,
incorporating mining algorithms and methods in the form of plugins. the frame-
work itself provides a common graphical user interface, high-level data structures
and methods for working with process logs and models, and also mechanisms for
visualizing mined process models using an array of formats.
after selecting a log ﬁle and the plugin which is to be used for its analysis,
the plugin-speciﬁc options for mining can be conﬁgured. the result can then be
visualized in diﬀerent ways, including graph-based visualizations like petri nets
or epcs. depending on the result of the plugin the outcome of mining can be
analyzed further, e.g. by checking certain properties like soundness of a mined
petri net.
5.3 flower log extraction
the ﬁrst step on the agenda of performing process mining in case handling
systems is to acquire event logs from such a system. flower stores event logs
not in traditional text ﬁle format, but it rather creates for each event an entry
in one or more database tables used for storing management information. while
the log information stored in there is very comprehensive, containing a vast array
of meta-data, at the same time it is quite hard to access and extract in a useful
manner. for a process mining project within the uwv (a large dutch company
using flower), ana karla alves de medeiros developed an initial version of a
converter from flower to our xml format. based on this prototype, a new,
more versatile, and easily extensible import ﬁlter has been developed. this ﬁlter
directly accesses the log database and is at the moment able to extract log
information for both task and data events for each case type stored there. at
this point in time it is not yet possible to create a uniﬁed log containing both
data and task events, however, this feature is in development and should be
available in the near future.
as flower allows to structure case types, regarding their process perspec-
tive, using sub-plans (i.e. sub-processes) both task and data events can be located
at multiple “levels” per case type. thus, it has been made conﬁgurable whether
events on all levels of a case type shall be included within one single log ﬁle,
or whether the events shall be grouped in multiple ﬁles on a per-level basis. an
auxiliary level report provides information about the level structure of case types
in form of a plain text ﬁle. as the prom framework allows for loading xml log
ﬁles also from compressed zip archives, all ﬁles created in one import session
are saved within one such archive, underlining their logical coupling.
further options include the prioritization and exclusion of certain case types
according to their id. regarding the eﬀort that is needed to extract flower
logs, due to a massive amount of database queries and demanding post-processing
necessary, this proves to be a useful feature in saving processing time and con-
centrating on certain case types in the focus of attention.13
5.4 mining flower logs with prom
a case handling system can be perceived as superset of a traditional workﬂow
management system, regarding its possibilities, and thus the behavior potentially
generated by it. while log traces produced by a wfm system will, presuming no
errors or cheats during enactment, be bound to follow the possibilities prescribed
by the process model, this is absolutely not true for case handling processes. here
the case type does not prescribe actions but rather limits the set of potential
tasks to a reasonable subset, so that the user always has far more opportunities
to deviate from the standard path suggested. further, the capability of flower
to skip and redo tasks makes it possible to navigate through the process back
and forth, thus allowing for a previously unknown degree of freedom. loops
do no longer have to be predeﬁned, and as such be easy to trace back to the
model, they can be performed at any point within the process given the fact
that appropriate roles do apply.
fig. 4. screenshot of the prom framework analyzing a flower task log
figure 4 shows a screenshot of prom, with the result of applying the multi-
phase mining algorithm [19] to a flower task log of a very simple example case
type of four tasks. in the test executions of this case type excessive use has been
made of the ﬂexibility oﬀered by flower, and the mining result reﬂects this by
e.g. including a vast number of task-skipping and returning arcs. it is obvious
that process mining techniques originally developed for mining logs created by a
wfm system can also be used for analyzing case handling logs. given a suitable
process and a conservative fashion of enactment this may be helpful in providing14
insight to case type and organization and prove suﬃcient. however, when users
make full use of the ﬂexibility and freedom oﬀered by a case handling system
the results of mining are prone to making interpretation hard. fortunately, some
mining plug-ins such as the social network analyzer (sna) [6] are more robust
in this respect.
6 discussion
the work that has been performed so far, regarding the application of process
mining to case handling systems, is still in its infancy. as described above, an
import ﬁlter has been created that allows for the extraction of comprehensive log
information from the case handling system flower. the following section points
out directions in which development of import facilities for prom continues,
introducing the new generic import ﬁlter framework. in the subsequent section
a selection of approaches dealing with the combined, or “holistic”, analysis of
both task and data event logs are presented, which we plan to pursue.
6.1 log import filter framework
so far there existed several converter programs for retrieving the necessary infor-
mation from the respective system and delivering a process log in the common
xml format for prom. there are converters for staﬀware and mqseries logs,
and also semi-automatic tools supporting the extraction of sap document ﬂows.
from a software engineering point of view the separate converters form a rather
undesirable situation, as all of these import ﬁlters share a great set of common
functionality. for example, the fact that all of them have their own methods for
writing the xml format is a serious problem with respect to code maintenance.
this drawback has been tackled by the development of a generic framework
for log import ﬁlters, providing common tools and means that are used repeat-
edly. for example, not only writing the logs has been encapsulated by the frame-
work, also conﬁguring import ﬁlters and keeping this conﬁguration persistent is
handled transparently by the framework. import ﬁlter implementations can fully
concentrate on the plain logic for log extraction, with the framework providing
a common, user-friendly gui. they can be loaded as plugins at runtime, which
makes the architecture especially ﬂexible and extensible.
one feature worth mentioning is the log anonymizer that is built into the
framework and can be used for any import ﬁlter in a transparent manner. using
this tool, all properties of a log, e.g. originator names or task identiﬁers, can be
exchanged by meaningless id strings. of course this replacement is performed
in a way that preserves the identity of anonymized items (i.e. all occurrences of
one identiﬁer are replaced by the same anonymizer string).
the core incentive has been to make writing further import ﬁlters as straight-
forward as possible. another goal is to provide third parties with a powerful and
yet easy-to-use tool for collecting actual logs in practice, in order to facilitate
the testing of mining algorithms on more practical examples. the availability15
of anonymization is expected to signiﬁcantly lower the reluctancy of users to
exchange logs.
6.2 holistic approaches for log analysis
the fact that a combined case handling log includes data- and task-related events
creates a somewhat novel situation. there are no longer just diﬀerent perspec-
tives of the same data but such uniﬁed case handling logs eﬀectively contain the
same process on two diﬀerent, yet closely related, layers of abstraction. apart
from analyzing data and activity logs separately, which makes perfectly sense
in certain settings, it appears more promising to look at both data and activ-
ity events in a holistic fashion, taking into account the relations between them
which are inherently driving a case handling system.
for performing a case type veriﬁcation the starting point would be to ﬁrst
mine the control ﬂow perspective and derive an appropriate process model, incor-
porating phenomena like skipping and redoing tasks in an implicit manner. the
next step is to assign data modiﬁcation events to the realm of tasks. as in a case
handling system data can basically only be manipulated between the events of
starting and ﬁnishing a task, and as these events are explicitly recorded in the ac-
tivity logs, this assignment of data manipulation events to tasks is quite straight-
forward. however, data modiﬁcation events that have resulted from modifying
case forms (that can be accessed at any time) need to be interpreted appropri-
ately to avoid distortion. the result of this complete procedure can be thought
of as a (simpliﬁed) process model, suggesting for each task within the process
a set of data elements as mandatory, following the pattern of data manipula-
tion events recorded in the logs. such an enhanced process model could then be
compared to the original case type deﬁnition to see whether what the case type
designer intended is really the way cases are handled within an organization.
in order to optimize the coupling and separation of work into activities, a
holistic mining approach can also investigate e.g. the idle time between successive
tasks. if there is an overwhelming majority of cases where two successive tasks
aandbare ﬁnished with practically no delay this might be a hint that they
should better be clustered into one single task. correspondingly, in case one task
is always interrupted and resumed later on it seems to be a good idea to think
about splitting it into two separate tasks.
the above approach is tailored towards business process improvement, and
as such a rather informal process representation, e.g. following the way flower
depicts its case type plans, seems most appropriate. however, given the fact that
we are dealing with process models that are closely intertwined with data manip-
ulation information, the modelling technique of colored petri nets (cpn) [23]
seems to be an obvious choice. it allows for a concise graphical representation
of data ﬂow by assigning potentially structured data types (“colors”) to places
and tokens. as described above it should be possible to derive from case han-
dling logs the information, which data objects are typically modiﬁed during each
task. starting from this, each place in the cpn process model could be assigned16
a speciﬁc color which is assembled from all data elements written by the preced-
ing and read by the subsequent task, i.e. transition. the derivation of a cpn
process model from uniﬁed activity and data logs is anticipated to be a complex
endeavor. nevertheless, given its formal semantics, the existence of excellent tool
support for their veriﬁcation and analysis, and the good ﬁt with the case han-
dling paradigm, the cpn language is considered to be the foundation for our
future eﬀorts on process mining in case handling systems.
7 related work
flexibility has been a “hot research topic” in workﬂow literature since the late
nineties [3, 5, 11, 16, 20, 21, 24, 27, 29, 32]. flexibility triggers all kinds of interest-
ing research questions, e.g. if one changes a process what to do with the running
cases? [5]. however, the idea of case handling, as it has been deﬁned in [2, 10], is
to avoid this. these ideas have been successfully implemented in flower (pal-
las athena, [14, 13]) and have proven to be valid in many practical applications.
flower has been applied in payment institutions, banks, insurance companies,
government bodies, telecommunications, housing corporations, educational in-
stitutions, health care, police, courts of law, and it companies.
the idea of applying process mining in the context of workﬂow management
was ﬁrst introduced in [12]. cook and wolf have investigated similar issues in
the context of software engineering processes using diﬀerent approaches [17].
it is impossible to point out the many process mining algorithms proposed in
literature. however, we would like to mention the αalgorithm [9] which served
as a starting point for the prom framework. for more information on process
mining we refer to a special issue of computers in industry on process mining
[8] and a survey paper [7].
as far as we know this is the ﬁrst paper focusing on the link between process
mining and case handling, which explains its explorative nature.
8 acknowledgements
this research is supported by the technology foundation stw, applied sci-
ence division of nwo and the technology programme of the dutch ministry of
economic aﬀairs.
the authors would like to thank ana karla alves de medeiros for imple-
menting the ﬁrst converter from flower to prom. we would also like to thank
her and the rest of the “process mining team” (among others ton weijters,
boudewijn van dongen, minseok song, laura maruster, eric verbeek, monique
jansen-vullers, hajo reijers, michael rosemann, anne rozinat and peter van
den brand) for their on-going work on process mining techniques. parts of this
paper have been based on earlier papers with these researchers.17
references
1. w.m.p. van der aalst. on the automatic generation of workﬂow processes based
on product structures. computers in industry , 39:97–111, 1999.
2. w.m.p. van der aalst and p.j.s. berens. beyond workﬂow management: product-
driven case handling. in s. ellis, t. rodden, and i. zigurs, editors, international
acm siggroup conference on supporting group work (group 2001) , pages
42–51. acm press, new york, 2001.
3. w.m.p. van der aalst, j. desel, and a. oberweis, editors. business process man-
agement: models, techniques, and empirical studies , volume 1806 of lecture notes
in computer science . springer-verlag, berlin, 2000.
4. w.m.p. van der aalst, a.h.m. ter hofstede, b. kiepuszewski, and a.p. barros.
workﬂow patterns. distributed and parallel databases , 14(1):5–51, 2003.
5. w.m.p. van der aalst and s. jablonski. dealing with workﬂow change: identiﬁca-
tion of issues and solutions. international journal of computer systems, science,
and engineering , 15(5):267–276, 2000.
6. w.m.p. van der aalst and m. song. mining social networks: uncovering interac-
tion patterns in business processes. in j. desel, b. pernici, and m. weske, editors,
international conference on business process management (bpm 2004) , volume
3080 of lecture notes in computer science , pages 244–260. springer-verlag, berlin,
2004.
7. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and
a.j.m.m. weijters. workﬂow mining: a survey of issues and approaches. data
and knowledge engineering , 47(2):237–267, 2003.
8. w.m.p. van der aalst and a.j.m.m. weijters, editors. process mining , special
issue of computers in industry, volume 53, number 3. elsevier science publishers,
amsterdam, 2004.
9. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining:
discovering process models from event logs. ieee transactions on knowledge
and data engineering , 16(9):1128–1142, 2004.
10. w.m.p. van der aalst, m. weske, and d. gr¨ unbauer. case handling: a new
paradigm for business process support. data and knowledge engineering ,
53(2):129–162, 2005.
11. a. agostini and g. de michelis. improving flexibility of workﬂow management
systems. in w.m.p. van der aalst, j. desel, and a. oberweis, editors, business
process management: models, techniques, and empirical studies , volume 1806 of
lecture notes in computer science , pages 218–234. springer-verlag, berlin, 2000.
12. r. agrawal, d. gunopulos, and f. leymann. mining process models from work-
ﬂow logs. in sixth international conference on extending database technology ,
pages 469–483, 1998.
13. pallas athena. case handling with flower: beyond workﬂow . pallas athena
bv, apeldoorn, the netherlands, 2002.
14. pallas athena. flower user manual . pallas athena bv, apeldoorn, the nether-
lands, 2002.
15. bpi. activity manager: standard program - standard forms (version 1.2) . work-
ﬂow management solutions, oosterbeek, the netherlands, 2002.
16. f. casati, s. ceri, b. pernici, and g. pozzi. workﬂow evolution. in proceedings
of er ’96 , pages 438–455, cottubus, germany, oct 1996.
17. j.e. cook and a.l. wolf. discovering models of software processes from event-
based data. acm transactions on software engineering and methodology ,
7(3):215–249, 1998.18
18. j. desel, w. reisig, and g. rozenberg, editors. lectures on concurrency and petri
nets, volume 3098 of lecture notes in computer science . springer-verlag, berlin,
2004.
19. b.f. van dongen and w.m.p. van der aalst. multi-phase process mining: building
instance graphs. in p. atzeni, w. chu, h. lu, s. zhou, and t.w. ling, editors, in-
ternational conference on conceptual modeling (er 2004) , volume 3288 of lecture
notes in computer science , pages 362–376. springer-verlag, berlin, 2004.
20. c.a. ellis and k. keddara. a workﬂow change is a workﬂow. in w.m.p. van der
aalst, j. desel, and a. oberweis, editors, business process management: models,
techniques, and empirical studies , volume 1806 of lecture notes in computer
science , pages 201–217. springer-verlag, berlin, 2000.
21. t. herrmann, m. hoﬀmann, k.u. loser, and k. moysich. semistructured models
are surprisingly useful for user-centered design. in g. de michelis, a. giboin,
l. karsenty, and r. dieng, editors, designing cooperative systems (coop 2000) ,
pages 159–174. ios press, amsterdam, 2000.
22. ids scheer. aris process performance manager (aris ppm): measure, ana-
lyze and optimize your business process performance (whitepaper). ids scheer,
saarbruecken, gemany, http://www.ids-scheer.com, 2002.
23. k. jensen. coloured petri nets. basic concepts, analysis methods and practi-
cal use . eatcs monographs on theoretical computer science. springer-verlag,
berlin, 1992.
24. m. klein, c. dellarocas, and a. bernstein, editors. adaptive workﬂow systems ,
volume 9 of special issue of the journal of computer supported cooperative work ,
2000.
25. london bridge group. vectus application developer’s guide . london bridge
group, wellesbourne, warwick, uk, 2001.
26. london bridge group. vectus technical architecture . london bridge group,
wellesbourne, warwick, uk, 2001.
27. m. reichert and p. dadam. adeptﬂex: supporting dynamic changes of
workﬂow without loosing control. journal of intelligent information systems ,
10(2):93–129, 1998.
28. h.a. reijers, s. limam, and w.m.p. van der aalst. product-based workﬂow
design. journal of management information systems , 20(1):229–262, 2003.
29. s. rinderle, m. reichert, and p. dadam. correctness criteria for dynamic
changes in workﬂow systems: a survey. data and knowledge engineering ,
50(1):9–34, 2004.
30. software-ley. cosa activity manager . software-ley gmbh, pullheim, germany,
2002.
31. staﬀware. staﬀware case handler – white paper . staﬀware plc, berkshire, uk,
2000.
32. m. weske. formal foundation and conceptual design of dynamic adaptations in
a workﬂow management system. in r. sprague, editor, proceedings of the thirty-
fourth annual hawaii international conference on system science (hicss-34) .
ieee computer society press, los alamitos, california, 2001.