removing operational friction in shared 
services using process mining  
 
both shared services and process mining aim at improving performance and compliance of operational 
processes. the key idea of shared services is to share efforts and resources for processes that are common 
among organizations or departments. the goal is tw ofold: (1) increasing efficiency and reducing costs by 
avoiding the replication of resources and (2) improving quality and effectiveness by the industrialization  
of service processes. s hared -service organization s aim to provide 'economies of scale ', but ma ny shared -
service projects fail  because moving the work to a central location may lead to hand -offs, rework, 
duplication, and ineffective communication. fortunately, process mining can be used to address these 
problems.  using the event data collected in an y shared -service organization , one can show the real 
processes and uncover inefficiencies (e.g., rework), bottlenecks, and undesired deviations.    
 
what is process mining?  
the author started to work on p rocess mining in the late nineties when he developed  the first process 
mining techniques to discover operational processes from event data. the main motivation for looking at 
event data was the low quality of process models used as input for business process management (bpm) 
and workflow management (wfm) pr ojects. processes modeled in notations such as bpmn, uml activity 
diagrams, or epcs tend to oversimplify reality.  implementing bpm/wfm systems based on these 
simplified process diagrams are a recipe for d isaster . as an example, take the order -to-cash (o2c)  process 
of a large multinational that processes over 30 million ordered items per year. these 30 million cases (i.e., 
instances of the o2c process) generate over 300 million events per year. over  60 different activities may 
occur . although the o2c process  is fairly standard, over 900,000 process variants  can be observed in one 
year! these variants  describe  different ways of executing this process. this real -life example shows that 
traditional process modeling cannot  capture the complexity of real-life oper ational  processes.  
input for process mining is an event log. an event log 'views'  a process from a particular angle. each event 
in the log refers to (1) a particular process instance (called case), (2) an activity, and (3) a timestamp. there 
may be additio nal event attributes referring to resources, people, costs, etc., but these are optional. 
events logs  are related to process models (discovered or hand -made). process models can be expressed 
using different formalisms ranging from directly -follows graphs ( dfgs) and accepting a utomata to petri 
nets, bpmn diagrams, and uml activity diagrams. typically,  four types of process mining  are identified . 
 process discovery:  learning process models from event data. a discovery technique takes an 
event log and produces a process model without using additional information. an example is the 
well-known alpha -algorithm, which  takes an event log and produces a petri net explaining  the 
behavior recorded in the log. most of the commercial process mining tools first discover dfgs 
before conduc ting further analysis.  
 conformance checking:  detecting and diagnosing both differences and commonalities between 
an ev ent log and a process mode l. conformance checking can be used to check if reality, as recorded in the log, conforms to the model and vice versa. the process model used as input may 
be descriptive or normative. moreover, the process model may have been made by hand or 
learned using process discovery.  
 process reengineering:  improving or extending the model based on event data. like for 
conformance checking, both an event log and a process model are used as input. however, now , 
the goal is not to diagnose differences. the goal is to ch ange the process model. for example, it 
is possible to repair  the model to better reflect reality. it is also possible to enrich an existing 
process model with additional perspectives. for example, replay techniques can be used to show 
bottlenecks or resou rce usage.  process reengineering yields updated models. these models can 
be used to improve the actual processes.  
 operational support:  directly influencing the process by providing warnings, predictions, or 
recommendations. conformance checking can be done  'on-the-fly' allowing people to act the 
moment things deviate. based on the model and event data related to running process instances, 
one can predict the remaining flow time, the likelihood of meeting the legal deadline, the 
associated costs, the probabi lity that a case will be rejected, etc. the process is not improved by 
changing the model, but by directly providing data -driven support in the form of warnings, 
predictions, and/or recommendations.  
all techniques start from the so -called control -flow pers pective, which  focuses on the ordering of 
activities.  then the time perspective (bottlenecks, delays, and frequencies), the data perspective 
(understanding decisions), and the resource and organization perspective  (social networks, roles, and 
authorization s) are added.  
until 2010 there were only a few commercial process mining tools (futura reflect by futura process 
intelligence, disco by fluxicon, and interstage automated business process discovery by fujitsu were 
notable exceptions). since 2010 there has been a rapid increase in the number of tools and their maturity. 
for example, celonis process mining (celonis) was introduced in 2011, minit (gradient ecm) was 
introduced in 2014, and processgold enterprise platform (processgold) was introduced in 2016. cu rrently, 
there are over 25 commercial tools available. these tools can easily deal with event logs having millions 
of events.  
 
figure 1: a process model discovered by prom based on sap data. the process model shows the dominant be havior in the 
purchase -to-pay (p2p) process. the numbers indicate frequencies , and the yellow dots refer to actual purchase orders.  
how to remove operational friction?  
shared -service organizations  aim to streamline processes and benefit from economies of s cale. however, 
as our earlier o2c example already showed, also standard processes tend to have many variants. thirty  
million cases  may generate 900,000 different process variants. a process variant is a sequence of activities, 
also called a trace, followed by at least one case. the most frequent process variant occurred over 3 million 
times, but there are also variants that are rare.  typically, activities and traces (i.e., process variants) follow 
a pareto distribution  (also known as the "80 -20 rule" or "power law") . often, a small percentage of 
activities accounts for most of the events and a small percentage of trace variants accoun ts for most of 
the traces.  20% of all variants may be able to explain 80% of all cases. however, the remaining 20% of 
cases account for 80% of the variants. many of these infrequent variants involve rework, passing the buck 
(leaving  a difficult problem for  someone else to deal with ), communication errors, and repair actions . 
some of these process variants make sense when dealing with exceptional cases. however, most 
deviations from the so -called 'happy path'  represent 'operational friction '.  process discov ery and 
conformance checking can reveal such operational friction s. it is possible to identify cases (1) that deviate 
from a normative process or that can be considered as outliers and (2) tha t have a poor performance (e.g., 
taking too long or inducing hig h costs). this information can be used to improve processes. after 
identifying sources of friction, process mining can be used in a continuous manner  providing actionable 
information.  
 
figure 2: conformance diagnostics provided by  prom for the purchase -to-pay (p2p) process using sap data. the red arcs show 
deviations from the mainstream process indicated in red. it is possible to drill -down on the cases exhibiting particular deviations.   
how can i start?  
next to the commercial pro cess mining systems that are generally easy to use, one can also start with 
open -source software like prom. prom provides over 1500 plug -ins supporting process discovery, 
conformance checking, process reengineering, and operational support.  event data can be loaded from 
databases . however, it is often easier to start with a simple event log stored in csv format or xes format. 
in a csv file each row refers to an event and the columns refer to  case, activity, timestamp, etc. xes is the 
ieee standard for stori ng event data (see www.xes -standard.org ) supported by tools such as prom, 
celonis, disco, processgold, minit, qpr, and myinvenio. several repositories provide publically available 
xes data, see for example https://data.4tu.nl/repository/collection:event_logs_real .  
 
how about rpa?  
most process mining projects do not involve robotic process automation (rpa) . the scope of process 
mining is much broader than rpa. process mining often  result s in organizational and managerial changes 
without automation or the introduction of new it systems.  however, process mining may play a key role 
in successful rpa projects. rpa aims to replace people by automation done in an 'outside -in' manner. t his 
differs from the classical 'inside -out' approach to improve information systems. unlike traditional 
workflow technology, the information system remains unchanged  and the robots u se the same interface 
as the humans they are replacing  or supporting . process mining can be used to  automatically visualize and 
select processes with the highest automation potential, and subsequently, build, test, and deploy rpa 
robots  driven by the disco vered process models.  
 
about the first international process mining conference (icpm)  
the international conference on process mining (icpm) is the first conference devoted to the rapidly 
growing process mining discipline. the conference will take place in aachen, germany from 24 -26 june 
2019.  all thought leaders working on process mining will be present at icpm 2019. the program includes 
a fully packed industry day next to exciting scientific talks by the leading scientists in the field. the 
conference is supported by all the main vendors providing process -mining software. however, the 
conference is neutral and provides insights that are tool independent. this makes icpm 2019 'the place 
to be ' for anyone working on process mining. moreover, it provides a gr eat stepping -stone of those that 
are new to the topic. next  to a range of excellent speakers, there will be the possibility to see the state -
of-the-art in action (e.g., dozens of tool demonstrations) and discuss real -life process mining experiences. 
next t o the leading academics, speakers from gartner, siemens, deloitte, ernst & young , dhl, merck, 
metronic, and many other organizations will provide novel insights in this new an exciting technology. 
visit https://i cpmconference.org  to register.  
 
about the author  
prof.dr.ir. wil van der aalst is a full professor at rwth aachen university leading the process and data 
science (pads) group. he is also part -time affiliated with the fraunhofer -institut für angewandte 
informationstechnik (fit) where he leads fit's process mining group. his research interests include 
process mining, petri nets, business process management, workflow management, process modeling, and 
process analysis. wil van der aalst has published over 220 j ournal papers, 20 books (as author or editor), 
500 refereed conference/workshop publications, and 75 book chapters. next to serving on the editorial 
boards of over ten scientific journals, he is also playing an advisory role for several companies, inclu ding 
fluxicon, celonis, processg old, and bright cape. van der aalst received honorary degrees from the 
moscow higher school of economics (prof. h.c.), tsinghua university, and hasselt university (dr. h.c.). he 
is also an elected member of the royal netherland s academy of arts and sciences, the royal holland 
society of sciences and humanities, and the academy of europe. in 2018, he was awarded an alexander -
von-humboldt professorship  (the most valuable german research award) . 
for the photo use http://www.padsweb.rwth -aachen.de/wvdaalst/about_me/wvda -bvo-24059.jpg  
(photo  is license -free, credits go to bart van overbeeke photography ).  