a framework for extracting and encoding
features from object-centric event data
jan niklas adams1[0000 −0001−8954−4925], gyunam park1[0000 −0001−9394−6513],
sergej levich3, daniel schuster2,1[0000 −0002−6512−9580], and wil m.p. van der
aalst1,2[0000 −0002−0955−6940]
1process and data science, rwth aachen university, aachen, germany
{niklas.adams,gnpark,schuster,wvdaalst }@pads.rwth-aachen.de
2fraunhofer institute for applied information technology
3information systems research, university of freiburg, freiburg, germany
sergej.levich@is.uni-freiburg.de
abstract. traditional process mining techniques take event data as in-
put where each event is associated with exactly one object. an object
represents the instantiation of a process. object-centric event data con-
tain events associated with multiple objects expressing the interaction
of multiple processes. as traditional process mining techniques assume
events associated with exactly one object, these techniques cannot be
applied to object-centric event data. to use traditional process mining
techniques, object-centric event data are flattened by removing all object
references but one. the flattening process is lossy, leading to inaccurate
features extracted from flattened data. furthermore, the graph-like struc-
ture of object-centric event data is lost when flattening. in this paper,
we introduce a general framework for extracting and encoding features
from object-centric event data. we calculate features natively on the
object-centric event data, leading to accurate measures. furthermore,
we provide three encodings for these features: tabular ,sequential , and
graph-based . while tabular and sequential encodings have been heavily
used in process mining, the graph-based encoding is a new technique
preserving the structure of the object-centric event data. we provide six
use cases: a visualization and a prediction use case for each of the three
encodings. we use explainable ai in the prediction use cases to show
the utility of both the object-centric features and the structure of the
sequential and graph-based encoding for a predictive model.
keywords: object-centric process mining ·machine learning ·ex-
plainable ai.
1 introduction
process mining [1] is a branch of computer science producing data-driven insights
and actions from event data generated by processes. these insights are typically
grouped into three categories: process discovery, conformance checking, and en-
hancement. process discovery techniques create process models describing the2 j. n. adams et al.
fig. 1: an object-centric event log and the underlying structure of events. the left-
hand side depicts the event log. events may be associated with multiple objects of
different object types (here: order and item). the right-hand side shows the graph of
directly-follows relationships for the events given by the objects. an event with multiple
objects may have multiple predecessor events.
possible paths of actions in a process. conformance checking techniques quantify
and qualify the correspondence between a process model and event data. pro-
cess enhancement techniques take an encoding of features of the event data as
input and deliver insights, predictions, or actions as output. such enhancement
techniques include process performance analysis [20,24], prediction [10,26,29] or
clustering of similar process executions [25].
generally, process enhancement techniques encode features of event data in
either of two ways: as a table [18,9] or as a set of sequences [12,26,19]. in a
tabular encoding, each row corresponds to feature values for, e.g., an event.
this tabular encoding is used, for example, for regression, decision trees, and
feed-forward neural networks. however, each process execution (also: case) is a
timely ordered sequence of events. therefore, summarizing event data to tabular
encoding removes the sequential structure of the event data. since this structure
itself is meaningful, sequential encodings were developed [19]. these encodings
represent each process execution as a sequence of feature values and are used for
predictive models considering sequentially encoded data, such as lstms [26], or
to visualize the variant of the process execution.
traditional process mining builds on two central assumptions: each event
is associated with exactly one object (the case) and each object is of the same
type. each object is associated with a sequence of events. a traditional event
log, therefore, describes a collection of homogeneously typed, isolated event se-
quences. this is a valid assumption when analyzing, e.g., the handling of insur-
ance claims. in this example, each object describes an instantiation of the same
type: an insurance claim. events are associated to exactly one insurance claim.
however, real-life information systems often paint another picture: events mayextracting and encoding features from object-centric event data 3
fig. 2: flattening an object-centric event log (cf. fig. 1) such that it can be used for tra-
ditional process enhancement techniques. the event log is transformed into sequences
of a chosen case notion. due to deficiency, convergence and divergence, the features
calculated on a flattened log might be misleading, e.g., through missing events. fur-
thermore, the graph-like structure of the original event log is lost.
be related to multiple objects of different types [3,4,11,28]. the most prominent
example of information systems generating event data with multiple associated
objects are erp systems. objects in such systems would correspond to, e.g.,
an order, different items of this order, and invoices in an order-to-cash process.
consider the simplified example of an order handling process depicted in fig. 1.
an event may be related to objects of type order, item, or both. an event with
multiple objects may have multiple predecessor events. therefore, the structure
of an object-centric event log (ocel) resembles a graph, not a sequential
structure as is assumed in traditional process mining.
this gap between ocels and traditional process enhancement techniques
is currently bridged by flattening an event log [2], i.e., mapping an ocel into
traditional event log format by enforcing a homogeneous, sequential structure.
this involves two steps: choosing a case notion and duplicating events with
multiple objects of that notion. all objects not included in this case notion
are discarded. flattening the event log of fig. 1 is depicted in fig. 2 for three
different case notions. the first two are case notions of a single object type [2].4 j. n. adams et al.
fig. 3: our framework enables accurate feature extraction for object-centric event
data. furthermore, we provide three encodings for object-centric features: tabular,
sequential, and graph-based. we present a visualization and prediction use case for
each encoding.
the third case notion is a composite case notion of co-appearing orders and
items, i.e., an order and all corresponding items. the flattened event data may
be used as input for traditional process enhancement techniques.
however, flattening manipulates the information of the object-centric event
log. the problems related to flattening are deficiency (disappearing events) [3],
convergence (duplicated events) [2] and divergence (misleading directly-follows
relations) [28,2]. we showcase divergence using an example. one might use a
composite case notion of order and item to flatten the event log (cf. fig. 2 case
notion: order & item). all orders and items related through events form one
composite object, i.e., o1,i1,i2, and o2,i3. the events of these objects are flattened
to one sequence, introducing inaccurate precedence constraints. e.g., events e3
ande4, which describe an item being picked, are now sequentially ordered, in-
dicating some order between them. however, the original event data show that
these two picking events are independent. the same holds for the relationship
of pick item and pay order: the object-centric event data do not indicate any
precedence constraint. however, the sequential representation enforces one.
the three problems of flattening have major consequences on the quality of
the calculated features of the flattened ocel: due to missing events, dupli-
cated events, or wrong precedence constraints, many features deliver incorrect
results (cf. sec. 4). furthermore, the tabular or sequential encoding constructed
from these features does not preserve the graph-like structure of the event data,
removing important structural information. therefore, features for ocels can
not accurately be extracted and encoded.
to solve the previously mentioned problem, an approach is necessary that
calculates features natively on the object-centric event data and enables a graph-
based encoding preserving the actual structure of the event log. in this paper, weextracting and encoding features from object-centric event data 5
table 1: process enhancement techniques and supporting frameworks.
feature extraction feature encoding existing
work object-centric flattened tabular sequential graph-based
(a) process
enhancement
techniquesp1 ✓ ✓ [9,13]
p2 ✓ ✓ [19,12,26]
p3 ✓ ✓ [23,27,16]
(b)
frameworksf1 ✓ ✓ [18]
f2 ✓ ✓ [7,14]
this paper ✓ ✓ ✓ ✓
introduce a general framework for extracting and encoding features for object-
centric event data (cf. fig. 3), providing two contributions: 1)we translate the
computation of the features introduced in the framework of de leoni et. al [18]
to the object-centric setting, providing accurate measures. 2)we provide three
different encodings to represent the extracted features for different algorithms
and methods: tabular, sequential, and graph-based. using features and encoding,
we provide six use cases. these use cases showcase the generalizability of our
framework to a plethora of different tasks. we use one visualization and one
prediction use case for each encoding. in the prediction use cases, we depict how
the different features and the structure of the encodings are utilized by predictive
models, leveraging on explainable ai and shap values [21]. these contributions
may be used as a foundation for new algorithms, new visualizations, new machine
learning models, more accurate predictions, and more.
this paper is structured as follows. first, we discuss related work on feature
extraction and encoding in sec. 2. we introduce object-centric event data and
process executions in sec. 3. in sec. 4, we provide an overview of native feature
calculation for object-centric event data. in sec. 5, we define three encodings
for object-centric features. sec. 6 depicts our six use cases for features and their
encodings. we conclude this paper in sec. 7.
2 related work
a plethora of process enhancement techniques exist in the literature, including
process performance analysis, predictive process monitoring, and trace cluster-
ing [1]. such techniques use encoded features extracted from an event log as
input. table 1(a) shows three categories of techniques using different feature
extraction (i.e., feature extractions using 1. ocels and 2. flattened event logs)
and encoding (i.e., 1. tabular, 2. sequential, and 3. graph encoding) approaches
with representative examples. first, p1represents the techniques using features
extracted from flattened event logs and encoded as tabular formats. for in-
stance, van dongen et al. [9] use tabular encoding by transforming an event
log into feature-outcome pairs to predict remaining times using non-parametric
regression. also, in [13], an event log is encoded into a tabular format with
additional features on context, e.g., resource availability, to predict processing
times. second, techniques in p2also use features based on flattened event logs
but encoded as sequential formats. leontjeva et al. [19] propose complex se-6 j. n. adams et al.
quence encoding to encode an event log to sequences to predict the outcome of
an ongoing case. to predict the next activity of an ongoing case, evermann et
al. [12] encode control-flow features using embedding techniques, whereas tax et
al. [26] use one-hot encoding . finally, p3consists of techniques using features
extracted from flattened event logs and encoded as graph formats. philipp et
al. [23] encode an event log to a graph where each node represents an activity,
and each edge indicates the relationship between activities. the graph is used to
learn a graph neural network (gnn) to predict process outcomes. venugopal
et al. [27] extend [23] by annotating nodes with temporal features. they use
gnns to predict the next activity and next timestamp of an event. instead of
representing a node as an activity, harl et al. [16] uses one-hot encoding of an
activity to represent a node to deploy gated graph neural network that provides
the explainability based on relevance score .
furthermore, to support the development of process enhancement techniques
using different feature extraction and encoding, several frameworks have been
proposed (cf. table 1(b)). first, de leoni [18] in f1suggest a framework to
compute features using flattened event logs and encode them to tables. second,
becker et al. [7] and di francescomarino et al. [14] in f2propose frameworks
for techniques for sequentially encoding extracted features. to the best of our
knowledge, no framework supporting graph encoding exists.
despite the limitations of flattened event logs to extract misleading features,
no study has been conducted to develop process enhancement techniques using
features based on ocels. in this work, we provide a framework for extract-
ing and encoding features based on ocels, with the goal of facilitating the
development of object-centric process enhancement approaches. our proposed
framework supports all existing encoding formats, i.e., tabular, sequential, and
graph, to be used for different algorithms and methods.
3 object-centric event data
given a set x, the powerset p(x) denotes the set of all possible subsets. a
sequence σ:{1, . . . , n } →xof length len(σ) =nassigns order to elements of
x. we denote a sequence with σ=⟨x1, . . . , x n⟩and the set of all sequences over
xwith x∗. we overload the notion x∈σto express x∈range (σ).
a graph is a tuple g= (v, e) of nodes vand edges e⊆v×v. the set of
all subgraphs of gis given by sub(g) ={(v′,(v′×v′)∩e)|v′⊆v}. a path
connects two distinct nodes through edges. the set of paths between two nodes
v, v′∈v, v̸=v′is defined by pathg(v, v′) ={⟨(v, v1),(v1, v2), . . . , (vk, v′)⟩ ∈
e∗}. two distinct nodes are connected if the set of paths between them is not
empty pathg(v, v′)̸=∅. the distance between two nodes is the length of the
shortest path distg(v, v′) =len(σd) such that σd∈pathg(v, v′)∧¬∃ σ′
d∈pathg(v,v′)
len(σd)> len (σ′
d). a graph g= (v, e) is connected iff a path exists between
all edges ∀v,v′∈vv̸=v′∧pathg(v, v′)̸=∅. the set of connected subgraphs of
g= (v, e) is defined as follows consub (g) ={g′∈sub(g)|g′is connected }.extracting and encoding features from object-centric event data 7
an event log is a collection of events associated with objects. each event con-
tains an activity, describing the executed action, a start and complete timestamp
and additional attributes. each object is associated to a sequence of events.
definition 1 (event log). letebe the universe of events, obe the uni-
verse of objects, otbe the universe of object types, abe the universe of ac-
tivities, cbe the universe of attributes and vbe the universe of attribute val-
ues. let a⊆ a be a set of activities and c⊆ c be a set of attributes. each
object is mapped to exactly one object type πtype :o → ot . an event log
l= (e, o, ot, π ct, πst, πtrace, πact, πatt)is a tuple composed of
•events e⊆ e, objects o⊆ o, and object types ot⊆ ot ,
•two time mappings for the completion πct:e→rand the start πst:e→r
of an event such that πst(e)≤πct(e)for any e∈e,
•a mapping πtrace :o→e∗mapping each object to a sequence of events such
that∀o∈oπtrace(o) =⟨e1, . . . , e n⟩ ∧ ∀ i∈{1,...n−1}πct(ei)≤πct(ei+1),
•an activity mapping πact:e→aand,
•an attribute mapping πatt:e×c↛v.
the table in fig. 1 depicts an example of an ocel. a row corresponds to one
event. sorting the events of an object in timely order, we retrieve the event
sequence for the object, e.g., πtrace(i3) = ⟨place order ,pick item ,send delivery ,
delivery received ⟩. the relationships between objects can be expressed in the
form of a graph, connecting objects that share events.
definition 2 (object graph). letl= (e, o, ot, π ct, πst, πtrace, πact, πatt)
be an event log. we denote the objects of an event e∈ewith πobj(e)={o∈o|
e∈πtrace(o)}. the object graph og l=(o, i)is an undirected graph of nodes o
and edges of object interactions i={{o, o′}⊆o|o̸=o′∧ ∃e∈e{o, o′} ⊆πobj(e)}.
objects which are directly or transitively connected in the object graph depend
on each other by sharing events. in traditional process mining, a process execu-
tion (case) is the event sequence of one object. we use the definitions of process
executions [6] and generalize this notion such that a process execution is the set
of events for multiple, connected objects.
definition 3 (process execution). letl= (e, o, ot, π ct, πst, πtrace, πact,
πatt)be an event log and og l= (o, i)be the corresponding object graph. a
process execution p= (o′, e′)is a tuple of objects o′⊆oand events e′⊆e
such that e′∈e′⇔πobj(e′)⊆o′ando′forms a connected subgraph in og l.
we define two techniques to extract process executions from an ocel. these
two techniques are two out of many possible process execution extraction tech-
niques. the first technique extracts process executions based on the connected
components of the object graph. all transitively connected objects form one
process execution. this might lead to large executions for entangled event logs.
therefore, we introduce the leading type extraction. a process execution is con-
structed for each object of a chosen leading object type. connected objects are
added to this process execution unless a connected object of the same type has8 j. n. adams et al.
a lower distance to the leading object. this limits executions in size but also
removes dependencies.
definition 4 (execution extraction). letl=(e, o, ot, π ct, πst, πtrace, πact,
πatt)be an event log. an execution extraction ex ⊆consub (ogl)retrieves con-
nected subgraphs from the object graph. a subgraph ex = (o′, i′)∈ex is mapped
to a process execution fextract(ex, l) = (o′, e′)withe′={e∈e|o′∩obj(e)̸=
∅}. we define two extraction techniques:
•excomp(l) ={g∈consub (ogl)| ¬∃g′∈consub (ogl)g∈sub(g′)}, and
•exlead(l,ot) ={g∈lead graphs ={g′= (o′, i′)∈consub (ogl)|
∃o∈o′πtype(o) = ot∧ ∀o′∈o′¬∃o′′∈o′o′′̸=o′∧πtype(o′′) = πtype(o′)∧
distg′(o, o′)>distg′(o, o′′)} | ¬∃ g′′∈lead graphs g∈sub(g′′)}for ot ∈ot.
when looking at the example of fig. 1, the process executions retrieved by
applying excomp would be based on the connected components of the object
graph, i.e., {o1, i1, i2}and{o2, i3}. using the leading type order, we would
retrieve the same executions. using item as the leading type, we would retrieve
{i1, o1},{i2, o1}and{i3, o2}.
4 object-centric features
this section deals with the problem resulting from flattening ocels to apply
process enhancement techniques: features are calculated on the manipulated,
flattened event data. therefore, they might be inaccurate. we propose an object-
centric adaptation of the features introduced by the seminal machine learning
framework of de leoni et al. [18]. we calculate them natively on the ocel. fur-
thermore, we provide several new features recently introduced in the literature
on object-centric process mining. a feature is, generally, calculated for an event.
it might describe a measure for the single event, in relationship to its process
executions, or the whole system.
definition 5 (features). letl= (e, o, ot, π ct, πst, πtrace, πact, πatt)be an
event log and ex ⊆consub (ogl)be a set of extracted process executions. a
feature fl:e×ex↛rmaps an event and a process execution onto a real number.
the primary need for adapting traditional feature calculation arises from two
main differentiations between object-centric and traditional event data: first,
each event can have multiple predeccesors/successors, one for each object. sec-
ond, each event might have multiple objects of different types. the computation
of features that are depended on previous and following behavior has to be
adapted to the graph structure. the most obvious example are preceding ac-
tivities: in traditional feature extraction, there is only one preceding activity
for each event. in object-centric feature extraction, there are multiple preceding
activities, one for each object. the graph-structure as well as the multiplicity
of objects also enables the definition of new features leveraging on the graph
structure and object (type) associations. previous (i.e., all events that happened
before the considered event in an execution) and following events can be adaptedextracting and encoding features from object-centric event data 9
fig. 4: overview of the features that can be extracted for event e6. these features are
the object-centric adaptations of [18].
in two ways: time-based (using the event’s timestamp) and path-based (using
path information of the graph). we use a simple time-based adaptation. how-
ever, the graph-based adaptation might give interesting new research directions.
an overview of the features collected from an object-centric adaptation of de
leoni et al.’s framework [18] and features recently introduced in the literature
[3,22] is depicted in fig. 4. similar to de leoni et al., we group features according
to different perspectives: control-flow, data-flow, resource, performance and
objects. we, now, discuss the different perspectives and the adaptations that
are necessary to apply them to the object-centric setting. table 2 provides a
qualitative evaluation of the impact of flattening on the resulting feature value:
features can be equal, they can be misleading/incorrect after flattening, and not
be available for flat event data.
the main adaptations of the control-flow perspectives are concerned with
the switch from sequential to graph-like control-flow. multiple preceding activ-
ities ( c2) as well as multiple current activities ( c1) (endpoints of the current
execution graph) are possible. for previous and following activities ( c3,c4),
we use a simple time-based adaptation.
the data-flow perspective needs slight adaptations for preceding character-
istic values ( d2). since there might be multiple preceding values, these need to
be aggregated. previous characteristic values ( d1) are adapted on a time basis,
and the characteristic value ( d3) needs no adaptation.10 j. n. adams et al.
table 2: impact of flattening on calculated feature values. calculating a feature for
an event on object-centric vs. flattened data can lead to correct or misleading results.
some features only exist on object-centric event data. most features are misleading due
to the graph structure and object multiplicity.
featuresimpact of flatteningonly available for ocelcorrect misleading
control-flowc1,c2,c3,c4 ✓
c5 ✓
datad1,d2 ✓
d3 ✓
resourcer1 ✓
r2,r3 ✓
performancep1,p2,p3,p6,p10 ✓
p4,p5,p7,p8 ✓
p9 ✓
objects o1,o2,o3,o4,o5 ✓
the resources perspective’s features are mainly concerned with system-wide
measurements, such as the workload of the current resource ( c1) or the total
system workload ( c2). therefore, this perspective remains mostly unaffected
by a move to object-centricity. future research might investigate new features
derived from resource multiplicity per event.
the performance perspective has recently been studied for new object-centric
features [22]. due to an event having multiple predecessors, the established per-
formance measures can be extended by several features expressing the time for
synchronization between objects ( p5), the pooling time of an object type ( p7),
or the lag between object types before the event ( p8).
finally, a new feature perspective concerning objects opens up. the paper
introducing the discovery of object-centric petri nets [3] introduces some basic
features of the object perspective. for example, an event’s number of objects
(o5), the event’s number of objects of a specific type ( o6), or the current
system’s total object count ( o1). investigations of additional features in this
perspective, e.g., quantifying the relationships between objects through graph
metrics on the object graph, might also be an interesting research direction.
5 feature encodings
in this section, we tackle the absence of feature encodings that represent the
graph-like structure of object-centric event data. we extend the currently used
tabular and sequential encodings with a graph-based one and introduce all three
encodings formally. together with the formal definition of each encoding, we
provide some common use cases, advantages, disadvantages and a continuation of
our running example from fig. 1. as an example of extracted features we choose
the number of previous objects ( o2), the synchronization time ( p5) and the
remaining time ( p3). the execution extraction for our example is the connectedextracting and encoding features from object-centric event data 11
fig. 5: example of tabular a), sequential b) and graph-based c) feature encodings
for the running example in fig. 1. the graph-based encoding preserves the structural
information from the ocel.
components extraction excomp. a tabular encoding is a common representation
of data points used for many use cases, such as regression analysis, clustering,
different data mining tasks, etc.
definition 6 (tabular encoding). letl= (e, o, ot, π ct, πst, πtrace, πact,
πatt)be an event log and ex ⊆consub (ogl)be a set of process executions. let
fl⊆e×ex↛ r be a set of features. the event feature table is defined by
tab(e, fl) =fl(e,ex)for all e∈e, ex∈ex (rows) and all fl∈fl(columns).
we depict an example of tabular encoding in fig. 5 a). such an encoding is easily
readable and versatile usable, however, the structural order information of the
event log is lost in the process of tabular encoding. a sequential encoding is
commonly used in sequence visualization, clustering, classification or next value
predictions (cf. sec. 2).
definition 7 (sequential encoding). letl= (e, o, ot, π ct, πst, πtrace, πact,
πatt)be an event log and ex ⊆consub (ogl)be a set of extracted process execu-
tions. let fl={fl,1, . . . , f l,m}⊆e×ex↛rbe a set of features. the sequential
encoding of an execution ex ∈ex is defined by seq (ex, fl) =⟨(fl,1(e1,ex), . . . ,
fl,m(e1,ex)), . . . , (fl,1(en,ex), . . . , f l,m(en,ex))⟩with with (o′,{e1, . . . , e n}) =
fextract(ex, l)andπct(e1)≤ ··· ≤ πct(en).
we depict a sequential encoding of the running example in fig. 5 b). the
events for process executions are ordered according to the complete timestamp of12 j. n. adams et al.
table 3: results for the different models based on different encodings.
regression lstm gnn
baseline mae 0.7598
train mae 0.5101 0.4717 0.4460
validation mae na 0.4625 0.4534
test mae 0.5087 0.4568 0.4497
the event. the resulting sequence is attributed with the different feature values
for each event. this encoding respects the timely order of events. however, it does
not respect the true precedence constraints of the event log : by merging all events
into one sequence, some event pairs are forced into a precedence relationships
they did not exhibit in the event log (cf. sec. 1). a graph encoding of features
may be used for extensive visualization, applying graph algorithms or for utilizing
graph neural networks [30].
definition 8 (graph encoding). letl=(e, o, ot, π ct, πst, πtrace, πact, πatt)
be an event log ex ⊆consub (ogl)be a set of extracted process executions. let
fl={fl,1, . . . , f l,m} ⊆e×ex↛ r be a set of features. for an extracted exe-
cution ex ∈ex , the graph of the corresponding process execution p= (o′, e′) =
fextract(ex, l)is defined by gp= (e′, k)with edges k={(e, e′)∈e′×e′|e̸=
e′∧o∈o′∧ ⟨e1, . . . , e n⟩ ∈πtrace(o)∧e=ei∧e′=ei+1∧i∈ {1, . . . , n −1}}).
the graph encoding is defined by gfeat(p, fl) = ( e′, k, l)with a node labeling
function l(e) ={fl(e,ex)|fl∈fl}for any e∈e′.
an example of the graph-based feature encoding for our running example is
depicted in fig. 5 c). each process execution is associated with a graph. each
node of the graph represents the feature values of an event.
6 use cases
in this section, we evaluate our framework by providing six use cases. we pursue
two evaluation goals with this approach: first, we aim to showcase the general-
izability of the framework by providing a collection of common process mining
tasks the framework can be applied to. second, we aim to showcase the feature’s
and encoding’s effectiveness in the use cases. over the last years, explainable ai
has been increasingly employed to make predictive process monitoring transpar-
ent [15,17]. through the use of shap [21] values, we are able to quantify feature
importance as well as structural importance of sequential and graph-based en-
coding.
the use cases are split into two parts: three visualization and three predic-
tion use cases. we use a real-life loan application event log [8] as an ocel. an
event can be related to an application and multiple loan offers as objects. we use
tabular, sequential, and graph-based encoding to gain insights into the process
through the visualization use cases. the prediction use cases aim at predicting
the remaining time of an event’s process execution ( p3) using three different
techniques for the different encodings: regression (tabular), lstm neural net-
works (sequential), and gnns (graph-based). we use the same features for eachextracting and encoding features from object-centric event data 13
fig. 6: time series describing two features over time: the weekly average number of
loan offers per event and the weekly average requested amount for each application.
using this evaluation some initial insights can be generated, e.g., the gradual increase
in requested amount over time.
encoding: preceding activities ( c2), average previous requested amount ( d1),
the elapsed time ( p2), and the previous number of offers ( o3). we use a 0.7/0.3
train/test split of the same events for each model for comparability reasons. we
set aside 20% of the training set as a validation set. the performance is assessed
using the mean absolute error (mae) of the normalized target variable. fur-
thermore, we provide a baseline mae achieved by predicting the training set’s
average remaining time. the summarized results are depicted in table 3.
we provide an open-source python implementation of our framework1. our
experiments can ge reproduced through a github repository2. the framework
can be extended with new features and adapted algorithms.
6.1 tabular encoding
visualization we split the event log into subsequent sublogs containing the
events of one week each. for each sublog, we extract the average requested
amount ( d3) and the number of offers per event ( o6). the resulting time series
is depicted in fig. 6. we can observe the dynamics of the process over time, e.g.,
the increase in the requested amount over time. furthermore, we can observe
that the number of offers is stable, except for a few short spikes.
prediction we use a linear regression model to predict the remaining time based
on the tabular encoding (cf. table 3). this is an object-centric adaption of use
cases [9,13]. we generate the shap values, i.e., the impact of different features
on the individual model prediction, for 1000 predictions of the test set. the
resulting bee swarm plot is depicted in fig. 7 (left side). red points indicate a
high feature value. the more they are positioned to the left, the more the feature
value reduces the model’s prediction. therefore, the combination of color and
position gives insights into the feature value’s impact on the model output. we
can, e.g., observe a high decreasing impact of the existence of the call activity
in the preceding activities to the predicted remaining time. one can also observe
an impact of the new object-centric feature of the number of previous objects
1https://github.com/ocpm/ocpa
2https://github.com/niklasadams/ocelfeatureextractionexperiments14 j. n. adams et al.
fig. 7: left: bee swarm plot of shap values for the regression model, showing the
aggregated importance of different features to the predictions. right: shap values of
one lstm prediction, visualized for the different positions of the input sequence.
fig. 8: sequential variant visualization of a process execution enriched with the object
information (blue = application, orange = first and second offer).
of type offer on the predicted remaining time: the more offers were previously
recorded in a case, the lower the predicted remaining time. in conclusion, the
selected set of object-centric feature adaptations yields valuable information for
a predictive model.
6.2 sequential encoding
visualization we choose one specific process execution and extract the sequen-
tial encoding for the current event’s activity ( c5) and the event’s objects ( o4)
features. the result is a variant enriched by object information, depicted in
fig. 8. even though such a visualization might have misleading causality infor-
mation for events between objects, one can already retrieve some valuable insight
into the intra-object order and the overall activities of an execution.
prediction we use a neural network with two 10-hidden-node lstm layers to
predict the remaining time of the sequentially encoded features. we use subse-
quences of length four (cf. table 3 for results). this is an object-centric adaption
of use cases [26,19]. the regression use case already covered the importance of
features for the prediction. therefore, we focus on the importance of the se-
quential encoding in this use case. we use shap values for each feature of theextracting and encoding features from object-centric event data 15
fig. 9: use cases for the graph encoding: a) activities and objects of one process
execution. shared events between objects are colored with multiple colors. b) shows
the importance of different edges of one instance graph when predicting.
four positions in the sequential encoding. the calculated feature impacts for an
individual prediction are depicted in fig. 7 (right side). the more the value
diverges from zero, the higher the feature’s impact on the model’s output. we
observe features with high importance among all four positions of the sequence.
therefore, the model utilizes the sequential encoding of the features, showcasing
its usefulness.
6.3 graph encoding
visualization fig. 9 a) depicts the graph-based variant visualization retrieved
from oc π[5] of the same process execution as fig. 8. using the graph, one
can place concurrent events in two different lanes according to their objects,
not indicating any precedence between them. one can intuitively determine the
concurrent paths in the variant and the interaction of different objects. for large
process executions, this provides structured access to the control-flow of the
underlying process.
prediction we use the graph-based feature encoding as an input for a gnn.
the gnn contains two graph convolution layers. each node in both layers has
a size of 24. input graphs are constrained to four nodes (cf. lstm use case).
we read the graphs out by averaging over the convoluted values, summarizing
to one predicted remaining time (cf. table 3 for results). this is an object-
centric adaptation of use cases [23,27]. we adapt shap values to determine the
importance of graph edges to the predicted remaining time. fig. 9 b) depicts the
calculated values for one graph instance. the more the value of an edge diverges
from zero, the higher its existence impacts the model’s prediction. we observe
substantially different values for all edges: while some edges have a relatively low
negative or positive impact on the model’s output, the presence of other edges
heavily impacts the predicted remaining time. therefore, the graph structure
itself yields important information for predicting the remaining time.
7 conclusion
we introduced a general framework to extract and encode features from ocels.
currently, object-centric event data needs to be flattened to apply process en-
hancement techniques to the data. this leads to inaccurate features. addi-
tionally, no feature encoding is available to express the graph-like structure of
object-centric event data. our framework calculates features natively on the
object-centric event data, leading to accurate features. furthermore, we provide16 j. n. adams et al.
a graph-based encoding of the features, preserving the underlying structure of
an ocel. we show the utility of the features and encodings in six use cases,
a visualization and prediction use case for each of the three encodings. this
framework lays a foundation for future machine learning approaches utilizing
object-centric event data and new algorithms using our encodings as a basis.
we provide a collection of use cases showing the applicability of our frame-
work for extracting and encoding features. for each of our framework steps,
interesting future research directions are present: which feature work well with
which encoding? what are the best prediction techniques for which encoding?
how to optimize existing network architectures to achieve maximum results?
furthermore, investigations of new features derived from the graph structure
and object-multiplicity as well as further traditional features not included in de
leoni et al.’s framework [18] is an interesting direction for future research.
references
1. van der aalst, w.m.p.: process mining: data science in action. springer (2016)
2. van der aalst, w.m.p.: object-centric process mining: dealing with diver-
gence and convergence in event data. in: sefm. pp. 3–25. springer (2019).
https://doi.org/10.1007/978-3-030-30446-1 1
3. van der aalst, w.m.p., berti, a.: discovering object-centric petri nets. fundam.
informaticae 175(1-4), 1–40 (2020). https://doi.org/10.3233/fi-2020-1946
4. adams, j.n., van der aalst, w.m.p.: precision and fitness in
object-centric process mining. in: icpm. pp. 128–135. ieee (2021).
https://doi.org/10.1109/icpm53251.2021.9576886
5. adams, j.n., van der aalst, w.m.p.: oc π: object-centric process in-
sights. in: petri nets. vol. 13288, pp. 139–150. springer (2022).
https://doi.org/10.1007/978-3-031-06653-5 8
6. adams, j.n., schuster, d., schmitz, s., schuh, g., van der aalst, w.m.p.: defining
cases and variants for object-centric event data. corr abs/2208.03235 (2022).
https://doi.org/10.48550/arxiv.2208.03235
7. becker, j., breuker, d., delfmann, p., matzner, m.: designing and implementing a
framework for event-based predictive modelling of business processes. in: emisa.
pp. 71–84. gi (2014)
8. van dongen, b.: bpi challenge 2017 (2017).
https://doi.org/10.4121/uuid:5f3067df-f10b-45da-b98b-86ae4c7a310b
9. van dongen, b.f., crooy, r.a., van der aalst, w.m.p.: cycle time prediction:
when will this case finally be finished? in: otm. pp. 319–336. springer (2008).
https://doi.org/10.1007/978-3-540-88871-0 22
10. ehrendorfer, m., mangler, j., rinderle-ma, s.: assessing the impact of context
data on process outcomes during runtime. in: icsoc. pp. 3–18. springer (2021).
https://doi.org/10.1007/978-3-030-91431-8 1
11. esser, s., fahland, d.: multi-dimensional event data in graph databases. j. data
semant. 10(1-2), 109–141 (2021). https://doi.org/10.1007/s13740-021-00122-1
12. evermann, j., rehse, j., fettke, p.: predicting process behaviour
using deep learning. decis. support syst. 100, 129–140 (2017).
https://doi.org/10.1016/j.dss.2017.04.003
13. folino, f., guarascio, m., pontieri, l.: discovering context-aware models for pre-
dicting business process performances. in: otm. pp. 287–304. springer (2012).
https://doi.org/10.1007/978-3-642-33606-5 18extracting and encoding features from object-centric event data 17
14. francescomarino, c.d., dumas, m., federici, m., ghidini, c., maggi, f.m., rizzi,
w.: predictive business process monitoring framework with hyperparameter op-
timization. in: caise. pp. 361–376. springer. https://doi.org/10.1007/978-3-319-
39696-5 22
15. galanti, r., coma-puig, b., de leoni, m., carmona, j., navarin, n.: ex-
plainable predictive process monitoring. in: icpm. pp. 1–8. ieee (2020).
https://doi.org/10.1109/icpm49681.2020.00012
16. harl, m., weinzierl, s., stierle, m., matzner, m.: explainable predictive business
process monitoring using gated graph neural networks. journal of decision systems
29(sup1), 312–327 (2020). https://doi.org/10.1080/12460125.2020.1780780
17. huang, t., metzger, a., pohl, k.: counterfactual explanations for predictive
business process monitoring. in: emcis. vol. 437, pp. 399–413. springer (2021).
https://doi.org/10.1007/978-3-030-95947-0 28
18. de leoni, m., van der aalst, w.m.p., dees, m.: a general process mining framework
for correlating, predicting and clustering dynamic behavior based on event logs.
inf. syst. 56, 235–257 (2016). https://doi.org/10.1016/j.is.2015.07.003
19. leontjeva, a., et al.: complex symbolic sequence encodings for predictive
monitoring of business processes. in: bpm. pp. 297–313. springer (2015).
https://doi.org/10.1007/978-3-319-23063-4 21
20. li, c., van zelst, s.j., van der aalst, w.m.p.: stage-based process per-
formance analysis. in: icsoc workshops. pp. 349–364. springer (2020).
https://doi.org/10.1007/978-3-030-76352-7 34
21. lundberg, s.m., lee, s.: a unified approach to interpreting model predictions. in:
neurips. pp. 4765–4774 (2017)
22. park, g., adams, j.n., van der aalst, w.m.p.: opera: object-
centric performance analysis. corr abs/2204.10662 (2022).
https://doi.org/10.48550/arxiv.2204.10662
23. philipp, p., et al.: analysis of control flow graphs using graph
convolutional neural networks. in: iscmi. pp. 73–77 (2019).
https://doi.org/10.1109/iscmi47871.2019.9004296
24. rogge-solti, a., weske, m.: prediction of remaining service execution time using
stochastic petri nets with arbitrary firing delays. in: icsoc. pp. 389–403. springer
(2013). https://doi.org/10.1007/978-3-642-45005-1 27
25. sun, y., bauer, b., weidlich, m.: compound trace clustering to generate accu-
rate and simple sub-process models. in: icsoc. pp. 175–190. springer (2017).
https://doi.org/10.1007/978-3-319-69035-3 12
26. tax, n., verenich, i., rosa, m.l., dumas, m.: predictive business process mon-
itoring with lstm neural networks. in: caise. pp. 477–492. springer (2017).
https://doi.org/10.1007/978-3-319-59536-8 30
27. venugopal, i., t¨ ollich, j., fairbank, m., scherp, a.: a comparison of deep-learning
methods for analysing and predicting business processes. in: ijcnn. pp. 1–8
(2021). https://doi.org/10.1109/ijcnn52387.2021.9533742
28. waibel, p., pfahlsberger, l., revoredo, k., mendling, j.: causal process mining
from relational databases with domain knowledge. corr abs/2202.08314 (2022)
29. wang, c., cao, j.: interval-based remaining time prediction for business processes.
in: icsoc. springer (2021). https://doi.org/10.1007/978-3-030-91431-8 3
30. wu, z., et al.: a comprehensive survey on graph neural networks.
ieee trans. neural networks learn. syst. 32(1), 4–24 (2021).
https://doi.org/10.1109/tnnls.2020.2978386
view publication stats