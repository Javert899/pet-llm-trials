development of the process mining discipline  
(prof.dr.ir. wil van der aalst , rwth aachen university ) 
 
it is exciting to see the spectacular developments in process mining since i started to work on this in the 
late 1990 -ties. many of the techniques we developed 15 -20 years ago have become standard functionality 
in today’s process mining tools. therefore, it is good to view current and future developments in this 
historical context.  
this chapter starts with a brief summary of the history of process mining showing how ideas from 
academia got adopted in commercial tools. this provides the basis to talk about the expanding scope of 
process mining, both in terms of applications and in terms of functionalities supported. despite the rapid 
development of the process mining discipline , there are still several challenges. some of these challenges 
are new, but there are also several challenges that have been around for a while and still need to be 
addressed urgently. this requires the concerted action of process mining users, technology providers, and 
scientists.  
 
adoption of traditional process mining techniques  
 
process mining started in the late nineties when i  had a sabbatical and was working for one year at the 
university of colorado in boulder (usa). before , i was mostly focusing on concurrency theory, discrete 
event simulation, and workflow management. we had b uilt our own simulation engines (e.g., exspect) 
and workflow management systems. although our research was well-received  and influential , i was 
disappointed by the  average  quality of process models and the impact process models had on reality . in 
both  simu lation studies and workflow implementations, the real processes often turned out to be very 
different from what was modeled by the people  involved . as a result , workflow and simulation projects 
often failed. therefore, i decided to focus on the analysis of  processes through event data  [1]. around the 
turn of the century, we developed the first process discovery algorithms  [2]. the alpha algorithm was the 
first algorithm able to learn concurren t process m odels from event data and still provide formal 
guarantees. however, at the time , little event data were  available and the assumptions made by the first 
algorithms were unrealistic. people working on data mining and machine learning were (and perhaps still 
are) not interested in process analysis. therefore, it was not easy to convince other researchers to work 
on this.  nevertheless, for me , it was crystal clear that process mining would become a crucial ingredient 
of any process management or process improv ement initiative.  
in the period that followed, i stopped working on the traditional business process management topics and 
fully focused on process mining. it is interesting to see that concepts such as conformance checking, 
organizational process mining,  decision mining, token animation, time prediction, etc. were already  
developed and implemented 15 years ago  [2]. these capabilities are still considered to be cutting -edge  
and not supported by most  of the commercial process mining tools . 
 growth of the number of new 
publications on process mining (per 
year ) according to scopus 1999 start of process mining research at tu /e
 2000 -2002 development of the first process mining 
algorithms (alpha and heuristic miner )
 2004 release of the first version of the prom framework
 2004 -2006 pioneering work on token -based conformance 
checking , organization mining , decision mining , etc.
 2007 first process mining company (futura pi )
 2010 pioneering work on alignment -based conformance 
checking and operational support
 2009 -2011 founding of fluxicon , celonis , and processgold
 2011 first process mining book
 2014 coursera process mining mooc
 2016  process mining data science in action   book
 2018 first market guide for process mining by gartner
 2018 over 30 software vendors offer process mining tools
 2018 celonis becomes a unicorn
 2019 first international process mining conference takes 
place in aachen (icpm 2019 ) 
figure 1: summary of the history of process mining also showing the growth  of scient ific papers on the topic.  
figure 1 illustrates the development of the field. on the one hand, the graph shows the growth of scientific 
process mining literature. each year , a growing number of process mining paper is published in journals 
and presented at conferences. on the other hand, the right -hand side of the figure also mentions  a few 
milestones illustrating the uptake in industry. the first process mining company (futu ra pi) was founded 
in 2007 by one of my students (peter van de brand). the software was later integrated in to the tools of 
pallas athena and perceptive software. a few years later, fluxicon, celonis , and processgold were 
founded. concurrently, the first pr ocess mining books appeared and the first online course for process  
mining was created (followed by over 120.000 participants). however, until 2015 the practical adoption 
of process mining in industry was limited. only in recent years, the actual usage acc elerated  [3, 4] . this is 
illustrated by the growing number of process mining vendors. currently, there are over 30 process mining 
vendors  (e.g., c elonis, disco, processgold, myinvenio, pafnow, minit, qpr, mehrwerk, puzzledata, 
lanalabs, stereologic, everflow, timelinepi, signavio, and logpickr). in 2018, the first international 
conference on proc ess mining (icpm) was organized illustrating the growi ng maturity of the field. 
moreover, as this book shows there are many exciting applications in organizations such as siemens, 
bmw, uber, springer, abb, bosch, bayer, telekom, etc.  
although some process mining vendors have added conformance checking techniques and more 
advanced discovery techniques like the inductive mining approach, the basis of most commercial process 
mining tools is still the directly -follows graph  (dfg ). this was actually the graph that serve d as input for 
the classical alpha algorithm  twenty years ago . the dfg can also be viewed as a traditional transition 
system or a markov chain  (when adding probabilities) . a dfg is a graph with nodes that correspond to 
activit ies and directed edges that correspond to directly -follows relationships  [2, 5] . the frequency on an 
arc connecting activity x to activity y show s how often x is directly followed by y for a sp ecific case (i.e., 
process instance). similarly, the arc can be annotated with time information to show bottlenecks. using 
frequencies it is possible to seamlessly simplify such process models. it is also possible to animate the 
cases using tokens moving a long the directed arcs. this is all easy to understand and highly scalable.  
therefore, this basic functionality is present in all of today's process mining tools.  
 expanding the scope of process mining  
 
over the last two decades , the scope of process mini ng expanded in different ways. first of all, process 
mining grew out of academia into industry.  also the number of application domains expanded  [6]. 
traditionally, applications were limited to financial or administrative processes. the order -to-cash (o2c) 
and purchase -to-pay (p2p) processes are obviou s candidates to apply process mining. however, nowadays 
process mining is also applied in healthcare, logistics, production, customs, transportation, user -interface 
design, security, trading, energy systems, smart homes, airports, etc. this makes perfect sense since event 
data and processes are not limited to specific application domains. finally, there is also a clear expansion 
in the capabilities of process mining tools. in itially, the focus was exclusively on process discovery based 
on historic data.  however, the scope of process mining expanded far beyond this as is illustrated by the 
four trends  depicted in figure 2  and discussed next . 
project -based 
(small scale )
discovery 
only backward 
looking
only 
diagnosticsenterprise -wide 
(large scale )
beyond 
discovery forward
looking
diagnostics 
and actions 
 
figure 2: four trends showing that the scope of process mining is expanding.  
the scope of process mining expanded from a tool for a data scientist used in an improvement project to 
the enterprise -wide , continuous  application of process mi ning.  process mining tools only supporting the 
construction of dfgs with frequencies and times tend to be used in smaller projects only. these projects 
often have a limited scope and duration. as a result, few people use the results and there is no support  
for continuous improvement. given the investments needed for  data preparation , it is often bette r to 
apply process mining at an enterprise -wide scale with many people using the results on a daily basis. it 
does not make sense to see process mining as a on e-time activity. however, the enterprise -wide, 
continuous application of process mining requires substantial resources in terms of computing power and 
data management (e.g., to extract the data and convert these into the right format). moreover, to lower 
the threshold for a larger process mining community within an organization, one needs to create 
customized dashboards.  therefore, process mining needs to be supported by higher -level management 
to realize the scale at which it is most effective.  
initially, process mining efforts focused on process discovery  [2]. however, over time it has become clear 
that process discovery is just the starting point  to process improvement. one can witness an uptake in 
conformance checking and performance analysis  techniques . moreover, process mining is often 
combined with data mining a nd machine learning techniques to find root causes for ineff iciencies and 
deviations. although process discovery will remain important, attention is shifting to the steps following 
discovery using optimization, machine learning, and simulation.  
a third trend is the shift in focus from backward looking to forward lo oking . traditional process mining 
techniques start from historic data. this can be used to diagnose conformance and compliance problems. 
however, organizations are often more interested in what is happing now or wh at is going to happen  next . 
backward -looki ng process mining can be used to fundamentally improve processes, but provides little 
support for the day -to-day management of processes. therefore, event data need to be updated continuously and process mining techniques need to be able to analyze cases t hat are still running. this is 
needed to control  and influence  the running process  instances . some of the commercial process mining 
tools provide excellent capabilities to show the current state of the process. a next step is the application 
of more forwar d-looking techniques  able to predict what will happen to individual cases and where 
bottlenecks are likely to develop. techniques  for operational support (i.e., detecting  compliance and 
performance problems at runtime , predicting such problems, and recomme nding actions) have been 
around for more than a decade. however, their quality still leaves much to be desired. the problem is that 
cases (i.e., process instances) highly influence each other when competing for resources. moreover, there 
may be a range of contextual factors influencing processes.  by simply applying existing machine learning 
and data mining techniques, one cannot get any reliable predictions. hence, additional work is needed.  
process variants sorted in frequencyfrequencytraditional 
automation
candidates for rpa 
(traditional automation 
is not cost effective )low-frequent process 
variants that cannot be 
automated and still require 
human involvementprocess mining is able to diagnose the full process spectrum
from high -frequent to low -frequent and from automated to manual
rpa shifts the boundary of 
cost-effective automation
 
figure 3: process mining can be used to identify candidates for rpa and monitor any mixture of automated/non -automated 
frequent/infrequent process variants . 
the fourth trend is the increased focus on actually improving the process. process mining tends to focus 
on diagnostics and not on the interventions  that should follow. insights generated by process mining 
should be actionable. therefore, process mining is  increasingly combined with robotic process 
automation (rpa) . process mining can be used to identify manual tasks that can be automated and 
monitor software robots. this allows for the automation of processes for which traditional workflow 
automation would  be too expensive.  figure 3 shows the spectrum of process variants. high -frequent 
variants are candidates for automation,  but lower frequent variants cannot be automated in a cost -
effective manner. rpa helps to shift the boundary where (partial) automatio n is still cost -effective. 
interestingly, process mining can be used before and after automation for any mixture of process variants  (automated or not) . however, rpa is just one of many ways to turn process mining diagnostics into 
actions. here , i would also like to coin the term robotic process management (rpm)  to refer to automatic 
process interventions. unlike rpa, rpm is not automating steps in the  operational process. rpm translates 
process mining diagnostics into management actions. for example, when a bottleneck emerges rpm may 
take actions such as alerting the manager, informing the affected customers, assigning more workers, etc. 
another example would be to prioritize targeted auditing activities when a significant increase in process 
deviations  occurs. these examples show that the diagnostics  provided by  process mining are just the 
starting point . 
 
an inconvenient truth  
 
despite the rapid developments in process mining, many of the original challenges remain  [2]. although 
there has been considerable progress in process mining research, commercial tools tend to not use the 
state -of-the-art due to pragmatic reasons such  as speed and simplicity. commercial software tends to 
make "short -cuts" that seem harmless at first, but inevitabl y lead to problems at a later stage.   
the first inconvenient truth is that filtered directly -follows graphs (dfgs) have well-known problems . 
dfgs  cannot express concurrency and filtering them may  provide misleading results. yet , the default 
discovery technique s used by commercial tools are all based on filtered dfgs.   
to illustrate the problem consider a fictive purchasing process consisting  of six steps: place order , receive 
invoice , receive goods , pay order , and close . in this idealized process , all five activities are performed for 
all procurement order s. the process always starts with activity place order  and end s with  activity  close . 
how ever, the three middle activities are executed in any order. for example, in rare cases the organization  
pays before receiving the invoice and goods. hence, there are six different process variants. in our event 
log there is information about 2000 orders, i.e., in total there are 10000 events. the most frequent variant 
is place order , receive invoice , receive goods , pay order , close  which  occurs 857 times. the least frequent 
variant is place order , pay order , receive goods , receive invoice , close  which  occurs only 4  times.  
 
figure 4: process model discovered by prom's inductive  miner.  note that all activities occur once per procurement order.  
figure 4 shows the process model discovered by prom's inductive miner  [2]. the three unordered 
activities in the middle are preceded by an and -split and are followed by an and -join. the model correctly 
shows that all activities happen precisely 2000 times. applying other basic process discovery algorithms 
like the alpha algorithm and region -based techniques yield the same compact and correct process model  
(but then  often  directl y expressed in terms of petri nets).  prom disco celonis 
figure 5: three identical dfgs returned by prom, disco, and celonis.  
let us now look at the corresponding directly -follows graph s (dfg ) used by most commercial process 
mining tools  [2]. figure 5 shows three dfgs generated by prom, disco, and celonis. apart from layout 
differences , these three models are identical. surprisingly, the dfgs suggest that there are  loops in the 
process  although  each activity is executed precisely once for each order. the process also seems more 
complex. to simpl ify such  dfgs, all process mining tools  can leave out infrequent paths  to simplify the 
model . however, this may lead to highly  misleading results, e.g., f requencies no long add up and averages 
are based on unclear fragments of behavior.  
 
figure 6: process model discovered by prom's inductive miner for the event logs where the middle three activities can be 
skipped . 
to further illustrate the problem , we now consider a variant of the order process where each of the middle 
activities is skipped with 50% probability.  this means that for  approximately  50% ∙50% ∙50%= 12.5% of cases 
only the activities place order  and close  are performed . figure 6 shows the process model disco vered by 
prom's inductive miner clearly showing that the three middle  activities c an be skipped. for example, the 
process model shows that for 988 of the 2000 orders there was no payment. figure 7 shows the 
corresponding petri net model  without frequencies .  
figure 7: petri net discovered by prom showing that  each of the three middle activities can be skipped.  
as before, we can also discover the dfg for this second event log. the result is shown in figure 8. again 
prom, disco, and celonis generate identical dfg s. we can see that for 236 orders , all three middle 
activities are skipped. again we see loops that do not exist and the underlying structure of the process 
clearly depicted in figures 6 and 7 is invisible  in the three dfgs . 
prom disco celonis
 
figure 8: three identical dfgs for the process where the three middle activities can be skipped.  
as mentioned dfgs can be seamlessly simplified by leaving out infrequent activities and arcs.  of the three 
middle activities, activity receive goods  is most frequent. hence, this activity remains when we filter the 
model to retain the three most frequent  activities. activities place order  and close  occur 2000 times, and 
activity receive goods  occurs 1053 times. figure 9 shows the filtered dfgs generated by disco and celonis. 
now there are some surprising differences . these differences illustrate that filtered dfgs can be very 
misleading.  disco
(freq)celonis
(freq)
disco
(time )celonis
(time ) 
figure 9: filtered dfgs generated by disco and celonis showing frequencies (left) and time (right).  
note that figure 8 and figure 9 are based on the same event data  and the frequencies of activities are the 
same in all dfgs shown, e.g., activity receive good s occurs 1053 times  in all dfgs . however, the 
information on the arcs is very different. let us first focus on the connection between activity place order  
and activity close . activity place order  directly followed activity close  in 236 cases. this was corr ectly 
shown in figure 8. however, celonis reports the same number (i.e., 236) when the other activities have 
been removed  (figure 9) . however, this can of course no longer be the case . after removing receive invoice  
and pay order  there are more cases where  place order  is directly followed activity close . also , disco reports 
an incorrect number  (i.e., 1151).  after removing the two activities, there are 947 cases where place order  
is directly followed by activity close  and the average time between these activities for these cases is 13.8 
days. surprisingly, disco reports 12 days and celonis reports 15.5 days.  hence, celonis and disco report 
different frequencies and times and both fail to show correct values for  frequencies and times .  
another example is the connection between activity receive goods  and activity close . if we project the log 
onto the three remaining activities, we can see that there are 1053 cases where activity receive goods  
directly follows activity close  and this takes on average 8.5 day s. disco reports a frequency of 1143 (too 
high) and an average time of 9.8 days (too high). celonis reports a frequency of 621 (too low) and an 
average time of 8 days (too low).  
moreover, the diagrams  in figure 9  are internally inconsistent. the frequencie s involved in split and join 
should add up to 2000, but we can witness 613+1151 and 236+613 for the split and 1143+1151 and 
236+621 for the join. these inconsistencies will confuse any user that would really like to understand the 
process.  figure 10 shows that this is not necessary.  
 
figure 10: process model discovered by prom's inductive miner  showing the correct frequencies  after abstracting from  the two 
lower frequent activities.  
these small examples illustrate an inconvenient truth. simplistic discovery techniques providing just a dfg 
with sliders to simplify matters are not adequately capturing the underlying process. the frequencies and 
times reported are wrong (or at best misleading)  and when activ ities are not executed in a fixed order 
there will always be loops in the model even when these do not exist in reality. these problems are not specific for disco or celonis. almost all com mercial process mining tools mak e shortcuts to ensure good 
performa nce and provide similar results. although this is a known problem that has been reported 
repeatedly over the last decade, vendors are reluctant to address it. there are two main reasons: 
simplicity  and performance . petri nets, bpmn models, uml diagrams, etc. are considered to be too 
complicated for the user. however, the price to pay for this simplicity is  the presence of spaghetti -like 
diagrams with many non -existing loops.  to ensure good performance, filtering of  the dfg is done on the 
graph rather than on the original data. this explains the incorrect frequencies and times  in figure 9 . 
another inconvenient truth is the limited support for conformance checking  [2]. although conformance 
checking is consider ed to be important from a practical point is view, it is still not very well support and 
rarely used. conformance checking approac hes ranging from token -based relay [7] to alignments [8] have 
been developed over  the past two decades. several vendors try to support conformance checking by 
comparing discovered dfgs with normative dfgs derived from hand -made pro cess models. this , of 
course,  does not work.  compare for example the dfgs in figure 5 with the dfgs in figure 8. the only 
difference is the connection between activity place order  and activity close . however, it is very difficult to 
see that in the second data sets all  possible subsets of these three activities  where skipped . 
 
figure 11: conformance checking applied to an event log with seven deviating cases: three cases skipped activity place order 
and four cases skipped receive goods.  
to illustrate the kind of diagnostics one would expect, we refer  to figure 1 1. these are diagnostics 
retu rned by prom given an event log  where we modified seven cases in such a way that all seven are  non-
compliant. the red  arcs show the deviations. activity place order  is skipped three times. activity receive 
goods  is skipped four times. using prom one can easily drill down on the deviations .  the red arcs  separate 
the deviations from the model and one can select any arc to  see the corresponding non -conforming 
procurement orders . figure 1 2 shows the normative bpmn model next two the dfgs generated by disco 
and celonis. based on these dfgs it remains partly un clear what the deviations are. it is possible to identify 
the three  cases where activity place order  is skipped. however, based on the arcs it is impossible  to see 
that a ctivity receive goods  was skipped  four times . the numbers on the arcs are not revealing this.  receive 
invoicepay 
orderreceive 
goodsplace 
order
close
bpmn disco celonis 
figure 12: the normative bpmn model and the dfgs generated by disco and celonis for the event log with seven deviating 
cases.  
some of the commercial software tools have added conformance checking capabilities in recent years, 
e.g., celonis supports a variant o f token -based replay. however, the usability, quality of diagnostics, and 
scalability of existing software tools leave much to be desired.  
also from a scientific point of view, process discovery and conformance checking are still challenging. 
these two fou ndational process mining problems have not yet been solved satisfactorily and there is still 
a lot of room for improvement  [2]. however, the current state -of-the-art techniques provide already 
partial solutions that perform well on real -life data sets. the hope and expectation is that commercial 
systems will adopt these techniques when user s get more critical and expect more precise and fully 
correct diagnostics.  
 
novel challenges  
 
as discussed, process discovery and conformance checking are still challenging and one can expect further 
improvement s in the coming years. however, next to these core process mining tasks, novel p rocess 
mining capabilities have been identified  (see figure 1 3). these provide new scientific and practical 
challenges.  here we briefly mention a few.  
 challenge: bridging the gap between process modeling and process mining.  many organizations 
use tools for  modeling processes. with the uptake of process mining , it becomes clear that these 
models do not correspond to reality. although such  idealized models are valuable, the gap 
between discovered and hand -made models needs to be bridged  [9]. a promising approach is the 
use of so-called hybrid process models that have a backbone formally describing the parts of the 
process that are clear and stable, and less rigid data -driven annotations to show the things that 
are less clear.  hybrid process models allow for formal reasoning, but also reveal information that 
cannot be captured using  mainstream formal models  because the behavior is to o complex or 
there is not enough data to justify a firm conclusion  [9]. next to combining formal modeling constructs (precisely  describing the possible behaviors) and informal  modeling constructs  (data -
based annotations  not allowing for any form of formal reasoning) , there is also the need to deal 
with multiple abstraction levels. modeled processes tend to be at a higher level of abstraction 
than discovered process models. one high -level activity can correspond to  many  low-level events 
at different level s of granularity.  it is not easy to bridge  the gap between process modeling and 
process mining.  however, both need to be integrat ed and supported in a seamless manner. a 
convergence of process modeling and process mining tools is needed and also inevitable .  
 challenge: incorporating stochastic information in process models to improve conformance 
checking  and prediction . frequencies of activities and process variants are essential for process 
mining. a highly frequent process variant (i.e., many cases having the same trace) should be 
incorporated in the corresponding process model. this is less important for a process var iant that 
occurs only once. on e can view frequencies as estimates for probabilities, e.g., if 150 cases end 
with activity reject  and 50 cases end with activity accept , then the data suggests that there is a 
75%  probability of rejection and  a 25% probability of acceptan ce. such information is typically not 
incorporated in process models. for example, the normative bpmn model may have a gateway 
modeling the choice between activity reject  and activity accept , but typically the probability is not 
indicated. obviously, such information is essential for predictive process mining. however, the 
same information is vital for conformance checking. typically, four conformance dimensions are 
identified: (1) recall : the discovered model should allow for the behavior seen in the event  log 
(avoiding "non -fitting" behavior), (2) precision : the discovered model should not allow for 
behavior completely unrelated to what was seen in the event log (avoiding "underfitting"), (3) 
generalization : the discovered model should generalize the example behavior seen in the event 
log (avoiding "overfitting"), and (4) simplicity : the discovered model should not be unnecessarily 
complex. the first two are most relevant for comparin g observed and modeled b ehavior (the 
other two relate more to the completeness and redundancy of event data and the 
understandability of the process model). recall  (often called fitness)  is typically well -understood. 
although there are many precision notions, it turns out to be p roblematic to define precision for 
process models without probabilities. adding in frequent behavior to a model ma y significantly 
lower traditional precision notions . this seems counterintuitive. moreover, from a practical point 
of view , a process may be no  longer be compliant if the distribution over the various paths in the 
model dramatically changes.  these observations suggest that probabilities need to be added to 
process models to allow for both prediction and all forms of comparison (including conforma nce 
checking ). moreover, adding stochastics to process models also enable s the interplay between 
process mining and simulation [10]. currently,  simulation is rarely used for process management. 
however, the uptake of process mining may lead to a revival of business process simulation.  
 challenge: process mining for multiple processes using different case notions.  traditional 
process mining techniq ues assume that each event refers to one case and that each case refers 
to one process. in reality , this is more complex  [5]. there may be different intertwined processes 
and one  event may be related to different cases (convergence) and, for a given case, there m ay 
be multiple instances of the same activity within a case (divergence). to create a traditional 
process model, the event data need to be "flattened". there are typically multiple choices 
possible, leading to different views and process models that are di sconnected. consider the 
classical example where the information system holds information about customer orders, 
products, payments, packages, and deliveries scattered over multiple tables. object -centric process mining  relaxes the traditional assumption t hat each event refer s to one case  [5]. an event 
may refer to any number of business objects and using novel process mining techniques one can 
discover one integrated process model showing multiple perspectives . 
 challenge: dealing with uncertain and continuous eve nt data.  the s tarting point for any process 
mining effort is  a collection of events. normally , we assume that events are discrete and certain, 
i.e., we assume that  each event reported has actually happened and that its attributes are correct . 
however, due the expanding scope of process mining  other  types of event data are encountered. 
events may be uncertain, e.g., the time may not be known exactly, the activity is not certain, and 
there may be multiple candidate case identifiers. consider for example senso r data that needs to 
be discretized or text data that needs to be preprocessed . in such settings we use classifiers that 
have a maximal accuracy of for example 80% . by lowering thresholds we may get more "false 
positives" (e.g., an activity that did not re ally happen was added to the event log) and by 
increasing thresholds we get more "false negatives". the attributes of events may also have 
continuous variables that determine the actual  meaning of the event. for example, a blood test 
may provide several me asurements relevant to the treatment process. another example is the 
event log of a wind turbine showing  information about wind speeds, wind direction, voltage, etc. 
such information can be  used to derive an event "shut down turbine because of strong winds ". 
future process mining tools and approaches  will need to be able to deal better with uncertain 
event data and measurements  that are continuous in nature.  
 challenge: comparative process mining to identify differences between process variants over 
time.  processes change over time and the same process may be performed at different locations. 
hence, it  is valuable to compare the corresponding  process variants  [11]. the relative 
performance often provides more insights than the absolute values.  for example, what were the 
main differences between january and february or what are the differences between the berlin 
office and the amsterdam office? comparing different process variants is not so easy. compare 
for example the dfgs in figure 5 to the dfgs in figure 8. it is not so easy to spot relevant 
differences. next to changes in the process structure, also frequencies and times may change.  
techniques for c omparative process mining  aim to address this  [11]. this includes techniques to 
support the visual comparison of process variants and machine learning techniques using process -
centric features  [12]. 
 challenge: causality -aware process mining ensuring correct and fair conclusions.  process mining 
technique s can be used to quickly uncover performance and compliance problems. based  on 
bottleneck analysis and conformance checking  results, we can annotate  event data to expose 
desirable  and undesirable "situations "(i.e., good and bad choices, cases, routes, etc.) . moreover, 
using feature extraction it is possible  to turn such situation s into supervised learning problem s 
and use data mining and machine learning techniques to uncover root causes for performance 
and compliance problems. such a combination of techniques yields  a powerful approach to 
automatically diagnose process -related pr oblems. however, correlation does not imply causation . 
unfortunately, these  terms that are mostly misunderstood and often used interchangeably.  for 
example, ice cream sales may strongly correlate with burglary. however, this does not imply that 
eating ice cream causes  theft . there is third variable (the weather) that is influencing both  ice 
cream sales and burglary . when delays in a process correlate with deviations, then this does not 
imply that one causes the other. therefore, explicit causal models are r equired to guide root -
cause analysis in process mining. in a causal model relations between processes features can be made explicit using a mixture of domain knowledge and statistical evidence. similar techniques 
can be used to avoid unfair or even discrim inating conclusions. for example, it is pointless to 
blame the workers that are overloaded for delays. also the most experienced workers often take 
the most difficult cases possibly  leading to unfair conclusions if one only considers the data.  
 challenge: confidentiality -aware process mining to avoid unintentionally leaking sensitive 
information.  event data are potentially very sensitive. a few timestamped events are often 
enough to identify a customer or employee. even when one removes explicit timestamps, the 
order of activities may already be enough for identification. preserving confidentialit y is, 
therefore,  a primary concern in process mining. current research aims at dedicated 
anonymization and encryption techniques. for example, one does not need to store complete 
cases to generate dfgs. it is sufficient to store direct succession  relations  without correlating all 
event s belonging to a case.  the introduction of the eu general data protection regulation (gdpr) 
illustrates the growing importance of data privacy.  therefore, the next generation of process 
mining tools will need to support confi dentiality preserving techniques. confidentiality -aware 
process mining is part of the broader domain of responsible data science  (rds) focusing on 
fairness , accuracy , confidentiality , and transparency . all four rds aspects are relevant for process 
mining. not addressing these concerns may slow down the adoption of process mining.  
the above list of challenges is far from complete. process mining is a relatively young, but also broad , 
discipline. it is interesting to compare the above list with the eleven challenges in the process mining 
manifesto written in  2011  [13]. this shows that the field developed rapidly.  
challenge : bridging the gap 
between process modeling and 
process miningchallenge : incorporating 
stochastic information in 
process models to improve 
conformance checking and 
predictionchallenge : process mining for 
multiple processes using 
different case notionschallenge : dealing with uncertain 
and continuous event data
challenge : comparative process 
mining to identify differences 
between process variants over timechallenge : causality -aware 
process mining ensuring correct 
and fair conclusionschallenge : confidentiality -aware process 
mining to avoid unintentionally leaking 
sensitive information
 
figure 13: some of the challenges getting more attention in research and thus showing the anticipated development of the process 
mining discipline.  
process hygiene  
most of the challenges mentioned in this chapter require the concerted action of process mining users, 
techn ology providers, and scientists. a collaborative effort is needed to make process mining "the new 
normal" . process mining should be as normal as personal hygiene  and not require a business case. 
activities such as b rushing your teeth, washing your hands after going to the toilet , and changing clothes 
do not require a business case. p rocess mining can be seen as the means to ensure process hygiene  (ph) 
or business process hygiene  (bph). objectively monitoring and analyzing key processes  is important for 
the overall health and well -being of an organization. unfortunately, m anager s, auditors, and accountants 
often still use medieval practices.  f inancial reporting framework s such as the nation -specific gaap 
(generally accepted accounting principles) standards still depend on the notion of materiality. as a result 
sampling  suffices .  given the availability of data and our ability to analyze processes this is remarkable. 
process hygiene (ph)  should not require a business case. not using process mining is a sign of self -neglect  
showing an inability or unwillingness to manage processes properly. hence, not using proces s mining should require a justification and not the other way around. using data qu ality and privacy concerns as 
reason s to not conduct process mining should be considered as poor hygiene  leading to "smelly 
processes".  
references  
1. aalst, w.m.p.v.d., process mining: discovery, conformance and enhancement of business 
processes . 2011: springer -verlag, berlin.  
2. aalst, w.m.p.v.d., process mining: data science in action . 2016: springer -verlag, berlin.  
3. kerremans, m., gartner market gu ide for process mining, research note g00387812 . 2019.  
4. kerremans, m., gartner market guide for process mining, research note g00353970 . 2018.  
5. aalst, w.m.p.v.d. object -centric process mining: dealing with divergence and convergence in 
event data . in software engineering and formal methods (sefm 2019) . 2019. springer -verlag, 
berlin.  
6. koplowitz, r., et al., process mining: your compass for digital transformation: the customer 
journey is the destination . 2019.  
7. rozinat, a. and w.m.p.v.d. aalst, confor mance checking of processes based on monitoring real 
behavior.  information systems, 2008. 33(1): p. 64 -95. 
8. carmona, j., et al., conformance checking: relating processes and models . 2018: springer -
verlag, berlin.  
9. aalst, w.m.p.v.d., et al. learning hyb rid process models from events: process discovery without 
faking confidence . in international conference on business process management (bpm 2017) . 
2017. springer -verlag, berlin.  
10. aalst, w.m.p.v.d. process mining and simulation: a match made in heaven!  in computer 
simulation conference (summersim 2018) . 2018. acm press.  
11. aalst, w.m.p.v.d. process cubes: slicing, dicing, rolling up and drilling down event data for 
process mining . in asia pacific conference on business process management (ap -bpm 2013) . 
2013. springer -verlag, berlin.  
12. bolt, a., m. de leoni, and w.m.p.v.d. aalst, process variant comparison: using event logs to 
detect differences in behavior and business rules.  information systems, 2018. 74(1): p. 53 -66. 
13. ieee task force on process mi ning. process mining manifesto . in business process management 
workshops . 2012. springer -verlag, berlin.  
 