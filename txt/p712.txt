business process management:
a comprehensive survey
wil m.p. van der aalst
department of mathematics and computer science,
technische universiteit eindhoven, the netherlands.
www.vdaalst.com
abstract. business process management (bpm) research resulted in a plethora
of methods, techniques, and tools to support the design, enactment, management,
and analysis of operational business processes. this survey aims to structure these
results and provides an overview of the state-of-the-art in bpm. in bpm the con-
cept of a process model is fundamental. process models may be used to conﬁgure
information systems, but may also be used to analyze, understand, and improve
the processes they describe. hence, the introduction of bpm technology has both
managerial and technical ramiﬁcations, and may enable signiﬁcant productivity
improvements, cost savings, and ﬂow-time reductions. the practical relevance of
bpm and rapid developments over the last decade justify a comprehensive survey.
1 introduction
business process management (bpm) is the discipline that combines knowledge from
information technology and knowledge from management sciences and applies this to
operational business processes [1, 2]. it has received considerable attention in recent
years due to its potential for signiﬁcantly increasing productivity and saving costs.
moreover, today there is an abundance of bpm systems . these systems are generic
software systems that are driven by explicit process designs to enact and manage oper-
ational business processes [3].
bpm can be seen as an extension of workﬂow management (wfm). wfm primar-
ily focuses on the automation of business processes [4–6], whereas bpm has a broader
scope: from process automation and process analysis to operations management and
the organization of work. on the one hand, bpm aims to improve operational business
processes, possibly without the use of new technologies. for example, by modeling a
business process and analyzing it using simulation, management may get ideas on how
to reduce costs while improving service levels. on the other hand, bpm is often associ-
ated with software to manage, control, and support operational processes. this was the
initial focus of wfm. however, traditional wfm technology aimed at the automation
of business processes in a rather mechanistic manner without much attention for human
factors and management support.
process-aware information systems (paiss) include traditional wfm systems and
modern bpm systems, but also include systems that provide more ﬂexibility or sup-
port speciﬁc processes [7]. for example, larger erp (enterprise resource planning)2 wil van der aalst
systems (e.g., sap and oracle), crm (customer relationship management) systems,
case-handling systems, rule-based systems, call center software, and high-end middle-
ware (e.g. websphere) can be seen as process-aware, although they do not necessarily
control processes through some generic workﬂow engine. instead, these systems have
in common that there is an explicit process notion and that the information system is
aware of the processes it supports. also a database system or e-mail program may be
used to execute steps in some business process. however, such software tools are not
“aware” of the processes they are used in. therefore, they are not actively involved in
the management and orchestration of the processes they are used for. bpm techniques
are not limited to wfm/bpm systems, but extend to any pais. in fact, bpm techniques
such as process mining [8] can be used to discover and analyze emerging processes that
are supported by systems that are not even “aware” of the processes they are used in.
the notion of a process model is foundational for bpm. a process model aims
to capture the different ways in which a case (i.e., process instance) can be handled.
a plethora of notations exists to model operational business processes (e.g., petri nets,
bpmn, uml, and epcs). these notations have in common that processes are described
in terms of activities (and possibly subprocesses). the ordering of these activities is
modeled by describing causal dependencies. moreover, the process model may also de-
scribe temporal properties, specify the creation and use of data, e.g., to model decisions,
and stipulate the way that resources interact with the process (e.g., roles, allocation
rules, and priorities).
book carc
add extra 
insurancedchange 
booking
e
confirm initiate 
check-inj
check driver’s 
license
k
charge credit 
cardi
select carg
supply 
carinab
skip extra
insurance
fhadd extra 
insurance
skip extra 
insurance
l
outc1 c2
c3c4
c5
c6
c7c8
c9
c10
c11acefgijkl
acddefhkjil
abdefjkgil
acdddefkhijl
acefgijkl
abefgjikl
...
fig. 1. a process model expressed in terms of a petri net and an event log with some example
traces.
figure 1 shows a process model expressed in terms of a petri net. the model allows
for the scenario ha;c;e;f;g;i;j;k;l i. this is the scenario where a car is booked (ac-business process management: a comprehensive survey 3
tivitya), extra insurance is added (activity c), the booking is conﬁrmed (activity e), the
check-in process is initiated (activity f), more insurance is added (activity g), a car is se-
lected (activity i), the license is checked (activity j), the credit card is charged (activity
k), and the car is supplied (activity l). another example scenario is ha;c;d;d;e;f;h;k;
j;i;liwere the booking was changed two times (activity d) and no extra insurance was
taken at check-in (activity h).
figure 1 focuses on control-ﬂow and does notmodel data, decisions, resources, etc.
thecontrol-ﬂow perspective (modeling the ordering of activities) is often the backbone
of a process model. however, other perspectives such as the resource perspective (mod-
eling roles, organizational units, authorizations, etc.), the data perspective (modeling
decisions, data creation, forms, etc.), the time perspective (modeling durations, dead-
lines, etc.), and the function perspective (describing activities and related applications)
are also essential for comprehensive process models.
the petri net notation is used to model the control-ﬂow in figure 1. however, vari-
ous alternative notations (e.g., bpmn, uml, and epcs) could have been used. discus-
sions on different notations tend to distract bpm professionals from the key issues. the
workﬂow patterns [9] describe the key functionalities in a language-independent man-
ner. obviously, there are differences in expressiveness and suitability among languages,
however, these are only relevant for the more advanced patterns. moreover, the study in
[10] revealed that business process modelers typically only use a fraction of an elabo-
rate language like bpmn. this illustrates the disconnect between bpm standardization
efforts and the real needs of bpm professionals.
the model shown in figure 1 could have been made by hand or discovered using
process mining [8]. as a matter of fact, models can have very different origins. more-
over, models may also serve very different purposes. the model in figure 1 can be used
to conﬁgure a bpm system. after conﬁguration, new cases are handled according to the
rules speciﬁed in the model. however, the model can also be used for analysis (without
aiming at system support), e.g., after adding timing information and frequencies it can
be used for “what-if” analysis using simulation. sometimes, process models are merely
used for discussion or training.
figure 2 provides a high-level view on four key bpm-related activities: model ,en-
act,analyze , and manage . process models obtained through modeling can be used for
enactment (e.g., execution using a bpm or wfm system) and analysis (e.g., what-
if analysis using simulation). bpm is a continuous effort, i.e., processes need to be
managed and bpm does not stop after completing the process design or system imple-
mentation. changing circumstances may trigger process adaptations and generate new
analysis questions. therefore, it is important to continuously monitor processes (e.g.,
using process mining).
this paper aims to survey the maturing bpm discipline. section 2 provides a his-
toric overview of bpm. section 3 further structures the bpm discipline. for example,
processes are classiﬁed using bpm-relevant properties. section 4 lists various bpm use
cases . these use cases refer to the creation of process models and their usage to im-
prove, enact and manage processes. section 5 discusses six key bpm concerns in more
detail: process modeling languages, process enactment infrastructures, process model4 wil van der aalst
model
enactanalyze
manage
fig. 2. a high-level view on bpm showing the four key activities: model (creating a process
model to be used for analysis or enactment), enact (using a process model to control and sup-
port concrete cases), analyze (analyzing a process using a process model and/or event logs), and
manage (all other activities, e.g., adjusting the process, reallocating resources, or managing large
collections of related process models).
analysis, process mining, process ﬂexibility, and process reuse. section 6 concludes the
paper with an outlook on the future of bpm.
2 history of bpm
business process management (bpm) has various roots in both computer science and
management science. therefore, it is difﬁcult to pinpoint the starting point of bpm.
since the industrial revolution, productivity has been increasing because of technical
innovations, improvements in the organization of work, and the use of information
technology. adam smith (1723-1790) showed the advantages of the division of la-
bor. frederick taylor (1856-1915) introduced the initial principles of scientiﬁc manage-
ment. henry ford (1863-1947) introduced the production line for the mass production
of “black t-fords”. it is easy to see that these ideas are used in today’s bpm systems.
around 1950 computers and digital communication infrastructures started to inﬂu-
ence business processes. this resulted in dramatic changes in the organization of work
and enabled new ways of doing business. today, innovations in computing and com-
munication are still the main drivers behind change in almost all business processes.
business processes have become more complex, heavily rely on information systems,
and may span multiple organizations. therefore, process modeling has become of the
utmost importance. process models assist in managing complexity by providing insight
and by documenting procedures. information systems need to be conﬁgured and driven
by precise instructions. cross-organizational processes can only function properly if
there is common agreement on the required interactions. as a result, process models
are widely used in todays organizations.
in the last century many process modeling techniques have been proposed. in fact,
the well-known turing machine described by alan turing (1912-1954) can be viewed
as a process model. it was instrumental in showing that many questions in computerbusiness process management: a comprehensive survey 5
science are undecidable. moreover, it added a data component (the tape) to earlier tran-
sition systems. petri nets play an even more prominent role in bpm as they are graphical
and able to model concurrency. in fact, most of the contemporary bpm notations and
systems use token-based semantics adopted from petri nets. petri nets were proposed
by carl adam petri (1926-2010) in 1962. this was the ﬁrst formalism treating concur-
rency as a ﬁrst-class citizen. concurrency is very important as in business processes
many things may happen in parallel. many cases may be handled at the same time
and even within a case there may be various enabled or concurrently running activities.
therefore, a bpm system should support concurrency natively.
since the seventies there has been consensus on the modeling of data (cf. the rela-
tional model by codd [11] and the entity-relationship model by chen [12]). although
there are different languages and different types of database management (dbm) sys-
tems, there has been consensus on the fundamental concepts for the information-centric
view of information systems for decades. the process-centric view on information
systems on the other hand can be characterized by the term “divergence”. there is
little consensus on its fundamental concepts. despite the availability of established
formal languages (e.g., petri nets and process calculi) industry has been pushing ad-
hoc/domain-speciﬁc languages. as a result there is a plethora of systems and languages
available today (bpmn, bpel, uml, epcs, etc.), some of which will be discussed in
section 5.1.
applicationapplication
database 
systemuser 
interface
application
database 
systemuser 
interface
database 
systemapplication
bpm system
1960 1975 1985 2000
fig. 3. historic view on information systems development illustrating that bpm systems can be
used to push “process logic” out of the application (adapted from [13])).
figure 3 sketches the emergence of bpm systems and their role in the overall infor-
mation system architecture. initially, information systems were developed from scratch,
i.e., everything had to be programmed, even storing and retrieving data. soon peo-
ple realized that many information systems had similar requirements with respect to6 wil van der aalst
data management. therefore, this generic functionality was subcontracted to a dbm
system. later, generic functionality related to user interaction (forms, buttons, graphs,
etc.) was subcontracted to tools that can automatically generate user interfaces. the
trend to subcontract recurring functionality to generic tools continued in different areas.
bpm systems can be seen in this context: a bpm system takes care of process-related
aspects. therefore, the application can focus on supporting individual/speciﬁc tasks.
in the mid 1990s many wfm systems became available. these systems focused on
automating workﬂows with little support for process analysis, process ﬂexibility, and
process management. bpm systems provide much broader support, e.g., by supporting
simulation, business process intelligence, case management, etc. however, compared to
the database market, the bpm market is much more diverse and there is no consensus
on notations and core capabilities. this is not a surprise as process management is much
more challenging than data management.
a good starting point for exploring the scientiﬁc origins of bpm is the early work
onofﬁce information systems . in the seventies, people like skip ellis, anatol holt, and
michael zisman already worked on so-called ofﬁce information systems, which were
driven by explicit process models [1, 14–22]. ellis et al. [14, 15, 23, 16] developed of-
ﬁce automation prototypes such as ofﬁcetalk-zero and ofﬁcetalk-d at xerox parc
in the late 1970s. these systems used information control nets (icn), a variant of
petri nets, to model processes. ofﬁce metaphors such as inbox, outbox, and forms were
used to interact with users. the prototype ofﬁce automation system scoop (system
for computerizing of ofﬁce processes) developed by michael zisman also used petri
nets to represent business processes [20, 22, 21]. it is interesting to see that pioneers
in ofﬁce information systems already used petri-net-based languages to model ofﬁce
procedures. during the seventies and eighties there was great optimism about the appli-
cability of ofﬁce information systems. unfortunately, few applications succeeded. as a
result of these experiences, both the application of this technology and research almost
stopped for a decade. consequently, hardly any advances were made in the eighties.
in the nineties, there was a clear revival of the ideas already present in the early ofﬁce
automation prototypes [4]. this is illustrated by the many commercial wfm systems
developed in this period.
in the mid-nineties there was the expectation that wfm systems would get a role
comparable to database management (dbm) systems. most information systems sub-
contract their data management to dbm systems and comparatively there are just a
few products. however, these products are widely used. despite the availability of
wfm/bpm systems, process management is not subcontracted to such systems at a
scale comparable to dbm systems. the application of “pure” wfm/bpm systems is
still limited to speciﬁc industries such as banking and insurance. however, wfm/bpm
technology is often hidden inside other systems. for example, erp systems like sap
and oracle provide workﬂow engines. many other platforms include workﬂow-like
functionality. for example, integration and application infrastructure software such as
ibm’s websphere and cordys’s business operations platform (bop) provides exten-
sive process support. in hindsight, it is easy to see why process management cannot
be subcontracted to a standard wfm/bpm system at a scale comparable to dbm sys-
tems. as illustrated by the varying support for the workﬂow patterns [9, 24, 25], processbusiness process management: a comprehensive survey 7
management is much more “thorny” than data management. bpm is multifaceted, com-
plex, and difﬁcult to demarcate. given the variety in requirements and close connec-
tion to business concerns, it is often impossible to use generic bpm/wfm solutions.
therefore, bpm functionality is often embedded in other systems. moreover, bpm
techniques are frequently used in a context with conventional information systems.
bpm has become a mature discipline. its relevance is acknowledged by practitioners
(users, managers, analysts, consultants, and software developers) and academics. this
is illustrated by the availability of many bpm systems and a range of bpm-related
conferences.
in this survey we will often refer to results presented at the annual international
bpm conference. the international bpm conference is celebrating its 10th anniversary
and its proceedings provide a good overview of the state-of-the-art: bpm 2003 (eind-
hoven, the netherlands) [26], bpm 2004 (potsdam, germany) [27], bpm 2005 (nancy,
france) [28], bpm 2006 (vienna, austria) [29], bpm 2007 (brisbane, australia) [30],
bpm 2008 (milan, italy) [31], bpm 2009 (ulm, germany) [32], bpm 2010 (hoboken,
usa) [33], bpm 2011 (clermont-ferrand, france) [34], and bpm 2012 (tallinn, es-
tonia) [35]. other sources of information are the following books on wfm/bpm: [5]
(ﬁrst comprehensive wfm book focusing on the different workﬂow perspectives and
the mobile language), [36] (edited book that served as the basis for the bpm confer-
ence series), [4] (most cited wfm book; a petri net-based approach is used to model,
analyze and enact workﬂow processes), [19] (book relating wfm systems to opera-
tional performance), [7] (edited book on process-aware information systems), [6] (book
on production wfm systems closely related to ibm’s workﬂow products), [37] (vision-
ary book linking management perspectives to the pi calculus), [2] (book presenting the
foundations of bpm, including different languages and architectures), [38] (book based
on yawl and the workﬂow patterns), [8] (book focusing on process mining and bpm),
and [39] (book on supporting ﬂexibility in process-aware information systems). most
of these books also provide a historical perspective on the bpm discipline.
3 structuring the bpm discipline
before discussing typical bpm use cases and some of the key concerns of bpm, we
ﬁrst structure the domain by describing the bpm life-cycle and various classiﬁcations
of processes.
figure 4 shows the bpm life-cycle . in the (re)design phase , a process model is
designed. this model is transformed into a running system in the implementation/conﬁ-
guration phase . if the model is already in executable form and a wfm or bpm system
is already running, this phase may be very short. however, if the model is informal and
needs to be hardcoded in conventional software, this phase may take substantial time.
after the system supports the designed processes, the run & adjust phase starts. in this
phase, the processes are enacted and adjusted when needed. in the run & adjust phase,
the process is not redesigned and no new software is created; only predeﬁned controls
are used to adapt or reconﬁgure the process. figure 4 shows two types of analysis:
model-based analysis anddata-based analysis . while the system is running, event data
are collected. these data can be used to analyze running processes, e.g., discover bot-8 wil van der aalst
tlenecks, waste, and deviations. this is input for the redesign phase. during this phase
process models can be used for analysis. for example, simulation is used for what-if
analysis or the correctness of a new design is veriﬁed using model checking.
(re)design
implement/configurerun & adjustmodel-based 
analysisdata-based analysis
fig. 4. the bpm life-cycle consisting of three phases: (1) (re)design , (2)implement/conﬁgure and
(3)run & adjust .
the scope of bpm extends far beyond the implementation of business processes.
therefore, the role of model-based and data-based analyses is emphasized in figure 4.
business processes can be classiﬁed into human-centric and system-centric [40] or
more precisely into person-to-person (p2p), person-to-application (p2a) and applica-
tion-to-application (a2a) processes [7].
in p2p processes, the participants involved are primarily people, i.e. the processes
predominantly involve activities that require human intervention. job tracking, project
management, and groupware tools are designed to support p2p processes. indeed, the
processes supported by these tools are not composed of fully-automated activities only.
in fact, the software tools used in these processes (e.g. project tracking servers, e-
mail clients, video-conferencing tools, etc.) are primarily oriented towards supporting
computer-mediated interactions. recently, the importance of social networks increased
signiﬁcantly (facebook, twitter, linkedin, etc.) and bpm systems need to be able to in-
corporate such computer-mediated human interactions [41]. the term “social bpm”
refers to exploiting such networks for process improvement.
on the other end of the spectrum, a2a processes are those that only involve ac-
tivities performed by software systems. financial systems may exchange messages and
money without any human involvement, logistic information systems may automati-
cally order products when inventory falls below a predeﬁned threshold, transaction
processing systems, eai platforms, and web-based integration servers are examples of
technologies to support a2a processes.
p2a processes involve both human activities and interactions between people, and
activities and interactions involving applications which act without human intervention.business process management: a comprehensive survey 9
most bpm/wfm systems fall in the p2a category. in fact, most information systems
aim at making people and applications work in an integrated manner.
note that the boundaries between p2p, p2a, and a2a are not crisp. instead, there
is a continuum of processes, techniques, and tools covering the spectrum from p2p (i.e.
manual, human-driven) to a2a (automated, application-driven).
p2p
p2a
a2aun-
framedad-hoc 
framedloosely 
framedtightly 
framed
knowledge 
intensive
repeatable
fig. 5. classiﬁcation of processes: most processes can be found around the diagonal.
orthogonal to the classiﬁcation of processes into p2p, p2a, and a2a, we distin-
guish between unframed ,ad hoc framed ,loosely framed , and tightly framed processes
[7] (cf. figure 5).
a process is said to be unframed if there is no explicit process model associated
with it. this is the case for collaborative processes supported by groupware systems
that do notoffer the possibility of deﬁning process models.
a process is said to be ad hoc framed if a process model is deﬁned a priori but only
executed once or a small number of times before being discarded or changed. this is the
case in project management environments where a process model (i.e. a project chart)
is often only executed once. it is also the case in scientiﬁc computing environments,
where a scientist may deﬁne a process model corresponding to a computation executed
on a grid and involving multiple datasets and computing resources [42]. such a process
is often executed only once (although parts may be reused for other experiments).
aloosely framed process is one for which there is an a-priori deﬁned process model
and a set of constraints, such that the predeﬁned model describes the “normal way of
doing things” while allowing the actual executions of the process to deviate from this
model (within certain limits). case handling systems aim to support such processes,
that is, they support the ideal process and implicitly deﬁned deviations (e.g., skipping
activities or rolling back to an earlier point in the process).
finally, a tightly framed process is one which consistently follows an a-priori de-
ﬁned process model. tightly framed processes are best supported by traditional wfm
systems.
as figure 5 shows, the degree of framing of the underlying processes (unframed,
ad hoc, loosely, or tightly framed), and the nature of the process participants (p2p, p2a,
and a2a) are correlated. most processes are found around the diagonal. knowledge-
intensive processes tend to be less framed and more people-centric. highly repeatable
processes tend to be tightly framed and automated.10 wil van der aalst
as with p2p, p2a, and a2a processes, the boundaries between unframed, ad hoc
framed, loosely framed, and tightly framed processes are not crisp. in particular, there
is a continuum between loosely and tightly framed processes. for instance, during its
operational life a process considered to be tightly framed can start deviating from its
model so often and so unpredictably, that at some point in time it may be considered
to have become loosely framed. conversely, when many instances of a loosely framed
process have been executed, a common structure may become apparent, which may
then be used to frame the process in a tighter manner.
figures 4 and 5 illustrate the breadth of the bpm spectrum. a wide variety of pro-
cesses – ranging from unframed and people-centric to tightly framed and fully auto-
mated – may be supported using bpm technology. different types of support are needed
in three main phases of the bpm life-cycle (cf. figure 4). moreover, various types of
analysis can be used in these phases: some are based on models only whereas others
also exploit event data. in the remainder we present a set of twenty bpm use cases
followed by a more detailed discussion of six key concerns . the use cases and key con-
cerns are used to provide a survey of the state-of-the-art in bpm research. moreover,
the proceedings of past bpm conferences are analyzed to see trends in the maturing
bpm discipline.
4 bpm use cases
to further structure the bpm discipline and to show “how, where, and when” bpm
techniques can be used, we provide a set of twenty bpm use cases. figures 6-13 show
graphical representations of these use cases. models are depicted as pentagons marked
with the letter “ m”. a model may be descriptive ( d), normative ( n), and/or executable
(e). a “ djnje” tag inside a pentagon means that the corresponding model is descrip-
tive, normative, or executable. tag “ e” means that the model is executable. conﬁg-
urable models are depicted as pentagons marked with “ cm”. event data (e.g., an event
log) are denoted by a disk symbol (cylinder shape) marked with the letter “ e”. informa-
tion systems used to support processes at runtime are depicted as squares with rounded
corners and marked with the letter “ s”. diagnostic information is denoted by a star
shape marked with the letter “ d”. we distinguish between conformance-related diag-
nostics (star shape marked with “ cd”) and performance-related diagnostics (star shape
marked with “ pd”).
the twenty atomic use cases can be chained together in so-called composite use
cases. these composite cases correspond to realistic bpm scenarios.
4.1 use cases to obtain models
the ﬁrst category of use cases we describe have in common that a process model is
produced (cf. figures 6 and 7).
design model (desm) use case design model (desm) refers to the creation of a pro-
cess model from scratch by a human. figure 6 shows the creation of a model repre-
sented by a pentagon marked with the letter “ m”. this is still the most common way tobusiness process management: a comprehensive survey 11
m
d|n|edesign model
em
d|ediscover model from 
event data
m
d|n|eselect model from 
collectionmmm
d|n|e(desm)
(discm)
(selm)
fig. 6. use cases to obtain a descriptive, normative, or executable process model.
create models. the hand-made model may be descriptive, normative, or executable. de-
scriptive models are made to describe the as-is or to-be situation. a descriptive model
may describe undesirable behavior. if the model only describes the desired behavior,
is is called normative. a normative model may describe a rule like “activities xandy
should never be executed by the same person for a given case” even though in reality
the rule is often violated and not enforced. an executable model can be interpreted un-
ambiguously by software, e.g., to enact or verify a process. given a state or sequence
of past activities, the model can determine the set of possible next activities. a model
may be executable and descriptive or normative, i.e., the three classes are not mutually
exclusive and combinations are possible.
discover model from event data (discm) the term “big data” is often used to
refer to the incredible growth of event data in recent years [43]. more and more or-
ganizations realize that the analysis of event data is crucial for process improvement
and achieving competitive advantage over competitors. use case discover model from
event data (discm) refers to the automated generation of a process model using process
mining techniques [8].
the goal of process mining is to extract knowledge about a particular (operational)
process from event logs, i.e., process mining describes a family of a-posteriori anal-
ysis techniques exploiting the information recorded in audit trails, transaction logs,
databases, etc. (cf. section 5.4). typically, these approaches assume that it is possible to
sequentially record events such that each event refers to an activity (i.e., a well-deﬁned
step in the process) and is related to a particular case (i.e., a process instance). fur-
thermore, some mining techniques use additional information such as the performer or
originator of the event (i.e., the person / resource executing or initiating the activity),
thetimestamp of the event, or data elements recorded with the event (e.g., the size of
an order).
a discovery technique takes an event log and produces a model without using any
a-priori information. an example is the -algorithm [44]. this algorithm takes an event12 wil van der aalst
log and produces a petri net explaining the behavior recorded in the log. for example,
given sufﬁcient example executions of the process shown in figure 1, the -algorithm is
able to automatically construct the corresponding petri net without using any additional
knowledge. if the event log contains information about resources, one can also discover
resource-related models, e.g., a social network showing how people work together in
an organization.
select model from collection (selm) large organizations may have repositories con-
taining hundreds of process models. there may be variations of the same model for dif-
ferent departments or products. moreover, processes may change over time resulting in
different versions. because of these complexities, (fragments of) process models may
be reinvented without reusing existing models. as a result, even more process models
need to coexist, thus further complicating model management. therefore, reuse is one
of the key concerns in bpm (cf. section 5.6).
use case select model from collection (selm) refers to the retrieval of existing pro-
cess models, e.g., based on keywords or process structures. an example of a query is
“return all models where activity send invoice can be followed by activity reimburse ”.
another example is the query “return all models containing activities that need to be
executed by someone with the role manager ”.
m
d|n|emerge modelsmmm
d|n|e
m
d|n|ecompose model m
d|n|em
d|n|e
m
d|n|e(merm)
(compm)
fig. 7. use cases to obtain a process model from other models.
merge models (merm) use case selm selects a complete model from some repos-
itory. however, often new models are created from existing models. use case merge
models (merm) refers to the scenario where different parts of different models are
merged into one model. for example, the initial part of one model is composed with
the ﬁnal part of another process, a process model is extended with parts taken from
another model, or different process models are uniﬁed resulting in a new model. unlike
classical composition the original parts may be indistinguishable.
compose model (compm) use case compose model (compm) refers to the situation
where different models are combined into a larger model. unlike use case merm the
different parts can be related to the original models used in the composition.business process management: a comprehensive survey 13
the ﬁve use cases shown in figures 6 and 7 all produce a model. the resulting
model may be used for analysis or enactment as will be shown in later use cases.
4.2 use cases involving conﬁgurable models
a conﬁgurable process model represents a family of process models , that is, a model that
through conﬁguration can be customized for a particular setting. for example, conﬁgu-
ration may be achieved by hiding (i.e., bypassing) or blocking (i.e., inhibiting) certain
fragments of the conﬁgurable process model [45]. in this way, the desired behavior is
selected. from the viewpoint of generic bpm software, conﬁgurable process models
can be seen as a mechanism to add “content” to these systems. by developing compre-
hensive collections of conﬁgurable models, particular domains can be supported. from
the viewpoint of erp software, conﬁgurable process models can be seen as a means to
make these systems more process-centric, although in the latter case quite some refac-
toring is needed as processes are often hidden in table structures and application code.
various conﬁgurable languages have been proposed as extensions of existing languages
(e.g., c-epcs [46], c-sap, c-bpel) but few are actually supported by enactment soft-
ware (e.g., c-yawl [47]). traditional reference models [48–50] can be seen as con-
ﬁgurable process models. however, conﬁguration is often implicit or ad-hoc and often
such reference models are not executable.
figure 8 shows three use cases related to conﬁgurable process models.
cm
d|n|emerge models into 
configurable modelmmm
d|n|ecm
d|n|edesign configurable 
model
m
d|n|econfigure configurable 
model
cm
d|n|e(descm)
(mercm)
(concm)
fig. 8. use cases to obtain and use conﬁgurable process models.
design conﬁgurable model (descm) conﬁgurable process models can be created
from scratch as shown by use case design conﬁgurable model (descm). creating a
conﬁgurable model is more involved than creating an ordinary non-conﬁgurable model.
for example, because of hiding and/or blocking selected fragments, the instances of a
conﬁgured model may suffer from behavioral anomalies such as deadlocks and live-
locks. this problem is exacerbated by the many possible conﬁgurations a model may14 wil van der aalst
have, and by the complex domain dependencies which may exist between various con-
ﬁguration options [51].
merge models into conﬁgurable model (mercm) a conﬁgurable process model
represents a family of process models. a common approach to obtain a conﬁgurable
model is to merge example members of such family into a model that is able to generate
a least the example variants. the merging of model variants into a conﬁgurable model
is analogous to the discovery of process models from example traces.
figure 9 illustrates the use case merge models into conﬁgurable model (mercm).
two variants of the same process are shown in the top-left corner. variant 1 models a
process where activity ais followed by activity b. after completing b, activitiesdand
fcan be executed in any order, followed by activity g. finally,his executed. variant 2
also starts with activity a. however, now ais followed by activities dandfordande.
moreover, after completing gthe process can loop back to a state where again there is
a choice between dandfordande.
the two variants can be merged into the conﬁgurable model shown in the center of
figure 9. activities candecan be blocked and activity bcan be hidden. if we block
candeand do not hide b(i.e.,bis activated), we obtain the ﬁrst variant. if we do not
blockcandeand hideb, we obtain the second variant.
conﬁgure conﬁgurable model (concm) figure 9 also illustrates use case conﬁgure
conﬁgurable model (concm). this use case creates a concrete model from some con-
ﬁgurable process model by selecting a concrete variant, i.e., from a family of process
variants one member is selected. the bottom part of figure 9 shows a variant created
by blocking activities candeand hiding activity b.
figure 9 is a bit misleading as it only shows the control-ﬂow. data-related aspects
and domain modeling play an important role in process conﬁguration. for example,
when conﬁguring erp systems like sap r/3 the data-perspective is most prominent.
4.3 use cases related to process execution
bpm systems are used to enact processes based on executable process models. in fact,
the initial focus of wfm systems was on process automation and implementation, and
not on the management, analysis and improvement of business processes (cf. figure 10).
reﬁne model (refm) only executable models can be enacted. therefore, use case
reﬁne model (refm) describes the scenario of converting a model tagged with “ djn”
into a model tagged with “ e”, i.e., a descriptive or normative model is reﬁned into a
model that is also executable. to make a model executable one needs to remove all
ambiguities, i.e., the supporting software should understand its meaning. moreover, it
may be necessary to detail aspects not considered relevant before. for example, it may
be necessary to design a form where the user can enter data.business process management: a comprehensive survey 15
variant 1 variant 2
example of additional variant merge models 
into configurable 
model
configure 
configurable 
model(mercm)
(concm)design 
configurable 
model
(descm)
aa bbdd
eegg hhcc
ffactivate
block
hidevariant 1
variant 2
aa bbdd
eegg hhcc
ffaa bbdd
eegg hhcc
ff
aa bbdd
gg hh
ffaadd
eegg hhcc
ff
aa bbdd
eegg hhcc
ff
aadd
gg hh
ffaa bbdd
gg hh
ff
aadd
eegg hhcc
ff
fig. 9. abstract example illustrating the use cases related to conﬁgurable process models. a con-
ﬁgurable model may be created from scratch (use case descm) or from existing process models
(use case mercm). the resulting conﬁgurable model can be used to generate concrete models by
hiding and blocking parts (use case concm).16 wil van der aalst
senact model
m
e
log event data
es
s
monitor
s drefine model
m
d|nm
e(refm)
(enm)
(loged)
(mon)
adapt while running
m
e(adawr) s m
e
fig. 10. use cases to enact models, to log event data, and to monitor running processes.
enact model (enm) executable models can be interpreted by bpm systems and used
to support the execution of concrete cases. use case enact model (enm) takes as input
a model and as output a running system. the running system should be reliable, usable,
and have a good performance. therefore, issues like exception handling, scalability,
and ergonomics play an important role. these factors are typically not modeled when
discussing or analyzing processes. yet they are vital for the actual success of the system.
therefore, section 5.2 discusses the process enactment infrastructure as one of the key
concerns of bpm.
log event data (loged) when process instances (i.e., cases) are handled by the
information system, they leave traces in audit trails, transaction logs, databases, etc.
even when no bpm/wfm systems is used, relevant events are often recorded by the
supporting information system. use case log event data (loged) refers to the recording
of event data, often referred to as event logs . such event logs are used as input for
various process mining techniques. section 5.4 discusses the use of event data as one of
the key concerns of bpm.
monitor (mon) whereas process mining techniques center around event data and mod-
els (e.g., models are discovered or enriched based on event logs), monitoring techniquesbusiness process management: a comprehensive survey 17
simply measure without building or using a process model. for example, it is possible to
measure response times without using or deriving a model. modern bpm systems show
dashboards containing information about key performance indicators (kpis) related to
costs, responsiveness, and quality. use case monitor (mon) refers to all measurements
done at runtime without actively creating or using a model.
adapt while running (adawr) bpm is all about making choices. when designing
a process model choices are made with respect to the ordering of activities. at run-
time, choices may be resolved by human decision making. also process conﬁguration
is about selecting the desired behavior from a family of process variants. as will be
explained in section 5.5, ﬂexibility can be viewed as the ability to make choices at dif-
ferent points in time (design-time, conﬁguration-time, or runtime). some types of ﬂexi-
bility require changes of the model at runtime. use case adapt while running (adawr)
refers to the situation where the model is adapted at runtime. the adapted model may
be used by selected cases (ad-hoc change) or by all new cases (evolutionary change).
adapting the system or process model at runtime may introduce all kinds of complica-
tions. for example, by making a concurrent process more sequential, deadlocks may be
introduced for already running cases.
4.4 use cases involving model-based analysis
process models are predominantly used for discussion, conﬁguration, and implementa-
tion. interestingly, process models can also be used for analysis. this is in fact one of
the key features of bpm. instead of directly hard-coding behavior in software, models
can be analyzed before being put into production.
analyze performance based on model (perfm) executable process models can be
used to analyze the expected performance in terms of response times, waiting times,
ﬂow times, utilization, costs, etc. use case analyze performance based on model (perfm)
refers to such analyses. simulation is the most widely applied analysis technique in
bpm because of its ﬂexibility. most bpm tools provide a simulation facility. analyti-
cal techniques using for example queueing networks or markov chains can also be used
to compute the expected performance. however, these are rarely used in practice due to
the additional assumptions needed.
verify model (verm) before a process model is put into production, one would like to
get assurance that the model is correct. consider for example the notion of soundness
[13, 52]. a process model is sound if cases cannot get stuck before reaching the end
(termination is always possible) and all parts of the process can be activated (no dead
segments). use case verify model (verm) refers to the analysis of such properties using
techniques such as model checking.
section 5.3 elaborates on model-based analysis as one of the key concerns of bpm.18 wil van der aalst
analyze performance 
based on model
m
epd
verify model
m
ecd(perfm)
(verm)
fig. 11. use cases for model-based analysis.
4.5 use cases extracting diagnostics from event data
a process model may serve as a pair of glasses that can be used to look at reality. as
figure 12 shows, we identify two use cases where diagnostic information is derived
from both model and event data.
check conformance using event data (confed) event data and models can be
compared to see where modeled and observed behavior deviate. for example, one may
replay history on a process model and see where observed events do not “ﬁt” the model.
use case check conformance using event data (confed) refers to all kinds of analysis
aiming at uncovering discrepancies between modeled and observed behavior. confor-
mance checking may be done for auditing purposes, e.g., to uncover fraud or malprac-
tices.
analyze performance using event data (perfed) event data often contain timing
information, i.e., events have timestamps that can be used for performance analysis.
use case analyze performance using event data (perfed) refers to the combined use of
models and timed event data. by replaying an event log with timestamps on a model,
one can measure delays, e.g., the time in-between two subsequent activities. the result
can be used to highlight bottlenecks and gather information for simulation or prediction
techniques.
4.6 use cases producing new models based on diagnostics or event data
diagnostic information and event data can be used to repair, extend, or improve models
(cf. figure 13).
repair model (repm) use case confed can be used to see where reality and model
deviate. the corresponding diagnostics can be used as input for use case repair model
(repm), i.e., the model is adapted to match reality better [53]. on the one hand, the
resulting model should correspond to the observed behavior. on the other hand, the
repaired model should be as close to the original model as possible. the challenge is to
balance both concerns.business process management: a comprehensive survey 19
check conformance 
using event data
m
ecde
analyze performance 
using event data
m
eepd(confed)
(perfed)
fig. 12. use cases were diagnostics are obtained using both model and log.
repair model
m
d|n|ecd m
d|n|e
extend model
m
eem
e
improve model
m
d|n|em
d|n|epd(repm)
(extm)
(impm)
fig. 13. use cases to repair, extend, or improve process models.
extend model (extm) event logs refer to activities being executed and events may be
annotated with additional information such as the person/resource executing or initiat-
ing the activity, the timestamp of the event, or data elements recorded with the event.
use case extend model (extm) refers to the use of such additional information to enrich
the process model. for example, timestamps of events may be used to add delay dis-
tributions to the model. data elements may be used to infer decision rules that can be
added to the model. resource information can be used to attach roles to activities in the
model. this way it is possible to extend a control-ﬂow oriented model with additional
perspectives.
improve model (impm) performance related diagnostics obtained through use case
perfed can be used to generate alternative process designs aiming at process improve-
ments, e.g., to reduce costs or response times. use case improve model (impm) refers
to bpm functionality helping organizations to improve processes by suggesting alter-
native process models. these models can be used to do “what-if” analysis. note that
unlike repm the focus impm is on improving the process itself.20 wil van der aalst
4.7 composite use cases
the twenty atomic use cases should not be considered in isolation, i.e., for practical
bpm scenarios these atomic use cases are chained together into composite use cases.
figure 14 shows three examples.
m
edesign model
(desm)analyze performance 
based on model
pd (perfm)
(a) a conventional simulation study not involving any event data can be viewed as a 
composite use case obtained by chaining two atomic use cases (desm and perfm)
log event data
es(loged)
m
d|n|e
design model(desm)check conformance 
using event data
cd
(confed)
(b) a composite use case obtained by chaining three atomic use cases (loged, desm, and confed)
m
d|ndesign model
(desm)
analyze performance using event datapd
(perfed)log event data
e(loged)enact model
srefine model
m
e(refm) (enm)
(c) a composite use case obtained by chaining five use cases: desm, refm, enm, loged, and perfed
fig. 14. three composite use case obtained by chaining atomic use cases.
the ﬁrst example (figure 14(a)) is the classical scenario where a model is con-
structed manually and subsequently used for performance analysis. note that the use
cases design model (desm) and analyze performance based on model (perfm) are
chained together. a conventional simulation not involving event data would ﬁt this com-
posite use case.
the second composite use case in figure 14 combines three atomic use cases: the
observed behavior extracted from some information system (loged) is compared with
a manually designed model (desm) in order to ﬁnd discrepancies (confed).
figure 14(c) shows a composite use case composed of ﬁve atomic use cases. the
initially designed model (desm) is reﬁned to make it executable (refm). the model
is used for enactment (enm) and the resulting behavior is logged (loged). the mod-
eled behavior and event data are used to reveal bottlenecks (perfed), i.e., performance
related information is extracted from the event log and projected onto the model.
the composite use cases in figure 14 are merely examples, i.e., a wide range of
bpm scenarios can be supported by composing the twenty atomic use cases.business process management: a comprehensive survey 21table 1. relative importance of use cases in [36], [26], [27], [28], [29], [30], [31], [32], [33], and [34]. each of the 289 papers was tagged with, on
average, 1.18 use cases (typically 1 or 2 use cases per paper). the table shows the relative frequency of each use case per year. the last row shows the
average over 10 years. all rows add up to 1.
design
modeldiscover
model
from event
dataselect
model
from
collectionmerge
modelscompose
modeldesign con-
ﬁgurable
modelmerge
models
into con-
ﬁgurable
modelconﬁgure
conﬁg-
urable
modelreﬁne
modelenact
modellog event
datamonitoradapt while
runninganalyze
perfor-
mance
based on
modelverify
modelcheck con-
formance
using event
dataanalyze
perfor-
mance
using event
datarepair
modelextend
modelimprove
model
desm discm selm merm compm descm mercm concm refm enm loged mon adawr perfm verm confed perfed repm extm impm
year
2000 0.406 0.000 0.000 0.000 0.031 0.000 0.000 0.000 0.000 0.188 0.000 0.000 0.063 0.125 0.188 0.000 0.000 0.000 0.000 0.000
2003 0.306 0.028 0.056 0.000 0.056 0.000 0.000 0.028 0.000 0.222 0.028 0.000 0.139 0.000 0.111 0.000 0.000 0.000 0.028 0.000
2004 0.348 0.130 0.000 0.000 0.043 0.000 0.000 0.000 0.000 0.217 0.000 0.000 0.043 0.087 0.087 0.000 0.000 0.000 0.000 0.043
2005 0.216 0.039 0.039 0.000 0.098 0.000 0.000 0.000 0.000 0.294 0.000 0.000 0.059 0.078 0.137 0.000 0.000 0.000 0.000 0.039
2006 0.094 0.038 0.057 0.019 0.132 0.000 0.000 0.000 0.019 0.245 0.019 0.000 0.075 0.019 0.226 0.019 0.019 0.000 0.000 0.019
2007 0.231 0.128 0.026 0.026 0.051 0.026 0.026 0.077 0.077 0.077 0.026 0.026 0.026 0.051 0.103 0.000 0.026 0.000 0.000 0.000
2008 0.227 0.045 0.023 0.000 0.045 0.000 0.023 0.000 0.023 0.182 0.045 0.000 0.023 0.091 0.136 0.000 0.045 0.023 0.068 0.000
2009 0.167 0.133 0.067 0.000 0.033 0.000 0.033 0.000 0.133 0.133 0.033 0.000 0.000 0.033 0.167 0.033 0.033 0.000 0.000 0.000
2010 0.167 0.133 0.100 0.000 0.000 0.033 0.000 0.033 0.033 0.300 0.000 0.000 0.000 0.000 0.100 0.067 0.000 0.000 0.033 0.000
2011 0.061 0.091 0.121 0.030 0.000 0.000 0.061 0.000 0.000 0.121 0.000 0.061 0.000 0.000 0.182 0.152 0.030 0.061 0.030 0.000
average 0.222 0.077 0.049 0.007 0.049 0.006 0.014 0.014 0.029 0.198 0.015 0.009 0.043 0.048 0.144 0.027 0.015 0.008 0.016 0.01022 wil van der aalst
4.8 analysis of bpm conference proceedings based on use cases
after describing the twenty bpm uses cases, we evaluate their relative importance in
bpm literature [54]. as a reference set of papers we used all papers in the proceedings
of past bpm conferences, i.e., bpm 2003 - bpm 2011 ([26], [27], [28], [29], [30],
[31], [32], [33], and [34]) and the edited book “business process management: models,
techniques, and empirical studies” [36]. the edited book [36] appeared in 2000 and
can be viewed as a predecessor of the ﬁrst bpm conference.
in total 289 papers were analyzed by tagging each paper with the use cases [54].
as will be discussed in section 5.7, we also tagged each paper with the key concerns
addressed. since the bpm conference is the premier conference in the ﬁeld, these 289
papers provide a representative view on bpm research over the last decade.
most papers were tagged with one dominant use case, but sometimes more tags
were used. in total, 367 tags were assigned (on average 1.18 use cases per paper). for
example, the paper “instantaneous soundness checking of industrial business process
models” [55] presented at bpm 2009 is a typical example of a paper tagged with use
case verify model (verm). in [55] 735 industrial business process models are checked
for soundness (absence of deadlock and lack of synchronization) using three differ-
ent approaches. the paper “graph matching algorithms for business process model
similarity search” [56] presented at the same conference was tagged with the use case
select model from collection (selm) since the paper presents an approach to rank pro-
cess models in a repository based on some input model. these examples illustrate the
tagging process.
by simply counting the number of tags per use case and year, the relative frequency
of each use case per year can be established. for example, for bpm 2009 four papers
were tagged with use case discover model from event data (discm). the total number
of tags assigned to the 23 bpm 2009 papers is 30. hence, the relative frequency of
discm is 4=30 = 0:133. table 1 shows all relative frequencies including the one just
mentioned. the table also shows the average relative frequency of each use case over
all ten years. these averages are shown graphically in figure 15.
figure 15 shows that use cases design model (desm) and enact model (enm) are
most frequent. this is not very surprising as these use cases are less speciﬁc than most
other use cases. the third most frequent use case – verify model (verm) – is more
surprising (relative frequency of 0.144). an example paper having such a tag is [55]
which was mentioned before. over the last decade there has been considerable progress
in this area and this is reﬂected by various veriﬁcation papers presented at bpm. in
this context it is remarkable that the use cases monitor (mon) and analyze performance
using event data (perfed) have a much lower relative frequency (respectively 0.009
and 0.015). given the practical needs of bpm one would expect more papers presenting
techniques to diagnose and improve the performance of business processes.
figure 16 shows changes of relative frequencies over time. the graph shows a slight
increase in process-mining related topics. however, no clear trends are visible due to
the many use cases and small number of years and papers per year. therefore, the
289 bpm papers were also analyzed based on the six key concerns presented next (cf.
section 5.7).business process management: a comprehensive survey 23
0.0000.0500.1000.1500.2000.250
fig. 15. average relative importance of use cases (taken from table 1).
0.0000.1000.2000.3000.4000.5000.6000.7000.8000.9001.000
2000 2003 2004 2005 2006 2007 2008 2009 2010 2011improve model (impm)
extend model (extm)
repair model (repm)
analyze performance using event data (perfed)
check conformance using event data (confed)
verify model (verm)
analyze performance based on model (perfm)
adapt while running (adawr)
monitor (mon)
log event data (loged)
enact model (enm)
refine model (refm)
configure configurable model (concm)
merge models into configurable model (mercm)
design configurable model (descm)
compose model (compm)
merge models (merm)
select model from collection (selm)
discover model from event data (discm)
design model (desm)
fig. 16. development of the relative importance of each use case plotted over time (derived from
table 1).
5 bpm key concerns
the use cases refer to the practical/intended use of bpm techniques and tools. however,
bpm research is not equally distributed over all of these use cases. some use cases pro-24 wil van der aalst
vide important engineering or managerial challenges, but these are not bpm-speciﬁc or
do not require additional bpm research. other use cases require foundational research
and are not yet encountered frequently in practice. therefore, we now zoom in on six
key concerns addressed by many bpm papers: process modeling languages, process
enactment infrastructures, process model analysis, process mining, process ﬂexibility,
and process reuse.
5.1 process modeling languages
the modeling and analysis of processes plays a central role in business process man-
agement. therefore, the choice of language to represent an organization’s processes is
essential. three classes of languages can be identiﬁed:
– formal languages : processes have been studied using theoretical models. mathe-
maticians have been using markov chains, queueing networks, etc. to model pro-
cesses. computer scientists have been using turing machines, transition systems,
petri nets, temporal logic and process algebras to model processes. all of these
languages have in common that they have unambiguous semantics and allow for
analysis .
– conceptual languages : users in practice often have problems using formal lan-
guages due to the rigorous semantics (making it impossible to leave things in-
tentionally vague) and low-level nature. they typically prefer to use higher-level
languages. examples are bpmn (business process modeling notation, [57, 58]),
epcs (event-driven process chains, [59–61]), uml activity diagrams, etc. (see
figure 17 for some examples). these language are typically informal , i.e., they do
not have a well-deﬁned semantics and do not allow for analysis. moreover, the lack
of semantics makes it impossible to directly execute them.
– execution languages : formal languages typically abstract from “implementation
details” (e.g., data structures, forms, and interoperability problems) and concep-
tual languages only provide an approximate description of the desired behavior.
therefore, more technical languages are needed for enactment. an example is the
bpel (business process execution language, [62]) language. most vendors pro-
vide a proprietary execution language. in the latter case, the source code of the
implemented tool determines the exact semantics.
note that fragments of languages like bpmn, uml, bpel, and epcs have been for-
malized by various authors [63, 64]. however, these formalizations typically cover only
selected parts of the language (e.g., abstract from data or or-joins). moreover, people
tend to use only a small fragment of languages like bpmn [10]. to illustrate problems
related to the standardization of industry-driven languages, consider the or-join se-
mantics described in the most recent bpmn standard [58]. many alternative semantics
have been proposed and are used by different tools and formalizations [65–68]. there is
a trade-off between accuracy and performance and due to the “vicious circle” [69, 66] it
is impossible to provide “clean semantics” for all cases. in fact, the or-join semantics
of [58] are not supported by any of the many tools claiming to support bpmn.business process management: a comprehensive survey 25
register 
requestadd extra 
insurance
check drivers 
licenceinitiate 
check-in
startselect
car
charge credit 
cardinitiate 
check-in
end
(a) bpmn (business process modeling notation) model
startregister 
requestxoradd extra 
insurance
xorinitiate 
check-inandcheck 
drivers 
licenceselect
car
charge 
credit cardandinitiate 
check-inno needneeded addedready to 
be 
selected
ready to 
be 
checked
ready to 
be 
chargedready for 
check-indone
(b) epc (event-driven process chain) model
fig. 17. two examples of conceptual procedural languages: (a) bpmn (business process mod-
eling notation, [58]) and (b) epc (event-driven process chain, [59]).
activity a
startend
and-split
activity b
end
or-joinor-join and-split
and-split
fig. 18. an example of a so-called “vicious circle” in a bpmn model with two or-joins.
figure 18 illustrates the “vicious circle” paradox [69, 66]. the intuitive semantics of
an or-join is to wait for all tokens to arrive. in the state shown in figure 18, each or-
join has a token on one of its input arcs (denoted by the two black dots). the top or-join
should occur if it cannot receive a token via its second input arc. by symmetry the same
holds for the second or-join. suppose that one or-join needs to wait for a second
token to arrive, then also the other or-join needs to wait due to symmetry. however, in
this case the process deadlocks and no second token will be received by any of the or-
joins, i.e., none of the or-joins should have blocked. suppose that one or-join does not
wait for a second token to arrive, then, by symmetry, also the other or-join can move
forward. however, in this case each or-join receives a second token and in hindsight
both should have blocked. the example shown has no obvious interpretation; however,
the paradox revealed by the “vicious circle” also appears in larger, more meaningful,
examples where one or-join depends on another or-join.26 wil van der aalst
thus far we only considered procedural languages like petri nets, bpmn, uml
activity diagrams, and bpel. although lion’s share of bpm research is focusing on
such languages, there is also bpm research related to more declarative forms of pro-
cess modeling. procedural process models take an “inside-to-outside” approach, i.e.,
all execution alternatives need to be speciﬁed explicitly and new alternatives must be
explicitly added to the model. declarative models use an “outside-to-inside” approach:
anything is possible unless explicitly forbidden. to illustrate the “outside-to-inside” ap-
proach of modeling we use the example shown in figure 19. the example is expressed
in terms of the declare language [70, 71] and is intended to be witty; it does not model
a realistic business process but illustrates the modeling constructs. the declare model
consists of four activities ( a= eat food, b= feel bad,c= drink beer, and d= drink
wine) and four constraints ( c1,c2,c3, andc4). without any constraints any sequence
of activities is allowed as only constraints can limit the allowed behavior.
eat food feel baddrink beer
drink winec
da bc1
c4c2
c3
fig. 19. example illustrating the declarative style of process modeling where anything is possible
unless explicitly forbidden by constraints.
declare is grounded in linear temporal logic (ltl) with ﬁnite-trace semantics,
i.e., each constraint is mapped onto an ltl formula using temporal operators such
as always ( ), eventually ( ), until ( t), weak until ( w), and next time ( ) [72, 73].
the construct connecting activities canddis a so-called non-coexistence constraint . in
terms of ltl constraint c1means “ :((c)^(d))”, i.e., canddcannot both be
true. hence, it is not allowed that both canddhappen for the same case (beer and wine
do not mix well). however, in principle, one of them can occur an arbitrary number of
times. there are two precedence constraints (c2andc3). the semantics of precedence
constraint c2which connects atoccan also be expressed in terms of ltl: “ (:c)w a”,
i.e.,cshould not happen before ahas happened. since the weak until ( w) is used in
“(:c)w a ”, traces without any aandcevents also satisfy the constraint. similarly,
dshould not happen before ahas happened: “ (:d)w a ”. there is one branched re-
sponse constraint :c4. the ltl formalization of the constraint connecting btocandd
is “(b)(c_d))”, i.e., every occurrence of bshould eventually be followed by c
ord. however, there does not need to be a one-to-one correspondence, e.g., four occur-
rences of activity bmay be followed by just one occurrence of activity c. for example,
traceha;c;c;a;b;b;b;b;c iis allowed. whereas in a procedural model, everything isbusiness process management: a comprehensive survey 27
forbidden unless explicitly enabled, a declarative model allows for anything unless ex-
plicitly forbidden. trace ha;a;c;d iis not allowed as it violates c1(cannot drink both
wine and beer). trace hb;c;ciis not allowed as it violates c2(cannot drink beer before
eating food). trace ha;c;biis not allowed as it violates c4(after feeling bad one should
eventually drink beer or wine). for processes with a lot of ﬂexibility, declarative models
are often more appropriate [70, 71].
recently, more and more authors realized that conventional process modeling lan-
guages such as bpmn, uml ads, statecharts, bpel, yawl, wf-nets, and epcs pro-
vide only a monolithic view on the real process of interest. the process is “ﬂattened”
to allow for a diagram that describes the life-cycle of one case in isolation. proclets
[74] are one of the few business process modeling languages not forcing the modeler to
straightjacket processes into one monolithic model. instead, processes can be decom-
posed into a collection of interacting proclets that may have one-to-many or many-to-
many relationships (following the cardinalities in the corresponding data model). for
example, one order may result in multiple deliveries and one delivery may involve order
lines of different orders. this cannot be handled by the classical reﬁnement of activi-
ties. however, order, order line, and delivery proclets may coexist independent of one
another and are only loosely coupled. for example, an orderline exists because it was
created in the context of order. however, the actual delivery of the corresponding item
depends on inventory levels, transportation planing, and competing orders.
object-oriented and artifact-centric approaches use ideas related to proclets [75–
80]. these approaches aim to provide a better balance between process-centric and
data-centric modeling.
there is an increasing interest in understanding and evaluating the comprehensibil-
ity of process models [81–83]. the connection between complexity and process model
understanding has been shown empirically in recent publications (e.g. [84–87]) and
mechanisms have been proposed to alleviate speciﬁc aspects of complexity (e.g. [88–
90]). in [82, 83] various change patterns have been proposed. the goal of these pat-
terns is to modify the process model to make it more understandable. the collection of
patterns for concrete syntax modiﬁcations described in [82] includes mechanisms for
arranging the layout, for highlighting parts of the model using enclosure, graphics, or
annotations, for representing speciﬁc concepts explicitly or in an alternative way, and
for providing naming guidance. a collection of patterns for abstract syntax modiﬁca-
tions has been presented in [83]. these patterns affect the formal structure of process
model elements and their interrelationships (and not just the concrete syntax). for ex-
ample, a process model may be converted into a behavioral equivalent process model
that is block structured and thus easier to understand.
the existence and parallel use of a plethora of languages causes many problems.
the lack of consensus makes it difﬁcult to exchange models. the gap between concep-
tual languages and execution languages leads to re-work and a disconnect between users
and implementers. moreover, conceptual languages and execution languages often do
not allow for analysis.
the workﬂow patterns initiative [91] was established in the late nineties with the
aim of delineating the fundamental requirements that arise during business process
modeling on a recurring basis and describe them in an imperative way. based on an28 wil van der aalst
analysis of contemporary workﬂow products and modeling problems encountered in
various workﬂow projects, a set of twenty patterns covering the control-ﬂow perspec-
tive of bpm was created [9]. later this initial set was extended and now also includes
workﬂow resource patterns [24], workﬂow data patterns [25], exception handling pat-
terns [92], service-interaction patterns [93], and change patterns [94].
these collections of workﬂow patterns can be used to compare bpm/wfm lan-
guages and systems. moreover, they help focusing on the core issues rather than adding
new notations to the “tower of babel for process languages”. the lack of consensus on
the modeling language to be used, resulted in a plethora of similar but subtly different
languages inhibiting effective and uniﬁed process support and analysis. this “tower of
babel” and the corresponding discussions obfuscated more foundational questions.
5.2 process enactment infrastructures
the workﬂow management coalition (wfmc) was founded in august 1993 as a in-
ternational non-proﬁt organization. in the early 1990-ties, the wfmc developed their
so-called reference model [95, 96]. although the detailed text describing the reference
model refers to outdated standards and technologies, it is remarkable to see that af-
ter almost twenty years the reference model of the wfmc still adequately structures
the desired functionality of a wfm/bpm system. figure 20 shows an overview of the
reference model. it describes the major components and interfaces within a workﬂow
architecture. in our description of the reference model we use the original terminology.
therefore, “business processes” are often referred to as “workﬂows” when explaining
the reference model.
the core of any wfm/bpm system is the so-called workﬂow enactment service .
the workﬂow enactment service provides the run-time environment which takes care
of the control and execution of workﬂows. for technical or managerial reasons the
workﬂow enactment service may use multiple workﬂow engines . a workﬂow engine
handles selected parts of the workﬂow and manages selected parts of the resources.
theprocess deﬁnition tools are used to specify and analyze workﬂow process deﬁni-
tions and/or resource classiﬁcations. these tools are used at design time. in most cases,
the process deﬁnition tools can also be used for business process modeling and analy-
sis. most wfm/bpm systems provide three process deﬁnition tools: (1) a tool with a
graphical interface to deﬁne workﬂow processes, (2) a tool to specify resource classes
(organizational model describing roles, groups, etc.), and (3) an analysis tool to analyze
a speciﬁed workﬂow (e.g., using simulation or veriﬁcation). the end-user communi-
cates with the workﬂow system via the workﬂow client applications . an example of a
workﬂow client application is the well-known in-basket also referred to as work-list .
via such an in-basket work items are offered to the end user. by selecting a work item,
the user can execute a task for a speciﬁc case. if necessary, the workﬂow engine in-
vokes applications via interface 3. the administration and monitoring tools are used
to monitor and control the workﬂows. these tools are used to register the progress of
cases and to detect bottlenecks. moreover, they are also used to set parameters, allocate
people and handle abnormalities. via interface 4 the workﬂow system can be connected
to other workﬂow systems.business process management: a comprehensive survey 29
fig. 20. reference model of the workﬂow management coalition (wfmc).
to standardize the ﬁve interfaces shown in figure 20, the wfmc aimed at a com-
mon workﬂow application programming interface (wapi). the wapi was envisaged
as a common set of api calls and related interchange formats which may be grouped
together to support each of the ﬁve interfaces (cf. [96]). the wfmc also started to
work on a common language to exchange process models soon after it was founded.
this resulted in the workﬂow process deﬁnition language (wpdl) [97] presented
in 1999. although many vendors claimed to be wfmc compliant, few made a seri-
ous effort to support this language. at the same time, xml emerged as a standard for
data interchange. since wpdl was not xml-based, the wfmc started working on
a new language: xpdl (xml process deﬁnition language). the starting point for
xpdl was wpdl. however, xpdl should not be considered as the xml version
of wpdl. several concepts have been added/changed and the wfmc remained fuzzy
about the exact relationship between xpdl and wpdl. in october 2002, the wfmc
released a “final draft” of xpdl [98]. the language developed over time, but before
widespread adoption, xpdl was overtaken by the business process execution lan-
guage for web services (bpel) [99, 62]. bpel builds on ibm’s wsfl (web services
flow language) [100] and microsoft’s xlang (web services for business process
design) [101] and combines accordingly the features of a block structured language
inherited from xlang with those for directed graphs originating from wsfl. bpel
received considerable support from large vendors such as ibm, oracle, etc. however,
in practical terms also the relevance of bpel is limited. vendors tend to develop all
kinds of extensions (e.g., for people-centric processes) and dialects of bpel. more-
over, the increasing popularity of bpmn is endangering the position of bpel (several
vendors allow for the direct execution of subsets of bpmn thereby bypassing bpel).30 wil van der aalst
furthermore, process models are rarely exchanged between different platforms because
of technical problems (the “devil is in the details”) and too few use cases.
offer
work enactment 
servicemanagement 
toolsdesign tools
run-time dataprocess 
dataorganizational 
data
perform
workworkermanagementdesignerhistorical 
data
case
dataapplicationsanalysis tools
fig. 21. bpm reference architecture.
figure 21 shows the bpm reference architecture proposed in [1]. it is similar to
the reference model of the wfmc, but the ﬁgure details the data sets used and lists
the roles of the various stakeholders (management, worker, and designer). the designer
uses the design tools to create models describing the processes and the structure of the
organization. the manager uses management tools to monitor the ﬂow of work and act
if necessary. the worker interacts with the enactment service. the enactment service
can offer work to workers and workers can search, select and perform work. to support
the execution of tasks, the enactment service may launch various kinds of applications.
note that the enactment service is the core of the system deciding on “what”, “how”,
“when”, and “by whom”. clearly, the enactment service is driven by models of the
processes and the organizations using the system. by merely changing these models the
system evolves and adapts. this is the ultimate promise of wfm/bpm systems.
service-oriented computing (soc) has had an incredible impact on the architecture
of process enactment infrastructures. the key idea of service-orientation is to subcon-
tract work to specialized services in a loosely coupled fashion . in soc, functionality
provided by business applications is encapsulated within web services, i.e., software
components described at a semantic level, which can be invoked by application pro-
grams or by other services through a stack of internet standards including http, xml,
soap, wsdl and uddi [102–107]. once deployed, web services provided by vari-
ous organizations can be inter-connected in order to implement business collaborations,business process management: a comprehensive survey 31
leading to composite web services. although service-orientation does not depend on a
particular technology, it is often associated with standards such as http, xml, soap,
wsdl, uddi, and bpel. figure 22 shows an overview of the “web services technol-
ogy stack” and its relation to bpmn and bpel.
transport
tcp/ip, httpmessaging
soap, xmldescription
wsdlexecutable business processes
ws-bpel
quality of service, ...
ws-transaction ws-coordination ws-xxdiscovery
uddibusiness process modeling
bpmn
fig. 22. web services technology stack linking business process modeling (e.g., using the bpmn
notation) to technologies to realize a soa.
in aservice oriented architecture (soa) services are interacting, e.g., by exchang-
ing messages. by combining basic services more complex services can be created [103,
107]. orchestration is concerned with the composition of services seen from the view-
point of single service (the “spider in the web”). choreography is concerned with the
composition of services seen from a global viewpoint focusing on the common and
complementary observable behavior. choreography is particularly relevant in a setting
where there is no single coordinator. the terms orchestration and choreography de-
scribe two aspects of integrating services to create end-to-end business processes. the
two terms overlap somewhat and their distinction has been heavily discussed over the
last decade.
soc and soa can be used to realize process enactment infrastructures. processes
may implement services and, in turn, may use existing services. all modern bpm/wfm
systems provide facilities to expose deﬁned processes as services and to implement
activities in a process by simply calling other services. see for example the yawl
architecture [38] which completely decouples the invocation of an activity from the
actual execution of the activity.
interactions between different processes and applications may be more involved as
illustrated by the service interaction patterns by barros, dumas, and ter hofstede [93]
and the enterprise integration patterns by hohpe and woolf [108].
for the implementation of process enactment infrastructures, cloud computing and
related technologies such as software as a service (saas), platform as a service (paas),
andinfrastructure as a service (iaas) are highly relevant. saas, often referred to as “on-32 wil van der aalst
demand software”, is a software delivery model in which software and associated data
are centrally hosted on the cloud. the saas provider takes care of all hardware and soft-
ware issues. a well-know example is the collection of services provided by safesforce.
in the paas delivery model, the consumer creates the software using tools and libraries
from the provider. the consumer also controls software deployment and conﬁguration
settings. however, the provider provides the networks, servers and storage. the iaas de-
livery model, also referred to as “hardware as a service”, offers only computers (often
as virtual machines), storage and network capabilities. the consumer needs to maintain
the operating systems and application software.
the above discussion of different technologies illustrates that there are many ways
to implement the functionality shown in figure 21. there are both functional andnon-
functional requirements that need to be considered when implementing a process-aware
information system. the different collections of workﬂow patterns can be used to elicit
functional requirements. for example, the control-ﬂow-oriented workﬂow patterns [9]
can be used elicit requirements with respect to the ordering of activities. an example
is the “deferred choice” pattern [9], i.e., a choice controlled by the environment rather
than the wfm/bpm system. an organization needs to determine whether this pattern is
important and, if so, the system should support it. the workﬂow resource patterns [24],
workﬂow data patterns [25], and exception handling patterns [92] can be used in a
similar fashion. however, architectural choices are mostly driven by non-functional
requirements related to costs, response times, and reliability.
several bpm research groups are concerned with the performance of wfm/bpm
systems. although the core process management technology by itself is seldom the
bottleneck, some process-aware information systems need to deal with millions of cases
and thousands of concurrent users. note that process-related data are typically small
compared to the data needed to actually execute activities. the process state can be
encoded compactly and the computation of the next state is typically very fast compared
to application-related processing. however, since wfm/bpm systems needs to control
other applications, architectural considerations are important for the overall system’s
performance. for example, when the number of cases handled per hour grows over time,
there is a need to reconﬁgure the system and to distribute the work over more computing
nodes. cloud computing and saas provide the opportunity to outsource such issues.
load balancing and system reconﬁguration are then handled by the service provider.
another concern addressed by bpm research is the reliability of the resulting in-
formation system. wfm/bpm systems are often the “spider in the web” connecting
different technologies. for example, the bpm system invokes applications to execute
particular tasks, stores process-related information in a database, and integrates differ-
ent legacy and web-based systems. different components may fail resulting in loss of
data and parts of the systems that are out-of-sync. ideally, the so-called acid properties
(atomicity, consistency, isolation and durability) are ensured by the wfm/bpm sys-
tem; atomicity : an activity is either successfully completed in full (commit) or restarts
from the very beginning (rollback), consistency : the result of an activity leads to a con-
sistent state, isolation : if several tasks are carried out simultaneously, the result is the
same as if they had been carried out entirely separately, and durability : once a task is
successfully completed, the result must be saved persistently to ensure that work cannotbusiness process management: a comprehensive survey 33
be lost. in the second half of the nineties many database researchers worked on so-called
workﬂow transactions, i.e., long-running transactions ensuring the acid properties at
a business process level [109, 40, 110–113]. business processes need to be executed in
a partly uncontrollable environment where people and organizations may deviate and
software components and communication infrastructures may malfunction. therefore,
the bpm system needs to be able to deal with failures and missing data. research
on workﬂow transactions [109, 40, 110–113] aims to gracefully handle exceptions and
maintain system integrity at all times.
related to reliability are security concerns. wfm/bpm systems should ensure that
only authorized people can execute activities and access data [114]. role-based access
control (rbac, [115]) techniques can be applied in this setting. the workﬂow resource
patterns [24] also incorporate rbac functionalities. moreover, process-speciﬁc secu-
rity patterns such as the “four-eyes principle” (the same person may not execute two
dependent tasks for the same case even if the person has the appropriate role for both
tasks) are incorporated. cloud computing and saas technologies fuel new security-
related anxieties. multi-tenancy, i.e., multiple organizations using the same system, is
interesting from a cost perspective. costs are shared by different organizations using
economies of scale. moreover, load balancing and reconﬁguration can be supported in
a better manner when many tenants are sharing a large common infrastructure. for ex-
ample, smaller organizations may share a workﬂow engine whereas larger organizations
use many engines at the same time. this is all handled by the service provider. for the
service consumer these system (re)conﬁgurations are invisible. however, multi-tenancy
implies that different, possibly competing, organizations are using the same cloud or
saas system. therefore, the process infrastructure should ensure that information from
one tenant cannot leak to another tenant.
5.3 process model analysis
there are two mainstream approaches for model-based analysis: veriﬁcation andper-
formance analysis . veriﬁcation is concerned with the correctness of a system or process.
performance analysis focuses on ﬂow times, waiting times, utilization, and service lev-
els. unlike process-mining, these approaches do not use event data and perform analysis
using just the model.
a typical correctness property used for veriﬁcation is the soundness notion [13,
52]. soundness was originally deﬁned for workﬂow nets (wf-nets) but it applies to all
modeling techniques. a wf-net is a petri net with a dedicated source place where the
process starts, and a dedicated sink place where the process ends. moreover, all nodes
are on a path from source to sink. a token on the source place denotes the initial state.
the state with just a token on the sink place denotes the desired end state. such a wf-net
models the life-cycle of cases of a given kind. examples of cases are insurance claims,
job applications, customer orders, replenishment orders, patient treatments, and credit
applications. the process model is instantiated once for each case. each of these process
instances has a well-deﬁned start (“case creation”) and end (“case completion”). in-
between these points, activities are conducted according to a predeﬁned procedure. one
model may be instantiated many times. for example, the process of handling insurance34 wil van der aalst
claims may be executed for thousands or even millions of claims. these instances can
be seen as copies of the same wf-net, i.e., tokens of different cases are not mixed.
book carc
add extra 
insurancedchange 
booking
e
confirm initiate 
check-inj
check driver’s 
license
k
charge credit 
cardi
select carg
supply 
carinab
skip extra
insurance
fhadd extra 
insurance
skip extra 
insurance
l
outc1 c2
c3c4
c5
c6
c7c8
c9
c10
c11c12
fig. 23. a wf-net that is not sound: activity dis dead (can never be executed), cases may dead-
lock in the state with a token in c4,c9,c10, and c11, and a token may be left behind in place
c12.
not every wf-net represents a correct process. the modeled process may exhibit
errors such as deadlocks, activities that can never become active, livelocks, and im-
proper termination (i.e., garbage being left in the process after completion). consider
for example the wf-net shown in figure 23 exhibiting several problems.
a wf-net is sound if and only if (a) from any reachable state it is possible to reach a
state with a token in the sink place ( option to complete ), (b) any reachable state having
a token in the sink place does not have a token in any of the other places ( proper com-
pletion ), and (c) for any transition there is a reachable state enabling it ( absence of dead
parts ) [13, 52]. the wf-net shown in figure 23 obviously violates all three properties.
for subclasses of wf-nets, soundness can be analyzed without constructing the state
space. for example, for free-choice petri nets, i.e., processes where choice and synchro-
nization can be separated, soundness can be checked by analyzing the rank of the corre-
sponding incidence matrix [13, 116]. hence, soundness can be checked in polynomial
time for free-choice wf-nets. invariants can often be used to diagnose soundness prob-
lems, e.g., the absence of particular place and transition invariants for the short-circuited
wf-net provides possible causes for non-soundness. however, most of the more inter-
esting veriﬁcation questions require the exploration of (a part of) the state space. see
[13, 65, 117, 118, 52, 119–125, 55, 126–131, 68] for examples of veriﬁcation techniques
analyzing soundness-related properties for workﬂows and business processes
soundness is a generic property, but sometimes a more speciﬁc property needs to be
investigated, e.g., “the ticket was checked for all rejected requests”. such properties can
be expressed in temporal logic [72, 73]. as mentioned earlier linear temporal logicbusiness process management: a comprehensive survey 35
(ltl) is an example of a temporal logic that, in addition to classical logical operators,
uses temporal operators such as: always ( ), eventually ( ), until ( t), weak until ( w),
and next time ( ). the expression b)gmeans that for all cases in which b(skip
extra insurance ) is executed also g(add extra insurance ) is executed. another example
is(e)l)that states that any occurrence of ewill eventually be followed by l(after
conﬁrmation eventually a car is supplied). model checking techniques can be used to
check such properties [72].
another veriﬁcation task is the comparison of two models. for example, the imple-
mentation of a process is compared to the high-level speciﬁcation of the process. there
exist different equivalence notions (trace equivalence, branching bisimilarity, etc.) [132,
133]. trace equivalence considers two transition systems to be equivalent if their exe-
cution sequences are the same. more reﬁned notions like (branching) bisimilarity also
take the moment of choice into account [132, 133]. two process models are bisimilar if
the ﬁrst model can “mimic any move” of the second, and vice versa. consider for ex-
ample the processes p=a:(b+c)andq=a:b+a:c. both process can generate traces
ha;biandha;ci. however, in process pthe choice between bandcis made after the
occurrence of awhereas inqthis choice is made upfront, i.e., before the concurrence
ofa. to understand that such differences are relevant replace a,bandcby “take exam”,
“pass”, and “fail” respectively.
also in the context of services soundness-like properties have been investigated
[134, 117, 135–144]. these techniques focus on uncovering problems related to inter-
actions between different parties or services. for example, one service is waiting for the
other service to make the ﬁrst move and vice versa. note that one can easily design ser-
vices that cannot interoperate with any other service. the approach using the so-called
operating guidelines [144] computes a ﬁnite characterization of all partner services, i.e.,
services that can interoperate well with a given service.
conﬁgurable models represent families of process models [47, 145, 146, 46, 147].
a conﬁgurable model can be conﬁgured to obtain a speciﬁc process model that is sub-
sequently used to handle individual cases, for instance, to process customer orders.
various conﬁgurable languages have been proposed as extensions of existing languages
(e. g., c-epcs [46], c-iepcs [146], c-wf-nets [148], c-sap and c-bpel [47]) but
few are actually supported by enactment software (e. g., c-yawl [47]). process con-
ﬁguration is notoriously difﬁcult as there may be all kinds of interdependencies between
conﬁguration decisions. in fact, an incorrect conﬁguration may lead to behavioral issues
such as deadlocks and livelocks. the approach presented in [148] derives propositional
logic constraints from conﬁgurable process models that, if satisﬁed by a conﬁguration
step, guarantee the behavioral correctness of the conﬁgured model. the approach in
[51] ensures this by using partner synthesis: for a conﬁgurable process model a ﬁnite
representation of all correct conﬁgurations is generated.
there are various tools to verify process/workﬂow models. a classical example
is woﬂan that is tailored towards checking soundness [149]. also workﬂow systems
such as yawl [150] provide veriﬁcation capabilities [68]. the tool wendy [151] is an
example of a tool tailored towards partner synthesis. see [55, 126] for a comparative
evaluation of several veriﬁcation tools checking soundness-related properties.36 wil van der aalst
obviously, model-based analysis is not limited to correctness. in fact, from a man-
agement point of view, performance analysis is more relevant. the performance of a
process or organization can be deﬁned in different ways. typically, three dimensions
of performance are identiﬁed: time,cost andquality . for each of these performance
dimensions different key performance indicators (kpis) can be deﬁned. when looking
at the time dimension the following performance indicators can be identiﬁed:
–thelead time (also referred to as ﬂow time) is the total time from the creation of
the case to the completion of the case. in terms of a wf-net, this is the time it takes
to go from source place to sink place. one can measure the average lead time over
all cases. however, the degree of variance may also be important, i.e., it makes a
difference whether all cases take more or less two weeks or if some take just a few
hours whereas others take more than one month. the service level is the percentage
of cases having a lead time lower than some threshold value, e.g., the percentage of
cases handled within two weeks.
–theservice time is the time actually worked on a case. one can measure the service
time per activity (e.g., the average time needed to make a decision is 35 minutes)
or for the entire case. note that in case of concurrency the overall service time (i.e.,
summing up the times spent on the various activities) may be longer than the lead
time. however, typically the service time is just a fraction of the lead time (minutes
versus weeks).
–thewaiting time is the time a case is waiting for a resource to become available.
this time can be measured per activity or for the case as a whole. an example is
the waiting time for a customer who wants to talk to a sales representative. another
example is the time a patient needs to wait before getting a knee operation. again
one may be interested in the average or variance of waiting times. it is also possible
to focus on a service level, e.g., the percentage of patients that has a knee operation
within three weeks after the initial diagnosis.
–thesynchronization time is the time an activity is not yet fully enabled and waiting
for an external trigger or another parallel branch. the time the case is partially en-
abled (i.e., waiting for synchronization rather than an available resource) is counted
as synchronization time.
performance indicators can also be deﬁned for the cost dimension . different costing
models can be used, e.g., activity based costing (abc), time-driven abc, and re-
source consumption accounting (rca) [152]. the costs of executing an activity may
be ﬁxed or depend on the type of resource used, its utilization, or the duration of the
activity. resource costs may depend on the utilization of resources. a key performance
indicator in most processes is the average utilization of resources over a given period,
e.g., an operating room in a hospital has been used 85% of the time over the last two
months.
the quality dimension typically focuses on the “product” or “service” delivered
to the customer. like costs, this can be measured in different ways. one example is
customer satisfaction measured through questionnaires. another example is the average
number of complaints per case or the number of product defects.
whereas veriﬁcation focuses on the (logical) correctness of the modeled process,
performance analysis aims at improving processes with respect to time, cost, or quality.business process management: a comprehensive survey 37
within the context of operations management many analysis techniques have been de-
veloped [153–156]. some of these techniques “optimize” the model given a particular
performance indicator. for example, integer programming or markov decision prob-
lems can be used to ﬁnd optimal policies. for typical bpm problems “what if” analy-
ses using simulation, queueing models, or markov models are often most appropriate.
analytical models typically require many assumptions and can only be used to answer
particular questions. therefore, one often needs to resort to simulation . most bpm tools
provide simulation capabilities.
although many organizations have tried to use simulation to analyze their business
processes at some stage, few are using simulation in a structured and effective manner.
this may be caused by a lack of training and limitations of existing tools. however,
there are also several additional and more fundamental problems. first of all, simula-
tion models tend to oversimplify things. in particular the behavior of resources is often
modeled in a rather na ¨ıve manner. people do not work at constant speeds and need to
distribute their attention over multiple processes. this can have dramatic effects on the
performance of a process and, therefore, such aspects should not be “abstracted away”
[157, 158]. second, various artifacts readily available are not used as input for simu-
lation . modern organizations store events in logs and some may have accurate process
models stored in their wfm/bpm systems. also note that in many organizations, the
state of the information system accurately reﬂects the state of the business processes
supported by this system. nevertheless, such information (i.e., event logs and status
data) is rarely used for simulation or a lot of manual work is needed to feed this infor-
mation into the model. third, the focus of simulation is mainly on “design” whereas
managers would also like to use simulation for “operational decision making” , i.e.,
solving the concrete problem at hand rather than some abstract future problem. fortu-
nately, short-term simulation [157] can provide answers for questions related to “here
and now”. the key idea is to start all simulation runs from the current state and focus on
the analysis of the transient behavior. this way a “fast forward button” into the future
is provided [8, 157].
veriﬁcation and performance analysis heavily rely on the availability of high quality
models. when the models and reality have little in common, model-based analysis does
not make much sense. for example, some process model may be internally consistent
and satisfy all kinds of desirable properties. however, if the model describes a highly
idealized version of reality, it may be useless for governance and auditing purposes as
in reality all kinds of deviations may take place. similar comments hold for simula-
tion models. it may be that the model predicts a signiﬁcant improvement whereas in
reality this is not the case because the model is based on ﬂawed assumptions. all of
these problems stem from a lack of alignment between hand-made models and reality.
process mining, discussed next, aims to address these problems by establishing a direct
connection between the models and actual low-level event data about the process.
5.4 process mining
as information systems are becoming more and more intertwined with the operational
processes they support, multitudes of events are recorded by these systems. the goal of
process mining is to use such event data to extract process related information, e.g., to38 wil van der aalst
automatically discover a process model by observing events recorded by some system
or to check the conformance of a given model by comparing it with reality [8, 159]. this
provides new means to improve processes in a variety of application domains. there are
two main drivers for this new technology. on the one hand, more and more events are
being recorded thus providing detailed information about the history of processes. on
the other hand, vendors of business process management (bpm) and business intelli-
gence (bi) software have been promising miracles. although bpm and bi technologies
received lots of attention, they did not live up to the expectations raised by academics,
consultants, and software vendors. hence, despite the omnipresence of event data, most
organizations diagnose problems based on ﬁction rather than facts.
process mining is an emerging discipline providing comprehensive sets of tools to
provide fact-based insights and to support process improvements [8, 160]. this new
discipline builds on process model-driven approaches and data mining. however, pro-
cess mining is much more than an amalgamation of existing approaches. for example,
existing data mining techniques are too data-centric to provide a comprehensive un-
derstanding of the end-to-end processes in an organization. bi tools focus on simple
dashboards and reporting rather than clear-cut business process insights. bpm suites
heavily rely on experts modeling idealized to-be processes and do not help the stake-
holders to understand the as-is processes.
figure 24 shows the process mining framework described in [8]. the top of the
diagram shows an external “world” consisting of business processes, people, and or-
ganizations supported by some information system. the information system records
information about this “world” in such a way that events logs can be extracted. the
term provenance used in figure 24 emphasizes the systematic, reliable, and trustworthy
recording of events. the term provenance originates from scientiﬁc computing, where
it refers to the data that is needed to be able to reproduce an experiment [42, 161].
business process provenance aims to systematically collect the information needed to
reconstruct what has actually happened in a process or organization [162]. when or-
ganizations base their decisions on event data it is essential to make sure that these
describe history well. moreover, from an auditing point of view it is necessary to en-
sure that event logs cannot be tampered with. business process provenance refers to
the set of activities needed to ensure that history, as captured in event logs, “cannot be
rewritten or obscured” such that it can serve as a reliable basis for process improvement
and auditing.
as shown in figure 24, event data can be partitioned into “pre mortem” and“post
mortem” event logs. “post mortem” event data refer to information about cases that
have completed, i.e., these data can be used for process improvement and auditing,
but not for inﬂuencing the cases they refer to. “pre mortem” event data refer to cases
that have not yet completed. if a case is still running, i.e., the case is still “alive” (pre
mortem), then it may be possible that information in the event log about this case (i.e.,
current data) can be exploited to ensure the correct or efﬁcient handling of this case.
“post mortem” event data are most relevant for off-line process mining , e.g., dis-
covering the control-ﬂow of a process based on one year of event data. for online pro-
cess mining mixtures of “pre mortem” (current) and “post mortem” (historic) data are
needed. for example, historic information can be used to learn a predictive model. sub-business process management: a comprehensive survey 39
information system(s)
current 
data“world”people
machinesorganizations
business 
processes documents
historic 
data
resources/
organizationdata/rulescontrol-flowde jure models
resources/
organizationdata/rulescontrol-flowde facto modelsprovenanceexplore
predict
recommend
detect
check
compare
promote
discover
enhance
diagnosecartography navigation auditingevent logs
models“pre 
mortem”“post 
mortem”
fig. 24. overview of the process mining spectrum.
sequently, information about a running case is combined with the predictive model to
provide an estimate for the remaining ﬂow time of the case.
the process mining framework described in [8] also distinguishes between two
types of models: “de jure models” and“de facto models” .a de jure model is nor-
mative , i.e., it speciﬁes how things should be done or handled. for example, a process
model used to conﬁgure a bpm system is normative and forces people to work in a
particular way. a de facto model is descriptive and its goal is not to steer or control real-
ity. instead, de facto models aim to capture reality. as shown in figure 24 both de jure
and de facto models may cover multiple perspectives including the control-ﬂow per-
spective (“how?”), the organizational perspective (“who?”), and the case perspective
(“what?”). the control-ﬂow perspective describes the ordering of activities. the orga-
nizational perspective describes resources (worker, machines, customers, services, etc.)40 wil van der aalst
and organizational entities (roles, departments, positions, etc.). the case perspective
describes data and rules.
in the middle of figure 24 ten process mining related activities are depicted. these
ten activities are grouped into three categories: cartography ,auditing , and navigation .
the activities in the cartography category aim at making “process maps”. the activities
in the auditing category all involve a de jure model that is confronted with reality in the
form of event data or a de facto model. the activities in the navigation category aim at
improving a process while it is running.
activity discover in figure 24 responds to use case discm (discover model from
event data) described earlier. lion’s share of process mining research has been devoted
to this activity [8, 163]. a discovery technique takes an event log and produces a model
without using any additional a-priori information. an example is the -algorithm [44]
that takes an event log and produces a petri net explaining the behavior recorded in
the log. if the event log contains information about resources, one can also discover
resource-related models, e.g., a social network showing how people work together in
an organization.
since the mid-nineties several groups have been working on techniques for process
discovery [160, 44, 164–169]. in [170] an overview is given of the early work in this
domain. the idea to apply process mining in the context of workﬂow management sys-
tems was introduced in [164]. in parallel, datta [166] looked at the discovery of business
process models. cook et al. investigated similar issues in the context of software engi-
neering processes [165]. herbst [171] was one of the ﬁrst to tackle more complicated
processes, e.g., processes containing duplicate tasks.
most of the classical approaches have problems dealing with concurrency. the -
algorithm [44] is an example of a simple technique that takes concurrency as a starting
point. however, this simple algorithm has problems dealing with complicated routing
constructs and noise (like most of the other approaches described in literature). process
discovery is very challenging because techniques need to balance four criteria: ﬁtness
(the discovered model should allow for the behavior seen in the event log), precision
(the discovered model should not allow for behavior completely unrelated to what was
seen in the event log), generalization (the discovered model should generalize the ex-
ample behavior seen in the event log), and simplicity (the discovered model should be
as simple as possible). this makes process discovery a challenging and highly relevant
research topic.
activity enhance in figure 24 corresponds to use cases repm (repair model) and
extm (extend model). when existing process models (either discovered or hand-made)
can be related to events logs, it is possible to enhance these models. the connection can
be used to repair models [53] or to extend them [172–175].
activity diagnose in figure 24 does not directly use event logs and focuses on clas-
sical model-based process analysis as discussed in section 5.3.
activity detect compares de jure models with current “pre mortem” data (events of
running process instances) with the goal to detect deviations at run-time. the moment
a predeﬁned rule is violated, an alert is generated [176–178].
activity check in figure 24 refers to use case confed (check conformance using
event data). historic “post mortem” data can be cross-checked with de jure models. thebusiness process management: a comprehensive survey 41
goal of this activity is to pinpoint deviations and quantify the level of compliance. var-
ious conformance checking techniques have been proposed in literature [179–188]. for
example, in [187] the ﬁtness of a model is computed by comparing the number of miss-
ing and remaining tokens with the number of consumed and produced tokens during
replay. the more sophisticated technique described in [179–181] creates as so-called
alignment which relates a trace in the event log to an execution sequence of the model
that is as similar as possible. ideally, the alignment consists of steps where log and
model agree on the activity to be executed. steps where just the model “makes a move”
or just the log “makes a move” have a predeﬁned penalty. this way the computation of
ﬁtness can be turned into an optimization problem: for each trace in the event log an
alignment with the lowest costs is selected. the resulting alignments can be used for all
kinds of analysis since any trace in the event log is related to an execution sequence of
the model. for example, timestamps in the model can be used to compute bottlenecks
and extend the model with performance information (see activity enhance in figure 24).
activity compare highlights differences and commonalities between a de jure model
and a de facto model. traditional equivalence notions such as trace equivalence, bisim-
ilarity, and branching bisimilarity [132, 133] can only be used to determine equivalence
using a predeﬁned equivalence notion, e.g., these techniques cannot be used to distin-
guish between very similar and highly dissimilar processes. other notions such a graph-
edit distance tend to focus on the syntax rather than the behavior of models. therefore,
recent bpm research explored various alternative similarity notions [189, 56, 190–193]
also note the greatest common divisor (gcd) and least common multiple (lcm)
notions deﬁned for process models in [194]. the gcd captures the common parts of
two or more models. the lcm embeds all input models. we refer to [189] for a survey
and empirical evaluation of some similarity notions.
activity promote takes (parts of) de facto models and converts these into (parts of)
de jure models, i.e., models used to control or support processes are improved based
on models learned from event data. by promoting proven “best practices” to de jure
models, existing processes can be improved.
the activities in the cartography and auditing categories in figure 24 can be viewed
as “backward-looking”. the last three activities forming the navigation category are
“forward-looking” and are sometimes referred to as operational support [8]. for exam-
ple, process mining techniques can be used to make predictions about the future of a
particular case and guide the user in selecting suitable actions. when comparing this
with a car navigation system from tomtom or garmin, this corresponds to functional-
ities such predicting the arrival time and guiding the driver using spoken instructions.
activity explore in figure 24 visualizes running cases and compares these cases
with similar cases that were handled earlier. the combination of event data and models
can be used to explore business processes at run-time and, if needed, trigger appropriate
actions.
by combining information about running cases with models (discovered or hand-
made), it is possible to make predictions about the future, e.g., predicting the remaining
ﬂow time or the probability of success. figure 24 shows that activity predict uses current
data and models (often learned over historic data). various techniques have been pro-42 wil van der aalst
posed in bpm literature [195–197]. note that already a decade ago staffware provided
a so-called “prediction engine” using simulation [198].
activity recommend in figure 24 aims to provide functionality similar to the guid-
ance given by car navigation systems. the information used for predicting the future
can also be used to recommend suitable actions (e.g. to minimize costs or time) [176,
199]. given a set of possible next steps, the most promising step is recommended. for
each possible step, simply assume that the step is made and predict the resulting perfor-
mance (e.g., remaining ﬂow time). the resulting predictions can be compared and used
to rank the possible next steps.
the ten activities in figure 24 illustrate that process mining extends far beyond
process discovery. the increasing availability and growing volume of event data suggest
that the importance of process mining will continue to grow in the coming years.
5.5 process flexibility
effective business processes must be able to accommodate changes in the environment
in which they operate, e.g., new laws, changes in business strategy, or emerging tech-
nologies. the ability to encompass such changes is termed process ﬂexibility and is def-
initely a key concern of bpm as is reﬂected by various publications [200–207]. modern
processes and information systems need to be able to deal with both foreseen and un-
foreseen changes. this quality of a process – termed ﬂexibility – reﬂects its ability to
deal with such changes, by varying or adapting those parts of the business process that
are affected by them, whilst retaining the essential format of those parts that are not
impacted by the variations. indeed, ﬂexibility is as much about what should stay the
same in a process as what should be allowed to change [208, 209].
in [209] a taxonomy of process ﬂexibility is presented. the taxonomy identiﬁes
four main ﬂexibility types: ﬂexibility by deﬁnition , ﬂexibility by deviation , ﬂexibility
byunderspeciﬁcation , and ﬂexibility by change (cf. figure 25).
flexibility by deﬁnition is the ability to incorporate alternative execution paths within
a process deﬁnition at design time such that selection of the most appropriate execution
path can be made at runtime for each process instance. for example, an xor-split
deﬁned at design time adds the ability to select one or more activities for subsequent
execution from a set of available activities. parallelism deﬁned at design time leaves
the actual ordering of activities open and thus provides more ﬂexibility than sequential
routing. all wfm/bpm systems support this type of ﬂexibility. however, declarative
languages make it easier to defer choices to runtime.
the classical workﬂow patterns mentioned earlier [9, 91] can be viewed as a classiﬁ-
cation of “ﬂexibility by deﬁnition” mechanisms for procedural languages. for example,
the “deferred choice” pattern [9] leaves the resolution of a choice to the environment
at runtime. note that a so-called “ﬂower place” in a petri net, i.e., a place with many
transitions that have this place as only input and output place, provides a lot of ﬂexi-
bility. also declarative languages like declare [70, 71] can be used to provide a lot of
ﬂexibility at runtime. (as discussed in section 5.1, declarative models use an “outside-
to-inside” approach: anything is possible unless explicitly forbidden.)
flexibility by deviation is the ability for a process instance to deviate at runtime
from the execution path prescribed by the original process without altering the processbusiness process management: a comprehensive survey 43
flexibility by 
definitionprocess 
definition
process 
instancedegree of impact
design time runtime
time at which flexibility is addedflexibility by 
deviationflexibility by 
underspecificationflexibility by change
fig. 25. taxonomy of process ﬂexibility identifying four main ﬂexibility types: ﬂexibility by
deﬁnition , ﬂexibility by deviation , ﬂexibility by underspeciﬁcation , and ﬂexibility by change .
deﬁnition itself. the deviation can only encompass changes to the execution sequence
for a speciﬁc process instance, and does not require modiﬁcations of the process deﬁni-
tion. typical deviations are undo ,redo, and skip.
the bpm jone system of perceptive/lexmark (based on the flower system devel-
oped by pallas athena) is a system that provides various mechanisms for deviations at
runtime. the case handling paradigm [200] supported by bpm jone allows the user to
skip or redo activities (if not explicitly forbidden and assuming the user is authorized to
do so). moreover, data can be entered earlier or later because the state is continuously
recomputed based on the available data.
flexibility by underspeciﬁcation is the ability to execute an incomplete process
speciﬁcation, i.e., a model that does not contain sufﬁcient information to allow it to be
executed to completion. an incomplete process speciﬁcation contains one or more so-
called placeholders . these placeholders are nodes which are marked as underspeciﬁed
(i.e., “holes” in the speciﬁcation) and whose content is speciﬁed during the execution
of the process. the manner in which these placeholders are ultimately enacted is deter-
mined by applying one of the following approaches: late binding (the implementation
of a placeholder is selected from a set of available process fragments) or late modeling
(a new process fragment is constructed in order to complete a given placeholder). for
late binding, a process fragment has to be selected from an existing set of fully prede-
ﬁned process fragments. this approach is limited to selection, and does not allow a new
process fragment to be constructed. for late modeling, a new process fragment can be
developed from scratch or composed from existing process fragments.
in the context of yawl [150], the so-called worklets approach [201] has been de-
veloped which allows for late binding and late modeling. late binding is supported
through so-called “ripple-down rules”, i.e., based on context information the user can
be guided to selecting a suitable fragment. in [210] the term “pockets of ﬂexibility” was44 wil van der aalst
introduced to refer to the placeholder for change. in [211] an explicit notion of “vague-
ness” is introduced in the context of process modeling. the authors propose model
elements such as arc conditions and task ordering to be deliberately omitted from mod-
els in the early stages of modeling. moreover, parts of the process model can be tagged
as “incomplete” or “unspeciﬁed”.
flexibility by change is the ability to modify a process deﬁnition at run-time such
that one or all of the currently executing process instances are migrated to a new process
deﬁnition. changes may be introduced both at the process instance and the process type
levels. a momentary change (also known as change at the instance level) is a change
affecting the execution of one or more selected process instances. an example of a
momentary change is the postponement of registering a patient that has arrived to the
hospital emergency center: treatment is started immediately rather than spending time
on formalities ﬁrst. such a momentary change performed on a given process instance
does not affect any future instances. an evolutionary change (also known as change at
the type level) is a change caused by modiﬁcation of the process deﬁnition, potentially
affecting all new process instances. a typical example of the evolutionary change is
the redesign of a business process to improve the overall performance characteristics
by allowing for more concurrency. running process instances that are impacted by an
evolutionary or a momentary change need to be handled properly. if a running process
instance is transferred to the new process, then there may not be a corresponding state
(called the “dynamic change bug” in [203]).
flexibility by change is very challenging and has been investigated by many re-
searchers. the ability to adapt the structure of running workﬂow was investigated in
the context of the wasa system [207]. in the context of the adept system, ﬂexibil-
ity by change has been examined in detail [205, 206]. this work shows that changes
can introduce all kinds of anomalies (missing data, deadlocks, double work, etc.). for
example, it is difﬁcult to handle both momentary changes and evolutionary changes at
the same time, e.g., an ad-hoc change made for a speciﬁc instance may be affected by
a later change at the type level. the declarative workﬂow system declare has been ex-
tended to support both evolutionary and momentary changes [204] thus illustrating that
a declarative style of modeled simpliﬁes the realization of all kinds of ﬂexility support.
see also [208, 212, 40, 213–215, 210] for other classiﬁcations of ﬂexibility.
5.6 process reuse
bpm initiatives within larger organizations resulted in collections of hundreds or even
thousands of process models. such large collections of process models provide new
challenges, sometimes referred to as “bpm-in-the-large” [216]. a recent survey [217]
shows that since 2005 there has been a growing research interest in the management
of large collections of business process models. the survey also refers to examples of
large collections, e.g., suncorp’s process model repository containing more than 6,000
insurance-related processes. organizations having hundreds or thousands of process
models often have problems maintaining these models. some models may be outdated,
parts of models may have been duplicated, and due to mergers there may be different
models for similar or even identical processes. reuse is limited, i.e., even though many
processes share activities, subprocesses, and organizational entities, processes are oftenbusiness process management: a comprehensive survey 45
modeled from scratch. bpm research aims to support the reuse of process modeling
efforts.
process model repositories allow for the storage and retrieval of process models.
most business process modeling tools, e.g., tools like aris [218, 219], provide such
facilities. the well-known sap reference model consisting of over 600 non-trivial pro-
cess models (expressed in terms of epcs) has been distributed with the aris toolset.
a more recent initiative is apromore [220, 221], an advanced process model repos-
itory providing a rich set of features for the analysis, management and usage of large
sets of process models.
m
mmmm
mm
mmm
m
mm
mmergesearch
cluster
unify/
refactorprocess model 
repository
convertquery
m
mcriterion
fig. 26. overview of the main activities related to the management of large process model col-
lections.
figure 26 shows various activities related to the management of large collections of
business process models stored in some repository.
activity search in figure 26 refers to use case selm (select model from collec-
tion). given a query, a set of models is returned. the returned models are often ranked
based on some metric (e.g., similarity or popularity). the query may refer to syntax
(i.e., structure and labels) or behavior . example queries referring to only the syntax are
“find all process models that contain both activity x and y”, “find all process models
containing activities executed by people having role r”, and “find all process mod-
els containing activities accessing data element d”. an example of a query that also
refers to behavior is “find all process models where activity x is always followed by
y”. sometimes behavior can be derived from the syntax, e.g., for free-choice nets [116,
130]. queries referring to behavior typically use some temporal logic, e.g., ltl with
standard temporal operators such as always ( ), eventually ( ), until ( t), weak until
(w), and next time ( ) [72, 73]. such queries can be formulated graphically using a
language like declare [70, 71]. another query language is the business process model
notation query (bpmn-q) language [222]. bpmn-q can be used to deﬁne patterns
using an extension of the bpmn syntax. both declare and bpmn-q can also be used
for compliance checking.46 wil van der aalst
amodel similarity search [56, 189, 191, 190] is a particular query looking for the
model most similar to a given model. for model similarity searches both syntax and be-
havior can be used. for example, given one model one may want to ﬁnd another model
that has the smallest edit distance (i.e., the number of atomic edit operation to convert
one model into another model). however, two behavioral equivalent models may have
many different syntactical differences. therefore, various approaches consider (an ab-
straction of) behavior. since it is often intractable to compare state spaces or execution
sequences, these approaches use abstractions of models such as direct succession [8] or
eventual succession [189, 223].
queries can refer to multiple perspectives. however, current research seems to focus
on control-ﬂow related queries.
activity merge in figure 26 corresponds to use cases merm (merge models) and
mercm (merge models into conﬁgurable model). a set of models is merged into a sin-
gle model that captures (most of) the behavior of the original models. for example, in
[224] models of ten dutch municipalities are merged into conﬁgurable process models
[47, 146, 46]. different techniques for process model merging have been proposed in
literature [225, 145, 226, 227]. when merging process models it is interesting to ana-
lyze commonalities and differences. in the context of inheritance of dynamic behavior,
notions such as the greatest common divisor (gcd) and least common multiple
(lcm) of process model variants have been deﬁned [194]. when merging models it
is often not sufﬁcient to just consider the syntax of the model. also behavioral issues
need to be considered. for example, a sequential process may be embedded in a more
concurrent model.
in [227], three requirements are listed for model merging. first of all, the behavior
of the merged model should subsume the behaviors of all input models. any execu-
tion sequence possible in one of the original models should be possible according to
the merged model (possibly after conﬁguration). second, it should be possible to trace
back each element in the merged model. for example, for each activity in the merged
model it should be indicated from which of the input models it originated. third, given
the merged model it should be possible to reconstruct each of the input models, i.e.,
each of the input models should correspond to a conﬁguration of the resulting merged
model. for example, in figure 9 the two input models can be reconstructed from the
conﬁgurable model by selecting appropriate conﬁgurations.
the approaches described in [225, 145, 226, 227, 224] produce conﬁgurable process
models [47, 146, 46]. in [228, 229] an approach is presented that does not produce a con-
ﬁgurable model and does not aim to address the three requirements listed in [227]. this
approach produces a model that has the smallest edit distance to all original models,
i.e., modiﬁcation rather than conﬁguration is used to create process model variants.
activity cluster in figure 26 aims to identify a set of related process models. for
example, models may be clustered in groups based on similarity search [189]. clusters
of related models may be used as input for merging, uniﬁcation, or refactoring.
activity unify/refactor in figure 26 takes a set of models as input and aims to im-
prove these models by aligning them, removing redundancies, and applying modeling
conventions consistently. note that large collections of process models often have over-
lapping process fragments without explicitly reusing parts. shared subprocesses may bebusiness process management: a comprehensive survey 47
modeled differently, models may use different conventions, and there may be different
versions of the same processes. model similarity search can be used to identify possible
redundancies before adding a new model.
activity convert in figure 26 refers to the various mappings from one notation to
another notation. as described in use case refm (reﬁne model) a conceptual model may
be converted into an executable model. it may also be converted into a formal model
that allows for analysis. often a repository contains models using different formats
while referring to the same process. it is far from trivial to keep all of these models
consistent, e.g., changes in the conceptual model should be reﬂected in the executable
model.
a general problem effecting all activities in figure 26, is the use for informal text.
the same activity may be labeled “approve claim” in one process and “evaluate insur-
ance claim” in another process. as a result the correspondence between both activities
may be missed and redundancies and inconsistencies remain unnoticed. to determine
the similarity between activity names in different models one can use na ¨ıve approaches
such as the string edit distance [230] or linguistic similarity (e.g., similarity based on
wordnet [231]). however, it is better to use a common ontology. semantic technolo-
gies [232] aim to address obvious problems related to string edit distance and linguistic
similarity. however, in practice, few process model collections use a common ontol-
ogy. therefore, in most cases, semantical annotations still need to be added to process
models before being able to use semantic technologies.
5.7 evolution of key concerns in bpm conference proceedings
as for the use cases, the papers in [36], [26], [27], [28], [29], [30], [31], [32], [33], and
[34] were tagged with one, or sometimes more, key concerns [54]. a total of 342 tags
were assigned to the 289 papers (1.18 tag per paper on average). the tags were used to
determine the relative frequencies listed in table 2. for example, for bpm 2010 four
papers were tagged with key concern process reuse . the total number of tags for bpm
2010 is 25. hence, the relative frequency is 4=25 = 0:16. the bottom row gives the
average relative frequency of each concern over all 10 years.
figure 27 shows the average relative frequency of each concern in a graphical man-
ner. as expected, the ﬁrst three concerns are most frequent. the fourth and sixth con-
cern (process mining and process reuse) are gaining importance, whereas the relative
frequency of the process ﬂexibility concern seems to decrease over time (see figure 28).
it should be noted that the tagging of the 289 papers with use cases and key con-
cerns is highly subjective. it is unlikely that two bpm experts would use precisely the
same tags for all papers. for example, to tag a paper one needs to decide what the
key contribution of the paper is. many papers are rather broad and difﬁcult to clas-
sify. for example, papers on topics such as “social bpm”, “bpm maturity”, “bpm in
healthcare”, and “bpm security” cannot be tagged easily, because these topics seem
orthogonal to the uses cases and key concerns. this explains why broad use cases like
design model (decm) and enact model (enm) score relatively high.
the key concerns were identiﬁed before tagging the papers [54]. in hindsight there
seem to be at least three potentially missing concerns: process integration ,patterns ,48 wil van der aalst
0.0000.0500.1000.1500.2000.2500.300
fig. 27. average relative importance of concerns (based on table 2).
0.0000.0500.1000.1500.2000.2500.3000.3500.4000.450
2000 2003 2004 2005 2006 2007 2008 2009 2010 2011process modeling languages
process enactment
infrastructures
process model analysis
process mining
process flexibility
process reuse
fig. 28. the importance of each concern plotted over time thus showing changes in the relative
attention for each concern over time (based on table 2).business process management: a comprehensive survey 49
table 2. relative importance of concerns over the years
process
modeling
languagesprocess
enactment
infrastruc-
turesprocess
model
analysisprocess
miningprocess
ﬂexibilityprocess
reuse
year
2000 0.355 0.161 0.290 0.000 0.161 0.032
2003 0.325 0.200 0.250 0.050 0.075 0.100
2004 0.286 0.238 0.238 0.143 0.048 0.048
2005 0.288 0.231 0.212 0.058 0.096 0.115
2006 0.154 0.308 0.288 0.096 0.077 0.077
2007 0.387 0.097 0.194 0.194 0.065 0.065
2008 0.324 0.108 0.297 0.135 0.081 0.054
2009 0.148 0.111 0.370 0.222 0.037 0.111
2010 0.240 0.240 0.200 0.160 0.000 0.160
2011 0.143 0.171 0.200 0.314 0.000 0.171
average 0.265 0.187 0.254 0.137 0.064 0.093
andcollaboration . many papers are concerned with web services and other technolo-
gies (e.g., saas, paas, clouds, and grids) to integrate processes. these are now tagged
asprocess enactment infrastructures (second concern). in the bpm proceedings there
are various papers proposing new patterns collections or evaluating existing languages
using the well-known workﬂow patterns [9, 24]. these are now tagged as process mod-
eling languages (ﬁrst concern). another recurring concern seems to collaboration, e.g.,
collaborative modeling or system development.
given a process, different perspectives can be considered: the control-ﬂow perspec-
tive (“what activities need to be executed and how are they ordered?”), the organi-
zational perspective (“what are the organizational roles, which activities can be exe-
cuted by a particular resource, and how is work distributed?”), the case/data perspec-
tive (“which characteristics of a case inﬂuence a particular decision?”), and the time
perspective (“what are the bottlenecks in my process?”), etc. the use cases and key
concerns are neutral/orthogonal with respect to these perspectives. although most pa-
pers focus on the control-ﬂow perspective, there are several papers that focus on the
organizational perspective, e.g., papers dealing with optimal resource allocations or
role-based access control. it would have been useful to add additional tags to papers
based on the perspectives considered.
despite these limitations, tables 1 and 2 provide a nice overview of developments
in the bpm discipline. comparing papers published in the early bpm proceedings with
papers published in more recent bpm proceedings clearly shows that the bpm disci-
pline progressed at a remarkable speed. the understanding of process modeling lan-
guages improved and analysis techniques have become much more powerful.50 wil van der aalst
6 outlook
over the last decade there has been a growing interest in business process management
(bpm). practitioners have been using bpm technologies to model, improve, and enact
business processes. today, a plethora of bpm systems and tools is available. academics
have been developing new techniques and approaches to support more advanced forms
of bpm. this survey describes the state-of-the-art in bpm. the bpm discipline has
been structured in various ways and developments have been put in their historic con-
text. the core of the survey is based on a set of twenty bpm use cases and six bpm key
concerns. the use cases show “how, where, and when” bpm techniques can be used.
the six key concerns highlight important research areas within the bpm discipline. ta-
ble 3 relates the bpm use cases and bpm key concerns. as shown, the six key concerns
cover the twenty use cases well.
the bpm discipline has developed at an amazing speed. however, a careful analysis
of bpm literature also reveals some weaknesses.
many papers introduce a new modeling language. the need for such new languages
is often unclear, and, in many cases, the proposed language is never used again after
publication. a related problem is that many papers spend more time on presenting the
context of the problem rather than the actual analysis and solution. for example, there
are papers proposing a new veriﬁcation technique for a language introduced in the same
paper. consequently, the results cannot be used or compared easily.
many papers cannot be linked to one of the twenty use cases in a straightforward
manner. authors seem to focus on originality rather than relevance and show little con-
cern for real-life use cases. one could argue that some of these papers propose solutions
for rather exotic or even non-existing problems.
our use-case based analysis of existing literature shows that various use cases are
neglected by both bpm researchers and bpm software. for example, use cases re-
lated to improving the performance of processes seem to be neglected. it is remark-
able that there are hardly any tools that provide suggestions for redesigning processes.
simulation tools just provide “what-if” analysis without suggesting better alternatives.
moreover, business “intelligence” tools do not use event data to suggest better process
designs. the active classiﬁcation of tools and publications using the use cases may sim-
ulate academics and practitioners to focus on process improvement scenarios.
many papers describe implementation efforts; however, frequently the software is
not available for the reader. moreover, regrettably, many of the research prototypes
seem to “disappear” after publication. as a result, research efforts get lost.
many papers include case studies, e.g., to test a new technique or system, which is
good. unfortunately, most case studies seem rather artiﬁcial. often the core contribution
of the paper is not really evaluated or the case study is deliberately kept vague.
to address the weaknesses just mentioned, authors and tool developers are encour-
aged to clearly state which of the bpm use cases their results (algorithms, procedures,
tools, etc.) aim to support. the twenty use cases presented in this paper can serve as the
starting point for a commonly agreed-upon taxonomy of bpm use cases. the current
use cases could be subdivided in more speciﬁc ones. such a structuring would hope-
fully result in collections of benchmark problems, comparable to the datasets used inbusiness process management: a comprehensive survey 51
table 3. relation between the twenty use cases and six key concerns ( += related and ++ =
strongly related).
use caseprocess
modeling
languagesprocess
enactment
infrastruc-
turesprocess
model
analysisprocess
miningprocess
ﬂexibilityprocess
reuse
design model
(desm)++ + +
discover model from
event data
(discm)++
select model from col-
lection
(selm)++
merge models
(merm)++
compose model
(compm)+
design conﬁgurable
model
(descm)+ ++
merge models into con-
ﬁgurable model
(mercm)++
conﬁgure conﬁgurable
model
(concm)++
reﬁne model
(refm)+ + +
enact model
(enm)+ ++ +
log event data
(loged)+ ++
monitor
(mon)+ +
adapt while running
(adawr)+ ++
analyze performance
based on model
(perfm)++
verify model
(verm)++ +
check conformance us-
ing event data
(confed)++
analyze performance
using event data
(perfed)++
repair model
(repm)++
extend model
(extm)++
improve model
(impm)++ +52 wil van der aalst
data mining and model checking competitions. practitioners and academics are encour-
aged to share open-source software and data sets (collections of process models, event
logs, etc.). currently, many prototypes are developed from scratch and “fade onto obliv-
ion” when the corresponding research project ends. moreover, it is often impossible to
compare different approaches in a fair manner as experiments are incomparable or can-
not be reproduced. given the importance of bpm, these weaknesses need to be tackled
urgently. this survey is a modest attempt to guide bpm research towards the real key
challenges in our ﬁeld.
references
1. w.m.p. van der aalst. business process management demystiﬁed: a tutorial on models,
systems and standards for workﬂow management. in j. desel, w. reisig, and g. rozen-
berg, editors, lectures on concurrency and petri nets , volume 3098 of lecture notes in
computer science , pages 1–65. springer-verlag, berlin, 2004.
2. m. weske. business process management: concepts, languages, architectures . springer-
verlag, berlin, 2007.
3. w.m.p. van der aalst, a.h.m. ter hofstede, and m. weske. business process management:
a survey. in w.m.p. van der aalst, a.h.m. ter hofstede, and m. weske, editors, interna-
tional conference on business process management (bpm 2003) , volume 2678 of lecture
notes in computer science , pages 1–12. springer-verlag, berlin, 2003.
4. w.m.p. van der aalst and k.m. van hee. workﬂow management: models, methods, and
systems . mit press, cambridge, ma, 2004.
5. s. jablonski and c. bussler. workﬂow management: modeling concepts, architecture, and
implementation . international thomson computer press, london, uk, 1996.
6. f. leymann and d. roller. production workﬂow: concepts and techniques . prentice-hall
ptr, upper saddle river, new jersey, usa, 1999.
7. m. dumas, w.m.p. van der aalst, and a.h.m. ter hofstede. process-aware information
systems: bridging people and software through process technology . wiley & sons, 2005.
8. w.m.p. van der aalst. process mining: discovery, conformance and enhancement of busi-
ness processes . springer-verlag, berlin, 2011.
9. w.m.p. van der aalst, a.h.m. ter hofstede, b. kiepuszewski, and a.p. barros. workﬂow
patterns. distributed and parallel databases , 14(1):5–51, 2003.
10. m. zur muehlen and j. recker. how much language is enough? theoretical and practical
use of the business process modeling notation. in z. bellahsene and m. l ´eonard, editors,
proceedings of the 20th international conference on advanced information systems engi-
neering (caise’08) , volume 5074 of lecture notes in computer science , pages 465–479.
springer-verlag, berlin, 2008.
11. e.f. codd. a relational model for large shared data banks. communications of the acm ,
13(6):377–387, june 1970.
12. p.p. chen. the entity-relationship model: towards a uniﬁed view of data. acm transac-
tions on database systems , 1:9–36, jan 1976.
13. w.m.p. van der aalst. the application of petri nets to workﬂow management. the journal
of circuits, systems and computers , 8(1):21–66, 1998.
14. c.a. ellis. information control nets: a mathematical model of ofﬁce information flow.
inproceedings of the conference on simulation, measurement and modeling of computer
systems , pages 225–240, boulder, colorado, 1979. acm press.business process management: a comprehensive survey 53
15. c.a. ellis and g. nutt. workﬂow: the process spectrum. in a. sheth, editor, proceedings
of the nsf workshop on workﬂow and process automation in information systems , pages
140–145, athens, georgia, may 1996.
16. c.a. ellis and g.j. nutt. ofﬁce information systems and computer science. acm com-
puting surveys , 12(1):27–60, 1980.
17. a.w. holt. coordination technology and petri nets. in g. rozenberg, editor, advances
in petri nets 1985 , volume 222 of lecture notes in computer science , pages 278–296.
springer-verlag, berlin, 1985.
18. a.w. holt, h. saint, r. shapiro, and s. warshall. final report on the information systems
theory project. technical report radc-tr-68-305, grifﬁss air force base, new york,
1968.
19. m. zur muehlen. workﬂow-based process controlling: foundation, design and applica-
tion of workﬂow-driven process information systems . logos, berlin, 2004.
20. m.d. zisman. representation, speciﬁcation and automation of ofﬁce procedures . phd
thesis, university of pennsylvania, warton school of business, 1977.
21. m.d. zisman. ofﬁce automation: revolution or evolution. sloan management review ,
13(3):1–16, 1978.
22. m.d. zisman. use of production systems for modeling asynchronous concurrent pro-
cesses. pattern-directed inference systems , pages 53–68, 1978.
23. c.a. ellis and g.j. nutt. computer science and ofﬁce information systems . xerox, palo
alto research center, 1979.
24. n. russell, w.m.p.van der aalst, a.h.m. ter hofstede, and d. edmond. workﬂow re-
source patterns: identiﬁcation, representation and tool support. in o. pastor and j. falcao
e cunha, editors, proceedings of the 17th conference on advanced information systems
engineering (caise’05) , volume 3520 of lecture notes in computer science , pages 216–
232. springer-verlag, berlin, 2005.
25. n. russell, a.h.m. ter hofstede, d. edmond, and w.m.p. van der aalst. workﬂow data
patterns: identiﬁcation, representation and tool support. in l. delcambre, c. kop, h.c.
mayr, j. mylopoulos, and o. pastor, editors, 24nd international conference on conceptual
modeling (er 2005) , volume 3716 of lecture notes in computer science , pages 353–368.
springer-verlag, berlin, 2005.
26. w.m.p. van der aalst, a.h.m. ter hofstede, and m. weske, editors. international con-
ference on business process management (bpm 2003) , volume 2678 of lecture notes in
computer science . springer-verlag, berlin, 2003.
27. j. desel, b. pernici, and m. weske, editors. international conference on business process
management (bpm 2004) , volume 3080 of lecture notes in computer science . springer-
verlag, berlin, 2004.
28. w.m.p. van der aalst, b. benatallah, f. casati, and f. curbera, editors. international con-
ference on business process management (bpm 2005) , volume 3649 of lecture notes in
computer science . springer-verlag, berlin, 2005.
29. s. dustdar, j.l. fiadeiro, and a. sheth, editors. international conference on business
process management (bpm 2006) , volume 4102 of lecture notes in computer science .
springer-verlag, berlin, 2006.
30. g. alonso, p. dadam, and m. rosemann, editors. international conference on business
process management (bpm 2007) , volume 4714 of lecture notes in computer science .
springer-verlag, berlin, 2007.
31. m. dumas, m. reichert, and m.c. shan, editors. international conference on business
process management (bpm 2008) , volume 5240 of lecture notes in computer science .
springer-verlag, berlin, 2008.54 wil van der aalst
32. u. dayal, j. eder, j. koehler, and h. reijers, editors. international conference on business
process management (bpm 2009) , volume 5701 of lecture notes in computer science .
springer-verlag, berlin, 2009.
33. r. hull, j. mendling, and s. tai, editors. international conference on business process
management (bpm 2010) , volume 6336 of lecture notes in computer science . springer-
verlag, berlin, 2010.
34. s. rinderle, f. toumani, and k. wolf, editors. international conference on business
process management (bpm 2011) , volume 6896 of lecture notes in computer science .
springer-verlag, berlin, 2011.
35. a. barros, a. gal, and e. kindler, editors. international conference on business process
management (bpm 2012) , volume 7481 of lecture notes in computer science . springer-
verlag, berlin, 2012.
36. w.m.p. van der aalst, j. desel, and a. oberweis, editors. business process management:
models, techniques, and empirical studies , volume 1806 of lecture notes in computer
science . springer-verlag, berlin, 2000.
37. h. smith and p. fingar. business process management: the third wave . meghan kiffer
press, 2006.
38. a.h.m. ter hofstede, w.m.p. van der aalst, m. adams, and n. russell. modern business
process automation: yawl and its support environment . springer-verlag, berlin, 2010.
39. m. reichert and b. weber. enabling flexibility in process-aware information systems:
challenges, methods, technologies . springer-verlag, berlin, 2012.
40. d. georgakopoulos, m. hornick, and a. sheth. an overview of workﬂow management:
from process modeling to workﬂow automation infrastructure. distributed and parallel
databases , 3:119–153, 1995.
41. r. medina-mora, t. winograd, r. flores, and f. floris. the action workﬂow approach to
workﬂow management technology. in m. mantel and r. baecker, editors, proceedings of
the 1992 acm conference on computer-supported cooperative work (cscw’92) , pages
281–288. acm, new york, 1992.
42. b. ludaescher, i. altintas, c. berkley, d. higgins, e. jaeger-frank, m. jones, e. lee, j. tao,
and y . zhao. scientiﬁc workﬂow management and the kepler system. concurrency and
computation: practice and experience , 18(10):1039–1065, 2006.
43. j. manyika, m. chui, b. brown, j. bughin, r. dobbs, c. roxburgh, and a. byers. big
data: the next frontier for innovation, competition, and productivity. mckinsey global
institute, 2011.
44. w.m.p. van der aalst, a.j.m.m. weijters, and l. maruster. workﬂow mining: discovering
process models from event logs. ieee transactions on knowledge and data engineering ,
16(9):1128–1142, 2004.
45. f. gottschalk, w.m.p. van der aalst, and h.m. jansen-vullers. conﬁgurable process mod-
els: a foundational approach. in j. becker and p. delfmann, editors, reference modeling:
efﬁcient information systems design through reuse of information models , pages 59–78.
physica-verlag, springer, heidelberg, germany, 2007.
46. m. rosemann and w.m.p. van der aalst. a conﬁgurable reference modelling language.
information systems , 32(1):1–23, 2007.
47. f. gottschalk, w.m.p. van der aalst, m.h jansen-vullers, and m. la rosa. conﬁgurable
workﬂow models. international journal of cooperative information systems , 17(2):177–
221, 2008.
48. t. curran and g. keller. sap r/3 business blueprint: understanding the business process
reference model . upper saddle river, 1997.
49. j. becker, p. delfmann, and r. knackstedt. adaptive reference modeling: integrating con-
ﬁgurative and generic adaptation techniques for information models. in j. becker andbusiness process management: a comprehensive survey 55
p. delfmann, editors, reference modeling: efﬁcient information systems design through
reuse of information models , pages 27–58. physica-verlag, springer, heidelberg, ger-
many, 2007.
50. p. fettke and p. loos. classiﬁcation of reference models - a methodology and its appli-
cation. information systems and e-business management , 1(1):35–53, 2003.
51. w.m.p. van der aalst, n. lohmann, and m. la rosa. ensuring correctness during process
conﬁguration via partner synthesis. information systems , 37(6):574–592, 2012.
52. w.m.p. van der aalst, k.m. van hee, a.h.m. ter hofstede, n. sidorova, h.m.w. verbeek,
m. v oorhoeve, and m.t. wynn. soundness of workﬂow nets: classiﬁcation, decidability,
and analysis. formal aspects of computing , 23(3):333–363, 2011.
53. d. fahland and w.m.p. van der aalst. repairing process models to reﬂect reality. in
a. barros, a. gal, and e. kindler, editors, international conference on business process
management (bpm 2012) , volume 7481 of lecture notes in computer science , pages 229–
245. springer-verlag, berlin, 2012.
54. w.m.p. van der aalst. a decade of business process management conferences: personal
reﬂections on a developing discipline. in a. barros, a. gal, and e. kindler, editors,
international conference on business process management (bpm 2012) , volume 7481 of
lecture notes in computer science , pages 1–16. springer-verlag, berlin, 2012.
55. d. fahland, c. favre, b. jobstmann, j. koehler, n. lohmann, h. v ¨olzer, and k. wolf.
instantaneous soundness checking of industrial business process models. in u. dayal,
j. eder, j. koehler, and h. reijers, editors, business process management (bpm 2009) , vol-
ume 5701 of lecture notes in computer science , pages 278–293. springer-verlag, berlin,
2009.
56. r. dijkman, m. dumas, and l. garcia-banuelos. graph matching algorithms for business
process model similarity search. in u. dayal, j. eder, j. koehler, and h. reijers, editors,
business process management (bpm 2009) , volume 5701 of lecture notes in computer
science , pages 48–63. springer-verlag, berlin, 2009.
57. s.a. white et al. business process modeling notation (bpml), version 1.0, 2004.
58. omg. business process model and notation (bpmn). object management group,
formal/2011-01-03, 2011.
59. g. keller, m. n ¨uttgens, and a.w. scheer. semantische processmodellierung auf der
grundlage ereignisgesteuerter processketten (epk). ver ¨offentlichungen des instituts f ¨ur
wirtschaftsinformatik, heft 89 (in german), university of saarland, saarbr ¨ucken, 1992.
60. g. keller and t. teufel. sap r/3 process oriented implementation . addison-wesley,
reading ma, 1998.
61. a.w. scheer. business process engineering: reference models for industrial enterprises .
springer-verlag, berlin, 1994.
62. a. alves, a. arkin, s. askary, c. barreto, b. bloch, f. curbera, m. ford, y . goland,
a. guzar, n. kartha, c.k. liu, r. khalaf, dieter koenig, m. marin, v . mehta,
s. thatte, d. rijn, p. yendluri, and a. yiu. web services business process execu-
tion language version 2.0 (oasis standard). ws-bpel tc oasis, http://docs.oasis-
open.org/wsbpel/2.0/wsbpel-v2.0.html, 2007.
63. c. ouyang, w.m.p. van der aalst, s. breutel, m. dumas, a.h.m. ter hofstede, and h.m.w.
verbeek. formal semantics and analysis of control flow in ws-bpel. science of com-
puter programming , 67(2-3):162–198, 2007.
64. c. ouyang, m. dumas, w.m.p. van der aalst, a.h.m. ter hofstede, and j. mendling. from
business process models to process-oriented software systems. acm transactions on
software engineering and methodology , 19(1):1–37, 2009.
65. w.m.p. van der aalst. formalization and veriﬁcation of event-driven process chains. in-
formation and software technology , 41(10):639–650, 1999.56 wil van der aalst
66. e. kindler. on the semantics of epcs: a framework for resolving the vicious circle.
data and knowledge engineering , 56(1):23–40, 2006.
67. h. v ¨olzer. a new semantics for the inclusive converging gateway in safe processes. in
r. hull, j. mendling, and s. tai, editors, business process management (bpm 2010) , vol-
ume 6336 of lecture notes in computer science , pages 294–309. springer-verlag, berlin,
2010.
68. m.t. wynn, h.m.w. verbeek, w.m.p. van der aalst, a.h.m. ter hofstede, and d. edmond.
business process veriﬁcation: finally a reality! business process management journal ,
15(1):74–92, 2009.
69. w.m.p. van der aalst, j. desel, and e. kindler. on the semantics of epcs: a vicious circle.
in m. n ¨uttgens and f.j. rump, editors, proceedings of the epk 2002: business process
management using epcs , pages 71–80, trier, germany, november 2002. gesellschaft f ¨ur
informatik, bonn.
70. w.m.p. van der aalst, m. pesic, and h. schonenberg. declarative workﬂows: balanc-
ing between flexibility and support. computer science - research and development ,
23(2):99–113, 2009.
71. m. montali, m. pesic, w.m.p. van der aalst, f. chesani, p. mello, and s. storari. declarative
speciﬁcation and veriﬁcation of service choreographies. acm transactions on the web ,
4(1):1–62, 2010.
72. e.m. clarke, o. grumberg, and d.a. peled. model checking . the mit press, cambridge,
massachusetts and london, uk, 1999.
73. z. manna and a. pnueli. the temporal logic of reactive and concurrent systems: speci-
ﬁcation . springer-verlag, new york, 1991.
74. w.m.p. van der aalst, p. barthelmess, c.a. ellis, and j. wainer. proclets: a framework for
lightweight interacting workﬂow processes. international journal of cooperative infor-
mation systems , 10(4):443–482, 2001.
75. acsi. artifact-centric service interoperation (acsi) project home page. www.
acsi-project.eu .
76. k. bhattacharya, c. gerede, r. hull, r. liu, and j. su. towards formal analysis of
artifact-centric business process models. in g. alonso, p. dadam, and m. rosemann,
editors, international conference on business process management (bpm 2007) , volume
4714 of lecture notes in computer science , pages 288–304. springer-verlag, berlin, 2007.
77. d. cohn and r. hull. business artifacts: a data-centric approach to modeling business
operations and processes. ieee data engineering bulletin , 32(3):3–9, 2009.
78. d. fahland, m. de leoni, b. van dongen, and w.m.p. van der aalst. many-to-many: some
observations on interactions in artifact choreographies. in d. eichhorn, a. koschmider,
and h. zhang, editors, proceedings of the 3rd central-european workshop on services and
their composition (zeus 2011) , ceur workshop proceedings. ceur-ws.org, 2011.
79. n. lohmann. compliance by design for artifact-centric business processes. in
s. rinderle, f. toumani, and k. wolf, editors, business process management (bpm 2011) ,
volume 6896 of lecture notes in computer science , pages 99–115. springer-verlag, berlin,
2011.
80. a. nigam and n.s. caswell. business artifacts: an approach to operational speciﬁcation.
ibm systems journal , 42(3):428–445, 2003.
81. j. mendling, h. reijers, and w.m.p. van der aalst. seven process modeling guidelines
(7pmg). information and software technology , 52(2):127–136, 2010.
82. m. la rosa, a.h.m. ter hofstede, p. wohed, h.a. reijers, j. mendling, and w.m.p. van
der aalst. managing process model complexity via concrete syntax modiﬁcations. ieee
transactions on industrial informatics , 7(2):255–265, 2011.business process management: a comprehensive survey 57
83. m. la rosa, p. wohed, j. mendling, a.h.m. ter hofstede, h.a. reijers, and w.m.p. van
der aalst. managing process model complexity via abstract syntax modiﬁcations. ieee
transactions on industrial informatics , 7(4):614–629, 2011.
84. a.a. abdul, g.k.t. wei, g.m. muketha, and w.p. wen. complexity metrics for mea-
suring the understandability and maintainability of business process models using goal-
question-metric (gqm). international journal of computer science and network security ,
8(5):219–225, 2008.
85. k.b. lassen and w.m.p. van der aalst. complexity metrics for workﬂow nets. information
and software technology , 51(3):610–626, 2009.
86. j. mendling, h.a. reijers, and j. cardoso. what makes process models understandable?
in g. alonso, p. dadam, and m. rosemann, editors, international conference on business
process management (bpm 2007) , volume 4714 of lecture notes in computer science ,
pages 48–63. springer-verlag, berlin, 2007.
87. j. recker, m. zur muehlen, k. siau, j. erickson, and m. indulska. measuring method
complexity: uml versus bpmn. in americas conference on information systems (amcis
2009) , pages 1–12. ais, 2009.
88. a. streit, b. pham, and r. brown. visualisation support for managing large business
process speciﬁcations. in w.m.p. van der aalst, b. benatallah, f. casati, and f. curbera,
editors, international conference on business process management (bpm 2005) , volume
3649 of lecture notes in computer science , pages 205—219. springer-verlag, berlin,
2005.
89. b. weber, m. reichert, j. mendling, and h.a. reijers. refactoring large process model
repositories. computers in industry , 62(5):467–486, 2011.
90. v . gruhn and r. laue. reducing the cognitive complexity of business process models. in
g. baciu, y . wang, y . yao, w. kinsner, k. chan, and l. zadeh, editors, ieee conference
on cognitive informatics (icci 2009) , pages 339–345, 2009.
91. workﬂow patterns home page. http://www.workﬂowpatterns.com.
92. n. russell, w.m.p. van der aalst, and a.h.m. ter hofstede. workﬂow exception patterns.
in e. dubois and k. pohl, editors, proceedings of the 18th international conference on
advanced information systems engineering (caise’06) , volume 4001 of lecture notes in
computer science , pages 288–302. springer-verlag, berlin, 2006.
93. a. barros, m. dumas, and a. ter hofstede. service interaction patterns. in w.m.p. van
der aalst, b. benatallah, f. casati, and f. curbera, editors, international conference on
business process management (bpm 2005) , volume 3649 of lecture notes in computer
science , pages 302–318. springer-verlag, berlin, 2005.
94. b. weber, m. reichert, and s. rinderle-ma. change patterns and change support fea-
tures: enhancing flexibility in process-aware information systems. data and knowledge
engineering , 66(3):438–466, 2008.
95. l. fischer, editor. workﬂow handbook 2003, workﬂow management coalition . future
strategies, lighthouse point, florida, 2003.
96. p. lawrence, editor. workﬂow handbook 1997, workﬂow management coalition . john
wiley and sons, new york, 1997.
97. wfmc. workﬂow management coalition workﬂow standard: interface 1 – process def-
inition interchange process model (wfmc-tc-1016). technical report, workﬂow man-
agement coalition, lighthouse point, florida, usa, 1999.
98. wfmc. workﬂow management coalition workﬂow standard: workﬂow process deﬁni-
tion interface – xml process deﬁnition language (xpdl) (wfmc-tc-1025). technical
report, workﬂow management coalition, lighthouse point, florida, usa, 2002.
99. t. andrews, f. curbera, h. dholakia, y . goland, j. klein, f. leymann, k. liu, d. roller,
d. smith, s. thatte, i. trickovic, and s. weerawarana. business process execution lan-58 wil van der aalst
guage for web services, version 1.1. standards proposal by bea systems, international
business machines corporation, and microsoft corporation, 2003.
100. f. leymann. web services flow language, version 1.0, 2001.
101. s. thatte. xlang web services for business process design, 2001.
102. w.m.p. van der aalst. don’t go with the flow: web services composition standards
exposed. ieee intelligent systems , 18(1):72–76, 2003.
103. g. alonso, f. casati, h. kuno, and v . machiraju. web services concepts, architectures
and applications . springer-verlag, berlin, 2004.
104. b. benatallah, f. casati, and f. toumani. representing, analysing and managing web
service protocols. data and knowledge engineering , 58(3):327–357, 2006.
105. f. casati, e. shan, u. dayal, and m.c. shan. business-oriented management of web
services. communications of the acm , 46(10):55–60, 2003.
106. m.p. papazoglou, p. traverso, s. dustdar, and f. leymann. service-oriented computing: a
research roadmap. international journal of cooperative information systems , 17(2):223–
255, 2008.
107. l.j. zhang, j. zhang, and h. cai. services computing, core enabling technology of the
modern services industry . springer-verlag, berlin, 2007.
108. g. hohpe and b. woolf. enterprise integration patterns . addison-wesley professional,
reading, ma, 2003.
109. g. alonso, d. agrawal, a. el abbadi, m. kamath, r. g ¨unth¨or, and c. mohan. advanced
transaction models in workﬂow contexts. in proceedings of the twelfth international
conference on data engineering, february 26 - march 1, 1996, new orleans, louisiana .
ieee computer society, 1996.
110. d. kuo, m. lawley, c. liu, and m.e. orlowska. a general model for nested transactional
workﬂows. in proceedings of the international workshop on advanced transaction models
and architecture (atma ’96) , pages 18–35, bombay, india, 1996.
111. a. reuter and f. schwenkreis. contracts - a low-level mechanism for building general-
purpose workﬂow management-systems. data engineering bulletin , 18(1):4–10, 1995.
112. g. v ossen. transactional workﬂows (tutorial). in f. bry, r. ramakrishnan, and k. ra-
mamohanarao, editors, proceedings of the 5th international conference on deductive and
object-oriented databases (dood’97) , volume 1341 of lecture notes in computer sci-
ence, pages 20–25. springer-verlag, berlin, 1997.
113. g. weikum and g. v ossen. transactional information systems: theory, algorithms, and
the practice of concurrency control and recovery . morgan kaufmann publishers, san
francisco, ca, 2002.
114. e. bertino, e. ferrari, and v . atluri. the speciﬁcation and enforcement of authorization
constraints in workﬂow management systems. acm transactions on information and
system security , 22(1):65–104, 1999.
115. d.f. ferraiolo, r. sandhu, s. gavrila, d.r. kuhn, and r. chandramouli. proposed nist
standard for role-based access control. acm transactions on information and system
security , 4(3):224–274, 2001.
116. j. desel and j. esparza. free choice petri nets , volume 40 of cambridge tracts in theo-
retical computer science . cambridge university press, cambridge, uk, 1995.
117. w.m.p. van der aalst. loosely coupled interorganizational workﬂows: modeling and an-
alyzing workﬂows crossing organizational boundaries. information and management ,
37(2):67–75, march 2000.
118. w.m.p. van der aalst. workﬂow veriﬁcation: finding control-flow errors using petri-net-
based techniques. in w.m.p. van der aalst, j. desel, and a. oberweis, editors, business
process management: models, techniques, and empirical studies , volume 1806 of lecture
notes in computer science , pages 161–183. springer-verlag, berlin, 2000.business process management: a comprehensive survey 59
119. k.m. van hee, n. sidorova, and m. v oorhoeve. soundness and separability of workﬂow
nets in the stepwise reﬁnement approach. in w.m.p. van der aalst and e. best, editors,
application and theory of petri nets 2003 , volume 2679 of lecture notes in computer
science , pages 335–354. springer-verlag, berlin, 2003.
120. k.m. van hee, n. sidorova, and m. v oorhoeve. generalised soundness of workﬂow nets
is decidable. in j. cortadella and w. reisig, editors, application and theory of petri nets
2004 , volume 3099 of lecture notes in computer science , pages 197–215. springer-verlag,
berlin, 2004.
121. w.m.p. van der aalst and a.h.m. ter hofstede. veriﬁcation of workﬂow task structures:
a petri-net-based approach. information systems , 25(1):43–69, 2000.
122. a. basu and r.w. blanning. a formal approach to workﬂow analysis. information
systems research , 11(1):17–36, 2000.
123. h.h. bi and j.l. zhao. applying propositional logic to workﬂow veriﬁcation. information
technology and management , 5(3-4):293–318, 2004.
124. y . choi and j. zhao. decomposition-based veriﬁcation of cyclic workﬂows. in d.a. peled
and y-k. tsay, editors, proceedings of automated technology for veriﬁcation and analysis
(atva 2005) , volume 3707 of lecture notes in computer science , pages 84–98, taipei,
taiwan, 2005. springer-verlag.
125. r. eshuis. symbolic model checking of uml activity diagrams. acm transactions on
software engineering methodology , 15(1):1–38, 2006.
126. d. fahland, c. favre, j. koehler, n. lohmann, h. v ¨olzer, and k. wolf. analysis on de-
mand: instantaneous soundness checking of industrial business process models. data and
knowledge engineering , 70(5):448–466, 2011.
127. s. fan, w.c. dou, and j. chen. dual workﬂow nets: mixed control/data-flow repre-
sentation for workﬂow modeling and veriﬁcation. in advances in web and network tech-
nologies, and information management (apweb/waim 2007 workshops) , volume 4537 of
lecture notes in computer science , pages 433–444. springer-verlag, berlin, 2007.
128. x. fu, t. bultan, and j. su. formal veriﬁcation of e-services and workﬂows. in c. bus-
sler, r. hull, s. mcilraith, m. orlowska, b. pernici, and j. yang, editors, web services,
e-business, and the semantic web, caise 2002 international workshop (wes 2002) , vol-
ume 2512 of lecture notes in computer science , pages 188–202. springer-verlag, berlin,
2002.
129. a.h.m. ter hofstede, m.e. orlowska, and j. rajapakse. veriﬁcation problems in concep-
tual workﬂow speciﬁcations. data and knowledge engineering , 24(3):239–256, 1998.
130. b. kiepuszewski, a.h.m. ter hofstede, and w.m.p. van der aalst. fundamentals of control
flow in workﬂows. acta informatica , 39(3):143–209, 2003.
131. w. sadiq and m.e. orlowska. applying graph reduction techniques for identifying struc-
tural conﬂicts in process models. in m. jarke and a. oberweis, editors, proceedings of
the 11th international conference on advanced information systems engineering (caise
’99), volume 1626 of lecture notes in computer science , pages 195–209. springer-verlag,
berlin, 1999.
132. r.j. van glabbeek and w.p. weijland. branching time and abstraction in bisimulation
semantics. journal of the acm , 43(3):555–600, 1996.
133. r. milner. communication and concurrency . prentice-hall, inc., 1989.
134. w.m.p. van der aalst. interorganizational workﬂows: an approach based on message
sequence charts and petri nets. systems analysis - modelling - simulation , 34(3):335–
367, 1999.
135. w.m.p. van der aalst. inheritance of interorganizational workﬂows: how to agree to
disagree without loosing control? information technology and management journal ,
4(4):345–389, 2003.60 wil van der aalst
136. w.m.p. van der aalst, n. lohmann, p. massuthe, c. stahl, and k. wolf. from public views
to private views: correctness-by-design for services. in m. dumas and h. heckel, editors,
proceedings of the 4th international workshop on web services and formal methods (ws-
fm 2007) , volume 4937 of lecture notes in computer science , pages 139–153. springer-
verlag, berlin, 2008.
137. w.m.p. van der aalst, n. lohmann, p. massuthe, c. stahl, and k. wolf. multiparty con-
tracts: agreeing and implementing interorganizational processes. the computer journal ,
53(1):90–106, 2010.
138. j.a. fisteus, l.s. fern ´andez, and c.d. kloos. formal veriﬁcation of bpel4ws business
collaborations. in k. bauknecht, m. bichler, and b. proll, editors, proceedings of the 5th
international conference on electronic commerce and web technologies (ec-web ’04) ,
volume 3182 of lecture notes in computer science , pages 79–94, zaragoza, spain, august
2004. springer-verlag, berlin.
139. h. foster, s. uchitel, j. magee, and j. kramer. model-based veriﬁcation of web service
composition. in proceedings of 18th ieee international conference on automated soft-
ware engineering (ase) , pages 152–161, montreal, canada, october 2003.
140. x. fu, t. bultan, and j. su. wsat: a tool for formal analysis of web services. in pro-
ceedings of 16th international conference on computer aided veriﬁcation (cav) , volume
3114 of lecture notes in computer science , pages 510–514. springer-verlag, berlin, 2004.
141. e. kindler, a. martens, and w. reisig. inter-operability of workﬂow applications: local
criteria for global soundness. in w.m.p. van der aalst, j. desel, and a. oberweis, editors,
business process management: models, techniques, and empirical studies , volume 1806
oflecture notes in computer science , pages 235–253. springer-verlag, berlin, 2000.
142. m. koshkina and f. van breugel. veriﬁcation of business processes for web ser-
vices. technical report cs-2003-11, york university, october 2003. available from:
http://www.cs.yorku.ca/techreports/2003/.
143. n. lohmann, p. massuthe, c. stahl, and d. weinberg. analyzing interacting bpel pro-
cesses. in s. dustdar, j.l. fiadeiro, and a. sheth, editors, international conference on
business process management (bpm 2006) , volume 4102 of lecture notes in computer
science , pages 17–32. springer-verlag, berlin, 2006.
144. n. lohmann, p. massuthe, and k. wolf. operating guidelines for finite-state services.
in j. kleijn and a. yakovlev, editors, 28th international conference on applications and
theory of petri nets and other models of concurrency, icatpn 2007, siedlce, poland,
june 25-29, 2007, proceedings , volume 4546 of lecture notes in computer science , pages
321–341. springer-verlag, berlin, 2007.
145. f. gottschalk, t. wagemakers, m.h. jansen-vullers, w.m.p. van der aalst, and m. la rosa.
conﬁgurable process models: experiences from a municipality case study. in p. van eck,
j. gordijn, and r. wieringa, editors, advanced information systems engineering, proceed-
ings of the 21st international conference on advanced information systems engineering
(caise’09) , volume 5565 of lecture notes in computer science , pages 486–500. springer-
verlag, berlin, 2009.
146. m. la rosa, m. dumas, a. ter hofstede, and j. mendling. conﬁgurable multi-perspective
business process models. information systems , 36(2):313–340, 2011.
147. a. schnieders and f. puhlmann. variability mechanisms in e-business process families.
in w. abramowicz and h.c. mayr, editors, proceedings of the 9th international conference
on business information systems (bis’06) , volume 85 of lni, pages 583–601. gi, 2006.
148. w.m.p. van der aalst, m. dumas, f. gottschalk, a.h.m. ter hofstede, m. la rosa, and
j. mendling. preserving correctness during business process model conﬁguration. for-
mal aspects of computing , 22(3):459–482, 2010.
149. h.m.w. verbeek, t. basten, and w.m.p. van der aalst. diagnosing workﬂow processes
using woﬂan. the computer journal , 44(4):246–279, 2001.business process management: a comprehensive survey 61
150. w.m.p. van der aalst and a.h.m. ter hofstede. yawl: yet another workﬂow language.
information systems , 30(4):245–275, 2005.
151. n. lohmann and d. weinberg. wendy: a tool to synthesize partners for services. in
j. lilius and w. penczek, editors, applications and theory of petri nets 2010 , volume 6128
oflecture notes in computer science , pages 279–307. springer-verlag, berlin, 2010.
152. b.d. clinton and a. van der merwe. management accounting: approaches, techniques,
and management processes. cost management , 20(3):14–22, 2006.
153. j.a. buzacott. commonalities in reengineered business processes: models and issues.
management science , 42(5):768–782, 1996.
154. j.j. moder and s.e. elmaghraby. handbook of operations research: foundations and
fundamentals . van nostrand reinhold,new york, 1978.
155. h. reijers. design and control of workﬂow processes: business process management for
the service industry , volume 2617 of lecture notes in computer science . springer-verlag,
berlin, 2003.
156. r. wild. production and operations management : principles and techniques . cassell,
london, 1989.
157. w.m.p. van der aalst. business process simulation revisited. in j. barjis, editor, enterprise
and organizational modeling and simulation , volume 63 of lecture notes in business
information processing , pages 1–14. springer-verlag, berlin, 2010.
158. w.m.p. van der aalst, j. nakatumba, a. rozinat, and n. russell. business process simula-
tion. in j. vom brocke and m. rosemann, editors, handbook on business process manage-
ment , international handbooks on information systems, pages 313–338. springer-verlag,
berlin, 2010.
159. ieee task force on process mining. process mining manifesto. in f. daniel, k. barkaoui,
and s. dustdar, editors, business process management workshops , volume 99 of lecture
notes in business information processing , pages 169–194. springer-verlag, berlin, 2012.
160. w.m.p. van der aalst, h.a. reijers, a.j.m.m. weijters, b.f. van dongen, a.k. alves de
medeiros, m. song, and h.m.w. verbeek. business process mining: an industrial appli-
cation. information systems , 32(5):713–732, 2007.
161. s. davidson, s. cohen-boulakia, a. eyal, b. ludaescher, t. mcphillips, s. bowers,
m. anand, and j. freire. provenance in scientiﬁc workﬂow systems. data engineering
bulletin , 30(4):44–50, 2007.
162. f. curbera, y . doganata, a. martens, n. mukhi, and a. slominski. business provenance:
a technology to increase traceability of end-to-end operations. in r. meersman and
z. tari, editors, proceedings of the 16th international conference on cooperative informa-
tion systems, coopis 2008, otm 2008, part i , volume 5331 of lecture notes in computer
science , pages 100–119. springer-verlag, berlin, 2008.
163. b.f. van dongen, a.k. alves de medeiros, and l. wenn. process mining: overview and
outlook of petri net discovery algorithms. in k. jensen and w.m.p. van der aalst, editors,
transactions on petri nets and other models of concurrency ii , volume 5460 of lecture
notes in computer science , pages 225–242. springer-verlag, berlin, 2009.
164. r. agrawal, d. gunopulos, and f. leymann. mining process models from workﬂow logs.
insixth international conference on extending database technology , volume 1377 of lec-
ture notes in computer science , pages 469–483. springer-verlag, berlin, 1998.
165. j.e. cook and a.l. wolf. discovering models of software processes from event-based
data. acm transactions on software engineering and methodology , 7(3):215–249, 1998.
166. a. datta. automating the discovery of as-is business process models: probabilistic and
algorithmic approaches. information systems research , 9(3):275–301, 1998.
167. b.f. van dongen and w.m.p. van der aalst. multi-phase process mining: building instance
graphs. in p. atzeni, w. chu, h. lu, s. zhou, and t.w. ling, editors, international con-62 wil van der aalst
ference on conceptual modeling (er 2004) , volume 3288 of lecture notes in computer
science , pages 362–376. springer-verlag, berlin, 2004.
168. b.f. van dongen and w.m.p. van der aalst. multi-phase mining: aggregating instances
graphs into epcs and petri nets. in d. marinescu, editor, proceedings of the second inter-
national workshop on applications of petri nets to coordination, workﬂow and business
process management , pages 35–58. florida international university, miami, florida, usa,
2005.
169. a.j.m.m. weijters and w.m.p. van der aalst. rediscovering workﬂow models from event-
based data using little thumb. integrated computer-aided engineering , 10(2):151–162,
2003.
170. w.m.p. van der aalst, b.f. van dongen, j. herbst, l. maruster, g. schimm, and a.j.m.m.
weijters. workﬂow mining: a survey of issues and approaches. data and knowledge
engineering , 47(2):237–267, 2003.
171. j. herbst. a machine learning approach to workﬂow management. in proceedings 11th
european conference on machine learning , volume 1810 of lecture notes in computer
science , pages 183–194. springer-verlag, berlin, 2000.
172. a. rozinat and w.m.p. van der aalst. decision mining in prom. in s. dustdar, j.l.
fiadeiro, and a. sheth, editors, international conference on business process management
(bpm 2006) , volume 4102 of lecture notes in computer science , pages 420–425. springer-
verlag, berlin, 2006.
173. a. rozinat, m. wynn, w.m.p. van der aalst, a.h.m. ter hofstede, and c. fidge. work-
ﬂow simulation for operational decision support. data and knowledge engineering ,
68(9):834–850, 2009.
174. a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering colored petri
nets from event logs. international journal on software tools for technology transfer ,
10(1):57–74, 2008.
175. a. rozinat, r.s. mans, m. song, and w.m.p. van der aalst. discovering simulation mod-
els.information systems , 34(3):305–327, 2009.
176. w.m.p. van der aalst, m. pesic, and m. song. beyond process mining: from the past
to present and future. in b. pernici, editor, advanced information systems engineering,
proceedings of the 22nd international conference on advanced information systems en-
gineering (caise’10) , volume 6051 of lecture notes in computer science , pages 38–52.
springer-verlag, berlin, 2010.
177. f.m. maggi, m. montali, and w.m.p. van der aalst. an operational decision support
framework for monitoring business constraints. in j. de lara and a. zisman, editors, in-
ternational conference on fundamental approaches to software engineering (fase 2012) ,
volume 7212 of lecture notes in computer science , pages 146–162. springer-verlag,
berlin, 2012.
178. f.m. maggi, m. westergaard, m. montali, and w.m.p. van der aalst. runtime veriﬁcation
of ltl-based declarative process models. in s. khurshid and k. sen, editors, runtime
veriﬁcation (rv 2011) , volume 7186 of lecture notes in computer science , pages 131–
146. springer-verlag, berlin, 2012.
179. w.m.p. van der aalst, a. adriansyah, and b. van dongen. replaying history on process
models for conformance checking and performance analysis. wires data mining and
knowledge discovery , 2(2):182–192, 2012.
180. a. adriansyah, b. van dongen, and w.m.p. van der aalst. conformance checking using
cost-based fitness analysis. in c.h. chi and p. johnson, editors, ieee international
enterprise computing conference (edoc 2011) , pages 55–64. ieee computer society,
2011.business process management: a comprehensive survey 63
181. a. adriansyah, b.f. van dongen, and w.m.p. van der aalst. towards robust conformance
checking. in m. zur muehlen and j. su, editors, bpm 2010 workshops, proceedings of the
sixth workshop on business process intelligence (bpi2010) , volume 66 of lecture notes
in business information processing , pages 122–133. springer-verlag, berlin, 2011.
182. t. calders, c. guenther, m. pechenizkiy, and a. rozinat. using minimum description
length for process mining. in acm symposium on applied computing (sac 2009) , pages
1451–1455. acm press, 2009.
183. j.e. cook and a.l. wolf. software process validation: quantitatively measuring the cor-
respondence of a process to a model. acm transactions on software engineering and
methodology , 8(2):147–176, 1999.
184. s. goedertier, d. martens, j. vanthienen, and b. baesens. robust process discovery with
artiﬁcial negative events. journal of machine learning research , 10:1305–1340, 2009.
185. j. munoz-gama and j. carmona. a fresh look at precision in process conformance. in
r. hull, j. mendling, and s. tai, editors, business process management (bpm 2010) , vol-
ume 6336 of lecture notes in computer science , pages 211–226. springer-verlag, berlin,
2010.
186. j. munoz-gama and j. carmona. enhancing precision in process conformance: stability,
conﬁdence and severity. in n. chawla, i. king, and a. sperduti, editors, ieee symposium
on computational intelligence and data mining (cidm 2011) , paris, france, april 2011.
ieee.
187. a. rozinat and w.m.p. van der aalst. conformance checking of processes based on mon-
itoring real behavior. information systems , 33(1):64–95, 2008.
188. j. de weerdt, m. de backer, j. vanthienen, and b. baesens. a robust f-measure for
evaluating discovered process models. in n. chawla, i. king, and a. sperduti, editors,
ieee symposium on computational intelligence and data mining (cidm 2011) , pages
148–155, paris, france, april 2011. ieee.
189. r. dijkman, m. dumas, b. van dongen, r. k ¨a¨arik, and j. mendling. similarity of business
process models: metrics and evaluation. information systems , 36(2):498–516, 2011.
190. t. jin, j. wang, and l. wen. efﬁcient retrieval of similar workﬂow models based on
structure. in otm 2011 , volume 7044 of lecture notes in computer science , pages 56–63.
springer-verlag, berlin, 2011.
191. t. jin, j. wang, and l. wen. efﬁcient retrieval of similar workﬂow models based on
behavior. in apweb 2012 , volume 7235 of lecture notes in computer science , pages
677–684. springer-verlag, berlin, 2012.
192. j. mendling, b.f. van dongen, and w.m.p. van der aalst. on the degree of behavioral
similarity between business process models. in m. nuettgens, f.j. rump, and a. gadatsch,
editors, proceedings of sixth workshop on event-driven process chains (wi-epk 2007) ,
pages 39–58, st. augustin, november 2007. gesellschaft f ¨ur informatik, bonn.
193. m. weidlich, r. dijkman, and m. weske. behavioral equivalence and compatibility of
business process models with complex correspondences. computer journal , 2012.
194. w.m.p. van der aalst and t. basten. identifying commonalities and differences in object
life cycles using behavioral inheritance. in j.m. colom and m. koutny, editors, applica-
tion and theory of petri nets 2001 , volume 2075 of lecture notes in computer science ,
pages 32–52. springer-verlag, berlin, 2001.
195. w.m.p. van der aalst, m.h. schonenberg, and m. song. time prediction based on process
mining. information systems , 36(2):450–475, 2011.
196. b.f. van dongen, r.a. crooy, and w.m.p. van der aalst. cycle time prediction: when
will this case finally be finished? in r. meersman and z. tari, editors, proceedings
of the 16th international conference on cooperative information systems, coopis 2008,
otm 2008, part i , volume 5331 of lecture notes in computer science , pages 319–336.
springer-verlag, berlin, 2008.64 wil van der aalst
197. h.a. reijers. case prediction in bpm systems: a research challenge. journal of the
korean institute of industrial engineers , 33:1–10, 2006.
198. staffware. staffware process suite version 2 – white paper . staffware plc, maidenhead,
uk, 2003.
199. h. schonenberg, b. weber, b.f. van dongen, and w.m.p. van der aalst. supporting flex-
ible processes through recommendations based on history. in m. dumas, m. reichert,
and m.c. shan, editors, international conference on business process management (bpm
2008) , volume 5240 of lecture notes in computer science , pages 51–66. springer-verlag,
berlin, 2008.
200. w.m.p. van der aalst, m. weske, and d. gr ¨unbauer. case handling: a new paradigm for
business process support. data and knowledge engineering , 53(2):129–162, 2005.
201. m. adams, a.h.m. ter hofstede, w.m.p. van der aalst, and d. edmond. dynamic, extensi-
ble and context-aware exception handling for workﬂows. in f. curbera, f. leymann, and
m. weske, editors, proceedings of the otm conference on cooperative information sys-
tems (coopis 2007) , volume 4803 of lecture notes in computer science , pages 95–112.
springer-verlag, berlin, 2007.
202. s. dustdar. caramba - a process-aware collaboration system supporting ad hoc and
collaborative processes in virtual teams. distributed and parallel databases , 15(1):45–
66, 2004.
203. c.a. ellis, k. keddara, and g. rozenberg. dynamic change within workﬂow systems.
in n. comstock, c. ellis, r. kling, j. mylopoulos, and s. kaplan, editors, proceedings of
the conference on organizational computing systems , pages 10 – 21, milpitas, california,
august 1995. acm sigois, acm press, new york.
204. m. pesic, m. h. schonenberg, n. sidorova, and w.m.p. van der aalst. constraint-based
workﬂow models: change made easy. in f. curbera, f. leymann, and m. weske, editors,
proceedings of the otm conference on cooperative information systems (coopis 2007) ,
volume 4803 of lecture notes in computer science , pages 77–94. springer-verlag, berlin,
2007.
205. m. reichert and p. dadam. adeptﬂex: supporting dynamic changes of workﬂow with-
out loosing control. journal of intelligent information systems , 10(2):93–129, 1998.
206. s. rinderle, m. reichert, and p. dadam. correctness criteria for dynamic changes in
workﬂow systems: a survey. data and knowledge engineering , 50(1):9–34, 2004.
207. m. weske. formal foundation and conceptual design of dynamic adaptations in a work-
ﬂow management system. in r. sprague, editor, proceedings of the thirty-fourth annual
hawaii international conference on system science (hicss-34) . ieee computer society
press, los alamitos, california, 2001.
208. w.m.p. van der aalst and s. jablonski. dealing with workﬂow change: identiﬁcation of is-
sues and solutions. international journal of computer systems, science, and engineering ,
15(5):267–276, 2000.
209. h. schonenberg, r. mans, n. russell, n. mulyar, and w.m.p. van der aalst. process flexi-
bility: a survey of contemporary approaches. in j. dietz, a. albani, and j. barjis, editors,
advances in enterprise engineering i , volume 10 of lecture notes in business information
processing , pages 16–30. springer-verlag, berlin, 2008.
210. s. sadiq, w. sadiq, and m. orlowska. pockets of flexibility in workﬂow speciﬁcation. in
proceedings of the 20th international conference on conceptual modeling (er 2001) , vol-
ume 2224 of lecture notes in computer science , pages 513–526. springer-verlag, berlin,
2001.
211. t. herrmann, m. hoffmann, k.u. loser, and k. moysich. semistructured models are
surprisingly useful for user-centered design. in g. de michelis, a. giboin, l. karsenty,
and r. dieng, editors, designing cooperative systems (coop 2000) , pages 159–174. ios
press, amsterdam, 2000.business process management: a comprehensive survey 65
212. m. adams. facilitating dynamic flexibility and exception handling for workﬂows . phd
thesis, queensland university of technology, 2007.
213. p. heinl, s. horn, s. jablonski, j. neeb, k. stein, and m. teschke. a comprehensive ap-
proach to flexibility in workﬂow management systems. in g. georgakopoulos, w. prinz,
and a.l. wolf, editors, work activities coordination and collaboration (wacc’99) , pages
79–88, san francisco, february 1999. acm press.
214. m. pesic. constraint-based workﬂow management systems: shifting control to users . phd
thesis, eindhoven university of technology, may 2008.
215. s. rinderle, m. reichert, and p. dadam. evaluation of correctness criteria for dynamic
workﬂow changes. in w.m.p. van der aalst, a.h.m. ter hofstede, and m. weske, editors,
international conference on business process management (bpm 2003) , volume 2678 of
lecture notes in computer science , pages 41–57. springer-verlag, berlin, 2003.
216. c. houy, p. fettke, p. loos, w.m.p. van der aalst, and j. krogstie. business process man-
agement in the large. business and information systems engineering , 3(6):385–388, 2011.
217. r. dijkman, m. la rosa, and h.a. reijers. managing large collections of business pro-
cess models: current techniques and challenges. computers in industry , 63(2):91–97,
2012.
218. a.w. scheer. business process engineering: aris-navigator for reference models for
industrial enterprises . springer-verlag, berlin, 1995.
219. a.w. scheer. aris: business process modelling . springer-verlag, berlin, 2000.
220. m.c. fauvet, m. la rosa, m. sadegh, a. alshareef, r.m. dijkman, l. garcia-banuelos,
h.a. reijers, w.m.p. van der aalst, m. dumas, and j. mendling. managing process model
collections with apromore. in p. maglio, m. weske, j. yang, and m. fantinato, editors,
proceedings of service-oriented computing (icsoc 2010) , volume 6470 of lecture notes
in computer science , pages 699–701. springer-verlag, berlin, 2010.
221. m. la rosa, h.a. reijers, w.m.p. van der aalst, r.m. dijkman, j. mendling, m. dumas,
and l. garcia-banuelos. apromore: an advanced process model repository. expert
systems with applications , 38(6):7029–7040, 2011.
222. a. awad, m. weidlich, and m. weske. visually specifying compliance rules and explain-
ing their violations for business processes. journal of visual languages and computing ,
22(1):30–55, 2011.
223. m. weidlich, a. polyvyanyy, n. desai, j. mendling, and m. weske. process compliance
measurement based on behavioral proﬁles. information systems , 36(7):1009–1025, 2011.
224. j.j.c.l. v ogelaar, h.m.w. verbeek, b. luka, and w.m.p. van der aalst. comparing busi-
ness processes to determine the feasibility of conﬁgurable models: a case study. in
f. daniel, k. barkaoui, and s. dustdar, editors, business process management workshops,
international workshop on process model collections (pmc 2011) , volume 100 of lecture
notes in business information processing , pages 50–61. springer-verlag, berlin, 2012.
225. f. gottschalk, w.m.p. van der aalst, and m.h. jansen-vullers. merging event-driven pro-
cess chains. in r. meersman and z. tari, editors, proceedings of the 16th international
conference on cooperative information systems, coopis 2008, otm 2008, part i , volume
5331 of lecture notes in computer science , pages 418–426. springer-verlag, berlin, 2008.
226. m. la rosa, m. dumas, r. uba, and r.m. dijkman. merging business process models. in
r. meersman, t. dillon, and p. herrero, editors, international conference on cooperative
information systems (coopis 2010) , volume 6426 of lecture notes in computer science ,
pages 96–113. springer-verlag, berlin, 2010.
227. m. la rosa, m. dumas, r. uba, and r.m. dijkman. business process model merging: an
approach to business process consolidation. acm transactions on software engineering
and methodology , 22(2), 2012.66 wil van der aalst
228. c. li, m. reichert, and a. wombacher. discovering reference models by mining pro-
cess variants using a heuristic approach. in u. dayal, j. eder, j. koehler, and h. reijers,
editors, business process management (bpm 2009) , volume 5701 of lecture notes in com-
puter science , pages 344–362. springer-verlag, berlin, 2009.
229. c. li, m. reichert, and a. wombacher. the minadept clustering approach for discov-
ering reference process models out of process variants. international journal of cooper-
ative information systems , 19(3-4):159–203, 2010.
230. v . levenshtein. binary codes capable of correcting deletions, insertions, and reversals.
soviet physics-doklady , 10(8):707–710, 1966.
231. g. miller. wordnet: a lexical database for english. communications of the acm ,
38(11):39–41, 1995.
232. m. hepp, f. leymann, j. domingue, a. wahler, and d. fensel. semantic business pro-
cess management: a vision towards using semantic web services for business process
management. in ieee international conference on e-business engineering (icebe 2005) ,
pages 535 – 540, 2005.