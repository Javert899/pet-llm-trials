predictive object-centric process
monitoring
bachelor’s thesis
author : timo rohrer
advisors :anahita farhang ghahfarokhi
mohamed behery
examiners :professor gerhard lakemeyer
professor wil van der aalst
registration date : 2020-11-18
submission date : 2021-03-18
this work is submitted to the
knowledge-based systems group (kbsg) at i5
and
process and data science (pads) chair at i9
at
rwth aachen universityarxiv:2207.10017v1  [cs.ai]  20 jul 2022iiabstract
the automation and digitalization of business processes has resulted in large amounts of
data captured in information systems, which can aid businesses in understanding their
processes better, improve workﬂows, or provide operational support. by making predic-
tions about ongoing processes, bottlenecks can be identiﬁed and resources reallocated, as
well as insights gained into the state of a process instance (case). traditionally, data is
extracted from systems in the form of an event log with a single identifying case notion,
such as an order id for an order to cash (o2c) process. however, real processes often
have multiple object types, for example, order, item, and package, so a format that forces
the use of a single case notion does not reﬂect the underlying relations in the data. the
object-centric event log (ocel) format was introduced to correctly capture this infor-
mation. the state-of-the-art predictive methods have been tailored to only traditional
event logs. this thesis shows that a prediction method utilizing generative adversar-
ial networks (gan), long short-term memory (lstm) architectures, and sequence to
sequence models (seq2seq), can be augmented with the rich data contained in ocel.
objects in ocel can have attributes that are useful in predicting the next event and
timestamp, such as a priority class attribute for an object type package indicating slower
or faster processing. in the metrics of sequence similarity of predicted remaining events
and mean absolute error (mae) of the timestamp, the approach in this thesis matches
or exceeds previous research, depending on whether selected object attributes are useful
features for the model. additionally, this thesis provides a web interface to predict the
next sequence of activities from user input.
iiiivcontents
1 introduction 3
1.1 motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5
1.2 research questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
1.3 contribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
1.4 thesis structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
2 preliminaries 7
2.1 process mining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7
2.2 traditional event logs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
2.3 object-centric event logs (ocel) . . . . . . . . . . . . . . . . . . . . . . . 8
2.3.1 ocel standard . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
2.4 deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.4.1 neural networks (nn) . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.4.2 recurrent neural network (rnn) . . . . . . . . . . . . . . . . . . . 13
2.4.3 long short-term memory (lstm) . . . . . . . . . . . . . . . . . . . 14
2.4.4 generative adversarial network (gan) . . . . . . . . . . . . . . . . 14
2.4.5 sequence to sequence model (seq2seq) . . . . . . . . . . . . . . . . . 16
3 related work 17
3.1 process model based methods . . . . . . . . . . . . . . . . . . . . . . . . . 17
3.2 deep learning based methods . . . . . . . . . . . . . . . . . . . . . . . . . 18
3.3 object-centric event logs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
4 gan for ocel prediction 21
4.1 data preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
4.2 generator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24
v4.3 gumble-softmax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
4.4 gan architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
5 implementation 29
5.1 extracting rcll dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
5.2 data preprocessing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
5.3 model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
5.3.1 training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
5.3.2 validation and testing . . . . . . . . . . . . . . . . . . . . . . . . . . 30
5.4 hyperparameter tuning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31
5.5 interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32
5.6 deployment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
6 evaluation 35
6.1 experimental setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
6.2 synthetic dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
6.2.1 description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
6.2.2 results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
6.3 rcll dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
6.3.1 description . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
6.3.2 results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
7 conclusion 41
7.1 summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
7.2 outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
a appendix 43
bibliography 51
viacknowledgments
at ﬁrst, i would like to express my deep gratitude to my advisers anahita farhang ghah-
farokhi and mohamed behery for their continual support throughout deﬁning the thesis
topic, conducting the research, and writing the thesis. our regular meetings provided
important guidance, excellent feedback, and interesting discussions.
i would futhermore like to thank professor gerhard lakemeyer and professor wil van der
aalst for accepting this thesis and taking the position of examiners. i would also like to
thank them for enabling this inter-institute thesis, where i was able to gather compelling
insights into both kbsg and pads.
lastly i am thankful for my family and friends for their encouragement and unfailing
support.
12chapter 1
introduction
in our increasingly digitized world, data is being collected everywhere. data is not only
omnipresent in our personal life but also in production and manufacturing processes, lo-
gistics and supply chains, customer service and internal communication systems. from
placing an order online, that order being processed at a facility, to it being shipped and
delivered, increasingly these activities are all recorded in ﬁne detail [1]. industry 4.0 and
the internet of things have greatly accelerated the need for innovative solutions dealing
with the data generated and recorded [2]. the internet of things, referring to the network
of objects being ﬁtted with sensors and data reporting capabilities, is a tangible repre-
sentation of the digital revolution occurring for the last few decades [3]. the tremendous
volume, velocity, and variety of data collected poses new challenges but also presents new
opportunities. businesses can extract value from the data by making predictions about
future activities and thereby increasing the eﬃciency of processes [4].
processes are comprised of a collection of events which can be extracted from information
systems that record the data. a single event in a process includes the activity occurring,
the timestamp, and additional resources related to the event. predictive business process
monitoring aims to learn from past process data to make predictions about ongoing cases
[1]. predictions can be made for what the next activity will be and when it would occur,
or the total time until completion of the case. it is a branch of process mining which
covers a collection of techniques supporting process discovery, performance analysis, and
conformance checking. process mining combines the traditional process science of process
modeling and analysis with data mining and machine learning methods from data science
[1]. driving the interest for this research discipline is the colossal collection of data in
consumer and business contexts as well as the need to remain competitive by improving or
rethinking processes with that data. there are multiple types of process mining techniques
[1]: process discovery for learning process models from past data, process conformance for
comparing a process to its model, and process enhancement where the model is improved
based on a process. several case studies have been done using process mining techniques
[5, 6] and some tools have been developed in this area [7 ?]. additionally, there are
techniques that provide operational support, which includes making predictions about
ongoing cases.
byexploitingdataofpastprocessinstances(cases),predictionscanbemadeaboutongoing
ones. as seen in figure 1.1, based on event logs a model can, for example, learn to
3chapter 1. introduction
figure 1.1: using a model trained on event log data and a partial trace to provide a
prediction about the completion date [1].
predict the completion time based on an ongoing case. this thesis focuses on predicting
future events, speciﬁcally the activity and the timestamp. however, detecting deviations
in processes as they are occurring or making direct recommendations with respect to a
goal is also possible [1]. being able to provide such predictions about ongoing cases very
powerful. thetimelefttoresolvingcustomerservicecasesrelaionshipmanagement(crm)
system would be diﬃcult and time-intensive for employees to predict. in addition to the
time to completion, future events themselves can be predicted [8]. for example, a model
might predict that based on the current ongoing case, an event will occur where additional
information will be requested, or that the case will be resolved shortly. with automatic
predictions, customers requesting that information can easily be provided with it, with no
additionalhumaninterventionorworkrequired. predictingwhenanorderwillbedelivered
in order to cash (o2c) processes similarly provides this information to customers without
additional eﬀort on the side of the company. aside from customer-facing applications,
providing operational support by predicting when production processes will be completed
also provides signiﬁcant value [9]. by giving estimates about remaining manufacturing
timelines based on the current progress, bottlenecks can be identiﬁed and resources re-
allocated to improve eﬃciency on the ﬂy. by predicting events in a logistics operation, the
scheduling of activities can be optimized to improve the eﬃciency and eﬀectiveness of the
operation. with the scale and autonomy of business processes, this form of operational
support is vital in the modern interconnected business world [10].
processes are often captured by information systems, such as enterprise resource plan-
ning (erp) and supply chain management (scm) systems. the stored data can be
extracted as an event log to perform analysis with process mining tools [1]. the event
logs that store process data usually contain at minimum information about the type of
activity occurring, the timestamp of the event, and a case identiﬁer, which refers to the
running case the event is associated with. traditionally in event log speciﬁcations such
as the xes standard, a case notion is required to be selected for the event log [11]. the
current research on predictive process monitoring has relied on these traditional event log
standards for training machine learning models [8, 10, 12–15]. however, in many real
information systems capturing process data, there exist multiple objects that relate to
events and a single case notion is inadequate to fully capture the process and relations
occurring [16].
to illustrate the shortcomings of traditional event logs, consider the following example
adapted from [16] ; a customer places an order which is identiﬁed with an order id and
4chapter 1. introduction
which contains multiple diﬀerent items, each with their own id. the availability of the
diﬀerent items has to be checked and some items are not yet in stock. shortly after, a
second order for the same customer is received. since all the items of the second order
are available, they are packed together with the available items from the ﬁrst order into a
single package and delivered. later, when the remaining items from the ﬁrst order come
into stock, a second package is loaded and delivered. in total there are multiple diﬀerent
objecttypes, namelycustomer, order, item, andpackage. theseareloggedproperlybythe
information system along with any attributes that exist. but when it comes to extracting
the data into an event log, deﬁning a single identifying case notion is diﬃcult. since
there are multiple object types, no one single case notion can capture all the information
contained in this process. convergence , which is when one event includes diﬀerent cases.
additionally, in divergence problems can arise there may be multiple instances of the same
activity within a case. traditional event logs make the assumption that there is a single
case notion and that each event refers to only one case. yet as demonstrated by the
example, process can include multiple object types. more precisely, there exist one-to-
many relations and many-to-many relations between activities and object types that are
not correctly modeled by traditional event logs.
toaddressthisproblemobject-centriceventlogswereproposed[16,17]. theshortcomings
of traditional event logs are remedied by not forcing the selection of a single case notion
and preserving one-to-many and many-to-many relations that exist in many real processes
[18–20]. the extensible object-centric (xoc) format was initially proposed, however, it
suﬀered from complexity and performance problems [21]. to address these concerns, the
more eﬃcient ocel1standard was speciﬁed to aid the exchange of data between systems
and tools. informally, the data is represented in two tables, one of the events and one for
the objects. the event table is organized by event id, and holds information about the
activity, timestamp, and other event attributes. additionally, it includes per event the
objects that are related to the event. so in the example above, the place order event would
include objects of types customer, order, and item in the ocel event table. in the object
table, the attributes for objects are recorded. there can be attributes such as the size and
weight for an object of type item, or the address for an object of type customer.
the challenge remains to integrate the ocel format of event logs with existing research
in prediction methods, as well as using the useful object attributes in predictions.
1.1 motivation
the motivation for this thesis is to utilize object-centric event logs in predicting succeeding
events and timestamps in ongoing cases. since the related research so far has only used a
singlecasenotionformatineventlogs, predictivemethodshavebeentailoredspeciﬁcallyto
thatstructure[8,10,12–15]. withoutselectingasinglecasenotion, thedevelopedmethods
cannotwork. therefore, inthisthesis, therelationsbetweenobjectsandactivitiesinevent
logs have to be visualized so that appropriate case notions can be selected for the desired
prediction task. additionally, the objects contained in object-centric event logs can have
attributes that aid in predictive tasks. in traditional event logs this information is a
subclass of case attributes [1] and in ocel logs it is referred to object attributes. for
example, an online order process can contain the object type package and for a given
1http://ocel-standard.org/
5chapter 1. introduction
package there can be the object attribute priority class . such data can be a useful feature
for predicting the time until a package is delivered. while some past research has utilized
the case attributes in traditional event logs [8], the more recent state-of-the-art models
[15] forgo using this information in predictions.
1.2 research questions
the main goal of the thesis is to leverage object-centric event logs to provide insights for
predictions.
to achieve this goal, the questions to be answered are:
1. how can recent improvements in machine learning models be enhanced with object-
centric event logs for prediction?
2. how can training and prediction be made more easily accessible?
1.3 contribution
the principal contribution of this thesis is bridging the gap between recent machine learn-
ing models and object-centric event logs. additionally, the relations between objects and
object attributes in ocel data are used to improve the prediction. to achieve these goals,
this thesis:
1. extracts an ocel dataset from a factory logistics simulation
2. augments a state-of-the-art generative adversarial network (gan) approach with
object attributes from ocel data to improve predictions
3. developsaninteractivewebtoolformakingpredictionsaboutongoingcasesdeployed
using docker and kubernetes
1.4 thesis structure
chapter 2 describes the necessary preliminaries about process mining, traditional and
object-centric event logs, and machine learning. chapter 3 explores recent research and
compares it to the proposed methods. chapter 4 details the data driven prediction model.
chapter 5 describes the implementation of the proposed model and the web interface.
chapter 6 discusses the results of the evaluation. chapter 7 summarizes the work and a
future outlook is given.
6chapter 2
preliminaries
in this chapter, a short introduction of process mining, the necessary groundwork, and def-
initions are presented. formal deﬁnitions, as well as intuitive examples of traditional event
logs and object-centric event logs are given. lastly, diﬀerent neural network architectures
are explained.
2.1 process mining
processes are ubiquitous in most companies’ day-to-day activities. common processes in-
cludeordertocash(o2c)andpurchasetopay(p2p)whichrecordabusinesses’workﬂow
regarding order processing. furthermore, manufacturing and production processes are in-
creasingly recorded as factories move to digitize the assembly line and automate industrial
practices [3]. after production, supply chains and logistics organizations have for long
recorded receiving and handling of goods in ﬁne detail. beyond that, internal communica-
tions, customer service processes, and essentially any series of activities can and are being
recorded for future analysis.
recording of the data can occur in a variety of ways: enterprise resource planning
(erp), supply chain management (scm), customer relationship management (crm),
and business process management (bpm) systems record data about events. process
mining extracts the data in the form of event logs and aims to extract useful information.
based on the methods and the ﬁnal goal, process mining is frequently separated into
four types [1]; process discovery deals with discovering process models from event logs,
using algorithms to build models such as transition systems or petri nets. conformance
checking deals with detecting abnormalities in an event log as compared to a process
model.process reengineering refers to improving an existing process model with data
from an event log to better reﬂect the underlying processes. lastly, operational support
is improving process on the ﬂy by making predictions about remaining time or the next
event and providing recommendations to decrease delays or bottlenecks [22]. predictive
process mining methods fall in the category of operational support and the developed
methods have been tailored to work with traditional event logs which are described in the
next section.
7chapter 2. preliminaries
2.2 traditional event logs
typically the process mining methods assume that information systems ingest sequential
seriesofeventsthatarerecordedwithavarietyofinformation, whichcanthenbeextracted
as an event log [1]. table 2.1 gives an example for a traditional event log. each row in the
log shows an event which is represented by the event id. each row is also uniquely tied to
a case based on a case notion, which is represented by the case id. in addition there is the
activityand atimestamp . while event logs do not necessarily need to be of this general
format, for the purposes of prediction this information is important.
since each event is uniquely tied to a case, it can be represented within a trace. a trace
is a ﬁnite non-empty sequence of events ordered by time within a case [1]. in table 2.1
for the case identiﬁed by case id73, the activities of the trace are: place order, check
availability, create package, load package, create invoice, failed delivery, receive payment,
deliver package .
an event log as it has been traditionally deﬁned is simply a set of traces, which can also
include incomplete or partial traces [1].
table 2.1: a fragment of a traditional event log example (adapted from [16]).
event id case id activity timestamp
... ... ... ...
9791 73 place order 2020-9-14 11:37
9792 73check availability 2020-9-14 11:40
9793 73create package 2020-9-14 15:10
9794 74 place order 2020-9-14 16:01
9795 74check availability 2020-9-14 16:05
9796 73 load package 2020-9-15 10:15
9797 73 create invoice 2020-9-15 10:16
9798 73 failed delivery 2020-9-15 14:39
9799 74create package 2020-9-15 16:39
9800 73receive payment 2020-9-16 09:42
9801 75 place order 2020-9-17 12:03
9802 73deliver package 2020-9-18 10:39
9803 75check availability 2020-9-18 11:40
9804 76 place order 2020-9-18 12:03
9805 75create package 2020-9-18 15:10
9806 76check availability 2020-9-18 15:40
... ... ... ...
2.3 object-centric event logs (ocel)
the event log shown in table 2.1 can be an inadequate model of real-world processes. in
o2csystemsliketheexamplesintables2.1and2.2, orderscanhavemultipleitems, which
might be split up into multiple diﬀerent packages with items from other orders. in table
2.2, the events that are captured in an object-centric event log are given. additionally,
there is information about the object types contained in the events, presented in table
2.3. the object types (case notions) are order, item, andpackage.
8chapter 2. preliminaries
table 2.2: a fragment of events in an ocel example (adapted from [16]).
event id activity timestamp order item package
... ... ... ... ... ...
9791 place order 2020-9-14 11:37 {o1}{i1,i2,i3}∅
9792 check availability 2020-9-14 11:40 {o1}{i1}∅
9793 pick item 2020-9-14 11:41 {o1}{i1}∅
9794 check availability 2020-9-14 11:42 {o1}{i2}∅
9795 check availability 2020-9-14 11:43 {o1}{i3}∅
9796 pick item 2020-9-14 11:47 {o1}{i2}∅
9797 pick item 2020-9-14 11:48 {o1}{i3}∅
9798 create package 2020-9-14 15:10 ∅{i1,i2}{p1}
9799 place order 2020-9-14 16:01 {o2}{i4,i5}∅
9800 check availability 2020-9-14 16:05 {o2}{i4}∅
9801 check availability 2020-9-14 16:06 {o2}{i5}∅
9802 pick item 2020-9-15 11:40 {o2}{i1}∅
9803 pick item 2020-9-15 11:41 {o2}{i2}∅
9804 create package 2020-9-15 16:18 ∅{i3,i4,i5}{p2}
9805 load package 2020-9-16 10:15 ∅∅{p1}
9806 deliver package 2020-9-16 14:39 ∅∅{p1}
9807 load package 2020-9-16 16:45 ∅∅{p2}
9808 send invoice 2020-9-17 10:15 {o1}{i1,i2,i3}∅
9809 deliver package 2020-9-17 10:26 ∅∅{p2}
9810 send invoice 2020-9-17 10:45 {o2}{i4,i5}∅
9811 receive payment 2020-9-17 10:49 {o1}{i1,i2,i3}∅
... ... ... ... ... ...
when approaching the data in table 2.2 from a traditional event log perspective and
trying to ﬁt a single case identiﬁer, events could suﬀer from convergence or divergence
[16].convergence is when one event is related to multiple cases and divergence occurs
when within a case a group of activities is independently repeated.
generally, theseissuesoccuratthepointofextractingthedatafromthesystemstheywere
recorded in: diﬀerent systems such as the sap erp software1support multiple object
types and when extracting the data as a traditional event log, the issues arise. if any one
of the object types is picked as the single case identiﬁer, the problems of convergence and
divergence result in an inadequate representation of the process, since it is not possible
to reduce these complex relationships into a traditional event log [16]. by preserving the
completedataintheformatofanobject-centriceventlog, anaccurateimageoftheprocess
is obtained, which can enable higher quality insights to be obtained with process mining
techniques.
1https://www.sap.com/products/erp.html
9chapter 2. preliminaries
table 2.3: a fragment of objects in an ocel example.
object id object type object priority object size object product object weight
... ... ... ... ... ...
o1 order low nan nan nan
o2 order high nan nan nan
i1 item nan 2mx2mx1m small box nan
i2 item nan 2.4mx2.3mx1.9m medium box nan
i3 item nan 2mx2mx0.5m small box nan
i4 item nan 3mx3mx2m large box nan
p1 package nan nan nan 50kg
... ... ... ... ... ...
2.3.1 ocel standard
to aid in exchanging the data from information systems into formats used in process
mining, the object-centric event logs (ocel) standard speciﬁcation was introduced
[23]. the universes used and applicable examples from table 2.2 and 2.3 are given in
deﬁnition 2.1.
deﬁnition 2.1 (universes ).below are the universes used:
•ueis the universe of event identiﬁers.
example: {9791, 9792, ...}
•uactis the universe of activities.
example: {place order, create package, ...}
•uattis the universe of attribute names.
•uvalis the universe of attribute values.
•utypis the universe of attribute types.
•uois the universe of object identiﬁers.
example: { i1,o1,p1, ...}
•uotis the universe of objects types.
example: {package, order, ...}
•utimestis the universe of timestamps.
example: {2020-9-16 14:39, ...}
using the universes, an object-centric event log is deﬁned in deﬁnition 2.2.
deﬁnition 2.2 (object-centric event log ).an object-centric event log is a tuple
l= (e,an,av,at,ot,o,π typ,πact,πtime,πvmap,πomap,πotyp,πovmap,≤)such that:
•e⊆ueis the set of event identiﬁers.
•an⊆uattis the set of attributes names.
•av⊆uvalis the set of attribute values (with the requirement that an ∩av=∅).
•at⊆utypis the set of attribute types.
10chapter 2. preliminaries
•ot⊆uotis the set of object types.
example: the object type itemexists in table 2.2
•o⊆uois the set of object identiﬁers.
example: the object identiﬁer p1exists in table 2.2
•πtyp:an∪av→atis the function associating an attribute name or value to its
corresponding type.
•πact:e→uactis the function associating an event (identiﬁer) to its activity.
example: the ﬁrst event in table 2.2 had activity place order
•πtime:e→utimestis the function associating an event (identiﬁer) to a timestamp.
example: the ﬁrst event in table 2.2 had timestamp 2020-9-14 11:37
•πvmap :e→(an/negationslash→av)such that
πtyp(n) =πtyp(πvmap(e)(n))∀e∈e∀n∈dom(πvmap(e))
is the function associating an event (identiﬁer) to its attribute value assignments.
•πomap :e→p(o)is the function associating an event (identiﬁer) to a set of related
object identiﬁers.
example: the ﬁrst event in table 2.2 is related to object types order, item, package
•πotyp∈o→otassigns precisely one object type to each object identiﬁer.
example: the ﬁrst object in table 2.3 is object type order
•πovmap :o→(an/negationslash→av)such that
πtyp(n) =πtyp(πovmap (o)(n))∀n∈dom(πovmap (o))∀o∈o
is the function associating an object to its attribute value assignments.
example: the ﬁrst object in table 2.3 has attribute value low
•≤is a total order (i.e., it respects the antisymmetry, transitivity, and connexity
properties). a possible way to deﬁne a total order is to consider the timestamps
associated with the events as a pre-order (i.e., assuming some arbitrary, but ﬁxed,
order for events having the same timestamp).
the traditional and object-centric event log standards share a far amount of similarities
butarecruciallydiﬀerentinhowtheytreatcasenotionsandobjects. thepreviousresearch
in predictive methods for event logs discussed in chapter 3 has only been conducted with
traditional event logs. to better understand the components of the most recent research,
an overview of deep learning is given next.
11chapter 2. preliminaries
2.4 deep learning
machine learning aims to develop methods to make predictions or decisions after learning
on training data. regression analysis [24], support vector machines [4], and extreme gradi-
ant boosting [25] are models that have performed well for many diﬀerent predictive tasks,
but the current state-of-the-art approaches [8, 10, 12–15] utilize neural networks.
2.4.1 neural networks (nn)
input
input
inputoutputhidden
layerinput
layeroutput
layer
figure 2.1: an example of a simple feedforward neural network.
a neural network as seen in figure 2.1 is a network of individual nodes called artiﬁcial
neurons [26]. each neuron receives a number of inputs and produces a single output value.
neurons are aggregated into layers and a network usually consists of one input layer, one
output layer, and a number of hidden layers in between. the connections between nodes
are called edges and have associated weights indicating the relative importance of the
connection. the output of an individual neuron is calculated as the weighted sum of all
the inputs and passed through an activation function, after which it is fed into a number of
neurons. the network is trained on sample data and the weights are adjusted to minimize
loss through an algorithm called backpropagation.
formally, the activation of a neuron is given in equation 2.1 [27]:
al
j=σ/parenleftbigg/summationdisplay
kwl
jkal−1
k+bl
j/parenrightbigg
(2.1)
whereal
jis the activation of the jthneuron in the lthlayer for a function σ. the weight
matrixwlconsists of the weights connecting to the lthlayer. the bias vector bl
jis the
measure of how easy the jthneuron in the lthlayer ﬁres.
to update the weights and biases a loss or cost function cis deﬁned. it represents a func-
tion used to evaluate the model output. the backpropagation steps include 4 equations
which help calculate the error and gradient of the loss function c. the goal is computing
the partial derivatives ∂c/∂wand∂c/∂b. where⊙is the elementwise product, the error
δlof the output layer lis given in equation 2.2:
δl=∇ac⊙σ/prime/parenleftbig
zl/parenrightbig
(2.2)
12chapter 2. preliminaries
whereσis a function and ∇acis a vector comprised of the components of the partial
derivative∂c/∂bl
jandzlis the weighted input to the neurons in layer l. next the error
in terms of the error in the next layer is given in equation 2.3:
δl=/parenleftbigg/parenleftbig
wl+1/parenrightbigtδl+1/parenrightbigg
⊙σ/prime/parenleftbig
zl/parenrightbig
(2.3)
the element (wl+1)tis the weight matrix transposed. now the original goals can be
computed; the bias partial derivative as seen in equation 2.4:
∂c
∂bl
j=δl
j (2.4)
and the weight partial derivative give in equation 2.5:
∂c
∂w=al−1
kδl
j (2.5)
backpropagation is presented in algorithm 1 where a mini-batch has msamples and the
learning rate is η:
algorithm 1: backpropogation (adapted from [27])
1fornumber of epochs do
2fornumber of mini-batches do
3foreach sample x in mini-batch do
4 computeax,1;
5 foreach l = 2,3, ..., l compute
6 zx,l=wlax,l−1+bl;
7 end
8 ax,l=σ(zx,l);
9 foreach l = l-1, l-2, ..., 2 compute
10 δx,l=∇acx⊙σ/prime(zx,l);
11 end
12 end
13 foreach l = l, l-1, ..., 2 update
14 wl→wl−η
m/summationtext
xδx,l(ax,l−1)t;
15 bl→bl−η
m/summationtext
xδx,l;
16 end
17end
18end
2.4.2 recurrent neural network (rnn)
as opposed to feedforward neural networks, where edges do not form any cycles, there are
cyclic structures used in memory like fashion in an rnn which make them suited well for
temporal data [26]. modeled as a directed graph, they describe a class of networks that
13chapter 2. preliminaries
rht
xtrh0
x0rh1
x1rh2
x2rht
xtunfold
figure 2.2: unfolding a recurrent neural network.
can use their internal state to process inputs of any length. this is achieved by unfolding
the rnn cell, meaning copies are created for diﬀerent time steps as seen in figure 2.2.
the input vector into the rnn ris represented as xtand the output vector as ht. the
output of the cell at t-1 is the input for the cell at time t. this enables the cell to have
memory and process inputs of diﬀerent lengths. however, for long sequences, rnns can
suﬀer from catastrophic interference where learned patterns are forgotten.
2.4.3 long short-term memory (lstm)
to combat the shortcomings of an rnn, the lstm architecture was introduced [29]. it
includes gates that control the ﬂow of data and a memory cell that learns patterns over
longer time periods. intuitively, the input gate determines how much of the new values
ﬂow into the cell, the forget gate determines how much of the values will be forgotten,
while the output gate controls which values contribute to the output to the next cell.
the gates can be seen as the standard neurons discussed before, which compute some
activation over the sum of weighted inputs.
as seen in figure 2.3, the input gate activation vector is it, the output gate activation
vectorot, and the forget gate activation vector ft. the activation functions are σgfor
the sigmoid function and σhfor the hyperbolic tangent function. the input vector is xt
andhtrepresents the hidden state or output vector. the cell state or memory vector is
represented by ctand the cell input activation vector by ˜ct. finallywandurepresent
the weight matrices and bany bias that the training step learns. the lstm cell updates
six parameters in each time step as listed in equation 2.6.
ft=σg(wfxt+ufht−1+bf) ˜ct=σh(wcxt+ucht−1+bc)
it=σg(wixt+uiht−1+bi)ct=ft◦ct−1+it◦˜ct
ot=σg(woxt+uoht−1+bo)ht=ot◦σh(ct)(2.6)
2.4.4 generative adversarial network (gan)
while lstm’s were able to demonstrate good results in predicting the next event, they
require a lot of labeled training data to be able to generalize well [14]. most publically
availablereal-lifeeventlogsarelimitedinsize, whichinhibitsthemodel’sabilitytoperform
better. introduced by goodfellow et al. in 2014 [30], gans employ a zero-sum game
with two player’s, meaning one player’s gain is oﬀset by the other player’s loss. one
14chapter 2. preliminaries
figure 2.3: lstm building block [28] (liscensed under gpl-3.0).
random input
generator network
fake data real data
discriminator network
real/fake classiﬁcation
figure 2.4: generative adversarial network architecture with random input.
15chapter 2. preliminaries
player is called the generator and tries to create new data that is similar to the training
data, and the other player is the discriminator who tries to distinguish between real and
fake data. each player tries to maximize their outcome through separate training with
backpropagation, which means the generator tries to produce more convincing fake data
and the discriminator tries to get better at detecting that fake data. ideally, this converges
to the point where the generator creates near-perfect fakes and the discriminator is no
better than 50% at predicting the truth. as seen in figure 2.4 the generator is fed with
random data, so early on in the training, the fakes are poor representations for the real
data and the discriminator can easily distinguish them. but with the feedback from the
discriminator, the generator can keep improving. radford et al. [31] standardized deep
convolutional generative adversarial networks (dcgans) which have been used among
other things, to create realistic human faces and upsample low-resolution images.
2.4.5 sequence to sequence model (seq2seq)
sequence to sequence (seq2seq) models were ﬁrst introduced in 2014 [32]. the main
problem they address is how to map one sequence to another. this occurs in many
domains, for example, machine translation, where a sentence in one language will have
a diﬀerent length in another language. an rnn or an lstm can not produce variable-
lengthoutputs, soseq2seqwasproposed. thereisanencoder/decoderarchitecturecentral
to the model: the encoder is an lstm that turns the input into a ﬁxed hidden vector and
the decoder is another lstm that transforms the hidden vector into an output.
16chapter 3
related work
in this section, an overview is given for past approaches in predictive process mining,
starting with process model based methods and ending with the state-of-the-art deep
learning models.
3.1 process model based methods
process mining is the intersection of data science and process science [1]. discovering
process models to describe past events has been a topic of research since the 1990’s, when
to better understand the execution of business practices an algorithm was developed to
generate a graph model from a log of activities [33]. the proposed algorithm creates
process models and can deal with cycles in processes and erroneous activities. notable
improvements were made with the α-miner [34] which can ﬁnd a petri net model from an
event log. furthermore, the heuristic miner [35] can better deal with noisy or incomplete
data. this represents process discovery, where a process model is generated based on event
logs. the model can be visualized to show the workﬂow between activities.
apart from performing post-hoc analysis using automatically generated process models,
theusecasecanbeextendedtoproviderealtimeoperationalsupportofrunningcases,such
as the prediction of the next activity. the prerequisite for the prediction is a process model
obtainedfromprocessdiscoverymethods. leetal.[36]extendshigherordermarkovmodels
with a sequence alignment technique to predict the next event. with no formal description
oftheunderlyingprocesses, themethodutilizesprobabilitymatricesforthetransitionfrom
oneeventtoanother. theassumptionthatsimilarsequencesarelikelytoproducethesame
outcome enables better results in terms of prediction accuracy. lakshmanan et al.[37] also
ﬁrst mines a process model from the event log. then at each split in the model, a decision
tree is learned from execution data and state transition probabilities computed. based on
an ongoing case a hidden markov model is used to predict the likelihood of a future event.
parallel executed tasks are supported and the approach is more accurate as demonstrated
on a simulated auto insurance event log. breuker et al.[10] recognizes the potential biases
in models such as petri nets and proposes using probabilistic ﬁnite automaton to predict
the next event. based on research in the ﬁeld of grammatical interference, a probabilistic
model of the event data is learned and used in next event predictions.
alloftheseapproachesdealwithdiscoveringprocessmodelsfromlogsbasedonthecontrol
17chapter 3. related work
ﬂow of activities where based on an ongoing case the next event is predicted. however,
with most information systems saving timestamp data, the models mined from event logs
can be enriched with timestamp data. then thetime untilthe nexteventcan bepredicted,
ortheremainingtimeforthewholecase, increasingtheusefulnessofthepredictions.
the time to completion of a case is predicted using non-parametric regression in [24].
occurrences of activities in cases, activity durations, and case data are combined in the
implementation. compared to the naive approach of subtracting the elapsed time from
the total average case time, the proposed methods perform better in real event logs. the
process mining techniques learned from process discovery are applied to time prediction
in [22]. a process model is mined from event logs and augmented with time information.
the annotated transition system predicts completion time based on an ongoing case,
therebyprovidingoperationalsupport. theapproachisimplementedintheprocessmining
tool prom1and outperforms simple heuristics on both synthetic and real event logs.
in order to support dynamic business processes, ad-hoc predictive clustering is used in
[9]. by distinguishing patterns in event logs as distinct process variants, clusters are
discovered. an ongoing case is estimated to belong to a speciﬁc cluster and then the
remaining processing time is predicted. the approach outperforms previous methods on a
real event log and is able to foresee service level agreement violations. in [38] the authors
create petri net models to predict remaining time. as opposed to state transition systems,
the approach can model concurrency and time passed is taken into consideration. the
largest gains in predicting accuracy are observed in longer running cases and it matches
previous approaches in shorter cases.
a unifying theme to the approaches presented so far is the reliance on some form of pro-
cess model mined through process discovery. such methods can not be used when process
models are too diﬃcult to obtain. additionally, process models can be imperfect abstrac-
tions of the underlying process, trading oﬀ precision for simplicity, therefore, making the
predictions only as good as the process model [8]. authors in [39] completed an empirical
evaluation of remaining case time prediction methods as of 2019. they concluded that
lstm neural networks achieved the most accurate results in terms of mean average er-
ror, with the tradeoﬀ of signiﬁcantly more computational resources being required to train
the models as opposed to transition systems. recently, machine learning approaches and
speciﬁcally deep learning methods have been developed which outperform previous work
for both next event and time prediction [13, 14]. as opposed to process model based tech-
niques, they do not use an explicit representation of a process model and instead rely on
learning features from the ground up to make predictions. the large amounts of trainable
parameters and inherent non-linearity in deep neural nets have proven to be advantageous
in predictive tasks [8].
3.2 deep learning based methods
evermann et al.[8] ﬁrst used deep learning in process prediction by predicting the next ac-
tivity. inspired by research using recurrent neural networks (rnn) in natural language
processing, the approach is based on lstm layers and encodes categorical variables. the
approach is tested on multiple real life event logs and is able to surpass previous research
[37] [10] in many cases. however, the encoding of attributes in an embedding space limits
1https://www.promtools.org/
18chapter 3. related work
the approach to event logs with a small number of unique activities and numerical values
are not utilized. in [12] sequences of events are mapped into 2d data structures similar
to images and used to train convolutional neural networks which predict the next activ-
ity. while performing well in terms of precision and recall on multiple real datasets, less
frequent activities are not correctly predicted.
tax et al. [13] combines the challenge of predicting the next event and the time for that
event into one architecture utilizing lstms with two hidden layers. one-hot encoding
was used for categorical data and timestamps were augmented so that business hours
were respected in the prediction. the previous research is surpassed in terms of accuracy
of the predicted next event and mean absolute error (mae) of the predicted timestamp
on multiple real datasets. furthermore, by continuously predicting the next event until the
end of a case, this approach can also predict the entire remaining case and the total time to
completion, where it also exceeds previous approaches. carmangoe et al. [40] combine the
work of [8] and [13] to predict the next event and its timestamp. categorical attributes are
embedded in an n-dimensional space where coordinates correspond to unique categories
and numerical attributes normalized to reduce variability. again two lstm layers are
utilized and diﬀerent architectures for sharing categorical attributes are explored.
taymouri et al. [14] ﬁrst introduced the idea of using generative adversarial nets (gan)
for next event and timestamp prediction in event logs. by having two lstm networks
play a zero-sum game against each other the generator becomes better at creating fake
next events over a number of iterations. while normally the generator receives a random
vector from a gaussian distribution as input, the approach uses the ongoing case as the
input. the predicted next event from the generator is added on the ongoing case to form
the fake preﬁx and the real next event is added to the ongoing case to form the fake preﬁx.
these are fed into the discriminator which returns a probability of the input being real,
which in turn is used as feedback for the generator. the generative approach allows the
network to make better generalizations about event logs and requires less training data
to produce good results. activities are one-hot encoded and events are augmented with
the elapsed time between the last event. in both predicting the next event and predicting
the timestamp of the event, the approach was able to signiﬁcantly outperform previous
approaches on multiple real event logs.
for predicting events further in the future, some of the previously discussed methods sim-
ply execute the prediction consecutively, using the output from the previous run as input
for the current one. while for shorter average case lengths the results can be good, such
methods fare poorly for longer remaining process executions since the errors propagate.
in [15] this is addressed by predicting the entire remaining events and timestamps from
an ongoing case instead of just the next event. sequence to sequence models are inte-
grated into the gan architecture from [14] to map an input preﬁx to an output suﬃx.
by utilizing the encoder/decoder structure for the generator, variable length outputs can
be achieved. the generator attempts to produce convincing suﬃxes and the discriminator
provides feedback by returning the probability the input is a real suﬃx for a given preﬁx.
on several real event logs, the approach performed better in terms of suﬃx similarity and
error in the predicted timestamps.
19chapter 3. related work
3.3 object-centric event logs
all the presented methods have worked with traditional event logs, but as [16] points
out, real life processes frequently are too complicated to reduce to a single case notion.
instead, there are multiple identiﬁers that refer to diﬀerent views of the event log and it
is not possible to in general identify a single case identiﬁer. therefore object-centric event
logs were introduced to more accurately capture the relations in real world data. past
research in object-centric event logs has been in formalizing the standard2and process
discovery [16]. additionally, there have been techniques proposed in extracting object-
centric event logs from information systems [41, 42] and automated event log building
[43]. furthermore, visualizing and modeling the processes has been researched [44–47].
however, the previously discussed prediction methods rely on traditional event logs with
a single case notion to calculate a trace for a case and train the predictive models. since
object-centric event logs do not force a single case notion, selecting an appropriate object
type is required ﬁrst. in this thesis, this is made easily understandable by showing the
relations between activities and object types as well as statistics about the diﬀerent object
types. furthermore, the object attributes contained in ocel can be useful features in
predictive tasks. while some past research has utilized the analogous case attributes in
traditional event logs [8], the more recent state-of-the-art models [15] forgo using this
information in predictions.
therefore, this thesis augments the state-of-the-art gan with sequence to sequence mod-
els approach [15] with object attributes from object-centric event logs (ocel). the idea
is that certain object attributes can improve the model, for example, an object attribute
weight for an object of object type package might indicate faster or slower shipping time.
this information can be learned by the model to provide more accurate predictions. fur-
thermore, few past research makes the predictive models easily accessible, therefore, this
thesis designs a web interface for easy training and prediction of ocel data.
2http://ocel-standard.org/
20chapter 4
gan for ocel prediction
in this section, the proposed methods are introduced. first, the necessary data pre-
processing steps and encoding strategy are explained. second, the sequence to sequence
model architecture for the generator is detailed. last, the gan architecture as a whole is
discussed.
4.1 data preprocessing
for this thesis, object-centric event logs conforming to the ocel standard [23] are used.
the standard speciﬁes data to be stored in the xml or json format and provides library
support for importing and exporting ﬁles in python. an imported ocel dataset consists
of two tables, one for the event data (table 2.2) and one for the object data (table 2.3).
in the event dataset, object types have relations with activities. the relations found in
the example event data in table 2.2 are visualized in figure 4.1.
as seen in figure 4.1, not every activity is related to every object type. this will vary
from dataset to dataset, so it is important to visualize the relationships. for example, as
seen in figure 4.1, only the activities pack items, load package , anddeliver package can
be predicted if object type packageis selected, since those are the only activities that are
related to that object type. therefore, depending on the use case of the prediction, the
appropriate object type should be selected. after selection of the object type package,
the object table 2.3 contains the object attribute object weight which will be used in the
prediction.
the event table 2.2 contains the familiar columns event id,activityandtimestamp . there
can also be additional event attributes. on the other hand, the object table 2.3 has
the identiﬁer object id for the speciﬁc object along with the corresponding object type .
furthermore, every object attribute is listed. for prediction in the model, only speciﬁc
data is used: while the event id is necessary to organize the cases and create training or
testing data, it is not used directly in the prediction. rather, the activity,timestamp , and
any object attributes are the only values that are used directly in the machine learning
model and therefore need data preprocessing. two types of data occur in the ocel;
numerical data such as the timestamp and categorical data such as the activity. these
require diﬀerent encoding so that the model can handle the data.
21chapter 4. gan for ocel prediction
place order
check availability
pick item
send invoice
receive payment
create package
load package
deliver packageorder
items
package1
11
1..*1..* 1
1..*
11..*1
1
111
1
1..*
11
11..*
11..*
1
1
1..*1
111
1..*
1..*
1
figure 4.1: relations in table 2.2 between activities and object types (adapted from [16]).
numerical data
the timestamp of an event occurring is a necessary features for the model, yet needs
conversion to be useful. instead of utilizing absolute dates and times, the relative time
elapsed between an event and the preceding event are calculated, as seen in table 4.1 :
table 4.1: example events with calculated elapsed time column.
event id event timestamp elapsed (s)
2812019-05-20 09:07:47 0
2822019-05-20 09:17:26 579
2832019-05-20 11:53:12 9346
22chapter 4. gan for ocel prediction
additionally, the values are normalized as described in equation 4.1 so that the model
does not learn false relations about the absolute value of elapsed time.
normalized value =value−minimum value
maximum value−minimum value(4.1)
this data can be encoded in other ways, but to show the approach in this thesis performs
well independent of a special encoding, the simplest one was chosen. the event timestamp
needs to be encoded in this manner, as well as any other numerical object attributes, such
asobject weight in table 2.3.
categorical data
categorical data such as event activity needs to undergo multiple transformations to be-
come usable in a machine learning model. first, the data is labelorintegerencoded. this
refers to converting values to a number, for example:
place order−→1
conﬁrm order−→2
pay order−→3
this alone makes categorical data usable in a model, however, the encoding can be misin-
terpreted. a model might learn a false hierarchy in the encoding from the natural order in
the numbers. this can lead to the model learning that 2 must come before 1, or because 2
is larger, it must occur more frequently than 1. these common unintended consequences
can be negated by encoding the numbers obtained using one hotencoding.
one hot encoding refers to converting the integers to a representation similar to a binary
encoding, where each category is represented by a column, as seen in table 4.2:
table 4.2: example activites one-hot encoded.
event activity place order conﬁrm order pay order
place order 1 0 0
conﬁrm order 0 1 0
pay order 0 0 1
theplace order activity would therefore be encoded as /angbracketleft1,0,0/angbracketright. theevent activity needs
to be one hot encoded as well as any categorical object attributes used in the prediction,
such asobject product in table 2.3.
vector representation
deﬁnition 4.1 (event vector ).given an event ei∈ewith the activity aiwhere
πact(ei) =aiwith the timetsamp tiwhereπtime(ei) =ti, and categorical attributes ci⊆
attwhere∀ci∈ciπtyp(ci) =stringandnumericalattributes ni⊆attwhere∀ni∈ni
πtyp(ni) =float:
•categorical data aiandci∈ciis one-hot encoded as enc(ai)andenc(ci)
23chapter 4. gan for ocel prediction
•elapsed time liis calculated from the timestamp tiandti−1whereπtime(ei−1) =ti−1
the resulting event vector for event eiis/angbracketleftenc(ai),enc(ci),ni,li/angbracketright
after normalizing the appropriate numerical values and encoding the categorical values,
the event vector from deﬁnition 4.1 can be built. as an example, take an event with an
activity, both categorical and numerical object attributes, and a corresponding elapsed
time. that example event is then represented as a vector:
event vector:/angbracketleft0,1,0,0/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
activity,0,0,0,1,0,0,0,0,0/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
categorical attributes,0.301,1,0.5,0.5818/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
numerical attributes,0.04818532/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
elapsed/angbracketright
in previous research [15] only the activity and elapsed time is encoded in the event vector.
object attributes that might have been present in the underlying process and stored in
information systems, typically are not preserved in traditional event logs, therefore, they
can not be used in the prediction. by leveraging the data contained in ocel, this thesis
augments the event vector with object attributes, which if the features are useful in the
prediction, can increase the accuracy.
a sequence of events necessitates an end of sequence (eos) bit, to signal that the end of
the case has been reached. therefore, the ﬁnal event is simply zeros and sets the eos bit.
an example case can be:
case:/angbracketleft/angbracketlefte1,0/angbracketright,/angbracketlefte2,0/angbracketright,/angbracketlefte3,0/angbracketright,/angbracketleft0,1/angbracketright/angbracketright
preﬁx/suﬃx split
deﬁnition 4.2 (preﬁx and suﬃx ).given a non-empty sequence of nevents
/angbracketlefte1,e2,e3,...en/angbracketrightordered based on the timestamp and related to an object o∈owhere
for1≤i≤n:o∈πomap(ei), a preﬁx is/angbracketlefte1,...,ek/angbracketrightfor somek≤n. then a suﬃx is the
remaining events /angbracketleftek,...,en/angbracketright.
when making a prediction, the input is an ongoing process called the preﬁxand the goal
is to predict the remainder of the process called the suﬃxas deﬁned in deﬁnition 4.2.
when preparing the ocel data, completed processes need to be split up into preﬁx/suﬃx
pairs to train the model. for a given process with ﬁve events eifor1≤i≤4, all possible
splits are created in table 4.3:
table 4.3: making example case into preﬁx and suﬃx splits.
preﬁx suﬃx
e1e2,e3,e4
e1,e2e3,e4
e1,e2,e3e4
this maximizes the amount of training data available and enables the model to predict
suﬃxes from both short and long input preﬁxes.
4.2 generator
as seen in section 4.1, the model needs to be able to take variable length sequences
(preﬁxes) as an input and produce variable length sequences (suﬃxes) as an output. as
24chapter 4. gan for ocel prediction
discussed in chapter 2, this is achieved with an encoder/decoder architecture used in
sequence to sequence models [32], which are the foundation of the generator. intuitively
the encoder returns a vector based on the input sequence and the decoder takes that as
input and returns the output sequence.
x1x2x3/angbracketlefteos/angbracketrighty1y5/angbracketlefteos/angbracketright encoder
decoderct
figure 4.2: encoder/decoder seq2seq model mapping /angbracketleftx1,x2,x3/angbracketrightto/angbracketlefty1,y2/angbracketright.
encoder
as illustrated in figure 4.2 the input sequence is a vector containing event vectors and the
/angbracketlefteos/angbracketrightto show the end of the sequence. this is the preﬁx; the sequence for the ongoing
process execution. the encoder is an lstm network which processes the preﬁx input
sequencex1,...,xtof lengtht. recall from deﬁnition 2.6 the cell state vector ct:
ct=ft◦ct−1+it◦˜ct
this is a summary of the input sequence for a timestep. the lstm cell is updated t
times, meaning the six equations in deﬁnition 2.6 are calculated, and the ﬁnal cell state
vector ctfor the entire preﬁx is given. as shown in figure 4.2 this is directly passed into
the decoder where it is used as the initial cell state.
decoder
thedecoderisanotherlstmnetworkthatstartsgeneratingtheoutputsequence y1,...yt/prime.
crucially, the output sequence length t/primecan be diﬀerent from the input sequence length
t. in each of the t/primedecoder updates, the output yt−1from the previous update is used
as the input for the current update.
conditional probability
the goal of the generator therefore, is to estimate the conditional probability of the output
sequence (suﬃx) y1,...,yt/primegiven an input sequence (preﬁx) x1,...,yt:
this probability given the encoder output ctis formally [32] given in equation 4.2:
p(y1,...,yt/prime|x1,...,xt) =t/prime/productdisplay
t=1p(yt|ct,y1,...,yt−1) (4.2)
25chapter 4. gan for ocel prediction
4.3 gumble-softmax
gan architectures require diﬀerentiable data in order to update the generator. however,
the vectors that are created from the event logs have some categorical data in them as well,
which when sampled from, are not diﬀerentiable. as demonstrated in [48], a sample from
a categorical distribution can be replaced with a diﬀerentiable sample from a gumbel-
softmax distribution.
letzbe categorical data with the class probabilities π1,π2,...,πk. these are one hot
encoded as described before. with gibeing the samples from gumbel(0,1) the gumbel
trick as deﬁned by [49] is given in equation 4.3:
z=one hot/parenleftbigg
argmax
i[gi+log(πi)]/parenrightbigg
(4.3)
however, the function returns non diﬀerentiable values so softmax is used to obtain a
diﬀerentiable approximation to arg max for yiwhereτrefers to the temperature, as seen
in equation 4.4:
yi=exp((log(πi) +gi)/τ)
/summationtextk
i=1exp((log(πj) +gj)/τ)(4.4)
4.4 gan architecture
preﬁx
encoder/decoder
fake suﬃx real suﬃx
discriminator lstm
real/fake classiﬁcation
figure 4.3: gan architecture for ocel prediction.
the generator of the gan consists of an encoder and decoder and receives a preﬁx as
input. conventional gans use random noise as the input, but since the goal is to make
predictions based on an ongoing process, a preﬁx is used instead. the generator returns
a fake suﬃx, which is compared to the real suﬃx by the discriminator, as seen in figure
4.3. the discriminator consists of an lstm and a fully connected layer and returns a
probability representing if the fake suﬃx resembles a real suﬃx.
26chapter 4. gan for ocel prediction
for a preﬁx pre, suﬃxsuf, generator g, and discriminator d, the objective functions
based on [50] [15] are deﬁned in deﬁnition 4.3:
deﬁnition 4.3 (generator and discriminator objective functions ).
l(d;g) =−log(d(suf))−log(1−d(g(pre)))
l(g;d) =−log/parenleftbiggd(g(pre))
1−d(g(pre))/parenrightbigg
first, the discriminator dis updated by minimizing the loss l(d;g)while the generator
stays ﬁxed. when the discriminator miss-classiﬁes a suﬃx, the discriminator loss penalizes
the discriminator. this occurs through backprapogation, where the weights of the network
are adjusted through gradient descent.
next the generator gis updated by minimizing the loss l(g;d)while the discriminator
stays ﬁxed. the generator is penalized when it produces suﬃxes that the discriminator
is able correctly classify. backpropagation occurs through both the discriminator and
generator so the gradients can be calculated, but only the generator’s weights are adjusted
in this step.
27chapter 4. gan for ocel prediction
28chapter 5
implementation
in this section the implementation of chapter 4 is detailed for the data preprocessing steps
and model initialization and training. furthermore, hyperparameter tuning of the model
is discussed, the web interface is described and the deployment is explained.
5.1 extracting rcll dataset
the rcll is a simulation of factory logistics discussed in more detail in chapter 6. the
events that occur are saved in a database with some unecessary for this thesis informa-
tion about the route, distance, and more. the relevant event information of indentiﬁer,
activity, and timestamp is extracted. the object types of robot, order, and components
are extracted as well and the event table of the ocel standard can be created. the
attributes for the objects are extracted to create the object table. the ﬁnal dataset is
stored according to the ocel standard in the json ﬁle format.
5.2 data preprocessing
the data preprocessing module handles the steps discussed in chapter 4 as well as some
common additional functions. the module was written in python 3, using the pandas
data analysis library1and pytorch machine learning library2.
importing ocel
the pm4py-mdl python package3is utilized to import the ocel data. reading both
xml and json ﬁles as per the ocel standard is supported and the import methods
return two pandas dataframes. one dataframe represents the events and is similar to
table 2.2 and the other represents the objects and is similar in form to table 2.3.
elapsed time calculation
the elapsed time is calculated for individual cases in the events dataframe. the elapsed
time for the ﬁrst event in a case, therefore, is zero and for every subsequent event, it is
the time that passed after the event right before.
1https://pandas.pydata.org/
2https://pytorch.org/
3https://github.com/javert899/pm4py-mdl
29chapter 5. implementation
one-hot encoding
the categorical values including activity names and categorical object attributes are one-
hot encoded and the mapping is saved for later reversal. this mapping is also important
when predicting for a new preﬁx, there the categorical values are encoded with this map-
ping so the model can interpret the data correctly.
normalizing
numerical values used in the prediction are normalized and the terms of the normaliza-
tion saved. when using the model in prediction these terms are needed to reverse the
normalization and interpret the results in absolute timestamp terms.
partitioning
when a mini-batch has randomly chosen inputs, it can have a large amount of variability
in the input lengths. while the model can be updated more frequently using mini-batch
gradient descent as shown in algorithm 1, the downside is that diﬀerent length cases
cause slowdowns in the computations, as observed in [32]. therefore, the partitions are
groups of cases with a similar length, which can be batched together.
variable length splits
within the created partitions, traces are split into every possible combination of lengths
for the preﬁx and suﬃx. the preﬁxes and corresponding suﬃxes are saved as pytorch
tensors. the tensors are saved as tensordatasets in dataloader objects. this enables
easy access during training.
5.3 model
the generator consists of two parts; the encoder and the decoder. the encoder is an
lstm network which maps the inputs to the hidden vector. the decoder is also an
lstm network connected to a fully connected layer and then passed through relu and
sigmoid activation functions. a concept called teacher forcing [51] is used in the generator
every so often based on randomness. when it is triggered, instead of using the output from
the decoder from the previous time step as the input for the current one, the real suﬃx is
used as the input. this can lead to faster training and better results. the discriminator
is an lstm network connected to a fully connected layer.
5.3.1 training
training occurs based on the algorithm 2.
the gradients need to be set to zero in lines 3 and 7 because pytorch accumulates the
gradients on the backward passes. exploding gradients can occur when large updates to
weights cause numerical under or overﬂow, which happens in lstm networks since they
need to unroll many timesteps as discussed in chapter 2. the solution to that is gradient
norm clipping seen in lines 6 and 9.
5.3.2 validation and testing
in the data preprocessing step, the main ocel data is split into training, validation, and
testing sets. training occurs with the training data, which represents 70% of the total
data. as seen in algorithm 2, during training the model is evaluated on validation data
30chapter 5. implementation
algorithm 2: training gan
1fornumber of epochs do
2fornumber of mini-batches do
3forpreﬁx, suﬃx in training data do
4 forward pass of generator and discriminator;
5 zero discriminator gradients;
6 update the discriminator to minimize loss;
7 clip discriminator gradient norm;
8 zero generator gradients;
9 update the generator to minimize loss;
10 clip generator gradient norm;
11 end
12 ifepoch multiple of 5 then
13 run model on validation data;
14 save model if beats current best;
15 end
16end
17end
periodically. validation data represents 10% of the total data. last, there is the testing
data with 20% of the total data. the model is benchmarked using either validation data
or testing data in the evaluation function. the model is set to evaluation mode to prevent
weights from being updated and a forward pass of the model (generator) is performed.
the fake suﬃx returned from the generator is compared to the real suﬃx in two metrics,
which are discussed in chapter 6.
5.4 hyperparameter tuning
figure 5.1: convergence of generator and discriminator loss on synthetic dataset.
convergence is diﬃcult for gans due to the nature of the adversarial game; gains by
the generator result in losses by the discriminator and vice versa. ideally, the generator
31chapter 5. implementation
improves to the point where the discriminator has a 50%accuracy. then, the loss calcu-
lated for each should be about the same, as seen in the convergence graph in figure 5.1.
this can be problematic since the discriminator continues giving feedback to the gener-
ator and the resulting fake suﬃxes can decrease in quality. as a result, the convergence
might be shortlived. training can fail because of model collapse, where the generator
can only output a small number of diﬀerent suﬃxes. convergence failure is also possible,
where the generator loss keeps increasing while the discriminator loss is near zero, mean-
ing the generator produces very poor quality suﬃxes that the discriminator can easily
identify.
the model has multiple hyperparameters: learning rate, type of optimizer, and the num-
ber of layers. the optuna python library4was used to aid in empirically ﬁnding the best
hyperparameters. the hyperparameters are suggested by optuna based on a given range
and then multiple trials are conducted to ﬁnd the best settings. optuna searches the range
of values eﬃciently using the tree-structured parzen estimator algorithm and can prune
trials that are performing poorly to avoid wasting resources. the algorithm repeatably
decreases the search space, ﬁrst searching in the range suggested. based on the evaluation
of the model with those hyperparameters, the range is narrowed, leading to an optimal
search space. the best hyperparameters found through tuning were: the rmsprop algo-
rithm for the optimizer, a learning rate of 5.5e−5, and ﬁve layers for the lstm networks.
the values were similar to the options used in past research [15].
5.5 interface
the web interface is implemented in python using the streamlit library5. as seen in
figure 5.2, the ﬁrst main section of the interface is select eventlog . there either an event
log in the ocel format can be uploaded, or one of the preloaded datasets picked from the
dropdown menu. next, there is an overview of common statistics regarding the activities
and object types present in the data. the choice of an object type to use in the prediction
is vital, therefore, a table visualizing the relations between activities and object types is
presented. the model can then be trained based on the selected object type and next the
prediction starts.
as seen in figure 5.3, the section for entering a preﬁx (ongoing case) starts with selecting
the object type. based on that information, the dropdown menu activityunder "enter
event information" is populated by all the activities that the object type has a relation to.
after selecting the activity, the timestamp information and identiﬁer for the object can be
entered. by choosing the "save event" button the event can be saved and is presented in
the table under "process execution". from there, more events can be created and saved to
create a preﬁx for which the prediction should be performed on. under the section "enter
object information" the ﬁelds are automatically retrieved from the ocel log, presenting
only the object attribute classes that are related to the object type. there, the desired
attribute values can be entered. that concludes the creation of a preﬁx with both event
and object attributes. subsequently, the interface presents the predicted suﬃx for the
preﬁx that was entered, using the trained model.
4https://optuna.org
5https://www.streamlit.io/
32chapter 5. implementation
figure 5.2: interface section for selecting the event log and viewing information.
5.6 deployment
to deploy the model and the interface easily, the container-orchestration system kuber-
netes6is used. the interface setup and required dependencies are deﬁned in a dockerﬁle
and a docker image7is built. this represents the information required to conﬁgure a
container in kubernetes using the deployment object. the kubernetes cluster can then
automatically create replica pods based on current load requirements and the interface is
exposed by the service object.
6https://kubernetes.io/
7https://www.docker.com/
33chapter 5. implementation
figure 5.3: interface section for inputting preﬁx.
34chapter 6
evaluation
inthischapterthetheexperimentalsetupisdetailed. thenthedatasetsusedinevaluating
the model are presented and the reslts are discussed.
6.1 experimental setup
the model was implemented as described in chapter 5. the training and testing was
performed on an intel xeon cpu, 16 gb ram, and a nvidia tesla t4 gpu with 16 gb
of gpu memory.
metrics
the evaluation metrics are kept the same as previous research for uniformity. to compare
the predicted suﬃxes to the real suﬃxes, the approach for calculating similarity sfrom
[15] is used as described in equation 6.1:
s(sf,sr) = 1−/parenleftbigg
dl(sf,sr)
max (|sf|,|sr|)/parenrightbigg
(6.1)
wheresfis the predicted suﬃx and sris the real suﬃx. since the suﬃx is a sequence,
damerau–levenshtein (dl) distance can be used. it is deﬁned as the minimum number
of operations needed to transform one sequence into the other sequence. the allowed
operations are insertion, deletion, substitution, or transposition.
as the measure of accuracy of timestamps, mean absolute error is used (mae) as seen
in equation 6.2:
mae =/summationtextn
i=1|tr−tf|
n(6.2)
wheretris the real timestamp and tfthe predicted timestamp.
35chapter 6. evaluation
6.2 synthetic dataset
to validate the approach a synthetic dataset was used. the synthetic dataset represents
an order process with diﬀerent object types. orders with multiple items are placed by
customers. items are packed into packages and sent out. an excerpt of the data can be
seen in figure a.1 in the appendix.
6.2.1 description
the activities modeled in the dataset are:
{place order, pick item, conﬁrm order, item out of stock, reorder item, pay order, create
package, send package, failed delivery, package delivered, payment reminder}
the object types in the dataset are:
{customers, items, orders, packages}
the attributes for each object type are shown in table 6.1:
table 6.1: object attributes in synthetic object centric event log.
object type object attribute
customers age
items color
orders price
packages weight
an important step in selecting an appropriate object type is understanding the relations
between activities and object types as seen in table 6.2.
table 6.2: relations between activities and object types in the synthetic dataset.
customers items orders packages
place order place order place order ∅
pick item pick item pick item ∅
conﬁrm order conﬁrm order conﬁrm order ∅
item out of stock item out of stock item out of stock ∅
reorder item reorder item reorder item ∅
pay order pay order pay order ∅
create package create package create package create package
send package send package send package send package
failed delivery failed delivery failed delivery failed delivery
package delivered package delivered package delivered package delivered
payment reminder payment reminder payment reminder ∅
additionally, to better understand the cases that are captured by the diﬀerent object
types, some statistics are given in table 6.3. these represent data after outliers outside of
two standard deviations in terms of case length had been removed, which is also what is
36chapter 6. evaluation
used when training. for example, in the case of the object type customers , this does not
remove any data, but in the case of orders, the number of cases decreases by less than 1%
and the max length for a case is decreased from 41 to 28.
table 6.3: statistics about synthetic object centric event log.
length of case case time (days)
number of cases max min mean max min mean
customers 17 1470 1171 1315.7 461.03 383.7 422.5
items 7860 10 7 7.82 103.87 0.51 14.48
orders 1923 28 7 15.57 114.69 1.67 18.9
packages 1238 4 3 3.14 7.71 0.03 1.69
6.2.2 results
table 6.4: sequence similarity and mae results for synthetic object centric event log.
sequence similariy s mae (normalized)
thesis taymouri [15] tax[13] thesis taymouri[15] tax[13]
customers 0.0986 0.0921 0.0371 0.4559 0.4983 0.5839
items 0.5102 0.5113 0.4781 0.0384 0.0461 0.0438
orders 0.3502 0.3288 0.3013 0.0336 0.0310 0.0487
packages 0.8654 0.8241 0.8121 0.0673 0.0632 0.0729
the predominant trend that can be observed in table 6.4 is that the approach detailed
in this thesis generally performs better than previous approaches across diﬀerent object
types. the largest improvement in sequence similarity can be observed for the object type
orders. this should mean that the object attribute pricefor object type ordersis a good
feature for the prediction of suﬃxes. to prove that assumption the model was trained
without the object attributes, meaning the model is almost identical in strucutre to the
approach by taymouri [15]. as expected, the results were equal. for the object types
items and packages less signiﬁcant improvements are observed. therefore, it is possible
the respective object attributes are less useful features for the model. the absolute results
of the object type packages were the best, most likely due to the low average case length
and little variance in possible event ﬂow.
the model is not able to predict suﬃxes well for the object type customer . taking into
account the statistics from table 6.3, this makes sense. there are only a few cases, making
learning features diﬃcult. furthermore, the average case length for cases of object type
ordersis signiﬁcantly longer than the other object types’ average case length. very long
cases clearly are diﬃcult for the model to predict. in the case of the synthetic event log,
the object type customers is not very useful in predicting an order process, since customers
make multiple orders in the dataset. this can hold interesting data about the ordering
habits of a customer, or can be used to predict when a customer might pay an order.
however, the structure of the model in this thesis as empirically demonstrated, is better
suited to shorter cases, therefore the metrics of sequence similarity and mae are very
low.
37chapter 6. evaluation
6.3 rcll dataset
the robocup logisitcs league (rcll) is a simulation of factory logistics. there are two
teams of three robots and the goal is to fulﬁll orders from a central system. the products
that can be ordered consist of the following components: a base, optional rings, and a
cap. there can be between zero and three rings, but there is always one base and one cap
according to the order. on a whole, the steps are to collect the base, mount rings per the
order, mount the cap, and deliver the order. to achieve this, the robots work together
navigating a map to access all the resources and workstations. an excerpt of the data can
be seen in figure a.2 in the appendix.
6.3.1 description
the activities modeled in the dataset are:
{clear-mps, deliver, discard-unknown, ﬁll-cap, ﬁll-rs, get-base-to-ﬁll-rs, mount-ﬁrst-ring,
mount-next-ring, process-mps, produce-c0, produce-cx}
the object types in the rcll object centric event log:
{robot, order, products}
the attributes for each object type are shown in table 6.5:
table 6.5: object attributes in rcll object centric event log.
object type object attribute
robot none
order delivery begin, delivery end
components station, cost
the object attributes of delivery begin/end refer to the delivery window that is associated
with the order. in the rcll simulation early delivery is considered fatal but late delivery
may be acceptable. the object attribute station and cost only applies if the component is
a ring. the station is the name of a ring station where the particular component needs to
be mounted at and the cost refers to how expensive it is to mount. all object types are
related to all activities in the rcll data and some statistics are given in table 6.6.
table 6.6: statistics about rcll object centric event log.
length of case case time (minutes)
number of cases max min mean max min mean
robot 3 94 88 91.67 16.65 4.711 11.838
orders 26 16 5 9.81 13.74 0.77 3.02
components 80 18 5 11.1 13.73 0.77 3.02
38chapter 6. evaluation
table 6.7: sequence similarity and mae results for rcll object centric event log.
sequence similariy s mae (normalized)
thesis taymouri [15] tax [13] thesis taymouri [15] tax [13]
robot 0.1408 0.1377 0.1128 0.4977 0.4992 0.5182
order 0.5242 0.4822 0.4627 0.0325 0.0312 0.0387
components 0.4629 0.4315 0.4179 0.0278 0.0281 0.0391
6.3.2 results
the trends observed in the synthetic dataset continue to be present with the rcll data,
as seen in table 6.7. overall, in both sequence similarity and mae, the model proposed
in this thesis meets or exceeds the previous research. for the object type orderthe
relatedobjectattributesenablethemodeltoachieveasigniﬁcantimprovementinsequence
similarity as opposed to the previous research. the improvement is less noticeable in the
timstamp prediction, which can lead to future research. the object type robotproved to
be diﬃcult to predict, most likely on account of the very long average case lengths. this
continues the trend seen in the synthetic data that the model struggles with longer cases.
furthermore, since there were no object attributes present for the object type robot, the
results are more or less the same as the approach by taymouri [15].
39chapter 6. evaluation
40chapter 7
conclusion
in this section, the thesis is summarized and an outlook for applications and expansions
are given.
7.1 summary
in this thesis, using object-centric event logs in state-of-the-art predictive models was
discussed. as demonstrated, the relations that frequently exist between object types and
activities in real processes can not be accurately modeled by traditional event logs. by
not forcing the selection of a single case id, the ocel standard enables the preservation
of such relations, as well as storing object attributes. in addition, the object attributes
contained in ocel data can hold important features for the prediction of next events and
timestamps (suﬃx) based on an ongoing case (preﬁx). while this had been used in past
research in the form of case attributes in traditional event logs, the most recent methods
were not utilizing this information.
the model proposed by this thesis augments the recent advancements in predictive meth-
ods with the rich data contained in ocel. the model makes use of a generative ad-
versarial network (gan) in a sequence to sequence model using encoder and decoder
long short-term memory layer (lstm). an individual event is encoded with activity
and timestamp information, as well as the relevant attributes. numerical and categori-
cal data is encoded and normalized where applicable. the model was ﬁrst trained and
evaluated on a synthetic event log to validate the approach. the synthetic event log rep-
resents an order process with multiple object types, including customers, items, orders ,
andpackages. the metrics for testing the model are a measure of sequence similarity
to evaluate the predicted suﬃx and mean absolute error for the predicted timestamps.
the results showed that overall, the approach presented in this thesis outperformed the
previous approaches in both metrics. for the object type orders, a noticeable increase in
sequence similarity was achieved. for the object type customers, the results were poor,
which can be explained by the long average case lengths and the low number of cases
available. these trends are also observed on a real event log of rcll data, which is a
simulation of factory logistics. again, object types which have short average case lengths
were able to perform better than previous research.
41chapter 7. conclusion
7.2 outlook
the main goal of the thesis was to use object-centric event logs with predictive methods.
by using object attributes as a feature, the model was able to outperform past approaches.
this can be applied to any ocel data with object attributes to improve the prediction
methods. however, there are some drawbacks, the main one being that only activities
related to the chosen object type can be predicted. this can lead to an incomplete or
disjointedviewoftheunderlyingprocess, whereintermediateactivitiesthatarenotrelated
to anobjecttypecan notbepredicted by thisapproach. therefore, the mainarea offuture
research is developing a method to predict a case using multiple object types, not just one
as in this thesis. this would allow for all activities to be predicted and can lead to more
useful real world applications. correlating the disjoint events was the topic of research
in [52]. by deﬁning correlation proﬁles, diﬀerent views on a process can be gained and
such research could be explored in the future. however, some more incremental research
based on the current work is possible as well. the encodings chosen for numerical and
categorical values were as simple as possible, to demonstrate the approach working well
independent of a special data preprocessing step. this can be improved by taking into
account business hours as a part of the timestamp prediction if such data is consistent
with those rules. this can lead to signiﬁcant increases in the accuracy since the model
presented in this thesis could predict an event to occur ten minutes after closing when
it should instead occur ten minutes after opening the next business day. furthermore,
there is some recent research to learn the time constraints of events using lstm layers
in time2vec [53]. instead of determining the business hours beforehand, time2vec can
learn the periodic and non-periodic patterns in the time data. furthermore, research to
determine the most useful types of object attributes can be conducted. in this thesis,
it was not exhaustively explored why certain attributes could lead to better results and
a more rigorous understanding of the factors that make certain attributes perform well
could lead to insights into how to improve predictions.
42appendix a
appendix
43appendix a. appendixevent id activity timestamp items orders customers packages
1.0 place order 2019-05-20 09:07:47 {880003, 880002, 880001, 880004} {990001} {marco pegoraro} ∅
2.0 place order 2019-05-20 10:35:21 {880005, 880006, 880008, 880007} {990002} {gyunam park} ∅
3.0 pick item 2019-05-20 10:38:17 {880006} {990002} {gyunam park} ∅
4.0 conﬁrm order 2019-05-20 11:13:54 {880003, 880002, 880001, 880004} {990001} {marco pegoraro} ∅
5.0 pick item 2019-05-20 11:20:13 {880002} {990001} {marco pegoraro} ∅
6.0 place order 2019-05-20 12:30:30 {880012, 880011, 880009, 880010} {990003} {majid raﬁei} ∅
7.0 conﬁrm order 2019-05-20 12:34:16 {880012, 880011, 880009, 880010} {990003} {majid raﬁei} ∅
figure a.1: first few events in event table from synthetic ocel
44appendix a. appendixevent id activity timestamp components order robot
2 fill-cap 2020-06-11 15:21:48.150 {cap_grey_1, base_silver_1} {o1} {0}
6 produce-c0 2020-06-11 15:22:06.251 {cap_grey_1, base_silver_1} {o1} {2}
15 deliver 2020-06-11 15:22:41.322 {cap_grey_1, base_silver_1} {o1} {2}
70 fill-cap 2020-06-11 15:25:31.418 {ring_yellow_3, cap_black_3, base_silver_3} {o12} {1}
78 fill-rs-1 2020-06-11 15:25:57.641 {ring_yellow_3, cap_black_3, base_silver_3} {o12} {1}
98 fill-cap 2020-06-11 15:27:01.212 {base_black_2, cap_grey_2} {o11} {0}
102 process-mps 2020-06-11 15:27:12.408 {base_black_2, cap_grey_2} {o11} {0}
107 clear-mps 2020-06-11 15:27:26.223 {base_black_2, cap_grey_2} {o11} {1}
114 deliver 2020-06-11 15:27:48.902 {base_black_2, cap_grey_2} {o11} {1}
figure a.2: first few events in event table from rcll ocel45appendix a. appendix
46bibliography
[1] wil van der aalst. process mining: data science in action . springer-verlag, 2
edition, . isbn 978-3-662-49850-7. doi: 10.1007/978-3-662-49851-4. url https:
//www.springer.com/gp/book/9783662498507 .
[2] alasdair gilchrist. industry 4.0 . apress. isbn 978-1-4842-2046-7. doi: 10.1007/
978-1-4842-2047-4.
[3] somayya madakam and siddharth tripathi. internet of things (iot): a literature
review. 03(5):164. doi: 10.4236/jcc.2015.35021. number: 05 publisher: scientiﬁc
research publishing.
[4] mirko polato, alessandro sperduti, andrea burattin, and massimiliano de leoni.
time and activity sequence prediction of business process instances. url http:
//arxiv.org/abs/1602.07566 .
[5] samuel mann, jan pennekamp, tobias brockhoﬀ, anahita farhang, mahsa pour-
bafrani, lukas oster, merih seran uysal, rahul sharma, uwe reisgen, klaus wehrle,
et al. connected, digitalized welding production—secure, ubiquitous utilization of
data across process layers. in advanced joining processes , pages 101–118. springer,
2020.
[6] merih seran uysal, sebastiaan j van zelst, tobias brockhoﬀ, anahita farhang ghah-
farokhi, mahsa pourbafrani, ruben schumacher, sebastian junglas, günther schuh,
and wm van der aalst. process mining for production processes in the automotive
industry. in industry forum at bpm , volume 20, 2020.
[7] mohammad reza harati nik, wil mp van der aalst, and mohammadreza fani sani.
bipm: combining bi and process mining. in data, pages 123–128, 2019.
[8] joerg evermann, jana-rebecca rehse, and peter fettke. predicting process be-
haviour using deep learning. 100:129–140. issn 01679236. doi: 10.1016/j.dss.2017.
04.003. url http://arxiv.org/abs/1612.04600 .
[9] francesco folino, massimo guarascio, and luigi pontieri. discovering context-aware
models for predicting business process performances. in on the move to meaningful
internet systems: otm 2012 , lecture notes in computer science, pages 287–304.
springer. isbn 978-3-642-33606-5. doi: 10.1007/978-3-642-33606-5_18.
[10] dominic breuker, martin matzner, patrick delfmann, and jörg becker. comprehen-
sible predictive models for business processes. 40(4):1009–1034. issn 0276-7783. doi:
10.25300/misq/2016/40.4.10.
47bibliography
[11] ieee standard for extensible event stream (xes) for achieving interoperability in
event logs and event streams. pages 1–50. doi: 10.1109/ieeestd.2016.7740858.
conference name: ieee std 1849-2016.
[12] vincenzo pasquadibisceglie, annalisa appice, giovanna castellano, and donato
malerba. using convolutional neural networks for predictive process analytics. in
2019 international conference on process mining (icpm) , pages 129–136. doi:
10.1109/icpm.2019.00028.
[13] niek tax, ilya verenich, marcello la rosa, and marlon dumas. predictive busi-
ness process monitoring with lstm neural networks. 10253:477–492. doi: 10.1007/
978-3-319-59536-8_30. url http://arxiv.org/abs/1612.02130 .
[14] farbod taymouri, marcello la rosa, sarah erfani, zahra dasht bozorgi, and ilya
verenich. predictive business process monitoring via generative adversarial nets: the
case of next event prediction. url http://arxiv.org/abs/2003.11268 .
[15] farbod taymouri and marcello la rosa. encoder-decoder generative adversarial nets
for suﬃx generation and remaining time prediction of business process models. url
http://arxiv.org/abs/2007.16030 .
[16] wil van der aalst. object-centric process mining: dealing with divergence and con-
vergence in event data. in software engineering and formal methods , lecture notes
in computer science, pages 3–25. springer international publishing, . isbn 978-3-
030-30446-1. doi: 10.1007/978-3-030-30446-1_1.
[17] anahita farhang ghahfarokhi, gyunam park, alessandro berti, and wil mp van der
aalst. ocel: a standard for object-centric event logs. in european conference on
advances in databases and information systems , pages 169–175. springer, 2021.
[18] anahita farhang ghahfarokhi, alessandro berti, and wil mp van der aalst. pro-
cess comparison using object-centric process cubes. arxiv preprint arxiv:2103.07184 ,
2021.
[19] anahita farhang ghahfarokhi and wil mp van der aalst. a python tool for object-
centric process mining comparison. arxiv e-prints , pages arxiv–2202, 2022.
[20] alessandro berti, anahita farhang ghahfarokhi, gyunam park, and wil mp van der
aalst. a scalable database for the storage of object-centric event logs. arxiv preprint
arxiv:2202.05639 , 2022.
[21] guangming li, eduardo gonzález lópez de murillas, renata medeiros de carvalho,
and wil m. p. van der aalst. extracting object-centric event logs to support process
mining on databases. in information systems in the big data era , lecture notes in
business information processing, pages 182–199. springer international publishing, .
isbn 978-3-319-92901-9. doi: 10.1007/978-3-319-92901-9_16.
[22] wil van der aalst, m. h. schonenberg, and m. song. time prediction based on
process mining. 36(2):450–475, . issn 0306-4379. doi: 10.1016/j.is.2010.09.001. url
http://www.sciencedirect.com/science/article/pii/s0306437910000864 .
[23] anahita farhang ghahfarokhi, gyunam park, alessandro berti, and wil van der
aalst. ocel standard. url http://ocel-standard.org/1.0/specification.
pdf.
48bibliography
[24] b. f. van dongen, r. a. crooy, and wil van der aalst. cycle time prediction: when
will this case ﬁnally be ﬁnished? in on the move to meaningful internet systems:
otm 2008 , lecture notes in computer science, pages 319–336. springer. isbn
978-3-540-88871-0. doi: 10.1007/978-3-540-88871-0_22.
[25] arik senderovich, chiara di francescomarino, chiara ghidini, kerwin jorbina, and
fabrizio maria maggi. intra and inter-case features in predictive process monitor-
ing: a tale of two dimensions. in business process management , lecture notes in
computer science, pages 306–323. springer international publishing. isbn 978-3-
319-65000-5. doi: 10.1007/978-3-319-65000-5_18.
[26] juergen schmidhuber. deep learning in neural networks. 61:85–117. issn 08936080.
doi: 10.1016/j.neunet.2014.09.003. url http://arxiv.org/abs/1404.7828 .
[27] michael nielsen. neural networks and deep learning . determination press.
[28] shi yan. understanding lstm and its diagrams. url https://medium.com/
mlreview/understanding-lstm-and-its-diagrams-37e2f46f1714 .
[29] sepp hochreiter and jürgen schmidhuber. long short-term memory. 9(8):1735–1780.
issn 0899-7667. doi: 10.1162/neco.1997.9.8.1735. publisher: mit press.
[30] ian goodfellow, jean pouget-abadie, mehdi mirza, bing xu, and david warde-
farley. generative adversarial nets. in advances in neural information processing
systems 27 , pages 2672–2680. curran associates, inc.
[31] alec radford, luke metz, and soumith chintala. unsupervised representation learn-
ing with deep convolutional generative adversarial networks. url http://arxiv.
org/abs/1511.06434 .
[32] ilya sutskever, oriol vinyals, and quoc v. le. sequence to sequence learning with
neural networks. url http://arxiv.org/abs/1409.3215 .
[33] rakesh agrawal, dimitrios gunopulos, and frank leymann. mining process models
from workﬂow logs. in advances in database technology — edbt’98 , lecture notes
in computer science, pages 467–483. springer. isbn 978-3-540-69709-1. doi: 10.
1007/bfb0101003.
[34] wil van der aalst, ton weijters, and laura maruster. workﬂow mining: discovering
process models from event logs. 16(9):1128–1142, . doi: 10.1109/tkde.2004.47.
[35] a. weijters and wil van der aalst. rediscovering workﬂow models from event-based
data using little thumb. 10:151–162. doi: 10.3233/ica-2003-10205.
[36] mai le, bogdan gabrys, and detlef nauck. a hybrid model for business process
event prediction. in research and development in intelligent systems xxix , pages
179–192. springer. isbn 978-1-4471-4739-8. doi: 10.1007/978-1-4471-4739-8_13.
[37] geetika t. lakshmanan, davood shamsi, yurdaer n. doganata, merve unuvar, and
rania khalaf. a markov prediction model for data-driven semi-structured business
processes. 42(1):97–126. issn 0219-3116. doi: 10.1007/s10115-013-0697-8.
[38] andreas rogge-solti and mathias weske. prediction of remaining service execution
time using stochastic petri nets with arbitrary ﬁring delays. in service-oriented
49bibliography
computing , lecture notes in computer science, pages 389–403. springer. isbn 978-
3-642-45005-1. doi: 10.1007/978-3-642-45005-1_27.
[39] ilya verenich, marlon dumas, marcello la rosa, fabrizio maria maggi, and irene
teinemaa. survey and cross-benchmark comparison of remaining time prediction
methods in business process monitoring. 10(4):34:1–34:34. issn 2157-6904. doi:
10.1145/3331449.
[40] manuel camargo, marlon dumas, and oscar gonzález-rojas. learning accurate
lstm models of business processes. in business process management , lecture notes
in computer science, pages 286–302. springer international publishing. isbn 978-
3-030-26619-6. doi: 10.1007/978-3-030-26619-6_19.
[41] alessandro berti and wil van der aalst. extracting multiple viewpoint models from
relational databases. url http://arxiv.org/abs/2001.02562 .
[42] a. p. simović, s. babarogić, and o. pantelić. a domain-speciﬁc language for sup-
porting event log extraction from erp systems. in 2018 7th international con-
ference on computers communications and control (icccc) , pages 12–16. doi:
10.1109/icccc.2018.8390430.
[43] e. gonzález lópez de murillas, h. a. reijers, and w. m. p. van der aalst. case
notion discovery and recommendation: automated event log building on databases.
62(7):2539–2575. issn 0219-3116. doi: 10.1007/s10115-019-01430-6.
[44] wil m. p. van der aalst and alessandro berti. discovering object-centric petri nets.
url http://arxiv.org/abs/2010.02047 .
[45] david cohn and richard hull. business artifacts: a data-centric approach to mod-
eling business operations and processes. 32:3–9.
[46] n. c. narendra, y. badr, p. thiran, and z. maamar. towards a uniﬁed approach
for business process modeling using context-based artifacts and web services. in
2009 ieee international conference on services computing , pages 332–339. doi:
10.1109/scc.2009.14.
[47] guangming li, renata medeiros de carvalho, and wil m. p. van der aalst. object-
centric behavioral constraint models: a hybrid model for behavioral and data perspec-
tives. in proceedings of the 34th acm/sigapp symposium on applied computing ,
sac ’19, pages 48–56. association for computing machinery, . isbn 978-1-4503-
5933-7. doi: 10.1145/3297280.3297287.
[48] eric jang, shixiang gu, and ben poole. categorical reparameterization with gumbel-
softmax. url http://arxiv.org/abs/1611.01144 .
[49] chris j. maddison, daniel tarlow, and tom minka. a* sampling. url http:
//arxiv.org/abs/1411.0030 .
[50] casper kaae sønderby, jose caballero, lucas theis, wenzhe shi, and ferenc huszár.
amortised map inference for image super-resolution. url http://arxiv.org/abs/
1610.04490 .
[51] ronald j. williams and david zipser. a learning algorithm for continually running
50bibliography
fully recurrent neural networks. 1(2):270–280. issn 0899-7667. doi: 10.1162/neco.
1989.1.2.270.
[52] guangming li, renata m. de carvalho, and wil aalst. conﬁgurable event correlation
for process discovery from object-centric event data. pages 203–210, . doi: 10.1109/
icws.2018.00033.
[53] seyed mehran kazemi, rishab goel, sepehr eghbali, janahan ramanan, jaspreet
sahota, sanjay thakur, stella wu, cathal smyth, pascal poupart, and marcus
brubaker. time2vec: learning a vector representation of time. url http:
//arxiv.org/abs/1907.05321 .
51