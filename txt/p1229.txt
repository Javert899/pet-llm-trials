process prediction with digital twins
tobias brockhoff1, malte heithoff2, istv ´an koren1, judith michael2, j´erˆome pfeiffer3, bernhard rumpe2,
merih seran uysal1, wil m. p. van der aalst1, and andreas wortmann3
1process and data science, rwth aachen university, aachen, germany
email: fbrockhoff,uysal,koren,wvdaalstg@pads.rwth-aachen.de
2software engineering, rwth aachen university, aachen, germany
email: fheithoff,michael,rumpeg@se-rwth.de
3institute for control engineering of machine tools and manufacturing units (isw)
university of stuttgart, stuttgart, germany, email: fjerome.pfeiffer,wortmanng@isw.uni-stuttgart.de
abstract —process discovery from event logs as well as process
prediction using process models at runtime are increasingly im-
portant aspects to improve the operation of digital twins of com-
plex systems. the integration of process mining functionalities
with model-driven digital twin architectures raises the question
which models are important for the model-driven engineering of
digital twins at designtime and at runtime. currently, research
on process mining and model-driven digital twins is conducted
in different research communities. within this position paper, we
motivate the need for the holistic combination of both research
directions to facilitate harnessing the data and the models of
the systems of the future at runtime. the presented position is
based upon continuous discussions, workshops, and joint research
between process mining experts and software engineering experts
in the internet of production excellence cluster. we aim to
motivate further joint research into the combination of process
mining techniques with model-driven digital twins to efﬁciently
combine data and models at runtime.
index terms—process mining, digital twins, model-driven
development, models@run.time
i. i ntroduction
digital twins (dts) [1] are everywhere: they are used to
improve the behavior of (cyber-physical) systems in agricul-
ture [2], construction [3], engineering [4], production [5],
medicine [6], business [7], and various other domains. while
research and industry produced different deﬁnitions, ranging
from underspeciﬁed (digital replica or virtual counterpart [8]),
over narrow (virtual representation based on augmented re-
ality technology [9]), to utopian (complete digital representa-
tion [10]) approaches. these concepts range between (1) high-
ﬁdelity design-time models used for design-space exploration,
dimensioning, or validation, and (2) software systems used to
represent, comprehend, and optimize the behavior of another
system during its runtime. we understand digital twins as the
latter: active software systems connected to another (cyber-
physical) system and using data and models during its runtime
to optimize its behavior. for the systematic combination of
data, models, and associated business processes, research in
both, model-driven development (mdd) and process mining
is required. especially process discovery from runtime data,
conformance checking, and process prediction using process
models at runtime are increasingly important aspects to sys-
tematically improve the operation of digital twins.currently, research on process mining and model-based
digital twins is conducted in different research communities.
through this position paper, we aim to motivate the need
for the holistic combination of both research directions to
facilitate harnessing the data and models of the cyber-physical
systems of the future at runtime. the position presented in this
paper is based upon continuous discussions, workshops, and
joint research between process mining experts and software
engineering experts in the internet of production excellence
cluster1. our position is manifested in the vision of a model-
driven toolchain and a software architecture that combine
established approaches from the model-driven development of
digital twins and process mining in the realm of industrial
processes [11] to better exploit the plethora of data available
to digital twins. with architecture and toolchain, we hope to
motivate and stimulate further joint research into the combi-
nation of process mining techniques with model-driven digital
twins to exploit efﬁciently using data and models at runtime.
in the remainder, sec. ii introduces preliminaries, sec. iii
details our vision, and sec. iv sketches a research roadmap.
ii. p reliminaries
we propose combining process mining within model-driven
digital twin architectures. to efﬁciently connect both, we
propose using the code generation framework montigem [12].
a. process mining
the massive amount of data generated in the internet of
things provides opportunities to connect high-level process-
oriented views with low-level events [13]. the data, e.g. col-
lected by a wide range of sensors, enables tracing operational
processes in detail. this enables identifying and remedying
operational challenges and problems early. operational fric-
tion [14] refers to phenomena hat lead to less-than-optimal
results like unnecessary rework, delays, or waste. at the
intersection of mdd and data-oriented technologies, process
mining [15] can play a pivotal role in removing it, by making
conformance and performance problems visible. conformance
checking techniques compare observed actions with modeled
behavior. it is backward-looking as opposed to forward-
looking process mining methods such as simulations [16],
1cf. https://iop.rwth-aachen.de
[bhk+21] t. brockhoff, m. heithoff, i. koren, j. michael, j. pfeiffer, b. rumpe, m. s. uysal, w. m. p. van der aalst, a. wortmann: 
process prediction with digital twins. 
in: int. conf. on model driven engineering languages and systems companion (models-c), 182-187, acm/ieee, oktober 2021. 
https://www.se-rwth.de/publications/fig. 1. essential components of a self-adaptive digital twin architecture
which can be used to predict delays and deviations. due to the
highly complex interplay of information systems as they are
typical for industrial settings involving various middleware so-
lutions, process discovery is challenging. we therefore embed
into our vision object-centric event logs [17] that document
processes involving different types of objects in industrial
processes, e.g., order-to-cash (including i.a. customer order,
production, shipment, invoicing). these possibly involve vari-
ous data sources spread over multiple information systems. we
enable backward-looking process mining for digital twins by
embedding it into their architecture using process models as
input of their code generation. the architecture sets the stage
for later forward-looking process mining that we describe in
the outlook of this paper.
b. model-driven digital twins
we understand dts as software systems that can actively
represent, control, and/or optimize the behavior of an observed
(cyber-physical) system. such a dt of a system consists of a
set of models of the system, a set of digital shadows (dss),
and provides a set of services to use the data and models
purposefully with respect to the original system [18].
figure 1 illustrates the software architecture of such a digital
twin [19] and interfaces a cyber-physical production system
(cpps) as well as to a data lake providing data from and about
the cpps as well as about the dt’s context. the architecture
comprises components with different responsibilities to realize
a self-adaptive loop [20]: the cpps produces data and persists
it in a data lake, which is a data storage that consists of
heterogeneous databases. based on this data, the pre-processor
queries data from the different databases and transforms the
data into dss [20]. a ds is a set of data traces and models
enriched with contextual and purposeful that can origin from
various sources and enables the dt to perform calculations
and reasoning based on it [21]. given the requested dss, the
evaluator compares the current state of the system with a list
of event-condition-action (eca) rules and creates goals sent to
the reasoner to mitigate undesired system states. the reasoner
comprises different ai subcomponents to fulﬁll the received
goals (such as ai planners and case-based reasoning [20]).
if the reasoner’s subcomponents produce multiple possiblesolutions, it determines the best one using application-speciﬁc
heuristics, e.g., fewest costs, most time efﬁcient, lowest energy
consumption. finally, the executor translates the selected so-
lution into executable commands and sends these to the cpps
(e.g., via opa ua). depending on feedback by the cpps it can
evaluate and alter the commands to contribute to a successful
execution of the solution.
c. montigem
we have successfully used montigem [12], [22], a highly
adaptable generator framework, to generate large parts of
a digital twin cockpit [19] that aims to integrate humans.
within a mdd approach, we use a set of models as input
for the generation process. the models used are uml class
diagrams in the textual cd4a language [22] to deﬁne the
data structure for a speciﬁc domain (domain model), data
models for aggregated information to be presented in certain
pages, graphical user interface (gui) models in the textual
gui-dsl [23] language to describe the user interface and its
relation to the data model, and object constraint language
(ocl) [24] expressions to constraint the data structure. the
generator provides all necessities for a full communication
pipe from the database over the backend up to the frontend.
a domain expert outlines the system for which montigem is
able to generate an almost ready-to-use application with few
hand-written extensions needed by a software engineer.
in the context of this paper, we aim to extend the process so
that the dt application is produced automatically in a single
integrated generation step. for example, we can include an
additional step into the automated generation process for the
described dt architecture. this generation step includes a
model in the architecture description language montiarc [25],
describing each component, its subcomponents, the compo-
nent’s interface and the communication to the other compo-
nents. other extension points are the possibility to integrate
initial process models to the dt.
the generated dt architecture enables networked moni-
toring and control of cpps. in the past, operational tech-
nologies (ot) were mostly used to control industrial equip-
ment [26] but not linked to networks, unlike information
technologies (it) responsible for core business operations
(e.g., erp or plc systems). today, there is a trend toward
ot-it convergence, with more and more physical devices
being integrated into networks. incorporating process-oriented
technologies enables new use cases, such as the process
prediction described in the next section.
iii. t owards process prediction for
model -driven digital twins
we envision a model-driven dt architecture that incorpo-
rates process mining techniques and uses models at runtime.
our vision covers ﬁve steps: (1) generation of the dt, (2)
conﬁguration of the generated dt application, (3) initialization
of dss, (4) process discovery, (5) runtime analysis, and (6)
user interaction.fig. 2. process and artifacts involved in the mdd of digital twins
a. generation of the dt
figure 2 highlights the model transformations involved in
creating a digital twin and resulting in a speciﬁc digital twin
application. these models can be fully or partly generated
or created by hand: we can use information sources such
as engineering models (automationml, cad, modellica,
sysml, etc.) to extract information relevant for the domain
model, eca rules the dt needs to react upon, its services or
constraints. other important information sources are experts
in these domains, who complete the missing models required
to derive and operate the digital twins manually. we pro-
pose the following minimal set of application-speciﬁc models
as crucial for the model-driven generation of digital twins:
(1) class diagram domain models describe the concepts and
data types available to the digital twin and are the basis for
digital shadows; (2) ocl models for validation of input data;
(3) tagging models for deﬁning roles and rights; (4) data
models to show selected parts of the domain model in certain
views of the gui; (5) gui models for describing the user
interfaces; and (6) process models that describe how the cpps
should behave. additionally to these application-speciﬁc mod-
els, our approach relies on application-independent models:
(1) a montiarc architecture model describing the components
of the digital twin and their relations; and (2) two class
diagrams describing the basic structure of all digital shadows
and process models that the digital twins can operate upon.
these models serve as the basis for generating applications of
self-adaptive digital twins.
example. an engineer aims to create a dt to represent
and optimize the behavior of an injection molding ma-chine: she deﬁnes relevant concepts, including properties
of sensors and actuators of the machine, manufacturing
phases, and attributes, such as injection ﬂow, nozzle
temperature, or back pressure in the domain model,
related constraints in ocl, and speciﬁes the required
digital shadows. she adds gui models for desired user
interfaces as well as process models of the intended be-
havior of the cpps. using the model-driven process, she
reuses all application-independent models and generates
the complete (but empty) digital application consisting of
data structures, data transfer objects, self-adaptive loop,
architecture implementation, and ui.
b. generated dt application
figure 3 shows the generated digital twin architecture
with its components and relevant data and model ﬂows. the
architecture comprises the components of the self-adaptive
digital twin together with process mining components. the
architecture has interfaces to the cpps , the data lake including
all relevant machine and process data and further relevant 3rd
party applications.
example. in our running example, the cpps is an
injection molding machine which is connected to the data
lake of the iop , 3rd party applications include, e.g., the
production planning system and the quality management
system.
the generated digital twin includes a database layer which
provides the domain concepts within the data storage, as well
as a data structure for the ds and process model concepts.
the other components access relevant information either via
interfaces from outside the dt or the interface of the database
layer. the following subsections discuss the dt components
and handled models in detail.
c. conﬁguration of the generated dt application
the digital twin application as generated is devoid of
behavior. in this step, a dt user or domain expert identiﬁes
relevant concepts and behavior and adds corresponding models
(e.g., eca rules or cases for case-based reasoning [20]).
moreover, she deﬁnes the digital shadow structures required
to reason about the cpps’s behavior and connects these to
the behavior models. to this end, she speciﬁes ds types that
deﬁne, for a given purpose, which parts of the data are relevant,
which models should be contained, the represented asset of the
cpps as well as the processes to obtain its data traces from the
various data sources available in the data lake. the structure
is based on the ds metamodel [21] and is extended to cover
further domain-speciﬁc requirements.
theprocess-aware digital twin cockpit pro-
vides a guided methodology: the domain expert chooses a
purpose he creates the ds for. this can vary from human-
readable text to a speciﬁc machine-processable optimization
model. in a next step, he deﬁnes which data (accessed by a
fully qualiﬁed address), with respective data points and meta
data, should be chosen from the data lake, how the data shouldfig. 3. main system architecture of a digital twin incorporating process mining services and models at runtime
be aggregated and what operations are performed on them.
such data points refer to data a ds needs to describe the
system’s behavior [21]. data aggregations can be modeled in
an expression language or a domain expert can even use a
more speciﬁc language or provide code in a general purpose
language. the domain expert then deﬁnes a ds type at design
time which is then stored in the dt database. ds types can
be modiﬁed or evolved at runtime by the user depending on
the current stage of investigation and it is possible to deﬁne
new ones at any point.
example. the domain expert deﬁnes a ds type with the
purpose of minimizing the rejection rate of a molded
part. the ds stands for the injection molding production
machine. relevant data traces for this purpose are job
histories including rejections rates for the last 6 months.
d. initialization of dss
in a next step we have to create all digital shadows using the
ds type deﬁnition. this happens once in the initialization step
with a selection of ds types, but also continuously throughout
the dt run time. the pre-processor component gets the
ds type from the database layer and receives new data from
the data lake through its interface. with the deﬁned rules,
thepre-processor decides which of the dss for which
purpose to address and computes data points cumulated in data
traces according to the ds type deﬁnition. in this step, the ds
type deﬁnition autonomously decides whether to update the
current digital shadow or to archive the current one and create
a new one with recent data. all digital shadows are then either
updated or newly stored in the dt data base, so each of the
components can access this information.
example. using the ds type deﬁnition, a ds for the
purpose minimizing the rejection rate of a molded part iscreated. the pre-processor aggregates the rejection
rates from every single job to one value per part. once
a week a new ds is created which aggregates again the
rejection rates based on the new time slice.
e. process discovery at digital twin runtime
the dt receives event logs from the data lake via
thedatabase layer andpre-processor into the
process discovery component. in the next step, it is
possible to derive process models out of event logs by ap-
plying process discovery algorithms, such as inductive visual
miner [27] and heuristic miner [28], which are stored in
theprocess discovery component. if the discovered
processes are relevant for a speciﬁc purpose and speciﬁed as
relevant models in the ds type, they are integrated within a
purpose-driven dss. moreover, they can be visualized to the
users via the dt cockpit for validation purposes.
example. it is possible to identify the underlying pro-
cess within the injection moulding machine using event
logs with the measurements of temperatures within the
injection moulding machine and the geolocation of each
molded part. this process is included within the ds with
the purpose to minimize the rejection rate for parts.
f . analysis at digital twin runtime
at runtime, the dt supports automatic or user-triggered
analyses. within the system architecture of the self-adaptive
dt, we consider two ways of runtime analysis using models:
the dt self-adaptive loop and the conformance checker
using process mining algorithms.
within the dt adaptive loop [18], the digital twin’s evalu-
ator component uses eca rules specifying undesired system
states through data patterns over ds types and ds instances
obtained from the data lake to determine whether action is
necessary. if so, it instantiates the goals deﬁned in the ecarules and passes these to the reasoner, which aims to ﬁnd a
solution to reach that goal by deﬁning concrete actions. the
actions are the input of the executor and either are translated
into machine commands or passed on to a human operator.
theconformance checker supports analysis and pre-
diction functionality with process mining and reasoning tech-
niques. it takes event logs and intended process models both
embedded in dss as input and identiﬁes deviations in the real-
world processes. the recognized problem is transferred to the
reasoner component to be resolved by concrete actions. it
can also store the proposed changes in the database layer to
let the user decide to change the original process model.
example. using eca rules derived from engineering
models or speciﬁed by domain experts, the digital twin’s
evaluator component identiﬁes that the nozzle through-
put is too low. it instantiates the goal “increase noz-
zle throughput” and passes it to the reasoner, which
leverages its ai subcomponents to produce a plan to
heat the material a bit more and increase pressure to
improve throughput. this plan is passed to the executor,
which translates this into opa ua commands and passes
these to the machine. concerning the process models,
theconformance checker detects inconsistencies
in discrete conﬁgurations, that resulted in process steps
taking too long.
g. user interaction at digital twin runtime
the generated dt provides a graphical interface for dif-
ferent user groups, also referred to as process-aware dt
cockpit as a client-server architecture (visual analytics, data
aggregation and business logics in the backend component
and visualizations in the frontend component).
the users are able to deﬁne ds types via the ds type
designer of the frontend , view historical information in
digital shadows and event logs, change created dss and
validate discovered process models. operators can receive
support for malfunctions in form of concrete actions.
example. the gui shows, e.g., the process with the
temperatures in each process step of the injection mould-
ing machine together with detected changes within the
rejection rate. moreover, concrete actions are shown to
reduce the temperature in speciﬁc process steps of the
machine to reduce the rejection rate.
this vision allows us to create a self-adaptive dt which
is able to handle and update models at runtime - both,
automatically and by user intervention.
iv. r oadmap and challenges
we propose a generative approach to combine model-driven
with data-driven technologies in the realm of process mining.
the digital twin architecture explicitly includes process mining
components that leverage the massive amount of data available
in the internet of things. this allows to gain new insights
by combining process-level models with low-level event data.combining comparative, object-centric, and forward-looking
process mining will contribute to creating digital shadows
that can be used to manage, control, and improve operational
processes. the instantiation of the architecture allows to drill-
down processes when a problem emerges, and even suggest
actions to human operators. the goal is to continuously
improve processes and respond to changes. we, thus, plan
to include research on action-oriented process mining [29]
in our architecture. the process-aware dt cockpit
keeps the human in the loop.
further model-driven software engineering (mdse) re-
search for dts. from the mdse perspective, the realization
of such an approach requires (1) the adaption of existing gen-
erators such as montigem to be able to handle the additional
models in different domain-speciﬁc languages (dsls), (2)
the integration of further generation steps, (3) to extend the
runtime environment of the dt to be able to handle process
models at runtime, and (4) to extend the runtime environment
of the dt or provide apis to include process mining services.
process mining is an integral part of our dt architecture
and is included internally. the interfaces required to handle
digital shadows and provide user support have to be tailored
to speciﬁc needs within digital twins and for their user groups.
deriving dts from engineering models. currently, digital
twins are engineered ad-hoc, with models created from scratch,
or other approaches only loosely based on the represented
system. for a truly efﬁcient engineering of dts, we need
to leverage knowledge contained in documents and original
engineering models.
automatically exploiting dt insights. where digital twins
are in place, they can provide tremendous insights about the
operation of the particular observed system instance. often,
these insights can be applied to other instances of the same
system type, similar systems, and future versions of these sys-
tems. yet, we are lacking means to automatically exploit these
insights sustainably. automatically improving the engineering
models of the observed system based on insights produced
by its digital twins could be valuable angle to improve this.
together with the aforementioned derivation, this would pave
the way for a model-driven devops with dts [30].
models at runtime in dts. szvetits and zdun [31] have
investigated how existing research literature uses models at
runtime. in the context of our work, models at runtime are
speciﬁcally used within self-adaptive systems [32]. our ap-
proach for self-adapting dts goes one step further to existing
approaches and allows for both, autonomic control loops as
well as human intervention. together with process mining we
thereby integrate manifold human control possibilities from
low-level system events to business processes in it.
researching digital shadows. the deﬁnition of the structure
of dss required lengthy discussions with different use cases
and stakeholders within the excellence cluster internet of
production [21], with aspects still being researched. from
a computer science perspective, the long-term operation of
digital twins poses further challenges such as how to handle
ds and ds-type evolvement,we believe our approach helps to overcome the challenges
of bi-directional synchronization between digital twins and
their actual systems [33], as our approach is able to (1) take the
raw runtime data provided by the cpps via the data lake and
extract the relevant information within the pre-processor , (2)
evaluate and reason about the digital twin models within digital
shadows to use this information extracted from the runtime
data, and (3) provide concrete actions produced using these
digital twin models to be fed into the system during execution
in an automated way or via human operators.
acknowledgement
funded by the deutsche forschungsgemeinschaft (dfg,
german research foundation) under germany’s excellence
strategy – exc 2023 internet of production -390621612.
we thank the alexander von humboldt (avh) stiftung for
supporting our research.
references
[1] w. kritzinger, m. karner, g. traar, j. henjes, and w. sihn, “digital
twin in manufacturing: a categorical literature review and classiﬁcation,”
ifac-papersonline , vol. 51, no. 11, pp. 1016–1022, 2018, 16th ifac
symp. on information control problems in manufacturing incom’18.
[2] j. reitz, m. schluse, and j. roßmann, “industry 4.0 beyond the factory:
an application to forestry,” in tagungsband des 4. kongresses montage
handhabung industrieroboter . springer, 2019, pp. 107–116.
[3] t. ruohom ¨aki, e. airaksinen, p. huuska, o. kes ¨aniemi, m. martikka,
and j. suomisto, “smart city platform enabling digital twin,” in proc.
of the int. conf. on intelligent systems (is) . ieee, 2018, pp. 155–161.
[4] m. ciavotta, m. alge, s. menato, d. rovere, and p. pedrazzoli,
“a microservice-based middleware for the digital factory,” procedia
manufacturing , vol. 11, pp. 931–938, 2017.
[5] h. wang, m. zhou, and b. liu, “tolerance allocation with simulation-
based digital twin for cfrp-metal countersunk bolt joint,” in int.
mechanical engineering congress and exposition , vol. 52019, 2018.
[6] n. k. chakshu, j. carson, i. sazonov, and p. nithiarasu, “a semi-
active human digital twin model for detecting severity of carotid
stenoses from head vibration-—a coupled computational mechanics and
computer vision method,” international journal for numerical methods
in biomedical engineering , vol. 35, no. 5, p. e3180, 2019.
[7] l. reinkemeyer, “process mining, rpa, bpm, and dto,” in process
mining in action , l. reinkemeyer, ed. springer, 2020, pp. 41–44.
[8] c.-s. shim, n.-s. dang, s. lon, and c.-h. jeon, “development of a
bridge maintenance system for prestressed concrete bridges using 3d
digital twin model,” structure and infrastructure engineering , vol. 15,
no. 10, pp. 1319–1332, 2019.
[9] h. pargmann, d. euhausen, and r. faber, “intelligent big data process-
ing for wind farm monitoring and analysis based on cloud-technologies
and digital twins: a quantitative approach,” in int. conf. on cloud
computing and big data analysis (icccbda) . ieee, 2018.
[10] c. mandolla, a. m. petruzzelli, g. percoco, and a. urbinati, “building
a digital twin for additive manufacturing through the exploitation of
blockchain: a case analysis of the aircraft industry,” computers in
industry , vol. 109, pp. 134–152, 2019.
[11] m. s. uysal, s. j. van zelst, t. brockhoff, a. f. ghahfarokhi, m. pour-
bafrani, r. schumacher, s. junglas, g. schuh, and w. m. van der aalst,
“process mining for production processes in the automotive industry,”
inindustry forum at bpm’20 , 2020.
[12] k. adam, j. michael, l. netz, b. rumpe, and s. varga, “enterprise
information systems in academia and practice: lessons learned from a
mbse project,” in 40 years emisa (emisa’19) , vol. lni 304, 2020.
[13] c. janiesch, a. koschmider, m. mecella, b. weber, a. burattin, c. di
ciccio, g. fortino, a. gal, u. kannengiesser, f. leotta, f. mannhardt,
a. marrella, j. mendling, a. oberweis, m. reichert, s. rinderle-ma,
e. serral, w. song, j. su, v . torres, m. weidlich, m. weske, and
l. zhang, “the internet of things meets business process management:
a manifesto,” ieee systems, man, and cybernetics magazine , vol. 6,
no. 4, pp. 34–44, 2020.[14] w. m. p. van der aalst, t. brockhoff, a. f. ghahfarokhi, m. pourbafrani,
m. s. uysal, and s. j. van zelst, “removing operational friction using
process mining: challenges provided by the internet of production
(iop),” in data management technologies and applications . springer,
2021.
[15] w. m. p. van der aalst, process mining: data science in action . berlin,
heidelberg: springer berlin heidelberg, 2016.
[16] m. kerremans, “market guide for process mining,” 2019, last
access: 28.07.2021. [online]. available: https://www.gartner.com/en/
documents/3939836/market-guide-for-process-mining
[17] w. m. p. van der aalst, “object-centric process mining: dealing with
divergence and convergence in event data,” in software engineering
and formal methods , ser. lncs, p. c. ¨olveczky and g. sala ¨un, eds.
springer, 2019, vol. 11724, pp. 3–25.
[18] p. bibow, m. dalibor, c. hopmann, b. mainz, b. rumpe, d. schmalz-
ing, m. schmitz, and a. wortmann, “model-driven development of
a digital twin for injection molding,” in int. conf. on advanced
information systems engineering (caise’20) , ser. lncs, vol. 12127.
springer, 2020, pp. 85–100.
[19] m. dalibor, j. michael, b. rumpe, s. varga, and a. wortmann,
“towards a model-driven architecture for interactive digital twin
cockpits,” in conceptual modeling . springer, 2020, pp. 377–387.
[20] t. bolender, g. b ¨urvenich, m. dalibor, b. rumpe, and a. wortmann,
“self-adaptive manufacturing with digital twins,” in 2021 int. symp.
on software engineering for adaptive and self-managing systems
(seams) . ieee, 2021, pp. 156–166.
[21] f. becker, p. bibow, m. dalibor, a. gannouni, v . hahn, c. hopmann,
m. jarke, i. koren, m. kr ¨oger, j. lipp, j. maibaum, j. michael,
b. rumpe, p. sapel, n. sch ¨afer, g. j. schmitz, g. schuh, and a. wort-
mann, “a conceptual model for digital shadows in industry and its
application,” in int. conf. on conceptual modeling (er’21) . springer,
2021.
[22] a. gerasimov, j. michael, l. netz, b. rumpe, and s. varga, “continuous
transition from model-driven prototype to full-size real-world enter-
prise information systems,” in 25th am. conf. on information systems
(amcis 2020) . ais, 2020.
[23] a. gerasimov, j. michael, l. netz, and b. rumpe, “agile generator-
based gui modeling for information systems,” in modelling to pro-
gram (m2p) . springer, 2021, pp. 113–126.
[24] m. richters and m. gogolla, ocl: syntax, semantics, and tools .
springer, 2002, pp. 42–68.
[25] r. heim, o. kautz, j. o. ringert, b. rumpe, and a. wortmann,
“retroﬁtting controlled dynamic reconﬁguration into the architecture
description language montiarcautomaton,” in europ. conf. on soft-
ware architecture - (ecsa’16) , ser. lncs, vol. 9839. springer, 2016.
[26] a. hahn, “operational technology and information technology in indus-
trial control systems,” in cyber-security of scada and other industrial
control systems . springer, 2016, pp. 51–68.
[27] s. j. j. leemans, d. fahland, and w. m. p. van der aalst, “process
and deviation exploration with inductive visual miner,” in bpm demo
sessions 2014 at int. conf. on business process management (bpm’14) ,
ser. ceur, vol. 1295. ceur-ws.org, 2014, p. 46.
[28] a. weijters, w. van der aalst, and a. medeiros, “process mining with
the heuristics miner-algorithm,” beta working paper series, wp 166,
eindhoven university of technology, eindhoven, 2006.
[29] g. park and w. m. p. van der aalst, “a general framework for action-
oriented process mining,” in business process management workshops ,
ser. lnbip, a. del r ´ıo ortega, h. leopold, and f. m. santoro, eds.
springer, 2020, vol. 397, pp. 206–218.
[30] b. combemale and m. wimmer, “towards a model-based devops for
cyber-physical systems,” in software engineering aspects of continuous
development and new paradigms of software production and deploy-
ment (devops’19) , ser. lncs, vol. 12055. springer, 2020, pp. 84–94.
[31] m. szvetits and u. zdun, “systematic literature review of the objectives,
techniques, kinds, and architectures of models at runtime,” software &
systems modeling , vol. 15, no. 1, pp. 31–69, 2016.
[32] a. bennaceur, r. france, g. tamburrelli, t. v ogel, p. j. mosterman,
w. cazzola, f. m. costa, a. pierantonio, m. tichy, m. aks ¸it et al. ,
“mechanisms for leveraging models at runtime in self-adaptive soft-
ware,” in models@ run. time . springer, 2014, pp. 19–46.
[33] f. bordeleau, b. combemale, r. eramo, m. van den brand, and
m. wimmer, “towards model-driven digital twin engineering: cur-
rent opportunities and future challenges,” in systems modelling and
management . springer, 2020, pp. 43–54.